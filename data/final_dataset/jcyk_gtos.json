{"home.repos.pwc.inspect_result.jcyk_gtos.translator_data.merge.merge_files": [[1, 20], ["open().readlines", "open().readlines", "open().readlines", "open().readlines", "print", "len", "len", "len", "len", "len", "len", "len", "len", "open", "zip", "open", "open", "open", "open", "d.rstrip().split", "h.rstrip().split", "s.rstrip().split", "t.rstrip().split", "len", "len", "len", "len", "len", "len", "fo.write", "d.rstrip", "h.rstrip", "s.rstrip", "t.rstrip", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["def", "merge_files", "(", "dep_file", ",", "head_file", ",", "tok_file", ",", "tgt_file", ",", "out_file", ")", ":", "\n", "    ", "drop", "=", "0", "\n", "dep", "=", "open", "(", "dep_file", ")", ".", "readlines", "(", ")", "\n", "head", "=", "open", "(", "head_file", ")", ".", "readlines", "(", ")", "\n", "tok", "=", "open", "(", "tok_file", ")", ".", "readlines", "(", ")", "\n", "tgt", "=", "open", "(", "tgt_file", ")", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "dep", ")", "==", "len", "(", "head", ")", "==", "len", "(", "tok", ")", "==", "len", "(", "tgt", ")", ",", "(", "len", "(", "dep", ")", ",", "len", "(", "head", ")", ",", "len", "(", "tok", ")", ",", "len", "(", "tgt", ")", ")", "\n", "with", "open", "(", "out_file", ",", "'w'", ")", "as", "fo", ":", "\n", "        ", "for", "d", ",", "h", ",", "s", ",", "t", "in", "zip", "(", "dep", ",", "head", ",", "tok", ",", "tgt", ")", ":", "\n", "            ", "dd", "=", "d", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "hh", "=", "h", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "ss", "=", "s", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "tt", "=", "t", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "assert", "len", "(", "dd", ")", "==", "len", "(", "hh", ")", "==", "len", "(", "ss", ")", ",", "(", "len", "(", "dd", ")", ",", "len", "(", "hh", ")", ",", "len", "(", "ss", ")", ",", "d", ",", "h", ",", "s", ",", "ss", "[", "-", "1", "]", ")", "\n", "if", "not", "0.5", "*", "len", "(", "dd", ")", "<=", "len", "(", "tt", ")", "<=", "4", "*", "len", "(", "dd", ")", ":", "\n", "                ", "drop", "+=", "1", "\n", "", "else", ":", "\n", "                ", "fo", ".", "write", "(", "d", "+", "h", "+", "s", "+", "t", ")", "\n", "", "", "", "print", "(", "drop", ")", "\n", "", "import", "sys", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.AMRGraph.__init__": [[24, 72], ["smatch_amr.get_triples", "networkx.DiGraph", "dict", "dict", "AMRGraph.is_attr_or_abs_form", "AMRGraph.AMRGraph.graph.add_node", "AMRGraph.AMRGraph._add_edge", "AMRGraph.AMRGraph._add_edge", "v.lower.lower.rstrip", "AMRGraph._is_abs_form", "discard_regexp.match", "print", "AMRGraph._is_attr_form", "AMRGraph._is_abs_form", "AMRGraph._is_abs_form", "v.lower.lower.lower", "print", "len", "print"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.is_attr_or_abs_form", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph._add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph._add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_attr_form", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form"], ["    ", "def", "__init__", "(", "self", ",", "smatch_amr", ")", ":", "\n", "# transform amr from original smatch format into our own data structure", "\n", "        ", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "=", "smatch_amr", ".", "get_triples", "(", ")", "\n", "self", ".", "root", "=", "smatch_amr", ".", "root", "\n", "self", ".", "graph", "=", "nx", ".", "DiGraph", "(", ")", "\n", "self", ".", "name2concept", "=", "dict", "(", ")", "\n", "\n", "\n", "# will do some adjustments", "\n", "self", ".", "abstract_concepts", "=", "dict", "(", ")", "\n", "for", "_", ",", "name", ",", "concept", "in", "instance_triple", ":", "\n", "            ", "if", "is_attr_or_abs_form", "(", "concept", ")", ":", "\n", "                ", "if", "_is_abs_form", "(", "concept", ")", ":", "\n", "                    ", "self", ".", "abstract_concepts", "[", "name", "]", "=", "concept", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'bad concept'", ",", "_", ",", "name", ",", "concept", ")", "\n", "", "", "self", ".", "name2concept", "[", "name", "]", "=", "concept", "\n", "self", ".", "graph", ".", "add_node", "(", "name", ")", "\n", "", "for", "rel", ",", "concept", ",", "value", "in", "attribute_triple", ":", "\n", "            ", "if", "rel", "==", "'TOP'", ":", "\n", "                ", "continue", "\n", "# discard some empty names", "\n", "", "if", "rel", "==", "'name'", "and", "discard_regexp", ".", "match", "(", "value", ")", ":", "\n", "                ", "continue", "\n", "# abstract concept can't have an attribute", "\n", "", "if", "concept", "in", "self", ".", "abstract_concepts", ":", "\n", "                ", "print", "(", "rel", ",", "self", ".", "abstract_concepts", "[", "concept", "]", ",", "value", ",", "\"abstract concept cannot have an attribute\"", ")", "\n", "continue", "\n", "", "name", "=", "\"%s_attr_%d\"", "%", "(", "value", ",", "len", "(", "self", ".", "name2concept", ")", ")", "\n", "if", "not", "_is_attr_form", "(", "value", ")", ":", "\n", "                ", "if", "_is_abs_form", "(", "value", ")", ":", "\n", "                    ", "self", ".", "abstract_concepts", "[", "name", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'bad attribute'", ",", "rel", ",", "concept", ",", "value", ")", "\n", "continue", "\n", "", "", "self", ".", "name2concept", "[", "name", "]", "=", "value", "\n", "self", ".", "_add_edge", "(", "rel", ",", "concept", ",", "name", ")", "\n", "\n", "", "for", "rel", ",", "head", ",", "tail", "in", "relation_triple", ":", "\n", "            ", "self", ".", "_add_edge", "(", "rel", ",", "head", ",", "tail", ")", "\n", "\n", "# lower concept", "\n", "", "for", "name", "in", "self", ".", "name2concept", ":", "\n", "            ", "v", "=", "self", ".", "name2concept", "[", "name", "]", "\n", "if", "not", "_is_abs_form", "(", "v", ")", ":", "\n", "                ", "v", "=", "v", ".", "lower", "(", ")", "\n", "", "v", "=", "v", ".", "rstrip", "(", "'_'", ")", "\n", "self", ".", "name2concept", "[", "name", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.AMRGraph.__len__": [[73, 75], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "name2concept", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.AMRGraph._add_edge": [[76, 81], ["AMRGraph.AMRGraph.graph.add_node", "AMRGraph.AMRGraph.graph.add_node", "AMRGraph.AMRGraph.graph.add_edge", "AMRGraph.AMRGraph.graph.add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge"], ["", "def", "_add_edge", "(", "self", ",", "rel", ",", "src", ",", "des", ")", ":", "\n", "        ", "self", ".", "graph", ".", "add_node", "(", "src", ")", "\n", "self", ".", "graph", ".", "add_node", "(", "des", ")", "\n", "self", ".", "graph", ".", "add_edge", "(", "src", ",", "des", ",", "label", "=", "rel", ")", "\n", "self", ".", "graph", ".", "add_edge", "(", "des", ",", "src", ",", "label", "=", "rel", "+", "'_reverse_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.AMRGraph.bfs": [[82, 99], ["set", "len", "g.neighbors", "len", "g.number_of_nodes", "queue.append", "depths.append", "set.add"], "methods", ["None"], ["", "def", "bfs", "(", "self", ")", ":", "\n", "        ", "g", "=", "self", ".", "graph", "\n", "queue", "=", "[", "self", ".", "root", "]", "\n", "depths", "=", "[", "0", "]", "\n", "visited", "=", "set", "(", "queue", ")", "\n", "step", "=", "0", "\n", "while", "step", "<", "len", "(", "queue", ")", ":", "\n", "            ", "u", "=", "queue", "[", "step", "]", "\n", "depth", "=", "depths", "[", "step", "]", "\n", "step", "+=", "1", "\n", "for", "v", "in", "g", ".", "neighbors", "(", "u", ")", ":", "\n", "                ", "if", "v", "not", "in", "visited", ":", "\n", "                    ", "queue", ".", "append", "(", "v", ")", "\n", "depths", ".", "append", "(", "depth", "+", "1", ")", "\n", "visited", ".", "add", "(", "v", ")", "\n", "", "", "", "is_connected", "=", "(", "len", "(", "queue", ")", "==", "g", ".", "number_of_nodes", "(", ")", ")", "\n", "return", "queue", ",", "depths", ",", "is_connected", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.AMRGraph.collect_concepts_and_relations": [[100, 116], ["AMRGraph.AMRGraph.bfs", "dict", "enumerate", "dict", "enumerate", "list", "networkx.all_shortest_paths", "dict", "len", "[].append", "range", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.bfs"], ["", "def", "collect_concepts_and_relations", "(", "self", ")", ":", "\n", "        ", "g", "=", "self", ".", "graph", "\n", "nodes", ",", "depths", ",", "is_connected", "=", "self", ".", "bfs", "(", ")", "\n", "concepts", "=", "[", "self", ".", "name2concept", "[", "n", "]", "for", "n", "in", "nodes", "]", "\n", "relations", "=", "dict", "(", ")", "\n", "for", "i", ",", "src", "in", "enumerate", "(", "nodes", ")", ":", "\n", "            ", "relations", "[", "i", "]", "=", "dict", "(", ")", "\n", "for", "j", ",", "tgt", "in", "enumerate", "(", "nodes", ")", ":", "\n", "                ", "relations", "[", "i", "]", "[", "j", "]", "=", "list", "(", ")", "\n", "for", "path", "in", "nx", ".", "all_shortest_paths", "(", "g", ",", "src", ",", "tgt", ")", ":", "\n", "                    ", "info", "=", "dict", "(", ")", "\n", "info", "[", "'node'", "]", "=", "path", "[", "1", ":", "-", "1", "]", "\n", "info", "[", "'edge'", "]", "=", "[", "g", "[", "path", "[", "i", "]", "]", "[", "path", "[", "i", "+", "1", "]", "]", "[", "'label'", "]", "for", "i", "in", "range", "(", "len", "(", "path", ")", "-", "1", ")", "]", "\n", "info", "[", "'length'", "]", "=", "len", "(", "info", "[", "'edge'", "]", ")", "\n", "relations", "[", "i", "]", "[", "j", "]", ".", "append", "(", "info", ")", "\n", "", "", "", "return", "concepts", ",", "depths", ",", "relations", ",", "is_connected", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_attr_form": [[13, 15], ["x.endswith", "number_regexp.match"], "function", ["None"], ["def", "_is_attr_form", "(", "x", ")", ":", "\n", "    ", "return", "(", "x", "in", "attr_value_set", "or", "x", ".", "endswith", "(", "'_'", ")", "or", "number_regexp", ".", "match", "(", "x", ")", "is", "not", "None", ")", "\n", "", "def", "_is_abs_form", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form": [[15, 17], ["abstract_regexp0.match", "abstract_regexp1.match"], "function", ["None"], ["", "def", "_is_abs_form", "(", "x", ")", ":", "\n", "    ", "return", "(", "abstract_regexp0", ".", "match", "(", "x", ")", "is", "not", "None", "or", "abstract_regexp1", ".", "match", "(", "x", ")", "is", "not", "None", ")", "\n", "", "def", "is_attr_or_abs_form", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.is_attr_or_abs_form": [[17, 19], ["AMRGraph._is_attr_form", "AMRGraph._is_abs_form"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_attr_form", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form"], ["", "def", "is_attr_or_abs_form", "(", "x", ")", ":", "\n", "    ", "return", "_is_attr_form", "(", "x", ")", "or", "_is_abs_form", "(", "x", ")", "\n", "", "def", "need_an_instance", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph.need_an_instance": [[19, 21], ["AMRGraph._is_attr_form", "abstract_regexp0.match"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_attr_form"], ["", "def", "need_an_instance", "(", "x", ")", ":", "\n", "    ", "return", "(", "not", "_is_attr_form", "(", "x", ")", "or", "(", "abstract_regexp0", ".", "match", "(", "x", ")", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.RelationEncoder.__init__": [[67, 85], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "rel_dim", ",", "embed_dim", ",", "hidden_size", ",", "num_layers", ",", "dropout", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "super", "(", "RelationEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rel_embed", "=", "AMREmbedding", "(", "vocab", ",", "rel_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "\n", "input_size", "=", "rel_dim", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout", "if", "num_layers", ">", "1", "else", "0.", ",", "\n", "bidirectional", "=", "bidirectional", "\n", ")", "\n", "tot_dim", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.RelationEncoder.reset_parameters": [[86, 89], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.RelationEncoder.forward": [[90, 120], ["src_tokens.size", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "src_tokens.index_select", "encoder.RelationEncoder.rel_embed", "torch.dropout", "torch.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.dropout.data.new().zero_", "encoder.RelationEncoder.rnn", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "combine_bidir.index_select", "encoder.RelationEncoder.out_proj", "sorted_src_lengths.data.tolist", "encoder.RelationEncoder.forward.combine_bidir"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "seq_len", ",", "bsz", "=", "src_tokens", ".", "size", "(", ")", "\n", "###", "\n", "sorted_src_lengths", ",", "indices", "=", "torch", ".", "sort", "(", "src_lengths", ",", "descending", "=", "True", ")", "\n", "sorted_src_tokens", "=", "src_tokens", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "###", "\n", "x", "=", "self", ".", "rel_embed", "(", "sorted_src_tokens", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "packed_x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "sorted_src_lengths", ".", "data", ".", "tolist", "(", ")", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "state_size", "=", "2", "*", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "else", ":", "\n", "            ", "state_size", "=", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "h0", "=", "x", ".", "data", ".", "new", "(", "*", "state_size", ")", ".", "zero_", "(", ")", "\n", "_", ",", "final_h", "=", "self", ".", "rnn", "(", "packed_x", ",", "h0", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "def", "combine_bidir", "(", "outs", ")", ":", "\n", "                ", "return", "outs", ".", "view", "(", "self", ".", "num_layers", ",", "2", ",", "bsz", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "num_layers", ",", "bsz", ",", "-", "1", ")", "\n", "", "final_h", "=", "combine_bidir", "(", "final_h", ")", "\n", "\n", "###", "\n", "", "_", ",", "positions", "=", "torch", ".", "sort", "(", "indices", ")", "\n", "final_h", "=", "final_h", ".", "index_select", "(", "1", ",", "positions", ")", "# num_layers x bsz x hidden_size", "\n", "\n", "output", "=", "self", ".", "out_proj", "(", "final_h", "[", "-", "1", "]", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.TokenEncoder.__init__": [[124, 136], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "encoder.AMREmbedding", "encoder.CNNEncoder", "torch.nn.Linear", "torch.nn.Linear", "encoder.TokenEncoder.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "token_vocab", ",", "char_vocab", ",", "char_dim", ",", "token_dim", ",", "embed_dim", ",", "filters", ",", "char2token_dim", ",", "dropout", ",", "pretrained_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "TokenEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "char_embed", "=", "AMREmbedding", "(", "char_vocab", ",", "char_dim", ")", "\n", "self", ".", "token_embed", "=", "AMREmbedding", "(", "token_vocab", ",", "token_dim", ",", "pretrained_file", ")", "\n", "self", ".", "char2token", "=", "CNNEncoder", "(", "filters", ",", "char_dim", ",", "char2token_dim", ")", "\n", "tot_dim", "=", "char2token_dim", "+", "token_dim", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "self", ".", "char_dim", "=", "char_dim", "\n", "self", ".", "token_dim", "=", "token_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.TokenEncoder.reset_parameters": [[137, 140], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.TokenEncoder.forward": [[141, 150], ["char_input.size", "encoder.TokenEncoder.char_embed", "encoder.TokenEncoder.char2token().view", "encoder.TokenEncoder.token_embed", "torch.dropout", "torch.dropout", "encoder.TokenEncoder.out_proj", "char_input.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.TokenEncoder.char2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "token_input", ",", "char_input", ")", ":", "\n", "        ", "seq_len", ",", "bsz", ",", "_", "=", "char_input", ".", "size", "(", ")", "\n", "char_repr", "=", "self", ".", "char_embed", "(", "char_input", ".", "view", "(", "seq_len", "*", "bsz", ",", "-", "1", ")", ")", "\n", "char_repr", "=", "self", ".", "char2token", "(", "char_repr", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "token_repr", "=", "self", ".", "token_embed", "(", "token_input", ")", "\n", "\n", "token", "=", "F", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "char_repr", ",", "token_repr", "]", ",", "-", "1", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "token", "=", "self", ".", "out_proj", "(", "token", ")", "\n", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.CNNEncoder.__init__": [[152, 161], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "sum", "encoder.Highway", "torch.nn.Linear", "torch.nn.Linear", "encoder.CNNEncoder.reset_parameters", "encoder.CNNEncoder.convolutions.append", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "filters", ",", "input_dim", ",", "output_dim", ",", "highway_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "width", ",", "out_c", "in", "filters", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "nn", ".", "Conv1d", "(", "input_dim", ",", "out_c", ",", "kernel_size", "=", "width", ")", ")", "\n", "", "final_dim", "=", "sum", "(", "f", "[", "1", "]", "for", "f", "in", "filters", ")", "\n", "self", ".", "highway", "=", "Highway", "(", "final_dim", ",", "highway_layers", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "final_dim", ",", "output_dim", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.CNNEncoder.reset_parameters": [[162, 165], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.CNNEncoder.forward": [[166, 179], ["input.transpose", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.CNNEncoder.highway", "encoder.CNNEncoder.out_proj", "conv", "torch.max", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "encoder.CNNEncoder.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# input: batch_size x seq_len x input_dim", "\n", "        ", "x", "=", "input", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conv_result", "=", "[", "]", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convolutions", ")", ":", "\n", "            ", "y", "=", "conv", "(", "x", ")", "\n", "y", ",", "_", "=", "torch", ".", "max", "(", "y", ",", "-", "1", ")", "\n", "y", "=", "F", ".", "relu", "(", "y", ")", "\n", "conv_result", ".", "append", "(", "y", ")", "\n", "\n", "", "conv_result", "=", "torch", ".", "cat", "(", "conv_result", ",", "dim", "=", "-", "1", ")", "\n", "conv_result", "=", "self", ".", "highway", "(", "conv_result", ")", "\n", "return", "self", ".", "out_proj", "(", "conv_result", ")", "#  batch_size x output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.Highway.__init__": [[181, 187], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "encoder.Highway.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "layers", ")", ":", "\n", "        ", "super", "(", "Highway", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", "*", "2", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "]", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.Highway.reset_parameters": [[188, 193], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", "self", ".", "input_dim", ":", "]", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", ":", "self", ".", "input_dim", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.Highway.forward": [[194, 202], ["layer", "torch.relu.chunk", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "new_x", "=", "layer", "(", "x", ")", "\n", "new_x", ",", "gate", "=", "new_x", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "new_x", "=", "F", ".", "relu", "(", "new_x", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "x", "=", "gate", "*", "x", "+", "(", "1", "-", "gate", ")", "*", "new_x", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.encoder.AMREmbedding": [[9, 65], ["set", "range", "numpy.asarray", "print", "float", "float", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "range", "embedding_matrix[].fill_", "torch.nn.Embedding.from_pretrained", "transformer.Embedding", "vocab.idx2token", "set.add", "open", "open", "embeddings_file.readlines", "open.close", "list", "numpy.mean", "numpy.std", "vocab.idx2token", "re.sub", "line.rstrip().split", "embeddings.values", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.asarray", "re.sub", "line.rstrip", "len", "open.write", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["def", "AMREmbedding", "(", "vocab", ",", "embedding_dim", ",", "pretrained_file", "=", "None", ",", "amr", "=", "False", ",", "dump_file", "=", "None", ")", ":", "\n", "    ", "if", "pretrained_file", "is", "None", ":", "\n", "        ", "return", "Embedding", "(", "vocab", ".", "size", ",", "embedding_dim", ",", "vocab", ".", "padding_idx", ")", "\n", "\n", "", "tokens_to_keep", "=", "set", "(", ")", "\n", "for", "idx", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "idx", ")", "\n", "# TODO: Is there a better way to do this? Currently we have a very specific 'amr' param.", "\n", "if", "amr", ":", "\n", "            ", "token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "", "tokens_to_keep", ".", "add", "(", "token", ")", "\n", "\n", "", "embeddings", "=", "{", "}", "\n", "\n", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", "=", "open", "(", "dump_file", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "\n", "\n", "", "with", "open", "(", "pretrained_file", ",", "encoding", "=", "'utf8'", ")", "as", "embeddings_file", ":", "\n", "        ", "for", "line", "in", "embeddings_file", ".", "readlines", "(", ")", ":", "\n", "            ", "fields", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "fields", ")", "-", "1", "!=", "embedding_dim", ":", "\n", "                ", "continue", "\n", "", "token", "=", "fields", "[", "0", "]", "\n", "if", "token", "in", "tokens_to_keep", ":", "\n", "                ", "if", "dump_file", "is", "not", "None", ":", "\n", "                    ", "fo", ".", "write", "(", "line", ")", "\n", "", "vector", "=", "np", ".", "asarray", "(", "fields", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "embeddings", "[", "token", "]", "=", "vector", "\n", "\n", "", "", "", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", ".", "close", "(", ")", "\n", "\n", "", "all_embeddings", "=", "np", ".", "asarray", "(", "list", "(", "embeddings", ".", "values", "(", ")", ")", ")", "\n", "print", "(", "'pretrained'", ",", "all_embeddings", ".", "shape", ")", "\n", "embeddings_mean", "=", "float", "(", "np", ".", "mean", "(", "all_embeddings", ")", ")", "\n", "embeddings_std", "=", "float", "(", "np", ".", "std", "(", "all_embeddings", ")", ")", "\n", "# Now we initialize the weight matrix for an embedding layer, starting with random vectors,", "\n", "# then filling in the word vectors we just read.", "\n", "embedding_matrix", "=", "torch", ".", "FloatTensor", "(", "vocab", ".", "size", ",", "embedding_dim", ")", ".", "normal_", "(", "embeddings_mean", ",", "\n", "embeddings_std", ")", "\n", "\n", "for", "i", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "i", ")", "\n", "\n", "# If we don't have a pre-trained vector for this word, we'll just leave this row alone,", "\n", "# so the word has a random initialization.", "\n", "if", "token", "in", "embeddings", ":", "\n", "            ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "token", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "amr", ":", "\n", "                ", "normalized_token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "if", "normalized_token", "in", "embeddings", ":", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "normalized_token", "]", ")", "\n", "", "", "", "", "embedding_matrix", "[", "vocab", ".", "padding_idx", "]", ".", "fill_", "(", "0.", ")", "\n", "\n", "return", "nn", ".", "Embedding", ".", "from_pretrained", "(", "embedding_matrix", ",", "freeze", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.work.parse_config": [[12, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--max_time_step'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--output_suffix'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.work.generate_batch": [[26, 39], ["utils.move_to_cuda", "dict", "model.work", "token_batch.append", "score_batch.append", "beam.get_k_best"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda", "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.work", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.get_k_best"], ["", "def", "generate_batch", "(", "model", ",", "batch", ",", "beam_size", ",", "alpha", ",", "max_time_step", ")", ":", "\n", "    ", "batch", "=", "move_to_cuda", "(", "batch", ",", "model", ".", "device", ")", "\n", "res", "=", "dict", "(", ")", "\n", "token_batch", ",", "score_batch", "=", "[", "]", ",", "[", "]", "\n", "beams", "=", "model", ".", "work", "(", "batch", ",", "beam_size", ",", "max_time_step", ")", "\n", "for", "beam", "in", "beams", ":", "\n", "        ", "best_hyp", "=", "beam", ".", "get_k_best", "(", "1", ",", "alpha", ")", "[", "0", "]", "\n", "predicted_token", "=", "[", "token", "for", "token", "in", "best_hyp", ".", "seq", "[", "1", ":", "-", "1", "]", "]", "\n", "token_batch", ".", "append", "(", "predicted_token", ")", "\n", "score_batch", ".", "append", "(", "best_hyp", ".", "score", ")", "\n", "", "res", "[", "'token'", "]", "=", "token_batch", "\n", "res", "[", "'score'", "]", "=", "score_batch", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.work.validate": [[40, 67], ["postprocess.PostProcess", "open", "extract.read_file", "sacrebleu.corpus_chrf", "line.startswith", "work.generate_batch", "sys_stream.extend", "len", "len", "postprocess.PostProcess.post_process", "sacrebleu.corpus_bleu", "json.loads", "ref_stream.append", "enumerate", "line[].strip", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.read_file", "home.repos.pwc.inspect_result.jcyk_gtos.translator.work.generate_batch", "home.repos.pwc.inspect_result.jcyk_gtos.translator.postprocess.PostProcess.post_process", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "validate", "(", "model", ",", "test_data", ",", "golden_file", ",", "beam_size", "=", "8", ",", "alpha", "=", "0.6", ",", "max_time_step", "=", "100", ")", ":", "\n", "    ", "\"\"\"For development Only\"\"\"", "\n", "pp", "=", "PostProcess", "(", ")", "\n", "\n", "ref_stream", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "golden_file", "+", "'.input_clean'", ")", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'# ::tokens '", ")", ":", "\n", "            ", "o", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::tokens '", ")", ":", "]", ".", "strip", "(", ")", ")", "\n", "ref_stream", ".", "append", "(", "' '", ".", "join", "(", "o", ")", ".", "lower", "(", ")", ")", "\n", "# gold model output", "\n", "", "", "graph", ",", "gold_sys_stream", ",", "_", ",", "abstract", "=", "read_file", "(", "golden_file", "+", "'.preproc'", ")", "\n", "ref_streams", "=", "[", "ref_stream", "]", "\n", "\n", "sys_stream", "=", "[", "]", "\n", "for", "batch", "in", "test_data", ":", "\n", "        ", "res", "=", "generate_batch", "(", "model", ",", "batch", ",", "beam_size", ",", "alpha", ",", "max_time_step", ")", "\n", "sys_stream", ".", "extend", "(", "res", "[", "'token'", "]", ")", "\n", "\n", "", "assert", "len", "(", "sys_stream", ")", "==", "len", "(", "ref_stream", ")", "\n", "sys_stream", "=", "[", "pp", ".", "post_process", "(", "o", ",", "abstract", "[", "i", "]", ",", "graph", "[", "i", "]", ")", "for", "i", ",", "o", "in", "enumerate", "(", "sys_stream", ")", "]", "\n", "\n", "bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "sys_stream", ",", "ref_streams", ",", "\n", "force", "=", "True", ",", "lowercase", "=", "True", ",", "\n", "tokenize", "=", "'none'", ")", ".", "score", "\n", "chrf", "=", "sacrebleu", ".", "corpus_chrf", "(", "sys_stream", ",", "ref_stream", ")", "\n", "\n", "return", "bleu", ",", "chrf", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformer.__init__": [[8, 13], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "graph_transformer.GraphTransformer.layers.append", "graph_transformer.GraphTransformerLayer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "GraphTransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformer.forward": [[14, 19], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", "=", "layer", "(", "x", ",", "relation", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformer.get_attn_weights": [[20, 28], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "attns.append"], "methods", ["None"], ["", "def", "get_attn_weights", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ")", ":", "\n", "        ", "attns", "=", "[", "]", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "attn", "=", "layer", "(", "x", ",", "relation", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "need_weights", "=", "True", ")", "\n", "attns", ".", "append", "(", "attn", ")", "\n", "", "attn", "=", "torch", ".", "stack", "(", "attns", ")", "\n", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformerLayer.__init__": [[31, 40], ["torch.nn.Module.__init__", "graph_transformer.RelationMultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "graph_transformer.GraphTransformerLayer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphTransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "RelationMultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformerLayer.reset_parameters": [[41, 46], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.GraphTransformerLayer.forward": [[47, 67], ["torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.fc2", "torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.ff_layer_norm", "graph_transformer.GraphTransformerLayer.self_attn", "graph_transformer.GraphTransformerLayer.self_attn", "graph_transformer.GraphTransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "need_weights", "=", "False", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "relation", "=", "relation", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "relation", "=", "relation", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.__init__": [[69, 85], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "graph_transformer.RelationMultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "RelationMultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "self", ".", "relation_in_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "2", "*", "embed_dim", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.reset_parameters": [[86, 92], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "relation_in_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.forward": [[93, 175], ["query.size", "key.size", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.relation_in_proj().chunk", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.softmax", "torch.softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.dropout.transpose().contiguous().view", "graph_transformer.RelationMultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "graph_transformer.RelationMultiheadAttention.in_proj_qkv", "graph_transformer.RelationMultiheadAttention.unsqueeze", "graph_transformer.RelationMultiheadAttention.unsqueeze", "list", "attn_weights.view.view.masked_fill_", "attn_weights.view.view.view", "attn_weights.view.view.masked_fill_", "attn_weights.view.view.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.view.view.view", "graph_transformer.RelationMultiheadAttention.in_proj_q", "graph_transformer.RelationMultiheadAttention.in_proj_kv", "graph_transformer.RelationMultiheadAttention.in_proj_q", "graph_transformer.RelationMultiheadAttention.in_proj_k", "graph_transformer.RelationMultiheadAttention.in_proj_v", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.relation_in_proj", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "attn_weights.view.view.size", "attn_mask.unsqueeze", "float", "key_padding_mask.unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous", "key_padding_mask.unsqueeze", "torch.dropout.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "relation", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "False", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            relation:  tgt_len x src_len x bsz x dim\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "src_len", "=", "key", ".", "size", "(", "0", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "\n", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "\n", "ra", ",", "rb", "=", "self", ".", "relation_in_proj", "(", "relation", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "ra", "=", "ra", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "rb", "=", "rb", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "q", "=", "q", ".", "unsqueeze", "(", "1", ")", "+", "ra", "\n", "k", "=", "k", ".", "unsqueeze", "(", "0", ")", "+", "rb", "\n", "q", "*=", "self", ".", "scaling", "\n", "# q: tgt_len x src_len x bsz*heads x dim", "\n", "# k: tgt_len x src_len x bsz*heads x dim", "\n", "# v: src_len x bsz*heads x dim", "\n", "\n", "attn_weights", "=", "torch", ".", "einsum", "(", "'ijbn,ijbn->ijb'", ",", "[", "q", ",", "k", "]", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", ",", "self", ".", "num_heads", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# attn_weights: tgt_len x src_len x bsz*heads", "\n", "# v: src_len x bsz*heads x dim", "\n", "", "attn", "=", "torch", ".", "einsum", "(", "'ijb,jbn->bin'", ",", "[", "attn_weights", ",", "v", "]", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads ", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", ",", "self", ".", "num_heads", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.in_proj_qkv": [[176, 178], ["graph_transformer.RelationMultiheadAttention._in_proj().chunk", "graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.in_proj_kv": [[179, 181], ["graph_transformer.RelationMultiheadAttention._in_proj().chunk", "graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.in_proj_q": [[182, 184], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.in_proj_k": [[185, 187], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention.in_proj_v": [[188, 190], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.graph_transformer.RelationMultiheadAttention._in_proj": [[191, 200], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.train.parse_config": [[14, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# vocabs", "\n", "parser", ".", "add_argument", "(", "'--token_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--predictable_token_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--token_char_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--relation_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_file'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# concept/token encoders", "\n", "parser", ".", "add_argument", "(", "'--token_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--token_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# char-cnn", "\n", "parser", ".", "add_argument", "(", "'--cnn_filters'", ",", "type", "=", "int", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--char2word_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--char2concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# relation encoder", "\n", "parser", ".", "add_argument", "(", "'--rel_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_hidden_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_num_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# core architecture", "\n", "parser", ".", "add_argument", "(", "'--embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ff_embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_heads'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--snt_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--graph_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--inference_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# dropout/unk ", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--unk_rate'", ",", "type", "=", "float", ")", "\n", "\n", "# IO", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--train_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ")", "\n", "\n", "# distributed training", "\n", "parser", ".", "add_argument", "(", "'--world_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_ADDR'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_PORT'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--start_rank'", ",", "type", "=", "int", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.train.average_gradients": [[74, 80], ["float", "model.parameters", "torch.get_world_size", "torch.all_reduce"], "function", ["None"], ["", "def", "average_gradients", "(", "model", ")", ":", "\n", "    ", "size", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "param", ".", "grad", ".", "data", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "param", ".", "grad", ".", "data", "/=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.train.update_lr": [[81, 84], ["min"], "function", ["None"], ["", "", "", "def", "update_lr", "(", "optimizer", ",", "embed_size", ",", "steps", ",", "warmup_steps", ")", ":", "\n", "    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "embed_size", "**", "-", "0.5", "*", "min", "(", "steps", "**", "-", "0.5", ",", "steps", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.train.main": [[85, 166], ["dict", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "extract.LexicalMap", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "random.seed", "torch.device", "torch.device", "torch.device", "generator.Generator", "model.cuda.cuda", "data.DataLoader", "data.DataLoader", "data.DataLoader.set_unk_rate", "model.cuda.named_parameters", "adam.AdamWeightDecayOptimizer", "range", "print", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "random.seed", "model.cuda.train", "name.endswith", "no_weight_decay_params.append", "weight_decay_params.append", "utils.move_to_cuda", "model.cuda.", "model.item", "model.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "train.update_lr", "adam.AdamWeightDecayOptimizer.step", "adam.AdamWeightDecayOptimizer.zero_grad", "torch.get_rank", "torch.get_rank", "torch.get_rank", "print", "train.average_gradients", "model.cuda.parameters", "torch.get_rank", "print", "model.cuda.train", "model.cuda.eval", "work.validate", "print", "print", "torch.save", "torch.save", "torch.save", "model.cuda.train", "model.cuda.state_dict", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.set_unk_rate", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda", "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.update_lr", "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad", "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.average_gradients", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.translator.work.validate", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict"], ["", "", "def", "main", "(", "args", ",", "local_rank", ")", ":", "\n", "    ", "vocabs", "=", "dict", "(", ")", "\n", "vocabs", "[", "'concept'", "]", "=", "Vocab", "(", "args", ".", "concept_vocab", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'token'", "]", "=", "Vocab", "(", "args", ".", "token_vocab", ",", "5", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'predictable_token'", "]", "=", "Vocab", "(", "args", ".", "predictable_token_vocab", ",", "5", ",", "[", "END", "]", ")", "\n", "vocabs", "[", "'token_char'", "]", "=", "Vocab", "(", "args", ".", "token_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'concept_char'", "]", "=", "Vocab", "(", "args", ".", "concept_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'relation'", "]", "=", "Vocab", "(", "args", ".", "relation_vocab", ",", "5", ",", "[", "CLS", ",", "rCLS", ",", "SEL", ",", "TL", "]", ")", "\n", "lexical_mapping", "=", "LexicalMap", "(", ")", "\n", "\n", "for", "name", "in", "vocabs", ":", "\n", "        ", "print", "(", "(", "name", ",", "vocabs", "[", "name", "]", ".", "size", ",", "vocabs", "[", "name", "]", ".", "coverage", ")", ")", "\n", "\n", "", "torch", ".", "manual_seed", "(", "19940117", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", ")", "\n", "random", ".", "seed", "(", "19940117", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "local_rank", ")", "\n", "model", "=", "Generator", "(", "vocabs", ",", "\n", "args", ".", "token_char_dim", ",", "args", ".", "token_dim", ",", "\n", "args", ".", "concept_char_dim", ",", "args", ".", "concept_dim", ",", "\n", "args", ".", "cnn_filters", ",", "args", ".", "char2word_dim", ",", "args", ".", "char2concept_dim", ",", "\n", "args", ".", "rel_dim", ",", "args", ".", "rnn_hidden_size", ",", "args", ".", "rnn_num_layers", ",", "\n", "args", ".", "embed_dim", ",", "args", ".", "ff_embed_dim", ",", "args", ".", "num_heads", ",", "args", ".", "dropout", ",", "\n", "args", ".", "snt_layers", ",", "args", ".", "graph_layers", ",", "args", ".", "inference_layers", ",", "\n", "args", ".", "pretrained_file", ",", "\n", "device", ")", "\n", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "random", ".", "seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "\n", "", "model", "=", "model", ".", "cuda", "(", "device", ")", "\n", "train_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "train_data", ",", "args", ".", "train_batch_size", ",", "for_train", "=", "True", ")", "\n", "dev_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "dev_data", ",", "args", ".", "dev_batch_size", ",", "for_train", "=", "False", ")", "\n", "train_data", ".", "set_unk_rate", "(", "args", ".", "unk_rate", ")", "\n", "\n", "weight_decay_params", "=", "[", "]", "\n", "no_weight_decay_params", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", ".", "endswith", "(", "'bias'", ")", "or", "'layer_norm'", "in", "name", ":", "\n", "            ", "no_weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "", "grouped_params", "=", "[", "{", "'params'", ":", "weight_decay_params", ",", "'weight_decay'", ":", "1e-4", "}", ",", "\n", "{", "'params'", ":", "no_weight_decay_params", ",", "'weight_decay'", ":", "0.", "}", "]", "\n", "optimizer", "=", "AdamWeightDecayOptimizer", "(", "grouped_params", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ")", "\n", "\n", "batches_acm", ",", "loss_acm", "=", "0", ",", "0", "\n", "discarded_batches_acm", "=", "0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "for", "batch", "in", "train_data", ":", "\n", "            ", "batch", "=", "move_to_cuda", "(", "batch", ",", "device", ")", "\n", "loss", "=", "model", "(", "batch", ")", "\n", "loss_value", "=", "loss", ".", "item", "(", ")", "\n", "if", "batches_acm", ">", "args", ".", "warmup_steps", "and", "loss_value", ">", "5.", "*", "(", "loss_acm", "/", "batches_acm", ")", ":", "\n", "                ", "discarded_batches_acm", "+=", "1", "\n", "print", "(", "'abnormal'", ",", "loss_value", ")", "\n", "continue", "\n", "", "loss_acm", "+=", "loss_value", "\n", "batches_acm", "+=", "1", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "                ", "average_gradients", "(", "model", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "update_lr", "(", "optimizer", ",", "args", ".", "embed_dim", ",", "batches_acm", ",", "args", ".", "warmup_steps", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "world_size", "==", "1", "or", "(", "dist", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "                ", "if", "batches_acm", "%", "args", ".", "print_every", "==", "-", "1", "%", "args", ".", "print_every", ":", "\n", "                    ", "print", "(", "'Train Epoch %d, Batch %d, Discarded Batch %d, loss %.3f'", "%", "(", "epoch", ",", "batches_acm", ",", "discarded_batches_acm", ",", "loss_acm", "/", "batches_acm", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "", "if", "batches_acm", ">", "args", ".", "warmup_steps", "and", "batches_acm", "%", "args", ".", "eval_every", "==", "-", "1", "%", "args", ".", "eval_every", ":", "\n", "                    ", "model", ".", "eval", "(", ")", "\n", "bleu", ",", "chrf", "=", "validate", "(", "model", ",", "dev_data", ",", "args", ".", "dev_data", "[", ":", "-", "len", "(", "'.preproc.json'", ")", "]", ")", "\n", "print", "(", "\"epoch\"", ",", "\"batch\"", ",", "\"bleu\"", ",", "\"chrf\"", ")", "\n", "print", "(", "epoch", ",", "batches_acm", ",", "bleu", ",", "chrf", ")", "\n", "torch", ".", "save", "(", "{", "'args'", ":", "args", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", "}", ",", "'%s/epoch%d_batch%d'", "%", "(", "args", ".", "ckpt", ",", "epoch", ",", "batches_acm", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.train.init_processes": [[167, 172], ["torch.init_process_group", "train.main"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.main"], ["", "", "", "", "", "def", "init_processes", "(", "args", ",", "local_rank", ",", "backend", "=", "'nccl'", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "args", ".", "MASTER_ADDR", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "args", ".", "MASTER_PORT", "\n", "dist", ".", "init_process_group", "(", "backend", ",", "rank", "=", "args", ".", "start_rank", "+", "local_rank", ",", "world_size", "=", "args", ".", "world_size", ")", "\n", "main", "(", "args", ",", "local_rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.separate_characters": [[38, 40], ["list", "line.strip().replace", "line.strip"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["def", "separate_characters", "(", "line", ")", ":", "\n", "    ", "return", "list", "(", "line", ".", "strip", "(", ")", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.separate_punctuation": [[41, 58], ["line.strip().split", "line.strip", "len", "tokenized.append", "tokenized.append"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "separate_punctuation", "(", "line", ")", ":", "\n", "    ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "tokenized", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "len", "(", "w", ")", "==", "1", ":", "\n", "            ", "tokenized", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "            ", "lastChar", "=", "w", "[", "-", "1", "]", "\n", "firstChar", "=", "w", "[", "0", "]", "\n", "if", "lastChar", "in", "string", ".", "punctuation", ":", "\n", "                ", "tokenized", "+=", "[", "w", "[", ":", "-", "1", "]", ",", "lastChar", "]", "\n", "", "elif", "firstChar", "in", "string", ".", "punctuation", ":", "\n", "                ", "tokenized", "+=", "[", "firstChar", ",", "w", "[", "1", ":", "]", "]", "\n", "", "else", ":", "\n", "                ", "tokenized", ".", "append", "(", "w", ")", "\n", "\n", "", "", "", "return", "tokenized", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.ngram_counts": [[59, 69], ["collections.defaultdict", "len", "range", "range", "collections.defaultdict", "tuple"], "function", ["None"], ["", "def", "ngram_counts", "(", "wordList", ",", "order", ")", ":", "\n", "    ", "counts", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "float", ")", ")", "\n", "nWords", "=", "len", "(", "wordList", ")", "\n", "for", "i", "in", "range", "(", "nWords", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "order", "+", "1", ")", ":", "\n", "            ", "if", "i", "+", "j", "<=", "nWords", ":", "\n", "                ", "ngram", "=", "tuple", "(", "wordList", "[", "i", ":", "i", "+", "j", "]", ")", "\n", "counts", "[", "j", "-", "1", "]", "[", "ngram", "]", "+=", "1", "\n", "\n", "", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.ngram_matches": [[70, 85], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "min"], "function", ["None"], ["", "def", "ngram_matches", "(", "ref_ngrams", ",", "hyp_ngrams", ")", ":", "\n", "    ", "matchingNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "totalRefNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "totalHypNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "\n", "for", "order", "in", "ref_ngrams", ":", "\n", "        ", "for", "ngram", "in", "hyp_ngrams", "[", "order", "]", ":", "\n", "            ", "totalHypNgramCount", "[", "order", "]", "+=", "hyp_ngrams", "[", "order", "]", "[", "ngram", "]", "\n", "", "for", "ngram", "in", "ref_ngrams", "[", "order", "]", ":", "\n", "            ", "totalRefNgramCount", "[", "order", "]", "+=", "ref_ngrams", "[", "order", "]", "[", "ngram", "]", "\n", "if", "ngram", "in", "hyp_ngrams", "[", "order", "]", ":", "\n", "                ", "matchingNgramCount", "[", "order", "]", "+=", "min", "(", "ref_ngrams", "[", "order", "]", "[", "ngram", "]", ",", "hyp_ngrams", "[", "order", "]", "[", "ngram", "]", ")", "\n", "\n", "\n", "", "", "", "return", "matchingNgramCount", ",", "totalRefNgramCount", ",", "totalHypNgramCount", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.ngram_precrecf": [[87, 110], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "function", ["None"], ["", "def", "ngram_precrecf", "(", "matching", ",", "reflen", ",", "hyplen", ",", "beta", ")", ":", "\n", "    ", "ngramPrec", "=", "defaultdict", "(", "float", ")", "\n", "ngramRec", "=", "defaultdict", "(", "float", ")", "\n", "ngramF", "=", "defaultdict", "(", "float", ")", "\n", "\n", "factor", "=", "beta", "**", "2", "\n", "\n", "for", "order", "in", "matching", ":", "\n", "        ", "if", "hyplen", "[", "order", "]", ">", "0", ":", "\n", "            ", "ngramPrec", "[", "order", "]", "=", "matching", "[", "order", "]", "/", "hyplen", "[", "order", "]", "\n", "", "else", ":", "\n", "            ", "ngramPrec", "[", "order", "]", "=", "1e-16", "\n", "", "if", "reflen", "[", "order", "]", ">", "0", ":", "\n", "            ", "ngramRec", "[", "order", "]", "=", "matching", "[", "order", "]", "/", "reflen", "[", "order", "]", "\n", "", "else", ":", "\n", "            ", "ngramRec", "[", "order", "]", "=", "1e-16", "\n", "", "denom", "=", "factor", "*", "ngramPrec", "[", "order", "]", "+", "ngramRec", "[", "order", "]", "\n", "if", "denom", ">", "0", ":", "\n", "            ", "ngramF", "[", "order", "]", "=", "(", "1", "+", "factor", ")", "*", "ngramPrec", "[", "order", "]", "*", "ngramRec", "[", "order", "]", "/", "denom", "\n", "", "else", ":", "\n", "            ", "ngramF", "[", "order", "]", "=", "1e-16", "\n", "\n", "", "", "return", "ngramF", ",", "ngramRec", ",", "ngramPrec", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.computeChrF": [[111, 195], ["float", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "zip", "chrF++.ngram_precrecf", "chrF++.ngram_precrecf", "chrF++.ngram_counts", "chrF++.ngram_counts", "rline.split", "range", "range", "chrF++.separate_punctuation", "chrF++.separate_characters", "chrF++.ngram_counts", "chrF++.ngram_counts", "chrF++.ngram_matches", "chrF++.ngram_matches", "chrF++.ngram_precrecf", "chrF++.ngram_precrecf", "sentence_level_scores.write", "sum", "sum", "sum", "sum", "sum", "sum", "chrF++.separate_punctuation", "chrF++.separate_characters", "totalChrNgramF.values", "totalNgramF.values", "totalChrNgramRec.values", "totalNgramRec.values", "totalChrNgramPrec.values", "totalNgramPrec.values", "sum", "sum", "sum", "sum", "sum", "sum", "chrNgramRec.values", "ngramRec.values", "chrNgramPrec.values", "ngramPrec.values", "chrNgramF.values", "ngramF.values"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_punctuation", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_characters", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_matches", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_matches", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_punctuation", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_characters"], ["", "def", "computeChrF", "(", "fpRef", ",", "fpHyp", ",", "nworder", ",", "ncorder", ",", "beta", ",", "sentence_level_scores", "=", "None", ")", ":", "\n", "    ", "norder", "=", "float", "(", "nworder", "+", "ncorder", ")", "\n", "\n", "# initialisation of document level scores", "\n", "totalMatchingCount", "=", "defaultdict", "(", "float", ")", "\n", "totalRefCount", "=", "defaultdict", "(", "float", ")", "\n", "totalHypCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrMatchingCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrRefCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrHypCount", "=", "defaultdict", "(", "float", ")", "\n", "averageTotalF", "=", "0.0", "\n", "\n", "nsent", "=", "0", "\n", "for", "hline", ",", "rline", "in", "zip", "(", "fpHyp", ",", "fpRef", ")", ":", "\n", "        ", "nsent", "+=", "1", "\n", "\n", "# preparation for multiple references", "\n", "maxF", "=", "0.0", "\n", "bestWordMatchingCount", "=", "None", "\n", "bestCharMatchingCount", "=", "None", "\n", "\n", "hypNgramCounts", "=", "ngram_counts", "(", "separate_punctuation", "(", "hline", ")", ",", "nworder", ")", "\n", "hypChrNgramCounts", "=", "ngram_counts", "(", "separate_characters", "(", "hline", ")", ",", "ncorder", ")", "\n", "\n", "# going through multiple references", "\n", "\n", "refs", "=", "rline", ".", "split", "(", "\"*#\"", ")", "\n", "\n", "for", "ref", "in", "refs", ":", "\n", "            ", "refNgramCounts", "=", "ngram_counts", "(", "separate_punctuation", "(", "ref", ")", ",", "nworder", ")", "\n", "refChrNgramCounts", "=", "ngram_counts", "(", "separate_characters", "(", "ref", ")", ",", "ncorder", ")", "\n", "\n", "# number of overlapping n-grams, total number of ref n-grams, total number of hyp n-grams", "\n", "matchingNgramCounts", ",", "totalRefNgramCount", ",", "totalHypNgramCount", "=", "ngram_matches", "(", "refNgramCounts", ",", "hypNgramCounts", ")", "\n", "matchingChrNgramCounts", ",", "totalChrRefNgramCount", ",", "totalChrHypNgramCount", "=", "ngram_matches", "(", "refChrNgramCounts", ",", "hypChrNgramCounts", ")", "\n", "\n", "# n-gram f-scores, recalls and precisions", "\n", "ngramF", ",", "ngramRec", ",", "ngramPrec", "=", "ngram_precrecf", "(", "matchingNgramCounts", ",", "totalRefNgramCount", ",", "totalHypNgramCount", ",", "beta", ")", "\n", "chrNgramF", ",", "chrNgramRec", ",", "chrNgramPrec", "=", "ngram_precrecf", "(", "matchingChrNgramCounts", ",", "totalChrRefNgramCount", ",", "totalChrHypNgramCount", ",", "beta", ")", "\n", "\n", "sentRec", "=", "(", "sum", "(", "chrNgramRec", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramRec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "sentPrec", "=", "(", "sum", "(", "chrNgramPrec", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramPrec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "sentF", "=", "(", "sum", "(", "chrNgramF", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramF", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "\n", "if", "sentF", ">", "maxF", ":", "\n", "                ", "maxF", "=", "sentF", "\n", "bestMatchingCount", "=", "matchingNgramCounts", "\n", "bestRefCount", "=", "totalRefNgramCount", "\n", "bestHypCount", "=", "totalHypNgramCount", "\n", "bestChrMatchingCount", "=", "matchingChrNgramCounts", "\n", "bestChrRefCount", "=", "totalChrRefNgramCount", "\n", "bestChrHypCount", "=", "totalChrHypNgramCount", "\n", "# all the references are done", "\n", "\n", "\n", "# write sentence level scores", "\n", "", "", "if", "sentence_level_scores", ":", "\n", "            ", "sentence_level_scores", ".", "write", "(", "\"%i::c%i+w%i-F%i\\t%.4f\\n\"", "%", "(", "nsent", ",", "ncorder", ",", "nworder", ",", "beta", ",", "100", "*", "maxF", ")", ")", "\n", "\n", "\n", "# collect document level ngram counts", "\n", "", "for", "order", "in", "range", "(", "nworder", ")", ":", "\n", "            ", "totalMatchingCount", "[", "order", "]", "+=", "bestMatchingCount", "[", "order", "]", "\n", "totalRefCount", "[", "order", "]", "+=", "bestRefCount", "[", "order", "]", "\n", "totalHypCount", "[", "order", "]", "+=", "bestHypCount", "[", "order", "]", "\n", "", "for", "order", "in", "range", "(", "ncorder", ")", ":", "\n", "            ", "totalChrMatchingCount", "[", "order", "]", "+=", "bestChrMatchingCount", "[", "order", "]", "\n", "totalChrRefCount", "[", "order", "]", "+=", "bestChrRefCount", "[", "order", "]", "\n", "totalChrHypCount", "[", "order", "]", "+=", "bestChrHypCount", "[", "order", "]", "\n", "\n", "", "averageTotalF", "+=", "maxF", "\n", "\n", "# all sentences are done", "\n", "\n", "# total precision, recall and F (aritmetic mean of all ngrams)", "\n", "", "totalNgramF", ",", "totalNgramRec", ",", "totalNgramPrec", "=", "ngram_precrecf", "(", "totalMatchingCount", ",", "totalRefCount", ",", "totalHypCount", ",", "beta", ")", "\n", "totalChrNgramF", ",", "totalChrNgramRec", ",", "totalChrNgramPrec", "=", "ngram_precrecf", "(", "totalChrMatchingCount", ",", "totalChrRefCount", ",", "totalChrHypCount", ",", "beta", ")", "\n", "\n", "totalF", "=", "(", "sum", "(", "totalChrNgramF", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramF", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "averageTotalF", "=", "averageTotalF", "/", "nsent", "\n", "totalRec", "=", "(", "sum", "(", "totalChrNgramRec", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramRec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "totalPrec", "=", "(", "sum", "(", "totalChrNgramPrec", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramPrec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "\n", "return", "totalF", ",", "averageTotalF", ",", "totalPrec", ",", "totalRec", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.chrF++.main": [[197, 229], ["sys.stdout.write", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "open", "open", "chrF++.computeChrF", "sys.stdout.write", "sys.stdout.write", "sys.stdout.write", "open.close", "open.close", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.computeChrF", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close"], ["", "def", "main", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "\"start_time:\\t%i\\n\"", "%", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "\n", "argParser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argParser", ".", "add_argument", "(", "\"-R\"", ",", "\"--reference\"", ",", "help", "=", "\"reference translation\"", ",", "required", "=", "True", ")", "\n", "argParser", ".", "add_argument", "(", "\"-H\"", ",", "\"--hypothesis\"", ",", "help", "=", "\"hypothesis translation\"", ",", "required", "=", "True", ")", "\n", "argParser", ".", "add_argument", "(", "\"-nc\"", ",", "\"--ncorder\"", ",", "help", "=", "\"character n-gram order (default=6)\"", ",", "type", "=", "int", ",", "default", "=", "6", ")", "\n", "argParser", ".", "add_argument", "(", "\"-nw\"", ",", "\"--nworder\"", ",", "help", "=", "\"word n-gram order (default=2)\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "argParser", ".", "add_argument", "(", "\"-b\"", ",", "\"--beta\"", ",", "help", "=", "\"beta parameter (default=2)\"", ",", "type", "=", "float", ",", "default", "=", "2.0", ")", "\n", "argParser", ".", "add_argument", "(", "\"-s\"", ",", "\"--sent\"", ",", "help", "=", "\"show sentence level scores\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "args", "=", "argParser", ".", "parse_args", "(", ")", "\n", "\n", "rtxt", "=", "open", "(", "args", ".", "reference", ",", "'r'", ")", "\n", "htxt", "=", "open", "(", "args", ".", "hypothesis", ",", "'r'", ")", "\n", "\n", "sentence_level_scores", "=", "None", "\n", "if", "args", ".", "sent", ":", "\n", "        ", "sentence_level_scores", "=", "sys", ".", "stdout", "# Or stderr?", "\n", "\n", "", "totalF", ",", "averageTotalF", ",", "totalPrec", ",", "totalRec", "=", "computeChrF", "(", "rtxt", ",", "htxt", ",", "args", ".", "nworder", ",", "args", ".", "ncorder", ",", "args", ".", "beta", ",", "sentence_level_scores", ")", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "\"c%i+w%i-F%i\\t%.4f\\n\"", "%", "(", "args", ".", "ncorder", ",", "args", ".", "nworder", ",", "args", ".", "beta", ",", "100", "*", "totalF", ")", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"c%i+w%i-avgF%i\\t%.4f\\n\"", "%", "(", "args", ".", "ncorder", ",", "args", ".", "nworder", ",", "args", ".", "beta", ",", "100", "*", "averageTotalF", ")", ")", "\n", "#sys.stdout.write(\"c%i+w%i-Prec\\t%.4f\\n\" % (args.ncorder, args.nworder, 100*totalPrec))", "\n", "#sys.stdout.write(\"c%i+w%i-Rec\\t%.4f\\n\"  % (args.ncorder, args.nworder, 100*totalRec))", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "\"end_time:\\t%i\\n\"", "%", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "htxt", ".", "close", "(", ")", "\n", "rtxt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.decoder.TokenGenerator.__init__": [[11, 21], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "decoder.TokenGenerator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "embed_dim", ",", "token_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "TokenGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alignment_layer", "=", "MultiheadAttention", "(", "embed_dim", ",", "1", ",", "dropout", ",", "weights_dropout", "=", "False", ")", "\n", "self", ".", "alignment_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "transfer", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "token_size", ")", "\n", "self", ".", "generator", "=", "nn", ".", "Linear", "(", "token_size", ",", "vocabs", "[", "'predictable_token'", "]", ".", "size", ")", "\n", "self", ".", "diverter", "=", "nn", ".", "Linear", "(", "token_size", ",", "2", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.decoder.TokenGenerator.reset_parameters": [[22, 29], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "transfer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "diverter", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "diverter", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "transfer", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "generator", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.decoder.TokenGenerator.forward": [[30, 66], ["decoder.TokenGenerator.alignment_layer", "torch.dropout", "torch.dropout", "decoder.TokenGenerator.alignment_layer_norm", "decoder.TokenGenerator.size", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.softmax().chunk", "torch.softmax().chunk", "torch.cat.size", "torch.cat.size", "copy_seq.transpose().contiguous().view().expand", "torch.cat.scatter_add_", "torch.cat.scatter_add_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "token_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "decoder.TokenGenerator.transfer", "torch.softmax", "torch.softmax", "copy_seq.max().item", "torch.cat.new_zeros().expand", "torch.cat.new_zeros().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log.gather().squeeze", "torch.log.gather().squeeze", "torch.softmax", "torch.softmax", "decoder.TokenGenerator.generator", "copy_seq.transpose().contiguous().view", "token_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "decoder.TokenGenerator.diverter", "copy_seq.max", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.log.gather", "torch.log.gather", "copy_seq.transpose().contiguous", "target.unsqueeze", "copy_seq.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "\n", "target", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "        ", "x", ",", "alignment_weight", "=", "self", ".", "alignment_layer", "(", "outs", ",", "graph_state", ",", "graph_state", ",", "\n", "key_padding_mask", "=", "graph_padding_mask", ",", "\n", "need_weights", "=", "True", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "alignment_layer_norm", "(", "outs", "+", "x", ")", "\n", "\n", "seq_len", ",", "bsz", ",", "_", "=", "outs", ".", "size", "(", ")", "\n", "outs_token", "=", "torch", ".", "tanh", "(", "self", ".", "transfer", "(", "outs", ")", ")", "\n", "outs_token", "=", "F", ".", "dropout", "(", "outs_token", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "gen_gate", ",", "copy_gate", "=", "F", ".", "softmax", "(", "self", ".", "diverter", "(", "outs_token", ")", ",", "-", "1", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "probs", "=", "gen_gate", "*", "F", ".", "softmax", "(", "self", ".", "generator", "(", "outs_token", ")", ",", "-", "1", ")", "\n", "\n", "tot_ext", "=", "1", "+", "copy_seq", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "vocab_size", "=", "probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "tot_ext", "-", "vocab_size", ">", "0", ":", "\n", "            ", "ext_probs", "=", "probs", ".", "new_zeros", "(", "(", "1", ",", "1", ",", "tot_ext", "-", "vocab_size", ")", ")", ".", "expand", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "torch", ".", "cat", "(", "[", "probs", ",", "ext_probs", "]", ",", "-", "1", ")", "\n", "\n", "", "index", "=", "copy_seq", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "bsz", ",", "-", "1", ")", ".", "expand", "(", "seq_len", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "copy_probs", "=", "(", "copy_gate", "*", "alignment_weight", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "probs", ".", "scatter_add_", "(", "-", "1", ",", "index", ",", "copy_probs", ")", "\n", "ll", "=", "torch", ".", "log", "(", "probs", "+", "1e-12", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "return", "ll", "\n", "\n", "", "token_loss", "=", "-", "ll", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "token_mask", "=", "torch", ".", "eq", "(", "target", ",", "self", ".", "vocabs", "[", "'predictable_token'", "]", ".", "padding_idx", ")", "\n", "token_loss", "=", "token_loss", ".", "masked_fill_", "(", "token_mask", ",", "0.", ")", ".", "sum", "(", "0", ")", "\n", "return", "token_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.decoder.DecodeLayer.__init__": [[69, 75], ["torch.nn.Module.__init__", "transformer.Transformer", "decoder.TokenGenerator"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "token_size", ",", "rel_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "DecodeLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inference_core", "=", "Transformer", "(", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "True", ")", "\n", "self", ".", "token_generator", "=", "TokenGenerator", "(", "vocabs", ",", "embed_dim", ",", "token_size", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.decoder.DecodeLayer.forward": [[76, 95], ["torch.dropout", "torch.dropout", "decoder.DecodeLayer.inference_core", "decoder.DecodeLayer.token_generator", "decoder.DecodeLayer.mean", "decoder.DecodeLayer.token_generator", "snt_padding_mask.size", "snt_padding_mask.float().sum", "snt_padding_mask.float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "probe", ",", "graph_state", ",", "snt_state", ",", "\n", "graph_padding_mask", ",", "snt_padding_mask", ",", "attn_mask", ",", "\n", "copy_seq", ",", "target", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "# probe: tgt_len x bsz x embed_dim", "\n", "# snt_state, graph_state: seq_len x bsz x embed_dim", "\n", "\n", "        ", "outs", "=", "F", ".", "dropout", "(", "probe", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "inference_core", "(", "outs", ",", "kv", "=", "snt_state", ",", "\n", "self_padding_mask", "=", "snt_padding_mask", ",", "self_attn_mask", "=", "attn_mask", ",", "\n", "external_memories", "=", "graph_state", ",", "external_padding_mask", "=", "graph_padding_mask", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "concept_ll", "=", "self", ".", "token_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "return", "concept_ll", "\n", "\n", "", "token_loss", "=", "self", ".", "token_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "target", "=", "target", ",", "work", "=", "False", ")", "\n", "token_tot", "=", "snt_padding_mask", ".", "size", "(", "0", ")", "-", "snt_padding_mask", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "token_loss", "=", "token_loss", "/", "token_tot", "\n", "return", "token_loss", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.__init__": [[13, 34], ["dict", "open().readlines", "dict", "int", "zip", "open", "line.strip().split", "int", "idx2token.append", "range", "print", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "min_occur_cnt", ",", "specials", "=", "None", ")", ":", "\n", "        ", "idx2token", "=", "[", "PAD", ",", "UNK", "]", "+", "(", "specials", "if", "specials", "is", "not", "None", "else", "[", "]", ")", "\n", "self", ".", "_priority", "=", "dict", "(", ")", "\n", "num_tot_tokens", "=", "0", "\n", "num_vocab_tokens", "=", "0", "\n", "for", "line", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "token", ",", "cnt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "cnt", "=", "int", "(", "cnt", ")", "\n", "num_tot_tokens", "+=", "cnt", "\n", "", "except", ":", "\n", "                ", "print", "(", "line", ")", "\n", "", "if", "cnt", ">=", "min_occur_cnt", ":", "\n", "                ", "idx2token", ".", "append", "(", "token", ")", "\n", "num_vocab_tokens", "+=", "cnt", "\n", "", "self", ".", "_priority", "[", "token", "]", "=", "int", "(", "cnt", ")", "\n", "", "self", ".", "coverage", "=", "num_vocab_tokens", "/", "num_tot_tokens", "\n", "self", ".", "_token2idx", "=", "dict", "(", "zip", "(", "idx2token", ",", "range", "(", "len", "(", "idx2token", ")", ")", ")", ")", "\n", "self", ".", "_idx2token", "=", "idx2token", "\n", "self", ".", "_padding_idx", "=", "self", ".", "_token2idx", "[", "PAD", "]", "\n", "self", ".", "_unk_idx", "=", "self", ".", "_token2idx", "[", "UNK", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.priority": [[35, 37], ["data.Vocab._priority.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "priority", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_priority", ".", "get", "(", "x", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.size": [[38, 41], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_idx2token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.unk_idx": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "unk_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_unk_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.padding_idx": [[46, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.idx2token": [[50, 54], ["isinstance", "data.Vocab.idx2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["", "def", "idx2token", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "idx2token", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_idx2token", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.Vocab.token2idx": [[55, 59], ["isinstance", "data.Vocab._token2idx.get", "data.Vocab.token2idx"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["", "def", "token2idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "token2idx", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_token2idx", ".", "get", "(", "x", ",", "self", ".", "unk_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.DataLoader.__init__": [[270, 283], ["json.load", "print", "open", "lex_map.get", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "lex_map", ",", "filename", ",", "batch_size", ",", "for_train", ")", ":", "\n", "        ", "self", ".", "data", "=", "json", ".", "load", "(", "open", "(", "filename", ",", "encoding", "=", "'utf8'", ")", ")", "\n", "for", "d", "in", "self", ".", "data", ":", "\n", "            ", "cp_seq", ",", "token2idx", ",", "idx2token", "=", "lex_map", ".", "get", "(", "d", "[", "'concept'", "]", ",", "vocabs", "[", "'predictable_token'", "]", ")", "\n", "d", "[", "'cp_seq'", "]", "=", "cp_seq", "\n", "d", "[", "'token2idx'", "]", "=", "token2idx", "\n", "d", "[", "'idx2token'", "]", "=", "idx2token", "\n", "", "print", "(", "\"Get %d AMR-English pairs from %s\"", "%", "(", "len", "(", "self", ".", "data", ")", ",", "filename", ")", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "train", "=", "for_train", "\n", "self", ".", "unk_rate", "=", "0.", "\n", "self", ".", "record_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.DataLoader.set_unk_rate": [[284, 286], ["None"], "methods", ["None"], ["", "def", "set_unk_rate", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "unk_rate", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.DataLoader.record": [[287, 289], ["None"], "methods", ["None"], ["", "def", "record", "(", "self", ")", ":", "\n", "        ", "self", ".", "record_flag", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.DataLoader.__iter__": [[290, 317], ["list", "range", "random.shuffle", "list.sort", "data.append", "batches.append", "random.shuffle", "len", "len", "batches.append", "len", "len", "data.batchify", "data.batchify", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.batchify", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.batchify"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "idx", "=", "list", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "if", "self", ".", "train", ":", "\n", "            ", "random", ".", "shuffle", "(", "idx", ")", "\n", "idx", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "self", ".", "data", "[", "x", "]", "[", "'token'", "]", ")", "+", "len", "(", "self", ".", "data", "[", "x", "]", "[", "'concept'", "]", ")", "**", "2", ")", "\n", "\n", "", "batches", "=", "[", "]", "\n", "num_tokens", ",", "data", "=", "0", ",", "[", "]", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "num_tokens", "+=", "len", "(", "self", ".", "data", "[", "i", "]", "[", "'token'", "]", ")", "+", "len", "(", "self", ".", "data", "[", "i", "]", "[", "'concept'", "]", ")", "**", "2", "\n", "data", ".", "append", "(", "self", ".", "data", "[", "i", "]", ")", "\n", "if", "num_tokens", ">=", "self", ".", "batch_size", "or", "len", "(", "data", ")", ">", "256", ":", "\n", "                ", "batches", ".", "append", "(", "data", ")", "\n", "num_tokens", ",", "data", "=", "0", ",", "[", "]", "\n", "\n", "", "", "if", "not", "self", ".", "train", "or", "num_tokens", ">", "self", ".", "batch_size", "/", "2", ":", "\n", "            ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "", "for", "batch", "in", "batches", ":", "\n", "            ", "if", "not", "self", ".", "record_flag", ":", "\n", "                ", "yield", "batchify", "(", "batch", ",", "self", ".", "vocabs", ",", "self", ".", "unk_rate", ",", "self", ".", "train", ")", "\n", "", "else", ":", "\n", "                ", "yield", "batchify", "(", "batch", ",", "self", ".", "vocabs", ",", "self", ".", "unk_rate", ",", "self", ".", "train", ")", ",", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data._back_to_txt_for_check": [[60, 75], ["enumerate", "tensor.t().tolist", "print", "txt.append", "tensor.t", "vocab.idx2token"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["", "", "def", "_back_to_txt_for_check", "(", "tensor", ",", "vocab", ",", "local_idx2token", "=", "None", ")", ":", "\n", "    ", "for", "bid", ",", "xs", "in", "enumerate", "(", "tensor", ".", "t", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "txt", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "            ", "if", "x", "==", "vocab", ".", "padding_idx", ":", "\n", "                ", "break", "\n", "", "if", "x", ">=", "vocab", ".", "size", ":", "\n", "                ", "assert", "local_idx2token", "is", "not", "None", "\n", "assert", "local_idx2token", "[", "bid", "]", "is", "not", "None", "\n", "tok", "=", "local_idx2token", "[", "bid", "]", "[", "x", "]", "\n", "", "else", ":", "\n", "                ", "tok", "=", "vocab", ".", "idx2token", "(", "x", ")", "\n", "", "txt", ".", "append", "(", "tok", ")", "\n", "", "txt", "=", "' '", ".", "join", "(", "txt", ")", "\n", "print", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.ListsToTensor": [[76, 99], ["max", "enumerate", "torch.LongTensor().t_().contiguous", "isinstance", "vocab.token2idx", "ys.append", "random.random", "len", "data.ListsToTensor.toIdx"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["", "", "def", "ListsToTensor", "(", "xs", ",", "vocab", "=", "None", ",", "local_vocabs", "=", "None", ",", "unk_rate", "=", "0.", ")", ":", "\n", "    ", "pad", "=", "vocab", ".", "padding_idx", "if", "vocab", "else", "0", "\n", "\n", "def", "toIdx", "(", "w", ",", "i", ")", ":", "\n", "        ", "if", "vocab", "is", "None", ":", "\n", "            ", "return", "w", "\n", "", "if", "isinstance", "(", "w", ",", "list", ")", ":", "\n", "            ", "return", "[", "toIdx", "(", "_", ",", "i", ")", "for", "_", "in", "w", "]", "\n", "", "if", "random", ".", "random", "(", ")", "<", "unk_rate", ":", "\n", "            ", "return", "vocab", ".", "unk_idx", "\n", "", "if", "local_vocabs", "is", "not", "None", ":", "\n", "            ", "local_vocab", "=", "local_vocabs", "[", "i", "]", "\n", "if", "(", "local_vocab", "is", "not", "None", ")", "and", "(", "w", "in", "local_vocab", ")", ":", "\n", "                ", "return", "local_vocab", "[", "w", "]", "\n", "", "", "return", "vocab", ".", "token2idx", "(", "w", ")", "\n", "\n", "", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "y", "=", "toIdx", "(", "x", ",", "i", ")", "+", "[", "pad", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "ys", ".", "append", "(", "y", ")", "\n", "", "data", "=", "torch", ".", "LongTensor", "(", "ys", ")", ".", "t_", "(", ")", ".", "contiguous", "(", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.ListsofStringToTensor": [[100, 113], ["max", "torch.LongTensor().transpose().contiguous", "ys.append", "len", "list", "zs.append", "torch.LongTensor().transpose", "len", "vocab.token2idx", "torch.LongTensor", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["", "def", "ListsofStringToTensor", "(", "xs", ",", "vocab", ",", "max_string_len", "=", "20", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "        ", "y", "=", "x", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "zs", "=", "[", "]", "\n", "for", "z", "in", "y", ":", "\n", "            ", "z", "=", "list", "(", "z", "[", ":", "max_string_len", "]", ")", "\n", "zs", ".", "append", "(", "vocab", ".", "token2idx", "(", "[", "STR", "]", "+", "z", "+", "[", "END", "]", ")", "+", "[", "vocab", ".", "padding_idx", "]", "*", "(", "max_string_len", "-", "len", "(", "z", ")", ")", ")", "\n", "", "ys", ".", "append", "(", "zs", ")", "\n", "\n", "", "data", "=", "torch", ".", "LongTensor", "(", "ys", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.ArraysToTensor": [[114, 125], ["numpy.array", "numpy.zeros", "enumerate", "list", "list", "tuple", "torch.from_numpy().long", "list", "len", "np.array.max", "torch.from_numpy", "slice", "slice"], "function", ["None"], ["", "def", "ArraysToTensor", "(", "xs", ")", ":", "\n", "    ", "\"list of numpy array, each has the same demonsionality\"", "\n", "x", "=", "np", ".", "array", "(", "[", "list", "(", "x", ".", "shape", ")", "for", "x", "in", "xs", "]", ")", "\n", "shape", "=", "[", "len", "(", "xs", ")", "]", "+", "list", "(", "x", ".", "max", "(", "axis", "=", "0", ")", ")", "\n", "data", "=", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "slicing_shape", "=", "list", "(", "x", ".", "shape", ")", "\n", "slices", "=", "tuple", "(", "[", "slice", "(", "i", ",", "i", "+", "1", ")", "]", "+", "[", "slice", "(", "0", ",", "x", ")", "for", "x", "in", "slicing_shape", "]", ")", "\n", "data", "[", "slices", "]", "=", "x", "\n", "tensor", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "long", "(", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.batchify": [[126, 268], ["data.ListsToTensor", "data.ListsofStringToTensor", "data.ListsToTensor", "data.ListsToTensor", "dict", "vocabs[].token2idx", "vocabs[].token2idx", "vocabs[].token2idx", "enumerate", "ArraysToTensor().transpose_", "len", "dict", "dict", "dict.items", "ArraysToTensor().t_", "torch.LongTensor", "dict", "vocabs[].token2idx", "vocabs[].token2idx", "vocabs[].token2idx", "vocabs[].token2idx", "enumerate", "len", "numpy.zeros", "enumerate", "torch.from_numpy().transpose_().long", "len", "dict", "dict", "dict.items", "ArraysToTensor().t_", "torch.LongTensor", "data.ListsToTensor", "data.ListsofStringToTensor", "data.ListsToTensor", "len", "range", "numpy.stack", "torch.from_numpy().transpose_().long.append", "numpy.array", "len", "len", "max", "range", "torch.from_numpy().transpose_().long.append", "enumerate", "numpy.array", "len", "tuple", "tuple", "tuple", "range", "numpy.array", "np.stack.append", "data.ArraysToTensor", "range", "range", "data.ArraysToTensor", "tuple", "tuple", "tuple", "tuple", "range", "np.stack.append", "enumerate", "torch.from_numpy().transpose_", "range", "range", "data.ArraysToTensor", "tuple", "dict.get", "np.array.append", "len", "len", "record.append", "max", "np.array.append", "enumerate", "len", "len", "random.choice", "len", "len", "vocabs[].token2idx", "len", "len", "len", "tuple", "dict.get", "all_r.append", "len", "len", "torch.from_numpy", "str", "str", "len", "len", "len", "len", "vocabs[].token2idx", "len", "len", "len", "str", "str"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["", "def", "batchify", "(", "data", ",", "vocabs", ",", "unk_rate", "=", "0.", ",", "train", "=", "True", ")", ":", "\n", "    ", "_conc", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'concept'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'concept'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_conc_char", "=", "ListsofStringToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'concept'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'concept_char'", "]", ")", "\n", "_depth", "=", "ListsToTensor", "(", "[", "[", "0", "]", "+", "x", "[", "'depth'", "]", "for", "x", "in", "data", "]", ")", "\n", "\n", "\n", "if", "train", ":", "\n", "\n", "        ", "all_relations", "=", "dict", "(", ")", "\n", "cls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "CLS", ")", "\n", "rcls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "rCLS", ")", "\n", "self_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "SEL", ")", "\n", "all_relations", "[", "tuple", "(", "[", "cls_idx", "]", ")", "]", "=", "0", "\n", "all_relations", "[", "tuple", "(", "[", "rcls_idx", "]", ")", "]", "=", "1", "\n", "all_relations", "[", "tuple", "(", "[", "self_idx", "]", ")", "]", "=", "2", "\n", "\n", "_relation_type", "=", "[", "]", "\n", "for", "bidx", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "n", "=", "len", "(", "x", "[", "'concept'", "]", ")", "\n", "brs", "=", "[", "[", "2", "]", "+", "[", "0", "]", "*", "(", "n", ")", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "rs", "=", "[", "1", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                    ", "all_path", "=", "x", "[", "'relation'", "]", "[", "str", "(", "i", ")", "]", "[", "str", "(", "j", ")", "]", "\n", "path", "=", "random", ".", "choice", "(", "all_path", ")", "[", "'edge'", "]", "\n", "if", "len", "(", "path", ")", "==", "0", ":", "# self loop", "\n", "                        ", "path", "=", "[", "SEL", "]", "\n", "", "if", "len", "(", "path", ")", ">", "8", ":", "# too long distance", "\n", "                        ", "path", "=", "[", "TL", "]", "\n", "", "path", "=", "tuple", "(", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "path", ")", ")", "\n", "rtype", "=", "all_relations", ".", "get", "(", "path", ",", "len", "(", "all_relations", ")", ")", "\n", "if", "rtype", "==", "len", "(", "all_relations", ")", ":", "\n", "                        ", "all_relations", "[", "path", "]", "=", "len", "(", "all_relations", ")", "\n", "", "rs", ".", "append", "(", "rtype", ")", "\n", "", "rs", "=", "np", ".", "array", "(", "rs", ",", "dtype", "=", "np", ".", "int", ")", "\n", "brs", ".", "append", "(", "rs", ")", "\n", "", "brs", "=", "np", ".", "stack", "(", "brs", ")", "\n", "_relation_type", ".", "append", "(", "brs", ")", "\n", "", "_relation_type", "=", "ArraysToTensor", "(", "_relation_type", ")", ".", "transpose_", "(", "0", ",", "2", ")", "\n", "# _relation_bank[_relation_type[i][j][b]] => from j to i go through what ", "\n", "\n", "B", "=", "len", "(", "all_relations", ")", "\n", "_relation_bank", "=", "dict", "(", ")", "\n", "_relation_length", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "all_relations", ".", "items", "(", ")", ":", "\n", "            ", "_relation_bank", "[", "v", "]", "=", "np", ".", "array", "(", "k", ",", "dtype", "=", "np", ".", "int", ")", "\n", "_relation_length", "[", "v", "]", "=", "len", "(", "k", ")", "\n", "", "_relation_bank", "=", "[", "_relation_bank", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_length", "=", "[", "_relation_length", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_bank", "=", "ArraysToTensor", "(", "_relation_bank", ")", ".", "t_", "(", ")", "\n", "_relation_length", "=", "torch", ".", "LongTensor", "(", "_relation_length", ")", "\n", "", "else", ":", "\n", "        ", "all_relations", "=", "dict", "(", ")", "\n", "cls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "CLS", ")", "\n", "rcls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "rCLS", ")", "\n", "self_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "SEL", ")", "\n", "pad_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "PAD", ")", "\n", "all_relations", "[", "tuple", "(", "[", "pad_idx", "]", ")", "]", "=", "0", "\n", "all_relations", "[", "tuple", "(", "[", "cls_idx", "]", ")", "]", "=", "1", "\n", "all_relations", "[", "tuple", "(", "[", "rcls_idx", "]", ")", "]", "=", "2", "\n", "all_relations", "[", "tuple", "(", "[", "self_idx", "]", ")", "]", "=", "3", "\n", "\n", "_relation_type", "=", "[", "]", "\n", "record", "=", "[", "]", "\n", "bsz", ",", "num_concepts", ",", "num_paths", "=", "0", ",", "0", ",", "0", "\n", "for", "bidx", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "n", "=", "len", "(", "x", "[", "'concept'", "]", ")", "\n", "num_concepts", "=", "max", "(", "n", "+", "1", ",", "num_concepts", ")", "\n", "brs", "=", "[", "[", "[", "3", "]", "]", "+", "[", "[", "1", "]", "]", "*", "(", "n", ")", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "rs", "=", "[", "[", "2", "]", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                    ", "all_r", "=", "[", "]", "\n", "all_path", "=", "x", "[", "'relation'", "]", "[", "str", "(", "i", ")", "]", "[", "str", "(", "j", ")", "]", "\n", "path0", "=", "all_path", "[", "0", "]", "[", "'edge'", "]", "\n", "if", "len", "(", "path0", ")", "==", "0", "or", "len", "(", "path0", ")", ">", "8", ":", "\n", "                        ", "all_path", "=", "all_path", "[", ":", "1", "]", "\n", "", "for", "path", "in", "all_path", ":", "\n", "                        ", "path", "=", "path", "[", "'edge'", "]", "\n", "if", "len", "(", "path", ")", "==", "0", ":", "# self loop", "\n", "                            ", "path", "=", "[", "SEL", "]", "\n", "", "if", "len", "(", "path", ")", ">", "8", ":", "# too long distance", "\n", "                            ", "path", "=", "[", "TL", "]", "\n", "", "path", "=", "tuple", "(", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "path", ")", ")", "\n", "rtype", "=", "all_relations", ".", "get", "(", "path", ",", "len", "(", "all_relations", ")", ")", "\n", "if", "rtype", "==", "len", "(", "all_relations", ")", ":", "\n", "                            ", "all_relations", "[", "path", "]", "=", "len", "(", "all_relations", ")", "\n", "", "all_r", ".", "append", "(", "rtype", ")", "\n", "", "record", ".", "append", "(", "len", "(", "all_r", ")", ")", "\n", "num_paths", "=", "max", "(", "len", "(", "all_r", ")", ",", "num_paths", ")", "\n", "rs", ".", "append", "(", "all_r", ")", "\n", "", "brs", ".", "append", "(", "rs", ")", "\n", "", "_relation_type", ".", "append", "(", "brs", ")", "\n", "", "bsz", "=", "len", "(", "_relation_type", ")", "\n", "_relation_matrix", "=", "np", ".", "zeros", "(", "(", "bsz", ",", "num_concepts", ",", "num_concepts", ",", "num_paths", ")", ")", "\n", "for", "b", ",", "x", "in", "enumerate", "(", "_relation_type", ")", ":", "\n", "            ", "for", "i", ",", "y", "in", "enumerate", "(", "x", ")", ":", "\n", "                ", "for", "j", ",", "z", "in", "enumerate", "(", "y", ")", ":", "\n", "                    ", "for", "k", ",", "r", "in", "enumerate", "(", "z", ")", ":", "\n", "                        ", "_relation_matrix", "[", "b", ",", "i", ",", "j", ",", "k", "]", "=", "r", "\n", "", "", "", "", "_relation_type", "=", "torch", ".", "from_numpy", "(", "_relation_matrix", ")", ".", "transpose_", "(", "0", ",", "2", ")", ".", "long", "(", ")", "\n", "\n", "B", "=", "len", "(", "all_relations", ")", "\n", "_relation_bank", "=", "dict", "(", ")", "\n", "_relation_length", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "all_relations", ".", "items", "(", ")", ":", "\n", "            ", "_relation_bank", "[", "v", "]", "=", "np", ".", "array", "(", "k", ",", "dtype", "=", "np", ".", "int", ")", "\n", "_relation_length", "[", "v", "]", "=", "len", "(", "k", ")", "\n", "", "_relation_bank", "=", "[", "_relation_bank", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_length", "=", "[", "_relation_length", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_bank", "=", "ArraysToTensor", "(", "_relation_bank", ")", ".", "t_", "(", ")", "\n", "_relation_length", "=", "torch", ".", "LongTensor", "(", "_relation_length", ")", "\n", "\n", "", "local_token2idx", "=", "[", "x", "[", "'token2idx'", "]", "for", "x", "in", "data", "]", "\n", "local_idx2token", "=", "[", "x", "[", "'idx2token'", "]", "for", "x", "in", "data", "]", "\n", "\n", "augmented_token", "=", "[", "[", "STR", "]", "+", "x", "[", "'token'", "]", "+", "[", "END", "]", "for", "x", "in", "data", "]", "\n", "\n", "_token_in", "=", "ListsToTensor", "(", "augmented_token", ",", "vocabs", "[", "'token'", "]", ",", "unk_rate", "=", "unk_rate", ")", "[", ":", "-", "1", "]", "\n", "_token_char_in", "=", "ListsofStringToTensor", "(", "augmented_token", ",", "vocabs", "[", "'token_char'", "]", ")", "[", ":", "-", "1", "]", "\n", "\n", "_token_out", "=", "ListsToTensor", "(", "augmented_token", ",", "vocabs", "[", "'predictable_token'", "]", ",", "local_token2idx", ")", "[", "1", ":", "]", "\n", "_cp_seq", "=", "ListsToTensor", "(", "[", "x", "[", "'cp_seq'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'predictable_token'", "]", ",", "local_token2idx", ")", "\n", "\n", "abstract", "=", "[", "x", "[", "'abstract'", "]", "for", "x", "in", "data", "]", "\n", "\n", "ret", "=", "{", "\n", "'concept'", ":", "_conc", ",", "\n", "'concept_char'", ":", "_conc_char", ",", "\n", "'concept_depth'", ":", "_depth", ",", "\n", "'relation'", ":", "_relation_type", ",", "\n", "'relation_bank'", ":", "_relation_bank", ",", "\n", "'relation_length'", ":", "_relation_length", ",", "\n", "'local_idx2token'", ":", "local_idx2token", ",", "\n", "'local_token2idx'", ":", "local_token2idx", ",", "\n", "'token_in'", ":", "_token_in", ",", "\n", "'token_char_in'", ":", "_token_char_in", ",", "\n", "'token_out'", ":", "_token_out", ",", "\n", "'cp_seq'", ":", "_cp_seq", ",", "\n", "'abstract'", ":", "abstract", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.data.parse_config": [[319, 333], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "", "def", "parse_config", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--token_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/token_vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/concept_vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--predictable_token_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/predictable_token_vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--token_char_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/token_char_vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/concept_char_vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--relation_vocab'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/relation_vocab'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/dev.txt.features.preproc.json'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.__init__": [[14, 47], ["torch.nn.Module.__init__", "encoder.TokenEncoder", "encoder.RelationEncoder", "encoder.TokenEncoder", "graph_transformer.GraphTransformer", "transformer.Transformer", "math.sqrt", "transformer.SinusoidalPositionalEmbedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.SelfAttentionMask", "decoder.DecodeLayer", "torch.nn.Linear", "torch.nn.Linear", "generator.Generator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "\n", "word_char_dim", ",", "word_dim", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "char2concept_dim", ",", "\n", "rel_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "\n", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "\n", "snt_layers", ",", "graph_layers", ",", "inference_layers", ",", "\n", "pretrained_file", ",", "device", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "concept_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'concept'", "]", ",", "vocabs", "[", "'concept_char'", "]", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2concept_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "self", ".", "relation_encoder", "=", "RelationEncoder", "(", "vocabs", "[", "'relation'", "]", ",", "rel_dim", ",", "embed_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "dropout", ")", "\n", "self", ".", "token_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'token'", "]", ",", "vocabs", "[", "'token_char'", "]", ",", "\n", "word_char_dim", ",", "word_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "\n", "self", ".", "graph_encoder", "=", "GraphTransformer", "(", "graph_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "snt_encoder", "=", "Transformer", "(", "snt_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "True", ")", "\n", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "token_position", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ",", "device", ")", "\n", "self", ".", "concept_depth", "=", "nn", ".", "Embedding", "(", "32", ",", "embed_dim", ")", "\n", "self", ".", "token_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "concept_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "self_attn_mask", "=", "SelfAttentionMask", "(", "device", ")", "\n", "self", ".", "decoder", "=", "DecodeLayer", "(", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "concept_dim", ",", "rel_dim", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "probe_generator", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.reset_parameters": [[48, 52], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "probe_generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "probe_generator", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "concept_depth", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.encoder_attn": [[53, 70], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "generator.Generator.concept_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.relation_encoder", "generator.Generator.sum", "inp[].ne().sum().clamp_", "inp[].ne().sum().clamp_.unsqueeze().type_as", "generator.Generator.graph_encoder.get_attn_weights", "generator.Generator.concept_depth", "generator.Generator.concept_encoder", "inp[].ne().sum", "inp[].ne().sum().clamp_.unsqueeze", "inp[].ne"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformer.get_attn_weights"], ["", "def", "encoder_attn", "(", "self", ",", "inp", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "inp", "[", "'concept'", "]", ",", "inp", "[", "'concept_char'", "]", ")", "+", "self", ".", "concept_depth", "(", "inp", "[", "'concept_depth'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "inp", "[", "'concept'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "\n", "relation", "=", "self", ".", "relation_encoder", "(", "inp", "[", "'relation_bank'", "]", ",", "inp", "[", "'relation_length'", "]", ")", "\n", "relation", "[", "0", ",", ":", "]", "=", "0.", "\n", "relation", "=", "relation", "[", "inp", "[", "'relation'", "]", "]", "\n", "sum_relation", "=", "relation", ".", "sum", "(", "dim", "=", "3", ")", "\n", "num_valid_paths", "=", "inp", "[", "'relation'", "]", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "3", ")", ".", "clamp_", "(", "min", "=", "1", ")", "\n", "divisor", "=", "(", "num_valid_paths", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "sum_relation", ")", "\n", "relation", "=", "sum_relation", "/", "divisor", "\n", "\n", "attn", "=", "self", ".", "graph_encoder", ".", "get_attn_weights", "(", "concept_repr", ",", "relation", ",", "self_padding_mask", "=", "concept_mask", ")", "\n", "# nlayers x tgt_len x src_len x  bsz x num_heads", "\n", "", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.encode_step": [[71, 96], ["generator.Generator.concept_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.relation_encoder", "generator.Generator.graph_encoder", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "generator.Generator.concept_depth", "relation.index_select().view.index_select().view.index_select().view", "relation.index_select().view.index_select().view.sum", "inp[].ne().sum().clamp_", "inp[].ne().sum().clamp_.unsqueeze().type_as", "generator.Generator.probe_generator", "generator.Generator.concept_encoder", "relation.index_select().view.index_select().view.index_select", "inp[].size", "inp[].ne().sum", "inp[].ne().sum().clamp_.unsqueeze", "inp[].view", "inp[].ne"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "encode_step", "(", "self", ",", "inp", ",", "train", "=", "True", ")", ":", "\n", "        ", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "inp", "[", "'concept'", "]", ",", "inp", "[", "'concept_char'", "]", ")", "+", "self", ".", "concept_depth", "(", "inp", "[", "'concept_depth'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "inp", "[", "'concept'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "\n", "relation", "=", "self", ".", "relation_encoder", "(", "inp", "[", "'relation_bank'", "]", ",", "inp", "[", "'relation_length'", "]", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "relation", "=", "relation", ".", "index_select", "(", "0", ",", "inp", "[", "'relation'", "]", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "*", "inp", "[", "'relation'", "]", ".", "size", "(", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "#pick = inp['relation'][:,:,:,0]", "\n", "#relation = relation.index_select(0, pick.view(-1)).view(*pick.size(), -1)", "\n", "            ", "relation", "[", "0", ",", ":", "]", "=", "0.", "\n", "relation", "=", "relation", "[", "inp", "[", "'relation'", "]", "]", "# i x j x bsz x num x dim", "\n", "sum_relation", "=", "relation", ".", "sum", "(", "dim", "=", "3", ")", "# i x j x bsz x dim", "\n", "num_valid_paths", "=", "inp", "[", "'relation'", "]", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "3", ")", ".", "clamp_", "(", "min", "=", "1", ")", "# i x j x bsz ", "\n", "divisor", "=", "(", "num_valid_paths", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "sum_relation", ")", "\n", "relation", "=", "sum_relation", "/", "divisor", "\n", "\n", "", "concept_repr", "=", "self", ".", "graph_encoder", "(", "concept_repr", ",", "relation", ",", "self_padding_mask", "=", "concept_mask", ")", "\n", "\n", "probe", "=", "torch", ".", "tanh", "(", "self", ".", "probe_generator", "(", "concept_repr", "[", ":", "1", "]", ")", ")", "\n", "concept_repr", "=", "concept_repr", "[", "1", ":", "]", "\n", "concept_mask", "=", "concept_mask", "[", "1", ":", "]", "\n", "return", "concept_repr", ",", "concept_mask", ",", "probe", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.work": [[97, 112], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "generator.Generator.encode_step", "search.Hypothesis", "concept_repr.size", "search.search_by_batch", "search.Beam", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encode_step", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.search_by_batch"], ["", "def", "work", "(", "self", ",", "data", ",", "beam_size", ",", "max_time_step", ",", "min_time_step", "=", "1", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "concept_repr", ",", "concept_mask", ",", "probe", "=", "self", ".", "encode_step", "(", "data", ",", "train", "=", "False", ")", "\n", "\n", "mem_dict", "=", "{", "'graph_state'", ":", "concept_repr", ",", "\n", "'graph_padding_mask'", ":", "concept_mask", ",", "\n", "'probe'", ":", "probe", ",", "\n", "'local_idx2token'", ":", "data", "[", "'local_idx2token'", "]", ",", "\n", "'cp_seq'", ":", "data", "[", "'cp_seq'", "]", "}", "\n", "init_state_dict", "=", "{", "}", "\n", "init_hyp", "=", "Hypothesis", "(", "init_state_dict", ",", "[", "STR", "]", ",", "0.", ")", "\n", "bsz", "=", "concept_repr", ".", "size", "(", "1", ")", "\n", "beams", "=", "[", "Beam", "(", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "[", "init_hyp", "]", ",", "self", ".", "device", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "search_by_batch", "(", "self", ",", "beams", ",", "mem_dict", ")", "\n", "", "return", "beams", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.prepare_incremental_input": [[114, 119], ["data.ListsToTensor", "data.ListsofStringToTensor", "data.ListsToTensor.cuda", "data.ListsofStringToTensor.cuda"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor"], ["", "def", "prepare_incremental_input", "(", "self", ",", "step_seq", ")", ":", "\n", "        ", "token", "=", "ListsToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'token'", "]", ")", "\n", "token_char", "=", "ListsofStringToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'token_char'", "]", ")", "\n", "token", ",", "token_char", "=", "token", ".", "cuda", "(", "self", ".", "device", ")", ",", "token_char", ".", "cuda", "(", "self", ".", "device", ")", "\n", "return", "token", ",", "token_char", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.decode_step": [[120, 168], ["graph_repr.size", "generator.Generator.token_embed_layer_norm", "enumerate", "generator.Generator.decoder", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "zip", "generator.Generator.token_position", "layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "generator.Generator.vocabs[].idx2token", "generator.Generator.squeeze", "topk_scores.tolist", "topk_token.tolist", "zip", "results.append", "generator.Generator.token_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "res.append", "generator.Generator.decode_step.idx2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["", "def", "decode_step", "(", "self", ",", "inp", ",", "state_dict", ",", "mem_dict", ",", "offset", ",", "topk", ")", ":", "\n", "        ", "step_token", ",", "step_token_char", "=", "inp", "\n", "graph_repr", "=", "mem_dict", "[", "'graph_state'", "]", "\n", "graph_padding_mask", "=", "mem_dict", "[", "'graph_padding_mask'", "]", "\n", "probe", "=", "mem_dict", "[", "'probe'", "]", "\n", "copy_seq", "=", "mem_dict", "[", "'cp_seq'", "]", "\n", "local_vocabs", "=", "mem_dict", "[", "'local_idx2token'", "]", "\n", "_", ",", "bsz", ",", "_", "=", "graph_repr", ".", "size", "(", ")", "\n", "\n", "new_state_dict", "=", "{", "}", "\n", "\n", "token_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "token_encoder", "(", "step_token", ",", "step_token_char", ")", "+", "self", ".", "token_position", "(", "step_token", ",", "offset", ")", "\n", "token_repr", "=", "self", ".", "token_embed_layer_norm", "(", "token_repr", ")", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "snt_encoder", ".", "layers", ")", ":", "\n", "            ", "name_i", "=", "'token_repr_%d'", "%", "idx", "\n", "if", "name_i", "in", "state_dict", ":", "\n", "                ", "prev_token_repr", "=", "state_dict", "[", "name_i", "]", "\n", "new_token_repr", "=", "torch", ".", "cat", "(", "[", "prev_token_repr", ",", "token_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "new_token_repr", "=", "token_repr", "\n", "\n", "", "new_state_dict", "[", "name_i", "]", "=", "new_token_repr", "\n", "token_repr", ",", "_", ",", "_", "=", "layer", "(", "token_repr", ",", "kv", "=", "new_token_repr", ",", "external_memories", "=", "graph_repr", ",", "external_padding_mask", "=", "graph_padding_mask", ")", "\n", "", "name", "=", "'token_state'", "\n", "if", "name", "in", "state_dict", ":", "\n", "            ", "prev_token_state", "=", "state_dict", "[", "name", "]", "\n", "new_token_state", "=", "torch", ".", "cat", "(", "[", "prev_token_state", ",", "token_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "new_token_state", "=", "token_repr", "\n", "", "new_state_dict", "[", "name", "]", "=", "new_token_state", "\n", "LL", "=", "self", ".", "decoder", "(", "probe", ",", "graph_repr", ",", "new_token_state", ",", "graph_padding_mask", ",", "None", ",", "None", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "\n", "\n", "def", "idx2token", "(", "idx", ",", "local_vocab", ")", ":", "\n", "            ", "if", "idx", "in", "local_vocab", ":", "\n", "                ", "return", "local_vocab", "[", "idx", "]", "\n", "", "return", "self", ".", "vocabs", "[", "'predictable_token'", "]", ".", "idx2token", "(", "idx", ")", "\n", "\n", "", "topk_scores", ",", "topk_token", "=", "torch", ".", "topk", "(", "LL", ".", "squeeze", "(", "0", ")", ",", "topk", ",", "1", ")", "# bsz x k", "\n", "\n", "results", "=", "[", "]", "\n", "for", "s", ",", "t", ",", "local_vocab", "in", "zip", "(", "topk_scores", ".", "tolist", "(", ")", ",", "topk_token", ".", "tolist", "(", ")", ",", "local_vocabs", ")", ":", "\n", "            ", "res", "=", "[", "]", "\n", "for", "score", ",", "token", "in", "zip", "(", "s", ",", "t", ")", ":", "\n", "                ", "res", ".", "append", "(", "(", "idx2token", "(", "token", ",", "local_vocab", ")", ",", "score", ")", ")", "\n", "", "results", ".", "append", "(", "res", ")", "\n", "\n", "", "return", "new_state_dict", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.generator.Generator.forward": [[169, 183], ["generator.Generator.encode_step", "generator.Generator.token_embed_layer_norm", "torch.dropout", "torch.dropout", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.self_attn_mask", "generator.Generator.snt_encoder", "probe.expand_as.expand_as.expand_as", "generator.Generator.decoder", "generator.Generator.token_position", "data[].size", "generator.Generator.token_encoder"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encode_step", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "concept_repr", ",", "concept_mask", ",", "probe", "=", "self", ".", "encode_step", "(", "data", ")", "\n", "token_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "token_encoder", "(", "data", "[", "'token_in'", "]", ",", "data", "[", "'token_char_in'", "]", ")", "+", "self", ".", "token_position", "(", "data", "[", "'token_in'", "]", ")", "\n", "token_repr", "=", "self", ".", "token_embed_layer_norm", "(", "token_repr", ")", "\n", "token_repr", "=", "F", ".", "dropout", "(", "token_repr", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "token_mask", "=", "torch", ".", "eq", "(", "data", "[", "'token_in'", "]", ",", "self", ".", "vocabs", "[", "'token'", "]", ".", "padding_idx", ")", "\n", "attn_mask", "=", "self", ".", "self_attn_mask", "(", "data", "[", "'token_in'", "]", ".", "size", "(", "0", ")", ")", "\n", "token_repr", "=", "self", ".", "snt_encoder", "(", "token_repr", ",", "\n", "self_padding_mask", "=", "token_mask", ",", "self_attn_mask", "=", "attn_mask", ",", "\n", "external_memories", "=", "concept_repr", ",", "external_padding_mask", "=", "concept_mask", ")", "\n", "\n", "probe", "=", "probe", ".", "expand_as", "(", "token_repr", ")", "# tgt_len x bsz x embed_dim", "\n", "return", "self", ".", "decoder", "(", "probe", ",", "concept_repr", ",", "token_repr", ",", "concept_mask", ",", "token_mask", ",", "attn_mask", ",", "data", "[", "'cp_seq'", "]", ",", "target", "=", "data", "[", "'token_out'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess.__init__": [[52, 70], ["postprocess.PostProcess.load_compound_map", "pycorenlp.StanfordCoreNLP", "pycorenlp.StanfordCoreNLP.annotate"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.load_compound_map", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.annotate"], ["def", "__init__", "(", "self", ",", "retokenize", "=", "False", ",", "span", "=", "True", ",", "compound_map_file", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        the defualt settings are for development only\n        for testing, span must be set to False\n        \"\"\"", "\n", "if", "retokenize", ":", "\n", "            ", "nlp", "=", "StanfordCoreNLP", "(", "'http://localhost:9000'", ")", "\n", "nlp_properties", "=", "{", "\n", "'annotators'", ":", "\"tokenize,ssplit\"", ",", "\n", "\"tokenize.options\"", ":", "\"splitHyphenated=true,normalizeParentheses=false\"", ",", "\n", "\"tokenize.whitespace\"", ":", "False", ",", "\n", "'ssplit.isOneSentence'", ":", "True", ",", "\n", "'outputFormat'", ":", "'json'", "\n", "}", "\n", "self", ".", "stanford_tokenize", "=", "lambda", "text", ":", "[", "x", "[", "'word'", "]", "for", "x", "in", "nlp", ".", "annotate", "(", "text", ",", "nlp_properties", ")", "[", "'sentences'", "]", "[", "0", "]", "[", "'tokens'", "]", "]", "\n", "", "self", ".", "retokenize", "=", "retokenize", "\n", "self", ".", "span", "=", "span", "\n", "self", ".", "compound_map", "=", "self", ".", "load_compound_map", "(", "compound_map_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess.load_compound_map": [[71, 80], ["dict", "open().readlines", "line.strip().split", "open", "line.strip"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "@", "staticmethod", "\n", "def", "load_compound_map", "(", "file_path", ")", ":", "\n", "        ", "compound_map", "=", "dict", "(", ")", "\n", "if", "file_path", "is", "None", ":", "\n", "            ", "return", "compound_map", "\n", "", "for", "line", "in", "open", "(", "file_path", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "compound", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "compound_map", "[", "'-'", ".", "join", "(", "compound", ")", "]", "=", "' '", ".", "join", "(", "compound", ")", "\n", "", "return", "compound_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess._find_node": [[81, 91], ["ret.append"], "methods", ["None"], ["", "def", "_find_node", "(", "self", ",", "abstract", ",", "graph", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "name", "in", "graph", ".", "name2concept", ":", "\n", "            ", "value", "=", "graph", ".", "name2concept", "[", "name", "]", "\n", "if", "abstract", "==", "value", ":", "\n", "                ", "ret", ".", "append", "(", "name", ")", "\n", "#assert len(ret) == 1, (ret)", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "return", "None", "\n", "", "return", "ret", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess._check": [[92, 204], ["re.search", "x.startswith", "x.startswith", "x.startswith", "x.startswith", "x.startswith", "postprocess.PostProcess._find_node", "postprocess.PostProcess._find_node", "int", "len", "xmap.get", "xmap.get", "xmap.get", "xmap.get", "xmap.get", "xmap.get", "xmap.get", "xmap.get", "len", "str", "str", "len", "num2words.num2words.num2words", "postprocess.PostProcess.country_map.get", "int", "str", "int", "int", "int", "int", "str", "str", "num2words.num2words.num2words", "str", "str", "num2words.num2words.num2words", "num2words.num2words.num2words", "xmap.get.strip", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess._find_node", "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess._find_node", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "_check", "(", "self", ",", "x", ",", "abstract", ",", "graph", ")", ":", "\n", "        ", "\"\"\"some speical cases where we map abstract symbols to strings, \n        will return None if not in any case\n        \"\"\"", "\n", "#China => Chinese", "\n", "if", "x", ".", "startswith", "(", "'NATIONALITY'", ")", "or", "x", ".", "startswith", "(", "'COUNTRY'", ")", ":", "\n", "            ", "node", "=", "self", ".", "_find_node", "(", "x", ",", "graph", ")", "\n", "if", "not", "node", ":", "\n", "                ", "return", "None", "\n", "", "node1", "=", "None", "\n", "for", "nxt", "in", "graph", ".", "graph", "[", "node", "]", ":", "\n", "                ", "if", "graph", ".", "graph", "[", "node", "]", "[", "nxt", "]", "[", "'label'", "]", "==", "\"name_reverse_\"", ":", "\n", "                    ", "node1", "=", "nxt", "\n", "break", "\n", "", "", "if", "not", "node1", ":", "\n", "                ", "return", "None", "\n", "", "if", "graph", ".", "name2concept", "[", "node1", "]", "==", "'country'", ":", "\n", "                ", "do_transform", "=", "False", "\n", "for", "nxt", "in", "graph", ".", "graph", "[", "node1", "]", ":", "\n", "                    ", "if", "graph", ".", "graph", "[", "node1", "]", "[", "nxt", "]", "[", "'label'", "]", "==", "\"domain\"", ":", "\n", "#or graph.graph[node1][nxt]['label'] == \"ARG1_reverse_\":", "\n", "                        ", "do_transform", "=", "True", "\n", "", "", "if", "do_transform", ":", "\n", "                    ", "v", "=", "self", ".", "country_map", ".", "get", "(", "abstract", "[", "'ops'", "]", ",", "None", ")", "\n", "if", "v", "is", "not", "None", ":", "\n", "                        ", "return", "[", "v", "]", "\n", "", "", "", "return", "None", "\n", "\n", "#100 => hundred ", "\n", "", "if", "re", ".", "search", "(", "r'^\\d+$'", ",", "x", ")", ":", "\n", "            ", "node", "=", "self", ".", "_find_node", "(", "x", ",", "graph", ")", "\n", "if", "node", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "for", "nxt", "in", "graph", ".", "graph", "[", "node", "]", ":", "\n", "                ", "if", "graph", ".", "graph", "[", "node", "]", "[", "nxt", "]", "[", "'label'", "]", "==", "\"li_reverse_\"", ":", "\n", "                    ", "return", "[", "str", "(", "abstract", "[", "'value'", "]", ")", "]", "\n", "", "", "value", "=", "abstract", "[", "'value'", "]", "\n", "if", "value", "==", "100000", ":", "\n", "                ", "return", "[", "'hundreds of thousands'", "]", "\n", "", "if", "int", "(", "value", ")", "==", "value", ":", "\n", "                ", "if", "value", ">=", "1000000000", "and", "value", "%", "1000", "==", "0", ":", "\n", "                    ", "v", "=", "value", "/", "1000000000", "\n", "if", "int", "(", "v", ")", "==", "v", ":", "\n", "                        ", "v", "=", "int", "(", "v", ")", "\n", "", "return", "[", "str", "(", "v", ")", "+", "' billion'", "]", "\n", "", "if", "value", ">=", "1000000", "and", "value", "%", "1000", "==", "0", ":", "\n", "                    ", "v", "=", "value", "/", "1000000", "\n", "if", "int", "(", "v", ")", "==", "v", ":", "\n", "                        ", "v", "=", "int", "(", "v", ")", "\n", "", "return", "[", "str", "(", "v", ")", "+", "' million'", "]", "\n", "", "", "return", "None", "\n", "\n", "# 7 => July", "\n", "", "if", "x", ".", "startswith", "(", "'DATE_ATTRS'", ")", ":", "\n", "            ", "assert", "'attrs'", "in", "abstract", "or", "'edges'", "in", "abstract", "\n", "if", "len", "(", "abstract", "[", "'attrs'", "]", ")", ">", "0", ":", "\n", "                ", "xmap", "=", "abstract", "[", "'attrs'", "]", "\n", "year", "=", "xmap", ".", "get", "(", "'year'", ",", "None", ")", "\n", "month", "=", "xmap", ".", "get", "(", "'month'", ",", "None", ")", "\n", "day", "=", "xmap", ".", "get", "(", "'day'", ",", "None", ")", "\n", "decade", "=", "xmap", ".", "get", "(", "'decade'", ",", "None", ")", "\n", "century", "=", "xmap", ".", "get", "(", "'century'", ",", "None", ")", "\n", "time", "=", "xmap", ".", "get", "(", "'time'", ",", "None", ")", "\n", "if", "year", "and", "month", "and", "day", ":", "\n", "#30 July 2019", "\n", "                    ", "return", "[", "str", "(", "day", ")", ",", "self", ".", "month_map", "[", "month", "]", ",", "str", "(", "year", ")", "]", "\n", "", "if", "day", "and", "month", ":", "\n", "#April 18th", "\n", "                    ", "return", "[", "self", ".", "month_map", "[", "month", "]", ",", "num2words", "(", "day", ",", "to", "=", "'ordinal_num'", ")", "]", "\n", "", "if", "year", "and", "month", ":", "\n", "#October 2008", "\n", "                    ", "return", "[", "self", ".", "month_map", "[", "month", "]", ",", "str", "(", "year", ")", "]", "\n", "", "if", "year", ":", "\n", "#2020", "\n", "                    ", "return", "[", "str", "(", "year", ")", "]", "\n", "", "if", "month", ":", "\n", "#October", "\n", "                    ", "return", "[", "self", ".", "month_map", "[", "month", "]", "]", "\n", "", "if", "day", ":", "\n", "#21st", "\n", "                    ", "return", "[", "num2words", "(", "day", ",", "to", "=", "'ordinal_num'", ")", "]", "\n", "", "if", "decade", ":", "\n", "#1980s", "\n", "                    ", "return", "[", "str", "(", "decade", ")", "+", "'s'", "]", "\n", "", "if", "century", ":", "\n", "# 21st", "\n", "                    ", "return", "[", "num2words", "(", "century", ",", "to", "=", "'ordinal_num'", ")", "]", "\n", "", "if", "time", ":", "\n", "#return as it is", "\n", "                    ", "return", "[", "time", ".", "strip", "(", "'\"'", ")", "]", "\n", "", "", "else", ":", "\n", "                ", "xmap", "=", "abstract", "[", "'edges'", "]", "\n", "weekday", "=", "xmap", ".", "get", "(", "'weekday'", ",", "None", ")", "\n", "dayperiod", "=", "xmap", ".", "get", "(", "'dayperiod'", ",", "None", ")", "\n", "if", "weekday", "and", "dayperiod", ":", "\n", "                    ", "return", "[", "weekday", ",", "dayperiod", "]", "\n", "", "if", "weekday", ":", "\n", "                    ", "return", "[", "weekday", "]", "\n", "", "if", "dayperiod", ":", "\n", "                    ", "return", "[", "dayperiod", "]", "\n", "", "", "assert", "False", "\n", "return", "None", "\n", "\n", "# 3 2 => 3:2", "\n", "", "if", "x", ".", "startswith", "(", "'SCORE_ENTITY'", ")", ":", "\n", "            ", "assert", "len", "(", "abstract", "[", "'ops'", "]", ")", "==", "2", "\n", "return", "[", "str", "(", "abstract", "[", "'ops'", "]", "[", "0", "]", ")", ",", "':'", ",", "str", "(", "abstract", "[", "'ops'", "]", "[", "1", "]", ")", "]", "\n", "\n", "# 3 => 3rd", "\n", "", "if", "x", ".", "startswith", "(", "'ORDINAL_ENTITY'", ")", ":", "\n", "            ", "assert", "len", "(", "abstract", "[", "'ops'", "]", ")", "==", "1", "\n", "return", "[", "num2words", "(", "int", "(", "abstract", "[", "'ops'", "]", "[", "0", "]", ")", ",", "to", "=", "'ordinal_num'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess.check": [[205, 230], ["dict", "postprocess.PostProcess._check", "isinstance", "isinstance", "isinstance", "len", "str", "isinstance", "isinstance", "isinstance", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess._check"], ["", "", "def", "check", "(", "self", ",", "abstract", ",", "graph", ")", ":", "\n", "        ", "\"\"\"Get the abstract-to-string map\"\"\"", "\n", "ret", "=", "dict", "(", ")", "\n", "for", "x", "in", "abstract", ":", "\n", "            ", "y", "=", "self", ".", "_check", "(", "x", ",", "abstract", "[", "x", "]", ",", "graph", ")", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "ret", "[", "x", "]", "=", "y", "\n", "continue", "\n", "\n", "", "xmap", "=", "abstract", "[", "x", "]", "\n", "if", "'ops'", "in", "xmap", ":", "\n", "                ", "assert", "'value'", "not", "in", "xmap", "\n", "assert", "isinstance", "(", "xmap", "[", "'ops'", "]", ",", "str", ")", "or", "isinstance", "(", "xmap", "[", "'ops'", "]", ",", "list", ")", "\n", "if", "isinstance", "(", "xmap", "[", "'ops'", "]", ",", "list", ")", ":", "\n", "                    ", "assert", "len", "(", "xmap", "[", "'ops'", "]", ")", "==", "1", "\n", "ret", "[", "x", "]", "=", "[", "str", "(", "xmap", "[", "'ops'", "]", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "                    ", "ret", "[", "x", "]", "=", "[", "xmap", "[", "'ops'", "]", "]", "\n", "", "", "elif", "'value'", "in", "xmap", ":", "\n", "                ", "assert", "'ops'", "not", "in", "xmap", "\n", "assert", "isinstance", "(", "xmap", "[", "'value'", "]", ",", "float", ")", "or", "isinstance", "(", "xmap", "[", "'value'", "]", ",", "int", ")", "or", "isinstance", "(", "xmap", "[", "'value'", "]", ",", "str", ")", "\n", "ret", "[", "x", "]", "=", "[", "str", "(", "xmap", "[", "'value'", "]", ")", "]", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess.post_process": [[231, 256], ["postprocess.PostProcess.check", "ret.lower.lower.lower", "ret.lower.lower.extend", "postprocess.PostProcess.compound_map.get", "ret.lower.lower.append", "postprocess.PostProcess.stanford_tokenize"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.PostProcess.check", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "post_process", "(", "self", ",", "sent", ",", "abstract", ",", "graph", ")", ":", "\n", "        ", "\"\"\"\n        span is for development only\n        \"\"\"", "\n", "if", "self", ".", "span", ":", "\n", "            ", "_abstract", "=", "{", "}", "\n", "for", "x", "in", "abstract", ":", "\n", "                ", "_abstract", "[", "x", "]", "=", "[", "abstract", "[", "x", "]", "[", "'span'", "]", "]", "\n", "", "abstract", "=", "_abstract", "\n", "", "else", ":", "\n", "            ", "abstract", "=", "self", ".", "check", "(", "abstract", ",", "graph", ")", "\n", "", "ret", "=", "[", "]", "\n", "for", "tok", "in", "sent", ":", "\n", "            ", "if", "tok", "in", "abstract", ":", "\n", "                ", "ret", ".", "extend", "(", "abstract", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tok", "=", "self", ".", "compound_map", ".", "get", "(", "tok", ",", "tok", ")", "\n", "ret", ".", "append", "(", "tok", ")", "\n", "", "", "ret", "=", "' '", ".", "join", "(", "ret", ")", "\n", "\n", "if", "self", ".", "retokenize", ":", "\n", "            ", "ret", "=", "' '", ".", "join", "(", "self", ".", "stanford_tokenize", "(", "ret", ")", ")", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "            ", "ret", "=", "ret", ".", "lower", "(", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.postprocess.parse_config": [[257, 268], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "parse_config", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--golden_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0/test.txt.features'", ")", "\n", "parser", ".", "add_argument", "(", "'--pred_file'", ",", "type", "=", "str", ",", "default", "=", "'./epoch718_batch137999_test_out'", ")", "\n", "parser", ".", "add_argument", "(", "'--retokenize'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--span'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--compound_map_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/AMR/amr_2.0_utils/joints.txt'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.record.parse_config": [[12, 22], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--output_suffix'", ",", "type", "=", "str", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.record.record_batch": [[23, 32], ["utils.move_to_cuda", "model.encoder_attn", "enumerate", "attn[].cpu", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda", "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encoder_attn"], ["", "def", "record_batch", "(", "model", ",", "batch", ",", "data", ")", ":", "\n", "    ", "batch", "=", "move_to_cuda", "(", "batch", ",", "model", ".", "device", ")", "\n", "attn", "=", "model", ".", "encoder_attn", "(", "batch", ")", "\n", "#nlayers x tgt_len x src_len x  bsz x num_heads", "\n", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "L", "=", "len", "(", "x", "[", "'concept'", "]", ")", "+", "1", "\n", "x", "[", "'attn'", "]", "=", "attn", "[", ":", ",", ":", "L", ",", ":", "L", ",", "i", ",", ":", "]", ".", "cpu", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Hypothesis.__init__": [[13, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "state_dict", ",", "seq", ",", "score", ")", ":", "\n", "#state_dict: hidden states of the last step (has not yet consider seq[-1])", "\n", "#seq: current generated sequence", "\n", "#score: accumlated score so far", "\n", "        ", "self", ".", "state_dict", "=", "state_dict", "\n", "self", ".", "seq", "=", "seq", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Hypothesis.is_completed": [[21, 28], ["None"], "methods", ["None"], ["", "def", "is_completed", "(", "self", ")", ":", "\n", "###########", "\n", "##rewrite##", "\n", "###########", "\n", "        ", "if", "self", ".", "seq", "[", "-", "1", "]", "==", "END", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Hypothesis.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.__init__": [[34, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "hypotheses", ",", "device", ")", ":", "\n", "# hypotheses are the collection of alive hypotheses", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "min_time_step", "=", "min_time_step", "\n", "self", ".", "max_time_step", "=", "max_time_step", "\n", "self", ".", "completed_hypotheses", "=", "[", "]", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "hypotheses", "=", "hypotheses", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.merge_score": [[44, 56], ["float"], "methods", ["None"], ["", "def", "merge_score", "(", "self", ",", "prev_hyp", ",", "step", ")", ":", "\n", "# step has two attributes: token and score", "\n", "###########", "\n", "##rewrite##", "\n", "###########", "\n", "        ", "token", ",", "score", "=", "step", "\n", "prefix", "=", "prev_hyp", ".", "seq", "\n", "\n", "if", "token", "==", "UNK", ":", "\n", "            ", "return", "float", "(", "'-inf'", ")", "\n", "", "new_score", "=", "prev_hyp", ".", "score", "+", "score", "\n", "return", "new_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.update": [[57, 93], ["enumerate", "candidates.sort", "torch.tensor().cuda", "dict", "new_states.items", "enumerate", "len", "v.index_select().split", "dict", "dict.items", "new_hyps.append", "hyp.is_completed", "search.Beam.merge_score", "candidates.append", "torch.tensor", "search.Hypothesis", "search.Beam.hypotheses.append", "len", "v.index_select", "search.Beam.completed_hypotheses.append", "v.size", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Hypothesis.is_completed", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.merge_score", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "update", "(", "self", ",", "new_states", ",", "last_steps", ")", ":", "\n", "# last_steps: list (#num_hypotheses) of list (#beam_size) of (token, score) ", "\n", "        ", "candidates", "=", "[", "]", "\n", "for", "prev_hyp_idx", ",", "steps", "in", "enumerate", "(", "last_steps", ")", ":", "\n", "            ", "for", "step", "in", "steps", ":", "\n", "                ", "token", "=", "step", "[", "0", "]", "\n", "score", "=", "self", ".", "merge_score", "(", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ",", "step", ")", "\n", "candidates", ".", "append", "(", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", ")", "\n", "\n", "", "", "candidates", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "live_nyp_num", "=", "self", ".", "beam_size", "-", "len", "(", "self", ".", "completed_hypotheses", ")", "\n", "candidates", "=", "candidates", "[", ":", "live_nyp_num", "]", "\n", "# candidates: list of triples (prev_hyp_idx, token, score)", "\n", "\n", "new_hyps", "=", "[", "]", "\n", "_prev_hyp_idx", "=", "torch", ".", "tensor", "(", "[", "x", "[", "0", "]", "for", "x", "in", "candidates", "]", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "_split_state", "=", "dict", "(", ")", "# key => list", "\n", "for", "k", ",", "v", "in", "new_states", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "_split_state", "[", "k", "]", "=", "v", ".", "index_select", "(", "split_dim", ",", "_prev_hyp_idx", ")", ".", "split", "(", "1", ",", "dim", "=", "split_dim", ")", "\n", "\n", "", "for", "idx", ",", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", "in", "enumerate", "(", "candidates", ")", ":", "\n", "            ", "state", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "_split_state", ".", "items", "(", ")", ":", "\n", "                ", "state", "[", "k", "]", "=", "_split_state", "[", "k", "]", "[", "idx", "]", "\n", "", "seq", "=", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ".", "seq", "+", "[", "token", "]", "\n", "new_hyps", ".", "append", "(", "Hypothesis", "(", "state", ",", "seq", ",", "score", ")", ")", "\n", "\n", "", "self", ".", "hypotheses", "=", "[", "]", "\n", "for", "hyp", "in", "new_hyps", ":", "\n", "            ", "if", "hyp", ".", "is_completed", "(", ")", ":", "\n", "                ", "if", "len", "(", "hyp", ")", "-", "2", ">=", "self", ".", "min_time_step", ":", "\n", "                    ", "self", ".", "completed_hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "self", ".", "steps", "+=", "1", "\n", "#self.print_everything()", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.completed": [[95, 99], ["len"], "methods", ["None"], ["", "def", "completed", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "<", "self", ".", "beam_size", "and", "self", ".", "steps", "<", "self", ".", "max_time_step", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.get_k_best": [[100, 105], ["search.Beam.completed_hypotheses.sort", "len", "len"], "methods", ["None"], ["", "def", "get_k_best", "(", "self", ",", "k", ",", "alpha", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "==", "0", ":", "\n", "            ", "self", ".", "completed_hypotheses", "=", "self", ".", "hypotheses", "\n", "", "self", ".", "completed_hypotheses", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "score", "/", "(", "(", "1", "+", "len", "(", "x", ".", "seq", ")", ")", "**", "alpha", ")", ",", "reverse", "=", "True", ")", "\n", "return", "self", ".", "completed_hypotheses", "[", ":", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.Beam.print_everything": [[106, 113], ["print", "print", "print", "print"], "methods", ["None"], ["", "def", "print_everything", "(", "self", ")", ":", "\n", "        ", "print", "(", "'alive:'", ")", "\n", "for", "x", "in", "self", ".", "hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "", "print", "(", "'completed:'", ")", "\n", "for", "x", "in", "self", ".", "completed_hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.search.search_by_batch": [[114, 169], ["model.prepare_incremental_input", "dict", "dict.items", "enumerate", "torch.tensor().cuda", "search.search_by_batch.ready_to_submit"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.prepare_incremental_input", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "", "def", "search_by_batch", "(", "model", ",", "beams", ",", "mem_dict", ")", ":", "\n", "\n", "    ", "def", "ready_to_submit", "(", "hypotheses", ")", ":", "\n", "        ", "inp", "=", "model", ".", "prepare_incremental_input", "(", "[", "hyp", ".", "seq", "[", "-", "1", ":", "]", "for", "hyp", "in", "hypotheses", "]", ")", "\n", "concat_hyps", "=", "dict", "(", ")", "\n", "for", "hyp", "in", "hypotheses", ":", "\n", "            ", "for", "k", ",", "v", "in", "hyp", ".", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "concat_hyps", ".", "get", "(", "k", ",", "[", "]", ")", "+", "[", "v", "]", "\n", "", "", "for", "k", ",", "v", "in", "concat_hyps", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "v", "[", "0", "]", ".", "size", "(", ")", ")", ">=", "3", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "0", ")", "\n", "", "", "return", "concat_hyps", ",", "inp", "\n", "\n", "", "while", "True", ":", "\n", "        ", "hypotheses", "=", "[", "]", "\n", "indices", "=", "[", "]", "\n", "offset", "=", "-", "1", "\n", "for", "idx", ",", "beam", "in", "enumerate", "(", "beams", ")", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "for", "hyp", "in", "beam", ".", "hypotheses", ":", "\n", "                    ", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "indices", ".", "append", "(", "idx", ")", "\n", "offset", "=", "len", "(", "hyp", ".", "seq", ")", "-", "1", "\n", "", "", "", "if", "not", "hypotheses", ":", "\n", "            ", "break", "\n", "\n", "", "indices", "=", "torch", ".", "tensor", "(", "indices", ")", ".", "cuda", "(", "beams", "[", "0", "]", ".", "device", ")", "\n", "state_dict", ",", "inp", "=", "ready_to_submit", "(", "hypotheses", ")", "\n", "cur_mem_dict", "=", "dict", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "mem_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "list", ")", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "[", "v", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "", "else", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "v", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "\n", "", "", "state_dict", ",", "results", "=", "model", ".", "decode_step", "(", "inp", ",", "state_dict", ",", "cur_mem_dict", ",", "offset", ",", "beams", "[", "0", "]", ".", "beam_size", ")", "\n", "_len_each_beam", "=", "[", "len", "(", "beam", ".", "hypotheses", ")", "for", "beam", "in", "beams", "if", "not", "beam", ".", "completed", "(", ")", "]", "\n", "_state_dict_each_beam", "=", "[", "dict", "(", ")", "for", "_", "in", "_len_each_beam", "]", "\n", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "v", ".", "split", "(", "_len_each_beam", ",", "dim", "=", "split_dim", ")", ")", ":", "\n", "                ", "_state_dict_each_beam", "[", "i", "]", "[", "k", "]", "=", "x", "\n", "\n", "", "", "_pos", "=", "0", "\n", "_idx", "=", "0", "\n", "for", "beam", "in", "beams", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "_len", "=", "len", "(", "beam", ".", "hypotheses", ")", "\n", "beam", ".", "update", "(", "_state_dict_each_beam", "[", "_idx", "]", ",", "results", "[", "_pos", ":", "_pos", "+", "_len", "]", ")", "\n", "_pos", "+=", "_len", "\n", "_idx", "+=", "1", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.adam.AdamWeightDecayOptimizer.__init__": [[9, 22], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "AdamWeightDecayOptimizer", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.adam.AdamWeightDecayOptimizer.__setstate__": [[23, 27], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdamWeightDecayOptimizer", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.adam.AdamWeightDecayOptimizer.step": [[28, 89], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "torch.zeros_like", "exp_avg.mul_", "exp_avg_sq.mul_", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "", "amsgrad", "=", "group", "[", "'amsgrad'", "]", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "'max_exp_avg_sq'", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want ot decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "", "update", "=", "(", "exp_avg", "/", "denom", ")", ".", "add_", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", ",", "update", ")", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.Transformer.__init__": [[9, 14], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "transformer.Transformer.layers.append", "transformer.TransformerLayer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "TransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.Transformer.forward": [[15, 21], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", ",", "_", "=", "layer", "(", "x", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "external_memories", ",", "external_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.TransformerLayer.__init__": [[24, 37], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerLayer.reset_parameters", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "with_external", "=", "with_external", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "self", ".", "external_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "external_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.TransformerLayer.reset_parameters": [[38, 43], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.TransformerLayer.forward": [[44, 73], ["torch.dropout", "torch.dropout", "transformer.TransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.fc2", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.ff_layer_norm", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.external_attn", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.external_layer_norm", "transformer.TransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "False", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "residual", "=", "x", "\n", "x", ",", "external_attn", "=", "self", ".", "external_attn", "(", "query", "=", "x", ",", "key", "=", "external_memories", ",", "value", "=", "external_memories", ",", "key_padding_mask", "=", "external_padding_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "external_layer_norm", "(", "residual", "+", "x", ")", "\n", "", "else", ":", "\n", "            ", "external_attn", "=", "None", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", ",", "external_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.__init__": [[76, 91], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "transformer.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.reset_parameters": [[92, 97], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.forward": [[98, 174], ["query.size", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout.transpose().contiguous().view", "transformer.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "transformer.MultiheadAttention.in_proj_qkv", "transformer.MultiheadAttention.transpose", "list", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.max", "attn_weights.transpose.transpose.transpose", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_kv", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_k", "transformer.MultiheadAttention.in_proj_v", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "attn_weights.transpose.transpose.size", "attn_mask.unsqueeze", "float", "key_padding_mask.transpose().unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "key_padding_mask.transpose().unsqueeze", "torch.dropout.transpose", "key_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "False", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "# k,v: bsz*heads x src_len x dim", "\n", "# q: bsz*heads x tgt_len x dim ", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "0", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads ", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "attn_weights", ",", "_", "=", "attn_weights", ".", "max", "(", "dim", "=", "1", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.in_proj_qkv": [[175, 177], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.in_proj_kv": [[178, 180], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.in_proj_q": [[181, 183], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.in_proj_k": [[184, 186], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention.in_proj_v": [[187, 189], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.MultiheadAttention._in_proj": [[190, 197], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SelfAttentionMask.__init__": [[205, 209], ["torch.nn.Module.__init__", "transformer.SelfAttentionMask.get_mask"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.get_mask"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "init_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "SelfAttentionMask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "init_size", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SelfAttentionMask.get_mask": [[210, 214], ["torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_mask", "(", "size", ")", ":", "\n", "        ", "weights", "=", "torch", ".", "ones", "(", "(", "size", ",", "size", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "triu_", "(", "1", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SelfAttentionMask.forward": [[215, 220], ["transformer.SelfAttentionMask.weights[].detach().to().detach", "transformer.SelfAttentionMask.get_mask", "transformer.SelfAttentionMask.weights.size", "transformer.SelfAttentionMask.weights[].detach().to", "transformer.SelfAttentionMask.weights[].detach"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.get_mask", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "self", ".", "weights", "is", "None", "or", "size", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "size", ")", "\n", "", "res", "=", "self", ".", "weights", "[", ":", "size", ",", ":", "size", "]", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.LearnedPositionalEmbedding.__init__": [[224, 229], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformer.LearnedPositionalEmbedding.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "device", ",", "max_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Embedding", "(", "max_size", ",", "embedding_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.LearnedPositionalEmbedding.reset_parameters": [[230, 232], ["torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weights", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.LearnedPositionalEmbedding.forward": [[233, 239], ["input.size", "transformer.LearnedPositionalEmbedding.weights().unsqueeze().expand", "transformer.LearnedPositionalEmbedding.weights().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.LearnedPositionalEmbedding.weights"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "positions", "=", "(", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "res", "=", "self", ".", "weights", "(", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SinusoidalPositionalEmbedding.__init__": [[243, 251], ["torch.nn.Module.__init__", "transformer.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "device", ",", "init_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SinusoidalPositionalEmbedding.get_embedding": [[252, 267], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.SinusoidalPositionalEmbedding.forward": [[268, 282], ["input.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach().to().detach", "transformer.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.SinusoidalPositionalEmbedding.weights.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach().to", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "transformer.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "\n", "self", ".", "embedding_dim", ",", "\n", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.transformer.Embedding": [[198, 203], ["torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.AMRIO.__init__": [[12, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.AMRIO.read": [[15, 40], ["open", "line.rstrip.rstrip.rstrip", "line.rstrip.rstrip.startswith", "line.rstrip.rstrip.startswith", "line.rstrip.rstrip.startswith", "len", "json.loads", "line.rstrip.rstrip.startswith", "len", "json.loads", "line.rstrip.rstrip.startswith", "AMRGraph.AMRGraph._is_abs_form", "to.lower", "json.loads", "line.rstrip.rstrip.startswith", "len", "AMRGraph.AMRGraph._is_abs_form", "le.lower", "json.loads", "line.rstrip.rstrip.startswith", "len", "json.loads", "smatch.AMR.get_amr_line", "smatch.AMR.parse_AMR_line", "AMRGraph.AMRGraph.AMRGraph", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form", "home.repos.pwc.inspect_result.jcyk_gtos.generator.AMRGraph._is_abs_form", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.parse_AMR_line"], ["", "@", "staticmethod", "\n", "def", "read", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::id '", ")", ":", "\n", "                    ", "amr_id", "=", "line", "[", "len", "(", "'# ::id '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::snt '", ")", ":", "\n", "                    ", "sentence", "=", "line", "[", "len", "(", "'# ::snt '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::tokens '", ")", ":", "\n", "                    ", "tokens", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::tokens '", ")", ":", "]", ")", "\n", "tokens", "=", "[", "to", "if", "_is_abs_form", "(", "to", ")", "else", "to", ".", "lower", "(", ")", "for", "to", "in", "tokens", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::lemmas '", ")", ":", "\n", "                    ", "lemmas", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::lemmas '", ")", ":", "]", ")", "\n", "lemmas", "=", "[", "le", "if", "_is_abs_form", "(", "le", ")", "else", "le", ".", "lower", "(", ")", "for", "le", "in", "lemmas", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::pos_tags '", ")", ":", "\n", "                    ", "pos_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::pos_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::ner_tags '", ")", ":", "\n", "                    ", "ner_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::ner_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::abstract_map '", ")", ":", "\n", "                    ", "abstract_map", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::abstract_map '", ")", ":", "]", ")", "\n", "graph_line", "=", "AMR", ".", "get_amr_line", "(", "f", ")", "\n", "amr", "=", "AMR", ".", "parse_AMR_line", "(", "graph_line", ")", "\n", "myamr", "=", "AMRGraph", "(", "amr", ")", "\n", "yield", "tokens", ",", "lemmas", ",", "abstract_map", ",", "myamr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.LexicalMap.__init__": [[44, 46], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.LexicalMap.get": [[48, 64], ["set", "cp_seq.append", "dict", "dict", "vocab.token2idx"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["", "def", "get", "(", "self", ",", "concept", ",", "vocab", "=", "None", ")", ":", "\n", "        ", "cp_seq", "=", "[", "]", "\n", "for", "conc", "in", "concept", ":", "\n", "            ", "cp_seq", ".", "append", "(", "conc", ")", "\n", "\n", "", "if", "vocab", "is", "None", ":", "\n", "            ", "return", "cp_seq", "\n", "\n", "", "new_tokens", "=", "set", "(", "cp", "for", "cp", "in", "cp_seq", "if", "vocab", ".", "token2idx", "(", "cp", ")", "==", "vocab", ".", "unk_idx", ")", "\n", "token2idx", ",", "idx2token", "=", "dict", "(", ")", ",", "dict", "(", ")", "\n", "nxt", "=", "vocab", ".", "size", "\n", "for", "x", "in", "new_tokens", ":", "\n", "            ", "token2idx", "[", "x", "]", "=", "nxt", "\n", "idx2token", "[", "nxt", "]", "=", "x", "\n", "nxt", "+=", "1", "\n", "", "return", "cp_seq", ",", "token2idx", ",", "idx2token", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.read_file": [[66, 76], ["extract.AMRIO.read", "print", "token.append", "lemma.append", "abstract.append", "amrs.append", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["", "", "def", "read_file", "(", "filename", ")", ":", "\n", "# read preprocessed amr file", "\n", "    ", "token", ",", "lemma", ",", "abstract", ",", "amrs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "_tok", ",", "_lem", ",", "_abstract", ",", "_myamr", "in", "AMRIO", ".", "read", "(", "filename", ")", ":", "\n", "        ", "token", ".", "append", "(", "_tok", ")", "\n", "lemma", ".", "append", "(", "_lem", ")", "\n", "abstract", ".", "append", "(", "_abstract", ")", "\n", "amrs", ".", "append", "(", "_myamr", ")", "\n", "", "print", "(", "'read from %s, %d amrs'", "%", "(", "filename", ",", "len", "(", "token", ")", ")", ")", "\n", "return", "amrs", ",", "token", ",", "lemma", ",", "abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.make_vocab": [[77, 88], ["collections.Counter", "collections.Counter", "collections.Counter.most_common", "collections.Counter.update", "list"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update"], ["", "def", "make_vocab", "(", "batch_seq", ",", "char_level", "=", "False", ")", ":", "\n", "    ", "cnt", "=", "Counter", "(", ")", "\n", "for", "seq", "in", "batch_seq", ":", "\n", "        ", "cnt", ".", "update", "(", "seq", ")", "\n", "", "if", "not", "char_level", ":", "\n", "        ", "return", "cnt", "\n", "", "char_cnt", "=", "Counter", "(", ")", "\n", "for", "x", ",", "y", "in", "cnt", ".", "most_common", "(", ")", ":", "\n", "        ", "for", "ch", "in", "list", "(", "x", ")", ":", "\n", "            ", "char_cnt", "[", "ch", "]", "+=", "y", "\n", "", "", "return", "cnt", ",", "char_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.write_vocab": [[90, 94], ["open", "vocab.most_common", "fo.write"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "def", "write_vocab", "(", "vocab", ",", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'w'", ")", "as", "fo", ":", "\n", "        ", "for", "x", ",", "y", "in", "vocab", ".", "most_common", "(", ")", ":", "\n", "            ", "fo", ".", "write", "(", "'%s\\t%d\\n'", "%", "(", "x", ",", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.extract.parse_config": [[96, 102], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--amr_files'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--nprocessors'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda": [[5, 17], ["torch.is_tensor", "maybe_tensor.cuda", "isinstance", "isinstance", "utils.move_to_cuda", "maybe_tensor.items", "utils.move_to_cuda"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.move_to_cuda"], ["def", "move_to_cuda", "(", "maybe_tensor", ",", "device", ")", ":", "\n", "    ", "if", "torch", ".", "is_tensor", "(", "maybe_tensor", ")", ":", "\n", "        ", "return", "maybe_tensor", ".", "cuda", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "dict", ")", ":", "\n", "        ", "return", "{", "\n", "key", ":", "move_to_cuda", "(", "value", ",", "device", ")", "\n", "for", "key", ",", "value", "in", "maybe_tensor", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "list", ")", ":", "\n", "        ", "return", "[", "move_to_cuda", "(", "x", ",", "device", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "else", ":", "\n", "        ", "return", "maybe_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.compute_f_by_tensor": [[18, 44], ["input.view().tolist.view().tolist", "target.view().tolist.view().tolist", "mask.view().tolist.view().tolist", "zip", "input.view().tolist.view", "target.view().tolist.view", "mask.view().tolist.view"], "function", ["None"], ["", "", "def", "compute_f_by_tensor", "(", "input", ",", "target", ",", "mask", ")", ":", "\n", "    ", "input", "=", "input", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "tp", ",", "fp", ",", "tn", ",", "fn", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "for", "i", ",", "t", ",", "m", "in", "zip", "(", "input", ",", "target", ",", "mask", ")", ":", "\n", "        ", "if", "m", "==", "1", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "if", "i", "==", "1", ":", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "tp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "fp", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "fn", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "tn", "+=", "1", "\n", "", "", "", "", "if", "tp", "==", "0", ":", "\n", "        ", "return", "0.", ",", "0.", ",", "0.", "\n", "\n", "", "P", "=", "tp", "/", "(", "tp", "+", "fp", ")", "\n", "R", "=", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "F", "=", "2", "*", "P", "*", "R", "/", "(", "P", "+", "R", ")", "\n", "return", "P", ",", "R", ",", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.gelu_fast": [[45, 49], ["hasattr", "math.sqrt", "torch.tanh", "torch.pow"], "function", ["None"], ["", "def", "gelu_fast", "(", "x", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "gelu_fast", ",", "\"_a\"", ")", ":", "\n", "        ", "gelu_fast", ".", "_a", "=", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n", "", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "gelu_fast", ".", "_a", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.gelu": [[50, 52], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.generator.utils.label_smoothed_nll_loss": [[54, 64], ["log_probs.gather().squeeze", "log_probs.sum", "log_probs.size", "log_probs.gather", "target.unsqueeze"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "label_smoothed_nll_loss", "(", "log_probs", ",", "target", ",", "eps", ")", ":", "\n", "#log_probs: N x C", "\n", "#target: N", "\n", "    ", "nll_loss", "=", "-", "log_probs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "if", "eps", "==", "0.", ":", "\n", "        ", "return", "nll_loss", "\n", "", "smooth_loss", "=", "-", "log_probs", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "eps_i", "=", "eps", "/", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.", "-", "eps", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.build_arg_parser": [[47, 72], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are separated by a single blank line'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--significant'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--vv'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Very Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ms'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score)'", "\n", "'instead of a single document-level smatch score (Default: false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pr'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.build_arg_parser2": [[74, 103], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "\"--files\"", ",", "nargs", "=", "2", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are '", "'separated by a single blank line. This option is required.'", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "'--significant'", ",", "dest", "=", "\"significant\"", ",", "type", "=", "\"int\"", ",", "default", "=", "2", ",", "\n", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--vv\"", ",", "\"--veryverbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"vv\"", ",", "\n", "help", "=", "'Very Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--ms\"", ",", "\"--multiple_score\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"ms\"", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score) instead of '", "'a single document-level smatch score (Default: False)'", ")", "\n", "parser", ".", "add_option", "(", "'--pr'", ",", "\"--precision_recall\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"pr\"", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_option", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_option", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_option", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "pr", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_best_match": [[105, 174], ["smatch.compute_pool", "range", "print", "print", "print", "print", "len", "smatch.compute_match", "print", "smatch.smart_init_mapping", "smatch.random_init_mapping", "print", "print", "smatch.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_pool", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_match", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.smart_init_mapping", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.random_init_mapping", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_best_gain"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize": [[176, 181], ["item.lower().rstrip", "item.lower"], "function", ["None"], ["", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_pool": [[183, 291], ["candidate_mapping.append", "set", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "smatch.normalize", "smatch.normalize", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.normalize"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.smart_init_mapping": [[293, 342], ["random.seed", "enumerate", "list", "result.append", "len", "no_word_match.append", "result.append", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.random_init_mapping": [[344, 379], ["random.seed", "list", "result.append", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_match": [[381, 431], ["enumerate", "print", "print", "tuple", "print", "print", "print", "tuple", "tuple", "print", "tuple", "print"], "function", ["None"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"match computing complete, result:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.move_gain": [[433, 477], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.swap_gain": [[479, 543], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_best_gain": [[545, 644], ["set", "enumerate", "enumerate", "range", "range", "print", "print", "set.remove", "len", "smatch.swap_gain", "print", "smatch.move_gain", "print", "print", "print", "print", "print", "print", "smatch.compute_match", "print", "print", "print", "print", "smatch.compute_match", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.swap_gain", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.move_gain", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_match", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_match"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.print_alignment": [[646, 665], ["zip", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_f": [[667, 694], ["float", "float", "float", "float", "print", "print"], "function", ["None"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.generate_amr_lines": [[696, 718], ["amr.AMR.get_amr_line", "amr.AMR.get_amr_line", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line"], ["", "", "def", "generate_amr_lines", "(", "f1", ",", "f2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "cur_amr1", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f1", ")", "\n", "cur_amr2", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f2", ")", "\n", "if", "not", "cur_amr1", "and", "not", "cur_amr2", ":", "\n", "            ", "pass", "\n", "", "elif", "not", "cur_amr1", ":", "\n", "            ", "print", "(", "\"Error: File 1 has less AMRs than file 2\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "elif", "not", "cur_amr2", ":", "\n", "            ", "print", "(", "\"Error: File 2 has less AMRs than file 1\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "else", ":", "\n", "            ", "yield", "cur_amr1", ",", "cur_amr2", "\n", "continue", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_amr_match": [[720, 784], ["amr1.rename_node", "amr2.rename_node", "amr1.get_triples", "amr2.get_triples", "smatch.get_best_match", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "amr_pair.append", "len", "len", "len", "len", "len", "len", "smatch.print_alignment", "len", "len", "amr.AMR.parse_AMR_line", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.rename_node", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.rename_node", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_best_match", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.print_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.parse_AMR_line"], ["", "", "def", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "amr_pair", "=", "[", "]", "\n", "for", "i", ",", "cur_amr", "in", "(", "1", ",", "cur_amr1", ")", ",", "(", "2", ",", "cur_amr2", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "amr_pair", ".", "append", "(", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Error in parsing amr %d: %s\"", "%", "(", "i", ",", "cur_amr", ")", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Please check if the AMR is ill-formatted. Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Error message: %s\"", "%", "e", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "", "amr1", ",", "amr2", "=", "amr_pair", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n", "if", "justinstance", ":", "\n", "        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.score_amr_pairs": [[786, 818], ["enumerate", "smatch.generate_amr_lines", "smatch.get_amr_match", "match_triple_dict.clear", "print", "print", "print", "smatch.compute_f", "smatch.compute_f"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.generate_amr_lines", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_amr_match", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_f", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_f"], ["", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.main": [[820, 854], ["smatch.score_amr_pairs", "args.f[].close", "args.f[].close", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.score_amr_pairs", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close"], ["", "", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "pr_flag", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "arguments", ".", "r", "+", "1", "\n", "if", "arguments", ".", "ms", ":", "\n", "        ", "single_score", "=", "False", "\n", "", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "arguments", ".", "vv", ":", "\n", "        ", "veryVerbose", "=", "True", "\n", "", "if", "arguments", ".", "pr", ":", "\n", "        ", "pr_flag", "=", "True", "\n", "# significant digits to print out", "\n", "", "floatdisplay", "=", "\"%%.%df\"", "%", "arguments", ".", "significant", "\n", "for", "(", "precision", ",", "recall", ",", "best_f_score", ")", "in", "score_amr_pairs", "(", "args", ".", "f", "[", "0", "]", ",", "args", ".", "f", "[", "1", "]", ",", "\n", "justinstance", "=", "arguments", ".", "justinstance", ",", "\n", "justattribute", "=", "arguments", ".", "justattribute", ",", "\n", "justrelation", "=", "arguments", ".", "justrelation", ")", ":", "\n", "# print(\"Sentence\", sent_num)", "\n", "        ", "if", "pr_flag", ":", "\n", "            ", "print", "(", "\"Precision: \"", "+", "floatdisplay", "%", "precision", ")", "\n", "print", "(", "\"Recall: \"", "+", "floatdisplay", "%", "recall", ")", "\n", "", "print", "(", "\"F-score: \"", "+", "floatdisplay", "%", "best_f_score", ")", "\n", "", "args", ".", "f", "[", "0", "]", ".", "close", "(", ")", "\n", "args", ".", "f", "[", "1", "]", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.get_names": [[22, 55], ["os.walk", "len", "print", "name_list.append", "os.path.exists"], "function", ["None"], ["def", "get_names", "(", "file_dir", ",", "files", ")", ":", "\n", "    ", "\"\"\"\n    Get the annotator name list based on a list of files\n    Args:\n    file_dir: AMR file folder\n    files: a list of AMR names, e.g. nw_wsj_0001_1\n\n    Returns:\n   a list of user names who annotate all the files\n    \"\"\"", "\n", "# for each user, check if they have files available", "\n", "# return user name list", "\n", "total_list", "=", "[", "]", "\n", "name_list", "=", "[", "]", "\n", "get_sub", "=", "False", "\n", "for", "path", ",", "subdir", ",", "dir_files", "in", "os", ".", "walk", "(", "file_dir", ")", ":", "\n", "        ", "if", "not", "get_sub", ":", "\n", "            ", "total_list", "=", "subdir", "[", ":", "]", "\n", "get_sub", "=", "True", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "for", "user", "in", "total_list", ":", "\n", "        ", "has_file", "=", "True", "\n", "for", "f", "in", "files", ":", "\n", "            ", "file_path", "=", "file_dir", "+", "user", "+", "\"/\"", "+", "f", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "                ", "has_file", "=", "False", "\n", "break", "\n", "", "", "if", "has_file", ":", "\n", "            ", "name_list", ".", "append", "(", "user", ")", "\n", "", "", "if", "len", "(", "name_list", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"********Error: Cannot find any user who completes the files*************\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "return", "name_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.compute_files": [[57, 130], ["smatch.compute_f", "smatch.get_amr_line", "smatch.get_amr_line", "amr.AMR.parse_AMR_line", "amr.AMR.parse_AMR_line", "amr.AMR.parse_AMR_line.rename_node", "amr.AMR.parse_AMR_line.rename_node", "amr.AMR.parse_AMR_line.get_triples", "amr.AMR.parse_AMR_line.get_triples", "smatch.get_best_match", "smatch.match_triple_dict.clear", "os.path.exists", "print", "os.path.exists", "print", "open", "open", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "print", "len", "len", "len", "len", "len", "len", "smatch.print_alignment", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.compute_f", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.rename_node", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.rename_node", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.get_best_match", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch.print_alignment"], ["", "def", "compute_files", "(", "user1", ",", "user2", ",", "file_list", ",", "dir_pre", ",", "start_num", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Compute the smatch scores for a file list between two users\n    Args:\n    user1: user 1 name\n    user2: user 2 name\n    file_list: file list\n    dir_pre: the file location prefix\n    start_num: the number of restarts in smatch\n    Returns:\n    smatch f score.\n\n    \"\"\"", "\n", "match_total", "=", "0", "\n", "test_total", "=", "0", "\n", "gold_total", "=", "0", "\n", "for", "fi", "in", "file_list", ":", "\n", "        ", "file1", "=", "dir_pre", "+", "user1", "+", "\"/\"", "+", "fi", "+", "\".txt\"", "\n", "file2", "=", "dir_pre", "+", "user2", "+", "\"/\"", "+", "fi", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file1", ")", ":", "\n", "            ", "print", "(", "\"*********Error: \"", ",", "file1", ",", "\"does not exist*********\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "-", "1.00", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "file2", ")", ":", "\n", "            ", "print", "(", "\"*********Error: \"", ",", "file2", ",", "\"does not exist*********\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "-", "1.00", "\n", "", "try", ":", "\n", "            ", "file1_h", "=", "open", "(", "file1", ",", "\"r\"", ")", "\n", "file2_h", "=", "open", "(", "file2", ",", "\"r\"", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "print", "(", "\"Cannot open the files\"", ",", "file1", ",", "file2", ",", "file", "=", "ERROR_LOG", ")", "\n", "break", "\n", "", "cur_amr1", "=", "smatch", ".", "get_amr_line", "(", "file1_h", ")", "\n", "cur_amr2", "=", "smatch", ".", "get_amr_line", "(", "file2_h", ")", "\n", "if", "cur_amr1", "==", "\"\"", ":", "\n", "            ", "print", "(", "\"AMR 1 is empty\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "continue", "\n", "", "if", "cur_amr2", "==", "\"\"", ":", "\n", "            ", "print", "(", "\"AMR 2 is empty\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "continue", "\n", "", "amr1", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr1", ")", "\n", "amr2", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr2", ")", "\n", "test_label", "=", "\"a\"", "\n", "gold_label", "=", "\"b\"", "\n", "amr1", ".", "rename_node", "(", "test_label", ")", "\n", "amr2", ".", "rename_node", "(", "gold_label", ")", "\n", "(", "test_inst", ",", "test_rel1", ",", "test_rel2", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "gold_inst", ",", "gold_rel1", ",", "gold_rel2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Instance triples of file 1:\"", ",", "len", "(", "test_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_inst", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of file 1:\"", ",", "len", "(", "test_rel1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_rel1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of file 1:\"", ",", "len", "(", "test_rel2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_rel2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of file 2:\"", ",", "len", "(", "gold_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_inst", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of file 2:\"", ",", "len", "(", "gold_rel1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_rel1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of file 2:\"", ",", "len", "(", "gold_rel2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_rel2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "(", "best_match", ",", "best_match_num", ")", "=", "smatch", ".", "get_best_match", "(", "test_inst", ",", "test_rel1", ",", "test_rel2", ",", "\n", "gold_inst", ",", "gold_rel1", ",", "gold_rel2", ",", "\n", "test_label", ",", "gold_label", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best Match:\"", ",", "smatch", ".", "print_alignment", "(", "best_match", ",", "test_inst", ",", "gold_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "match_total", "+=", "best_match_num", "\n", "test_total", "+=", "(", "len", "(", "test_inst", ")", "+", "len", "(", "test_rel1", ")", "+", "len", "(", "test_rel2", ")", ")", "\n", "gold_total", "+=", "(", "len", "(", "gold_inst", ")", "+", "len", "(", "gold_rel1", ")", "+", "len", "(", "gold_rel2", ")", ")", "\n", "smatch", ".", "match_triple_dict", ".", "clear", "(", ")", "\n", "", "(", "precision", ",", "recall", ",", "f_score", ")", "=", "smatch", ".", "compute_f", "(", "match_total", ",", "test_total", ",", "gold_total", ")", "\n", "return", "\"%.2f\"", "%", "f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.get_max_width": [[132, 134], ["max", "len", "str"], "function", ["None"], ["", "def", "get_max_width", "(", "table", ",", "index", ")", ":", "\n", "    ", "return", "max", "(", "[", "len", "(", "str", "(", "row", "[", "index", "]", ")", ")", "for", "row", "in", "table", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.pprint_table": [[136, 150], ["range", "len", "col_paddings.append", "print", "range", "print", "smatch-table.get_max_width", "row[].ljust", "len", "str().rjust", "print", "str"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.get_max_width"], ["", "def", "pprint_table", "(", "table", ")", ":", "\n", "    ", "\"\"\"\n    Print a table in pretty format\n\n    \"\"\"", "\n", "col_paddings", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "table", "[", "0", "]", ")", ")", ":", "\n", "        ", "col_paddings", ".", "append", "(", "get_max_width", "(", "table", ",", "i", ")", ")", "\n", "", "for", "row", "in", "table", ":", "\n", "        ", "print", "(", "row", "[", "0", "]", ".", "ljust", "(", "col_paddings", "[", "0", "]", "+", "1", ")", ",", "end", "=", "\"\"", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "row", ")", ")", ":", "\n", "            ", "col", "=", "str", "(", "row", "[", "i", "]", ")", ".", "rjust", "(", "col_paddings", "[", "i", "]", "+", "2", ")", "\n", "print", "(", "col", ",", "end", "=", "''", ")", "\n", "", "print", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.build_arg_parser": [[152, 165], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["", "", "def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch table calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fl\"", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "help", "=", "'AMR ID list file'", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "'+'", ",", "help", "=", "'AMR IDs (at least one)'", ")", "\n", "parser", ".", "add_argument", "(", "\"-p\"", ",", "nargs", "=", "'*'", ",", "help", "=", "\"User list (can be none)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fd\"", ",", "default", "=", "isi_dir_pre", ",", "help", "=", "\"AMR File directory. Default=location on isi machine\"", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.build_arg_parser2": [[167, 182], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch table calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"--fl\"", ",", "dest", "=", "\"fl\"", ",", "type", "=", "\"string\"", ",", "help", "=", "'AMR ID list file'", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "action", "=", "\"callback\"", ",", "callback", "=", "cb", ",", "help", "=", "\"AMR IDs (at least one)\"", ")", "\n", "parser", ".", "add_option", "(", "\"-p\"", ",", "dest", "=", "\"p\"", ",", "type", "=", "\"string\"", ",", "action", "=", "\"callback\"", ",", "callback", "=", "cb", ",", "help", "=", "\"User list\"", ")", "\n", "parser", ".", "add_option", "(", "\"--fd\"", ",", "dest", "=", "\"fd\"", ",", "type", "=", "\"string\"", ",", "help", "=", "\"file directory\"", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "fd", "=", "isi_dir_pre", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.cb": [[184, 199], ["getattr", "setattr", "arguments.extend", "arguments.append", "getattr", "len"], "function", ["None"], ["", "def", "cb", "(", "option", ",", "value", ",", "parser", ")", ":", "\n", "    ", "\"\"\"\n    Callback function to handle variable number of arguments in optparse\n\n    \"\"\"", "\n", "arguments", "=", "[", "value", "]", "\n", "for", "arg", "in", "parser", ".", "rargs", ":", "\n", "        ", "if", "arg", "[", "0", "]", "!=", "\"-\"", ":", "\n", "            ", "arguments", ".", "append", "(", "arg", ")", "\n", "", "else", ":", "\n", "            ", "del", "parser", ".", "rargs", "[", ":", "len", "(", "arguments", ")", "]", "\n", "break", "\n", "", "", "if", "getattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ")", ":", "\n", "        ", "arguments", ".", "extend", "(", "getattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ")", ")", "\n", "", "setattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ",", "arguments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.check_args": [[201, 259], ["os.path.exists", "print", "args.fl.readline", "args.fl.readline.strip().split", "smatch-table.get_names", "len", "print", "len", "print", "get_names.index", "get_names.pop", "get_names.append", "enumerate", "print", "len", "print", "len", "len", "print", "args.fl.readline.strip", "print", "get_names.pop", "os.path.exists", "print", "pop_name.append"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.readline", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.get_names", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "check_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Parse arguments and check if the arguments are valid\n\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "fd", ")", ":", "\n", "        ", "print", "(", "\"Not a valid path\"", ",", "args", ".", "fd", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "args", ".", "fl", "is", "not", "None", ":", "\n", "# we already ensure the file can be opened and opened the file", "\n", "        ", "file_line", "=", "args", ".", "fl", ".", "readline", "(", ")", "\n", "amr_ids", "=", "file_line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "", "elif", "args", ".", "f", "is", "None", ":", "\n", "        ", "print", "(", "\"No AMR ID was given\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "else", ":", "\n", "        ", "amr_ids", "=", "args", ".", "f", "\n", "", "names", "=", "[", "]", "\n", "check_name", "=", "True", "\n", "if", "args", ".", "p", "is", "None", ":", "\n", "        ", "names", "=", "get_names", "(", "args", ".", "fd", ",", "amr_ids", ")", "\n", "# no need to check names", "\n", "check_name", "=", "False", "\n", "if", "len", "(", "names", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"Cannot find any user who tagged these AMR\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "else", ":", "\n", "            ", "names", "=", "args", ".", "p", "\n", "", "", "if", "len", "(", "names", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"No user was given\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "len", "(", "names", ")", "==", "1", ":", "\n", "        ", "print", "(", "\"Only one user is given. Smatch calculation requires at least two users.\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "\"consensus\"", "in", "names", ":", "\n", "        ", "con_index", "=", "names", ".", "index", "(", "\"consensus\"", ")", "\n", "names", ".", "pop", "(", "con_index", ")", "\n", "names", ".", "append", "(", "\"consensus\"", ")", "\n", "# check if all the AMR_id and user combinations are valid", "\n", "", "if", "check_name", ":", "\n", "        ", "pop_name", "=", "[", "]", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "            ", "for", "amr", "in", "amr_ids", ":", "\n", "                ", "amr_path", "=", "args", ".", "fd", "+", "name", "+", "\"/\"", "+", "amr", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "amr_path", ")", ":", "\n", "                    ", "print", "(", "\"User\"", ",", "name", ",", "\"fails to tag AMR\"", ",", "amr", ",", "file", "=", "ERROR_LOG", ")", "\n", "pop_name", ".", "append", "(", "i", ")", "\n", "break", "\n", "", "", "", "if", "len", "(", "pop_name", ")", "!=", "0", ":", "\n", "            ", "pop_num", "=", "0", "\n", "for", "p", "in", "pop_name", ":", "\n", "                ", "print", "(", "\"Deleting user\"", ",", "names", "[", "p", "-", "pop_num", "]", ",", "\"from the name list\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "names", ".", "pop", "(", "p", "-", "pop_num", ")", "\n", "pop_num", "+=", "1", "\n", "", "", "if", "len", "(", "names", ")", "<", "2", ":", "\n", "            ", "print", "(", "\"Not enough users to evaluate. Smatch requires >2 users who tag all the AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "\"\"", ",", "\"\"", ",", "False", "\n", "", "", "return", "amr_ids", ",", "names", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.main": [[261, 298], ["smatch-table.check_args", "len", "range", "table[].append", "range", "range", "range", "smatch-table.pprint_table", "table.append", "table[].append", "table[].append", "range", "range", "time.clock", "table[].append", "time.clock", "table[].append", "smatch-table.compute_files"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.check_args", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.pprint_table", "home.repos.pwc.inspect_result.jcyk_gtos.smatch.smatch-table.compute_files"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "global", "verbose", "\n", "(", "ids", ",", "names", ",", "result", ")", "=", "check_args", "(", "arguments", ")", "\n", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "not", "result", ":", "\n", "        ", "return", "0", "\n", "", "acc_time", "=", "0", "\n", "len_name", "=", "len", "(", "names", ")", "\n", "table", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "        ", "table", ".", "append", "(", "[", "]", ")", "\n", "", "table", "[", "0", "]", ".", "append", "(", "\"\"", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "        ", "table", "[", "0", "]", ".", "append", "(", "names", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "        ", "table", "[", "i", "+", "1", "]", ".", "append", "(", "names", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "start", "=", "time", ".", "clock", "(", ")", "\n", "table", "[", "i", "+", "1", "]", ".", "append", "(", "compute_files", "(", "names", "[", "i", "]", ",", "names", "[", "j", "]", ",", "ids", ",", "args", ".", "fd", ",", "args", ".", "r", ")", ")", "\n", "end", "=", "time", ".", "clock", "(", ")", "\n", "if", "table", "[", "i", "+", "1", "]", "[", "-", "1", "]", "!=", "-", "1.0", ":", "\n", "                    ", "acc_time", "+=", "end", "-", "start", "\n", "", "", "else", ":", "\n", "                ", "table", "[", "i", "+", "1", "]", ".", "append", "(", "\"\"", ")", "\n", "# check table", "\n", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "if", "table", "[", "i", "]", "[", "j", "]", "!=", "table", "[", "j", "]", "[", "i", "]", ":", "\n", "                    ", "if", "table", "[", "i", "]", "[", "j", "]", ">", "table", "[", "j", "]", "[", "i", "]", ":", "\n", "                        ", "table", "[", "j", "]", "[", "i", "]", "=", "table", "[", "i", "]", "[", "j", "]", "\n", "", "else", ":", "\n", "                        ", "table", "[", "i", "]", "[", "j", "]", "=", "table", "[", "j", "]", "[", "i", "]", "\n", "", "", "", "", "", "pprint_table", "(", "table", ")", "\n", "return", "acc_time", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.__init__": [[38, 70], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "node_list", "=", "None", ",", "node_value_list", "=", "None", ",", "relation_list", "=", "None", ",", "attribute_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n", "                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.rename_node": [[71, 87], ["range", "enumerate", "len", "enumerate", "str"], "methods", ["None"], ["", "", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "node_relations", "in", "self", ".", "relations", ":", "\n", "            ", "for", "i", ",", "l", "in", "enumerate", "(", "node_relations", ")", ":", "\n", "                ", "node_relations", "[", "i", "]", "[", "1", "]", "=", "node_map_dict", "[", "l", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples": [[88, 110], ["range", "len", "instance_triple.append", "relation_triple.append", "attribute_triple.append"], "methods", ["None"], ["", "", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in three lists.\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        attribute triple: relation of attributes, e.g. polarity(w, - )\n        and relation triple, e.g. arg0 (w, b)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# l[0] is relation name", "\n", "# l[1] is the other node this node has relation with", "\n", "for", "l", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "# l[0] is the attribute name", "\n", "# l[1] is the attribute value", "\n", "", "for", "l", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_triples2": [[112, 137], ["range", "len", "instance_triple.append", "relation_triple.append", "relation_triple.append"], "methods", ["None"], ["", "def", "get_triples2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in two lists:\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        relation_triple: a triple representing all relations. E.g arg0 (w, b) or E.g. polarity(w, - )\n        Note that we do not differentiate between attribute triple and relation triple. Both are considered as relation\n        triples.\n        All triples are represented by (triple_type, argument 1 of the triple, argument 2 of the triple)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "# an instance triple is instance(node name, node value).", "\n", "# For example, instance(b, boy).", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# l[0] is relation name", "\n", "# l[1] is the other node this node has relation with", "\n", "for", "l", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "# l[0] is the attribute name", "\n", "# l[1] is the attribute value", "\n", "", "for", "l", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "", "", "return", "instance_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.__str__": [[139, 154], ["range", "len", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "relation", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "lines", ".", "append", "(", "\"Node \"", "+", "relation", "[", "1", "]", "+", "\" via \"", "+", "relation", "[", "0", "]", ")", "\n", "", "for", "attribute", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "attribute", "[", "0", "]", "+", "\" value \"", "+", "attribute", "[", "1", "]", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.__repr__": [[155, 157], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.__str__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.output_amr": [[158, 164], ["print", "amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.__str__"], ["", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", "(", "self", ".", "__str__", "(", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.get_amr_line": [[165, 191], ["line.strip.strip.strip", "line.strip.strip.strip().startswith", "cur_amr.append", "line.strip.strip.strip", "line.strip.strip.strip"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "@", "staticmethod", "\n", "def", "get_amr_line", "(", "input_f", ")", ":", "\n", "        ", "\"\"\"\n        Read the file containing AMRs. AMRs are separated by a blank line.\n        Each call of get_amr_line() returns the next available AMR (in one-line form).\n        Note: this function does not verify if the AMR is valid\n\n        \"\"\"", "\n", "cur_amr", "=", "[", "]", "\n", "has_content", "=", "False", "\n", "for", "line", "in", "input_f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                ", "if", "not", "has_content", ":", "\n", "# empty lines before current AMR", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "# end of current AMR", "\n", "                    ", "break", "\n", "", "", "if", "line", ".", "strip", "(", ")", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "# ignore the comment line (starting with \"#\") in the AMR file", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "has_content", "=", "True", "\n", "cur_amr", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "cur_amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.smatch.amr.AMR.parse_AMR_line": [[192, 429], ["set", "collections.defaultdict", "collections.defaultdict", "enumerate", "attribute_list[].append", "amr.AMR", "line.strip", "relation_list.append", "attribute_list.append", "r.endswith", "node_relation_dict[].append", "print", "node_value_list.append", "node_relation_dict[].append", "node_relation_dict[].append", "cur_charseq.append", "cur_charseq.append", "node_rel_list.append", "cur_charseq.append", "node_attr_list.append", "print", "cur_charseq.append", "node_rel_list.append", "node_attr_list.append", "temp_attr_value.split", "parts[].strip", "parts[].strip", "cur_charseq.append", "stack.append", "node_name_list.append", "print", "stack.pop", "cur_charseq.append", "len", "print", "len", "print", "amr.AMR.parse_AMR_line.update_triple"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ")", ":", "\n", "        ", "\"\"\"\n        Parse a AMR from line representation to an AMR object.\n        This parsing algorithm scans the line once and process each character, in a shift-reduce style.\n\n        \"\"\"", "\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n", "# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n", "# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "\n", "exceptions", "=", "set", "(", "[", "\"prep-on-behalf-of\"", ",", "\"prep-out-of\"", ",", "\"consist-of\"", "]", ")", "\n", "def", "update_triple", "(", "node_relation_dict", ",", "triple", ")", ":", "\n", "# we detect a relation (r) between u and v, with direction u to v.", "\n", "# in most cases, if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n", "# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "# but note some exceptions like \"prep-on-behalf-of\" and \"prep-out-of\"", "\n", "# also note relation \"mod\" is the reverse of \"domain\"", "\n", "            ", "u", ",", "r", ",", "v", "=", "triple", "\n", "if", "r", ".", "endswith", "(", "\"-of\"", ")", "and", "not", "r", "in", "exceptions", ":", "\n", "                ", "node_relation_dict", "[", "v", "]", ".", "append", "(", "(", "r", "[", ":", "-", "3", "]", ",", "u", ")", ")", "\n", "", "elif", "r", "==", "\"mod\"", ":", "\n", "                ", "node_relation_dict", "[", "v", "]", ".", "append", "(", "(", "\"domain\"", ",", "u", ")", ")", "\n", "", "else", ":", "\n", "                ", "node_relation_dict", "[", "u", "]", ".", "append", "(", "(", "r", ",", "v", ")", ")", "\n", "\n", "", "", "state", "=", "0", "\n", "# node stack for parsing", "\n", "stack", "=", "[", "]", "\n", "# current not-yet-reduced character sequence", "\n", "cur_charseq", "=", "[", "]", "\n", "# key: node name value: node value", "\n", "node_dict", "=", "{", "}", "\n", "# node name list (order: occurrence of the node)", "\n", "node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n", "# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", "(", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n", "", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n", "# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                        ", "print", "(", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict2", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", "(", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n", "node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "2", "]", ",", "cur_relation_name", ",", "node_name", ")", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", "(", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", "(", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n", "# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict2", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "# Last significant symbol is \"/\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# we get \"nation\" here", "\n", "", "", "elif", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# map node name to its value", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# pop from stack, as the current node has been processed", "\n", "", "stack", ".", "pop", "(", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "state", "=", "0", "\n", "", "else", ":", "\n", "# not significant symbols, so we just shift.", "\n", "                ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "#create data structures to initialize an AMR", "\n", "", "", "node_value_list", "=", "[", "]", "\n", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n", "for", "v", "in", "node_name_list", ":", "\n", "            ", "if", "v", "not", "in", "node_dict", ":", "\n", "                ", "print", "(", "\"Error: Node name not found\"", ",", "v", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "                ", "node_value_list", ".", "append", "(", "node_dict", "[", "v", "]", ")", "\n", "# build relation list and attribute list for this node", "\n", "", "node_rel_list", "=", "[", "]", "\n", "node_attr_list", "=", "[", "]", "\n", "if", "v", "in", "node_relation_dict1", ":", "\n", "                ", "for", "v1", "in", "node_relation_dict1", "[", "v", "]", ":", "\n", "                    ", "node_rel_list", ".", "append", "(", "[", "v1", "[", "0", "]", ",", "v1", "[", "1", "]", "]", ")", "\n", "", "", "if", "v", "in", "node_relation_dict2", ":", "\n", "                ", "for", "v2", "in", "node_relation_dict2", "[", "v", "]", ":", "\n", "# if value is in quote, it is a constant value", "\n", "# strip the quote and put it in attribute map", "\n", "                    ", "if", "v2", "[", "1", "]", "[", "0", "]", "==", "\"\\\"\"", "and", "v2", "[", "1", "]", "[", "-", "1", "]", "==", "\"\\\"\"", ":", "\n", "                        ", "assert", "True", "==", "False", "\n", "node_attr_list", ".", "append", "(", "[", "[", "v2", "[", "0", "]", "]", ",", "v2", "[", "1", "]", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "# if value is a node name", "\n", "", "elif", "v2", "[", "1", "]", "in", "node_dict", ":", "\n", "                        ", "node_rel_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                        ", "node_attr_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "# each node has a relation list and attribute list", "\n", "", "", "", "relation_list", ".", "append", "(", "node_rel_list", ")", "\n", "attribute_list", ".", "append", "(", "node_attr_list", ")", "\n", "# add TOP as an attribute. The attribute value is the top node value", "\n", "", "attribute_list", "[", "0", "]", ".", "append", "(", "[", "\"TOP\"", ",", "node_value_list", "[", "0", "]", "]", ")", "\n", "result_amr", "=", "AMR", "(", "node_name_list", ",", "node_value_list", ",", "relation_list", ",", "attribute_list", ")", "\n", "return", "result_amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.url_to_filename": [[33, 49], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode"], ["def", "url_to_filename", "(", "url", ":", "str", ",", "etag", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.filename_to_url": [[51, 73], ["os.path.join", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "def", "filename_to_url", "(", "filename", ":", "str", ",", "cache_dir", ":", "str", "=", "None", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``FileNotFoundError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "DATASET_CACHE", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path": [[75, 101], ["isinstance", "urllib.parse.urlparse", "str", "file.get_from_cache", "os.path.exists", "FileNotFoundError", "ValueError"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ":", "Union", "[", "str", ",", "Path", "]", ",", "cache_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "DATASET_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.split_s3_path": [[103, 114], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ":", "str", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.s3_request": [[116, 133], ["functools.wraps", "func", "int", "FileNotFoundError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ":", "Callable", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ":", "str", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.s3_etag": [[135, 142], ["boto3.resource", "file.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ":", "str", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.s3_get": [[144, 150], ["boto3.resource", "file.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ":", "str", ",", "temp_file", ":", "IO", ")", "->", "None", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.http_get": [[152, 162], ["requests.get", "requests.get.headers.get", "stog.utils.tqdm.Tqdm.tqdm", "requests.get.iter_content", "Tqdm.tqdm.close", "int", "Tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "def", "http_get", "(", "url", ":", "str", ",", "temp_file", ":", "IO", ")", "->", "None", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "Tqdm", ".", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_from_cache": [[165, 220], ["os.makedirs", "url.startswith", "file.url_to_filename", "os.path.join", "file.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file.s3_get", "file.http_get", "open", "shutil.copyfileobj", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.url_to_filename", "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.s3_etag", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.flush", "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.s3_get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.http_get", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "def", "get_from_cache", "(", "url", ":", "str", ",", "cache_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "DATASET_CACHE", "\n", "\n", "", "os", ".", "makedirs", "(", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "            ", "raise", "IOError", "(", "\"HEAD request failed for url {} with status code {}\"", "\n", ".", "format", "(", "url", ",", "response", ".", "status_code", ")", ")", "\n", "", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_file_extension": [[222, 226], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ":", "str", ",", "dot", "=", "True", ",", "lower", ":", "bool", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_spacy_model": [[227, 252], ["disable.append", "disable.append", "disable.append", "spacy.load", "logger.warning", "spacy.cli.download.download", "spacy.load"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "def", "get_spacy_model", "(", "spacy_model_name", ":", "str", ",", "pos_tags", ":", "bool", ",", "parse", ":", "bool", ",", "ner", ":", "bool", ")", "->", "SpacyModelType", ":", "\n", "    ", "\"\"\"\n    In order to avoid loading spacy models a whole bunch of times, we'll save references to them,\n    keyed by the options we used to create the spacy model, so any particular configuration only\n    gets loaded once.\n    \"\"\"", "\n", "\n", "options", "=", "(", "spacy_model_name", ",", "pos_tags", ",", "parse", ",", "ner", ")", "\n", "if", "options", "not", "in", "LOADED_SPACY_MODELS", ":", "\n", "        ", "disable", "=", "[", "'vectors'", ",", "'textcat'", "]", "\n", "if", "not", "pos_tags", ":", "\n", "            ", "disable", ".", "append", "(", "'tagger'", ")", "\n", "", "if", "not", "parse", ":", "\n", "            ", "disable", ".", "append", "(", "'parser'", ")", "\n", "", "if", "not", "ner", ":", "\n", "            ", "disable", ".", "append", "(", "'ner'", ")", "\n", "", "try", ":", "\n", "            ", "spacy_model", "=", "spacy", ".", "load", "(", "spacy_model_name", ",", "disable", "=", "disable", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Spacy models '{spacy_model_name}' not found.  Downloading and installing.\"", ")", "\n", "spacy_download", "(", "spacy_model_name", ")", "\n", "spacy_model", "=", "spacy", ".", "load", "(", "spacy_model_name", ",", "disable", "=", "disable", ")", "\n", "\n", "", "LOADED_SPACY_MODELS", "[", "options", "]", "=", "spacy_model", "\n", "", "return", "LOADED_SPACY_MODELS", "[", "options", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.__init__": [[54, 60], ["os.path.dirname", "os.makedirs", "open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "filename", ":", "str", ",", "terminal", ":", "TextIO", ",", "file_friendly_terminal_output", ":", "bool", ")", "->", "None", ":", "\n", "        ", "self", ".", "terminal", "=", "terminal", "\n", "self", ".", "file_friendly_terminal_output", "=", "file_friendly_terminal_output", "\n", "parent_directory", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "os", ".", "makedirs", "(", "parent_directory", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "log", "=", "open", "(", "filename", ",", "'a'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write": [[61, 70], ["logging.replace_cr_with_newline", "logging.TeeLogger.log.write", "logging.TeeLogger.terminal.write", "logging.TeeLogger.terminal.write"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.replace_cr_with_newline", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "def", "write", "(", "self", ",", "message", ")", ":", "\n", "        ", "cleaned", "=", "replace_cr_with_newline", "(", "message", ")", "\n", "\n", "if", "self", ".", "file_friendly_terminal_output", ":", "\n", "            ", "self", ".", "terminal", ".", "write", "(", "cleaned", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "terminal", ".", "write", "(", "message", ")", "\n", "\n", "", "self", ".", "log", ".", "write", "(", "cleaned", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.flush": [[71, 74], ["logging.TeeLogger.terminal.flush", "logging.TeeLogger.log.flush"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.flush", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.flush"], ["", "def", "flush", "(", "self", ")", ":", "\n", "        ", "self", ".", "terminal", ".", "flush", "(", ")", "\n", "self", ".", "log", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.init_logger": [[8, 27], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_name", "=", "None", ",", "log_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Adopted from OpenNMT-py:\n        https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/utils/logging.py\n    \"\"\"", "\n", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "log_name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.replace_cr_with_newline": [[32, 45], ["message.replace.replace"], "function", ["None"], ["def", "replace_cr_with_newline", "(", "message", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    TQDM and requests use carriage returns to get the training line to update for each batch\n    without adding more lines to the terminal output.  Displaying those in a file won't work\n    correctly, so we'll just make sure that each batch shows up on its one line.\n    :param message: the message to permute\n    :return: the message with carriage returns replaced with newlines\n    \"\"\"", "\n", "if", "'\\r'", "in", "message", ":", "\n", "        ", "message", "=", "message", ".", "replace", "(", "'\\r'", ",", "''", ")", "\n", "if", "not", "message", "or", "message", "[", "-", "1", "]", "!=", "'\\n'", ":", "\n", "            ", "message", "+=", "'\\n'", "\n", "", "", "return", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.checks.ConfigurationError.__init__": [[22, 25], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "message", ")", ":", "\n", "        ", "super", "(", "ConfigurationError", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.checks.ConfigurationError.__str__": [[26, 28], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.checks.log_pytorch_version_info": [[30, 33], ["logger.info"], "function", ["None"], ["", "", "def", "log_pytorch_version_info", "(", ")", ":", "\n", "    ", "import", "torch", "\n", "logger", ".", "info", "(", "\"Pytorch version: %s\"", ",", "torch", ".", "__version__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.checks.check_dimensions_match": [[35, 41], ["checks.ConfigurationError"], "function", ["None"], ["", "def", "check_dimensions_match", "(", "dimension_1", ":", "int", ",", "\n", "dimension_2", ":", "int", ",", "\n", "dim_1_name", ":", "str", ",", "\n", "dim_2_name", ":", "str", ")", "->", "None", ":", "\n", "    ", "if", "dimension_1", "!=", "dimension_2", ":", "\n", "        ", "raise", "ConfigurationError", "(", "f\"{dim_1_name} must match {dim_2_name}, but got {dimension_1} \"", "\n", "f\"and {dimension_2} instead\"", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.checks.check_for_gpu": [[44, 47], ["checks.ConfigurationError", "torch.cuda.device_count"], "function", ["None"], ["", "", "def", "check_for_gpu", "(", "device_id", ":", "int", ")", ":", "\n", "    ", "if", "device_id", "is", "not", "None", "and", "device_id", ">=", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Experiment specified a GPU but none is available;\"", "\n", "\" if you want to run on CPU use the override\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.FromParams.from_params": [[201, 259], ["logger.info", "Registrable._registry.get", "typing.cast", "params.pop_choice", "subclass.from_params", "cls", "from_params.takes_arg", "from_params.create_kwargs", "getattr", "typing.cast.list_available", "extras.items", "from_params.takes_arg"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.takes_arg", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.create_kwargs", "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.list_available", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.takes_arg"], ["@", "classmethod", "\n", "def", "from_params", "(", "cls", ":", "Type", "[", "T", "]", ",", "params", ":", "Params", ",", "**", "extras", ")", "->", "T", ":", "\n", "        ", "\"\"\"\n        This is the automatic implementation of `from_params`. Any class that subclasses `FromParams`\n        (or `Registrable`, which itself subclasses `FromParams`) gets this implementation for free.\n        If you want your class to be instantiated from params in the \"obvious\" way -- pop off parameters\n        and hand them to your constructor with the same names -- this provides that functionality.\n\n        If you need more complex logic in your from `from_params` method, you'll have to implement\n        your own method that overrides this one.\n        \"\"\"", "\n", "# pylint: disable=protected-access", "\n", "from", "stog", ".", "utils", ".", "registrable", "import", "Registrable", "# import here to avoid circular imports", "\n", "\n", "logger", ".", "info", "(", "f\"instantiating class {cls} from params {getattr(params, 'params', params)} \"", "\n", "f\"and extras {extras}\"", ")", "\n", "\n", "if", "params", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "registered_subclasses", "=", "Registrable", ".", "_registry", ".", "get", "(", "cls", ")", "\n", "\n", "if", "registered_subclasses", "is", "not", "None", ":", "\n", "# We know ``cls`` inherits from Registrable, so we'll use a cast to make mypy happy.", "\n", "# We have to use a disable to make pylint happy.", "\n", "# pylint: disable=no-member", "\n", "            ", "as_registrable", "=", "cast", "(", "Type", "[", "Registrable", "]", ",", "cls", ")", "\n", "default_to_first_choice", "=", "as_registrable", ".", "default_implementation", "is", "not", "None", "\n", "choice", "=", "params", ".", "pop_choice", "(", "\"type\"", ",", "\n", "choices", "=", "as_registrable", ".", "list_available", "(", ")", ",", "\n", "default_to_first_choice", "=", "default_to_first_choice", ")", "\n", "subclass", "=", "registered_subclasses", "[", "choice", "]", "\n", "\n", "# We want to call subclass.from_params. It's possible that it's just the \"free\"", "\n", "# implementation here, in which case it accepts `**extras` and we are not able", "\n", "# to make any assumptions about what extra parameters it needs.", "\n", "#", "\n", "# It's also possible that it has a custom `from_params` method. In that case it", "\n", "# won't accept any **extra parameters and we'll need to filter them out.", "\n", "if", "not", "takes_arg", "(", "subclass", ".", "from_params", ",", "'extras'", ")", ":", "\n", "# Necessarily subclass.from_params is a custom implementation, so we need to", "\n", "# pass it only the args it's expecting.", "\n", "                ", "extras", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "extras", ".", "items", "(", ")", "if", "takes_arg", "(", "subclass", ".", "from_params", ",", "k", ")", "}", "\n", "\n", "", "return", "subclass", ".", "from_params", "(", "params", "=", "params", ",", "**", "extras", ")", "\n", "", "else", ":", "\n", "# This is not a base class, so convert our params and extras into a dict of kwargs.", "\n", "\n", "            ", "if", "cls", ".", "__init__", "==", "object", ".", "__init__", ":", "\n", "# This class does not have an explicit constructor, so don't give it any kwargs.", "\n", "# Without this logic, create_kwargs will look at object.__init__ and see that", "\n", "# it takes *args and **kwargs and look for those.", "\n", "                ", "kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "# This class has a constructor, so create kwargs for it.", "\n", "                ", "kwargs", "=", "create_kwargs", "(", "cls", ",", "params", ",", "**", "extras", ")", "\n", "\n", "", "return", "cls", "(", "**", "kwargs", ")", "# type: ignore", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.takes_arg": [[58, 72], ["inspect.isclass", "inspect.signature", "inspect.ismethod", "inspect.isfunction", "inspect.signature", "stog.utils.checks.ConfigurationError"], "function", ["None"], ["def", "takes_arg", "(", "obj", ",", "arg", ":", "str", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Checks whether the provided obj takes a certain arg.\n    If it's a class, we're really checking whether its constructor does.\n    If it's a function or method, we're checking the object itself.\n    Otherwise, we raise an error.\n    \"\"\"", "\n", "if", "inspect", ".", "isclass", "(", "obj", ")", ":", "\n", "        ", "signature", "=", "inspect", ".", "signature", "(", "obj", ".", "__init__", ")", "\n", "", "elif", "inspect", ".", "ismethod", "(", "obj", ")", "or", "inspect", ".", "isfunction", "(", "obj", ")", ":", "\n", "        ", "signature", "=", "inspect", ".", "signature", "(", "obj", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ConfigurationError", "(", "f\"object {obj} is not callable\"", ")", "\n", "", "return", "arg", "in", "signature", ".", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.remove_optional": [[73, 85], ["getattr", "getattr", "len", "type"], "function", ["None"], ["", "def", "remove_optional", "(", "annotation", ":", "type", ")", ":", "\n", "    ", "\"\"\"\n    Optional[X] annotations are actually represented as Union[X, NoneType].\n    For our purposes, the \"Optional\" part is not interesting, so here we\n    throw it away.\n    \"\"\"", "\n", "origin", "=", "getattr", "(", "annotation", ",", "'__origin__'", ",", "None", ")", "\n", "args", "=", "getattr", "(", "annotation", ",", "'__args__'", ",", "(", ")", ")", "\n", "if", "origin", "==", "Union", "and", "len", "(", "args", ")", "==", "2", "and", "args", "[", "1", "]", "==", "type", "(", "None", ")", ":", "\n", "        ", "return", "args", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.create_kwargs": [[86, 194], ["inspect.signature", "inspect.signature.parameters.items", "params.assert_empty", "from_params.remove_optional", "getattr", "getattr", "hasattr", "params.pop", "from_params.takes_arg", "isinstance", "remove_optional.from_params", "stog.utils.checks.ConfigurationError", "params.pop", "params.pop", "remove_optional.by_name", "params.pop_int", "params.pop_int", "extras.items", "from_params.takes_arg", "params.pop_bool", "params.pop_bool", "params.pop_float", "params.pop_float", "hasattr", "params.pop().items", "len", "value_cls.from_params", "params.pop", "params.pop", "params.pop", "stog.utils.params.Params"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.remove_optional", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.takes_arg", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.by_name", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.from_params.takes_arg", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params"], ["", "", "def", "create_kwargs", "(", "cls", ":", "Type", "[", "T", "]", ",", "params", ":", "Params", ",", "**", "extras", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Given some class, a `Params` object, and potentially other keyword arguments,\n    create a dict of keyword args suitable for passing to the class's constructor.\n\n    The function does this by finding the class's constructor, matching the constructor\n    arguments to entries in the `params` object, and instantiating values for the parameters\n    using the type annotation and possibly a from_params method.\n\n    Any values that are provided in the `extras` will just be used as is.\n    For instance, you might provide an existing `Vocabulary` this way.\n    \"\"\"", "\n", "# Get the signature of the constructor.", "\n", "signature", "=", "inspect", ".", "signature", "(", "cls", ".", "__init__", ")", "\n", "kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "\n", "# Iterate over all the constructor parameters and their annotations.", "\n", "for", "name", ",", "param", "in", "signature", ".", "parameters", ".", "items", "(", ")", ":", "\n", "# Skip \"self\". You're not *required* to call the first parameter \"self\",", "\n", "# so in theory this logic is fragile, but if you don't call the self parameter", "\n", "# \"self\" you kind of deserve what happens.", "\n", "        ", "if", "name", "==", "\"self\"", ":", "\n", "            ", "continue", "\n", "\n", "# If the annotation is a compound type like typing.Dict[str, int],", "\n", "# it will have an __origin__ field indicating `typing.Dict`", "\n", "# and an __args__ field indicating `(str, int)`. We capture both.", "\n", "", "annotation", "=", "remove_optional", "(", "param", ".", "annotation", ")", "\n", "origin", "=", "getattr", "(", "annotation", ",", "'__origin__'", ",", "None", ")", "\n", "args", "=", "getattr", "(", "annotation", ",", "'__args__'", ",", "[", "]", ")", "\n", "\n", "# The parameter is optional if its default value is not the \"no default\" sentinel.", "\n", "default", "=", "param", ".", "default", "\n", "optional", "=", "default", "!=", "_NO_DEFAULT", "\n", "\n", "# Some constructors expect extra non-parameter items, e.g. vocab: Vocabulary.", "\n", "# We check the provided `extras` for these and just use them if they exist.", "\n", "if", "name", "in", "extras", ":", "\n", "            ", "kwargs", "[", "name", "]", "=", "extras", "[", "name", "]", "\n", "\n", "# The next case is when the parameter type is itself constructible from_params.", "\n", "", "elif", "hasattr", "(", "annotation", ",", "'from_params'", ")", ":", "\n", "            ", "if", "name", "in", "params", ":", "\n", "# Our params have an entry for this, so we use that.", "\n", "                ", "subparams", "=", "params", ".", "pop", "(", "name", ")", "\n", "\n", "if", "takes_arg", "(", "annotation", ".", "from_params", ",", "'extras'", ")", ":", "\n", "# If annotation.params accepts **extras, we need to pass them all along.", "\n", "# For example, `BasicTextFieldEmbedder.from_params` requires a Vocabulary", "\n", "# object, but `TextFieldEmbedder.from_params` does not.", "\n", "                    ", "subextras", "=", "extras", "\n", "", "else", ":", "\n", "# Otherwise, only supply the ones that are actual args; any additional ones", "\n", "# will cause a TypeError.", "\n", "                    ", "subextras", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "extras", ".", "items", "(", ")", "if", "takes_arg", "(", "annotation", ".", "from_params", ",", "k", ")", "}", "\n", "\n", "# In some cases we allow a string instead of a param dict, so", "\n", "# we need to handle that case separately.", "\n", "", "if", "isinstance", "(", "subparams", ",", "str", ")", ":", "\n", "                    ", "kwargs", "[", "name", "]", "=", "annotation", ".", "by_name", "(", "subparams", ")", "(", ")", "\n", "", "else", ":", "\n", "                    ", "kwargs", "[", "name", "]", "=", "annotation", ".", "from_params", "(", "params", "=", "subparams", ",", "**", "subextras", ")", "\n", "", "", "elif", "not", "optional", ":", "\n", "# Not optional and not supplied, that's an error!", "\n", "                ", "raise", "ConfigurationError", "(", "f\"expected key {name} for {cls.__name__}\"", ")", "\n", "", "else", ":", "\n", "                ", "kwargs", "[", "name", "]", "=", "default", "\n", "\n", "# If the parameter type is a Python primitive, just pop it off", "\n", "# using the correct casting pop_xyz operation.", "\n", "", "", "elif", "annotation", "==", "str", ":", "\n", "            ", "kwargs", "[", "name", "]", "=", "(", "params", ".", "pop", "(", "name", ",", "default", ")", "\n", "if", "optional", "\n", "else", "params", ".", "pop", "(", "name", ")", ")", "\n", "", "elif", "annotation", "==", "int", ":", "\n", "            ", "kwargs", "[", "name", "]", "=", "(", "params", ".", "pop_int", "(", "name", ",", "default", ")", "\n", "if", "optional", "\n", "else", "params", ".", "pop_int", "(", "name", ")", ")", "\n", "", "elif", "annotation", "==", "bool", ":", "\n", "            ", "kwargs", "[", "name", "]", "=", "(", "params", ".", "pop_bool", "(", "name", ",", "default", ")", "\n", "if", "optional", "\n", "else", "params", ".", "pop_bool", "(", "name", ")", ")", "\n", "", "elif", "annotation", "==", "float", ":", "\n", "            ", "kwargs", "[", "name", "]", "=", "(", "params", ".", "pop_float", "(", "name", ",", "default", ")", "\n", "if", "optional", "\n", "else", "params", ".", "pop_float", "(", "name", ")", ")", "\n", "\n", "# This is special logic for handling types like Dict[str, TokenIndexer], which it creates by", "\n", "# instantiating each value from_params and returning the resulting dict.", "\n", "", "elif", "origin", "in", "(", "Dict", ",", "dict", ")", "and", "len", "(", "args", ")", "==", "2", "and", "hasattr", "(", "args", "[", "-", "1", "]", ",", "'from_params'", ")", ":", "\n", "            ", "value_cls", "=", "annotation", ".", "__args__", "[", "-", "1", "]", "\n", "\n", "value_dict", "=", "{", "}", "\n", "\n", "for", "key", ",", "value_params", "in", "params", ".", "pop", "(", "name", ",", "Params", "(", "{", "}", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "value_dict", "[", "key", "]", "=", "value_cls", ".", "from_params", "(", "params", "=", "value_params", ",", "**", "extras", ")", "\n", "\n", "", "kwargs", "[", "name", "]", "=", "value_dict", "\n", "\n", "", "else", ":", "\n", "# Pass it on as is and hope for the best.   \u00af\\_(\u30c4)_/\u00af", "\n", "            ", "if", "optional", ":", "\n", "                ", "kwargs", "[", "name", "]", "=", "params", ".", "pop", "(", "name", ",", "default", ")", "\n", "", "else", ":", "\n", "                ", "kwargs", "[", "name", "]", "=", "params", ".", "pop", "(", "name", ")", "\n", "\n", "", "", "", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__init__": [[17, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__eq__": [[20, 50], ["params.Params.as_flat_dict", "other.as_flat_dict", "params.Params.items", "isinstance", "logger.info", "len", "len", "logger.info", "logger.info", "type", "type", "len", "len", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.as_flat_dict", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.as_flat_dict", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "Params", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'The params you compare is not an instance of Params. ({} != {})'", ".", "format", "(", "\n", "type", "(", "self", ")", ",", "type", "(", "other", ")", "\n", ")", ")", "\n", "return", "False", "\n", "\n", "", "this_flat_params", "=", "self", ".", "as_flat_dict", "(", ")", "\n", "other_flat_params", "=", "other", ".", "as_flat_dict", "(", ")", "\n", "\n", "if", "len", "(", "this_flat_params", ")", "!=", "len", "(", "other_flat_params", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'The numbers of parameters are different: {} != {}'", ".", "format", "(", "\n", "len", "(", "this_flat_params", ")", ",", "\n", "len", "(", "other_flat_params", ")", "\n", ")", ")", "\n", "return", "False", "\n", "\n", "", "same", "=", "True", "\n", "for", "k", ",", "v", "in", "this_flat_params", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "==", "'environment.recover'", ":", "\n", "                ", "continue", "\n", "", "if", "k", "not", "in", "other_flat_params", ":", "\n", "                ", "logger", ".", "info", "(", "'The parameter \"{}\" is not specified.'", ".", "format", "(", "k", ")", ")", "\n", "same", "=", "False", "\n", "", "elif", "other_flat_params", "[", "k", "]", "!=", "v", ":", "\n", "                ", "logger", ".", "info", "(", "'The values of \"{}\" not not the same: {} != {}'", ".", "format", "(", "\n", "k", ",", "v", ",", "other_flat_params", "[", "k", "]", "\n", ")", ")", "\n", "same", "=", "False", "\n", "", "", "return", "same", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__getitem__": [[51, 56], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "item", "in", "self", ".", "params", ":", "\n", "            ", "return", "self", ".", "params", "[", "item", "]", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__setitem__": [[57, 59], ["None"], "methods", ["None"], ["", "", "def", "__setitem__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "self", ".", "params", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__delitem__": [[60, 62], ["None"], "methods", ["None"], ["", "def", "__delitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "del", "self", ".", "params", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__iter__": [[63, 65], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__len__": [[66, 68], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items": [[69, 71], ["params.Params.params.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.get": [[72, 74], ["params.Params.params.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "get", "(", "self", ",", "key", ",", "default", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "get", "(", "key", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.as_flat_dict": [[75, 92], ["params.Params.as_flat_dict.recurse"], "methods", ["None"], ["", "def", "as_flat_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the parameters of a flat dictionary from keys to values.\n        Nested structure is collapsed with periods.\n        \"\"\"", "\n", "flat_params", "=", "{", "}", "\n", "\n", "def", "recurse", "(", "parameters", ",", "path", ")", ":", "\n", "            ", "for", "key", ",", "value", "in", "parameters", ".", "items", "(", ")", ":", "\n", "                ", "newpath", "=", "path", "+", "[", "key", "]", "\n", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                    ", "recurse", "(", "value", ",", "newpath", ")", "\n", "", "else", ":", "\n", "                    ", "flat_params", "[", "'.'", ".", "join", "(", "newpath", ")", "]", "=", "value", "\n", "\n", "", "", "", "recurse", "(", "self", ".", "params", ",", "[", "]", ")", "\n", "return", "flat_params", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.to_file": [[93, 96], ["open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "def", "to_file", "(", "self", ",", "output_json_file", ")", ":", "\n", "        ", "with", "open", "(", "output_json_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "'\\t'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.from_file": [[97, 110], ["params_file_list.split.split.split", "cls", "open", "params_file.endswith", "stog.algorithms.dict_merge.dict_merge", "params_file.endswith", "yaml.load", "json.load"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.dict_merge.dict_merge", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "", "@", "classmethod", "\n", "def", "from_file", "(", "cls", ",", "params_file_list", ")", ":", "\n", "        ", "params_file_list", "=", "params_file_list", ".", "split", "(", "\",\"", ")", "\n", "params_dict", "=", "{", "}", "\n", "for", "params_file", "in", "params_file_list", ":", "\n", "            ", "with", "open", "(", "params_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "if", "params_file", ".", "endswith", "(", "'.yaml'", ")", ":", "\n", "                    ", "dict_merge", ".", "dict_merge", "(", "params_dict", ",", "yaml", ".", "load", "(", "f", ")", ")", "\n", "", "elif", "params_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "                    ", "params_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "", "", "return", "cls", "(", "params_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__repr__": [[111, 113], ["json.dumps"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "json", ".", "dumps", "(", "self", ".", "params", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.duplicate": [[114, 120], ["params.Params", "copy.deepcopy"], "methods", ["None"], ["", "def", "duplicate", "(", "self", ")", "->", "'Params'", ":", "\n", "        ", "\"\"\"\n        Uses ``copy.deepcopy()`` to create a duplicate (but fully distinct)\n        copy of these Params.\n        \"\"\"", "\n", "return", "Params", "(", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.remove_pretrained_embedding_params": [[121, 129], ["params.remove_pretrained_embedding_params.recurse"], "function", ["None"], ["", "", "def", "remove_pretrained_embedding_params", "(", "params", ")", ":", "\n", "    ", "def", "recurse", "(", "parameters", ",", "key", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "k", ":", "\n", "                ", "parameters", "[", "key", "]", "=", "None", "\n", "", "elif", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                ", "recurse", "(", "v", ",", "key", ")", "\n", "", "", "", "recurse", "(", "params", ",", "'pretrained_file'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.batch_tensor_dicts": [[21, 45], ["collections.defaultdict", "key_to_tensors.items", "tensor_dict.items", "torch.stack", "key_to_tensors[].append", "all", "batched_tensor.squeeze.squeeze", "tensor.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["def", "batch_tensor_dicts", "(", "tensor_dicts", ":", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "remove_trailing_dimension", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Takes a list of tensor dictionaries, where each dictionary is assumed to have matching keys,\n    and returns a single dictionary with all tensors with the same key batched together.\n    Parameters\n    ----------\n    tensor_dicts : ``List[Dict[str, torch.Tensor]]``\n        The list of tensor dictionaries to batch.\n    remove_trailing_dimension : ``bool``\n        If ``True``, we will check for a trailing dimension of size 1 on the tensors that are being\n        batched, and remove it if we find it.\n    \"\"\"", "\n", "key_to_tensors", ":", "Dict", "[", "str", ",", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "tensor_dict", "in", "tensor_dicts", ":", "\n", "        ", "for", "key", ",", "tensor", "in", "tensor_dict", ".", "items", "(", ")", ":", "\n", "            ", "key_to_tensors", "[", "key", "]", ".", "append", "(", "tensor", ")", "\n", "", "", "batched_tensors", "=", "{", "}", "\n", "for", "key", ",", "tensor_list", "in", "key_to_tensors", ".", "items", "(", ")", ":", "\n", "        ", "batched_tensor", "=", "torch", ".", "stack", "(", "tensor_list", ")", "\n", "if", "remove_trailing_dimension", "and", "all", "(", "tensor", ".", "size", "(", "-", "1", ")", "==", "1", "for", "tensor", "in", "tensor_list", ")", ":", "\n", "            ", "batched_tensor", "=", "batched_tensor", ".", "squeeze", "(", "-", "1", ")", "\n", "", "batched_tensors", "[", "key", "]", "=", "batched_tensor", "\n", "", "return", "batched_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_lengths_from_binary_sequence_mask": [[47, 62], ["mask.long().sum", "mask.long"], "function", ["None"], ["", "def", "get_lengths_from_binary_sequence_mask", "(", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Compute sequence lengths for each batch element in a tensor using a\n    binary mask.\n    Parameters\n    ----------\n    mask : torch.Tensor, required.\n        A 2D binary mask of shape (batch_size, sequence_length) to\n        calculate the per-batch sequence lengths from.\n    Returns\n    -------\n    A torch.LongTensor of shape (batch_size,) representing the lengths\n    of the sequences in the batch.\n    \"\"\"", "\n", "return", "mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_mask_from_sequence_lengths": [[64, 78], ["sequence_lengths.new_ones", "sequence_lengths.new_ones.cumsum", "sequence_lengths.size", "sequence_lengths.unsqueeze"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "get_mask_from_sequence_lengths", "(", "sequence_lengths", ":", "torch", ".", "Tensor", ",", "max_length", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given a variable of shape ``(batch_size,)`` that represents the sequence lengths of each batch\n    element, this function returns a ``(batch_size, max_length)`` mask variable.  For example, if\n    our input was ``[2, 2, 3]``, with a ``max_length`` of 4, we'd return\n    ``[[1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]]``.\n    We require ``max_length`` here instead of just computing it from the input ``sequence_lengths``\n    because it lets us avoid finding the max, then copying that value from the GPU to the CPU so\n    that we can use it to construct a new tensor.\n    \"\"\"", "\n", "# (batch_size, max_length)", "\n", "ones", "=", "sequence_lengths", ".", "new_ones", "(", "sequence_lengths", ".", "size", "(", "0", ")", ",", "max_length", ")", "\n", "range_tensor", "=", "ones", ".", "cumsum", "(", "dim", "=", "1", ")", "\n", "return", "(", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", ">=", "range_tensor", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.sort_batch_by_length": [[80, 116], ["sequence_lengths.sort", "tensor.index_select", "sequence_lengths.new_tensor", "permutation_index.sort", "sequence_lengths.new_tensor.index_select", "stog.utils.checks.ConfigurationError", "torch.arange", "isinstance", "isinstance", "len"], "function", ["None"], ["", "def", "sort_batch_by_length", "(", "tensor", ":", "torch", ".", "Tensor", ",", "sequence_lengths", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Sort a batch first tensor by some specified lengths.\n    Parameters\n    ----------\n    tensor : torch.FloatTensor, required.\n        A batch first Pytorch tensor.\n    sequence_lengths : torch.LongTensor, required.\n        A tensor representing the lengths of some dimension of the tensor which\n        we want to sort by.\n    Returns\n    -------\n    sorted_tensor : torch.FloatTensor\n        The original tensor sorted along the batch dimension with respect to sequence_lengths.\n    sorted_sequence_lengths : torch.LongTensor\n        The original sequence_lengths sorted by decreasing size.\n    restoration_indices : torch.LongTensor\n        Indices into the sorted_tensor such that\n        ``sorted_tensor.index_select(0, restoration_indices) == original_tensor``\n    permuation_index : torch.LongTensor\n        The indices used to sort the tensor. This is useful if you want to sort many\n        tensors using the same ordering.\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "or", "not", "isinstance", "(", "sequence_lengths", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Both the tensor and sequence lengths must be torch.Tensors.\"", ")", "\n", "\n", "", "sorted_sequence_lengths", ",", "permutation_index", "=", "sequence_lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "sorted_tensor", "=", "tensor", ".", "index_select", "(", "0", ",", "permutation_index", ")", "\n", "\n", "index_range", "=", "sequence_lengths", ".", "new_tensor", "(", "torch", ".", "arange", "(", "0", ",", "len", "(", "sequence_lengths", ")", ")", ")", "\n", "# This is the equivalent of zipping with index, sorting by the original", "\n", "# sequence lengths and returning the now sorted indices.", "\n", "_", ",", "reverse_mapping", "=", "permutation_index", ".", "sort", "(", "0", ",", "descending", "=", "False", ")", "\n", "restoration_indices", "=", "index_range", ".", "index_select", "(", "0", ",", "reverse_mapping", ")", "\n", "return", "sorted_tensor", ",", "sorted_sequence_lengths", ",", "restoration_indices", ",", "permutation_index", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_final_encoder_states": [[118, 148], ["encoder_outputs.size", "last_word_indices.view().expand", "encoder_outputs.gather", "torch.cat.squeeze", "mask.sum().long", "torch.cat", "last_word_indices.view", "mask.sum"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "get_final_encoder_states", "(", "encoder_outputs", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "bidirectional", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given the output from a ``Seq2SeqEncoder``, with shape ``(batch_size, sequence_length,\n    encoding_dim)``, this method returns the final hidden state for each element of the batch,\n    giving a tensor of shape ``(batch_size, encoding_dim)``.  This is not as simple as\n    ``encoder_outputs[:, -1]``, because the sequences could have different lengths.  We use the\n    mask (which has shape ``(batch_size, sequence_length)``) to find the final state for each batch\n    instance.\n    Additionally, if ``bidirectional`` is ``True``, we will split the final dimension of the\n    ``encoder_outputs`` into two and assume that the first half is for the forward direction of the\n    encoder and the second half is for the backward direction.  We will concatenate the last state\n    for each encoder dimension, giving ``encoder_outputs[:, -1, :encoding_dim/2]`` concated with\n    ``encoder_outputs[:, 0, encoding_dim/2:]``.\n    \"\"\"", "\n", "# These are the indices of the last words in the sequences (i.e. length sans padding - 1).  We", "\n", "# are assuming sequences are right padded.", "\n", "# Shape: (batch_size,)", "\n", "last_word_indices", "=", "mask", ".", "sum", "(", "1", ")", ".", "long", "(", ")", "-", "1", "\n", "batch_size", ",", "_", ",", "encoder_output_dim", "=", "encoder_outputs", ".", "size", "(", ")", "\n", "expanded_indices", "=", "last_word_indices", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "encoder_output_dim", ")", "\n", "# Shape: (batch_size, 1, encoder_output_dim)", "\n", "final_encoder_output", "=", "encoder_outputs", ".", "gather", "(", "1", ",", "expanded_indices", ")", "\n", "final_encoder_output", "=", "final_encoder_output", ".", "squeeze", "(", "1", ")", "# (batch_size, encoder_output_dim)", "\n", "if", "bidirectional", ":", "\n", "        ", "final_forward_output", "=", "final_encoder_output", "[", ":", ",", ":", "(", "encoder_output_dim", "//", "2", ")", "]", "\n", "final_backward_output", "=", "encoder_outputs", "[", ":", ",", "0", ",", "(", "encoder_output_dim", "//", "2", ")", ":", "]", "\n", "final_encoder_output", "=", "torch", ".", "cat", "(", "[", "final_forward_output", ",", "final_backward_output", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "final_encoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_dropout_mask": [[150, 171], ["tensor_for_masking.new_tensor", "tensor_for_masking.new_tensor.float().div", "torch.rand", "tensor_for_masking.new_tensor.float", "tensor_for_masking.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "get_dropout_mask", "(", "dropout_probability", ":", "float", ",", "tensor_for_masking", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Computes and returns an element-wise dropout mask for a given tensor, where\n    each element in the mask is dropped out with probability dropout_probability.\n    Note that the mask is NOT applied to the tensor - the tensor is passed to retain\n    the correct CUDA tensor type for the mask.\n    Parameters\n    ----------\n    dropout_probability : float, required.\n        Probability of dropping a dimension of the input.\n    tensor_for_masking : torch.Tensor, required.\n    Returns\n    -------\n    A torch.FloatTensor consisting of the binary mask scaled by 1/ (1 - dropout_probability).\n    This scaling ensures expected values and variances of the output of applying this mask\n     and the original tensor are the same.\n    \"\"\"", "\n", "binary_mask", "=", "tensor_for_masking", ".", "new_tensor", "(", "torch", ".", "rand", "(", "tensor_for_masking", ".", "size", "(", ")", ")", ">", "dropout_probability", ")", "\n", "# Scale mask by 1/keep_prob to preserve output statistics.", "\n", "dropout_mask", "=", "binary_mask", ".", "float", "(", ")", ".", "div", "(", "1.0", "-", "dropout_probability", ")", "\n", "return", "dropout_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_softmax": [[173, 197], ["torch.nn.functional.softmax", "mask.unsqueeze.float", "torch.nn.functional.softmax", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze", "torch.nn.functional.softmax.sum"], "function", ["None"], ["", "def", "masked_softmax", "(", "vector", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    ``torch.nn.functional.softmax(vector)`` does not work if some elements of ``vector`` should be\n    masked.  This performs a softmax on just the non-masked portions of ``vector``.  Passing\n    ``None`` in for the mask is also acceptable; you'll just get a regular softmax.\n    ``vector`` can have an arbitrary number of dimensions; the only requirement is that ``mask`` is\n    broadcastable to ``vector's`` shape.  If ``mask`` has fewer dimensions than ``vector``, we will\n    unsqueeze on dimension 1 until they match.  If you need a different unsqueezing of your mask,\n    do it yourself before passing the mask into this function.\n    In the case that the input vector is completely masked, this function returns an array\n    of ``0.0``. This behavior may cause ``NaN`` if this is used as the last layer of a model\n    that uses categorical cross-entropy loss.\n    \"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "# To limit numerical errors from large vector elements outside the mask, we zero these out.", "\n", "", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", "*", "mask", ",", "dim", "=", "dim", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_log_softmax": [[199, 228], ["torch.nn.functional.log_softmax", "mask.unsqueeze.float", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze"], "function", ["None"], ["", "def", "masked_log_softmax", "(", "vector", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    ``torch.nn.functional.log_softmax(vector)`` does not work if some elements of ``vector`` should be\n    masked.  This performs a log_softmax on just the non-masked portions of ``vector``.  Passing\n    ``None`` in for the mask is also acceptable; you'll just get a regular log_softmax.\n    ``vector`` can have an arbitrary number of dimensions; the only requirement is that ``mask`` is\n    broadcastable to ``vector's`` shape.  If ``mask`` has fewer dimensions than ``vector``, we will\n    unsqueeze on dimension 1 until they match.  If you need a different unsqueezing of your mask,\n    do it yourself before passing the mask into this function.\n    In the case that the input vector is completely masked, the return value of this function is\n    arbitrary, but not ``nan``.  You should be masking the result of whatever computation comes out\n    of this in that case, anyway, so the specific values returned shouldn't matter.  Also, the way\n    that we deal with this case relies on having single-precision floats; mixing half-precision\n    floats with fully-masked vectors will likely give you ``nans``.\n    If your logits are all extremely negative (i.e., the max value in your logit vector is -50 or\n    lower), the way we handle masking here could mess you up.  But if you've got logit values that\n    extreme, you've got bigger problems than this.\n    \"\"\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "# vector + mask.log() is an easy way to zero out masked elements in logspace, but it", "\n", "# results in nans when the whole vector is masked.  We need a very small value instead of a", "\n", "# zero in the mask for these cases.  log(1 + 1e-45) is still basically 0, so we can safely", "\n", "# just add 1e-45 before calling mask.log().  We use 1e-45 because 1e-46 is so small it", "\n", "# becomes 0 - this is just the smallest value we can actually use.", "\n", "", "vector", "=", "vector", "+", "(", "mask", "+", "1e-45", ")", ".", "log", "(", ")", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_max": [[230, 257], ["vector.masked_fill", "vector.masked_fill.max"], "function", ["None"], ["", "def", "masked_max", "(", "vector", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", ",", "\n", "keepdim", ":", "bool", "=", "False", ",", "\n", "min_val", ":", "float", "=", "-", "1e7", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    To calculate max along certain dimensions on masked values\n    Parameters\n    ----------\n    vector : ``torch.Tensor``\n        The vector to calculate max, assume unmasked parts are already zeros\n    mask : ``torch.Tensor``\n        The mask of the vector. It must be broadcastable with vector.\n    dim : ``int``\n        The dimension to calculate max\n    keepdim : ``bool``\n        Whether to keep dimension\n    min_val : ``float``\n        The minimal value for paddings\n    Returns\n    -------\n    A ``torch.Tensor`` of including the maximum values.\n    \"\"\"", "\n", "one_minus_mask", "=", "(", "1.0", "-", "mask", ")", ".", "byte", "(", ")", "\n", "replaced_vector", "=", "vector", ".", "masked_fill", "(", "one_minus_mask", ",", "min_val", ")", "\n", "max_value", ",", "_", "=", "replaced_vector", ".", "max", "(", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "return", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_mean": [[259, 288], ["vector.masked_fill", "torch.sum", "torch.sum", "mask.float", "torch.sum.clamp"], "function", ["None"], ["", "def", "masked_mean", "(", "vector", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", ",", "\n", "keepdim", ":", "bool", "=", "False", ",", "\n", "eps", ":", "float", "=", "1e-8", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    To calculate mean along certain dimensions on masked values\n    Parameters\n    ----------\n    vector : ``torch.Tensor``\n        The vector to calculate mean.\n    mask : ``torch.Tensor``\n        The mask of the vector. It must be broadcastable with vector.\n    dim : ``int``\n        The dimension to calculate mean\n    keepdim : ``bool``\n        Whether to keep dimension\n    eps : ``float``\n        A small value to avoid zero division problem.\n    Returns\n    -------\n    A ``torch.Tensor`` of including the mean values.\n    \"\"\"", "\n", "one_minus_mask", "=", "(", "1.0", "-", "mask", ")", ".", "byte", "(", ")", "\n", "replaced_vector", "=", "vector", ".", "masked_fill", "(", "one_minus_mask", ",", "0.0", ")", "\n", "\n", "value_sum", "=", "torch", ".", "sum", "(", "replaced_vector", ",", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "value_count", "=", "torch", ".", "sum", "(", "mask", ".", "float", "(", ")", ",", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "return", "value_sum", "/", "value_count", ".", "clamp", "(", "min", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.viterbi_decode": [[290, 372], ["list", "range", "torch.max", "reversed", "viterbi_path.reverse", "tag_sequence.size", "torch.zeros", "path_scores.append", "path_scores.append", "torch.max", "path_indices.append", "int", "viterbi_path.append", "len", "stog.utils.checks.ConfigurationError", "path_scores[].unsqueeze", "torch.zeros", "path_scores.append", "path_scores.append", "paths.squeeze", "best_path.numpy", "int", "range", "logger.warning", "scores.squeeze"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "viterbi_decode", "(", "tag_sequence", ":", "torch", ".", "Tensor", ",", "\n", "transition_matrix", ":", "torch", ".", "Tensor", ",", "\n", "tag_observations", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform Viterbi decoding in log space over a sequence given a transition matrix\n    specifying pairwise (transition) potentials between tags and a matrix of shape\n    (sequence_length, num_tags) specifying unary potentials for possible tags per\n    timestep.\n    Parameters\n    ----------\n    tag_sequence : torch.Tensor, required.\n        A tensor of shape (sequence_length, num_tags) representing scores for\n        a set of tags over a given sequence.\n    transition_matrix : torch.Tensor, required.\n        A tensor of shape (num_tags, num_tags) representing the binary potentials\n        for transitioning between a given pair of tags.\n    tag_observations : Optional[List[int]], optional, (default = None)\n        A list of length ``sequence_length`` containing the class ids of observed\n        elements in the sequence, with unobserved elements being set to -1. Note that\n        it is possible to provide evidence which results in degenerate labellings if\n        the sequences of tags you provide as evidence cannot transition between each\n        other, or those transitions are extremely unlikely. In this situation we log a\n        warning, but the responsibility for providing self-consistent evidence ultimately\n        lies with the user.\n    Returns\n    -------\n    viterbi_path : List[int]\n        The tag indices of the maximum likelihood tag sequence.\n    viterbi_score : torch.Tensor\n        The score of the viterbi path.\n    \"\"\"", "\n", "sequence_length", ",", "num_tags", "=", "list", "(", "tag_sequence", ".", "size", "(", ")", ")", "\n", "if", "tag_observations", ":", "\n", "        ", "if", "len", "(", "tag_observations", ")", "!=", "sequence_length", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Observations were provided, but they were not the same length \"", "\n", "\"as the sequence. Found sequence of length: {} and evidence: {}\"", "\n", ".", "format", "(", "sequence_length", ",", "tag_observations", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "tag_observations", "=", "[", "-", "1", "for", "_", "in", "range", "(", "sequence_length", ")", "]", "\n", "\n", "", "path_scores", "=", "[", "]", "\n", "path_indices", "=", "[", "]", "\n", "\n", "if", "tag_observations", "[", "0", "]", "!=", "-", "1", ":", "\n", "        ", "one_hot", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "one_hot", "[", "tag_observations", "[", "0", "]", "]", "=", "100000.", "\n", "path_scores", ".", "append", "(", "one_hot", ")", "\n", "", "else", ":", "\n", "        ", "path_scores", ".", "append", "(", "tag_sequence", "[", "0", ",", ":", "]", ")", "\n", "\n", "# Evaluate the scores for all possible paths.", "\n", "", "for", "timestep", "in", "range", "(", "1", ",", "sequence_length", ")", ":", "\n", "# Add pairwise potentials to current scores.", "\n", "        ", "summed_potentials", "=", "path_scores", "[", "timestep", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "+", "transition_matrix", "\n", "scores", ",", "paths", "=", "torch", ".", "max", "(", "summed_potentials", ",", "0", ")", "\n", "\n", "# If we have an observation for this timestep, use it", "\n", "# instead of the distribution over tags.", "\n", "observation", "=", "tag_observations", "[", "timestep", "]", "\n", "# Warn the user if they have passed", "\n", "# invalid/extremely unlikely evidence.", "\n", "if", "tag_observations", "[", "timestep", "-", "1", "]", "!=", "-", "1", ":", "\n", "            ", "if", "transition_matrix", "[", "tag_observations", "[", "timestep", "-", "1", "]", ",", "observation", "]", "<", "-", "10000", ":", "\n", "                ", "logger", ".", "warning", "(", "\"The pairwise potential between tags you have passed as \"", "\n", "\"observations is extremely unlikely. Double check your evidence \"", "\n", "\"or transition potentials!\"", ")", "\n", "", "", "if", "observation", "!=", "-", "1", ":", "\n", "            ", "one_hot", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "one_hot", "[", "observation", "]", "=", "100000.", "\n", "path_scores", ".", "append", "(", "one_hot", ")", "\n", "", "else", ":", "\n", "            ", "path_scores", ".", "append", "(", "tag_sequence", "[", "timestep", ",", ":", "]", "+", "scores", ".", "squeeze", "(", ")", ")", "\n", "", "path_indices", ".", "append", "(", "paths", ".", "squeeze", "(", ")", ")", "\n", "\n", "# Construct the most likely sequence backwards.", "\n", "", "viterbi_score", ",", "best_path", "=", "torch", ".", "max", "(", "path_scores", "[", "-", "1", "]", ",", "0", ")", "\n", "viterbi_path", "=", "[", "int", "(", "best_path", ".", "numpy", "(", ")", ")", "]", "\n", "for", "backward_timestep", "in", "reversed", "(", "path_indices", ")", ":", "\n", "        ", "viterbi_path", ".", "append", "(", "int", "(", "backward_timestep", "[", "viterbi_path", "[", "-", "1", "]", "]", ")", ")", "\n", "# Reverse the backward path.", "\n", "", "viterbi_path", ".", "reverse", "(", ")", "\n", "return", "viterbi_path", ",", "viterbi_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_text_field_mask": [[374, 417], ["tensor_dims.sort", "tensor.dim", "text_field_tensors.values", "ValueError"], "function", ["None"], ["", "def", "get_text_field_mask", "(", "text_field_tensors", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "num_wrapping_dims", ":", "int", "=", "0", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "\"\"\"\n    Takes the dictionary of tensors produced by a ``TextField`` and returns a mask\n    with 0 where the tokens are padding, and 1 otherwise.  We also handle ``TextFields``\n    wrapped by an arbitrary number of ``ListFields``, where the number of wrapping ``ListFields``\n    is given by ``num_wrapping_dims``.\n    If ``num_wrapping_dims == 0``, the returned mask has shape ``(batch_size, num_tokens)``.\n    If ``num_wrapping_dims > 0`` then the returned mask has ``num_wrapping_dims`` extra\n    dimensions, so the shape will be ``(batch_size, ..., num_tokens)``.\n    There could be several entries in the tensor dictionary with different shapes (e.g., one for\n    word ids, one for character ids).  In order to get a token mask, we use the tensor in\n    the dictionary with the lowest number of dimensions.  After subtracting ``num_wrapping_dims``,\n    if this tensor has two dimensions we assume it has shape ``(batch_size, ..., num_tokens)``,\n    and use it for the mask.  If instead it has three dimensions, we assume it has shape\n    ``(batch_size, ..., num_tokens, num_features)``, and sum over the last dimension to produce\n    the mask.  Most frequently this will be a character id tensor, but it could also be a\n    featurized representation of each token, etc.\n    If the input ``text_field_tensors`` contains the \"mask\" key, this is returned instead of inferring the mask.\n    TODO(joelgrus): can we change this?\n    NOTE: Our functions for generating masks create torch.LongTensors, because using\n    torch.ByteTensors  makes it easy to run into overflow errors\n    when doing mask manipulation, such as summing to get the lengths of sequences - see below.\n    >>> mask = torch.ones([260]).byte()\n    >>> mask.sum() # equals 260.\n    >>> var_mask = torch.autograd.V(mask)\n    >>> var_mask.sum() # equals 4, due to 8 bit precision - the sum overflows.\n    \"\"\"", "\n", "if", "\"mask\"", "in", "text_field_tensors", ":", "\n", "        ", "return", "text_field_tensors", "[", "\"mask\"", "]", "\n", "\n", "", "tensor_dims", "=", "[", "(", "tensor", ".", "dim", "(", ")", ",", "tensor", ")", "for", "tensor", "in", "text_field_tensors", ".", "values", "(", ")", "]", "\n", "tensor_dims", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "\n", "smallest_dim", "=", "tensor_dims", "[", "0", "]", "[", "0", "]", "-", "num_wrapping_dims", "\n", "if", "smallest_dim", "==", "2", ":", "\n", "        ", "token_tensor", "=", "tensor_dims", "[", "0", "]", "[", "1", "]", "\n", "return", "(", "token_tensor", "!=", "0", ")", ".", "long", "(", ")", "\n", "", "elif", "smallest_dim", "==", "3", ":", "\n", "        ", "character_tensor", "=", "tensor_dims", "[", "0", "]", "[", "1", "]", "\n", "return", "(", "(", "character_tensor", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ">", "0", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Expected a tensor with dimension 2 or 3, found {}\"", ".", "format", "(", "smallest_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.last_dim_softmax": [[419, 431], ["warnings.warn", "nn.masked_softmax"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_softmax"], ["", "", "def", "last_dim_softmax", "(", "tensor", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Takes a tensor with 3 or more dimensions and does a masked softmax over the last dimension.  We\n    assume the tensor has shape ``(batch_size, ..., sequence_length)`` and that the mask (if given)\n    has shape ``(batch_size, sequence_length)``.\n    .. deprecated:: 0.6.1\n           ``last_dim_softmax`` was deprecated in favor of just using ``masked_softmax`` in version\n           0.6.1.  It will be removed in version 0.8.\n    \"\"\"", "\n", "warnings", ".", "warn", "(", "\"``last_dim_softmax`` was deprecated in favor of just using ``masked_softmax`` \"", "\n", "\"in version 0.6.1.  It will be removed in version 0.8.\"", ",", "DeprecationWarning", ")", "\n", "return", "masked_softmax", "(", "tensor", ",", "mask", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.last_dim_log_softmax": [[433, 446], ["warnings.warn", "nn.masked_log_softmax"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_log_softmax"], ["", "def", "last_dim_log_softmax", "(", "tensor", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Takes a tensor with 3 or more dimensions and does a masked log softmax over the last dimension.\n    We assume the tensor has shape ``(batch_size, ..., sequence_length)`` and that the mask (if given)\n    has shape ``(batch_size, sequence_length)``.\n    .. deprecated:: 0.6.1\n           ``last_dim_log_softmax`` was deprecated in favor of just using ``masked_log_softmax`` in\n           version 0.6.1.  It will be removed in version 0.8.\n    \"\"\"", "\n", "warnings", ".", "warn", "(", "\"``last_dim_log_softmax`` was deprecated in favor of just using \"", "\n", "\"``masked_log_softmax`` in version 0.6.1.  It will be removed in version 0.8.\"", ",", "\n", "DeprecationWarning", ")", "\n", "return", "masked_log_softmax", "(", "tensor", ",", "mask", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.weighted_sum": [[448, 481], ["intermediate.sum", "attention.unsqueeze().bmm().squeeze", "attention.bmm", "attention.dim", "list", "range", "matrix.unsqueeze.expand", "attention.unsqueeze().expand_as", "attention.dim", "matrix.unsqueeze.dim", "attention.dim", "matrix.unsqueeze.dim", "matrix.unsqueeze.dim", "matrix.unsqueeze.size", "matrix.unsqueeze.unsqueeze", "list.insert", "attention.unsqueeze().bmm", "attention.size", "attention.unsqueeze", "attention.dim", "matrix.unsqueeze.dim", "attention.unsqueeze"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "weighted_sum", "(", "matrix", ":", "torch", ".", "Tensor", ",", "attention", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Takes a matrix of vectors and a set of weights over the rows in the matrix (which we call an\n    \"attention\" vector), and returns a weighted sum of the rows in the matrix.  This is the typical\n    computation performed after an attention mechanism.\n    Note that while we call this a \"matrix\" of vectors and an attention \"vector\", we also handle\n    higher-order tensors.  We always sum over the second-to-last dimension of the \"matrix\", and we\n    assume that all dimensions in the \"matrix\" prior to the last dimension are matched in the\n    \"vector\".  Non-matched dimensions in the \"vector\" must be `directly after the batch dimension`.\n    For example, say I have a \"matrix\" with dimensions ``(batch_size, num_queries, num_words,\n    embedding_dim)``.  The attention \"vector\" then must have at least those dimensions, and could\n    have more. Both:\n        - ``(batch_size, num_queries, num_words)`` (distribution over words for each query)\n        - ``(batch_size, num_documents, num_queries, num_words)`` (distribution over words in a\n          query for each document)\n    are valid input \"vectors\", producing tensors of shape:\n    ``(batch_size, num_queries, embedding_dim)`` and\n    ``(batch_size, num_documents, num_queries, embedding_dim)`` respectively.\n    \"\"\"", "\n", "# We'll special-case a few settings here, where there are efficient (but poorly-named)", "\n", "# operations in pytorch that already do the computation we need.", "\n", "if", "attention", ".", "dim", "(", ")", "==", "2", "and", "matrix", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "return", "attention", ".", "unsqueeze", "(", "1", ")", ".", "bmm", "(", "matrix", ")", ".", "squeeze", "(", "1", ")", "\n", "", "if", "attention", ".", "dim", "(", ")", "==", "3", "and", "matrix", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "return", "attention", ".", "bmm", "(", "matrix", ")", "\n", "", "if", "matrix", ".", "dim", "(", ")", "-", "1", "<", "attention", ".", "dim", "(", ")", ":", "\n", "        ", "expanded_size", "=", "list", "(", "matrix", ".", "size", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "attention", ".", "dim", "(", ")", "-", "matrix", ".", "dim", "(", ")", "+", "1", ")", ":", "\n", "            ", "matrix", "=", "matrix", ".", "unsqueeze", "(", "1", ")", "\n", "expanded_size", ".", "insert", "(", "i", "+", "1", ",", "attention", ".", "size", "(", "i", "+", "1", ")", ")", "\n", "", "matrix", "=", "matrix", ".", "expand", "(", "*", "expanded_size", ")", "\n", "", "intermediate", "=", "attention", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "matrix", ")", "*", "matrix", "\n", "return", "intermediate", ".", "sum", "(", "dim", "=", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.sequence_cross_entropy_with_logits": [[483, 550], ["logits.view", "torch.nn.functional.log_softmax", "targets.view().long", "negative_log_likelihood_flat.sum.view", "logits.size", "logits.size", "torch.zeros_like().scatter_", "negative_log_likelihood_flat.sum.sum", "weights.float", "negative_log_likelihood_flat.view.sum", "targets.view", "torch.gather", "targets.size", "weights.sum().float", "per_batch_loss.sum", "torch.zeros_like", "weights.sum", "weights.sum"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "sequence_cross_entropy_with_logits", "(", "logits", ":", "torch", ".", "FloatTensor", ",", "\n", "targets", ":", "torch", ".", "LongTensor", ",", "\n", "weights", ":", "torch", ".", "FloatTensor", ",", "\n", "batch_average", ":", "bool", "=", "True", ",", "\n", "label_smoothing", ":", "float", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Computes the cross entropy loss of a sequence, weighted with respect to\n    some user provided weights. Note that the weighting here is not the same as\n    in the :func:`torch.nn.CrossEntropyLoss()` criterion, which is weighting\n    classes; here we are weighting the loss contribution from particular elements\n    in the sequence. This allows loss computations for models which use padding.\n    Parameters\n    ----------\n    logits : ``torch.FloatTensor``, required.\n        A ``torch.FloatTensor`` of size (batch_size, sequence_length, num_classes)\n        which contains the unnormalized probability for each class.\n    targets : ``torch.LongTensor``, required.\n        A ``torch.LongTensor`` of size (batch, sequence_length) which contains the\n        index of the true class for each corresponding step.\n    weights : ``torch.FloatTensor``, required.\n        A ``torch.FloatTensor`` of size (batch, sequence_length)\n    batch_average : bool, optional, (default = True).\n        A bool indicating whether the loss should be averaged across the batch,\n        or returned as a vector of losses per batch element.\n    label_smoothing : ``float``, optional (default = None)\n        Whether or not to apply label smoothing to the cross-entropy loss.\n        For example, with a label smoothing value of 0.2, a 4 class classifcation\n        target would look like ``[0.05, 0.05, 0.85, 0.05]`` if the 3rd class was\n        the correct label.\n    Returns\n    -------\n    A torch.FloatTensor representing the cross entropy loss.\n    If ``batch_average == True``, the returned loss is a scalar.\n    If ``batch_average == False``, the returned loss is a vector of shape (batch_size,).\n    \"\"\"", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "log_probs_flat", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "-", "1", ")", "\n", "# shape : (batch * max_len, 1)", "\n", "targets_flat", "=", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "long", "(", ")", "\n", "\n", "if", "label_smoothing", "is", "not", "None", "and", "label_smoothing", ">", "0.0", ":", "\n", "        ", "num_classes", "=", "logits", ".", "size", "(", "-", "1", ")", "\n", "smoothing_value", "=", "label_smoothing", "/", "num_classes", "\n", "# Fill all the correct indices with 1 - smoothing value.", "\n", "one_hot_targets", "=", "torch", ".", "zeros_like", "(", "log_probs_flat", ")", ".", "scatter_", "(", "-", "1", ",", "targets_flat", ",", "1.0", "-", "label_smoothing", ")", "\n", "smoothed_targets", "=", "one_hot_targets", "+", "smoothing_value", "\n", "negative_log_likelihood_flat", "=", "-", "log_probs_flat", "*", "smoothed_targets", "\n", "negative_log_likelihood_flat", "=", "negative_log_likelihood_flat", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "# Contribution to the negative log likelihood only comes from the exact indices", "\n", "# of the targets, as the target distributions are one-hot. Here we use torch.gather", "\n", "# to extract the indices of the num_classes dimension which contribute to the loss.", "\n", "# shape : (batch * sequence_length, 1)", "\n", "        ", "negative_log_likelihood_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "targets_flat", ")", "\n", "# shape : (batch, sequence_length)", "\n", "", "negative_log_likelihood", "=", "negative_log_likelihood_flat", ".", "view", "(", "*", "targets", ".", "size", "(", ")", ")", "\n", "# shape : (batch, sequence_length)", "\n", "negative_log_likelihood", "=", "negative_log_likelihood", "*", "weights", ".", "float", "(", ")", "\n", "# shape : (batch_size,)", "\n", "per_batch_loss", "=", "negative_log_likelihood", ".", "sum", "(", "1", ")", "/", "(", "weights", ".", "sum", "(", "1", ")", ".", "float", "(", ")", "+", "1e-13", ")", "\n", "\n", "if", "batch_average", ":", "\n", "        ", "num_non_empty_sequences", "=", "(", "(", "weights", ".", "sum", "(", "1", ")", ">", "0", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "+", "1e-13", ")", "\n", "return", "per_batch_loss", ".", "sum", "(", ")", "/", "num_non_empty_sequences", "\n", "", "return", "per_batch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.replace_masked_values": [[552, 564], ["tensor.masked_fill", "tensor.dim", "mask.dim", "stog.utils.checks.ConfigurationError", "tensor.dim", "mask.dim"], "function", ["None"], ["", "def", "replace_masked_values", "(", "tensor", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "replace_with", ":", "float", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Replaces all masked values in ``tensor`` with ``replace_with``.  ``mask`` must be broadcastable\n    to the same shape as ``tensor``. We require that ``tensor.dim() == mask.dim()``, as otherwise we\n    won't know which dimensions of the mask to unsqueeze.\n    This just does ``tensor.masked_fill()``, except the pytorch method fills in things with a mask\n    value of 1, where we want the opposite.  You can do this in your own code with\n    ``tensor.masked_fill((1 - mask).byte(), replace_with)``.\n    \"\"\"", "\n", "if", "tensor", ".", "dim", "(", ")", "!=", "mask", ".", "dim", "(", ")", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"tensor.dim() (%d) != mask.dim() (%d)\"", "%", "(", "tensor", ".", "dim", "(", ")", ",", "mask", ".", "dim", "(", ")", ")", ")", "\n", "", "return", "tensor", ".", "masked_fill", "(", "(", "1", "-", "mask", ")", ".", "byte", "(", ")", ",", "replace_with", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.tensors_equal": [[566, 599], ["isinstance", "all", "isinstance", "all", "isinstance", "isinstance", "len", "len", "nn.tensors_equal", "isinstance", "tensor1.keys", "tensor2.keys", "zip", "nn.tensors_equal", "isinstance", "tensor1.size", "tensor2.size", "print", "type", "type"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.tensors_equal", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.tensors_equal", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "tensors_equal", "(", "tensor1", ":", "torch", ".", "Tensor", ",", "tensor2", ":", "torch", ".", "Tensor", ",", "tolerance", ":", "float", "=", "1e-12", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    A check for tensor equality (by value).  We make sure that the tensors have the same shape,\n    then check all of the entries in the tensor for equality.  We additionally allow the input\n    tensors to be lists or dictionaries, where we then do the above check on every position in the\n    list / item in the dictionary.  If we find objects that aren't tensors as we're doing that, we\n    just defer to their equality check.\n    This is kind of a catch-all method that's designed to make implementing ``__eq__`` methods\n    easier, in a way that's really only intended to be useful for tests.\n    \"\"\"", "\n", "# pylint: disable=too-many-return-statements", "\n", "if", "isinstance", "(", "tensor1", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "tensor2", ",", "(", "list", ",", "tuple", ")", ")", "or", "len", "(", "tensor1", ")", "!=", "len", "(", "tensor2", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "all", "(", "[", "tensors_equal", "(", "t1", ",", "t2", ",", "tolerance", ")", "for", "t1", ",", "t2", "in", "zip", "(", "tensor1", ",", "tensor2", ")", "]", ")", "\n", "", "elif", "isinstance", "(", "tensor1", ",", "dict", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "tensor2", ",", "dict", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "tensor1", ".", "keys", "(", ")", "!=", "tensor2", ".", "keys", "(", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "all", "(", "[", "tensors_equal", "(", "tensor1", "[", "key", "]", ",", "tensor2", "[", "key", "]", ",", "tolerance", ")", "for", "key", "in", "tensor1", "]", ")", "\n", "", "elif", "isinstance", "(", "tensor1", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "tensor2", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "tensor1", ".", "size", "(", ")", "!=", "tensor2", ".", "size", "(", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "(", "(", "tensor1", "-", "tensor2", ")", ".", "abs", "(", ")", ".", "float", "(", ")", "<", "tolerance", ")", ".", "all", "(", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "tensor1", "==", "tensor2", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "print", "(", "type", "(", "tensor1", ")", ",", "type", "(", "tensor2", ")", ")", "\n", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.device_mapping": [[602, 614], ["storage.cuda"], "function", ["None"], ["", "", "", "def", "device_mapping", "(", "cuda_device", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    In order to `torch.load()` a GPU-trained model onto a CPU (or specific GPU),\n    you have to supply a `map_location` function. Call this with\n    the desired `cuda_device` to get the function that `torch.load()` needs.\n    \"\"\"", "\n", "def", "inner_device_mapping", "(", "storage", ":", "torch", ".", "Storage", ",", "location", ")", "->", "torch", ".", "Storage", ":", "# pylint: disable=unused-argument", "\n", "        ", "if", "cuda_device", ">=", "0", ":", "\n", "            ", "return", "storage", ".", "cuda", "(", "cuda_device", ")", "\n", "", "else", ":", "\n", "            ", "return", "storage", "\n", "", "", "return", "inner_device_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.combine_tensors": [[616, 641], ["combination.replace().replace.replace().replace", "torch.cat", "len", "stog.utils.checks.ConfigurationError", "nn._get_combination", "combination.replace().replace.replace", "combination.replace().replace.split"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination"], ["", "def", "combine_tensors", "(", "combination", ":", "str", ",", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Combines a list of tensors using element-wise operations and concatenation, specified by a\n    ``combination`` string.  The string refers to (1-indexed) positions in the input tensor list,\n    and looks like ``\"1,2,1+2,3-1\"``.\n    We allow the following kinds of combinations: ``x``, ``x*y``, ``x+y``, ``x-y``, and ``x/y``,\n    where ``x`` and ``y`` are positive integers less than or equal to ``len(tensors)``.  Each of\n    the binary operations is performed elementwise.  You can give as many combinations as you want\n    in the ``combination`` string.  For example, for the input string ``\"1,2,1*2\"``, the result\n    would be ``[1;2;1*2]``, as you would expect, where ``[;]`` is concatenation along the last\n    dimension.\n    If you have a fixed, known way to combine tensors that you use in a model, you should probably\n    just use something like ``torch.cat([x_tensor, y_tensor, x_tensor * y_tensor])``.  This\n    function adds some complexity that is only necessary if you want the specific combination used\n    to be `configurable`.\n    If you want to do any element-wise operations, the tensors involved in each element-wise\n    operation must have the same shape.\n    This function also accepts ``x`` and ``y`` in place of ``1`` and ``2`` in the combination\n    string.\n    \"\"\"", "\n", "if", "len", "(", "tensors", ")", ">", "9", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Double-digit tensor lists not currently supported\"", ")", "\n", "", "combination", "=", "combination", ".", "replace", "(", "'x'", ",", "'1'", ")", ".", "replace", "(", "'y'", ",", "'2'", ")", "\n", "to_concatenate", "=", "[", "_get_combination", "(", "piece", ",", "tensors", ")", "for", "piece", "in", "combination", ".", "split", "(", "','", ")", "]", "\n", "return", "torch", ".", "cat", "(", "to_concatenate", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination": [[643, 663], ["combination.isdigit", "nn._get_combination", "nn._get_combination", "int", "len", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination"], ["", "def", "_get_combination", "(", "combination", ":", "str", ",", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "combination", ".", "isdigit", "(", ")", ":", "\n", "        ", "index", "=", "int", "(", "combination", ")", "-", "1", "\n", "return", "tensors", "[", "index", "]", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "combination", ")", "!=", "3", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Invalid combination: \"", "+", "combination", ")", "\n", "", "first_tensor", "=", "_get_combination", "(", "combination", "[", "0", "]", ",", "tensors", ")", "\n", "second_tensor", "=", "_get_combination", "(", "combination", "[", "2", "]", ",", "tensors", ")", "\n", "operation", "=", "combination", "[", "1", "]", "\n", "if", "operation", "==", "'*'", ":", "\n", "            ", "return", "first_tensor", "*", "second_tensor", "\n", "", "elif", "operation", "==", "'/'", ":", "\n", "            ", "return", "first_tensor", "/", "second_tensor", "\n", "", "elif", "operation", "==", "'+'", ":", "\n", "            ", "return", "first_tensor", "+", "second_tensor", "\n", "", "elif", "operation", "==", "'-'", ":", "\n", "            ", "return", "first_tensor", "-", "second_tensor", "\n", "", "else", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Invalid operation: \"", "+", "operation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.combine_tensors_and_multiply": [[665, 702], ["combination.replace().replace.replace().replace", "combination.replace().replace.split", "zip", "len", "stog.utils.checks.ConfigurationError", "tensor.size", "nn._get_combination_dim", "to_sum.append", "combination.replace().replace.replace", "nn._get_combination_and_multiply"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_dim", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_and_multiply"], ["", "", "", "def", "combine_tensors_and_multiply", "(", "combination", ":", "str", ",", "\n", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "weights", ":", "torch", ".", "nn", ".", "Parameter", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Like :func:`combine_tensors`, but does a weighted (linear) multiplication while combining.\n    This is a separate function from ``combine_tensors`` because we try to avoid instantiating\n    large intermediate tensors during the combination, which is possible because we know that we're\n    going to be multiplying by a weight vector in the end.\n    Parameters\n    ----------\n    combination : ``str``\n        Same as in :func:`combine_tensors`\n    tensors : ``List[torch.Tensor]``\n        A list of tensors to combine, where the integers in the ``combination`` are (1-indexed)\n        positions in this list of tensors.  These tensors are all expected to have either three or\n        four dimensions, with the final dimension being an embedding.  If there are four\n        dimensions, one of them must have length 1.\n    weights : ``torch.nn.Parameter``\n        A vector of weights to use for the combinations.  This should have shape (combined_dim,),\n        as calculated by :func:`get_combined_dim`.\n    \"\"\"", "\n", "if", "len", "(", "tensors", ")", ">", "9", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Double-digit tensor lists not currently supported\"", ")", "\n", "", "combination", "=", "combination", ".", "replace", "(", "'x'", ",", "'1'", ")", ".", "replace", "(", "'y'", ",", "'2'", ")", "\n", "pieces", "=", "combination", ".", "split", "(", "','", ")", "\n", "tensor_dims", "=", "[", "tensor", ".", "size", "(", "-", "1", ")", "for", "tensor", "in", "tensors", "]", "\n", "combination_dims", "=", "[", "_get_combination_dim", "(", "piece", ",", "tensor_dims", ")", "for", "piece", "in", "pieces", "]", "\n", "dims_so_far", "=", "0", "\n", "to_sum", "=", "[", "]", "\n", "for", "piece", ",", "combination_dim", "in", "zip", "(", "pieces", ",", "combination_dims", ")", ":", "\n", "        ", "weight", "=", "weights", "[", "dims_so_far", ":", "(", "dims_so_far", "+", "combination_dim", ")", "]", "\n", "dims_so_far", "+=", "combination_dim", "\n", "to_sum", ".", "append", "(", "_get_combination_and_multiply", "(", "piece", ",", "tensors", ",", "weight", ")", ")", "\n", "", "result", "=", "to_sum", "[", "0", "]", "\n", "for", "result_piece", "in", "to_sum", "[", "1", ":", "]", ":", "\n", "        ", "result", "=", "result", "+", "result_piece", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_and_multiply": [[704, 744], ["combination.isdigit", "torch.matmul", "nn._get_combination", "nn._get_combination", "int", "len", "stog.utils.checks.ConfigurationError", "torch.matmul().squeeze", "ValueError", "first_tensor.squeeze.dim", "first_tensor.squeeze.size().index", "first_tensor.squeeze.squeeze", "second_tensor.squeeze.dim", "second_tensor.squeeze.size().index", "second_tensor.squeeze.squeeze", "torch.matmul().squeeze", "first_tensor.squeeze.dim", "second_tensor.squeeze.dim", "torch.matmul", "ValueError", "first_tensor.squeeze.dim", "first_tensor.squeeze.size().index", "first_tensor.squeeze.squeeze", "second_tensor.squeeze.dim", "second_tensor.squeeze.size().index", "second_tensor.squeeze.squeeze", "first_tensor.squeeze.size", "second_tensor.squeeze.size", "second_tensor.squeeze.transpose", "first_tensor.squeeze.dim", "second_tensor.squeeze.dim", "torch.matmul", "torch.matmul", "torch.matmul", "stog.utils.checks.ConfigurationError", "first_tensor.squeeze.size", "second_tensor.squeeze.size", "second_tensor.squeeze.pow().transpose", "torch.matmul", "torch.matmul", "second_tensor.squeeze.pow"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "_get_combination_and_multiply", "(", "combination", ":", "str", ",", "\n", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "weight", ":", "torch", ".", "nn", ".", "Parameter", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "combination", ".", "isdigit", "(", ")", ":", "\n", "        ", "index", "=", "int", "(", "combination", ")", "-", "1", "\n", "return", "torch", ".", "matmul", "(", "tensors", "[", "index", "]", ",", "weight", ")", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "combination", ")", "!=", "3", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Invalid combination: \"", "+", "combination", ")", "\n", "", "first_tensor", "=", "_get_combination", "(", "combination", "[", "0", "]", ",", "tensors", ")", "\n", "second_tensor", "=", "_get_combination", "(", "combination", "[", "2", "]", ",", "tensors", ")", "\n", "operation", "=", "combination", "[", "1", "]", "\n", "if", "operation", "==", "'*'", ":", "\n", "            ", "if", "first_tensor", ".", "dim", "(", ")", ">", "4", "or", "second_tensor", ".", "dim", "(", ")", ">", "4", ":", "\n", "                ", "raise", "ValueError", "(", "\"Tensors with dim > 4 not currently supported\"", ")", "\n", "", "if", "first_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "                ", "expanded_dim", "=", "first_tensor", ".", "size", "(", ")", ".", "index", "(", "1", ")", "\n", "first_tensor", "=", "first_tensor", ".", "squeeze", "(", "expanded_dim", ")", "\n", "", "if", "second_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "                ", "expanded_dim", "=", "second_tensor", ".", "size", "(", ")", ".", "index", "(", "1", ")", "\n", "second_tensor", "=", "second_tensor", ".", "squeeze", "(", "expanded_dim", ")", "\n", "", "intermediate", "=", "first_tensor", "*", "weight", "\n", "return", "torch", ".", "matmul", "(", "intermediate", ",", "second_tensor", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "elif", "operation", "==", "'/'", ":", "\n", "            ", "if", "first_tensor", ".", "dim", "(", ")", ">", "4", "or", "second_tensor", ".", "dim", "(", ")", ">", "4", ":", "\n", "                ", "raise", "ValueError", "(", "\"Tensors with dim > 4 not currently supported\"", ")", "\n", "", "if", "first_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "                ", "expanded_dim", "=", "first_tensor", ".", "size", "(", ")", ".", "index", "(", "1", ")", "\n", "first_tensor", "=", "first_tensor", ".", "squeeze", "(", "expanded_dim", ")", "\n", "", "if", "second_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "                ", "expanded_dim", "=", "second_tensor", ".", "size", "(", ")", ".", "index", "(", "1", ")", "\n", "second_tensor", "=", "second_tensor", ".", "squeeze", "(", "expanded_dim", ")", "\n", "", "intermediate", "=", "first_tensor", "*", "weight", "\n", "return", "torch", ".", "matmul", "(", "intermediate", ",", "second_tensor", ".", "pow", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "elif", "operation", "==", "'+'", ":", "\n", "            ", "return", "torch", ".", "matmul", "(", "first_tensor", ",", "weight", ")", "+", "torch", ".", "matmul", "(", "second_tensor", ",", "weight", ")", "\n", "", "elif", "operation", "==", "'-'", ":", "\n", "            ", "return", "torch", ".", "matmul", "(", "first_tensor", ",", "weight", ")", "-", "torch", ".", "matmul", "(", "second_tensor", ",", "weight", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Invalid operation: \"", "+", "operation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_combined_dim": [[746, 765], ["combination.replace().replace.replace().replace", "sum", "len", "stog.utils.checks.ConfigurationError", "combination.replace().replace.replace", "nn._get_combination_dim", "combination.replace().replace.split"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_dim"], ["", "", "", "def", "get_combined_dim", "(", "combination", ":", "str", ",", "tensor_dims", ":", "List", "[", "int", "]", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    For use with :func:`combine_tensors`.  This function computes the resultant dimension when\n    calling ``combine_tensors(combination, tensors)``, when the tensor dimension is known.  This is\n    necessary for knowing the sizes of weight matrices when building models that use\n    ``combine_tensors``.\n    Parameters\n    ----------\n    combination : ``str``\n        A comma-separated list of combination pieces, like ``\"1,2,1*2\"``, specified identically to\n        ``combination`` in :func:`combine_tensors`.\n    tensor_dims : ``List[int]``\n        A list of tensor dimensions, where each dimension is from the `last axis` of the tensors\n        that will be input to :func:`combine_tensors`.\n    \"\"\"", "\n", "if", "len", "(", "tensor_dims", ")", ">", "9", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Double-digit tensor lists not currently supported\"", ")", "\n", "", "combination", "=", "combination", ".", "replace", "(", "'x'", ",", "'1'", ")", ".", "replace", "(", "'y'", ",", "'2'", ")", "\n", "return", "sum", "(", "[", "_get_combination_dim", "(", "piece", ",", "tensor_dims", ")", "for", "piece", "in", "combination", ".", "split", "(", "','", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_dim": [[767, 780], ["combination.isdigit", "nn._get_combination_dim", "nn._get_combination_dim", "int", "len", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_dim", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn._get_combination_dim"], ["", "def", "_get_combination_dim", "(", "combination", ":", "str", ",", "tensor_dims", ":", "List", "[", "int", "]", ")", "->", "int", ":", "\n", "    ", "if", "combination", ".", "isdigit", "(", ")", ":", "\n", "        ", "index", "=", "int", "(", "combination", ")", "-", "1", "\n", "return", "tensor_dims", "[", "index", "]", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "combination", ")", "!=", "3", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Invalid combination: \"", "+", "combination", ")", "\n", "", "first_tensor_dim", "=", "_get_combination_dim", "(", "combination", "[", "0", "]", ",", "tensor_dims", ")", "\n", "second_tensor_dim", "=", "_get_combination_dim", "(", "combination", "[", "2", "]", ",", "tensor_dims", ")", "\n", "operation", "=", "combination", "[", "1", "]", "\n", "if", "first_tensor_dim", "!=", "second_tensor_dim", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Tensor dims must match for operation \\\"{}\\\"\"", ".", "format", "(", "operation", ")", ")", "\n", "", "return", "first_tensor_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.logsumexp": [[782, 804], ["tensor.max", "stable_vec.exp().sum().log", "max_score.unsqueeze", "stable_vec.exp().sum", "stable_vec.exp"], "function", ["None"], ["", "", "def", "logsumexp", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", "=", "-", "1", ",", "\n", "keepdim", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    A numerically stable computation of logsumexp. This is mathematically equivalent to\n    `tensor.exp().sum(dim, keep=keepdim).log()`.  This function is typically used for summing log\n    probabilities.\n    Parameters\n    ----------\n    tensor : torch.FloatTensor, required.\n        A tensor of arbitrary size.\n    dim : int, optional (default = -1)\n        The dimension of the tensor to apply the logsumexp to.\n    keepdim: bool, optional (default = False)\n        Whether to retain a dimension of size one at the dimension we reduce over.\n    \"\"\"", "\n", "max_score", ",", "_", "=", "tensor", ".", "max", "(", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "if", "keepdim", ":", "\n", "        ", "stable_vec", "=", "tensor", "-", "max_score", "\n", "", "else", ":", "\n", "        ", "stable_vec", "=", "tensor", "-", "max_score", ".", "unsqueeze", "(", "dim", ")", "\n", "", "return", "max_score", "+", "(", "stable_vec", ".", "exp", "(", ")", ".", "sum", "(", "dim", ",", "keepdim", "=", "keepdim", ")", ")", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of": [[805, 813], ["tensor.get_device"], "function", ["None"], ["", "def", "get_device_of", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns the device of the tensor.\n    \"\"\"", "\n", "if", "not", "tensor", ".", "is_cuda", ":", "\n", "        ", "return", "-", "1", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "get_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.flatten_and_batch_shift_indices": [[814, 852], ["range", "offset_indices.view.view", "nn.get_range_vector", "offsets.unsqueeze.unsqueeze", "indices.size", "nn.get_device_of", "len", "indices.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "", "def", "flatten_and_batch_shift_indices", "(", "indices", ":", "torch", ".", "Tensor", ",", "\n", "sequence_length", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    This is a subroutine for :func:`~batched_index_select`. The given ``indices`` of size\n    ``(batch_size, d_1, ..., d_n)`` indexes into dimension 2 of a target tensor, which has size\n    ``(batch_size, sequence_length, embedding_size)``. This function returns a vector that\n    correctly indexes into the flattened target. The sequence length of the target must be\n    provided to compute the appropriate offsets.\n    .. code-block:: python\n        indices = torch.ones([2,3], dtype=torch.long)\n        # Sequence length of the target tensor.\n        sequence_length = 10\n        shifted_indices = flatten_and_batch_shift_indices(indices, sequence_length)\n        # Indices into the second element in the batch are correctly shifted\n        # to take into account that the target tensor will be flattened before\n        # the indices are applied.\n        assert shifted_indices == [1, 1, 1, 11, 11, 11]\n    Parameters\n    ----------\n    indices : ``torch.LongTensor``, required.\n    sequence_length : ``int``, required.\n        The length of the sequence the indices index into.\n        This must be the second dimension of the tensor.\n    Returns\n    -------\n    offset_indices : ``torch.LongTensor``\n    \"\"\"", "\n", "# Shape: (batch_size)", "\n", "offsets", "=", "get_range_vector", "(", "indices", ".", "size", "(", "0", ")", ",", "get_device_of", "(", "indices", ")", ")", "*", "sequence_length", "\n", "for", "_", "in", "range", "(", "len", "(", "indices", ".", "size", "(", ")", ")", "-", "1", ")", ":", "\n", "        ", "offsets", "=", "offsets", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# Shape: (batch_size, d_1, ..., d_n)", "\n", "", "offset_indices", "=", "indices", "+", "offsets", "\n", "\n", "# Shape: (batch_size * d_1 * ... * d_n)", "\n", "offset_indices", "=", "offset_indices", ".", "view", "(", "-", "1", ")", "\n", "return", "offset_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.batched_index_select": [[854, 902], ["target.view", "target.view.index_select", "flattened_target.index_select.view", "nn.flatten_and_batch_shift_indices", "target.size", "list", "target.size", "indices.size", "target.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.flatten_and_batch_shift_indices", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "batched_index_select", "(", "target", ":", "torch", ".", "Tensor", ",", "\n", "indices", ":", "torch", ".", "LongTensor", ",", "\n", "flattened_indices", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    The given ``indices`` of size ``(batch_size, d_1, ..., d_n)`` indexes into the sequence\n    dimension (dimension 2) of the target, which has size ``(batch_size, sequence_length,\n    embedding_size)``.\n    This function returns selected values in the target with respect to the provided indices, which\n    have size ``(batch_size, d_1, ..., d_n, embedding_size)``. This can use the optionally\n    precomputed :func:`~flattened_indices` with size ``(batch_size * d_1 * ... * d_n)`` if given.\n    An example use case of this function is looking up the start and end indices of spans in a\n    sequence tensor. This is used in the\n    :class:`~allennlp.models.coreference_resolution.CoreferenceResolver`. Model to select\n    contextual word representations corresponding to the start and end indices of mentions. The key\n    reason this can't be done with basic torch functions is that we want to be able to use look-up\n    tensors with an arbitrary number of dimensions (for example, in the coref model, we don't know\n    a-priori how many spans we are looking up).\n    Parameters\n    ----------\n    target : ``torch.Tensor``, required.\n        A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n        This is the tensor to be indexed.\n    indices : ``torch.LongTensor``\n        A tensor of shape (batch_size, ...), where each element is an index into the\n        ``sequence_length`` dimension of the ``target`` tensor.\n    flattened_indices : Optional[torch.Tensor], optional (default = None)\n        An optional tensor representing the result of calling :func:~`flatten_and_batch_shift_indices`\n        on ``indices``. This is helpful in the case that the indices can be flattened once and\n        cached for many batch lookups.\n    Returns\n    -------\n    selected_targets : ``torch.Tensor``\n        A tensor with shape [indices.size(), target.size(-1)] representing the embedded indices\n        extracted from the batch flattened target tensor.\n    \"\"\"", "\n", "if", "flattened_indices", "is", "None", ":", "\n", "# Shape: (batch_size * d_1 * ... * d_n)", "\n", "        ", "flattened_indices", "=", "flatten_and_batch_shift_indices", "(", "indices", ",", "target", ".", "size", "(", "1", ")", ")", "\n", "\n", "# Shape: (batch_size * sequence_length, embedding_size)", "\n", "", "flattened_target", "=", "target", ".", "view", "(", "-", "1", ",", "target", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "# Shape: (batch_size * d_1 * ... * d_n, embedding_size)", "\n", "flattened_selected", "=", "flattened_target", ".", "index_select", "(", "0", ",", "flattened_indices", ")", "\n", "selected_shape", "=", "list", "(", "indices", ".", "size", "(", ")", ")", "+", "[", "target", ".", "size", "(", "-", "1", ")", "]", "\n", "# Shape: (batch_size, d_1, ..., d_n, embedding_size)", "\n", "selected_targets", "=", "flattened_selected", ".", "view", "(", "*", "selected_shape", ")", "\n", "return", "selected_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.flattened_index_select": [[904, 932], ["target.index_select", "target.index_select.view", "indices.dim", "stog.utils.checks.ConfigurationError", "indices.view", "target.size", "indices.size", "indices.size", "indices.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "flattened_index_select", "(", "target", ":", "torch", ".", "Tensor", ",", "\n", "indices", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    The given ``indices`` of size ``(set_size, subset_size)`` specifies subsets of the ``target``\n    that each of the set_size rows should select. The `target` has size\n    ``(batch_size, sequence_length, embedding_size)``, and the resulting selected tensor has size\n    ``(batch_size, set_size, subset_size, embedding_size)``.\n    Parameters\n    ----------\n    target : ``torch.Tensor``, required.\n        A Tensor of shape (batch_size, sequence_length, embedding_size).\n    indices : ``torch.LongTensor``, required.\n        A LongTensor of shape (set_size, subset_size). All indices must be < sequence_length\n        as this tensor is an index into the sequence_length dimension of the target.\n    Returns\n    -------\n    selected : ``torch.Tensor``, required.\n        A Tensor of shape (batch_size, set_size, subset_size, embedding_size).\n    \"\"\"", "\n", "if", "indices", ".", "dim", "(", ")", "!=", "2", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Indices passed to flattened_index_select had shape {} but \"", "\n", "\"only 2 dimensional inputs are supported.\"", ".", "format", "(", "indices", ".", "size", "(", ")", ")", ")", "\n", "# Shape: (batch_size, set_size * subset_size, embedding_size)", "\n", "", "flattened_selected", "=", "target", ".", "index_select", "(", "1", ",", "indices", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "# Shape: (batch_size, set_size, subset_size, embedding_size)", "\n", "selected", "=", "flattened_selected", ".", "view", "(", "target", ".", "size", "(", "0", ")", ",", "indices", ".", "size", "(", "0", ")", ",", "indices", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "return", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector": [[934, 943], ["torch.arange", "torch.cuda.LongTensor().fill_().cumsum", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor"], "function", ["None"], ["", "def", "get_range_vector", "(", "size", ":", "int", ",", "device", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Returns a range vector with the desired size, starting at 0. The CUDA implementation\n    is meant to avoid copy data from CPU to GPU.\n    \"\"\"", "\n", "if", "device", ">", "-", "1", ":", "\n", "        ", "return", "torch", ".", "cuda", ".", "LongTensor", "(", "size", ",", "device", "=", "device", ")", ".", "fill_", "(", "1", ")", ".", "cumsum", "(", "0", ")", "-", "1", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "arange", "(", "0", ",", "size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.bucket_values": [[945, 980], ["combined_index.clamp", "distances.float().log", "math.log", "distances.float"], "function", ["None"], ["", "", "def", "bucket_values", "(", "distances", ":", "torch", ".", "Tensor", ",", "\n", "num_identity_buckets", ":", "int", "=", "4", ",", "\n", "num_total_buckets", ":", "int", "=", "10", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Places the given values (designed for distances) into ``num_total_buckets``semi-logscale\n    buckets, with ``num_identity_buckets`` of these capturing single values.\n    The default settings will bucket values into the following buckets:\n    [0, 1, 2, 3, 4, 5-7, 8-15, 16-31, 32-63, 64+].\n    Parameters\n    ----------\n    distances : ``torch.Tensor``, required.\n        A Tensor of any size, to be bucketed.\n    num_identity_buckets: int, optional (default = 4).\n        The number of identity buckets (those only holding a single value).\n    num_total_buckets : int, (default = 10)\n        The total number of buckets to bucket values into.\n    Returns\n    -------\n    A tensor of the same shape as the input, containing the indices of the buckets\n    the values were placed in.\n    \"\"\"", "\n", "# Chunk the values into semi-logscale buckets using .floor().", "\n", "# This is a semi-logscale bucketing because we divide by log(2) after taking the log.", "\n", "# We do this to make the buckets more granular in the initial range, where we expect", "\n", "# most values to fall. We then add (num_identity_buckets - 1) because we want these indices", "\n", "# to start _after_ the fixed number of buckets which we specified would only hold single values.", "\n", "logspace_index", "=", "(", "distances", ".", "float", "(", ")", ".", "log", "(", ")", "/", "math", ".", "log", "(", "2", ")", ")", ".", "floor", "(", ")", ".", "long", "(", ")", "+", "(", "num_identity_buckets", "-", "1", ")", "\n", "# create a mask for values which will go into single number buckets (i.e not a range).", "\n", "use_identity_mask", "=", "(", "distances", "<=", "num_identity_buckets", ")", ".", "long", "(", ")", "\n", "use_buckets_mask", "=", "1", "+", "(", "-", "1", "*", "use_identity_mask", ")", "\n", "# Use the original values if they are less than num_identity_buckets, otherwise", "\n", "# use the logspace indices.", "\n", "combined_index", "=", "use_identity_mask", "*", "distances", "+", "use_buckets_mask", "*", "logspace_index", "\n", "# Clamp to put anything > num_total_buckets into the final bucket.", "\n", "return", "combined_index", ".", "clamp", "(", "0", ",", "num_total_buckets", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.add_sentence_boundary_token_ids": [[981, 1033], ["mask.sum().detach().cpu().numpy", "list", "list", "tensor.new_zeros", "len", "enumerate", "mask.sum().detach().cpu", "len", "enumerate", "ValueError", "mask.sum().detach", "mask.sum"], "function", ["None"], ["", "def", "add_sentence_boundary_token_ids", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "sentence_begin_token", ":", "Any", ",", "\n", "sentence_end_token", ":", "Any", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Add begin/end of sentence tokens to the batch of sentences.\n    Given a batch of sentences with size ``(batch_size, timesteps)`` or\n    ``(batch_size, timesteps, dim)`` this returns a tensor of shape\n    ``(batch_size, timesteps + 2)`` or ``(batch_size, timesteps + 2, dim)`` respectively.\n    Returns both the new tensor and updated mask.\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        A tensor of shape ``(batch_size, timesteps)`` or ``(batch_size, timesteps, dim)``\n    mask : ``torch.Tensor``\n         A tensor of shape ``(batch_size, timesteps)``\n    sentence_begin_token: Any (anything that can be broadcast in torch for assignment)\n        For 2D input, a scalar with the <S> id. For 3D input, a tensor with length dim.\n    sentence_end_token: Any (anything that can be broadcast in torch for assignment)\n        For 2D input, a scalar with the </S> id. For 3D input, a tensor with length dim.\n    Returns\n    -------\n    tensor_with_boundary_tokens : ``torch.Tensor``\n        The tensor with the appended and prepended boundary tokens. If the input was 2D,\n        it has shape (batch_size, timesteps + 2) and if the input was 3D, it has shape\n        (batch_size, timesteps + 2, dim).\n    new_mask : ``torch.Tensor``\n        The new mask for the tensor, taking into account the appended tokens\n        marking the beginning and end of the sentence.\n    \"\"\"", "\n", "# TODO: matthewp, profile this transfer", "\n", "sequence_lengths", "=", "mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tensor_shape", "=", "list", "(", "tensor", ".", "data", ".", "shape", ")", "\n", "new_shape", "=", "list", "(", "tensor_shape", ")", "\n", "new_shape", "[", "1", "]", "=", "tensor_shape", "[", "1", "]", "+", "2", "\n", "tensor_with_boundary_tokens", "=", "tensor", ".", "new_zeros", "(", "*", "new_shape", ")", "\n", "if", "len", "(", "tensor_shape", ")", "==", "2", ":", "\n", "        ", "tensor_with_boundary_tokens", "[", ":", ",", "1", ":", "-", "1", "]", "=", "tensor", "\n", "tensor_with_boundary_tokens", "[", ":", ",", "0", "]", "=", "sentence_begin_token", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "sequence_lengths", ")", ":", "\n", "            ", "tensor_with_boundary_tokens", "[", "i", ",", "j", "+", "1", "]", "=", "sentence_end_token", "\n", "", "new_mask", "=", "(", "tensor_with_boundary_tokens", "!=", "0", ")", ".", "long", "(", ")", "\n", "", "elif", "len", "(", "tensor_shape", ")", "==", "3", ":", "\n", "        ", "tensor_with_boundary_tokens", "[", ":", ",", "1", ":", "-", "1", ",", ":", "]", "=", "tensor", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "sequence_lengths", ")", ":", "\n", "            ", "tensor_with_boundary_tokens", "[", "i", ",", "0", ",", ":", "]", "=", "sentence_begin_token", "\n", "tensor_with_boundary_tokens", "[", "i", ",", "j", "+", "1", ",", ":", "]", "=", "sentence_end_token", "\n", "", "new_mask", "=", "(", "(", "tensor_with_boundary_tokens", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ">", "0", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"add_sentence_boundary_token_ids only accepts 2D and 3D input\"", ")", "\n", "\n", "", "return", "tensor_with_boundary_tokens", ",", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.remove_sentence_boundaries": [[1034, 1071], ["mask.sum().detach().cpu().numpy", "list", "list", "tensor.new_zeros", "tensor.new_zeros", "enumerate", "mask.sum().detach().cpu", "mask.sum().detach", "mask.sum"], "function", ["None"], ["", "def", "remove_sentence_boundaries", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Remove begin/end of sentence embeddings from the batch of sentences.\n    Given a batch of sentences with size ``(batch_size, timesteps, dim)``\n    this returns a tensor of shape ``(batch_size, timesteps - 2, dim)`` after removing\n    the beginning and end sentence markers.  The sentences are assumed to be padded on the right,\n    with the beginning of each sentence assumed to occur at index 0 (i.e., ``mask[:, 0]`` is assumed\n    to be 1).\n    Returns both the new tensor and updated mask.\n    This function is the inverse of ``add_sentence_boundary_token_ids``.\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        A tensor of shape ``(batch_size, timesteps, dim)``\n    mask : ``torch.Tensor``\n         A tensor of shape ``(batch_size, timesteps)``\n    Returns\n    -------\n    tensor_without_boundary_tokens : ``torch.Tensor``\n        The tensor after removing the boundary tokens of shape ``(batch_size, timesteps - 2, dim)``\n    new_mask : ``torch.Tensor``\n        The new mask for the tensor of shape ``(batch_size, timesteps - 2)``.\n    \"\"\"", "\n", "# TODO: matthewp, profile this transfer", "\n", "sequence_lengths", "=", "mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tensor_shape", "=", "list", "(", "tensor", ".", "data", ".", "shape", ")", "\n", "new_shape", "=", "list", "(", "tensor_shape", ")", "\n", "new_shape", "[", "1", "]", "=", "tensor_shape", "[", "1", "]", "-", "2", "\n", "tensor_without_boundary_tokens", "=", "tensor", ".", "new_zeros", "(", "*", "new_shape", ")", "\n", "new_mask", "=", "tensor", ".", "new_zeros", "(", "(", "new_shape", "[", "0", "]", ",", "new_shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "sequence_lengths", ")", ":", "\n", "        ", "if", "j", ">", "2", ":", "\n", "            ", "tensor_without_boundary_tokens", "[", "i", ",", ":", "(", "j", "-", "2", ")", ",", ":", "]", "=", "tensor", "[", "i", ",", "1", ":", "(", "j", "-", "1", ")", ",", ":", "]", "\n", "new_mask", "[", "i", ",", ":", "(", "j", "-", "2", ")", "]", "=", "1", "\n", "\n", "", "", "return", "tensor_without_boundary_tokens", ",", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.add_positional_features": [[1073, 1121], ["tensor.size", "get_range_vector().data.float", "get_range_vector().data.float", "torch.cat", "math.log", "float", "torch.exp", "get_range_vector().data.float.unsqueeze", "inverse_timescales.unsqueeze", "torch.cat", "torch.cat.unsqueeze", "torch.sin", "torch.cos", "nn.get_range_vector", "nn.get_range_vector", "float", "float", "torch.cat.new_zeros", "nn.get_device_of", "nn.get_device_of"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of"], ["", "def", "add_positional_features", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "min_timescale", ":", "float", "=", "1.0", ",", "\n", "max_timescale", ":", "float", "=", "1.0e4", ")", ":", "\n", "# pylint: disable=line-too-long", "\n", "    ", "\"\"\"\n    Implements the frequency-based positional encoding described\n    in `Attention is all you Need\n    <https://www.semanticscholar.org/paper/Attention-Is-All-You-Need-Vaswani-Shazeer/0737da0767d77606169cbf4187b83e1ab62f6077>`_ .\n    Adds sinusoids of different frequencies to a ``Tensor``. A sinusoid of a\n    different frequency and phase is added to each dimension of the input ``Tensor``.\n    This allows the attention heads to use absolute and relative positions.\n    The number of timescales is equal to hidden_dim / 2 within the range\n    (min_timescale, max_timescale). For each timescale, the two sinusoidal\n    signals sin(timestep / timescale) and cos(timestep / timescale) are\n    generated and concatenated along the hidden_dim dimension.\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        a Tensor with shape (batch_size, timesteps, hidden_dim).\n    min_timescale : ``float``, optional (default = 1.0)\n        The smallest timescale to use.\n    max_timescale : ``float``, optional (default = 1.0e4)\n        The largest timescale to use.\n    Returns\n    -------\n    The input tensor augmented with the sinusoidal frequencies.\n    \"\"\"", "\n", "_", ",", "timesteps", ",", "hidden_dim", "=", "tensor", ".", "size", "(", ")", "\n", "\n", "timestep_range", "=", "get_range_vector", "(", "timesteps", ",", "get_device_of", "(", "tensor", ")", ")", ".", "data", ".", "float", "(", ")", "\n", "# We're generating both cos and sin frequencies,", "\n", "# so half for each.", "\n", "num_timescales", "=", "hidden_dim", "//", "2", "\n", "timescale_range", "=", "get_range_vector", "(", "num_timescales", ",", "get_device_of", "(", "tensor", ")", ")", ".", "data", ".", "float", "(", ")", "\n", "\n", "log_timescale_increments", "=", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "float", "(", "num_timescales", "-", "1", ")", "\n", "inverse_timescales", "=", "min_timescale", "*", "torch", ".", "exp", "(", "timescale_range", "*", "-", "log_timescale_increments", ")", "\n", "\n", "# Broadcasted multiplication - shape (timesteps, num_timescales)", "\n", "scaled_time", "=", "timestep_range", ".", "unsqueeze", "(", "1", ")", "*", "inverse_timescales", ".", "unsqueeze", "(", "0", ")", "\n", "# shape (timesteps, 2 * num_timescales)", "\n", "sinusoids", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "scaled_time", ")", ",", "torch", ".", "cos", "(", "scaled_time", ")", "]", ",", "1", ")", "\n", "if", "hidden_dim", "%", "2", "!=", "0", ":", "\n", "# if the number of dimensions is odd, the cos and sin", "\n", "# timescales had size (hidden_dim - 1) / 2, so we need", "\n", "# to add a row of zeros to make up the difference.", "\n", "        ", "sinusoids", "=", "torch", ".", "cat", "(", "[", "sinusoids", ",", "sinusoids", ".", "new_zeros", "(", "timesteps", ",", "1", ")", "]", ",", "1", ")", "\n", "", "return", "tensor", "+", "sinusoids", ".", "unsqueeze", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.register": [[41, 53], ["stog.utils.checks.ConfigurationError"], "methods", ["None"], ["@", "classmethod", "\n", "def", "register", "(", "cls", ":", "Type", "[", "T", "]", ",", "name", ":", "str", ")", ":", "\n", "        ", "registry", "=", "Registrable", ".", "_registry", "[", "cls", "]", "\n", "def", "add_subclass_to_registry", "(", "subclass", ":", "Type", "[", "T", "]", ")", ":", "\n", "# Add to registry, raise an error if key has already been used.", "\n", "            ", "if", "name", "in", "registry", ":", "\n", "                ", "message", "=", "\"Cannot register %s as %s; name already in use for %s\"", "%", "(", "\n", "name", ",", "cls", ".", "__name__", ",", "registry", "[", "name", "]", ".", "__name__", ")", "\n", "raise", "ConfigurationError", "(", "message", ")", "\n", "", "registry", "[", "name", "]", "=", "subclass", "\n", "return", "subclass", "\n", "", "return", "add_subclass_to_registry", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.by_name": [[54, 60], ["logger.info", "Registrable._registry[].get", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "@", "classmethod", "\n", "def", "by_name", "(", "cls", ":", "Type", "[", "T", "]", ",", "name", ":", "str", ")", "->", "Type", "[", "T", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"instantiating registered subclass {name} of {cls}\"", ")", "\n", "if", "name", "not", "in", "Registrable", ".", "_registry", "[", "cls", "]", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"%s is not a registered name for %s\"", "%", "(", "name", ",", "cls", ".", "__name__", ")", ")", "\n", "", "return", "Registrable", ".", "_registry", "[", "cls", "]", ".", "get", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.list_available": [[61, 74], ["list", "Registrable._registry[].keys", "stog.utils.checks.ConfigurationError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "list_available", "(", "cls", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"List default first if it exists\"\"\"", "\n", "keys", "=", "list", "(", "Registrable", ".", "_registry", "[", "cls", "]", ".", "keys", "(", ")", ")", "\n", "default", "=", "cls", ".", "default_implementation", "\n", "\n", "if", "default", "is", "None", ":", "\n", "            ", "return", "keys", "\n", "", "elif", "default", "not", "in", "keys", ":", "\n", "            ", "message", "=", "\"Default implementation %s is not registered\"", "%", "default", "\n", "raise", "ConfigurationError", "(", "message", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "default", "]", "+", "[", "k", "for", "k", "in", "keys", "if", "k", "!=", "default", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.time.time_to_str": [[4, 12], ["datetime.datetime.fromtimestamp"], "function", ["None"], ["def", "time_to_str", "(", "timestamp", ":", "int", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Convert seconds past Epoch to human readable string.\n    \"\"\"", "\n", "datetimestamp", "=", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "timestamp", ")", "\n", "return", "'{:04d}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}'", ".", "format", "(", "\n", "datetimestamp", ".", "year", ",", "datetimestamp", ".", "month", ",", "datetimestamp", ".", "day", ",", "\n", "datetimestamp", ".", "hour", ",", "datetimestamp", ".", "minute", ",", "datetimestamp", ".", "second", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.time.str_to_time": [[15, 21], ["datetime.datetime", "int", "time_str.split"], "function", ["None"], ["", "def", "str_to_time", "(", "time_str", ":", "str", ")", "->", "datetime", ".", "datetime", ":", "\n", "    ", "\"\"\"\n    Convert human readable string to datetime.datetime.\n    \"\"\"", "\n", "pieces", "=", "[", "int", "(", "piece", ")", "for", "piece", "in", "time_str", ".", "split", "(", "'-'", ")", "]", "\n", "return", "datetime", ".", "datetime", "(", "*", "pieces", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.exception_hook.ExceptionHook.__call__": [[3, 8], ["exception_hook.ExceptionHook.instance", "ultratb.FormattedTB"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.instance"], ["def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "instance", "is", "None", ":", "\n", "            ", "from", "IPython", ".", "core", "import", "ultratb", "\n", "self", ".", "instance", "=", "ultratb", ".", "FormattedTB", "(", "mode", "=", "\"Plain\"", ",", "color_scheme", "=", "\"Linux\"", ",", "call_pdb", "=", "1", ")", "\n", "", "return", "self", ".", "instance", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.is_abstract_token": [[15, 17], ["re.search", "re.search"], "function", ["None"], ["def", "is_abstract_token", "(", "token", ")", ":", "\n", "    ", "return", "re", ".", "search", "(", "r'^([A-Z]+_)+\\d+$'", ",", "token", ")", "or", "re", ".", "search", "(", "r'^\\d0*$'", ",", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.is_english_punct": [[19, 21], ["re.search"], "function", ["None"], ["", "def", "is_english_punct", "(", "c", ")", ":", "\n", "    ", "return", "re", ".", "search", "(", "r'^[,.?!:;\"\\'-(){}\\[\\]]$'", ",", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.find_similar_token": [[23, 41], ["re.sub", "enumerate"], "function", ["None"], ["", "def", "find_similar_token", "(", "token", ",", "tokens", ")", ":", "\n", "    ", "token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "# .lower())", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "if", "token", "==", "t", ":", "\n", "            ", "return", "tokens", "[", "i", "]", "\n", "# t = t.lower()", "\n", "# if (token == t or", "\n", "#     (t.startswith(token) and len(token) > 3) or", "\n", "#     token + 'd' == t or", "\n", "#     token + 'ed' == t or", "\n", "#     re.sub('ly$', 'le', t) == token or", "\n", "#     re.sub('tive$', 'te', t) == token or", "\n", "#     re.sub('tion$', 'te', t) == token or", "\n", "#     re.sub('ied$', 'y', t) == token or", "\n", "#     re.sub('ly$', '', t) == token", "\n", "# ):", "\n", "#     return tokens[i]", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.namespace_match": [[43, 57], ["namespace.endswith"], "function", ["None"], ["", "def", "namespace_match", "(", "pattern", ":", "str", ",", "namespace", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Adopted from AllenNLP:\n        https://github.com/allenai/allennlp/blob/v0.6.1/allennlp/common/util.py#L164\n\n    Matches a namespace pattern against a namespace string.  For example, ``*tags`` matches\n    ``passage_tags`` and ``question_tags`` and ``tokens`` matches ``tokens`` but not\n    ``stemmed_tokens``.\n    \"\"\"", "\n", "if", "pattern", "[", "0", "]", "==", "'*'", "and", "namespace", ".", "endswith", "(", "pattern", "[", "1", ":", "]", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "pattern", "==", "namespace", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length": [[59, 101], ["range", "len", "padded_sequence.append", "padded_sequence.insert", "default_value", "default_value"], "function", ["None"], ["", "def", "pad_sequence_to_length", "(", "sequence", ":", "List", ",", "\n", "desired_length", ":", "int", ",", "\n", "default_value", ":", "Callable", "[", "[", "]", ",", "Any", "]", "=", "lambda", ":", "0", ",", "\n", "padding_on_right", ":", "bool", "=", "True", ")", "->", "List", ":", "\n", "    ", "\"\"\"\n    Take a list of objects and pads it to the desired length, returning the padded list.  The\n    original list is not modified.\n\n    Parameters\n    ----------\n    sequence : List\n        A list of objects to be padded.\n\n    desired_length : int\n        Maximum length of each sequence. Longer sequences are truncated to this length, and\n        shorter ones are padded to it.\n\n    default_value: Callable, default=lambda: 0\n        Callable that outputs a default value (of any type) to use as padding values.  This is\n        a lambda to avoid using the same object when the default value is more complex, like a\n        list.\n\n    padding_on_right : bool, default=True\n        When we add padding tokens (or truncate the sequence), should we do it on the right or\n        the left?\n\n    Returns\n    -------\n    padded_sequence : List\n    \"\"\"", "\n", "# Truncates the sequence to the desired length.", "\n", "if", "padding_on_right", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", ":", "desired_length", "]", "\n", "", "else", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", "-", "desired_length", ":", "]", "\n", "# Continues to pad with default_value() until we reach the desired length.", "\n", "", "for", "_", "in", "range", "(", "desired_length", "-", "len", "(", "padded_sequence", ")", ")", ":", "\n", "        ", "if", "padding_on_right", ":", "\n", "            ", "padded_sequence", ".", "append", "(", "default_value", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "padded_sequence", ".", "insert", "(", "0", ",", "default_value", "(", ")", ")", "\n", "", "", "return", "padded_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.sanitize": [[102, 134], ["isinstance", "isinstance", "x.cpu().tolist", "isinstance", "x.tolist", "isinstance", "x.cpu", "x.item", "isinstance", "isinstance", "string.sanitize", "isinstance", "x.items", "string.sanitize", "hasattr", "x.to_json", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.sanitize", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.sanitize"], ["", "def", "sanitize", "(", "x", ":", "Any", ")", "->", "Any", ":", "# pylint: disable=invalid-name,too-many-return-statements", "\n", "    ", "\"\"\"\n    Sanitize turns PyTorch and Numpy types into basic Python types so they\n    can be serialized into JSON.\n    \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "(", "str", ",", "float", ",", "int", ",", "bool", ")", ")", ":", "\n", "# x is already serializable", "\n", "        ", "return", "x", "\n", "", "elif", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "# tensor needs to be converted to a list (and moved to cpu if necessary)", "\n", "        ", "return", "x", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "numpy", ".", "ndarray", ")", ":", "\n", "# array needs to be converted to a list", "\n", "        ", "return", "x", ".", "tolist", "(", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "numpy", ".", "number", ")", ":", "\n", "# NumPy numbers need to be converted to Python numbers", "\n", "        ", "return", "x", ".", "item", "(", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "# Dicts need their values sanitized", "\n", "        ", "return", "{", "key", ":", "sanitize", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "# Lists and Tuples need their values sanitized", "\n", "        ", "return", "[", "sanitize", "(", "x_i", ")", "for", "x_i", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "(", "spacy", ".", "tokens", ".", "Token", ",", "allennlp", ".", "data", ".", "Token", ")", ")", ":", "\n", "# Tokens get sanitized to just their text.", "\n", "        ", "return", "x", ".", "text", "\n", "", "elif", "x", "is", "None", ":", "\n", "        ", "return", "\"None\"", "\n", "", "elif", "hasattr", "(", "x", ",", "'to_json'", ")", ":", "\n", "        ", "return", "x", ".", "to_json", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Cannot sanitize {x} of type {type(x)}. \"", "\n", "\"If this is your own custom class, add a `to_json(self)` method \"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.set_default_mininterval": [[22, 25], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "set_default_mininterval", "(", "value", ":", "float", ")", "->", "None", ":", "\n", "        ", "Tqdm", ".", "default_mininterval", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.set_slower_interval": [[26, 38], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "set_slower_interval", "(", "use_slower_interval", ":", "bool", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        If ``use_slower_interval`` is ``True``, we will dramatically slow down ``tqdm's`` default\n        output rate.  ``tqdm's`` default output rate is great for interactively watching progress,\n        but it is not great for log files.  You might want to set this if you are primarily going\n        to be looking at output through log files, not the terminal.\n        \"\"\"", "\n", "if", "use_slower_interval", ":", "\n", "            ", "Tqdm", ".", "default_mininterval", "=", "10.0", "\n", "", "else", ":", "\n", "            ", "Tqdm", ".", "default_mininterval", "=", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm": [[39, 47], ["tqdm.tqdm.tqdm"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm"], ["", "", "@", "staticmethod", "\n", "def", "tqdm", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_kwargs", "=", "{", "\n", "'mininterval'", ":", "Tqdm", ".", "default_mininterval", ",", "\n", "**", "kwargs", "\n", "}", "\n", "\n", "return", "_tqdm", "(", "*", "args", ",", "**", "new_kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of": [[7, 13], ["iter", "list", "itertools.islice"], "function", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.ensure_list": [[14, 23], ["isinstance", "list"], "function", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.is_lazy": [[24, 30], ["isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.add_noise_to_dict_values": [[31, 43], ["dictionary.items", "random.uniform"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], []], "home.repos.pwc.inspect_result.jcyk_gtos.utils.extract_tokens_from_amr.extract_amr_token": [[6, 11], ["stog.data.dataset_readers.AbstractMeaningRepresentationDatasetReader", "stog.data.dataset_readers.AbstractMeaningRepresentationDatasetReader.read"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["def", "extract_amr_token", "(", "file_path", ")", ":", "\n", "    ", "dataset_reader", "=", "AbstractMeaningRepresentationDatasetReader", "(", ")", "\n", "for", "instance", "in", "dataset_reader", ".", "read", "(", "file_path", ")", ":", "\n", "        ", "amr_tokens", "=", "instance", ".", "fields", "[", "\"amr_tokens\"", "]", "[", "\"decoder_tokens\"", "]", "\n", "yield", "\" \"", ".", "join", "(", "amr_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.archive_model": [[36, 64], ["os.path.join", "os.path.join", "os.path.join", "logger.info", "os.path.exists", "logger.error", "os.path.exists", "logger.error", "tarfile.open", "archive.add", "archive.add", "archive.add", "os.path.join"], "function", ["None"], ["def", "archive_model", "(", "serialization_dir", ":", "str", ",", "weights", ":", "str", "=", "_DEFAULT_WEIGHTS", ")", ":", "\n", "    ", "\"\"\"\n    Archive the model weights, its training configuration, and its\n    vocabulary to `model.tar.gz`. Include the additional ``files_to_archive``\n    if provided.\n    Parameters\n    ----------\n    serialization_dir: ``str``\n        The directory where the weights and vocabulary are written out.\n    weights: ``str``, optional (default=_DEFAULT_WEIGHTS)\n        Which weights file to include in the archive. The default is ``best.th``.\n    \"\"\"", "\n", "weights_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "weights", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "weights_file", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"weights file %s does not exist, unable to archive model\"", ",", "weights_file", ")", "\n", "return", "\n", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config_file", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"config file %s does not exist, unable to archive model\"", ",", "config_file", ")", "\n", "\n", "", "archive_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"model.tar.gz\"", ")", "\n", "logger", ".", "info", "(", "\"archiving weights and vocabulary to %s\"", ",", "archive_file", ")", "\n", "with", "tarfile", ".", "open", "(", "archive_file", ",", "'w:gz'", ")", "as", "archive", ":", "\n", "        ", "archive", ".", "add", "(", "config_file", ",", "arcname", "=", "CONFIG_NAME", ")", "\n", "archive", ".", "add", "(", "weights_file", ",", "arcname", "=", "_WEIGHTS_NAME", ")", "\n", "archive", ".", "add", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"vocabulary\"", ")", ",", "\n", "arcname", "=", "\"vocabulary\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.load_archive": [[66, 119], ["stog.utils.file.cached_path", "os.path.isdir", "stog.utils.params.Params.from_file", "stog.models.model.Model.load", "Archive", "logger.info", "logger.info", "tempfile.mkdtemp", "logger.info", "os.path.join", "os.path.join", "shutil.rmtree", "tarfile.open", "archive.extractall"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.from_file", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "", "def", "load_archive", "(", "archive_file", ":", "str", ",", "\n", "device", "=", "None", ",", "\n", "weights_file", ":", "str", "=", "None", ")", "->", "Archive", ":", "\n", "    ", "\"\"\"\n    Instantiates an Archive from an archived `tar.gz` file.\n    Parameters\n    ----------\n    archive_file: ``str``\n        The archive file to load the model from.\n    weights_file: ``str``, optional (default = None)\n        The weights file to use.  If unspecified, weights.th in the archive_file will be used.\n    device: ``None`` or PyTorch device object.\n    \"\"\"", "\n", "# redirect to the cache, if necessary", "\n", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ")", "\n", "\n", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "        ", "logger", ".", "info", "(", "f\"loading archive file {archive_file}\"", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "f\"loading archive file {archive_file} from cache at {resolved_archive_file}\"", ")", "\n", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "        ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "        ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "f\"extracting archive file {resolved_archive_file} to temp dir {tempdir}\"", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "            ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "\n", "", "serialization_dir", "=", "tempdir", "\n", "\n", "# Load config", "\n", "", "config", "=", "Params", ".", "from_file", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", ")", "\n", "config", ".", "loading_from_archive", "=", "True", "\n", "\n", "if", "weights_file", ":", "\n", "        ", "weights_path", "=", "weights_file", "\n", "", "else", ":", "\n", "        ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_WEIGHTS_NAME", ")", "\n", "\n", "# Instantiate model. Use a duplicate of the config, as it will get consumed.", "\n", "", "model", "=", "Model", ".", "load", "(", "config", ",", "\n", "weights_file", "=", "weights_path", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "device", "=", "device", ")", "\n", "\n", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "        ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "\n", "", "return", "Archive", "(", "model", "=", "model", ",", "config", "=", "config", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.set_seed": [[24, 52], ["logger.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "params", ")", ":", "\n", "    ", "\"\"\"\n    Adopted from AllenNLP:\n        https://github.com/allenai/allennlp/blob/606a61abf04e3108949022ae1bcea975b2adb560/allennlp/common/util.py\n\n    Sets random seeds for reproducible experiments. This may not work as expected\n    if you use this from within a python project in which you have already imported Pytorch.\n    If you use the scripts/run_model.py entry point to training models with this library,\n    your experiments should be reasonably reproducible. If you are using this from your own\n    project, you will want to call this function before importing Pytorch. Complete determinism\n    is very difficult to achieve with libraries doing optimized linear algebra due to massively\n    parallel execution, which is exacerbated by using GPUs.\n    \"\"\"", "\n", "seed", ",", "numpy_seed", ",", "torch_seed", "=", "params", "[", "'seed'", "]", ",", "params", "[", "'numpy_seed'", "]", ",", "params", "[", "'torch_seed'", "]", "\n", "if", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "", "if", "numpy_seed", "is", "not", "None", ":", "\n", "        ", "numpy", ".", "random", ".", "seed", "(", "numpy_seed", ")", "\n", "", "if", "torch_seed", "is", "not", "None", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "torch_seed", ")", "\n", "# Seed all GPUs with the same seed if available.", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "torch_seed", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "'Init random seeds => tseed: {seed} numpy_seed: {numpy_seed} torch_seed: {torch_seed}'", ".", "format", "(", "\n", "seed", "=", "seed", ",", "\n", "numpy_seed", "=", "numpy_seed", ",", "\n", "torch_seed", "=", "torch_seed", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.prepare_global_logging": [[55, 81], ["stog.utils.tqdm.Tqdm.set_slower_interval", "os.path.join", "stog.utils.logging.TeeLogger", "stog.utils.logging.TeeLogger", "stog.utils.logging.init_logger", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.set_slower_interval", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.init_logger"], ["", "def", "prepare_global_logging", "(", "params", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    This function configures 3 global logging attributes - streaming stdout and stderr\n    to a file as well as the terminal, setting the formatting for the python logging\n    library and setting the interval frequency for the Tqdm progress bar.\n    Note that this function does not set the logging level, which is set in ``allennlp/run.py``.\n    Parameters\n    ----------\n    serializezation_dir : ``str``, required.\n        The directory to stream logs to.\n    file_friendly_logging : ``bool``, required.\n        Whether logs should clean the output to prevent carridge returns\n        (used to update progress bars on a single terminal line).\n    \"\"\"", "\n", "serialization_dir", "=", "params", "[", "'serialization_dir'", "]", "\n", "file_friendly_logging", "=", "params", "[", "'file_friendly_logging'", "]", "\n", "Tqdm", ".", "set_slower_interval", "(", "file_friendly_logging", ")", "\n", "std_out_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"stdout.log\"", ")", "\n", "sys", ".", "stdout", "=", "TeeLogger", "(", "std_out_file", ",", "# type: ignore", "\n", "sys", ".", "stdout", ",", "\n", "file_friendly_logging", ")", "\n", "sys", ".", "stderr", "=", "TeeLogger", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"stderr.log\"", ")", ",", "# type: ignore", "\n", "sys", ".", "stderr", ",", "\n", "file_friendly_logging", ")", "\n", "\n", "logging", ".", "init_logger", "(", "log_file", "=", "std_out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.check_for_gpu": [[83, 87], ["stog.utils.checks.ConfigurationError", "torch.cuda.device_count"], "function", ["None"], ["", "def", "check_for_gpu", "(", "params", ")", "->", "object", ":", "\n", "    ", "device_id", "=", "params", "[", "'cuda_device'", "]", "\n", "if", "device_id", "is", "not", "None", "and", "device_id", ">=", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"Experiment specified a GPU but none is available;\"", "\n", "\" if you want to run on CPU use the override\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.device_mapping": [[91, 103], ["storage.cuda"], "function", ["None"], ["", "", "def", "device_mapping", "(", "cuda_device", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    In order to `torch.load()` a GPU-trained model onto a CPU (or specific GPU),\n    you have to supply a `map_location` function. Call this with\n    the desired `cuda_device` to get the function that `torch.load()` needs.\n    \"\"\"", "\n", "def", "inner_device_mapping", "(", "storage", ":", "torch", ".", "Storage", ",", "location", ")", "->", "torch", ".", "Storage", ":", "# pylint: disable=unused-argument", "\n", "        ", "if", "cuda_device", ">=", "0", ":", "\n", "            ", "return", "storage", ".", "cuda", "(", "cuda_device", ")", "\n", "", "else", ":", "\n", "            ", "return", "storage", "\n", "", "", "return", "inner_device_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.peak_memory_mb": [[105, 127], ["resource.getrusage"], "function", ["None"], ["", "def", "peak_memory_mb", "(", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Get peak memory usage for this process, as measured by\n    max-resident-set size:\n    https://unix.stackexchange.com/questions/30940/getrusage-system-call-what-is-maximum-resident-set-size\n    Only works on OSX and Linux, returns 0.0 otherwise.\n    \"\"\"", "\n", "if", "resource", "is", "None", "or", "sys", ".", "platform", "not", "in", "(", "'linux'", ",", "'darwin'", ")", ":", "\n", "        ", "return", "0.0", "\n", "\n", "# TODO(joelgrus): For whatever, our pinned version 0.521 of mypy does not like", "\n", "# next line, but later versions (e.g. 0.530) are fine with it. Once we get that", "\n", "# figured out, remove the type: ignore.", "\n", "", "peak", "=", "resource", ".", "getrusage", "(", "resource", ".", "RUSAGE_SELF", ")", ".", "ru_maxrss", "# type: ignore", "\n", "\n", "if", "sys", ".", "platform", "==", "'darwin'", ":", "\n", "# On OSX the result is in bytes.", "\n", "        ", "return", "peak", "/", "1_000_000", "\n", "\n", "", "else", ":", "\n", "# On Linux the result is in kilobytes.", "\n", "        ", "return", "peak", "/", "1_000", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.gpu_memory_mb": [[129, 155], ["subprocess.check_output", "int", "logger.exception", "subprocess.check_output.strip().split", "enumerate", "subprocess.check_output.strip"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "", "def", "gpu_memory_mb", "(", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Get the current GPU memory usage.\n    Based on https://discuss.pytorch.org/t/access-gpu-memory-usage-in-pytorch/3192/4\n    Returns\n    -------\n    ``Dict[int, int]``\n        Keys are device ids as integers.\n        Values are memory usage as integers in MB.\n        Returns an empty ``dict`` if GPUs are not available.\n    \"\"\"", "\n", "# pylint: disable=bare-except", "\n", "try", ":", "\n", "        ", "result", "=", "subprocess", ".", "check_output", "(", "[", "'nvidia-smi'", ",", "'--query-gpu=memory.used'", ",", "\n", "'--format=csv,nounits,noheader'", "]", ",", "\n", "encoding", "=", "'utf-8'", ")", "\n", "gpu_memory", "=", "[", "int", "(", "x", ")", "for", "x", "in", "result", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "]", "\n", "return", "{", "gpu", ":", "memory", "for", "gpu", ",", "memory", "in", "enumerate", "(", "gpu_memory", ")", "}", "\n", "", "except", "FileNotFoundError", ":", "\n", "# `nvidia-smi` doesn't exist, assume that means no GPU.", "\n", "        ", "return", "{", "}", "\n", "", "except", ":", "\n", "# Catch *all* exceptions, because this memory check is a nice-to-have", "\n", "# and we'd never want a training run to fail because of it.", "\n", "        ", "logger", ".", "exception", "(", "\"unable to check gpu_memory_mb(), continuing\"", ")", "\n", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.get_frozen_and_tunable_parameter_names": [[157, 166], ["model.named_parameters", "frozen_parameter_names.append", "tunable_parameter_names.append"], "function", ["None"], ["", "", "def", "get_frozen_and_tunable_parameter_names", "(", "model", ":", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "frozen_parameter_names", "=", "[", "]", "\n", "tunable_parameter_names", "=", "[", "]", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "parameter", ".", "requires_grad", ":", "\n", "            ", "frozen_parameter_names", ".", "append", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "tunable_parameter_names", ".", "append", "(", "name", ")", "\n", "", "", "return", "[", "frozen_parameter_names", ",", "tunable_parameter_names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.has_tensor": [[168, 181], ["isinstance", "isinstance", "any", "isinstance", "any", "environment.has_tensor", "obj.values", "environment.has_tensor"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.has_tensor", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.has_tensor"], ["", "def", "has_tensor", "(", "obj", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Given a possibly complex data structure,\n    check if it has any torch.Tensors in it.\n    \"\"\"", "\n", "if", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "isinstance", "(", "obj", ",", "dict", ")", ":", "\n", "        ", "return", "any", "(", "has_tensor", "(", "value", ")", "for", "value", "in", "obj", ".", "values", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "any", "(", "has_tensor", "(", "item", ")", "for", "item", "in", "obj", ")", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.move_to_device": [[183, 200], ["environment.has_tensor", "isinstance", "obj.to", "isinstance", "isinstance", "environment.move_to_device", "isinstance", "obj.items", "environment.move_to_device", "tuple", "environment.move_to_device"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.has_tensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device"], ["", "", "def", "move_to_device", "(", "obj", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Given a structure (possibly) containing Tensors on the CPU,\n    move all the Tensors to the specified GPU (or do nothing, if they should be on the CPU).\n    \"\"\"", "\n", "if", "not", "has_tensor", "(", "obj", ")", ":", "\n", "        ", "return", "obj", "\n", "", "elif", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "obj", ".", "to", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "dict", ")", ":", "\n", "        ", "return", "{", "key", ":", "move_to_device", "(", "value", ",", "device", ")", "for", "key", ",", "value", "in", "obj", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "obj", ",", "list", ")", ":", "\n", "        ", "return", "[", "move_to_device", "(", "item", ",", "device", ")", "for", "item", "in", "obj", "]", "\n", "", "elif", "isinstance", "(", "obj", ",", "tuple", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "move_to_device", "(", "item", ",", "device", ")", "for", "item", "in", "obj", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.occupy_gpu": [[201, 206], ["torch.cuda.LongTensor"], "function", ["None"], ["", "", "def", "occupy_gpu", "(", "device", ")", ":", "\n", "    ", "\"\"\"\n    To prevent somebody taking you gpu if you are not using them.\n    \"\"\"", "\n", "torch", ".", "cuda", ".", "LongTensor", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.__init__": [[23, 26], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_dataset_reader", "=", "dataset_reader", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.load_line": [[27, 33], ["json.loads"], "methods", ["None"], ["", "def", "load_line", "(", "self", ",", "line", ":", "str", ")", "->", "JsonDict", ":", "# pylint: disable=no-self-use", "\n", "        ", "\"\"\"\n        If your inputs are not in JSON-lines format (e.g. you have a CSV)\n        you can override this function to parse them correctly.\n        \"\"\"", "\n", "return", "json", ".", "loads", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.dump_line": [[34, 40], ["json.dumps"], "methods", ["None"], ["", "def", "dump_line", "(", "self", ",", "outputs", ":", "JsonDict", ")", "->", "str", ":", "# pylint: disable=no-self-use", "\n", "        ", "\"\"\"\n        If you don't want your outputs in JSON-lines format\n        you can override this function to output them differently.\n        \"\"\"", "\n", "return", "json", ".", "dumps", "(", "outputs", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_json": [[41, 44], ["predictor.Predictor._json_to_instance", "predictor.Predictor.predict_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor._json_to_instance", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_instance"], ["", "def", "predict_json", "(", "self", ",", "inputs", ":", "JsonDict", ")", "->", "JsonDict", ":", "\n", "        ", "instance", "=", "self", ".", "_json_to_instance", "(", "inputs", ")", "\n", "return", "self", ".", "predict_instance", "(", "instance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_instance": [[45, 48], ["predictor.Predictor._model.forward_on_instance", "stog.utils.string.sanitize"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.forward_on_instance", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.sanitize"], ["", "def", "predict_instance", "(", "self", ",", "instance", ":", "Instance", ")", "->", "JsonDict", ":", "\n", "        ", "outputs", "=", "self", ".", "_model", ".", "forward_on_instance", "(", "instance", ")", "\n", "return", "sanitize", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor._json_to_instance": [[49, 56], ["None"], "methods", ["None"], ["", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Converts a JSON object into an :class:`~allennlp.data.instance.Instance`\n        and a ``JsonDict`` of information which the ``Predictor`` should pass through,\n        such as tokenised inputs.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_batch_json": [[57, 60], ["predictor.Predictor._batch_json_to_instances", "predictor.Predictor.predict_batch_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor._batch_json_to_instances", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.predict_batch_instance"], ["", "def", "predict_batch_json", "(", "self", ",", "inputs", ":", "List", "[", "JsonDict", "]", ")", "->", "List", "[", "JsonDict", "]", ":", "\n", "        ", "instances", "=", "self", ".", "_batch_json_to_instances", "(", "inputs", ")", "\n", "return", "self", ".", "predict_batch_instance", "(", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_batch_instance": [[61, 64], ["predictor.Predictor._model.forward_on_instances", "stog.utils.string.sanitize"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.forward_on_instances", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.sanitize"], ["", "def", "predict_batch_instance", "(", "self", ",", "instances", ":", "List", "[", "Instance", "]", ")", "->", "List", "[", "JsonDict", "]", ":", "\n", "        ", "outputs", "=", "self", ".", "_model", ".", "forward_on_instances", "(", "instances", ")", "\n", "return", "sanitize", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor._batch_json_to_instances": [[65, 78], ["instances.append", "predictor.Predictor._json_to_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor._json_to_instance"], ["", "def", "_batch_json_to_instances", "(", "self", ",", "json_dicts", ":", "List", "[", "JsonDict", "]", ")", "->", "List", "[", "Instance", "]", ":", "\n", "        ", "\"\"\"\n        Converts a list of JSON objects into a list of :class:`~allennlp.data.instance.Instance`s.\n        By default, this expects that a \"batch\" consists of a list of JSON blobs which would\n        individually be predicted by :func:`predict_json`. In order to use this method for\n        batch prediction, :func:`_json_to_instance` should be implemented by the subclass, or\n        if the instances have some dependency on each other, this method should be overridden\n        directly.\n        \"\"\"", "\n", "instances", "=", "[", "]", "\n", "for", "json_dict", "in", "json_dicts", ":", "\n", "            ", "instances", ".", "append", "(", "self", ".", "_json_to_instance", "(", "json_dict", ")", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.from_path": [[79, 98], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_path", "(", "cls", ",", "archive_path", ":", "str", ",", "predictor_name", ":", "str", "=", "None", ")", "->", "'Predictor'", ":", "\n", "        ", "\"\"\"\n        Instantiate a :class:`Predictor` from an archive path.\n\n        If you need more detailed configuration options, such as running the predictor on the GPU,\n        please use `from_archive`.\n\n        Parameters\n        ----------\n        archive_path The path to the archive.\n\n        Returns\n        -------\n        A Predictor instance.\n        \"\"\"", "\n", "# Comment it out for cyclic imports", "\n", "# return Predictor.from_archive(load_archive(archive_path), predictor_name)", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.from_archive": [[99, 128], ["archive.config.duplicate", "config[].get", "stog.data.dataset_builder.load_dataset_reader", "hasattr", "model.eval", "archive.config.duplicate.get().get", "config[].get", "stog.data.dataset_builder.load_dataset_reader.set_evaluation", "Predictor.by_name", "stog.utils.checks.ConfigurationError", "archive.config.duplicate.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.duplicate", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset_reader", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.set_evaluation", "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.by_name", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "@", "classmethod", "\n", "def", "from_archive", "(", "cls", ",", "archive", ",", "predictor_name", ":", "str", "=", "None", ")", "->", "'Predictor'", ":", "\n", "        ", "\"\"\"\n        Instantiate a :class:`Predictor` from an :class:`~allennlp.models.archival.Archive`;\n        that is, from the result of training a model. Optionally specify which `Predictor`\n        subclass; otherwise, the default one for the model will be used.\n        \"\"\"", "\n", "# Duplicate the config so that the config inside the archive doesn't get consumed", "\n", "config", "=", "archive", ".", "config", ".", "duplicate", "(", ")", "\n", "\n", "if", "not", "predictor_name", ":", "\n", "            ", "model_type", "=", "config", ".", "get", "(", "\"model\"", ")", ".", "get", "(", "\"model_type\"", ")", "\n", "if", "not", "model_type", "in", "DEFAULT_PREDICTORS", ":", "\n", "                ", "raise", "ConfigurationError", "(", "f\"No default predictor for model type {model_type}.\\n\"", "f\"Please specify a predictor explicitly.\"", ")", "\n", "", "predictor_name", "=", "DEFAULT_PREDICTORS", "[", "model_type", "]", "\n", "\n", "", "word_splitter", "=", "None", "\n", "if", "config", "[", "'model'", "]", ".", "get", "(", "'use_bert'", ",", "False", ")", ":", "\n", "            ", "word_splitter", "=", "config", "[", "'data'", "]", ".", "get", "(", "'word_splitter'", ",", "None", ")", "\n", "", "dataset_reader", "=", "load_dataset_reader", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"data_type\"", "]", ",", "word_splitter", "=", "word_splitter", ")", "\n", "if", "hasattr", "(", "dataset_reader", ",", "'set_evaluation'", ")", ":", "\n", "            ", "dataset_reader", ".", "set_evaluation", "(", ")", "\n", "\n", "", "model", "=", "archive", ".", "model", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "return", "Predictor", ".", "by_name", "(", "predictor_name", ")", "(", "model", ",", "dataset_reader", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.predict": [[23, 25], ["stog.STOGPredictor.predict_json"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_json"], ["def", "predict", "(", "self", ",", "source", ":", "str", ")", "->", "JsonDict", ":", "\n", "        ", "return", "self", ".", "predict_json", "(", "{", "\"source\"", ":", "source", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor._json_to_instance": [[26, 33], ["stog.STOGPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Expects JSON that looks like ``{\"source\": \"...\"}``.\n        \"\"\"", "\n", "source", "=", "json_dict", "[", "\"source\"", "]", "\n", "return", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.predict_batch_instance": [[34, 80], ["stog.STOGPredictor._model.vocab.get_vocab_size", "super().predict_batch_instance", "zip", "enumerate", "outputs.append", "head_labels.append", "dict", "nodes.append", "copy_indicators.append", "nodes.append", "copy_indicators.append", "stog.STOGPredictor._model.vocab.get_token_from_index", "copy_vocab.get_token_from_idx", "stog.STOGPredictor._model.vocab.get_token_from_index", "nodes.index", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.predict_batch_instance", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_from_idx", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "@", "overrides", "\n", "def", "predict_batch_instance", "(", "self", ",", "instances", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "gen_vocab_size", "=", "self", ".", "_model", ".", "vocab", ".", "get_vocab_size", "(", "'decoder_token_ids'", ")", "\n", "_outputs", "=", "super", "(", "STOGPredictor", ",", "self", ")", ".", "predict_batch_instance", "(", "instances", ")", "\n", "for", "instance", ",", "output", "in", "zip", "(", "instances", ",", "_outputs", ")", ":", "\n", "            ", "gold_amr", "=", "instance", ".", "fields", "[", "'amr'", "]", ".", "metadata", "\n", "copy_vocab", "=", "instance", ".", "fields", "[", "'src_copy_vocab'", "]", ".", "metadata", "\n", "node_indexes", "=", "output", "[", "'nodes'", "]", "\n", "head_indexes", "=", "output", "[", "'heads'", "]", "\n", "head_label_indexes", "=", "output", "[", "'head_labels'", "]", "\n", "corefs", "=", "output", "[", "'corefs'", "]", "\n", "\n", "nodes", "=", "[", "]", "\n", "head_labels", "=", "[", "]", "\n", "copy_indicators", "=", "[", "]", "\n", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "node_indexes", ")", ":", "\n", "# Lookup the node.", "\n", "                ", "if", "index", ">=", "gen_vocab_size", ":", "\n", "                    ", "copy_index", "=", "index", "-", "gen_vocab_size", "\n", "nodes", ".", "append", "(", "copy_vocab", ".", "get_token_from_idx", "(", "copy_index", ")", ")", "\n", "copy_indicators", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "nodes", ".", "append", "(", "self", ".", "_model", ".", "vocab", ".", "get_token_from_index", "(", "index", ",", "'decoder_token_ids'", ")", ")", "\n", "copy_indicators", ".", "append", "(", "0", ")", "\n", "# Lookup the head label.", "\n", "", "head_labels", ".", "append", "(", "self", ".", "_model", ".", "vocab", ".", "get_token_from_index", "(", "\n", "head_label_indexes", "[", "i", "]", ",", "'head_tags'", ")", ")", "\n", "\n", "", "if", "END_SYMBOL", "in", "nodes", ":", "\n", "                ", "nodes", "=", "nodes", "[", ":", "nodes", ".", "index", "(", "END_SYMBOL", ")", "]", "\n", "head_indexes", "=", "head_indexes", "[", ":", "len", "(", "nodes", ")", "]", "\n", "head_labels", "=", "head_labels", "[", ":", "len", "(", "nodes", ")", "]", "\n", "corefs", "=", "corefs", "[", ":", "len", "(", "nodes", ")", "]", "\n", "\n", "", "outputs", ".", "append", "(", "dict", "(", "\n", "nodes", "=", "nodes", ",", "\n", "heads", "=", "head_indexes", ",", "\n", "corefs", "=", "corefs", ",", "\n", "head_labels", "=", "head_labels", ",", "\n", "copy_indicators", "=", "copy_indicators", ",", "\n", "gold_amr", "=", "gold_amr", "\n", ")", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.dump_line": [[81, 97], ["stog.data.dataset_readers.amr_parsing.amr.AMRGraph.from_prediction", "str().replace", "str", "gold_graph.get_tgt_tokens"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.from_prediction", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_tgt_tokens"], ["", "@", "overrides", "\n", "def", "dump_line", "(", "self", ",", "output", ")", ":", "\n", "# return ' '.join(output['nodes']) + '\\n'", "\n", "        ", "pred_graph", "=", "AMRGraph", ".", "from_prediction", "(", "output", ")", "\n", "amr", "=", "output", "[", "'gold_amr'", "]", "\n", "gold_graph", "=", "amr", ".", "graph", "\n", "amr", ".", "graph", "=", "pred_graph", "\n", "\n", "string_to_print", "=", "str", "(", "amr", ")", ".", "replace", "(", "\n", "\"# ::save-date\"", ",", "\"# ::tgt_ref {}\\n# ::tgt_pred {}\\n# ::save-date\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "output", "[", "\"nodes\"", "]", ")", ",", "\n", "\" \"", ".", "join", "(", "gold_graph", ".", "get_tgt_tokens", "(", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "return", "string_to_print", "+", "'\\n\\n'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.decode_mst": [[6, 83], ["numpy.array", "numpy.zeros", "numpy.zeros", "range", "maximum_spanning_tree.chu_liu_edmonds", "numpy.zeros", "final_edges.items", "stog.utils.checks.ConfigurationError", "energy.max.argmax", "energy.max.max", "representatives.append", "range", "numpy.ones", "stog.utils.checks.ConfigurationError", "range"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.chu_liu_edmonds", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["def", "decode_mst", "(", "energy", ":", "numpy", ".", "ndarray", ",", "\n", "length", ":", "int", ",", "\n", "has_labels", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "numpy", ".", "ndarray", ",", "numpy", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Note: Counter to typical intuition, this function decodes the _maximum_\n    spanning tree.\n    Decode the optimal MST tree with the Chu-Liu-Edmonds algorithm for\n    maximum spanning arboresences on graphs.\n    Parameters\n    ----------\n    energy : ``numpy.ndarray``, required.\n        A tensor with shape (num_labels, timesteps, timesteps)\n        containing the energy of each edge. If has_labels is ``False``,\n        the tensor should have shape (timesteps, timesteps) instead.\n    length : ``int``, required.\n        The length of this sequence, as the energy may have come\n        from a padded batch.\n    has_labels : ``bool``, optional, (default = True)\n        Whether the graph has labels or not.\n    \"\"\"", "\n", "if", "has_labels", "and", "energy", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"The dimension of the energy array is not equal to 3.\"", ")", "\n", "", "elif", "not", "has_labels", "and", "energy", ".", "ndim", "!=", "2", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"The dimension of the energy array is not equal to 2.\"", ")", "\n", "", "input_shape", "=", "energy", ".", "shape", "\n", "max_length", "=", "input_shape", "[", "-", "1", "]", "\n", "\n", "# Our energy matrix might have been batched -", "\n", "# here we clip it to contain only non padded tokens.", "\n", "if", "has_labels", ":", "\n", "        ", "energy", "=", "energy", "[", ":", ",", ":", "length", ",", ":", "length", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energy", ".", "argmax", "(", "axis", "=", "0", ")", "\n", "energy", "=", "energy", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "energy", "=", "energy", "[", ":", "length", ",", ":", "length", "]", "\n", "label_id_matrix", "=", "None", "\n", "# get original score matrix", "\n", "", "original_score_matrix", "=", "energy", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "numpy", ".", "array", "(", "original_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "old_input", "=", "numpy", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "old_output", "=", "numpy", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "current_nodes", "=", "[", "True", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "representatives", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "\n", "for", "node1", "in", "range", "(", "length", ")", ":", "\n", "        ", "original_score_matrix", "[", "node1", ",", "node1", "]", "=", "0.0", "\n", "score_matrix", "[", "node1", ",", "node1", "]", "=", "0.0", "\n", "representatives", ".", "append", "(", "{", "node1", "}", ")", "\n", "\n", "for", "node2", "in", "range", "(", "node1", "+", "1", ",", "length", ")", ":", "\n", "            ", "old_input", "[", "node1", ",", "node2", "]", "=", "node1", "\n", "old_output", "[", "node1", ",", "node2", "]", "=", "node2", "\n", "\n", "old_input", "[", "node2", ",", "node1", "]", "=", "node2", "\n", "old_output", "[", "node2", ",", "node1", "]", "=", "node1", "\n", "\n", "", "", "final_edges", ":", "Dict", "[", "int", ",", "int", "]", "=", "{", "}", "\n", "\n", "# The main algorithm operates inplace.", "\n", "chu_liu_edmonds", "(", "length", ",", "score_matrix", ",", "current_nodes", ",", "\n", "final_edges", ",", "old_input", ",", "old_output", ",", "representatives", ")", "\n", "\n", "heads", "=", "numpy", ".", "zeros", "(", "[", "max_length", "]", ",", "numpy", ".", "int32", ")", "\n", "if", "has_labels", ":", "\n", "        ", "head_type", "=", "numpy", ".", "ones", "(", "[", "max_length", "]", ",", "numpy", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "head_type", "=", "None", "\n", "\n", "", "for", "child", ",", "parent", "in", "final_edges", ".", "items", "(", ")", ":", "\n", "        ", "heads", "[", "child", "]", "=", "parent", "\n", "if", "has_labels", ":", "\n", "            ", "head_type", "[", "child", "]", "=", "label_id_matrix", "[", "parent", ",", "child", "]", "\n", "\n", "", "", "return", "heads", ",", "head_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.chu_liu_edmonds": [[85, 248], ["range", "maximum_spanning_tree._find_cycle", "range", "enumerate", "maximum_spanning_tree.chu_liu_edmonds", "enumerate", "parents.append", "range", "float", "float", "considered_representatives.append", "range", "set", "considered_representatives[].add", "representatives[].add"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._find_cycle", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.chu_liu_edmonds"], ["", "def", "chu_liu_edmonds", "(", "length", ":", "int", ",", "\n", "score_matrix", ":", "numpy", ".", "ndarray", ",", "\n", "current_nodes", ":", "List", "[", "bool", "]", ",", "\n", "final_edges", ":", "Dict", "[", "int", ",", "int", "]", ",", "\n", "old_input", ":", "numpy", ".", "ndarray", ",", "\n", "old_output", ":", "numpy", ".", "ndarray", ",", "\n", "representatives", ":", "List", "[", "Set", "[", "int", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Applies the chu-liu-edmonds algorithm recursively\n    to a graph with edge weights defined by score_matrix.\n    Note that this function operates in place, so variables\n    will be modified.\n    Parameters\n    ----------\n    length : ``int``, required.\n        The number of nodes.\n    score_matrix : ``numpy.ndarray``, required.\n        The score matrix representing the scores for pairs\n        of nodes.\n    current_nodes : ``List[bool]``, required.\n        The nodes which are representatives in the graph.\n        A representative at it's most basic represents a node,\n        but as the algorithm progresses, individual nodes will\n        represent collapsed cycles in the graph.\n    final_edges: ``Dict[int, int]``, required.\n        An empty dictionary which will be populated with the\n        nodes which are connected in the maximum spanning tree.\n    old_input: ``numpy.ndarray``, required.\n        a map from an edge to its head node.\n        Key: The edge is a tuple, and elements in a tuple\n        could be a node or a representative of a cycle.\n    old_output: ``numpy.ndarray``, required.\n    representatives : ``List[Set[int]]``, required.\n        A list containing the nodes that a particular node\n        is representing at this iteration in the graph.\n    Returns\n    -------\n    Nothing - all variables are modified in place.\n    \"\"\"", "\n", "# Set the initial graph to be the greedy best one.", "\n", "# Node '0' is always the root node.", "\n", "parents", "=", "[", "-", "1", "]", "\n", "for", "node1", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "# Init the parent of each node to be the root node.", "\n", "        ", "parents", ".", "append", "(", "0", ")", "\n", "if", "current_nodes", "[", "node1", "]", ":", "\n", "# If the node is a representative,", "\n", "# find the max outgoing edge to other non-root representative,", "\n", "# and update its parent.", "\n", "            ", "max_score", "=", "score_matrix", "[", "0", ",", "node1", "]", "\n", "for", "node2", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                ", "if", "node2", "==", "node1", "or", "not", "current_nodes", "[", "node2", "]", ":", "\n", "                    ", "continue", "\n", "\n", "", "new_score", "=", "score_matrix", "[", "node2", ",", "node1", "]", "\n", "if", "new_score", ">", "max_score", ":", "\n", "                    ", "max_score", "=", "new_score", "\n", "parents", "[", "node1", "]", "=", "node2", "\n", "\n", "# Check if this solution has a cycle.", "\n", "", "", "", "", "has_cycle", ",", "cycle", "=", "_find_cycle", "(", "parents", ",", "length", ",", "current_nodes", ")", "\n", "# If there are no cycles, find all edges and return.", "\n", "if", "not", "has_cycle", ":", "\n", "        ", "final_edges", "[", "0", "]", "=", "-", "1", "\n", "for", "node", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "            ", "if", "not", "current_nodes", "[", "node", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "parent", "=", "old_input", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "child", "=", "old_output", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "final_edges", "[", "child", "]", "=", "parent", "\n", "", "return", "\n", "\n", "# Otherwise, we have a cycle so we need to remove an edge.", "\n", "# From here until the recursive call is the contraction stage of the algorithm.", "\n", "", "cycle_weight", "=", "0.0", "\n", "# Find the weight of the cycle.", "\n", "index", "=", "0", "\n", "for", "node", "in", "cycle", ":", "\n", "        ", "index", "+=", "1", "\n", "cycle_weight", "+=", "score_matrix", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "\n", "# For each node in the graph, find the maximum weight incoming", "\n", "# and outgoing edge into the cycle.", "\n", "", "cycle_representative", "=", "cycle", "[", "0", "]", "\n", "for", "node", "in", "range", "(", "length", ")", ":", "\n", "# Nodes not in the cycle.", "\n", "        ", "if", "not", "current_nodes", "[", "node", "]", "or", "node", "in", "cycle", ":", "\n", "            ", "continue", "\n", "\n", "", "in_edge_weight", "=", "float", "(", "\"-inf\"", ")", "\n", "in_edge", "=", "-", "1", "\n", "out_edge_weight", "=", "float", "(", "\"-inf\"", ")", "\n", "out_edge", "=", "-", "1", "\n", "\n", "for", "node_in_cycle", "in", "cycle", ":", "\n", "            ", "if", "score_matrix", "[", "node_in_cycle", ",", "node", "]", ">", "in_edge_weight", ":", "\n", "                ", "in_edge_weight", "=", "score_matrix", "[", "node_in_cycle", ",", "node", "]", "\n", "in_edge", "=", "node_in_cycle", "\n", "\n", "# Add the new edge score to the cycle weight", "\n", "# and subtract the edge we're considering removing.", "\n", "", "score", "=", "(", "cycle_weight", "+", "\n", "score_matrix", "[", "node", ",", "node_in_cycle", "]", "-", "\n", "score_matrix", "[", "parents", "[", "node_in_cycle", "]", ",", "node_in_cycle", "]", ")", "\n", "\n", "if", "score", ">", "out_edge_weight", ":", "\n", "                ", "out_edge_weight", "=", "score", "\n", "out_edge", "=", "node_in_cycle", "\n", "\n", "", "", "score_matrix", "[", "cycle_representative", ",", "node", "]", "=", "in_edge_weight", "\n", "old_input", "[", "cycle_representative", ",", "node", "]", "=", "old_input", "[", "in_edge", ",", "node", "]", "\n", "old_output", "[", "cycle_representative", ",", "node", "]", "=", "old_output", "[", "in_edge", ",", "node", "]", "\n", "\n", "score_matrix", "[", "node", ",", "cycle_representative", "]", "=", "out_edge_weight", "\n", "old_output", "[", "node", ",", "cycle_representative", "]", "=", "old_output", "[", "node", ",", "out_edge", "]", "\n", "old_input", "[", "node", ",", "cycle_representative", "]", "=", "old_input", "[", "node", ",", "out_edge", "]", "\n", "\n", "# For the next recursive iteration, we want to consider the cycle as a", "\n", "# single node. Here we collapse the cycle into the first node in the", "\n", "# cycle (first node is arbitrary), set all the other nodes not be", "\n", "# considered in the next iteration. We also keep track of which", "\n", "# representatives we are considering this iteration because we need", "\n", "# them below to check if we're done.", "\n", "", "considered_representatives", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "for", "i", ",", "node_in_cycle", "in", "enumerate", "(", "cycle", ")", ":", "\n", "        ", "considered_representatives", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "i", ">", "0", ":", "\n", "# We need to consider at least one", "\n", "# node in the cycle, arbitrarily choose", "\n", "# the first.", "\n", "            ", "current_nodes", "[", "node_in_cycle", "]", "=", "False", "\n", "\n", "", "for", "node", "in", "representatives", "[", "node_in_cycle", "]", ":", "\n", "            ", "considered_representatives", "[", "i", "]", ".", "add", "(", "node", ")", "\n", "if", "i", ">", "0", ":", "\n", "                ", "representatives", "[", "cycle_representative", "]", ".", "add", "(", "node", ")", "\n", "\n", "", "", "", "chu_liu_edmonds", "(", "length", ",", "score_matrix", ",", "current_nodes", ",", "final_edges", ",", "old_input", ",", "old_output", ",", "representatives", ")", "\n", "\n", "# Expansion stage.", "\n", "# check each node in cycle, if one of its representatives", "\n", "# is a key in the final_edges, it is the one we need.", "\n", "# The node we are looking for is the node which is the child", "\n", "# of the incoming edge to the cycle.", "\n", "found", "=", "False", "\n", "key_node", "=", "-", "1", "\n", "for", "i", ",", "node", "in", "enumerate", "(", "cycle", ")", ":", "\n", "        ", "for", "cycle_rep", "in", "considered_representatives", "[", "i", "]", ":", "\n", "            ", "if", "cycle_rep", "in", "final_edges", ":", "\n", "                ", "key_node", "=", "node", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "found", ":", "\n", "            ", "break", "\n", "\n", "# break the cycle.", "\n", "", "", "previous", "=", "parents", "[", "key_node", "]", "\n", "while", "previous", "!=", "key_node", ":", "\n", "        ", "child", "=", "old_output", "[", "parents", "[", "previous", "]", ",", "previous", "]", "\n", "parent", "=", "old_input", "[", "parents", "[", "previous", "]", ",", "previous", "]", "\n", "final_edges", "[", "child", "]", "=", "parent", "\n", "previous", "=", "parents", "[", "previous", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._find_cycle": [[250, 302], ["set", "range", "set", "set.add", "list", "range", "set.add", "set.add", "set.add"], "function", ["None"], ["", "", "def", "_find_cycle", "(", "parents", ":", "List", "[", "int", "]", ",", "\n", "length", ":", "int", ",", "\n", "current_nodes", ":", "List", "[", "bool", "]", ")", "->", "Tuple", "[", "bool", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    :return:\n        has_cycle: whether the graph has at least a cycle.\n        cycle: a list of nodes which form a cycle in the graph.\n    \"\"\"", "\n", "\n", "# 'added' means that the node has been visited.", "\n", "added", "=", "[", "False", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "added", "[", "0", "]", "=", "True", "\n", "cycle", "=", "set", "(", ")", "\n", "has_cycle", "=", "False", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "        ", "if", "has_cycle", ":", "\n", "            ", "break", "\n", "# don't redo nodes we've already", "\n", "# visited or aren't considering.", "\n", "", "if", "added", "[", "i", "]", "or", "not", "current_nodes", "[", "i", "]", ":", "\n", "            ", "continue", "\n", "# Initialize a new possible cycle.", "\n", "", "this_cycle", "=", "set", "(", ")", "\n", "this_cycle", ".", "add", "(", "i", ")", "\n", "added", "[", "i", "]", "=", "True", "\n", "has_cycle", "=", "True", "\n", "next_node", "=", "i", "\n", "while", "parents", "[", "next_node", "]", "not", "in", "this_cycle", ":", "\n", "            ", "next_node", "=", "parents", "[", "next_node", "]", "\n", "# If we see a node we've already processed,", "\n", "# we can stop, because the node we are", "\n", "# processing would have been in that cycle.", "\n", "# Note that in the first pass of the for loop,", "\n", "# every node except that the root has been assigned", "\n", "# a head, if there's no cycle, the while loop", "\n", "# will finally arrive at the root", "\n", "if", "added", "[", "next_node", "]", ":", "\n", "                ", "has_cycle", "=", "False", "\n", "break", "\n", "", "added", "[", "next_node", "]", "=", "True", "\n", "this_cycle", ".", "add", "(", "next_node", ")", "\n", "\n", "", "if", "has_cycle", ":", "\n", "            ", "original", "=", "next_node", "\n", "cycle", ".", "add", "(", "original", ")", "\n", "next_node", "=", "parents", "[", "original", "]", "\n", "while", "next_node", "!=", "original", ":", "\n", "                ", "cycle", ".", "add", "(", "next_node", ")", "\n", "next_node", "=", "parents", "[", "next_node", "]", "\n", "", "break", "\n", "\n", "", "", "return", "has_cycle", ",", "list", "(", "cycle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.decode_mst_with_coreference": [[304, 389], ["numpy.array", "numpy.zeros", "numpy.zeros", "range", "maximum_spanning_tree.adapted_chu_liu_edmonds", "maximum_spanning_tree._validate", "numpy.zeros", "final_edges.items", "stog.utils.checks.ConfigurationError", "energy.max.argmax", "energy.max.max", "representatives.append", "range", "numpy.ones", "stog.utils.checks.ConfigurationError", "range"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.adapted_chu_liu_edmonds", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._validate", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "decode_mst_with_coreference", "(", "\n", "energy", ":", "numpy", ".", "ndarray", ",", "\n", "coreference", ":", "List", "[", "int", "]", ",", "\n", "length", ":", "int", ",", "\n", "has_labels", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "numpy", ".", "ndarray", ",", "numpy", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Note: Counter to typical intuition, this function decodes the _maximum_\n    spanning tree.\n    Decode the optimal MST tree with the Chu-Liu-Edmonds algorithm for\n    maximum spanning arboresences on graphs.\n    Parameters\n    ----------\n    energy : ``numpy.ndarray``, required.\n        A tensor with shape (num_labels, timesteps, timesteps)\n        containing the energy of each edge. If has_labels is ``False``,\n        the tensor should have shape (timesteps, timesteps) instead.\n    coreference: ``List[int]``, required.\n        A list which maps a node to its first precedent.\n    length : ``int``, required.\n        The length of this sequence, as the energy may have come\n        from a padded batch.\n    has_labels : ``bool``, optional, (default = True)\n        Whether the graph has labels or not.\n    \"\"\"", "\n", "if", "has_labels", "and", "energy", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"The dimension of the energy array is not equal to 3.\"", ")", "\n", "", "elif", "not", "has_labels", "and", "energy", ".", "ndim", "!=", "2", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"The dimension of the energy array is not equal to 2.\"", ")", "\n", "", "input_shape", "=", "energy", ".", "shape", "\n", "max_length", "=", "input_shape", "[", "-", "1", "]", "\n", "\n", "# Our energy matrix might have been batched -", "\n", "# here we clip it to contain only non padded tokens.", "\n", "if", "has_labels", ":", "\n", "        ", "energy", "=", "energy", "[", ":", ",", ":", "length", ",", ":", "length", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energy", ".", "argmax", "(", "axis", "=", "0", ")", "\n", "energy", "=", "energy", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "energy", "=", "energy", "[", ":", "length", ",", ":", "length", "]", "\n", "label_id_matrix", "=", "None", "\n", "# get original score matrix", "\n", "", "original_score_matrix", "=", "energy", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "numpy", ".", "array", "(", "original_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "old_input", "=", "numpy", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "old_output", "=", "numpy", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "current_nodes", "=", "[", "True", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "representatives", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "\n", "for", "node1", "in", "range", "(", "length", ")", ":", "\n", "        ", "original_score_matrix", "[", "node1", ",", "node1", "]", "=", "0.0", "\n", "score_matrix", "[", "node1", ",", "node1", "]", "=", "0.0", "\n", "representatives", ".", "append", "(", "{", "node1", "}", ")", "\n", "\n", "for", "node2", "in", "range", "(", "node1", "+", "1", ",", "length", ")", ":", "\n", "            ", "old_input", "[", "node1", ",", "node2", "]", "=", "node1", "\n", "old_output", "[", "node1", ",", "node2", "]", "=", "node2", "\n", "\n", "old_input", "[", "node2", ",", "node1", "]", "=", "node2", "\n", "old_output", "[", "node2", ",", "node1", "]", "=", "node1", "\n", "\n", "", "", "final_edges", ":", "Dict", "[", "int", ",", "int", "]", "=", "{", "}", "\n", "\n", "# The main algorithm operates inplace.", "\n", "adapted_chu_liu_edmonds", "(", "\n", "length", ",", "score_matrix", ",", "coreference", ",", "current_nodes", ",", "\n", "final_edges", ",", "old_input", ",", "old_output", ",", "representatives", ")", "\n", "\n", "# Modify edges which are invalid according to coreference.", "\n", "_validate", "(", "final_edges", ",", "length", ",", "original_score_matrix", ",", "coreference", ")", "\n", "\n", "heads", "=", "numpy", ".", "zeros", "(", "[", "max_length", "]", ",", "numpy", ".", "int32", ")", "\n", "if", "has_labels", ":", "\n", "        ", "head_type", "=", "numpy", ".", "ones", "(", "[", "max_length", "]", ",", "numpy", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "head_type", "=", "None", "\n", "\n", "", "for", "child", ",", "parent", "in", "final_edges", ".", "items", "(", ")", ":", "\n", "        ", "heads", "[", "child", "]", "=", "parent", "\n", "if", "has_labels", ":", "\n", "            ", "head_type", "[", "child", "]", "=", "label_id_matrix", "[", "parent", ",", "child", "]", "\n", "\n", "", "", "return", "heads", ",", "head_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.adapted_chu_liu_edmonds": [[391, 571], ["range", "maximum_spanning_tree._find_cycle", "range", "enumerate", "maximum_spanning_tree.adapted_chu_liu_edmonds", "enumerate", "parents.append", "range", "float", "float", "considered_representatives.append", "range", "set", "considered_representatives[].add", "representatives[].add"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._find_cycle", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.adapted_chu_liu_edmonds"], ["", "def", "adapted_chu_liu_edmonds", "(", "length", ":", "int", ",", "\n", "score_matrix", ":", "numpy", ".", "ndarray", ",", "\n", "coreference", ":", "List", "[", "int", "]", ",", "\n", "current_nodes", ":", "List", "[", "bool", "]", ",", "\n", "final_edges", ":", "Dict", "[", "int", ",", "int", "]", ",", "\n", "old_input", ":", "numpy", ".", "ndarray", ",", "\n", "old_output", ":", "numpy", ".", "ndarray", ",", "\n", "representatives", ":", "List", "[", "Set", "[", "int", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Applies the chu-liu-edmonds algorithm recursively\n    to a graph with edge weights defined by score_matrix.\n    Note that this function operates in place, so variables\n    will be modified.\n    Parameters\n    ----------\n    length : ``int``, required.\n        The number of nodes.\n    score_matrix : ``numpy.ndarray``, required.\n        The score matrix representing the scores for pairs\n        of nodes.\n    coreference: ``List[int]``, required.\n        A list which maps a node to its first precedent.\n    current_nodes : ``List[bool]``, required.\n        The nodes which are representatives in the graph.\n        A representative at it's most basic represents a node,\n        but as the algorithm progresses, individual nodes will\n        represent collapsed cycles in the graph.\n    final_edges: ``Dict[int, int]``, required.\n        An empty dictionary which will be populated with the\n        nodes which are connected in the maximum spanning tree.\n    old_input: ``numpy.ndarray``, required.\n        a map from an edge to its head node.\n        Key: The edge is a tuple, and elements in a tuple\n        could be a node or a representative of a cycle.\n    old_output: ``numpy.ndarray``, required.\n    representatives : ``List[Set[int]]``, required.\n        A list containing the nodes that a particular node\n        is representing at this iteration in the graph.\n    Returns\n    -------\n    Nothing - all variables are modified in place.\n    \"\"\"", "\n", "# Set the initial graph to be the greedy best one.", "\n", "# Node '0' is always the root node.", "\n", "parents", "=", "[", "-", "1", "]", "\n", "for", "node1", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "# Init the parent of each node to be the root node.", "\n", "        ", "parents", ".", "append", "(", "0", ")", "\n", "if", "current_nodes", "[", "node1", "]", ":", "\n", "# If the node is a representative,", "\n", "# find the max outgoing edge to other non-root representative,", "\n", "# and update its parent.", "\n", "            ", "max_score", "=", "score_matrix", "[", "0", ",", "node1", "]", "\n", "for", "node2", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                ", "if", "node2", "==", "node1", "or", "not", "current_nodes", "[", "node2", "]", ":", "\n", "                    ", "continue", "\n", "\n", "# Exclude edges formed by two coreferred nodes", "\n", "", "_parent", "=", "old_input", "[", "node1", ",", "node2", "]", "\n", "_child", "=", "old_output", "[", "node1", ",", "node2", "]", "\n", "if", "coreference", "[", "_parent", "]", "==", "coreference", "[", "_child", "]", ":", "\n", "                    ", "continue", "\n", "\n", "", "new_score", "=", "score_matrix", "[", "node2", ",", "node1", "]", "\n", "if", "new_score", ">", "max_score", ":", "\n", "                    ", "max_score", "=", "new_score", "\n", "parents", "[", "node1", "]", "=", "node2", "\n", "\n", "# Check if this solution has a cycle.", "\n", "", "", "", "", "has_cycle", ",", "cycle", "=", "_find_cycle", "(", "parents", ",", "length", ",", "current_nodes", ")", "\n", "# If there are no cycles, find all edges and return.", "\n", "if", "not", "has_cycle", ":", "\n", "        ", "final_edges", "[", "0", "]", "=", "-", "1", "\n", "for", "node", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "            ", "if", "not", "current_nodes", "[", "node", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "parent", "=", "old_input", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "child", "=", "old_output", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "final_edges", "[", "child", "]", "=", "parent", "\n", "", "return", "\n", "\n", "# Otherwise, we have a cycle so we need to remove an edge.", "\n", "# From here until the recursive call is the contraction stage of the algorithm.", "\n", "", "cycle_weight", "=", "0.0", "\n", "# Find the weight of the cycle.", "\n", "index", "=", "0", "\n", "for", "node", "in", "cycle", ":", "\n", "        ", "index", "+=", "1", "\n", "cycle_weight", "+=", "score_matrix", "[", "parents", "[", "node", "]", ",", "node", "]", "\n", "\n", "# For each node in the graph, find the maximum weight incoming", "\n", "# and outgoing edge into the cycle.", "\n", "", "cycle_representative", "=", "cycle", "[", "0", "]", "\n", "for", "node", "in", "range", "(", "length", ")", ":", "\n", "# Nodes not in the cycle.", "\n", "        ", "if", "not", "current_nodes", "[", "node", "]", "or", "node", "in", "cycle", ":", "\n", "            ", "continue", "\n", "\n", "", "in_edge_weight", "=", "float", "(", "\"-inf\"", ")", "\n", "in_edge", "=", "-", "1", "\n", "out_edge_weight", "=", "float", "(", "\"-inf\"", ")", "\n", "out_edge", "=", "-", "1", "\n", "\n", "for", "node_in_cycle", "in", "cycle", ":", "\n", "# Exclude edges formed by two coreferred nodes.", "\n", "            ", "_parent", "=", "old_input", "[", "node_in_cycle", ",", "node", "]", "\n", "_child", "=", "old_output", "[", "node_in_cycle", ",", "node", "]", "\n", "if", "coreference", "[", "_parent", "]", "!=", "coreference", "[", "_child", "]", ":", "\n", "                ", "if", "score_matrix", "[", "node_in_cycle", ",", "node", "]", ">", "in_edge_weight", ":", "\n", "                    ", "in_edge_weight", "=", "score_matrix", "[", "node_in_cycle", ",", "node", "]", "\n", "in_edge", "=", "node_in_cycle", "\n", "\n", "# Exclude edges formed by two coreferred nodes.", "\n", "", "", "_parent", "=", "old_input", "[", "node", ",", "node_in_cycle", "]", "\n", "_child", "=", "old_output", "[", "node", ",", "node_in_cycle", "]", "\n", "if", "coreference", "[", "_parent", "]", "!=", "coreference", "[", "_child", "]", ":", "\n", "# Add the new edge score to the cycle weight", "\n", "# and subtract the edge we're considering removing.", "\n", "                ", "score", "=", "(", "cycle_weight", "+", "\n", "score_matrix", "[", "node", ",", "node_in_cycle", "]", "-", "\n", "score_matrix", "[", "parents", "[", "node_in_cycle", "]", ",", "node_in_cycle", "]", ")", "\n", "\n", "if", "score", ">", "out_edge_weight", ":", "\n", "                    ", "out_edge_weight", "=", "score", "\n", "out_edge", "=", "node_in_cycle", "\n", "\n", "", "", "", "score_matrix", "[", "cycle_representative", ",", "node", "]", "=", "in_edge_weight", "\n", "old_input", "[", "cycle_representative", ",", "node", "]", "=", "old_input", "[", "in_edge", ",", "node", "]", "\n", "old_output", "[", "cycle_representative", ",", "node", "]", "=", "old_output", "[", "in_edge", ",", "node", "]", "\n", "\n", "score_matrix", "[", "node", ",", "cycle_representative", "]", "=", "out_edge_weight", "\n", "old_output", "[", "node", ",", "cycle_representative", "]", "=", "old_output", "[", "node", ",", "out_edge", "]", "\n", "old_input", "[", "node", ",", "cycle_representative", "]", "=", "old_input", "[", "node", ",", "out_edge", "]", "\n", "\n", "# For the next recursive iteration, we want to consider the cycle as a", "\n", "# single node. Here we collapse the cycle into the first node in the", "\n", "# cycle (first node is arbitrary), set all the other nodes not be", "\n", "# considered in the next iteration. We also keep track of which", "\n", "# representatives we are considering this iteration because we need", "\n", "# them below to check if we're done.", "\n", "", "considered_representatives", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "for", "i", ",", "node_in_cycle", "in", "enumerate", "(", "cycle", ")", ":", "\n", "        ", "considered_representatives", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "i", ">", "0", ":", "\n", "# We need to consider at least one", "\n", "# node in the cycle, arbitrarily choose", "\n", "# the first.", "\n", "            ", "current_nodes", "[", "node_in_cycle", "]", "=", "False", "\n", "\n", "", "for", "node", "in", "representatives", "[", "node_in_cycle", "]", ":", "\n", "            ", "considered_representatives", "[", "i", "]", ".", "add", "(", "node", ")", "\n", "if", "i", ">", "0", ":", "\n", "                ", "representatives", "[", "cycle_representative", "]", ".", "add", "(", "node", ")", "\n", "\n", "", "", "", "adapted_chu_liu_edmonds", "(", "length", ",", "score_matrix", ",", "coreference", ",", "current_nodes", ",", "final_edges", ",", "old_input", ",", "old_output", ",", "representatives", ")", "\n", "\n", "# Expansion stage.", "\n", "# check each node in cycle, if one of its representatives", "\n", "# is a key in the final_edges, it is the one we need.", "\n", "# The node we are looking for is the node which is the child", "\n", "# of the incoming edge to the cycle.", "\n", "found", "=", "False", "\n", "key_node", "=", "-", "1", "\n", "for", "i", ",", "node", "in", "enumerate", "(", "cycle", ")", ":", "\n", "        ", "for", "cycle_rep", "in", "considered_representatives", "[", "i", "]", ":", "\n", "            ", "if", "cycle_rep", "in", "final_edges", ":", "\n", "                ", "key_node", "=", "node", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "found", ":", "\n", "            ", "break", "\n", "\n", "# break the cycle.", "\n", "", "", "previous", "=", "parents", "[", "key_node", "]", "\n", "while", "previous", "!=", "key_node", ":", "\n", "        ", "child", "=", "old_output", "[", "parents", "[", "previous", "]", ",", "previous", "]", "\n", "parent", "=", "old_input", "[", "parents", "[", "previous", "]", ",", "previous", "]", "\n", "final_edges", "[", "child", "]", "=", "parent", "\n", "previous", "=", "parents", "[", "previous", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._validate": [[573, 637], ["enumerate", "group_by_precedent.values", "group_by_precedent[].append", "set", "conflicts_by_parent.items", "range", "len", "conflicts_by_parent[].append", "conflicts_by_parent.keys", "max", "len", "numpy.argsort", "final_edges.copy", "maximum_spanning_tree._find_cycle", "set.add"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree._find_cycle"], ["", "", "def", "_validate", "(", "final_edges", ",", "length", ",", "original_score_matrix", ",", "coreference", ")", ":", "\n", "# Count how many edges have been modified by this function.", "\n", "    ", "modified", "=", "0", "\n", "\n", "# Make a constant used by _find_cycle.", "\n", "current_nodes", "=", "[", "True", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "\n", "# Group nodes by coreference.", "\n", "group_by_precedent", "=", "{", "}", "\n", "for", "node", ",", "precedent", "in", "enumerate", "(", "coreference", ")", ":", "\n", "        ", "if", "precedent", "not", "in", "group_by_precedent", ":", "\n", "            ", "group_by_precedent", "[", "precedent", "]", "=", "[", "]", "\n", "", "group_by_precedent", "[", "precedent", "]", ".", "append", "(", "node", ")", "\n", "\n", "# Validate parents of nodes in each group.", "\n", "", "for", "group", "in", "group_by_precedent", ".", "values", "(", ")", ":", "\n", "# Skip if only one node in the group.", "\n", "        ", "if", "len", "(", "group", ")", "==", "1", ":", "\n", "            ", "continue", "\n", "# Group conflicting nodes by parent.", "\n", "", "conflicts_by_parent", "=", "{", "}", "\n", "for", "child", "in", "group", ":", "\n", "            ", "parent", "=", "final_edges", "[", "child", "]", "\n", "if", "parent", "not", "in", "conflicts_by_parent", ":", "\n", "                ", "conflicts_by_parent", "[", "parent", "]", "=", "[", "]", "\n", "", "conflicts_by_parent", "[", "parent", "]", ".", "append", "(", "child", ")", "\n", "\n", "# Keep the parents which have already been taken.", "\n", "", "reserved_parents", "=", "set", "(", "conflicts_by_parent", ".", "keys", "(", ")", ")", "\n", "for", "parent", ",", "conflicts", "in", "conflicts_by_parent", ".", "items", "(", ")", ":", "\n", "# Skip if no conflict.", "\n", "            ", "if", "len", "(", "conflicts", ")", "==", "1", ":", "\n", "                ", "continue", "\n", "# Find the node that has the maximum edge with the parent.", "\n", "", "winner", "=", "max", "(", "conflicts", ",", "key", "=", "lambda", "_child", ":", "original_score_matrix", "[", "parent", ",", "_child", "]", ")", "\n", "# Modify other nodes' parents.", "\n", "for", "child", "in", "conflicts", ":", "\n", "# Skip the winner.", "\n", "                ", "if", "child", "==", "winner", ":", "\n", "                    ", "continue", "\n", "# Sort its candidate parents by score.", "\n", "", "parent_scores", "=", "original_score_matrix", "[", ":", ",", "child", "]", "\n", "for", "_parent", "in", "numpy", ".", "argsort", "(", "parent_scores", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "# Skip its current parent and the reserved parents.", "\n", "                    ", "if", "_parent", "==", "parent", "or", "_parent", "in", "reserved_parents", ":", "\n", "                        ", "continue", "\n", "# Check if there's any cycle if we use this parent.", "\n", "", "parents", "=", "final_edges", ".", "copy", "(", ")", "\n", "parents", "[", "child", "]", "=", "_parent", "\n", "has_cycle", ",", "_", "=", "_find_cycle", "(", "parents", ",", "length", ",", "current_nodes", ")", "\n", "if", "has_cycle", ":", "\n", "                        ", "continue", "\n", "# Add it to the reserved parents.", "\n", "", "reserved_parents", ".", "add", "(", "_parent", ")", "\n", "# Update its parent.", "\n", "final_edges", "[", "child", "]", "=", "_parent", "\n", "# Update the counter.", "\n", "modified", "+=", "1", "\n", "break", "\n", "# else:", "\n", "#     print('* Could not find another parent. Use the old one.')", "\n", "# if modified > 0:", "\n", "#     print('* Validate')", "\n", "", "", "", "", "return", "modified", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.dict_merge.dict_merge": [[22, 37], ["merge_dct.items", "isinstance", "isinstance", "dict_merge.dict_merge", "dct.get"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.dict_merge.dict_merge", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["def", "dict_merge", "(", "dct", ",", "merge_dct", ")", ":", "\n", "    ", "\"\"\" Recursive dict merge. Inspired by :meth:``dict.update()``, instead of\n    updating only top-level keys, dict_merge recurses down into dicts nested\n    to an arbitrary depth, updating keys. The ``merge_dct`` is merged into\n    ``dct``.\n\n    :param dct: dict onto which the merge is executed\n    :param merge_dct: dct merged into dct\n    :return: None\n    \"\"\"", "\n", "for", "k", ",", "v", "in", "merge_dct", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "dct", ".", "get", "(", "k", ")", ",", "dict", ")", "and", "isinstance", "(", "v", ",", "collections", ".", "Mapping", ")", ":", "\n", "            ", "dict_merge", "(", "dct", "[", "k", "]", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "dct", "[", "k", "]", "=", "v", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.__init__": [[12, 15], ["tensorboardX.SummaryWriter", "tensorboardX.SummaryWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "train_log", "=", "None", ",", "dev_log", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_train_log", "=", "SummaryWriter", "(", "train_log", ")", "if", "train_log", "is", "not", "None", "else", "None", "\n", "self", ".", "_dev_log", "=", "SummaryWriter", "(", "dev_log", ")", "if", "dev_log", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter._item": [[16, 23], ["hasattr", "value.item"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_item", "(", "value", ":", "Any", ")", ":", "\n", "        ", "if", "hasattr", "(", "value", ",", "'item'", ")", ":", "\n", "            ", "val", "=", "value", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "val", "=", "value", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_train_scalar": [[24, 28], ["tensorboard.TensorboardWriter._train_log.add_scalar", "tensorboard.TensorboardWriter._item"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter._item"], ["", "def", "add_train_scalar", "(", "self", ",", "name", ":", "str", ",", "value", ":", "float", ",", "global_step", ":", "int", ")", "->", "None", ":", "\n", "# get the scalar", "\n", "        ", "if", "self", ".", "_train_log", "is", "not", "None", ":", "\n", "            ", "self", ".", "_train_log", ".", "add_scalar", "(", "name", ",", "self", ".", "_item", "(", "value", ")", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_train_histogram": [[29, 34], ["isinstance", "values.cpu().data.numpy().flatten", "tensorboard.TensorboardWriter._train_log.add_histog.am", "values.cpu().data.numpy", "values.cpu"], "methods", ["None"], ["", "", "def", "add_train_histogram", "(", "self", ",", "name", ":", "str", ",", "values", ":", "torch", ".", "Tensor", ",", "global_step", ":", "int", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_train_log", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "values", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "values_to_write", "=", "values", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "_train_log", ".", "add_histog", ".", "am", "(", "name", ",", "values_to_write", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_dev_scalar": [[35, 39], ["tensorboard.TensorboardWriter._dev_log.add_scalar", "tensorboard.TensorboardWriter._item"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter._item"], ["", "", "", "def", "add_dev_scalar", "(", "self", ",", "name", ":", "str", ",", "value", ":", "float", ",", "global_step", ":", "int", ")", "->", "None", ":", "\n", "\n", "        ", "if", "self", ".", "_dev_log", "is", "not", "None", ":", "\n", "            ", "self", ".", "_dev_log", ".", "add_scalar", "(", "name", ",", "self", ".", "_item", "(", "value", ")", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.__init__": [[32, 131], ["os.path.join", "os.path.join", "stog.training.tensorboard.TensorboardWriter", "stog.training.tensorboard.TensorboardWriter"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "iterator", ",", "\n", "training_dataset", ",", "\n", "dev_dataset", "=", "None", ",", "\n", "dev_iterator", "=", "None", ",", "\n", "dev_metric", "=", "'-loss'", ",", "\n", "device", "=", "None", ",", "\n", "patience", "=", "None", ",", "\n", "grad_clipping", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_epochs", "=", "20", ",", "\n", "serialization_dir", "=", "None", ",", "\n", "num_serialized_models_to_keep", "=", "20", ",", "\n", "model_save_interval", "=", "None", ",", "\n", "summary_interval", "=", "100", ",", "\n", "batch_size", "=", "64", ",", "\n", "n_gpus", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        :param model:\n            The model to train.\n        :param optimizer:\n            Optimizer.\n        :param iterator:\n            A method for iterating over a ``Dataset``, yielding padded indexed batches.\n        :param training_dataset:\n            A ``Dataset`` to train on. The dataset should have already been indexed.\n        :param dev_dataset:\n            A ``Dataset`` to validate on. The dataset should have already been indexed.\n        :param dev_iterator:\n            An iterator to use for the dev set.  If ``None``, then\n            use the training `iterator`.\n        :param dev_metric:\n            Dev metric to measure for whether to stop training using patience\n            and whether to serialize an ``is_best`` model each epoch.\n        :param device:\n            Specified device.\n        :param patience:\n            Number of epochs to be patient before early stopping: the training is stopped\n            after ``patience`` epochs with no improvement. If given, it must be ``> 0``.\n            If None, early stopping is disabled.\n        :param grad_clipping:\n            If provided, gradients will be clipped `during the backward pass` to have an (absolute)\n            maximum of this value.  If you are getting ``NaNs`` in your gradients during training\n            that are not solved by using ``grad_norm``, you may need this.\n        :param shuffle:\n            Whether to shuffle the instances in the iterator or not.\n        :param num_epochs:\n            Number of training epochs.\n        :param serialization_dir:\n            Path to save and load model states, training states, and logs.\n        :param num_serialized_models_to_keep:\n            Number of previous model checkpoints to retain.  Default is to keep 20 checkpoints.\n            A value of None or -1 means all checkpoints will be kept.\n        :param model_save_interval:\n            If provided, then serialize models every ``model_save_interval``\n            seconds within single epochs.  In all cases, models are also saved\n            at the end of every epoch if ``serialization_dir`` is provided.\n        :param summary_interval:\n            Number of batches between logging scalars to tensorboard\n        :param batch_size:\n            Training and dev batch size\n        :param n_gpus:\n            Number of GPUs\n        \"\"\"", "\n", "self", ".", "_model", "=", "model", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_iterator", "=", "iterator", "\n", "self", ".", "_training_dataset", "=", "training_dataset", "\n", "self", ".", "_dev_dataset", "=", "dev_dataset", "\n", "self", ".", "_dev_iterator", "=", "dev_iterator", "\n", "self", ".", "_dev_metric", "=", "dev_metric", "[", "1", ":", "]", "\n", "self", ".", "_dev_metric_decreases", "=", "dev_metric", "[", "0", "]", "==", "\"-\"", "\n", "self", ".", "_device", "=", "device", "\n", "self", ".", "_patience", "=", "patience", "\n", "self", ".", "_grad_clipping", "=", "grad_clipping", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "self", ".", "_num_epochs", "=", "num_epochs", "\n", "self", ".", "_serialization_dir", "=", "serialization_dir", "\n", "self", ".", "_num_serialized_models_to_keep", "=", "num_serialized_models_to_keep", "\n", "self", ".", "_model_save_interval", "=", "model_save_interval", "\n", "self", ".", "_summary_interval", "=", "summary_interval", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_n_gpus", "=", "n_gpus", "\n", "\n", "self", ".", "_num_trained_batches", "=", "0", "\n", "self", ".", "_serialized_paths", "=", "[", "]", "\n", "\n", "if", "serialization_dir", "is", "not", "None", ":", "\n", "            ", "train_log", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'log'", ",", "'train'", ")", "\n", "dev_log", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'log'", ",", "'dev'", ")", "\n", "self", ".", "_tensorboard", "=", "TensorboardWriter", "(", "train_log", ",", "dev_log", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tensorboard", "=", "TensorboardWriter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._batch_loss": [[132, 158], ["stog.utils.environment.move_to_device", "trainer.Trainer._model", "trainer.Trainer._model.module.get_regularization_penalty", "trainer.Trainer._model.get_regularization_penalty", "RuntimeError", "output_dict[].sum", "output_dict[].sum", "output_dict[].sum", "output_dict[].sum"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_regularization_penalty", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_regularization_penalty"], ["", "", "def", "_batch_loss", "(", "self", ",", "batch", ",", "for_training", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Does a forward pass on the given batch and returns the ``loss`` value in the result.\n        If ``for_training`` is `True` also applies regularization penalty.\n        \"\"\"", "\n", "batch", "=", "move_to_device", "(", "batch", ",", "self", ".", "_device", ")", "\n", "output_dict", "=", "self", ".", "_model", "(", "batch", ",", "for_training", "=", "for_training", ")", "\n", "\n", "try", ":", "\n", "            ", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "                ", "loss", "=", "(", "output_dict", "[", "'token_loss'", "]", ".", "sum", "(", ")", "/", "output_dict", "[", "'num_tokens'", "]", ".", "sum", "(", ")", "+", "\n", "output_dict", "[", "'edge_loss'", "]", ".", "sum", "(", ")", "/", "output_dict", "[", "'num_nodes'", "]", ".", "sum", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "output_dict", "[", "\"loss\"", "]", "\n", "", "if", "for_training", ":", "\n", "                ", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "                    ", "loss", "+=", "self", ".", "_model", ".", "module", ".", "get_regularization_penalty", "(", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "+=", "self", ".", "_model", ".", "get_regularization_penalty", "(", ")", "\n", "", "", "", "except", "KeyError", ":", "\n", "            ", "if", "for_training", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The model you are trying to optimize does not contain a\"", "\n", "\" 'loss' key in the output of model.forward(inputs).\"", ")", "\n", "", "loss", "=", "None", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._train_epoch": [[159, 224], ["logger.info", "logger.info", "stog.utils.environment.gpu_memory_mb().items", "trainer.Trainer._model.train", "trainer.Trainer._iterator", "trainer.Trainer._iterator.get_num_batches", "logger.info", "time.time", "stog.utils.tqdm.Tqdm.tqdm", "logger.info", "logger.info", "trainer.Trainer._optimizer.zero_grad", "trainer.Trainer._batch_loss", "trainer.Trainer.backward", "trainer.Trainer.item", "trainer.Trainer._optimizer.step", "trainer.Trainer._description_from_metrics", "stog.utils.tqdm.Tqdm.tqdm.set_description", "trainer.Trainer._model.module.get_metrics", "trainer.Trainer._model.get_metrics", "stog.utils.environment.gpu_memory_mb", "trainer.Trainer._model.module.get_metrics", "trainer.Trainer._model.get_metrics", "trainer.Trainer._tensorboard.add_train_scalar", "trainer.Trainer._metrics_to_tensorboard", "time.time", "trainer.Trainer._save_checkpoint", "stog.utils.environment.peak_memory_mb", "time.time", "stog.utils.time.time_to_str", "trainer.Trainer.items", "int"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.get_num_batches", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._batch_loss", "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._description_from_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.gpu_memory_mb", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_train_scalar", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._metrics_to_tensorboard", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.peak_memory_mb", "home.repos.pwc.inspect_result.jcyk_gtos.utils.time.time_to_str", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "self", ".", "_num_epochs", "-", "1", ")", ")", "\n", "logger", ".", "info", "(", "f'Peak CPU memory usage MB: {peak_memory_mb()}'", ")", "\n", "for", "gpu", ",", "memory", "in", "gpu_memory_mb", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"GPU {gpu} memory usage MB: {memory}\"", ")", "\n", "\n", "", "training_loss", "=", "0.0", "\n", "# Set the model to \"train\" mode.", "\n", "self", ".", "_model", ".", "train", "(", ")", "\n", "\n", "# Get tqdm for the training batches", "\n", "# TODO: How to deal with cuda device. Typically I set CUDA_VISIBLE_DEVICES before execute script, so it;s alway 0", "\n", "train_generator", "=", "self", ".", "_iterator", "(", "\n", "instances", "=", "self", ".", "_training_dataset", ",", "\n", "shuffle", "=", "self", ".", "_shuffle", ",", "\n", "num_epochs", "=", "1", "\n", ")", "\n", "\n", "num_training_batches", "=", "self", ".", "_iterator", ".", "get_num_batches", "(", "self", ".", "_training_dataset", ")", "\n", "\n", "logger", ".", "info", "(", "'Training...'", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "batches_this_epoch", "=", "0", "\n", "train_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "train_generator", ",", "total", "=", "num_training_batches", ")", "\n", "\n", "for", "batch", "in", "train_generator_tqdm", ":", "\n", "            ", "batches_this_epoch", "+=", "1", "\n", "self", ".", "_num_trained_batches", "+=", "1", "\n", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "_batch_loss", "(", "batch", ",", "for_training", "=", "True", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "training_loss", "+=", "loss", ".", "item", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "                ", "metrics", "=", "self", ".", "_model", ".", "module", ".", "get_metrics", "(", ")", "\n", "", "else", ":", "\n", "                ", "metrics", "=", "self", ".", "_model", ".", "get_metrics", "(", ")", "\n", "", "description", "=", "self", ".", "_description_from_metrics", "(", "metrics", ")", "\n", "\n", "train_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Log parameter values to Tensorboard", "\n", "if", "self", ".", "_num_trained_batches", "%", "self", ".", "_summary_interval", "==", "0", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\n", "\"loss/loss_train\"", ",", "metrics", "[", "self", ".", "_dev_metric", "]", ",", "self", ".", "_num_trained_batches", ")", "\n", "self", ".", "_metrics_to_tensorboard", "(", "\n", "self", ".", "_num_trained_batches", ",", "\n", "{", "\"epoch_metrics/\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "}", ")", "\n", "\n", "# Save model if needed.", "\n", "", "if", "self", ".", "_model_save_interval", "is", "not", "None", "and", "(", "\n", "time", ".", "time", "(", ")", "-", "last_save_time", ">", "self", ".", "_model_save_interval", "\n", ")", ":", "\n", "                ", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_save_checkpoint", "(", "\n", "'{0}.{1}'", ".", "format", "(", "epoch", ",", "time_to_str", "(", "int", "(", "last_save_time", ")", ")", ")", ",", "[", "]", ",", "is_best", "=", "False", "\n", ")", "\n", "", "", "logger", ".", "info", "(", "'Finish one epoch.'", ")", "\n", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "            ", "return", "self", ".", "_model", ".", "module", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_model", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._metrics_to_tensorboard": [[225, 244], ["set", "train_metrics.keys", "set.update", "train_metrics.get", "dev_metrics.get", "dev_metrics.keys", "trainer.Trainer._tensorboard.add_train_scalar", "trainer.Trainer._tensorboard.add_dev_scalar"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_train_scalar", "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_dev_scalar"], ["", "", "def", "_metrics_to_tensorboard", "(", "self", ",", "\n", "epoch", ":", "int", ",", "\n", "train_metrics", ":", "dict", ",", "\n", "dev_metrics", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sends all of the train metrics (and dev metrics, if provided) to tensorboard.\n        \"\"\"", "\n", "metric_names", "=", "set", "(", "train_metrics", ".", "keys", "(", ")", ")", "\n", "if", "dev_metrics", "is", "not", "None", ":", "\n", "            ", "metric_names", ".", "update", "(", "dev_metrics", ".", "keys", "(", ")", ")", "\n", "", "dev_metrics", "=", "dev_metrics", "or", "{", "}", "\n", "\n", "for", "name", "in", "metric_names", ":", "\n", "            ", "train_metric", "=", "train_metrics", ".", "get", "(", "name", ")", "\n", "if", "train_metric", "is", "not", "None", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "name", ",", "train_metric", ",", "epoch", ")", "\n", "", "dev_metric", "=", "dev_metrics", ".", "get", "(", "name", ")", "\n", "if", "dev_metric", "is", "not", "None", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "add_dev_scalar", "(", "name", ",", "dev_metric", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._metrics_to_console": [[245, 274], ["set", "max", "logger.info", "sorted", "train_metrics.keys", "set.update", "train_metrics.get", "dev_metrics.get", "dev_metrics.keys", "len", "logger.info", "name.ljust", "logger.info", "name.ljust", "logger.info", "name.ljust"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "", "", "def", "_metrics_to_console", "(", "self", ",", "# pylint: disable=no-self-use", "\n", "train_metrics", ":", "dict", ",", "\n", "dev_metrics", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Logs all of the train metrics (and validation metrics, if provided) to the console.\n        \"\"\"", "\n", "dev_metrics", "=", "dev_metrics", "or", "{", "}", "\n", "dual_message_template", "=", "\"%s |  %8.3f  |  %8.3f\"", "\n", "no_dev_message_template", "=", "\"%s |  %8.3f  |  %8s\"", "\n", "no_train_message_template", "=", "\"%s |  %8s  |  %8.3f\"", "\n", "header_template", "=", "\"%s |  %-10s\"", "\n", "\n", "metric_names", "=", "set", "(", "train_metrics", ".", "keys", "(", ")", ")", "\n", "if", "dev_metrics", ":", "\n", "            ", "metric_names", ".", "update", "(", "dev_metrics", ".", "keys", "(", ")", ")", "\n", "\n", "", "name_length", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "metric_names", "]", ")", "\n", "\n", "logger", ".", "info", "(", "header_template", ",", "\"Training\"", ".", "rjust", "(", "name_length", "+", "13", ")", ",", "\"Dev\"", ")", "\n", "for", "name", "in", "sorted", "(", "metric_names", ")", ":", "\n", "            ", "train_metric", "=", "train_metrics", ".", "get", "(", "name", ")", "\n", "dev_metric", "=", "dev_metrics", ".", "get", "(", "name", ")", "\n", "\n", "if", "dev_metric", "is", "not", "None", "and", "train_metric", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "dual_message_template", ",", "name", ".", "ljust", "(", "name_length", ")", ",", "train_metric", ",", "dev_metric", ")", "\n", "", "elif", "dev_metric", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "no_train_message_template", ",", "name", ".", "ljust", "(", "name_length", ")", ",", "\"N/A\"", ",", "dev_metric", ")", "\n", "", "elif", "train_metric", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "no_dev_message_template", ",", "name", ".", "ljust", "(", "name_length", ")", ",", "train_metric", ",", "\"N/A\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._validate_dev": [[275, 324], ["logger.info", "trainer.Trainer._model.eval", "dev_iterator", "dev_iterator.get_num_batches", "stog.utils.tqdm.Tqdm.tqdm", "trainer.Trainer._batch_loss", "trainer.Trainer._description_from_metrics", "stog.utils.tqdm.Tqdm.tqdm.set_description", "trainer.Trainer._model.module.get_metrics", "trainer.Trainer._model.get_metrics", "trainer.Trainer.item", "trainer.Trainer._model.module.get_metrics", "trainer.Trainer._model.get_metrics"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.get_num_batches", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._batch_loss", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._description_from_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics"], ["", "", "", "def", "_validate_dev", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Computes the dev loss. Returns it and the number of batches.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Validating on dev\"", ")", "\n", "\n", "self", ".", "_model", ".", "eval", "(", ")", "\n", "\n", "# TODO: edge loss is wrong when _dev_iterator is used.", "\n", "if", "False", ":", "# self._dev_iterator is not None:", "\n", "            ", "dev_iterator", "=", "self", ".", "_dev_iterator", "\n", "", "else", ":", "\n", "            ", "dev_iterator", "=", "self", ".", "_iterator", "\n", "\n", "", "dev_generator", "=", "dev_iterator", "(", "\n", "instances", "=", "self", ".", "_dev_dataset", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_epochs", "=", "1", "\n", ")", "\n", "\n", "num_dev_batches", "=", "dev_iterator", ".", "get_num_batches", "(", "self", ".", "_dev_dataset", ")", "\n", "dev_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "dev_generator", ",", "\n", "total", "=", "num_dev_batches", ")", "\n", "batches_this_epoch", "=", "0", "\n", "dev_loss", "=", "0", "\n", "for", "batch", "in", "dev_generator_tqdm", ":", "\n", "\n", "            ", "batches_this_epoch", "+=", "1", "\n", "loss", "=", "self", ".", "_batch_loss", "(", "batch", ",", "for_training", "=", "True", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "# You shouldn't necessarily have to compute a loss for validation, so we allow for", "\n", "# `loss` to be None.  We need to be careful, though - `batches_this_epoch` is", "\n", "# currently only used as the divisor for the loss function, so we can safely only", "\n", "# count those batches for which we actually have a loss.  If this variable ever", "\n", "# gets used for something else, we might need to change things around a bit.", "\n", "                ", "dev_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "                ", "dev_metrics", "=", "self", ".", "_model", ".", "module", ".", "get_metrics", "(", ")", "\n", "", "else", ":", "\n", "                ", "dev_metrics", "=", "self", ".", "_model", ".", "get_metrics", "(", ")", "\n", "", "description", "=", "self", ".", "_description_from_metrics", "(", "dev_metrics", ")", "\n", "dev_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "_n_gpus", ">", "1", ":", "\n", "            ", "return", "self", ".", "_model", ".", "module", ".", "get_metrics", "(", "reset", "=", "True", ",", "mimick_test", "=", "epoch", ">", "50", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_model", ".", "get_metrics", "(", "reset", "=", "True", ",", "mimick_test", "=", "epoch", ">", "50", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train": [[325, 406], ["trainer.Trainer._enable_gradient_clipping", "logger.info", "time.time", "range", "metrics.update", "trainer.Trainer.items", "trainer.Trainer.items", "trainer.Trainer._restore_checkpoint", "time.time", "trainer.Trainer._train_epoch", "trainer.Trainer._save_checkpoint", "trainer.Trainer._metrics_to_tensorboard", "trainer.Trainer._metrics_to_console", "trainer.Trainer._tensorboard.add_dev_scalar", "logger.info", "time.time", "dict", "traceback.print_exc", "stog.utils.checks.ConfigurationError", "metrics.update", "time.time", "time.strftime", "str", "logger.info", "torch.no_grad", "trainer.Trainer._validate_dev", "trainer.Trainer._is_best_so_far", "dev_metric_per_epoch.append", "trainer.Trainer._should_stop_early", "time.gmtime", "time.time", "datetime.timedelta", "time.strftime", "trainer.Trainer.copy", "logger.info", "time.gmtime", "trainer.Trainer.copy.items", "float", "int"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._enable_gradient_clipping", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._restore_checkpoint", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._train_epoch", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._metrics_to_tensorboard", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._metrics_to_console", "home.repos.pwc.inspect_result.jcyk_gtos.training.tensorboard.TensorboardWriter.add_dev_scalar", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._validate_dev", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._is_best_so_far", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._should_stop_early", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Trains the supplied model with the supplied parameters.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "epoch_counter", ",", "dev_metric_per_epoch", "=", "self", ".", "_restore_checkpoint", "(", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "ConfigurationError", "(", "\n", "\"Could not recover training from the checkpoint.  Did you mean to output to \"", "\n", "\"a different serialization directory or delete the existing serialization \"", "\n", "\"directory?\"", ")", "\n", "\n", "", "self", ".", "_enable_gradient_clipping", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "# Init.", "\n", "training_start_time", "=", "time", ".", "time", "(", ")", "\n", "epochs_trained_this_time", "=", "0", "\n", "metrics", "=", "{", "}", "\n", "training_metrics", "=", "{", "}", "\n", "dev_metrics", "=", "{", "}", "\n", "is_best_so_far", "=", "True", "\n", "best_epoch_dev_metrics", "=", "{", "}", "\n", "\n", "for", "epoch", "in", "range", "(", "epoch_counter", ",", "self", ".", "_num_epochs", ")", ":", "\n", "            ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "training_metrics", "=", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "# Validate on the dev set.", "\n", "if", "self", ".", "_dev_dataset", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "dev_metrics", "=", "self", ".", "_validate_dev", "(", "epoch", ")", "\n", "\n", "# Check dev metric for early stopping", "\n", "this_epoch_dev_metric", "=", "dev_metrics", "[", "self", ".", "_dev_metric", "]", "\n", "\n", "# Check dev metric to see if it's the best so far", "\n", "is_best_so_far", "=", "self", ".", "_is_best_so_far", "(", "this_epoch_dev_metric", ",", "dev_metric_per_epoch", ")", "\n", "if", "is_best_so_far", ":", "\n", "                        ", "best_epoch_dev_metrics", "=", "dev_metrics", ".", "copy", "(", ")", "\n", "", "dev_metric_per_epoch", ".", "append", "(", "this_epoch_dev_metric", ")", "\n", "if", "self", ".", "_should_stop_early", "(", "dev_metric_per_epoch", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "# Save status.", "\n", "", "", "", "self", ".", "_save_checkpoint", "(", "epoch", ",", "dev_metric_per_epoch", ",", "is_best", "=", "is_best_so_far", ")", "\n", "self", ".", "_metrics_to_tensorboard", "(", "epoch", ",", "training_metrics", ",", "dev_metrics", "=", "dev_metrics", ")", "\n", "self", ".", "_metrics_to_console", "(", "training_metrics", ",", "dev_metrics", "=", "dev_metrics", ")", "\n", "self", ".", "_tensorboard", ".", "add_dev_scalar", "(", "'learning_rate'", ",", "self", ".", "_optimizer", ".", "lr", ",", "epoch", ")", "\n", "\n", "if", "is_best_so_far", ":", "\n", "# We may not have had validation data, so we need to hide this behind an if.", "\n", "                ", "metrics", "[", "'best_epoch'", "]", "=", "epoch", "\n", "metrics", ".", "update", "(", "{", "f\"best_dev_{k}\"", ":", "v", "for", "k", ",", "v", "in", "best_epoch_dev_metrics", ".", "items", "(", ")", "}", ")", "\n", "\n", "# Estimate ETA.", "\n", "", "epoch_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "logger", ".", "info", "(", "\"Epoch duration: %s\"", ",", "time", ".", "strftime", "(", "\"%H:%M:%S\"", ",", "time", ".", "gmtime", "(", "epoch_elapsed_time", ")", ")", ")", "\n", "\n", "if", "epoch", "<", "self", ".", "_num_epochs", "-", "1", ":", "\n", "                ", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "estimated_time_remaining", "=", "training_elapsed_time", "*", "(", "(", "self", ".", "_num_epochs", "-", "epoch_counter", ")", "/", "float", "(", "epoch", "-", "epoch_counter", "+", "1", ")", "-", "1", ")", "\n", "formatted_time", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "estimated_time_remaining", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Estimated training time remaining: %s\"", ",", "formatted_time", ")", "\n", "\n", "", "epochs_trained_this_time", "+=", "1", "\n", "\n", "# Finish training, and summarize the status.", "\n", "", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "metrics", ".", "update", "(", "dict", "(", "\n", "training_duration", "=", "time", ".", "strftime", "(", "\"%H:%M:%S\"", ",", "time", ".", "gmtime", "(", "training_elapsed_time", ")", ")", ",", "\n", "training_start_epoch", "=", "epoch_counter", ",", "\n", "training_epochs", "=", "epochs_trained_this_time", "\n", ")", ")", "\n", "for", "key", ",", "value", "in", "training_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"training_\"", "+", "key", "]", "=", "value", "\n", "", "for", "key", ",", "value", "in", "dev_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"dev_\"", "+", "key", "]", "=", "value", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._enable_gradient_clipping": [[407, 415], ["trainer.Trainer._model.parameters", "grad.clamp", "parameter.register_hook"], "methods", ["None"], ["", "def", "_enable_gradient_clipping", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_grad_clipping", "is", "not", "None", ":", "\n", "# Pylint is unable to tell that we're in the case that _grad_clipping is not None...", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "            ", "clip_function", "=", "lambda", "grad", ":", "grad", ".", "clamp", "(", "-", "self", ".", "_grad_clipping", ",", "self", ".", "_grad_clipping", ")", "\n", "for", "parameter", "in", "self", ".", "_model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "parameter", ".", "requires_grad", ":", "\n", "                    ", "parameter", ".", "register_hook", "(", "clip_function", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._should_stop_early": [[416, 425], ["len", "max", "max"], "methods", ["None"], ["", "", "", "", "def", "_should_stop_early", "(", "self", ",", "metric_history", ":", "List", "[", "float", "]", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        uses patience and the validation metric to determine if training should stop early\n        \"\"\"", "\n", "if", "self", ".", "_patience", "and", "self", ".", "_patience", "<", "len", "(", "metric_history", ")", ":", "\n", "# Is the best score in the past N epochs worse than or equal the best score overall?", "\n", "            ", "return", "max", "(", "metric_history", "[", "-", "self", ".", "_patience", ":", "]", ")", "<=", "max", "(", "metric_history", "[", ":", "-", "self", ".", "_patience", "]", ")", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._is_best_so_far": [[426, 436], ["min", "max"], "methods", ["None"], ["", "def", "_is_best_so_far", "(", "self", ",", "\n", "this_epoch_dev_metric", ":", "float", ",", "\n", "dev_metric_per_epoch", ":", "List", "[", "float", "]", ")", ":", "\n", "        ", "if", "not", "dev_metric_per_epoch", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_dev_metric_decreases", ":", "\n", "                ", "return", "this_epoch_dev_metric", "<=", "min", "(", "dev_metric_per_epoch", ")", "\n", "", "else", ":", "\n", "                ", "return", "this_epoch_dev_metric", ">=", "max", "(", "dev_metric_per_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._description_from_metrics": [[437, 440], ["metrics.items", "name.startswith"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "", "def", "_description_from_metrics", "(", "self", ",", "metrics", ":", "Dict", "[", "str", ",", "float", "]", ")", "->", "str", ":", "\n", "        ", "return", "', '", ".", "join", "(", "[", "\"%s: %.4f\"", "%", "(", "name", ",", "value", ")", "for", "name", ",", "value", "in", "\n", "metrics", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "\"_\"", ")", "]", ")", "+", "\" ||\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._save_checkpoint": [[441, 484], ["os.path.join", "trainer.Trainer._model.state_dict", "torch.save", "os.path.join", "torch.save", "trainer.Trainer._optimizer.state_dict", "logger.info", "shutil.copyfile", "shutil.copyfile", "trainer.Trainer._serialized_paths.append", "os.path.join", "os.path.join", "len", "trainer.Trainer._serialized_paths.pop", "time.time", "os.remove"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict"], ["", "def", "_save_checkpoint", "(", "self", ",", "\n", "epoch", ":", "Union", "[", "int", ",", "str", "]", ",", "\n", "dev_metric_per_epoch", ":", "List", "[", "float", "]", ",", "\n", "is_best", ":", "Optional", "[", "bool", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves a checkpoint of the model to self._serialization_dir.\n        Is a no-op if self._serialization_dir is None.\n\n        Parameters\n        ----------\n        epoch : Union[int, str], required.\n            The epoch of training.  If the checkpoint is saved in the middle\n            of an epoch, the parameter is a string with the epoch and timestamp.\n        is_best: bool, optional (default = None)\n            A flag which causes the model weights at the given epoch to\n            be copied to a \"best.th\" file. The value of this flag should\n            be based on some validation metric computed by your model.\n        \"\"\"", "\n", "if", "self", ".", "_serialization_dir", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\"model_state_epoch_{}.th\"", ".", "format", "(", "epoch", ")", ")", "\n", "model_state", "=", "self", ".", "_model", ".", "state_dict", "(", ")", "\n", "torch", ".", "save", "(", "model_state", ",", "model_path", ")", "\n", "\n", "training_state", "=", "{", "'epoch'", ":", "epoch", ",", "\n", "'dev_metric_per_epoch'", ":", "dev_metric_per_epoch", ",", "\n", "'optimizer'", ":", "self", ".", "_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'num_trained_batches'", ":", "self", ".", "_num_trained_batches", "}", "\n", "training_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\n", "\"training_state_epoch_{}.th\"", ".", "format", "(", "epoch", ")", ")", "\n", "torch", ".", "save", "(", "training_state", ",", "training_path", ")", "\n", "if", "is_best", ":", "\n", "                ", "logger", ".", "info", "(", "\"Best validation performance so far. \"", "\n", "\"Copying weights to '%s/best.th'.\"", ",", "self", ".", "_serialization_dir", ")", "\n", "shutil", ".", "copyfile", "(", "model_path", ",", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\"best.th\"", ")", ")", "\n", "shutil", ".", "copyfile", "(", "training_path", ",", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_serialization_dir", ",", "\"best_training_state.th\"", ")", ")", "\n", "\n", "", "if", "self", ".", "_num_serialized_models_to_keep", "and", "self", ".", "_num_serialized_models_to_keep", ">=", "0", ":", "\n", "                ", "self", ".", "_serialized_paths", ".", "append", "(", "[", "time", ".", "time", "(", ")", ",", "model_path", ",", "training_path", "]", ")", "\n", "if", "len", "(", "self", ".", "_serialized_paths", ")", ">", "self", ".", "_num_serialized_models_to_keep", ":", "\n", "                    ", "paths_to_remove", "=", "self", ".", "_serialized_paths", ".", "pop", "(", "0", ")", "\n", "for", "fname", "in", "paths_to_remove", "[", "1", ":", "]", ":", "\n", "                        ", "os", ".", "remove", "(", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._find_latest_checkpoint": [[485, 525], ["os.listdir", "os.path.join", "os.path.join", "re.search().group", "len", "epoch.split", "sorted", "str", "len", "int_epochs.append", "int_epochs.append", "re.search", "int", "int"], "methods", ["None"], ["", "", "", "", "", "def", "_find_latest_checkpoint", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_serialization_dir", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "serialization_files", "=", "os", ".", "listdir", "(", "self", ".", "_serialization_dir", ")", "\n", "model_checkpoints", "=", "[", "x", "for", "x", "in", "serialization_files", "if", "'model_state_epoch'", "in", "x", "]", "\n", "# Get the last checkpoint file.  Epochs are specified as either an", "\n", "# int (for end of epoch files) or with epoch and timestamp for", "\n", "# within epoch checkpoints, e.g. 5.2018-02-02-15-33-42", "\n", "found_epochs", "=", "[", "\n", "# pylint: disable=anomalous-backslash-in-string", "\n", "re", ".", "search", "(", "\"model_state_epoch_([0-9\\.\\-]+)\\.th\"", ",", "x", ")", ".", "group", "(", "1", ")", "\n", "for", "x", "in", "model_checkpoints", "\n", "]", "\n", "if", "len", "(", "found_epochs", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "int_epochs", "=", "[", "]", "\n", "for", "epoch", "in", "found_epochs", ":", "\n", "            ", "pieces", "=", "epoch", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "pieces", ")", "==", "1", ":", "\n", "# Just a single epoch without timestamp", "\n", "                ", "int_epochs", ".", "append", "(", "[", "int", "(", "pieces", "[", "0", "]", ")", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "# has a timestamp", "\n", "                ", "int_epochs", ".", "append", "(", "[", "int", "(", "pieces", "[", "0", "]", ")", ",", "pieces", "[", "1", "]", "]", ")", "\n", "", "", "last_epoch", "=", "sorted", "(", "int_epochs", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "if", "last_epoch", "[", "1", "]", "==", "0", ":", "\n", "            ", "epoch_to_load", "=", "str", "(", "last_epoch", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "epoch_to_load", "=", "'{0}.{1}'", ".", "format", "(", "last_epoch", "[", "0", "]", ",", "last_epoch", "[", "1", "]", ")", "\n", "\n", "# model state", "\n", "", "model_state_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_serialization_dir", ",", "'model_state_epoch_{}.th'", ".", "format", "(", "epoch_to_load", ")", ")", "\n", "# misc training state, e.g. optimizer state, epoch, etc.", "\n", "training_state_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_serialization_dir", ",", "'training_state_epoch_{}.th'", ".", "format", "(", "epoch_to_load", ")", "\n", ")", "\n", "return", "model_state_path", ",", "training_state_path", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._restore_checkpoint": [[526, 542], ["trainer.Trainer._find_latest_checkpoint", "torch.load", "trainer.Trainer._model.load_state_dict", "torch.load", "trainer.Trainer._optimizer.set_state", "stog.utils.environment.device_mapping", "stog.utils.environment.device_mapping"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer._find_latest_checkpoint", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.set_state", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.device_mapping", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.device_mapping"], ["", "def", "_restore_checkpoint", "(", "self", ")", ":", "\n", "        ", "last_checkpoint", "=", "self", ".", "_find_latest_checkpoint", "(", ")", "\n", "\n", "if", "last_checkpoint", "is", "None", ":", "\n", "            ", "return", "0", ",", "[", "]", "\n", "\n", "", "model_state_path", ",", "training_state_path", "=", "last_checkpoint", "\n", "\n", "model_state", "=", "torch", ".", "load", "(", "model_state_path", ",", "map_location", "=", "device_mapping", "(", "-", "1", ")", ")", "\n", "self", ".", "_model", ".", "load_state_dict", "(", "model_state", ")", "\n", "training_state", "=", "torch", ".", "load", "(", "training_state_path", ",", "map_location", "=", "device_mapping", "(", "-", "1", ")", ")", "\n", "self", ".", "_num_trained_batches", "=", "training_state", "[", "'num_trained_batches'", "]", "\n", "self", ".", "_optimizer", ".", "set_state", "(", "training_state", "[", "'optimizer'", "]", ")", "\n", "self", ".", "_optimizer", ".", "_step", "=", "self", ".", "_num_trained_batches", "\n", "starting_epoch", "=", "training_state", "[", "'epoch'", "]", "+", "1", "\n", "return", "starting_epoch", ",", "training_state", "[", "'dev_metric_per_epoch'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.from_params": [[543, 592], ["logger.info", "torch.cuda.device_count", "torch.nn.DataParallel.to", "stog.modules.optimizer.Optimizer", "stog.modules.optimizer.Optimizer.set_parameters", "cls", "logger.info", "torch.nn.DataParallel", "torch.nn.DataParallel.named_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.set_parameters"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "model", ",", "train_data", ",", "dev_data", ",", "train_iterator", ",", "dev_iterator", ",", "params", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Building optimizer..'", ")", "\n", "\n", "device", "=", "params", "[", "'device'", "]", "\n", "optimizer_type", "=", "params", "[", "'optimizer_type'", "]", "\n", "lr", "=", "params", "[", "'learning_rate'", "]", "\n", "max_grad_norm", "=", "params", "[", "'max_grad_norm'", "]", "\n", "dev_metric", "=", "params", "[", "'dev_metric'", "]", "\n", "shuffle", "=", "params", "[", "'shuffle'", "]", "\n", "epochs", "=", "params", "[", "'epochs'", "]", "\n", "serialization_dir", "=", "params", "[", "'serialization_dir'", "]", "\n", "model_save_interval", "=", "params", "[", "'model_save_interval'", "]", "\n", "batch_size", "=", "params", "[", "'batch_size'", "]", "\n", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "if", "n_gpus", ">", "1", ":", "\n", "            ", "logger", ".", "info", "(", "'Multi-GPU ({}) model is enabled!'", ".", "format", "(", "n_gpus", ")", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "Optimizer", "(", "optimizer_type", ",", "lr", ",", "max_grad_norm", ",", "device", "=", "device", ")", "\n", "\n", "parameters", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", ".", "set_parameters", "(", "parameters", ")", "\n", "\n", "trainer", "=", "cls", "(", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "iterator", "=", "train_iterator", ",", "\n", "training_dataset", "=", "train_data", ",", "\n", "dev_dataset", "=", "dev_data", ",", "\n", "dev_iterator", "=", "dev_iterator", ",", "\n", "dev_metric", "=", "dev_metric", ",", "\n", "device", "=", "device", ",", "\n", "patience", "=", "None", ",", "\n", "grad_clipping", "=", "None", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_epochs", "=", "epochs", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "5", ",", "\n", "model_save_interval", "=", "model_save_interval", ",", "\n", "summary_interval", "=", "100", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "n_gpus", "=", "n_gpus", "\n", ")", "\n", "\n", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.augmented_lstm.AugmentedLstm.__init__": [[59, 85], ["super().__init__", "augmented_lstm.AugmentedLstm.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ",", "\n", "go_forward", ":", "bool", "=", "True", ",", "\n", "recurrent_dropout_probability", ":", "float", "=", "0.0", ",", "\n", "use_highway", ":", "bool", "=", "True", ",", "\n", "use_input_projection_bias", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", "AugmentedLstm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Required to be wrapped with a :class:`PytorchSeq2SeqWrapper`.", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "self", ".", "go_forward", "=", "go_forward", "\n", "self", ".", "use_highway", "=", "use_highway", "\n", "self", ".", "recurrent_dropout_probability", "=", "recurrent_dropout_probability", "\n", "\n", "# We do the projections for all the gates all at once, so if we are", "\n", "# using highway layers, we need some extra projections, which is", "\n", "# why the sizes of the Linear layers change here depending on this flag.", "\n", "if", "use_highway", ":", "\n", "            ", "self", ".", "input_linearity", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "6", "*", "hidden_size", ",", "bias", "=", "use_input_projection_bias", ")", "\n", "self", ".", "state_linearity", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "5", "*", "hidden_size", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_linearity", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "4", "*", "hidden_size", ",", "bias", "=", "use_input_projection_bias", ")", "\n", "self", ".", "state_linearity", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "4", "*", "hidden_size", ",", "bias", "=", "True", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.augmented_lstm.AugmentedLstm.reset_parameters": [[86, 95], ["stog.modules.initializers.block_orthogonal", "stog.modules.initializers.block_orthogonal", "augmented_lstm.AugmentedLstm.state_linearity.bias.data.fill_", "augmented_lstm.AugmentedLstm.state_linearity.bias.data[].fill_"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.block_orthogonal", "home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.block_orthogonal"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "# Use sensible default initializations for parameters.", "\n", "        ", "block_orthogonal", "(", "self", ".", "input_linearity", ".", "weight", ".", "data", ",", "[", "self", ".", "hidden_size", ",", "self", ".", "input_size", "]", ")", "\n", "block_orthogonal", "(", "self", ".", "state_linearity", ".", "weight", ".", "data", ",", "[", "self", ".", "hidden_size", ",", "self", ".", "hidden_size", "]", ")", "\n", "\n", "self", ".", "state_linearity", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "# Initialize forget gate biases to 1.0 as per An Empirical", "\n", "# Exploration of Recurrent Network Architectures, (Jozefowicz, 2015).", "\n", "self", ".", "state_linearity", ".", "bias", ".", "data", "[", "self", ".", "hidden_size", ":", "2", "*", "self", ".", "hidden_size", "]", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.augmented_lstm.AugmentedLstm.forward": [[96, 212], ["torch.nn.utils.rnn.pad_packed_sequence", "sequence_tensor.new_zeros", "range", "torch.nn.utils.rnn.pack_padded_sequence", "isinstance", "stog.utils.checks.ConfigurationError", "sequence_tensor.size", "sequence_tensor.size", "sequence_tensor.new_zeros", "sequence_tensor.data.new_zeros", "initial_state[].squeeze", "initial_state[].squeeze", "stog.utils.nn.get_dropout_mask", "full_batch_previous_memory[].clone", "full_batch_previous_state[].clone", "augmented_lstm.AugmentedLstm.input_linearity", "augmented_lstm.AugmentedLstm.state_linearity", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.sigmoid", "full_batch_previous_memory.data.clone.data.clone.data.clone", "full_batch_previous_state.data.clone.data.clone.data.clone", "full_batch_previous_state.data.clone.data.clone.unsqueeze", "full_batch_previous_memory.data.clone.data.clone.unsqueeze", "torch.tanh", "torch.sigmoid", "type", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_dropout_mask"], ["", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "PackedSequence", ",", "\n", "initial_state", ":", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        inputs : PackedSequence, required.\n            A tensor of shape (batch_size, num_timesteps, input_size)\n            to apply the LSTM over.\n        initial_state : Tuple[torch.Tensor, torch.Tensor], optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. Each tensor has shape (1, batch_size, output_dimension).\n        Returns\n        -------\n        A PackedSequence containing a torch.FloatTensor of shape\n        (batch_size, num_timesteps, output_dimension) representing\n        the outputs of the LSTM per timestep and a tuple containing\n        the LSTM state, with shape (1, batch_size, hidden_size) to\n        match the Pytorch API.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "PackedSequence", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'inputs must be PackedSequence but got %s'", "%", "(", "type", "(", "inputs", ")", ")", ")", "\n", "\n", "", "sequence_tensor", ",", "batch_lengths", "=", "pad_packed_sequence", "(", "inputs", ",", "batch_first", "=", "True", ")", "\n", "batch_size", "=", "sequence_tensor", ".", "size", "(", ")", "[", "0", "]", "\n", "total_timesteps", "=", "sequence_tensor", ".", "size", "(", ")", "[", "1", "]", "\n", "\n", "output_accumulator", "=", "sequence_tensor", ".", "new_zeros", "(", "batch_size", ",", "total_timesteps", ",", "self", ".", "hidden_size", ")", "\n", "if", "initial_state", "is", "None", ":", "\n", "            ", "full_batch_previous_memory", "=", "sequence_tensor", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "full_batch_previous_state", "=", "sequence_tensor", ".", "data", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "full_batch_previous_state", "=", "initial_state", "[", "0", "]", ".", "squeeze", "(", "0", ")", "\n", "full_batch_previous_memory", "=", "initial_state", "[", "1", "]", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "current_length_index", "=", "batch_size", "-", "1", "if", "self", ".", "go_forward", "else", "0", "\n", "if", "self", ".", "recurrent_dropout_probability", ">", "0.0", ":", "\n", "            ", "dropout_mask", "=", "get_dropout_mask", "(", "self", ".", "recurrent_dropout_probability", ",", "full_batch_previous_memory", ")", "\n", "", "else", ":", "\n", "            ", "dropout_mask", "=", "None", "\n", "\n", "", "for", "timestep", "in", "range", "(", "total_timesteps", ")", ":", "\n", "# The index depends on which end we start.", "\n", "            ", "index", "=", "timestep", "if", "self", ".", "go_forward", "else", "total_timesteps", "-", "timestep", "-", "1", "\n", "\n", "# What we are doing here is finding the index into the batch dimension", "\n", "# which we need to use for this timestep, because the sequences have", "\n", "# variable length, so once the index is greater than the length of this", "\n", "# particular batch sequence, we no longer need to do the computation for", "\n", "# this sequence. The key thing to recognise here is that the batch inputs", "\n", "# must be _ordered_ by length from longest (first in batch) to shortest", "\n", "# (last) so initially, we are going forwards with every sequence and as we", "\n", "# pass the index at which the shortest elements of the batch finish,", "\n", "# we stop picking them up for the computation.", "\n", "if", "self", ".", "go_forward", ":", "\n", "                ", "while", "batch_lengths", "[", "current_length_index", "]", "<=", "index", ":", "\n", "                    ", "current_length_index", "-=", "1", "\n", "# If we're going backwards, we are _picking up_ more indices.", "\n", "", "", "else", ":", "\n", "# First conditional: Are we already at the maximum number of elements in the batch?", "\n", "# Second conditional: Does the next shortest sequence beyond the current batch", "\n", "# index require computation use this timestep?", "\n", "                ", "while", "current_length_index", "<", "(", "len", "(", "batch_lengths", ")", "-", "1", ")", "and", "batch_lengths", "[", "current_length_index", "+", "1", "]", ">", "index", ":", "\n", "                    ", "current_length_index", "+=", "1", "\n", "\n", "# Actually get the slices of the batch which we need for the computation at this timestep.", "\n", "", "", "previous_memory", "=", "full_batch_previous_memory", "[", "0", ":", "current_length_index", "+", "1", "]", ".", "clone", "(", ")", "\n", "previous_state", "=", "full_batch_previous_state", "[", "0", ":", "current_length_index", "+", "1", "]", ".", "clone", "(", ")", "\n", "timestep_input", "=", "sequence_tensor", "[", "0", ":", "current_length_index", "+", "1", ",", "index", "]", "\n", "\n", "# Do the projections for all the gates all at once.", "\n", "projected_input", "=", "self", ".", "input_linearity", "(", "timestep_input", ")", "\n", "projected_state", "=", "self", ".", "state_linearity", "(", "previous_state", ")", "\n", "\n", "# Main LSTM equations using relevant chunks of the big linear", "\n", "# projections of the hidden state and inputs.", "\n", "input_gate", "=", "torch", ".", "sigmoid", "(", "projected_input", "[", ":", ",", "0", "*", "self", ".", "hidden_size", ":", "1", "*", "self", ".", "hidden_size", "]", "+", "\n", "projected_state", "[", ":", ",", "0", "*", "self", ".", "hidden_size", ":", "1", "*", "self", ".", "hidden_size", "]", ")", "\n", "forget_gate", "=", "torch", ".", "sigmoid", "(", "projected_input", "[", ":", ",", "1", "*", "self", ".", "hidden_size", ":", "2", "*", "self", ".", "hidden_size", "]", "+", "\n", "projected_state", "[", ":", ",", "1", "*", "self", ".", "hidden_size", ":", "2", "*", "self", ".", "hidden_size", "]", ")", "\n", "memory_init", "=", "torch", ".", "tanh", "(", "projected_input", "[", ":", ",", "2", "*", "self", ".", "hidden_size", ":", "3", "*", "self", ".", "hidden_size", "]", "+", "\n", "projected_state", "[", ":", ",", "2", "*", "self", ".", "hidden_size", ":", "3", "*", "self", ".", "hidden_size", "]", ")", "\n", "output_gate", "=", "torch", ".", "sigmoid", "(", "projected_input", "[", ":", ",", "3", "*", "self", ".", "hidden_size", ":", "4", "*", "self", ".", "hidden_size", "]", "+", "\n", "projected_state", "[", ":", ",", "3", "*", "self", ".", "hidden_size", ":", "4", "*", "self", ".", "hidden_size", "]", ")", "\n", "memory", "=", "input_gate", "*", "memory_init", "+", "forget_gate", "*", "previous_memory", "\n", "timestep_output", "=", "output_gate", "*", "torch", ".", "tanh", "(", "memory", ")", "\n", "\n", "if", "self", ".", "use_highway", ":", "\n", "                ", "highway_gate", "=", "torch", ".", "sigmoid", "(", "projected_input", "[", ":", ",", "4", "*", "self", ".", "hidden_size", ":", "5", "*", "self", ".", "hidden_size", "]", "+", "\n", "projected_state", "[", ":", ",", "4", "*", "self", ".", "hidden_size", ":", "5", "*", "self", ".", "hidden_size", "]", ")", "\n", "highway_input_projection", "=", "projected_input", "[", ":", ",", "5", "*", "self", ".", "hidden_size", ":", "6", "*", "self", ".", "hidden_size", "]", "\n", "timestep_output", "=", "highway_gate", "*", "timestep_output", "+", "(", "1", "-", "highway_gate", ")", "*", "highway_input_projection", "\n", "\n", "# Only do dropout if the dropout prob is > 0.0 and we are in training mode.", "\n", "", "if", "dropout_mask", "is", "not", "None", "and", "self", ".", "training", ":", "\n", "                ", "timestep_output", "=", "timestep_output", "*", "dropout_mask", "[", "0", ":", "current_length_index", "+", "1", "]", "\n", "\n", "# We've been doing computation with less than the full batch, so here we create a new", "\n", "# variable for the the whole batch at this timestep and insert the result for the", "\n", "# relevant elements of the batch into it.", "\n", "", "full_batch_previous_memory", "=", "full_batch_previous_memory", ".", "data", ".", "clone", "(", ")", "\n", "full_batch_previous_state", "=", "full_batch_previous_state", ".", "data", ".", "clone", "(", ")", "\n", "full_batch_previous_memory", "[", "0", ":", "current_length_index", "+", "1", "]", "=", "memory", "\n", "full_batch_previous_state", "[", "0", ":", "current_length_index", "+", "1", "]", "=", "timestep_output", "\n", "output_accumulator", "[", "0", ":", "current_length_index", "+", "1", ",", "index", "]", "=", "timestep_output", "\n", "\n", "", "output_accumulator", "=", "pack_padded_sequence", "(", "output_accumulator", ",", "batch_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Mimic the pytorch API by returning state in the following shape:", "\n", "# (num_layers * num_directions, batch_size, hidden_size). As this", "\n", "# LSTM cannot be stacked, the first dimension here is just 1.", "\n", "final_state", "=", "(", "full_batch_previous_state", ".", "unsqueeze", "(", "0", ")", ",", "\n", "full_batch_previous_memory", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "return", "output_accumulator", ",", "final_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_lstm.StackedLstm.__init__": [[32, 60], ["super().__init__", "range", "stog.modules.augmented_lstm.AugmentedLstm", "stacked_lstm.StackedLstm.add_module", "layers.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ",", "\n", "num_layers", ":", "int", ",", "\n", "recurrent_dropout_probability", ":", "float", "=", "0.0", ",", "\n", "use_highway", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", "StackedLstm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Required to be wrapped with a :class:`PytorchSeq2SeqWrapper`.", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bidirectional", "=", "False", "\n", "\n", "layers", "=", "[", "]", "\n", "lstm_input_size", "=", "input_size", "\n", "for", "layer_index", "in", "range", "(", "num_layers", ")", ":", "\n", "\n", "            ", "layer", "=", "AugmentedLstm", "(", "lstm_input_size", ",", "hidden_size", ",", "\n", "go_forward", "=", "True", ",", "\n", "recurrent_dropout_probability", "=", "recurrent_dropout_probability", ",", "\n", "use_highway", "=", "use_highway", ",", "\n", "use_input_projection_bias", "=", "False", ")", "\n", "lstm_input_size", "=", "hidden_size", "\n", "self", ".", "add_module", "(", "'layer_{}'", ".", "format", "(", "layer_index", ")", ",", "layer", ")", "\n", "layers", ".", "append", "(", "layer", ")", "\n", "\n", "", "self", ".", "lstm_layers", "=", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_lstm.StackedLstm.forward": [[61, 99], ["enumerate", "getattr", "getattr.", "final_states.append", "torch.cat", "len", "len", "stog.utils.checks.ConfigurationError", "list", "zip", "initial_state[].size", "zip", "initial_state[].split", "initial_state[].split"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "PackedSequence", ",", "\n", "initial_state", ":", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        inputs : ``PackedSequence``, required.\n            A batch first ``PackedSequence`` to run the stacked LSTM over.\n        initial_state : Tuple[torch.Tensor, torch.Tensor], optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. Each tensor has shape (1, batch_size, output_dimension).\n        Returns\n        -------\n        output_sequence : PackedSequence\n            The encoded sequence of shape (batch_size, sequence_length, hidden_size)\n        final_states: torch.Tensor\n            The per-layer final (state, memory) states of the LSTM, each with shape\n            (num_layers, batch_size, hidden_size).\n        \"\"\"", "\n", "if", "not", "initial_state", ":", "\n", "            ", "hidden_states", "=", "[", "None", "]", "*", "len", "(", "self", ".", "lstm_layers", ")", "\n", "", "elif", "initial_state", "[", "0", "]", ".", "size", "(", ")", "[", "0", "]", "!=", "len", "(", "self", ".", "lstm_layers", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Initial states were passed to forward() but the number of \"", "\n", "\"initial states does not match the number of layers.\"", ")", "\n", "", "else", ":", "\n", "            ", "hidden_states", "=", "list", "(", "zip", "(", "initial_state", "[", "0", "]", ".", "split", "(", "1", ",", "0", ")", ",", "\n", "initial_state", "[", "1", "]", ".", "split", "(", "1", ",", "0", ")", ")", ")", "\n", "\n", "", "output_sequence", "=", "inputs", "\n", "final_states", "=", "[", "]", "\n", "for", "i", ",", "state", "in", "enumerate", "(", "hidden_states", ")", ":", "\n", "            ", "forward_layer", "=", "getattr", "(", "self", ",", "'layer_{}'", ".", "format", "(", "i", ")", ")", "\n", "# The state is duplicated to mirror the Pytorch API for LSTMs.", "\n", "output_sequence", ",", "final_state", "=", "forward_layer", "(", "output_sequence", ",", "state", ")", "\n", "final_states", ".", "append", "(", "final_state", ")", "\n", "\n", "", "final_state_tuple", "=", "[", "torch", ".", "cat", "(", "state_list", ",", "0", ")", "for", "state_list", "in", "zip", "(", "*", "final_states", ")", "]", "\n", "return", "output_sequence", ",", "final_state_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_lstm.StackedLstm.from_params": [[100, 108], ["cls", "params.get", "params.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "params", ")", ":", "\n", "        ", "return", "cls", "(", "\n", "input_size", "=", "params", "[", "'input_size'", "]", ",", "\n", "hidden_size", "=", "params", "[", "'hidden_size'", "]", ",", "\n", "num_layers", "=", "params", "[", "'num_layers'", "]", ",", "\n", "recurrent_dropout_probability", "=", "params", ".", "get", "(", "'dropout'", ",", "0.0", ")", ",", "\n", "use_highway", "=", "params", ".", "get", "(", "'use_highway'", ",", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.time_distributed.TimeDistributed.__init__": [[21, 24], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "super", "(", "TimeDistributed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_module", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.time_distributed.TimeDistributed.forward": [[25, 45], ["time_distributed.TimeDistributed._module", "time_distributed.TimeDistributed.contiguous().view", "input_tensor.size", "reshaped_inputs.append", "len", "RuntimeError", "input_tensor.contiguous().view", "time_distributed.TimeDistributed.contiguous", "str", "input_tensor.contiguous", "time_distributed.TimeDistributed.size"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "reshaped_inputs", "=", "[", "]", "\n", "for", "input_tensor", "in", "inputs", ":", "\n", "            ", "input_size", "=", "input_tensor", ".", "size", "(", ")", "\n", "if", "len", "(", "input_size", ")", "<=", "2", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"No dimension to distribute: \"", "+", "str", "(", "input_size", ")", ")", "\n", "\n", "# Squash batch_size and time_steps into a single axis; result has shape", "\n", "# (batch_size * time_steps, input_size).", "\n", "", "squashed_shape", "=", "[", "-", "1", "]", "+", "[", "x", "for", "x", "in", "input_size", "[", "2", ":", "]", "]", "\n", "reshaped_inputs", ".", "append", "(", "input_tensor", ".", "contiguous", "(", ")", ".", "view", "(", "*", "squashed_shape", ")", ")", "\n", "\n", "", "reshaped_outputs", "=", "self", ".", "_module", "(", "*", "reshaped_inputs", ")", "\n", "\n", "# Now get the output back into the right shape.", "\n", "# (batch_size, time_steps, [hidden_size])", "\n", "new_shape", "=", "[", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", "]", "+", "[", "x", "for", "x", "in", "reshaped_outputs", ".", "size", "(", ")", "[", "1", ":", "]", "]", "\n", "outputs", "=", "reshaped_outputs", ".", "contiguous", "(", ")", ".", "view", "(", "*", "new_shape", ")", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.input_variational_dropout.InputVariationalDropout.forward": [[12, 32], ["input_tensor.data.new_ones", "torch.nn.functional.dropout", "torch.nn.functional.dropout.unsqueeze", "torch.nn.functional.dropout.unsqueeze"], "methods", ["None"], ["def", "forward", "(", "self", ",", "input_tensor", ")", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Apply dropout to input tensor.\n        Parameters\n        ----------\n        input_tensor: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)``\n        Returns\n        -------\n        output: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)`` with dropout applied.\n        \"\"\"", "\n", "ones", "=", "input_tensor", ".", "data", ".", "new_ones", "(", "input_tensor", ".", "shape", "[", "0", "]", ",", "input_tensor", ".", "shape", "[", "-", "1", "]", ")", "\n", "dropout_mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "ones", ",", "self", ".", "p", ",", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "if", "self", ".", "inplace", ":", "\n", "            ", "input_tensor", "*=", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "*", "input_tensor", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.uniform_unit_scaling": [[39, 74], ["torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "tensor.uniform_", "list", "math.sqrt", "tensor.size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["def", "uniform_unit_scaling", "(", "tensor", ":", "torch", ".", "Tensor", ",", "nonlinearity", ":", "str", "=", "\"linear\"", ")", ":", "\n", "    ", "\"\"\"\n    An initaliser which preserves output variance for approximately gaussian\n    distributed inputs. This boils down to initialising layers using a uniform\n    distribution in the range ``(-sqrt(3/dim[0]) * scale, sqrt(3 / dim[0]) * scale)``, where\n    ``dim[0]`` is equal to the input dimension of the parameter and the ``scale``\n    is a constant scaling factor which depends on the non-linearity used.\n    See `Random Walk Initialisation for Training Very Deep Feedforward Networks\n    <https://www.semanticscholar.org/paper/Random-Walk-Initialization-for-Training-Very-Deep-Sussillo-Abbott/be9728a0728b6acf7a485225b1e41592176eda0b>`_\n    for more information.\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``, required.\n        The tensor to initialise.\n    nonlinearity : ``str``, optional (default = \"linear\")\n        The non-linearity which is performed after the projection that this\n        tensor is involved in. This must be the name of a function contained\n        in the ``torch.nn.functional`` package.\n    Returns\n    -------\n    The initialised tensor.\n    \"\"\"", "\n", "size", "=", "1.", "\n", "# Estimate the input size. This won't work perfectly,", "\n", "# but it covers almost all use cases where this initialiser", "\n", "# would be expected to be useful, i.e in large linear and", "\n", "# convolutional layers, as the last dimension will almost", "\n", "# always be the output size.", "\n", "for", "dimension", "in", "list", "(", "tensor", ".", "size", "(", ")", ")", "[", ":", "-", "1", "]", ":", "\n", "        ", "size", "*=", "dimension", "\n", "\n", "", "activation_scaling", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "nonlinearity", ",", "tensor", ")", "\n", "max_value", "=", "math", ".", "sqrt", "(", "3", "/", "size", ")", "*", "activation_scaling", "\n", "\n", "return", "tensor", ".", "uniform_", "(", "-", "max_value", ",", "max_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.block_orthogonal": [[76, 116], ["list", "any", "itertools.product", "tensor.size", "stog.utils.checks.ConfigurationError", "list", "zip", "tuple", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "range", "zip", "tensor[].contiguous", "zip", "slice"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "block_orthogonal", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "split_sizes", ":", "List", "[", "int", "]", ",", "\n", "gain", ":", "float", "=", "1.0", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    An initializer which allows initializing model parameters in \"blocks\". This is helpful\n    in the case of recurrent models which use multiple gates applied to linear projections,\n    which can be computed efficiently if they are concatenated together. However, they are\n    separate parameters which should be initialized independently.\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``, required.\n        A tensor to initialize.\n    split_sizes : List[int], required.\n        A list of length ``tensor.ndim()`` specifying the size of the\n        blocks along that particular dimension. E.g. ``[10, 20]`` would\n        result in the tensor being split into chunks of size 10 along the\n        first dimension and 20 along the second.\n    gain : float, optional (default = 1.0)\n        The gain (scaling) applied to the orthogonal initialization.\n    \"\"\"", "\n", "data", "=", "tensor", ".", "data", "\n", "sizes", "=", "list", "(", "tensor", ".", "size", "(", ")", ")", "\n", "if", "any", "(", "[", "a", "%", "b", "!=", "0", "for", "a", ",", "b", "in", "zip", "(", "sizes", ",", "split_sizes", ")", "]", ")", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"tensor dimensions must be divisible by their respective \"", "\n", "\"split_sizes. Found size: {} and split_sizes: {}\"", ".", "format", "(", "sizes", ",", "split_sizes", ")", ")", "\n", "", "indexes", "=", "[", "list", "(", "range", "(", "0", ",", "max_size", ",", "split", ")", ")", "\n", "for", "max_size", ",", "split", "in", "zip", "(", "sizes", ",", "split_sizes", ")", "]", "\n", "# Iterate over all possible blocks within the tensor.", "\n", "for", "block_start_indices", "in", "itertools", ".", "product", "(", "*", "indexes", ")", ":", "\n", "# A list of tuples containing the index to start at for this block", "\n", "# and the appropriate step size (i.e split_size[i] for dimension i).", "\n", "        ", "index_and_step_tuples", "=", "zip", "(", "block_start_indices", ",", "split_sizes", ")", "\n", "# This is a tuple of slices corresponding to:", "\n", "# tensor[index: index + step_size, ...]. This is", "\n", "# required because we could have an arbitrary number", "\n", "# of dimensions. The actual slices we need are the", "\n", "# start_index: start_index + step for each dimension in the tensor.", "\n", "block_slice", "=", "tuple", "(", "[", "slice", "(", "start_index", ",", "start_index", "+", "step", ")", "\n", "for", "start_index", ",", "step", "in", "index_and_step_tuples", "]", ")", "\n", "data", "[", "block_slice", "]", "=", "torch", ".", "nn", ".", "init", ".", "orthogonal_", "(", "tensor", "[", "block_slice", "]", ".", "contiguous", "(", ")", ",", "gain", "=", "gain", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.zero": [[118, 120], ["tensor.data.zero_"], "function", ["None"], ["", "", "def", "zero", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "None", ":", "\n", "    ", "return", "tensor", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.initializers.lstm_hidden_bias": [[121, 130], ["tensor.data.zero_"], "function", ["None"], ["", "def", "lstm_hidden_bias", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Initialize the biases of the forget gate to 1, and all other gates to 0,\n    following Jozefowicz et al., An Empirical Exploration of Recurrent Network Architectures\n    \"\"\"", "\n", "# gates are (b_hi|b_hf|b_hg|b_ho) of shape (4*hidden_size)", "\n", "tensor", ".", "data", ".", "zero_", "(", ")", "\n", "hidden_size", "=", "tensor", ".", "shape", "[", "0", "]", "//", "4", "\n", "tensor", ".", "data", "[", "hidden_size", ":", "(", "2", "*", "hidden_size", ")", "]", "=", "1.0", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.__init__": [[29, 33], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "stateful", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "_EncoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stateful", "=", "stateful", "\n", "self", ".", "_states", ":", "Optional", "[", "RnnStateStorage", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.sort_and_run_forward": [[34, 123], ["mask.size", "torch.sum().int().item", "stog.utils.nn.get_lengths_from_binary_sequence_mask", "stog.utils.nn.sort_batch_by_length", "torch.nn.utils.rnn.pack_padded_sequence", "module", "sorted_sequence_lengths[].data.tolist", "encoder_base._EncoderBase._get_initial_states", "torch.sum().int", "isinstance", "[].contiguous", "torch.sum", "[].contiguous", "hidden_state.index_select", "state.index_select"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_lengths_from_binary_sequence_mask", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.sort_batch_by_length", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase._get_initial_states"], ["", "def", "sort_and_run_forward", "(", "self", ",", "\n", "module", ":", "Callable", "[", "[", "PackedSequence", ",", "Optional", "[", "RnnState", "]", "]", ",", "\n", "Tuple", "[", "Union", "[", "PackedSequence", ",", "torch", ".", "Tensor", "]", ",", "RnnState", "]", "]", ",", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "Optional", "[", "RnnState", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Adopted from AllenNLP:\n            https://github.com/allenai/allennlp/blob/v0.6.1/allennlp/modules/encoder_base.py\n\n        This function exists because Pytorch RNNs require that their inputs be sorted\n        before being passed as input. As all of our Seq2xxxEncoders use this functionality,\n        it is provided in a base class. This method can be called on any module which\n        takes as input a ``PackedSequence`` and some ``hidden_state``, which can either be a\n        tuple of tensors or a tensor.\n        As all of our Seq2xxxEncoders have different return types, we return `sorted`\n        outputs from the module, which is called directly. Additionally, we return the\n        indices into the batch dimension required to restore the tensor to it's correct,\n        unsorted order and the number of valid batch elements (i.e the number of elements\n        in the batch which are not completely masked). This un-sorting and re-padding\n        of the module outputs is left to the subclasses because their outputs have different\n        types and handling them smoothly here is difficult.\n        Parameters\n        ----------\n        module : ``Callable[[PackedSequence, Optional[RnnState]],\n                            Tuple[Union[PackedSequence, torch.Tensor], RnnState]]``, required.\n            A function to run on the inputs. In most cases, this is a ``torch.nn.Module``.\n        inputs : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length, embedding_size)`` representing\n            the inputs to the Encoder.\n        mask : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length)``, representing masked and\n            non-masked elements of the sequence for each element in the batch.\n        hidden_state : ``Optional[RnnState]``, (default = None).\n            A single tensor of shape (num_layers, batch_size, hidden_size) representing the\n            state of an RNN with or a tuple of\n            tensors of shapes (num_layers, batch_size, hidden_size) and\n            (num_layers, batch_size, memory_size), representing the hidden state and memory\n            state of an LSTM-like RNN.\n        Returns\n        -------\n        module_output : ``Union[torch.Tensor, PackedSequence]``.\n            A Tensor or PackedSequence representing the output of the Pytorch Module.\n            The batch size dimension will be equal to ``num_valid``, as sequences of zero\n            length are clipped off before the module is called, as Pytorch cannot handle\n            zero length sequences.\n        final_states : ``Optional[RnnState]``\n            A Tensor representing the hidden state of the Pytorch Module. This can either\n            be a single tensor of shape (num_layers, num_valid, hidden_size), for instance in\n            the case of a GRU, or a tuple of tensors, such as those required for an LSTM.\n        restoration_indices : ``torch.LongTensor``\n            A tensor of shape ``(batch_size,)``, describing the re-indexing required to transform\n            the outputs back to their original batch order.\n        \"\"\"", "\n", "# In some circumstances you may have sequences of zero length. ``pack_padded_sequence``", "\n", "# requires all sequence lengths to be > 0, so remove sequences of zero length before", "\n", "# calling self._module, then fill with zeros.", "\n", "\n", "# First count how many sequences are empty.", "\n", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "num_valid", "=", "torch", ".", "sum", "(", "mask", "[", ":", ",", "0", "]", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "\n", "sequence_lengths", "=", "get_lengths_from_binary_sequence_mask", "(", "mask", ")", "\n", "sorted_inputs", ",", "sorted_sequence_lengths", ",", "restoration_indices", ",", "sorting_indices", "=", "sort_batch_by_length", "(", "inputs", ",", "sequence_lengths", ")", "\n", "\n", "# Now create a PackedSequence with only the non-empty, sorted sequences.", "\n", "packed_sequence_input", "=", "pack_padded_sequence", "(", "\n", "sorted_inputs", "[", ":", "num_valid", ",", ":", ",", ":", "]", ",", "\n", "sorted_sequence_lengths", "[", ":", "num_valid", "]", ".", "data", ".", "tolist", "(", ")", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "# Prepare the initial states.", "\n", "if", "not", "self", ".", "stateful", ":", "\n", "            ", "if", "hidden_state", "is", "None", ":", "\n", "                ", "initial_states", "=", "hidden_state", "\n", "", "elif", "isinstance", "(", "hidden_state", ",", "tuple", ")", ":", "\n", "                ", "initial_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "[", ":", ",", ":", "num_valid", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "for", "state", "in", "hidden_state", "]", "\n", "", "else", ":", "\n", "                ", "initial_states", "=", "hidden_state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "[", ":", ",", ":", "num_valid", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "initial_states", "=", "self", ".", "_get_initial_states", "(", "batch_size", ",", "num_valid", ",", "sorting_indices", ")", "\n", "\n", "# Actually call the module on the sorted PackedSequence.", "\n", "", "module_output", ",", "final_states", "=", "module", "(", "packed_sequence_input", ",", "initial_states", ")", "\n", "\n", "return", "module_output", ",", "final_states", ",", "restoration_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase._get_initial_states": [[124, 206], ["encoder_base._EncoderBase._states[].size", "tuple", "len", "correctly_shaped_state.index_select", "tuple", "encoder_base._EncoderBase._states[].size", "state.new_zeros", "resized_states.append", "encoder_base._EncoderBase._states[].size", "tuple", "state.index_select", "state.size", "state.size", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "_get_initial_states", "(", "self", ",", "\n", "batch_size", ":", "int", ",", "\n", "num_valid", ":", "int", ",", "\n", "sorting_indices", ":", "torch", ".", "LongTensor", ")", "->", "Optional", "[", "RnnState", "]", ":", "\n", "        ", "\"\"\"\n        Returns an initial state for use in an RNN. Additionally, this method handles\n        the batch size changing across calls by mutating the state to append initial states\n        for new elements in the batch. Finally, it also handles sorting the states\n        with respect to the sequence lengths of elements in the batch and removing rows\n        which are completely padded. Importantly, this `mutates` the state if the\n        current batch size is larger than when it was previously called.\n        Parameters\n        ----------\n        batch_size : ``int``, required.\n            The batch size can change size across calls to stateful RNNs, so we need\n            to know if we need to expand or shrink the states before returning them.\n            Expanded states will be set to zero.\n        num_valid : ``int``, required.\n            The batch may contain completely padded sequences which get removed before\n            the sequence is passed through the encoder. We also need to clip these off\n            of the state too.\n        sorting_indices ``torch.LongTensor``, required.\n            Pytorch RNNs take sequences sorted by length. When we return the states to be\n            used for a given call to ``module.forward``, we need the states to match up to\n            the sorted sequences, so before returning them, we sort the states using the\n            same indices used to sort the sequences.\n        Returns\n        -------\n        This method has a complex return type because it has to deal with the first time it\n        is called, when it has no state, and the fact that types of RNN have heterogeneous\n        states.\n        If it is the first time the module has been called, it returns ``None``, regardless\n        of the type of the ``Module``.\n        Otherwise, for LSTMs, it returns a tuple of ``torch.Tensors`` with shape\n        ``(num_layers, num_valid, state_size)`` and ``(num_layers, num_valid, memory_size)``\n        respectively, or for GRUs, it returns a single ``torch.Tensor`` of shape\n        ``(num_layers, num_valid, state_size)``.\n        \"\"\"", "\n", "# We don't know the state sizes the first time calling forward,", "\n", "# so we let the module define what it's initial hidden state looks like.", "\n", "if", "self", ".", "_states", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# Otherwise, we have some previous states.", "\n", "", "if", "batch_size", ">", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", ":", "\n", "# This batch is larger than the all previous states.", "\n", "# If so, resize the states.", "\n", "            ", "num_states_to_concat", "=", "batch_size", "-", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "resized_states", "=", "[", "]", "\n", "# state has shape (num_layers, batch_size, hidden_size)", "\n", "for", "state", "in", "self", ".", "_states", ":", "\n", "# This _must_ be inside the loop because some", "\n", "# RNNs have states with different last dimension sizes.", "\n", "                ", "zeros", "=", "state", ".", "new_zeros", "(", "state", ".", "size", "(", "0", ")", ",", "\n", "num_states_to_concat", ",", "\n", "state", ".", "size", "(", "2", ")", ")", "\n", "resized_states", ".", "append", "(", "torch", ".", "cat", "(", "[", "state", ",", "zeros", "]", ",", "1", ")", ")", "\n", "", "self", ".", "_states", "=", "tuple", "(", "resized_states", ")", "\n", "correctly_shaped_states", "=", "self", ".", "_states", "\n", "\n", "", "elif", "batch_size", "<", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", ":", "\n", "# This batch is smaller than the previous one.", "\n", "            ", "correctly_shaped_states", "=", "tuple", "(", "state", "[", ":", ",", ":", "batch_size", ",", ":", "]", "for", "state", "in", "self", ".", "_states", ")", "\n", "", "else", ":", "\n", "            ", "correctly_shaped_states", "=", "self", ".", "_states", "\n", "\n", "# At this point, our states are of shape (num_layers, batch_size, hidden_size).", "\n", "# However, the encoder uses sorted sequences and additionally removes elements", "\n", "# of the batch which are fully padded. We need the states to match up to these", "\n", "# sorted and filtered sequences, so we do that in the next two blocks before", "\n", "# returning the state/s.", "\n", "", "if", "len", "(", "self", ".", "_states", ")", "==", "1", ":", "\n", "# GRUs only have a single state. This `unpacks` it from the", "\n", "# tuple and returns the tensor directly.", "\n", "            ", "correctly_shaped_state", "=", "correctly_shaped_states", "[", "0", "]", "\n", "sorted_state", "=", "correctly_shaped_state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "\n", "return", "sorted_state", "[", ":", ",", ":", "num_valid", ",", ":", "]", "\n", "", "else", ":", "\n", "# LSTMs have a state tuple of (state, memory).", "\n", "            ", "sorted_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "\n", "for", "state", "in", "correctly_shaped_states", "]", "\n", "return", "tuple", "(", "state", "[", ":", ",", ":", "num_valid", ",", ":", "]", "for", "state", "in", "sorted_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase._update_states": [[207, 282], ["state.index_select", "tuple", "encoder_base._EncoderBase._states[].size", "final_states[].size", "tuple", "zip", "zip", "new_states.append", "new_states.append", "old_state.detach", "new_state.detach", "state[].sum"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "", "def", "_update_states", "(", "self", ",", "\n", "final_states", ":", "RnnStateStorage", ",", "\n", "restoration_indices", ":", "torch", ".", "LongTensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        After the RNN has run forward, the states need to be updated.\n        This method just sets the state to the updated new state, performing\n        several pieces of book-keeping along the way - namely, unsorting the\n        states and ensuring that the states of completely padded sequences are\n        not updated. Finally, it also detaches the state variable from the\n        computational graph, such that the graph can be garbage collected after\n        each batch iteration.\n        Parameters\n        ----------\n        final_states : ``RnnStateStorage``, required.\n            The hidden states returned as output from the RNN.\n        restoration_indices : ``torch.LongTensor``, required.\n            The indices that invert the sorting used in ``sort_and_run_forward``\n            to order the states with respect to the lengths of the sequences in\n            the batch.\n        \"\"\"", "\n", "# TODO(Mark): seems weird to sort here, but append zeros in the subclasses.", "\n", "# which way around is best?", "\n", "new_unsorted_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "restoration_indices", ")", "\n", "for", "state", "in", "final_states", "]", "\n", "\n", "if", "self", ".", "_states", "is", "None", ":", "\n", "# We don't already have states, so just set the", "\n", "# ones we receive to be the current state.", "\n", "            ", "self", ".", "_states", "=", "tuple", "(", "state", ".", "data", "for", "state", "in", "new_unsorted_states", ")", "\n", "", "else", ":", "\n", "# Now we've sorted the states back so that they correspond to the original", "\n", "# indices, we need to figure out what states we need to update, because if we", "\n", "# didn't use a state for a particular row, we want to preserve its state.", "\n", "# Thankfully, the rows which are all zero in the state correspond exactly", "\n", "# to those which aren't used, so we create masks of shape (new_batch_size,),", "\n", "# denoting which states were used in the RNN computation.", "\n", "            ", "current_state_batch_size", "=", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "new_state_batch_size", "=", "final_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "# Masks for the unused states of shape (1, new_batch_size, 1)", "\n", "used_new_rows_mask", "=", "[", "(", "state", "[", "0", ",", ":", ",", ":", "]", ".", "sum", "(", "-", "1", ")", "\n", "!=", "0.0", ")", ".", "float", "(", ")", ".", "view", "(", "1", ",", "new_state_batch_size", ",", "1", ")", "\n", "for", "state", "in", "new_unsorted_states", "]", "\n", "new_states", "=", "[", "]", "\n", "if", "current_state_batch_size", ">", "new_state_batch_size", ":", "\n", "# The new state is smaller than the old one,", "\n", "# so just update the indices which we used.", "\n", "                ", "for", "old_state", ",", "new_state", ",", "used_mask", "in", "zip", "(", "self", ".", "_states", ",", "\n", "new_unsorted_states", ",", "\n", "used_new_rows_mask", ")", ":", "\n", "# zero out all rows in the previous state", "\n", "# which _were_ used in the current state.", "\n", "                    ", "masked_old_state", "=", "old_state", "[", ":", ",", ":", "new_state_batch_size", ",", ":", "]", "*", "(", "1", "-", "used_mask", ")", "\n", "# The old state is larger, so update the relevant parts of it.", "\n", "old_state", "[", ":", ",", ":", "new_state_batch_size", ",", ":", "]", "=", "new_state", "+", "masked_old_state", "\n", "new_states", ".", "append", "(", "old_state", ".", "detach", "(", ")", ")", "\n", "", "", "else", ":", "\n", "# The states are the same size, so we just have to", "\n", "# deal with the possibility that some rows weren't used.", "\n", "                ", "new_states", "=", "[", "]", "\n", "for", "old_state", ",", "new_state", ",", "used_mask", "in", "zip", "(", "self", ".", "_states", ",", "\n", "new_unsorted_states", ",", "\n", "used_new_rows_mask", ")", ":", "\n", "# zero out all rows which _were_ used in the current state.", "\n", "                    ", "masked_old_state", "=", "old_state", "*", "(", "1", "-", "used_mask", ")", "\n", "# The old state is larger, so update the relevant parts of it.", "\n", "new_state", "+=", "masked_old_state", "\n", "new_states", ".", "append", "(", "new_state", ".", "detach", "(", ")", ")", "\n", "\n", "# It looks like there should be another case handled here - when", "\n", "# the current_state_batch_size < new_state_batch_size. However,", "\n", "# this never happens, because the states themeselves are mutated", "\n", "# by appending zeros when calling _get_inital_states, meaning that", "\n", "# the new states are either of equal size, or smaller, in the case", "\n", "# that there are some unused elements (zero-length) for the RNN computation.", "\n", "", "", "self", ".", "_states", "=", "tuple", "(", "new_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.reset_states": [[283, 285], ["None"], "methods", ["None"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "_states", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.__init__": [[34, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.zero_grad": [[38, 42], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.step": [[43, 47], ["op.step"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.state": [[48, 52], ["op.state.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.state_dict": [[53, 56], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict": [[57, 62], ["range", "len", "len", "len", "optimizer.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.__init__": [[93, 117], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "method", ",", "learning_rate", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_steps", "=", "None", ",", "decay_steps", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "adagrad_accum", "=", "0.0", ",", "\n", "decay_method", "=", "None", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "model_size", "=", "None", ",", "\n", "device", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "original_lr", "=", "learning_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_steps", "=", "start_decay_steps", "\n", "self", ".", "decay_steps", "=", "decay_steps", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "adagrad_accum", "=", "adagrad_accum", "\n", "self", ".", "decay_method", "=", "decay_method", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.lr": [[118, 124], ["max"], "methods", ["None"], ["", "@", "property", "\n", "def", "lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "", "else", ":", "\n", "            ", "return", "max", "(", "op", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "for", "op", "in", "self", ".", "optimizer", ".", "optimizers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict": [[125, 127], ["optimizer.Optimizer.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.set_parameters": [[128, 159], ["torch.SGD", "torch.SGD", "torch.Adagrad", "torch.Adagrad", "optimizer.Optimizer.params.append", "optimizer.Optimizer.sparse_params.append", "torch.Adadelta", "torch.Adadelta", "[].fill_", "torch.Adam", "torch.Adam", "optimizer.MultipleOptimizer", "RuntimeError", "torch.Adam", "torch.Adam", "torch.SparseAdam", "torch.SparseAdam"], "methods", ["None"], ["", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "params", "=", "[", "]", "\n", "self", ".", "sparse_params", "=", "[", "]", "\n", "for", "k", ",", "p", "in", "params", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "if", "self", ".", "method", "!=", "'sparseadam'", "or", "\"embed\"", "not", "in", "k", ":", "\n", "                    ", "self", ".", "params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "sparse_params", ".", "append", "(", "p", ")", "\n", "", "", "", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", ".", "fill_", "(", "self", ".", "adagrad_accum", ")", "\n", "", "", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "3e-9", ")", "\n", "", "elif", "self", ".", "method", "==", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "MultipleOptimizer", "(", "\n", "[", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", ",", "\n", "optim", ".", "SparseAdam", "(", "self", ".", "sparse_params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.set_state": [[160, 172], ["optimizer.Optimizer.optimizer.load_state_dict", "optimizer.Optimizer.optimizer.state.values", "state.items", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "v.to"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "def", "set_state", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"\n        If you want to load the checkpoint of an optimizer, call this function after set_parameters.\n        Because the method optim.set_parameters(model.parameters()) will overwrite optim.optimizer,\n        and with ith the values stored in optim.optimizer.state_dict()\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "# Convert back the state values to cuda type if applicable", "\n", "for", "state", "in", "self", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                    ", "state", "[", "k", "]", "=", "v", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer._set_rate": [[173, 180], ["None"], "methods", ["None"], ["", "", "", "", "def", "_set_rate", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "self", ".", "learning_rate", "=", "learning_rate", "\n", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "", "else", ":", "\n", "            ", "for", "op", "in", "self", ".", "optimizer", ".", "optimizers", ":", "\n", "                ", "op", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad": [[181, 183], ["optimizer.Optimizer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad"], ["", "", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.step": [[184, 214], ["optimizer.Optimizer.optimizer.step", "optimizer.Optimizer._set_rate", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "min"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer._set_rate"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "decay_method", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_set_rate", "(", "\n", "self", ".", "original_lr", "*", "\n", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", ")", "\n", "# Decay based on start_decay_steps every decay_steps", "\n", "", "else", ":", "\n", "            ", "if", "(", "(", "self", ".", "start_decay_steps", "is", "not", "None", ")", "and", "(", "\n", "self", ".", "_step", ">=", "self", ".", "start_decay_steps", ")", ")", ":", "\n", "                ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "                ", "if", "(", "(", "self", ".", "_step", "-", "self", ".", "start_decay_steps", ")", "\n", "%", "self", ".", "decay_steps", "==", "0", ")", ":", "\n", "                    ", "self", ".", "learning_rate", "=", "self", ".", "learning_rate", "*", "self", ".", "lr_decay", "\n", "\n", "", "", "", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.build_optim": [[11, 30], ["optimizer.Optimizer", "optimizer.Optimizer.set_parameters", "model.named_parameters"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.set_parameters"], ["def", "build_optim", "(", "opt", ",", "model", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "optim", "=", "Optimizer", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_steps", "=", "opt", ".", "start_decay_steps", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "encoder_size", "\n", ")", "\n", "\n", "parameters", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optim", ".", "set_parameters", "(", "parameters", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_bilstm.StackedBidirectionalLstm.__init__": [[32, 66], ["super().__init__", "range", "stog.modules.augmented_lstm.AugmentedLstm", "stog.modules.augmented_lstm.AugmentedLstm", "stacked_bilstm.StackedBidirectionalLstm.add_module", "stacked_bilstm.StackedBidirectionalLstm.add_module", "layers.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ",", "\n", "num_layers", ":", "int", ",", "\n", "recurrent_dropout_probability", ":", "float", "=", "0.0", ",", "\n", "use_highway", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", "StackedBidirectionalLstm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Required to be wrapped with a :class:`PytorchSeq2SeqWrapper`.", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bidirectional", "=", "True", "\n", "\n", "layers", "=", "[", "]", "\n", "lstm_input_size", "=", "input_size", "\n", "for", "layer_index", "in", "range", "(", "num_layers", ")", ":", "\n", "\n", "            ", "forward_layer", "=", "AugmentedLstm", "(", "lstm_input_size", ",", "hidden_size", ",", "\n", "go_forward", "=", "True", ",", "\n", "recurrent_dropout_probability", "=", "recurrent_dropout_probability", ",", "\n", "use_highway", "=", "use_highway", ",", "\n", "use_input_projection_bias", "=", "False", ")", "\n", "backward_layer", "=", "AugmentedLstm", "(", "lstm_input_size", ",", "hidden_size", ",", "\n", "go_forward", "=", "False", ",", "\n", "recurrent_dropout_probability", "=", "recurrent_dropout_probability", ",", "\n", "use_highway", "=", "use_highway", ",", "\n", "use_input_projection_bias", "=", "False", ")", "\n", "\n", "lstm_input_size", "=", "hidden_size", "*", "2", "\n", "self", ".", "add_module", "(", "'forward_layer_{}'", ".", "format", "(", "layer_index", ")", ",", "forward_layer", ")", "\n", "self", ".", "add_module", "(", "'backward_layer_{}'", ".", "format", "(", "layer_index", ")", ",", "backward_layer", ")", "\n", "layers", ".", "append", "(", "[", "forward_layer", ",", "backward_layer", "]", ")", "\n", "", "self", ".", "lstm_layers", "=", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_bilstm.StackedBidirectionalLstm.forward": [[67, 114], ["enumerate", "getattr", "getattr", "getattr.", "getattr.", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "final_states.append", "torch.cat", "len", "len", "stog.utils.checks.ConfigurationError", "list", "zip", "initial_state[].size", "zip", "torch.cat", "initial_state[].split", "initial_state[].split", "zip"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "PackedSequence", ",", "\n", "initial_state", ":", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        inputs : ``PackedSequence``, required.\n            A batch first ``PackedSequence`` to run the stacked LSTM over.\n        initial_state : Tuple[torch.Tensor, torch.Tensor], optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. Each tensor has shape (1, batch_size, output_dimension * 2).\n        Returns\n        -------\n        output_sequence : PackedSequence\n            The encoded sequence of shape (batch_size, sequence_length, hidden_size * 2)\n        final_states: torch.Tensor\n            The per-layer final (state, memory) states of the LSTM, each with shape\n            (num_layers, batch_size, hidden_size * 2).\n        \"\"\"", "\n", "if", "not", "initial_state", ":", "\n", "            ", "hidden_states", "=", "[", "None", "]", "*", "len", "(", "self", ".", "lstm_layers", ")", "\n", "", "elif", "initial_state", "[", "0", "]", ".", "size", "(", ")", "[", "0", "]", "!=", "len", "(", "self", ".", "lstm_layers", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Initial states were passed to forward() but the number of \"", "\n", "\"initial states does not match the number of layers.\"", ")", "\n", "", "else", ":", "\n", "            ", "hidden_states", "=", "list", "(", "zip", "(", "initial_state", "[", "0", "]", ".", "split", "(", "1", ",", "0", ")", ",", "\n", "initial_state", "[", "1", "]", ".", "split", "(", "1", ",", "0", ")", ")", ")", "\n", "\n", "", "output_sequence", "=", "inputs", "\n", "final_states", "=", "[", "]", "\n", "for", "i", ",", "state", "in", "enumerate", "(", "hidden_states", ")", ":", "\n", "            ", "forward_layer", "=", "getattr", "(", "self", ",", "'forward_layer_{}'", ".", "format", "(", "i", ")", ")", "\n", "backward_layer", "=", "getattr", "(", "self", ",", "'backward_layer_{}'", ".", "format", "(", "i", ")", ")", "\n", "# The state is duplicated to mirror the Pytorch API for LSTMs.", "\n", "forward_output", ",", "final_forward_state", "=", "forward_layer", "(", "output_sequence", ",", "state", ")", "\n", "backward_output", ",", "final_backward_state", "=", "backward_layer", "(", "output_sequence", ",", "state", ")", "\n", "\n", "forward_output", ",", "lengths", "=", "pad_packed_sequence", "(", "forward_output", ",", "batch_first", "=", "True", ")", "\n", "backward_output", ",", "_", "=", "pad_packed_sequence", "(", "backward_output", ",", "batch_first", "=", "True", ")", "\n", "\n", "output_sequence", "=", "torch", ".", "cat", "(", "[", "forward_output", ",", "backward_output", "]", ",", "-", "1", ")", "\n", "output_sequence", "=", "pack_padded_sequence", "(", "output_sequence", ",", "lengths", ",", "batch_first", "=", "True", ")", "\n", "final_states", ".", "append", "(", "(", "torch", ".", "cat", "(", "both_direction_states", ",", "-", "1", ")", "for", "both_direction_states", "\n", "in", "zip", "(", "final_forward_state", ",", "final_backward_state", ")", ")", ")", "\n", "\n", "", "final_state_tuple", "=", "[", "torch", ".", "cat", "(", "state_list", ",", "0", ")", "for", "state_list", "in", "zip", "(", "*", "final_states", ")", "]", "\n", "return", "output_sequence", ",", "final_state_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.modules.stacked_bilstm.StackedBidirectionalLstm.from_params": [[115, 123], ["cls", "params.get", "params.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "params", ")", ":", "\n", "        ", "return", "cls", "(", "\n", "input_size", "=", "params", "[", "'input_size'", "]", ",", "\n", "hidden_size", "=", "params", "[", "'hidden_size'", "]", ",", "\n", "num_layers", "=", "params", "[", "'num_layers'", "]", ",", "\n", "recurrent_dropout_probability", "=", "params", ".", "get", "(", "'dropout'", ",", "0.0", ")", ",", "\n", "use_highway", "=", "params", ".", "get", "(", "'use_highway'", ",", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention_layers.global_attention.GlobalAttention.__init__": [[58, 67], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "decoder_hidden_size", ",", "encoder_hidden_size", ",", "attention", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder_hidden_size", "=", "decoder_hidden_size", "\n", "self", ".", "encoder_hidden_size", "=", "encoder_hidden_size", "\n", "self", ".", "attention", "=", "attention", "\n", "self", ".", "output_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "decoder_hidden_size", "+", "encoder_hidden_size", ",", "\n", "decoder_hidden_size", ",", "\n", "bias", "=", "isinstance", "(", "attention", ",", "MLPAttention", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention_layers.global_attention.GlobalAttention.forward": [[69, 121], ["source.unsqueeze.unsqueeze.size", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.GlobalAttention.output_layer().view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "isinstance", "global_attention.GlobalAttention.attention", "isinstance", "mask.byte().unsqueeze.byte().unsqueeze.byte().unsqueeze", "global_attention.GlobalAttention.masked_fill_", "attn_h.squeeze.squeeze.squeeze", "align_vectors.squeeze.squeeze.squeeze", "global_attention.GlobalAttention.attention().squeeze", "global_attention.GlobalAttention.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.GlobalAttention.output_layer", "mask.byte().unsqueeze.byte().unsqueeze.byte", "float", "global_attention.GlobalAttention.attention"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "mask", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          source (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          memory_bank (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          mask (`LongTensor`): the source context mask `[batch, length]`\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "\n", "one_step", "=", "False", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "attention", ",", "MLPAttention", ")", "and", "coverage", "is", "not", "None", ":", "\n", "            ", "align", "=", "self", ".", "attention", "(", "source", ",", "memory_bank", ",", "coverage", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "attention", ",", "BiaffineAttention", ")", ":", "\n", "            ", "align", "=", "self", ".", "attention", "(", "source", ",", "memory_bank", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "align", "=", "self", ".", "attention", "(", "source", ",", "memory_bank", ")", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "byte", "(", ")", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "align_vectors", "=", "F", ".", "softmax", "(", "align", ",", "2", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "source", "]", ",", "2", ")", ".", "view", "(", "batch_", "*", "target_l", ",", "-", "1", ")", "\n", "attn_h", "=", "self", ".", "output_layer", "(", "concat_c", ")", ".", "view", "(", "batch_", ",", "target_l", ",", "-", "1", ")", "\n", "\n", "attn_h", "=", "torch", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "coverage", "=", "coverage", "+", "align_vectors", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", ",", "coverage", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.linear.bilinear.BiLinear.__init__": [[19, 43], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "bilinear.BiLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "bilinear.BiLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "left_features", ",", "right_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "'''\n        Args:\n            left_features: size of left input\n            right_features: size of right input\n            out_features: size of output\n            bias: If set to False, the layer will not learn an additive bias.\n                Default: True\n        '''", "\n", "super", "(", "BiLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left_features", "=", "left_features", "\n", "self", ".", "right_features", "=", "right_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ",", "self", ".", "right_features", ")", ")", "\n", "self", ".", "W_l", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "self", ".", "W_r", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.linear.bilinear.BiLinear.reset_parameters": [[44, 49], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_l", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_r", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.linear.bilinear.BiLinear.forward": [[50, 75], ["input_left.view.view.size", "input_right.view.view.size", "int", "input_left.view.view.view", "input_right.view.view.view", "torch.bilinear", "torch.bilinear", "torch.bilinear", "torch.bilinear.view", "numpy.prod", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "input_left", ",", "input_right", ")", ":", "\n", "        ", "'''\n        Args:\n            input_left: Tensor\n                the left input tensor with shape = [batch1, batch2, ..., left_features]\n            input_right: Tensor\n                the right input tensor with shape = [batch1, batch2, ..., right_features]\n        Returns:\n        '''", "\n", "\n", "left_size", "=", "input_left", ".", "size", "(", ")", "\n", "right_size", "=", "input_right", ".", "size", "(", ")", "\n", "assert", "left_size", "[", ":", "-", "1", "]", "==", "right_size", "[", ":", "-", "1", "]", ",", "\"batch size of left and right inputs mis-match: (%s, %s)\"", "%", "(", "left_size", "[", ":", "-", "1", "]", ",", "right_size", "[", ":", "-", "1", "]", ")", "\n", "batch", "=", "int", "(", "np", ".", "prod", "(", "left_size", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# convert left and right input to matrices [batch, left_features], [batch, right_features]", "\n", "input_left", "=", "input_left", ".", "view", "(", "batch", ",", "self", ".", "left_features", ")", "\n", "input_right", "=", "input_right", ".", "view", "(", "batch", ",", "self", ".", "right_features", ")", "\n", "\n", "# output [batch, out_features]", "\n", "output", "=", "F", ".", "bilinear", "(", "input_left", ",", "input_right", ",", "self", ".", "U", ",", "self", ".", "bias", ")", "\n", "output", "=", "output", "+", "F", ".", "linear", "(", "input_left", ",", "self", ".", "W_l", ",", "None", ")", "+", "F", ".", "linear", "(", "input_right", ",", "self", ".", "W_r", ",", "None", ")", "\n", "# convert back to [batch1, batch2, ..., out_features]", "\n", "return", "output", ".", "view", "(", "left_size", "[", ":", "-", "1", "]", "+", "(", "self", ".", "out_features", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.linear.bilinear.BiLinear.__repr__": [[76, 81], ["str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "'in1_features='", "+", "str", "(", "self", ".", "left_features", ")", "+", "', in2_features='", "+", "str", "(", "self", ".", "right_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.cnn_encoder.CnnEncoder.__init__": [[48, 74], ["stog.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.__init__", "enumerate", "torch.nn.Conv1d", "cnn_encoder.CnnEncoder.add_module", "len", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "ngram_filter_sizes", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "2", ",", "3", ",", "4", ",", "5", ")", ",", "# pylint: disable=bad-whitespace", "\n", "conv_layer_activation", "=", "torch", ".", "nn", ".", "functional", ".", "relu", ",", "\n", "output_dim", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "CnnEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_embedding_dim", "=", "embedding_dim", "\n", "self", ".", "_num_filters", "=", "num_filters", "\n", "self", ".", "_ngram_filter_sizes", "=", "ngram_filter_sizes", "\n", "self", ".", "_activation", "=", "conv_layer_activation", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "\n", "self", ".", "_convolution_layers", "=", "[", "Conv1d", "(", "in_channels", "=", "self", ".", "_embedding_dim", ",", "\n", "out_channels", "=", "self", ".", "_num_filters", ",", "\n", "kernel_size", "=", "ngram_size", ")", "\n", "for", "ngram_size", "in", "self", ".", "_ngram_filter_sizes", "]", "\n", "for", "i", ",", "conv_layer", "in", "enumerate", "(", "self", ".", "_convolution_layers", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "'conv_layer_%d'", "%", "i", ",", "conv_layer", ")", "\n", "\n", "", "maxpool_output_dim", "=", "self", ".", "_num_filters", "*", "len", "(", "self", ".", "_ngram_filter_sizes", ")", "\n", "if", "self", ".", "_output_dim", ":", "\n", "            ", "self", ".", "projection_layer", "=", "Linear", "(", "maxpool_output_dim", ",", "self", ".", "_output_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "projection_layer", "=", "None", "\n", "self", ".", "_output_dim", "=", "maxpool_output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.cnn_encoder.CnnEncoder.get_input_dim": [[75, 78], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.cnn_encoder.CnnEncoder.get_output_dim": [[79, 82], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.cnn_encoder.CnnEncoder.forward": [[83, 115], ["torch.transpose", "range", "len", "getattr", "filter_outputs.append", "torch.cat", "cnn_encoder.CnnEncoder.projection_layer", "mask.unsqueeze().float", "len", "cnn_encoder.CnnEncoder._activation().max", "mask.unsqueeze", "cnn_encoder.CnnEncoder._activation", "getattr."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "tokens", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "# Our input is expected to have shape `(batch_size, num_tokens, embedding_dim)`.  The", "\n", "# convolution layers expect input of shape `(batch_size, in_channels, sequence_length)`,", "\n", "# where the conv layer `in_channels` is our `embedding_dim`.  We thus need to transpose the", "\n", "# tensor first.", "\n", "", "tokens", "=", "torch", ".", "transpose", "(", "tokens", ",", "1", ",", "2", ")", "\n", "# Each convolution layer returns output of size `(batch_size, num_filters, pool_length)`,", "\n", "# where `pool_length = num_tokens - ngram_size + 1`.  We then do an activation function,", "\n", "# then do max pooling over each filter for the whole input sequence.  Because our max", "\n", "# pooling is simple, we just use `torch.max`.  The resultant tensor of has shape", "\n", "# `(batch_size, num_conv_layers * num_filters)`, which then gets projected using the", "\n", "# projection layer, if requested.", "\n", "\n", "filter_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_convolution_layers", ")", ")", ":", "\n", "            ", "convolution_layer", "=", "getattr", "(", "self", ",", "'conv_layer_{}'", ".", "format", "(", "i", ")", ")", "\n", "filter_outputs", ".", "append", "(", "\n", "self", ".", "_activation", "(", "convolution_layer", "(", "tokens", ")", ")", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", "\n", ")", "\n", "\n", "# Now we have a list of `num_conv_layers` tensors of shape `(batch_size, num_filters)`.", "\n", "# Concatenating them gives us a tensor of shape `(batch_size, num_filters * num_conv_layers)`.", "\n", "", "maxpool_output", "=", "torch", ".", "cat", "(", "filter_outputs", ",", "dim", "=", "1", ")", "if", "len", "(", "filter_outputs", ")", ">", "1", "else", "filter_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "projection_layer", ":", "\n", "            ", "result", "=", "self", ".", "projection_layer", "(", "maxpool_output", ")", "\n", "", "else", ":", "\n", "            ", "result", "=", "maxpool_output", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.__init__": [[38, 47], ["stog.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.__init__", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "module", ":", "torch", ".", "nn", ".", "modules", ".", "RNNBase", ")", "->", "None", ":", "\n", "# Seq2VecEncoders cannot be stateful.", "\n", "        ", "super", "(", "PytorchSeq2VecWrapper", ",", "self", ")", ".", "__init__", "(", "stateful", "=", "False", ")", "\n", "self", ".", "_module", "=", "module", "\n", "try", ":", "\n", "            ", "if", "not", "self", ".", "_module", ".", "batch_first", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Our encoder semantics assumes batch is always first!\"", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.get_input_dim": [[48, 50], ["None"], "methods", ["None"], ["", "", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_module", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.get_output_dim": [[51, 57], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "try", ":", "\n", "            ", "is_bidirectional", "=", "self", ".", "_module", ".", "bidirectional", "\n", "", "except", "AttributeError", ":", "\n", "            ", "is_bidirectional", "=", "False", "\n", "", "return", "self", ".", "_module", ".", "hidden_size", "*", "(", "2", "if", "is_bidirectional", "else", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.forward": [[58, 110], ["mask.size", "pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.sort_and_run_forward", "isinstance", "torch.cat.size", "torch.cat.transpose().index_select", "last_layer_state.contiguous().view", "torch.cat.new_zeros", "torch.cat", "torch.cat.transpose", "last_layer_state.contiguous", "pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper.get_output_dim", "pytorch_seq2vec_wrapper.PytorchSeq2VecWrapper._module"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.sort_and_run_forward", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.get_output_dim"], ["", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "if", "mask", "is", "None", ":", "\n", "# If a mask isn't passed, there is no padding in the batch of instances, so we can just", "\n", "# return the last sequence output as the state.  This doesn't work in the case of", "\n", "# variable length sequences, as the last state for each element of the batch won't be", "\n", "# at the end of the max sequence length, so we have to use the state of the RNN below.", "\n", "            ", "return", "self", ".", "_module", "(", "inputs", ",", "hidden_state", ")", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "state", ",", "restoration_indices", ",", "=", "self", ".", "sort_and_run_forward", "(", "self", ".", "_module", ",", "inputs", ",", "mask", ",", "hidden_state", ")", "\n", "\n", "# Deal with the fact the LSTM state is a tuple of (state, memory).", "\n", "if", "isinstance", "(", "state", ",", "tuple", ")", ":", "\n", "            ", "state", "=", "state", "[", "0", "]", "\n", "\n", "", "num_layers_times_directions", ",", "num_valid", ",", "encoding_dim", "=", "state", ".", "size", "(", ")", "\n", "# Add back invalid rows.", "\n", "if", "num_valid", "<", "batch_size", ":", "\n", "# batch size is the second dimension here, because pytorch", "\n", "# returns RNN state as a tensor of shape (num_layers * num_directions,", "\n", "# batch_size, hidden_size)", "\n", "            ", "zeros", "=", "state", ".", "new_zeros", "(", "num_layers_times_directions", ",", "\n", "batch_size", "-", "num_valid", ",", "\n", "encoding_dim", ")", "\n", "state", "=", "torch", ".", "cat", "(", "[", "state", ",", "zeros", "]", ",", "1", ")", "\n", "\n", "# Restore the original indices and return the final state of the", "\n", "# top layer. Pytorch's recurrent layers return state in the form", "\n", "# (num_layers * num_directions, batch_size, hidden_size) regardless", "\n", "# of the 'batch_first' flag, so we transpose, extract the relevant", "\n", "# layer state (both forward and backward if using bidirectional layers)", "\n", "# and return them as a single (batch_size, self.get_output_dim()) tensor.", "\n", "\n", "# now of shape: (batch_size, num_layers * num_directions, hidden_size).", "\n", "", "unsorted_state", "=", "state", ".", "transpose", "(", "0", ",", "1", ")", ".", "index_select", "(", "0", ",", "restoration_indices", ")", "\n", "\n", "# Extract the last hidden vector, including both forward and backward states", "\n", "# if the cell is bidirectional. Then reshape by concatenation (in the case", "\n", "# we have bidirectional states) or just squash the 1st dimension in the non-", "\n", "# bidirectional case. Return tensor has shape (batch_size, hidden_size * num_directions).", "\n", "try", ":", "\n", "            ", "last_state_index", "=", "2", "if", "self", ".", "_module", ".", "bidirectional", "else", "1", "\n", "", "except", "AttributeError", ":", "\n", "            ", "last_state_index", "=", "1", "\n", "", "last_layer_state", "=", "unsorted_state", "[", ":", ",", "-", "last_state_index", ":", ",", ":", "]", "\n", "return", "last_layer_state", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", ",", "self", ".", "get_output_dim", "(", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.get_input_dim": [[14, 21], ["None"], "methods", ["None"], ["def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the dimension of the vector input for each element in the sequence input\n        to a ``Seq2VecEncoder``. This is `not` the shape of the input tensor, but the\n        last element of that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.get_output_dim": [[22, 28], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the dimension of the final vector output by this ``Seq2VecEncoder``.  This is `not`\n        the shape of the returned tensor, but the last element of that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.boe_encoder.BagOfEmbeddingsEncoder.__init__": [[22, 28], ["stog.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "averaged", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "BagOfEmbeddingsEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_embedding_dim", "=", "embedding_dim", "\n", "self", ".", "_averaged", "=", "averaged", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.boe_encoder.BagOfEmbeddingsEncoder.get_input_dim": [[29, 32], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.boe_encoder.BagOfEmbeddingsEncoder.get_output_dim": [[33, 36], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2vec_encoders.boe_encoder.BagOfEmbeddingsEncoder.forward": [[37, 62], ["tokens.sum", "mask.unsqueeze().float", "stog.utils.nn.get_lengths_from_binary_sequence_mask", "torch.max", "tokens.new_full", "tokens.new_full.unsqueeze().float", "tokens.new_full.new_ones", "mask.unsqueeze", "tokens.size", "tokens.new_full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_lengths_from_binary_sequence_mask", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "#pylint: disable=arguments-differ", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "tokens", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "# Our input has shape `(batch_size, num_tokens, embedding_dim)`, so we sum out the `num_tokens`", "\n", "# dimension.", "\n", "", "summed", "=", "tokens", ".", "sum", "(", "1", ")", "\n", "\n", "if", "self", ".", "_averaged", ":", "\n", "            ", "if", "mask", "is", "not", "None", ":", "\n", "                ", "lengths", "=", "get_lengths_from_binary_sequence_mask", "(", "mask", ")", "\n", "length_mask", "=", "(", "lengths", ">", "0", ")", "\n", "\n", "# Set any length 0 to 1, to avoid dividing by zero.", "\n", "lengths", "=", "torch", ".", "max", "(", "lengths", ",", "lengths", ".", "new_ones", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "lengths", "=", "tokens", ".", "new_full", "(", "(", "1", ",", ")", ",", "fill_value", "=", "tokens", ".", "size", "(", "1", ")", ")", "\n", "length_mask", "=", "None", "\n", "\n", "", "summed", "=", "summed", "/", "lengths", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "if", "length_mask", "is", "not", "None", ":", "\n", "                ", "summed", "=", "summed", "*", "(", "length_mask", ">", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "", "return", "summed", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.pointer_generator.PointerGenerator.__init__": [[8, 24], ["super().__init__", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Linear", "torch.nn.Sigmoid", "stog.metrics.seq2seq_metrics.Seq2SeqMetrics"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "switch_input_size", ",", "vocab_size", ",", "vocab_pad_idx", ",", "force_copy", ")", ":", "\n", "        ", "super", "(", "PointerGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "vocab_size", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_pointer", "=", "torch", ".", "nn", ".", "Linear", "(", "switch_input_size", ",", "3", ")", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "metrics", "=", "Seq2SeqMetrics", "(", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "vocab_pad_idx", "=", "vocab_pad_idx", "\n", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "\n", "self", ".", "eps", "=", "1e-20", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.pointer_generator.PointerGenerator.forward": [[25, 108], ["hiddens.view.view.size", "source_attention_maps.size", "target_attention_maps.size", "hiddens.view.view.view", "torch.nn.functional.softmax", "p[].view", "p[].view", "p[].view", "pointer_generator.PointerGenerator.linear", "scores.view.view.view", "pointer_generator.PointerGenerator.softmax", "torch.mul", "torch.mul", "torch.bmm", "torch.mul", "torch.bmm", "torch.cat", "torch.cat.clone", "torch.cat.clone.max", "dict", "pointer_generator.PointerGenerator.linear_pointer", "float", "p[].view.expand_as", "p[].view.expand_as", "source_attention_maps.float", "p[].view.expand_as", "target_attention_maps.float", "invalid_indexes.get", "enumerate", "invalid_indexes.get", "enumerate", "torch.mul.contiguous", "torch.bmm.contiguous", "torch.bmm.contiguous"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "forward", "(", "self", ",", "hiddens", ",", "source_attentions", ",", "source_attention_maps", ",", "\n", "target_attentions", ",", "target_attention_maps", ",", "invalid_indexes", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by copying target nodes.\n\n        :param hiddens: decoder outputs, [batch_size, num_target_nodes, hidden_size]\n        :param source_attentions: attention of each source node,\n            [batch_size, num_target_nodes, num_source_nodes]\n        :param source_attention_maps: a sparse indicator matrix\n            mapping each source node to its index in the dynamic vocabulary.\n            [batch_size, num_source_nodes, dynamic_vocab_size]\n        :param target_attentions: attention of each target node,\n            [batch_size, num_target_nodes, num_target_nodes]\n        :param target_attention_maps: a sparse indicator matrix\n            mapping each target node to its index in the dynamic vocabulary.\n            [batch_size, num_target_nodes, dynamic_vocab_size]\n        :param invalid_indexes: indexes which are not considered in prediction.\n        \"\"\"", "\n", "batch_size", ",", "num_target_nodes", ",", "_", "=", "hiddens", ".", "size", "(", ")", "\n", "source_dynamic_vocab_size", "=", "source_attention_maps", ".", "size", "(", "2", ")", "\n", "target_dynamic_vocab_size", "=", "target_attention_maps", ".", "size", "(", "2", ")", "\n", "hiddens", "=", "hiddens", ".", "view", "(", "batch_size", "*", "num_target_nodes", ",", "-", "1", ")", "\n", "\n", "# Pointer probability.", "\n", "p", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "linear_pointer", "(", "hiddens", ")", ",", "dim", "=", "1", ")", "\n", "p_copy_source", "=", "p", "[", ":", ",", "0", "]", ".", "view", "(", "batch_size", ",", "num_target_nodes", ",", "1", ")", "\n", "p_copy_target", "=", "p", "[", ":", ",", "1", "]", ".", "view", "(", "batch_size", ",", "num_target_nodes", ",", "1", ")", "\n", "p_generate", "=", "p", "[", ":", ",", "2", "]", ".", "view", "(", "batch_size", ",", "num_target_nodes", ",", "1", ")", "\n", "\n", "# Probability distribution over the vocabulary.", "\n", "# [batch_size * num_target_nodes, vocab_size]", "\n", "scores", "=", "self", ".", "linear", "(", "hiddens", ")", "\n", "scores", "[", ":", ",", "self", ".", "vocab_pad_idx", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "# [batch_size, num_target_nodes, vocab_size]", "\n", "scores", "=", "scores", ".", "view", "(", "batch_size", ",", "num_target_nodes", ",", "-", "1", ")", "\n", "vocab_probs", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "scaled_vocab_probs", "=", "torch", ".", "mul", "(", "vocab_probs", ",", "p_generate", ".", "expand_as", "(", "vocab_probs", ")", ")", "\n", "\n", "# [batch_size, num_target_nodes, num_source_nodes]", "\n", "scaled_source_attentions", "=", "torch", ".", "mul", "(", "source_attentions", ",", "p_copy_source", ".", "expand_as", "(", "source_attentions", ")", ")", "\n", "# [batch_size, num_target_nodes, dynamic_vocab_size]", "\n", "scaled_copy_source_probs", "=", "torch", ".", "bmm", "(", "scaled_source_attentions", ",", "source_attention_maps", ".", "float", "(", ")", ")", "\n", "\n", "# Probability distribution over the dynamic vocabulary.", "\n", "# [batch_size, num_target_nodes, num_target_nodes]", "\n", "# TODO: make sure for target_node_i, its attention to target_node_j >= target_node_i", "\n", "# should be zero.", "\n", "scaled_target_attentions", "=", "torch", ".", "mul", "(", "target_attentions", ",", "p_copy_target", ".", "expand_as", "(", "target_attentions", ")", ")", "\n", "# [batch_size, num_target_nodes, dymanic_vocab_size]", "\n", "scaled_copy_target_probs", "=", "torch", ".", "bmm", "(", "scaled_target_attentions", ",", "target_attention_maps", ".", "float", "(", ")", ")", "\n", "\n", "if", "invalid_indexes", ":", "\n", "            ", "if", "invalid_indexes", ".", "get", "(", "'vocab'", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "vocab_invalid_indexes", "=", "invalid_indexes", "[", "'vocab'", "]", "\n", "for", "i", ",", "indexes", "in", "enumerate", "(", "vocab_invalid_indexes", ")", ":", "\n", "                    ", "for", "index", "in", "indexes", ":", "\n", "                        ", "scaled_vocab_probs", "[", "i", ",", ":", ",", "index", "]", "=", "0", "\n", "\n", "", "", "", "if", "invalid_indexes", ".", "get", "(", "'source_copy'", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "source_copy_invalid_indexes", "=", "invalid_indexes", "[", "'source_copy'", "]", "\n", "for", "i", ",", "indexes", "in", "enumerate", "(", "source_copy_invalid_indexes", ")", ":", "\n", "                    ", "for", "index", "in", "indexes", ":", "\n", "                        ", "scaled_copy_source_probs", "[", "i", ",", ":", ",", "index", "]", "=", "0", "\n", "\n", "# [batch_size, num_target_nodes, vocab_size + dynamic_vocab_size]", "\n", "", "", "", "", "probs", "=", "torch", ".", "cat", "(", "[", "\n", "scaled_vocab_probs", ".", "contiguous", "(", ")", ",", "\n", "scaled_copy_source_probs", ".", "contiguous", "(", ")", ",", "\n", "scaled_copy_target_probs", ".", "contiguous", "(", ")", "\n", "]", ",", "dim", "=", "2", ")", "\n", "\n", "# Set the probability of coref NA to 0.", "\n", "_probs", "=", "probs", ".", "clone", "(", ")", "\n", "_probs", "[", ":", ",", ":", ",", "self", ".", "vocab_size", "+", "source_dynamic_vocab_size", "]", "=", "0", "\n", "\n", "_", ",", "predictions", "=", "_probs", ".", "max", "(", "2", ")", "\n", "\n", "return", "dict", "(", "\n", "probs", "=", "probs", ",", "\n", "predictions", "=", "predictions", ",", "\n", "source_dynamic_vocab_size", "=", "source_dynamic_vocab_size", ",", "\n", "target_dynamic_vocab_size", "=", "target_dynamic_vocab_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.pointer_generator.PointerGenerator.compute_loss": [[110, 209], ["generate_targets.ne", "target_copy_targets.ne", "probs.gather().squeeze", "target_copy_target_probs.mul.mul.mul", "probs.gather().squeeze", "source_copy_target_probs.mul().mul.mul().mul.mul().mul", "probs.gather().squeeze", "generate_targets.ne.sum().item", "predictions.eq().mul", "generate_targets.ne.sum().item", "predictions.eq().mul.sum().item", "target_copy_targets.ne.mul().sum().item", "predictions.eq().mul.mul().sum().item", "predictions.ge().mul().mul().sum().item", "source_copy_mask.mul().mul().sum().item", "predictions.eq().mul.mul().mul().sum().item", "predictions.ge().mul().mul().mul().mul().sum().item", "pointer_generator.PointerGenerator.metrics", "dict", "source_copy_targets.ne", "source_copy_targets.ne", "target_copy_targets.ne.float", "source_copy_targets.unsqueeze", "source_copy_mask.float", "probs.gather().squeeze.mul().mul", "generate_targets.ne", "additional_generate_mask.sum().item", "torch.sum().mul", "generate_targets.ne.long", "loss.sum().item", "target_copy_targets.unsqueeze", "probs.gather", "probs.gather", "source_copy_target_probs.mul().mul.mul().mul.mul", "probs.gather", "non_source_copy_mask.float", "generate_targets.ne.sum", "probs.gather().squeeze.mul", "generate_targets.ne.float", "likelihood.log().mul", "non_source_copy_mask.long", "predictions.eq", "generate_targets.ne.sum", "predictions.eq().mul.sum", "target_copy_targets.ne.mul().sum", "predictions.eq().mul.mul().sum", "predictions.ge().mul().mul().sum", "source_copy_mask.mul().mul().sum", "predictions.eq().mul.mul().mul().sum", "predictions.ge().mul().mul().mul().mul().sum", "loss.sum().div", "loss.sum", "torch.tensor().type_as", "non_target_copy_mask.float", "probs.gather().squeeze.mul", "additional_generate_mask.float", "additional_generate_mask.sum", "torch.sum", "generate_targets.ne.float", "target_copy_targets_with_offset.squeeze", "target_copy_targets.ne.long", "source_copy_mask.long", "non_target_copy_mask.long", "loss.sum", "float", "generate_targets.unsqueeze", "non_target_copy_mask.float", "torch.min", "likelihood.log", "source_copy_targets_with_offset.squeeze", "non_target_copy_mask.long", "target_copy_targets.ne.mul", "predictions.eq().mul.mul", "predictions.ge().mul().mul", "source_copy_mask.mul().mul", "predictions.eq().mul.mul().mul", "predictions.ge().mul().mul().mul().mul", "loss.sum", "torch.tensor", "predictions.ge().mul", "source_copy_mask.mul", "predictions.eq().mul.mul", "predictions.ge().mul().mul().mul", "float", "predictions.ge", "predictions.ge().mul().mul", "predictions.ge().mul", "predictions.lt", "predictions.ge"], "methods", ["None"], ["", "def", "compute_loss", "(", "self", ",", "probs", ",", "predictions", ",", "generate_targets", ",", "\n", "source_copy_targets", ",", "source_dynamic_vocab_size", ",", "\n", "target_copy_targets", ",", "target_dynamic_vocab_size", ",", "\n", "coverage_records", ",", "copy_attentions", ")", ":", "\n", "        ", "\"\"\"\n        Priority: target_copy > source_copy > generate\n\n        :param probs: probability distribution,\n            [batch_size, num_target_nodes, vocab_size + dynamic_vocab_size]\n        :param predictions: [batch_size, num_target_nodes]\n        :param generate_targets: target node index in the vocabulary,\n            [batch_size, num_target_nodes]\n        :param source_copy_targets:  target node index in the dynamic vocabulary,\n            [batch_size, num_target_nodes]\n        :param source_dynamic_vocab_size: int\n        :param target_copy_targets:  target node index in the dynamic vocabulary,\n            [batch_size, num_target_nodes]\n        :param target_dynamic_vocab_size: int\n        :param coverage_records: None or a tensor recording source-side coverages.\n            [batch_size, num_target_nodes, num_source_nodes]\n        :param copy_attentions: [batch_size, num_target_nodes, num_source_nodes]\n        \"\"\"", "\n", "\n", "non_pad_mask", "=", "generate_targets", ".", "ne", "(", "self", ".", "vocab_pad_idx", ")", "\n", "\n", "source_copy_mask", "=", "source_copy_targets", ".", "ne", "(", "1", ")", "&", "source_copy_targets", ".", "ne", "(", "0", ")", "# 1 is the index for unknown words", "\n", "non_source_copy_mask", "=", "1", "-", "source_copy_mask", "\n", "\n", "target_copy_mask", "=", "target_copy_targets", ".", "ne", "(", "0", ")", "# 0 is the index for coref NA", "\n", "non_target_copy_mask", "=", "1", "-", "target_copy_mask", "\n", "\n", "# [batch_size, num_target_nodes, 1]", "\n", "target_copy_targets_with_offset", "=", "target_copy_targets", ".", "unsqueeze", "(", "2", ")", "+", "self", ".", "vocab_size", "+", "source_dynamic_vocab_size", "\n", "# [batch_size, num_target_nodes]", "\n", "target_copy_target_probs", "=", "probs", ".", "gather", "(", "dim", "=", "2", ",", "index", "=", "target_copy_targets_with_offset", ")", ".", "squeeze", "(", "2", ")", "\n", "target_copy_target_probs", "=", "target_copy_target_probs", ".", "mul", "(", "target_copy_mask", ".", "float", "(", ")", ")", "\n", "\n", "# [batch_size, num_target_nodes, 1]", "\n", "source_copy_targets_with_offset", "=", "source_copy_targets", ".", "unsqueeze", "(", "2", ")", "+", "self", ".", "vocab_size", "\n", "# [batch_size, num_target_nodes]", "\n", "source_copy_target_probs", "=", "probs", ".", "gather", "(", "dim", "=", "2", ",", "index", "=", "source_copy_targets_with_offset", ")", ".", "squeeze", "(", "2", ")", "\n", "source_copy_target_probs", "=", "source_copy_target_probs", ".", "mul", "(", "non_target_copy_mask", ".", "float", "(", ")", ")", ".", "mul", "(", "source_copy_mask", ".", "float", "(", ")", ")", "\n", "\n", "# [batch_size, num_target_nodes]", "\n", "generate_target_probs", "=", "probs", ".", "gather", "(", "dim", "=", "2", ",", "index", "=", "generate_targets", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "# Except copy-oov nodes, all other nodes should be copied.", "\n", "likelihood", "=", "target_copy_target_probs", "+", "source_copy_target_probs", "+", "generate_target_probs", ".", "mul", "(", "non_target_copy_mask", ".", "float", "(", ")", ")", ".", "mul", "(", "non_source_copy_mask", ".", "float", "(", ")", ")", "\n", "num_tokens", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "            ", "non_generate_oov_mask", "=", "generate_targets", ".", "ne", "(", "1", ")", "\n", "additional_generate_mask", "=", "(", "non_target_copy_mask", "&", "source_copy_mask", "&", "non_generate_oov_mask", ")", "\n", "likelihood", "=", "likelihood", "+", "generate_target_probs", ".", "mul", "(", "additional_generate_mask", ".", "float", "(", ")", ")", "\n", "num_tokens", "+=", "additional_generate_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Add eps for numerical stability.", "\n", "", "likelihood", "=", "likelihood", "+", "self", ".", "eps", "\n", "\n", "coverage_loss", "=", "0", "\n", "if", "coverage_records", "is", "not", "None", ":", "\n", "            ", "coverage_loss", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "min", "(", "coverage_records", ",", "copy_attentions", ")", ",", "2", ")", ".", "mul", "(", "non_pad_mask", ".", "float", "(", ")", ")", "\n", "\n", "# Drop pads.", "\n", "", "loss", "=", "-", "likelihood", ".", "log", "(", ")", ".", "mul", "(", "non_pad_mask", ".", "float", "(", ")", ")", "+", "coverage_loss", "\n", "\n", "# Mask out copy targets for which copy does not happen.", "\n", "targets", "=", "target_copy_targets_with_offset", ".", "squeeze", "(", "2", ")", "*", "target_copy_mask", ".", "long", "(", ")", "+", "source_copy_targets_with_offset", ".", "squeeze", "(", "2", ")", "*", "non_target_copy_mask", ".", "long", "(", ")", "*", "source_copy_mask", ".", "long", "(", ")", "+", "generate_targets", "*", "non_target_copy_mask", ".", "long", "(", ")", "*", "non_source_copy_mask", ".", "long", "(", ")", "\n", "targets", "=", "targets", "*", "non_pad_mask", ".", "long", "(", ")", "\n", "\n", "pred_eq", "=", "predictions", ".", "eq", "(", "targets", ")", ".", "mul", "(", "non_pad_mask", ")", "\n", "\n", "num_non_pad", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_correct_pred", "=", "pred_eq", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "num_target_copy", "=", "target_copy_mask", ".", "mul", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_correct_target_copy", "=", "pred_eq", ".", "mul", "(", "target_copy_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_correct_target_point", "=", "predictions", ".", "ge", "(", "self", ".", "vocab_size", "+", "source_dynamic_vocab_size", ")", ".", "mul", "(", "target_copy_mask", ")", ".", "mul", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "num_source_copy", "=", "source_copy_mask", ".", "mul", "(", "non_target_copy_mask", ")", ".", "mul", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_correct_source_copy", "=", "pred_eq", ".", "mul", "(", "non_target_copy_mask", ")", ".", "mul", "(", "source_copy_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_correct_source_point", "=", "predictions", ".", "ge", "(", "self", ".", "vocab_size", ")", ".", "mul", "(", "predictions", ".", "lt", "(", "self", ".", "vocab_size", "+", "source_dynamic_vocab_size", ")", ")", ".", "mul", "(", "non_target_copy_mask", ")", ".", "mul", "(", "source_copy_mask", ")", ".", "mul", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "self", ".", "metrics", "(", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "num_non_pad", ",", "num_correct_pred", ",", "\n", "num_source_copy", ",", "num_correct_source_copy", ",", "num_correct_source_point", ",", "\n", "num_target_copy", ",", "num_correct_target_copy", ",", "num_correct_target_point", "\n", ")", "\n", "\n", "return", "dict", "(", "\n", "loss", "=", "loss", ".", "sum", "(", ")", ".", "div", "(", "float", "(", "num_tokens", ")", ")", ",", "\n", "total_loss", "=", "loss", ".", "sum", "(", ")", ",", "\n", "num_tokens", "=", "torch", ".", "tensor", "(", "[", "float", "(", "num_tokens", ")", "]", ")", ".", "type_as", "(", "loss", ")", ",", "\n", "predictions", "=", "predictions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.__init__": [[14, 40], ["super().__init__", "stog.metrics.AttachmentScores"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "decode_algorithm", ",", "\n", "head_sentinel", ",", "\n", "edge_node_h_linear", ",", "\n", "edge_node_m_linear", ",", "\n", "edge_label_h_linear", ",", "\n", "edge_label_m_linear", ",", "\n", "encode_dropout", ",", "\n", "biaffine_attention", ",", "\n", "edge_label_bilinear", "\n", ")", ":", "\n", "        ", "super", "(", "DeepBiaffineGraphDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decode_algorithm", "=", "decode_algorithm", "\n", "self", ".", "head_sentinel", "=", "head_sentinel", "\n", "self", ".", "edge_node_h_linear", "=", "edge_node_h_linear", "\n", "self", ".", "edge_node_m_linear", "=", "edge_node_m_linear", "\n", "self", ".", "edge_label_h_linear", "=", "edge_label_h_linear", "\n", "self", ".", "edge_label_m_linear", "=", "edge_label_m_linear", "\n", "self", ".", "encode_dropout", "=", "encode_dropout", "\n", "self", ".", "biaffine_attention", "=", "biaffine_attention", "\n", "self", ".", "edge_label_bilinear", "=", "edge_label_bilinear", "\n", "\n", "self", ".", "metrics", "=", "AttachmentScores", "(", ")", "\n", "\n", "self", ".", "minus_inf", "=", "-", "1e8", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.forward": [[41, 68], ["mask.sum().item", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._add_head_sentinel", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_node_scores", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.get_loss", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.decode", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.metrics", "dict", "edge_node_nll.item", "edge_label_nll.item", "mask.sum", "torch.tensor().type_as", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._add_head_sentinel", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_node_scores", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.get_loss", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode"], ["", "def", "forward", "(", "self", ",", "memory_bank", ",", "edge_heads", ",", "edge_labels", ",", "corefs", ",", "mask", ")", ":", "\n", "        ", "num_nodes", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "memory_bank", ",", "edge_heads", ",", "edge_labels", ",", "corefs", ",", "mask", "=", "self", ".", "_add_head_sentinel", "(", "\n", "memory_bank", ",", "edge_heads", ",", "edge_labels", ",", "corefs", ",", "mask", ")", "\n", "\n", "(", "edge_node_h", ",", "edge_node_m", ")", ",", "(", "edge_label_h", ",", "edge_label_m", ")", "=", "self", ".", "encode", "(", "memory_bank", ")", "\n", "\n", "edge_node_scores", "=", "self", ".", "_get_edge_node_scores", "(", "edge_node_h", ",", "edge_node_m", ",", "mask", ")", "\n", "\n", "edge_node_nll", ",", "edge_label_nll", "=", "self", ".", "get_loss", "(", "\n", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "edge_heads", ",", "edge_labels", ",", "mask", ")", "\n", "\n", "pred_edge_heads", ",", "pred_edge_labels", "=", "self", ".", "decode", "(", "\n", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "corefs", ",", "mask", ")", "\n", "\n", "self", ".", "metrics", "(", "\n", "pred_edge_heads", ",", "pred_edge_labels", ",", "edge_heads", "[", ":", ",", "1", ":", "]", ",", "edge_labels", "[", ":", ",", "1", ":", "]", ",", "mask", "[", ":", ",", "1", ":", "]", ",", "\n", "edge_node_nll", ".", "item", "(", ")", ",", "edge_label_nll", ".", "item", "(", ")", "\n", ")", "\n", "\n", "return", "dict", "(", "\n", "edge_heads", "=", "pred_edge_heads", ",", "\n", "edge_labels", "=", "pred_edge_labels", ",", "\n", "loss", "=", "(", "edge_node_nll", "+", "edge_label_nll", ")", "/", "num_nodes", ",", "\n", "total_loss", "=", "edge_node_nll", "+", "edge_label_nll", ",", "\n", "num_nodes", "=", "torch", ".", "tensor", "(", "float", "(", "num_nodes", ")", ")", ".", "type_as", "(", "memory_bank", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode": [[70, 99], ["torch.nn.functional.elu", "torch.nn.functional.elu", "torch.nn.functional.elu", "torch.nn.functional.elu", "torch.cat", "torch.cat", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode_dropout().transpose", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode_dropout().transpose", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.chunk", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.chunk", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_node_h_linear", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_node_m_linear", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_label_h_linear", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_label_m_linear", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode_dropout", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.encode_dropout", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.transpose", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.transpose"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "memory_bank", ")", ":", "\n", "        ", "\"\"\"\n        Map contextual representation into specific space (w/ lower dimensionality).\n\n        :param input: [batch, length, hidden_size]\n        :return:\n            edge_node: a tuple of (head, modifier) hidden state with size [batch, length, edge_hidden_size]\n            edge_label: a tuple of (head, modifier) hidden state with size [batch, length, label_hidden_size]\n        \"\"\"", "\n", "\n", "# Output: [batch, length, edge_hidden_size]", "\n", "edge_node_h", "=", "torch", ".", "nn", ".", "functional", ".", "elu", "(", "self", ".", "edge_node_h_linear", "(", "memory_bank", ")", ")", "\n", "edge_node_m", "=", "torch", ".", "nn", ".", "functional", ".", "elu", "(", "self", ".", "edge_node_m_linear", "(", "memory_bank", ")", ")", "\n", "\n", "# Output: [batch, length, label_hidden_size]", "\n", "edge_label_h", "=", "torch", ".", "nn", ".", "functional", ".", "elu", "(", "self", ".", "edge_label_h_linear", "(", "memory_bank", ")", ")", "\n", "edge_label_m", "=", "torch", ".", "nn", ".", "functional", ".", "elu", "(", "self", ".", "edge_label_m_linear", "(", "memory_bank", ")", ")", "\n", "\n", "# Apply dropout to certain node?", "\n", "# [batch, length * 2, hidden_size]", "\n", "edge_node", "=", "torch", ".", "cat", "(", "[", "edge_node_h", ",", "edge_node_m", "]", ",", "dim", "=", "1", ")", "\n", "edge_label", "=", "torch", ".", "cat", "(", "[", "edge_label_h", ",", "edge_label_m", "]", ",", "dim", "=", "1", ")", "\n", "edge_node", "=", "self", ".", "encode_dropout", "(", "edge_node", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "edge_label", "=", "self", ".", "encode_dropout", "(", "edge_label", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "edge_node_h", ",", "edge_node_m", "=", "edge_node", ".", "chunk", "(", "2", ",", "1", ")", "\n", "edge_label_h", ",", "edge_label_m", "=", "edge_label", ".", "chunk", "(", "2", ",", "1", ")", "\n", "\n", "return", "(", "edge_node_h", ",", "edge_node_m", ")", ",", "(", "edge_label_h", ",", "edge_label_m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.get_loss": [[100, 134], ["edge_node_scores.size", "stog.utils.nn.masked_log_softmax", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_label_scores", "torch.nn.functional.log_softmax", "torch.arange().view().type_as", "torch.arange().view().expand().type_as", "_edge_node_log_likelihood[].sum", "_edge_label_log_likelihood[].sum", "mask.unsqueeze", "mask.unsqueeze", "torch.arange().view", "torch.arange().view().expand", "torch.arange", "torch.arange().view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.masked_log_softmax", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_label_scores"], ["", "def", "get_loss", "(", "self", ",", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "edge_heads", ",", "edge_labels", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        :param edge_label_h: [batch, length, hidden_size]\n        :param edge_label_m: [batch, length, hidden_size]\n        :param edge_node_scores:  [batch, length, length]\n        :param edge_heads:  [batch, length]\n        :param edge_labels:  [batch, length]\n        :param mask: [batch, length]\n        :return:  [batch, length - 1]\n        \"\"\"", "\n", "batch_size", ",", "max_len", ",", "_", "=", "edge_node_scores", ".", "size", "(", ")", "\n", "\n", "edge_node_log_likelihood", "=", "masked_log_softmax", "(", "\n", "edge_node_scores", ",", "mask", ".", "unsqueeze", "(", "2", ")", "+", "mask", ".", "unsqueeze", "(", "1", ")", ",", "dim", "=", "1", ")", "\n", "\n", "edge_label_scores", "=", "self", ".", "_get_edge_label_scores", "(", "edge_label_h", ",", "edge_label_m", ",", "edge_heads", ")", "\n", "edge_label_log_likelihood", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "edge_label_scores", ",", "dim", "=", "2", ")", "\n", "\n", "# Create indexing matrix for batch: [batch, 1]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "type_as", "(", "edge_heads", ")", "\n", "# Create indexing matrix for modifier: [batch, modifier_length]", "\n", "modifier_index", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "view", "(", "1", ",", "max_len", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", ".", "type_as", "(", "edge_heads", ")", "\n", "# Index the log likelihood of gold edges.", "\n", "_edge_node_log_likelihood", "=", "edge_node_log_likelihood", "[", "\n", "batch_index", ",", "edge_heads", ".", "data", ",", "modifier_index", "]", "\n", "_edge_label_log_likelihood", "=", "edge_label_log_likelihood", "[", "\n", "batch_index", ",", "modifier_index", ",", "edge_labels", ".", "data", "]", "\n", "\n", "# Exclude the dummy root.", "\n", "# Output [batch, length - 1]", "\n", "gold_edge_node_nll", "=", "-", "_edge_node_log_likelihood", "[", ":", ",", "1", ":", "]", ".", "sum", "(", ")", "\n", "gold_edge_label_nll", "=", "-", "_edge_label_log_likelihood", "[", ":", ",", "1", ":", "]", ".", "sum", "(", ")", "\n", "\n", "return", "gold_edge_node_nll", ",", "gold_edge_label_nll", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.decode": [[135, 140], ["deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.mst_decode", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.greedy_decode"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.mst_decode", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.greedy_decode"], ["", "def", "decode", "(", "self", ",", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "corefs", ",", "mask", ")", ":", "\n", "        ", "if", "self", ".", "decode_algorithm", "==", "'mst'", ":", "\n", "            ", "return", "self", ".", "mst_decode", "(", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "corefs", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "greedy_decode", "(", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.greedy_decode": [[141, 163], ["edge_node_scores.size", "edge_node_scores.max", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_label_scores", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.max", "torch.diag", "minus_mask.unsqueeze", "edge_node_scores.new().fill_", "mask.float", "minus_mask.unsqueeze", "edge_node_scores.new"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_label_scores"], ["", "", "def", "greedy_decode", "(", "self", ",", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "mask", ")", ":", "\n", "# out_arc shape [batch, length, length]", "\n", "        ", "edge_node_scores", "=", "edge_node_scores", ".", "data", "\n", "max_len", "=", "edge_node_scores", ".", "size", "(", "1", ")", "\n", "\n", "# Set diagonal elements to -inf", "\n", "edge_node_scores", "=", "edge_node_scores", "+", "torch", ".", "diag", "(", "edge_node_scores", ".", "new", "(", "max_len", ")", ".", "fill_", "(", "-", "np", ".", "inf", ")", ")", "\n", "\n", "# Set invalid positions to -inf", "\n", "minus_mask", "=", "(", "1", "-", "mask", ".", "float", "(", ")", ")", "*", "self", ".", "minus_inf", "\n", "edge_node_scores", "=", "edge_node_scores", "+", "minus_mask", ".", "unsqueeze", "(", "2", ")", "+", "minus_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# Compute naive predictions.", "\n", "# prediction shape = [batch, length]", "\n", "_", ",", "edge_heads", "=", "edge_node_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "# Based on predicted heads, compute the edge label scores.", "\n", "# [batch, length, num_labels]", "\n", "edge_label_scores", "=", "self", ".", "_get_edge_label_scores", "(", "edge_label_h", ",", "edge_label_m", ",", "edge_heads", ")", "\n", "_", ",", "edge_labels", "=", "edge_label_scores", ".", "max", "(", "dim", "=", "2", ")", "\n", "\n", "return", "edge_heads", "[", ":", ",", "1", ":", "]", ",", "edge_labels", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.mst_decode": [[164, 186], ["edge_label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.size", "mask.data.sum().long().cpu().numpy", "edge_label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "edge_label_m.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_label_bilinear", "torch.nn.functional.log_softmax().permute", "torch.nn.functional.log_softmax", "torch.exp", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._run_mst_decoding", "minus_mask.unsqueeze", "mask.data.sum().long().cpu", "edge_label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "edge_label_m.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "torch.nn.functional.log_softmax", "mask.float", "minus_mask.unsqueeze", "torch.nn.functional.log_softmax.unsqueeze", "mask.data.sum().long", "edge_label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "edge_label_m.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "mask.data.sum"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._run_mst_decoding"], ["", "def", "mst_decode", "(", "self", ",", "edge_label_h", ",", "edge_label_m", ",", "edge_node_scores", ",", "corefs", ",", "mask", ")", ":", "\n", "        ", "batch_size", ",", "max_length", ",", "edge_label_hidden_size", "=", "edge_label_h", ".", "size", "(", ")", "\n", "lengths", "=", "mask", ".", "data", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "expanded_shape", "=", "[", "batch_size", ",", "max_length", ",", "max_length", ",", "edge_label_hidden_size", "]", "\n", "edge_label_h", "=", "edge_label_h", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "*", "expanded_shape", ")", ".", "contiguous", "(", ")", "\n", "edge_label_m", "=", "edge_label_m", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "expanded_shape", ")", ".", "contiguous", "(", ")", "\n", "# [batch, max_head_length, max_modifier_length, num_labels]", "\n", "edge_label_scores", "=", "self", ".", "edge_label_bilinear", "(", "edge_label_h", ",", "edge_label_m", ")", "\n", "edge_label_scores", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "edge_label_scores", ",", "dim", "=", "3", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "# Set invalid positions to -inf", "\n", "minus_mask", "=", "(", "1", "-", "mask", ".", "float", "(", ")", ")", "*", "self", ".", "minus_inf", "\n", "edge_node_scores", "=", "edge_node_scores", "+", "minus_mask", ".", "unsqueeze", "(", "2", ")", "+", "minus_mask", ".", "unsqueeze", "(", "1", ")", "\n", "# [batch, max_head_length, max_modifier_length]", "\n", "edge_node_scores", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "edge_node_scores", ",", "dim", "=", "1", ")", "\n", "\n", "# [batch, num_labels, max_head_length, max_modifier_length]", "\n", "batch_energy", "=", "torch", ".", "exp", "(", "edge_node_scores", ".", "unsqueeze", "(", "1", ")", "+", "edge_label_scores", ")", "\n", "\n", "edge_heads", ",", "edge_labels", "=", "self", ".", "_run_mst_decoding", "(", "batch_energy", ",", "lengths", ",", "corefs", ")", "\n", "return", "edge_heads", "[", ":", ",", "1", ":", "]", ",", "edge_labels", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._run_mst_decoding": [[187, 223], ["enumerate", "zip", "energy.max", "enumerate", "edge_heads.append", "edge_labels.append", "torch.from_numpy", "torch.from_numpy", "batch_energy.detach().cpu", "stog.algorithms.maximum_spanning_tree.decode_mst_with_coreference", "stog.algorithms.maximum_spanning_tree.decode_mst", "instance_head_labels.append", "numpy.stack", "numpy.stack", "corefs[].detach().cpu().tolist", "scores.numpy", "scores.numpy", "label_ids[].item", "batch_energy.detach", "corefs[].detach().cpu", "corefs[].detach"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.decode_mst_with_coreference", "home.repos.pwc.inspect_result.jcyk_gtos.algorithms.maximum_spanning_tree.decode_mst"], ["", "@", "staticmethod", "\n", "def", "_run_mst_decoding", "(", "batch_energy", ",", "lengths", ",", "corefs", "=", "None", ")", ":", "\n", "        ", "edge_heads", "=", "[", "]", "\n", "edge_labels", "=", "[", "]", "\n", "for", "i", ",", "(", "energy", ",", "length", ")", "in", "enumerate", "(", "zip", "(", "batch_energy", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "lengths", ")", ")", ":", "\n", "# energy: [num_labels, max_head_length, max_modifier_length]", "\n", "# scores | label_ids : [max_head_length, max_modifier_length]", "\n", "            ", "scores", ",", "label_ids", "=", "energy", ".", "max", "(", "dim", "=", "0", ")", "\n", "# Although we need to include the root node so that the MST includes it,", "\n", "# we do not want the dummy root node to be the head of more than one nodes,", "\n", "# since there should be only one root in a sentence.", "\n", "# Here, we enforce this by setting the scores for all word -> ROOT edges", "\n", "# edges to be 0.", "\n", "# TODO: set it to -1 seems better?", "\n", "scores", "[", "0", ",", ":", "]", "=", "0", "\n", "# Decode the heads. Because we modify the scores to prevent", "\n", "# adding in word -> ROOT edges, we need to find the labels ourselves.", "\n", "if", "corefs", "is", "not", "None", ":", "\n", "                ", "coref", "=", "corefs", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "[", ":", "length", "]", "\n", "instance_heads", ",", "_", "=", "decode_mst_with_coreference", "(", "\n", "scores", ".", "numpy", "(", ")", ",", "coref", ",", "length", ",", "has_labels", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "instance_heads", ",", "_", "=", "decode_mst", "(", "scores", ".", "numpy", "(", ")", ",", "length", ",", "has_labels", "=", "False", ")", "\n", "\n", "# Find the labels which correspond to the edges in the max spanning tree.", "\n", "", "instance_head_labels", "=", "[", "]", "\n", "for", "child", ",", "parent", "in", "enumerate", "(", "instance_heads", ")", ":", "\n", "                ", "instance_head_labels", ".", "append", "(", "label_ids", "[", "parent", ",", "child", "]", ".", "item", "(", ")", ")", "\n", "# We don't care what the head or tag is for the root token, but by default it's", "\n", "# not necessarily the same in the batched vs unbatched case, which is annoying.", "\n", "# Here we'll just set them to zero.", "\n", "", "instance_heads", "[", "0", "]", "=", "0", "\n", "instance_head_labels", "[", "0", "]", "=", "0", "\n", "edge_heads", ".", "append", "(", "instance_heads", ")", "\n", "edge_labels", ".", "append", "(", "instance_head_labels", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "edge_heads", ")", ")", ",", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "edge_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.from_params": [[224, 259], ["torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout2d", "stog.modules.attention.BiaffineAttention", "vocab.get_vocab_size", "stog.modules.linear.BiLinear", "cls", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "vocab", ",", "params", ")", ":", "\n", "        ", "decode_algorithm", "=", "params", "[", "'decode_algorithm'", "]", "\n", "input_size", "=", "params", "[", "'input_size'", "]", "\n", "edge_node_hidden_size", "=", "params", "[", "'edge_node_hidden_size'", "]", "\n", "edge_label_hidden_size", "=", "params", "[", "'edge_label_hidden_size'", "]", "\n", "dropout", "=", "params", "[", "'dropout'", "]", "\n", "\n", "head_sentinel", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "1", ",", "1", ",", "input_size", "]", ")", ")", "\n", "\n", "# Transform representations into a space for edge node heads, edge node modifiers", "\n", "edge_node_h_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "edge_node_hidden_size", ")", "\n", "edge_node_m_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "edge_node_hidden_size", ")", "\n", "\n", "# Transform representations into a space for edge label heads, edge label modifiers", "\n", "edge_label_h_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "edge_label_hidden_size", ")", "\n", "edge_label_m_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "edge_label_hidden_size", ")", "\n", "\n", "encode_dropout", "=", "torch", ".", "nn", ".", "Dropout2d", "(", "p", "=", "dropout", ")", "\n", "\n", "biaffine_attention", "=", "BiaffineAttention", "(", "edge_node_hidden_size", ",", "edge_node_hidden_size", ")", "\n", "\n", "num_labels", "=", "vocab", ".", "get_vocab_size", "(", "\"head_tags\"", ")", "\n", "edge_label_bilinear", "=", "BiLinear", "(", "edge_label_hidden_size", ",", "edge_label_hidden_size", ",", "num_labels", ")", "\n", "\n", "return", "cls", "(", "\n", "decode_algorithm", "=", "decode_algorithm", ",", "\n", "head_sentinel", "=", "head_sentinel", ",", "\n", "edge_node_h_linear", "=", "edge_node_h_linear", ",", "\n", "edge_node_m_linear", "=", "edge_node_m_linear", ",", "\n", "edge_label_h_linear", "=", "edge_label_h_linear", ",", "\n", "edge_label_m_linear", "=", "edge_label_m_linear", ",", "\n", "encode_dropout", "=", "encode_dropout", ",", "\n", "biaffine_attention", "=", "biaffine_attention", ",", "\n", "edge_label_bilinear", "=", "edge_label_bilinear", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._add_head_sentinel": [[261, 281], ["torch.cat.size", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.head_sentinel.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_ones", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "_add_head_sentinel", "(", "self", ",", "memory_bank", ",", "edge_heads", ",", "edge_labels", ",", "corefs", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Add a dummy ROOT at the beginning of each node sequence.\n        :param memory_bank: [batch, length, hidden_size]\n        :param edge_head: None or [batch, length]\n        :param edge_labels: None or [batch, length]\n        :param corefs: None or [batch, length]\n        :param mask: [batch, length]\n        \"\"\"", "\n", "batch_size", ",", "_", ",", "hidden_size", "=", "memory_bank", ".", "size", "(", ")", "\n", "head_sentinel", "=", "self", ".", "head_sentinel", ".", "expand", "(", "[", "batch_size", ",", "1", ",", "hidden_size", "]", ")", "\n", "memory_bank", "=", "torch", ".", "cat", "(", "[", "head_sentinel", ",", "memory_bank", "]", ",", "1", ")", "\n", "if", "edge_heads", "is", "not", "None", ":", "\n", "            ", "edge_heads", "=", "torch", ".", "cat", "(", "[", "edge_heads", ".", "new_zeros", "(", "batch_size", ",", "1", ")", ",", "edge_heads", "]", ",", "1", ")", "\n", "", "if", "edge_labels", "is", "not", "None", ":", "\n", "            ", "edge_labels", "=", "torch", ".", "cat", "(", "[", "edge_labels", ".", "new_zeros", "(", "batch_size", ",", "1", ")", ",", "edge_labels", "]", ",", "1", ")", "\n", "", "if", "corefs", "is", "not", "None", ":", "\n", "            ", "corefs", "=", "torch", ".", "cat", "(", "[", "corefs", ".", "new_zeros", "(", "batch_size", ",", "1", ")", ",", "corefs", "]", ",", "1", ")", "\n", "", "mask", "=", "torch", ".", "cat", "(", "[", "mask", ".", "new_ones", "(", "batch_size", ",", "1", ")", ",", "mask", "]", ",", "1", ")", "\n", "return", "memory_bank", ",", "edge_heads", ",", "edge_labels", ",", "corefs", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_node_scores": [[282, 285], ["deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.biaffine_attention().squeeze", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.biaffine_attention"], "methods", ["None"], ["", "def", "_get_edge_node_scores", "(", "self", ",", "edge_node_h", ",", "edge_node_m", ",", "mask", ")", ":", "\n", "        ", "edge_node_scores", "=", "self", ".", "biaffine_attention", "(", "edge_node_h", ",", "edge_node_m", ",", "mask_d", "=", "mask", ",", "mask_e", "=", "mask", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "edge_node_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_label_scores": [[286, 307], ["edge_label_h[].contiguous.size", "torch.arange().view().type_as().long", "edge_label_h[].contiguous", "edge_label_m.contiguous.contiguous.contiguous", "deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.edge_label_bilinear", "torch.arange().view().type_as", "torch.arange().view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "_get_edge_label_scores", "(", "self", ",", "edge_label_h", ",", "edge_label_m", ",", "edge_heads", ")", ":", "\n", "        ", "\"\"\"\n        Compute the edge label scores.\n        :param edge_label_h: [batch, length, edge_label_hidden_size]\n        :param edge_label_m: [batch, length, edge_label_hidden_size]\n        :param heads: [batch, length] -- element at [i, j] means the head index of node_j at batch_i.\n        :return: [batch, length, num_labels]\n        \"\"\"", "\n", "batch_size", "=", "edge_label_h", ".", "size", "(", "0", ")", "\n", "# Create indexing matrix for batch: [batch, 1]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "type_as", "(", "edge_heads", ".", "data", ")", ".", "long", "(", ")", "\n", "\n", "# Select the heads' representations based on the gold/predicted heads.", "\n", "# [batch, length, edge_label_hidden_size]", "\n", "edge_label_h", "=", "edge_label_h", "[", "batch_index", ",", "edge_heads", ".", "data", "]", ".", "contiguous", "(", ")", "\n", "edge_label_m", "=", "edge_label_m", ".", "contiguous", "(", ")", "\n", "\n", "# [batch, length, num_labels]", "\n", "edge_label_scores", "=", "self", ".", "edge_label_bilinear", "(", "edge_label_h", ",", "edge_label_m", ")", "\n", "\n", "return", "edge_label_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.rnn_decoder.RNNDecoderBase.__init__": [[9, 13], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_cell", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.rnn_decoder.RNNDecoderBase.forward": [[14, 16], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "input", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.rnn_decoder.InputFeedRNNDecoder.__init__": [[20, 32], ["rnn_decoder.RNNDecoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "rnn_cell", ",", "\n", "dropout", ",", "\n", "attention_layer", ",", "\n", "source_copy_attention_layer", "=", "None", ",", "\n", "coref_attention_layer", "=", "None", ",", "\n", "use_coverage", "=", "False", ")", ":", "\n", "        ", "super", "(", "InputFeedRNNDecoder", ",", "self", ")", ".", "__init__", "(", "rnn_cell", ",", "dropout", ")", "\n", "self", ".", "attention_layer", "=", "attention_layer", "\n", "self", ".", "source_copy_attention_layer", "=", "source_copy_attention_layer", "\n", "self", ".", "coref_attention_layer", "=", "coref_attention_layer", "\n", "self", ".", "use_coverage", "=", "use_coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.rnn_decoder.InputFeedRNNDecoder.forward": [[33, 131], ["inputs.size", "enumerate", "torch.cat", "torch.cat", "torch.cat", "len", "dict", "inputs.new_zeros", "inputs.new_zeros", "inputs.split", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_decoder.InputFeedRNNDecoder.rnn_cell", "torch.nn.utils.rnn.pad_packed_sequence", "torch.cat.append", "torch.cat.append", "rnn_decoder.InputFeedRNNDecoder.attention_layer", "rnn_decoder.InputFeedRNNDecoder.dropout", "target_copy_hidden_states.append", "torch.cat.append", "torch.cat", "torch.cat", "memory_bank.size", "rnn_decoder.InputFeedRNNDecoder.source_copy_attention_layer", "torch.cat.append", "torch.cat.append", "torch.cat.append", "len", "inputs.new_zeros", "torch.cat", "rnn_decoder.InputFeedRNNDecoder.coref_attention_layer", "rnn_decoder.InputFeedRNNDecoder.coref_attention_layer", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "mask", ",", "hidden_state", ",", "\n", "input_feed", "=", "None", ",", "target_copy_hidden_states", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param inputs: [batch_size, decoder_seq_length, embedding_size]\n        :param memory_bank: [batch_size, encoder_seq_length, encoder_hidden_size]\n        :param mask:  None or [batch_size, decoder_seq_length]\n        :param hidden_state: a tuple of (state, memory) with shape [num_encoder_layers, batch_size, encoder_hidden_size]\n        :param input_feed: None or [batch_size, 1, hidden_size]\n        :param target_copy_hidden_states: None or [batch_size, seq_length, hidden_size]\n        :param coverage: None or [batch_size, 1, encode_seq_length]\n        :return:\n        \"\"\"", "\n", "batch_size", ",", "sequence_length", ",", "_", "=", "inputs", ".", "size", "(", ")", "\n", "one_step_length", "=", "[", "1", "]", "*", "batch_size", "\n", "source_copy_attentions", "=", "[", "]", "\n", "target_copy_attentions", "=", "[", "]", "\n", "coverage_records", "=", "[", "]", "\n", "decoder_hidden_states", "=", "[", "]", "\n", "rnn_hidden_states", "=", "[", "]", "\n", "\n", "if", "input_feed", "is", "None", ":", "\n", "            ", "input_feed", "=", "inputs", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "self", ".", "rnn_cell", ".", "hidden_size", ")", "\n", "\n", "", "if", "target_copy_hidden_states", "is", "None", ":", "\n", "            ", "target_copy_hidden_states", "=", "[", "]", "\n", "\n", "", "if", "self", ".", "use_coverage", "and", "coverage", "is", "None", ":", "\n", "            ", "coverage", "=", "inputs", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "memory_bank", ".", "size", "(", "1", ")", ")", "\n", "\n", "", "for", "step_i", ",", "input", "in", "enumerate", "(", "inputs", ".", "split", "(", "1", ",", "dim", "=", "1", ")", ")", ":", "\n", "# input: [batch_size, 1, embeddings_size]", "\n", "# input_feed: [batch_size, 1, hidden_size]", "\n", "            ", "_input", "=", "torch", ".", "cat", "(", "[", "input", ",", "input_feed", "]", ",", "2", ")", "\n", "packed_input", "=", "pack_padded_sequence", "(", "_input", ",", "one_step_length", ",", "batch_first", "=", "True", ")", "\n", "# hidden_state: a tuple of (state, memory) with shape [num_layers, batch_size, hidden_size]", "\n", "packed_output", ",", "hidden_state", "=", "self", ".", "rnn_cell", "(", "packed_input", ",", "hidden_state", ")", "\n", "# output: [batch_size, 1, hidden_size]", "\n", "output", ",", "_", "=", "pad_packed_sequence", "(", "packed_output", ",", "batch_first", "=", "True", ")", "\n", "rnn_hidden_states", ".", "append", "(", "output", ")", "\n", "\n", "coverage_records", ".", "append", "(", "coverage", ")", "\n", "output", ",", "std_attention", ",", "coverage", "=", "self", ".", "attention_layer", "(", "\n", "output", ",", "memory_bank", ",", "mask", ",", "coverage", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "input_feed", "=", "output", "\n", "\n", "if", "self", ".", "source_copy_attention_layer", "is", "not", "None", ":", "\n", "                ", "_", ",", "source_copy_attention", "=", "self", ".", "source_copy_attention_layer", "(", "\n", "output", ",", "memory_bank", ",", "mask", ")", "\n", "source_copy_attentions", ".", "append", "(", "source_copy_attention", ")", "\n", "", "else", ":", "\n", "                ", "source_copy_attentions", ".", "append", "(", "std_attention", ")", "\n", "\n", "", "if", "self", ".", "coref_attention_layer", "is", "not", "None", ":", "\n", "                ", "if", "len", "(", "target_copy_hidden_states", ")", "==", "0", ":", "\n", "                    ", "target_copy_attention", "=", "inputs", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "sequence_length", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "target_copy_memory", "=", "torch", ".", "cat", "(", "target_copy_hidden_states", ",", "1", ")", "\n", "\n", "if", "sequence_length", "==", "1", ":", "\n", "                        ", "_", ",", "target_copy_attention", ",", "_", "=", "self", ".", "coref_attention_layer", "(", "\n", "output", ",", "target_copy_memory", ")", "\n", "", "else", ":", "\n", "                        ", "_", ",", "target_copy_attention", ",", "_", "=", "self", ".", "coref_attention_layer", "(", "\n", "output", ",", "target_copy_memory", ")", "\n", "target_copy_attention", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "target_copy_attention", ",", "(", "0", ",", "sequence_length", "-", "step_i", ")", ",", "'constant'", ",", "0", "\n", ")", "\n", "\n", "", "", "target_copy_attentions", ".", "append", "(", "target_copy_attention", ")", "\n", "\n", "", "target_copy_hidden_states", ".", "append", "(", "output", ")", "\n", "decoder_hidden_states", ".", "append", "(", "output", ")", "\n", "\n", "", "decoder_hidden_states", "=", "torch", ".", "cat", "(", "decoder_hidden_states", ",", "1", ")", "\n", "rnn_hidden_states", "=", "torch", ".", "cat", "(", "rnn_hidden_states", ",", "1", ")", "\n", "source_copy_attentions", "=", "torch", ".", "cat", "(", "source_copy_attentions", ",", "1", ")", "\n", "if", "len", "(", "target_copy_attentions", ")", ":", "\n", "            ", "target_copy_attentions", "=", "torch", ".", "cat", "(", "target_copy_attentions", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "target_copy_attentions", "=", "None", "\n", "", "if", "self", ".", "use_coverage", ":", "\n", "            ", "coverage_records", "=", "torch", ".", "cat", "(", "coverage_records", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "coverage_records", "=", "None", "\n", "\n", "", "return", "dict", "(", "\n", "decoder_hidden_states", "=", "decoder_hidden_states", ",", "\n", "rnn_hidden_states", "=", "rnn_hidden_states", ",", "\n", "source_copy_attentions", "=", "source_copy_attentions", ",", "\n", "target_copy_attentions", "=", "target_copy_attentions", ",", "\n", "coverage_records", "=", "coverage_records", ",", "\n", "last_hidden_state", "=", "hidden_state", ",", "\n", "input_feed", "=", "input_feed", ",", "\n", "coverage", "=", "coverage", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.generator.Generator.__init__": [[7, 18], ["super().__init__", "torch.nn.Sequential", "torch.nn.NLLLoss", "stog.metrics.seq2seq_metrics.Seq2SeqMetrics", "torch.nn.Linear", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["from", "decoder", "import", "DecodeLayer", "\n", "from", "transformer", "import", "Transformer", ",", "SinusoidalPositionalEmbedding", ",", "SelfAttentionMask", "\n", "from", "graph_transformer", "import", "GraphTransformer", "\n", "from", "data", "import", "ListsToTensor", ",", "ListsofStringToTensor", ",", "STR", "\n", "from", "search", "import", "Hypothesis", ",", "Beam", ",", "search_by_batch", "\n", "\n", "class", "Generator", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "\n", "word_char_dim", ",", "word_dim", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "char2concept_dim", ",", "\n", "rel_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.generator.Generator.forward": [[19, 33], ["inputs.view.view.size", "inputs.view.view.view", "generator.Generator._generator", "scores.view.view.view", "scores.view.view.max", "dict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "\n", "snt_layers", ",", "graph_layers", ",", "inference_layers", ",", "\n", "pretrained_file", ",", "device", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "concept_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'concept'", "]", ",", "vocabs", "[", "'concept_char'", "]", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2concept_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "self", ".", "relation_encoder", "=", "RelationEncoder", "(", "vocabs", "[", "'relation'", "]", ",", "rel_dim", ",", "embed_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "dropout", ")", "\n", "self", ".", "token_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'token'", "]", ",", "vocabs", "[", "'token_char'", "]", ",", "\n", "word_char_dim", ",", "word_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "\n", "self", ".", "graph_encoder", "=", "GraphTransformer", "(", "graph_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "snt_encoder", "=", "Transformer", "(", "snt_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.generator.Generator.compute_loss": [[35, 52], ["inputs.size", "generator.Generator.", "output[].view", "output[].view", "targets.view.view.view", "generator.Generator.criterion", "targets.view.view.ne", "output[].view.eq().masked_select().sum().item", "targets.view.ne.sum().item", "generator.Generator.metrics", "dict", "generator.Generator.item", "output[].view.eq().masked_select().sum", "targets.view.ne.sum", "generator.Generator.div", "float", "output[].view.eq().masked_select", "output[].view.eq"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "token_position", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ",", "device", ")", "\n", "self", ".", "concept_depth", "=", "nn", ".", "Embedding", "(", "32", ",", "embed_dim", ")", "\n", "self", ".", "token_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "concept_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "self_attn_mask", "=", "SelfAttentionMask", "(", "device", ")", "\n", "self", ".", "decoder", "=", "DecodeLayer", "(", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "concept_dim", ",", "rel_dim", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "probe_generator", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "probe_generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "probe_generator", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "concept_depth", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.decoders.generator.Generator.from_params": [[54, 60], ["cls"], "methods", ["None"], ["        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "inp", "[", "'concept'", "]", ",", "inp", "[", "'concept_char'", "]", ")", "+", "self", ".", "concept_depth", "(", "inp", "[", "'concept_depth'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "inp", "[", "'concept'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "\n", "relation", "=", "self", ".", "relation_encoder", "(", "inp", "[", "'relation_bank'", "]", ",", "inp", "[", "'relation_length'", "]", ")", "\n", "relation", "[", "0", ",", ":", "]", "=", "0.", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.token_characters_encoder.TokenCharactersEncoder.__init__": [[21, 29], ["stog.modules.token_embedders.token_embedder.TokenEmbedder.__init__", "stog.modules.time_distributed.TimeDistributed", "stog.modules.time_distributed.TimeDistributed", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "embedding", ",", "encoder", ":", "Seq2VecEncoder", ",", "dropout", ":", "float", "=", "0.0", ")", "->", "None", ":", "\n", "        ", "super", "(", "TokenCharactersEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_embedding", "=", "TimeDistributed", "(", "embedding", ")", "\n", "self", ".", "_encoder", "=", "TimeDistributed", "(", "encoder", ")", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.token_characters_encoder.TokenCharactersEncoder.get_output_dim": [[30, 32], ["token_characters_encoder.TokenCharactersEncoder._encoder._module.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.get_output_dim"], ["", "", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_encoder", ".", "_module", ".", "get_output_dim", "(", ")", "# pylint: disable=protected-access", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.token_characters_encoder.TokenCharactersEncoder.forward": [[33, 36], ["token_characters_encoder.TokenCharactersEncoder._dropout", "token_characters_encoder.TokenCharactersEncoder._encoder", "token_characters_encoder.TokenCharactersEncoder._embedding"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_characters", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "# pylint: disable=arguments-differ", "\n", "        ", "mask", "=", "(", "token_characters", "!=", "0", ")", ".", "long", "(", ")", "\n", "return", "self", ".", "_dropout", "(", "self", ".", "_encoder", "(", "self", ".", "_embedding", "(", "token_characters", ")", ",", "mask", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.token_characters_encoder.TokenCharactersEncoder.from_params": [[38, 51], ["params.pop", "embedding_params.setdefault", "stog.modules.embedding.Embedding.from_params", "params.pop", "stog.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.from_params", "params.pop_float", "params.assert_empty", "cls"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "vocab", ":", "Vocabulary", ",", "params", ":", "Params", ")", "->", "'TokenCharactersEncoder'", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "embedding_params", ":", "Params", "=", "params", ".", "pop", "(", "\"embedding\"", ")", "\n", "# Embedding.from_params() uses \"tokens\" as the default namespace, but we need to change", "\n", "# that to be \"token_characters\" by default.", "\n", "embedding_params", ".", "setdefault", "(", "\"vocab_namespace\"", ",", "\"token_characters\"", ")", "\n", "embedding", "=", "Embedding", ".", "from_params", "(", "vocab", ",", "embedding_params", ")", "\n", "encoder_params", ":", "Params", "=", "params", ".", "pop", "(", "\"encoder\"", ")", "\n", "encoder", "=", "Seq2VecEncoder", ".", "from_params", "(", "encoder_params", ")", "\n", "dropout", "=", "params", ".", "pop_float", "(", "\"dropout\"", ",", "0.0", ")", "\n", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "embedding", ",", "encoder", ",", "dropout", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.token_embedder.TokenEmbedder.get_output_dim": [[19, 25], ["None"], "methods", ["None"], ["def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the final output dimension that this ``TokenEmbedder`` uses to represent each\n        token.  This is `not` the shape of the returned tensor, but the last element of that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.Embedding.__init__": [[77, 116], ["stog.modules.token_embedders.token_embedder.TokenEmbedder.__init__", "torch.FloatTensor", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.Parameter", "torch.nn.functional.embedding.Embedding.weight.data[].fill_", "torch.nn.Linear", "torch.FloatTensor.size", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["def", "__init__", "(", "self", ",", "\n", "num_embeddings", ":", "int", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "projection_dim", ":", "int", "=", "None", ",", "\n", "weight", ":", "torch", ".", "FloatTensor", "=", "None", ",", "\n", "padding_index", ":", "int", "=", "None", ",", "\n", "trainable", ":", "bool", "=", "True", ",", "\n", "max_norm", ":", "float", "=", "None", ",", "\n", "norm_type", ":", "float", "=", "2.", ",", "\n", "scale_grad_by_freq", ":", "bool", "=", "False", ",", "\n", "sparse", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "Embedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "padding_index", "=", "padding_index", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "self", ".", "sparse", "=", "sparse", "\n", "self", ".", "trainable", "=", "trainable", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n", "self", ".", "output_dim", "=", "projection_dim", "or", "embedding_dim", "\n", "\n", "if", "weight", "is", "None", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "num_embeddings", ",", "embedding_dim", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "weight", ",", "requires_grad", "=", "trainable", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "if", "weight", ".", "size", "(", ")", "!=", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"A weight matrix was passed with contradictory embedding shapes.\"", ")", "\n", "", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "weight", ",", "requires_grad", "=", "trainable", ")", "\n", "\n", "", "if", "self", ".", "padding_index", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", ".", "data", "[", "self", ".", "padding_index", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "", "if", "projection_dim", ":", "\n", "            ", "self", ".", "_projection", "=", "torch", ".", "nn", ".", "Linear", "(", "embedding_dim", ",", "projection_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_projection", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.Embedding.get_output_dim": [[117, 120], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.Embedding.forward": [[121, 140], ["torch.nn.functional.embedding", "original_inputs.dim", "inputs.view.view.view", "original_inputs.dim", "stog.modules.time_distributed.TimeDistributed.view", "range", "stog.modules.time_distributed.TimeDistributed.", "inputs.view.view.size", "list", "stog.modules.time_distributed.TimeDistributed", "original_inputs.size", "stog.modules.time_distributed.TimeDistributed.size", "stog.modules.time_distributed.TimeDistributed.dim"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "original_inputs", "=", "inputs", "\n", "if", "original_inputs", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "inputs", "=", "inputs", ".", "view", "(", "-", "1", ",", "inputs", ".", "size", "(", "-", "1", ")", ")", "\n", "", "embedded", "=", "embedding", "(", "inputs", ",", "self", ".", "weight", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ",", "\n", "norm_type", "=", "self", ".", "norm_type", ",", "\n", "scale_grad_by_freq", "=", "self", ".", "scale_grad_by_freq", ",", "\n", "sparse", "=", "self", ".", "sparse", ")", "\n", "if", "original_inputs", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "view_args", "=", "list", "(", "original_inputs", ".", "size", "(", ")", ")", "+", "[", "embedded", ".", "size", "(", "-", "1", ")", "]", "\n", "embedded", "=", "embedded", ".", "view", "(", "*", "view_args", ")", "\n", "", "if", "self", ".", "_projection", ":", "\n", "            ", "projection", "=", "self", ".", "_projection", "\n", "for", "_", "in", "range", "(", "embedded", ".", "dim", "(", ")", "-", "2", ")", ":", "\n", "                ", "projection", "=", "TimeDistributed", "(", "projection", ")", "\n", "", "embedded", "=", "projection", "(", "embedded", ")", "\n", "", "return", "embedded", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.Embedding.load_pretrain_from_file": [[142, 149], ["embedding._read_pretrained_embeddings_file", "torch.nn.Parameter"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_pretrained_embeddings_file"], ["", "def", "load_pretrain_from_file", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "pretrained_file", ",", "vocab_namespace", ",", "amr", "=", "False", ")", ":", "\n", "        ", "weight", "=", "_read_pretrained_embeddings_file", "(", "pretrained_file", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "vocab", ",", "\n", "vocab_namespace", ",", "\n", "amr", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "weight", ",", "requires_grad", "=", "self", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.Embedding.from_params": [[150, 218], ["params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "params.get", "cls", "vocab.get_vocab_size", "embedding._read_pretrained_embeddings_file"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_pretrained_embeddings_file"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "vocab", ":", "Vocabulary", ",", "params", ")", "->", "'Embedding'", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        We need the vocabulary here to know how many items we need to embed, and we look for a\n        ``vocab_namespace`` key in the parameter dictionary to know which vocabulary to use.  If\n        you know beforehand exactly how many embeddings you need, or aren't using a vocabulary\n        mapping for the things getting embedded here, then you can pass in the ``num_embeddings``\n        key directly, and the vocabulary will be ignored.\n\n        In the configuration file, a file containing pretrained embeddings can be specified\n        using the parameter ``\"pretrained_file\"``.\n        It can be the path to a local file or an URL of a (cached) remote file.\n        Two formats are supported:\n\n            * hdf5 file - containing an embedding matrix in the form of a torch.Tensor;\n\n            * text file - an utf-8 encoded text file with space separated fields::\n\n                    [word] [dim 1] [dim 2] ...\n\n              The text file can eventually be compressed with gzip, bz2, lzma or zip.\n              You can even select a single file inside an archive containing multiple files\n              using the URI::\n\n                    \"(archive_uri)#file_path_inside_the_archive\"\n\n              where ``archive_uri`` can be a file system path or a URL. For example::\n\n                    \"(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt\"\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "num_embeddings", "=", "params", ".", "get", "(", "'num_embeddings'", ",", "None", ")", "\n", "vocab_namespace", "=", "params", ".", "get", "(", "\"vocab_namespace\"", ",", "\"tokens\"", ")", "\n", "if", "num_embeddings", "is", "None", ":", "\n", "            ", "num_embeddings", "=", "vocab", ".", "get_vocab_size", "(", "vocab_namespace", ")", "\n", "", "embedding_dim", "=", "params", ".", "get", "(", "'embedding_dim'", ")", "\n", "pretrained_file", "=", "params", ".", "get", "(", "\"pretrained_file\"", ",", "None", ")", "\n", "data_type", "=", "params", ".", "get", "(", "'data_type'", ",", "None", ")", "\n", "projection_dim", "=", "params", ".", "get", "(", "\"projection_dim\"", ",", "None", ")", "\n", "trainable", "=", "params", ".", "get", "(", "\"trainable\"", ",", "True", ")", "\n", "padding_index", "=", "params", ".", "get", "(", "'padding_index'", ",", "None", ")", "\n", "max_norm", "=", "params", ".", "get", "(", "'max_norm'", ",", "None", ")", "\n", "norm_type", "=", "params", ".", "get", "(", "'norm_type'", ",", "2.", ")", "\n", "scale_grad_by_freq", "=", "params", ".", "get", "(", "'scale_grad_by_freq'", ",", "False", ")", "\n", "sparse", "=", "params", ".", "get", "(", "'sparse'", ",", "False", ")", "\n", "\n", "if", "pretrained_file", ":", "\n", "# If we're loading a saved model, we don't want to actually read a pre-trained", "\n", "# embedding file - the embeddings will just be in our saved weights, and we might not", "\n", "# have the original embedding file anymore, anyway.", "\n", "            ", "weight", "=", "_read_pretrained_embeddings_file", "(", "pretrained_file", ",", "\n", "embedding_dim", ",", "\n", "vocab", ",", "\n", "vocab_namespace", ",", "\n", "data_type", "==", "'AMR'", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "None", "\n", "\n", "", "return", "cls", "(", "num_embeddings", "=", "num_embeddings", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "\n", "projection_dim", "=", "projection_dim", ",", "\n", "weight", "=", "weight", ",", "\n", "padding_index", "=", "padding_index", ",", "\n", "trainable", "=", "trainable", ",", "\n", "max_norm", "=", "max_norm", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "scale_grad_by_freq", "=", "scale_grad_by_freq", ",", "\n", "sparse", "=", "sparse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__init__": [[424, 477], ["embedding.parse_embeddings_file_uri", "stog.utils.file.cached_path", "zipfile.is_zipfile", "next", "torch.nn.functional.embedding.EmbeddingsTextFile._get_num_tokens_from_first_line", "torch.nn.functional.embedding.EmbeddingsTextFile._open_inside_zip", "tarfile.is_tarfile", "itertools.chain", "torch.nn.functional.embedding.EmbeddingsTextFile._open_inside_tar", "stog.utils.file.get_file_extension", "package.open", "ValueError", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.parse_embeddings_file_uri", "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._get_num_tokens_from_first_line", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._open_inside_zip", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._open_inside_tar", "home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_file_extension"], ["def", "__init__", "(", "self", ",", "\n", "file_uri", ":", "str", ",", "\n", "encoding", ":", "str", "=", "DEFAULT_ENCODING", ",", "\n", "cache_dir", ":", "str", "=", "None", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "uri", "=", "file_uri", "\n", "self", ".", "_encoding", "=", "encoding", "\n", "self", ".", "_cache_dir", "=", "cache_dir", "\n", "self", ".", "_archive_handle", ":", "Any", "=", "None", "# only if the file is inside an archive", "\n", "\n", "main_file_uri", ",", "path_inside_archive", "=", "parse_embeddings_file_uri", "(", "file_uri", ")", "\n", "main_file_local_path", "=", "cached_path", "(", "main_file_uri", ",", "cache_dir", "=", "cache_dir", ")", "\n", "\n", "if", "zipfile", ".", "is_zipfile", "(", "main_file_local_path", ")", ":", "# ZIP archive", "\n", "            ", "self", ".", "_open_inside_zip", "(", "main_file_uri", ",", "path_inside_archive", ")", "\n", "\n", "", "elif", "tarfile", ".", "is_tarfile", "(", "main_file_local_path", ")", ":", "# TAR archive", "\n", "            ", "self", ".", "_open_inside_tar", "(", "main_file_uri", ",", "path_inside_archive", ")", "\n", "\n", "", "else", ":", "# all the other supported formats, including uncompressed files", "\n", "            ", "if", "path_inside_archive", ":", "\n", "                ", "raise", "ValueError", "(", "'Unsupported archive format: %s'", "+", "main_file_uri", ")", "\n", "\n", "# All the python packages for compressed files share the same interface of io.open", "\n", "", "extension", "=", "get_file_extension", "(", "main_file_uri", ")", "\n", "package", "=", "{", "\n", "'.txt'", ":", "io", ",", "\n", "'.vec'", ":", "io", ",", "\n", "'.gz'", ":", "gzip", ",", "\n", "'.bz2'", ":", "bz2", ",", "\n", "'.lzma'", ":", "lzma", ",", "\n", "}", ".", "get", "(", "extension", ",", "None", ")", "\n", "\n", "if", "package", "is", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "'The embeddings file has an unknown file extension \"%s\". '", "\n", "'We will assume the file is an (uncompressed) text file'", ",", "extension", ")", "\n", "package", "=", "io", "\n", "\n", "", "self", ".", "_handle", "=", "package", ".", "open", "(", "main_file_local_path", ",", "'rt'", ",", "encoding", "=", "encoding", ")", "# type: ignore", "\n", "\n", "# To use this with tqdm we'd like to know the number of tokens. It's possible that the", "\n", "# first line of the embeddings file contains this: if it does, we want to start iteration", "\n", "# from the 2nd line, otherwise we want to start from the 1st.", "\n", "# Unfortunately, once we read the first line, we cannot move back the file iterator", "\n", "# because the underlying file may be \"not seekable\"; we use itertools.chain instead.", "\n", "", "first_line", "=", "next", "(", "self", ".", "_handle", ")", "# this moves the iterator forward", "\n", "self", ".", "num_tokens", "=", "EmbeddingsTextFile", ".", "_get_num_tokens_from_first_line", "(", "first_line", ")", "\n", "if", "self", ".", "num_tokens", ":", "\n", "# the first line is a header line: start iterating from the 2nd line", "\n", "            ", "self", ".", "_iterator", "=", "self", ".", "_handle", "\n", "", "else", ":", "\n", "# the first line is not a header line: start iterating from the 1st line", "\n", "            ", "self", ".", "_iterator", "=", "itertools", ".", "chain", "(", "[", "first_line", "]", ",", "self", ".", "_handle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._open_inside_zip": [[478, 488], ["stog.utils.file.cached_path", "zipfile.ZipFile", "typing.cast", "zipfile.ZipFile.open", "io.TextIOWrapper", "zipfile.ZipFile.namelist", "torch.nn.functional.embedding.EmbeddingsTextFile._get_the_only_file_in_the_archive"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._get_the_only_file_in_the_archive"], ["", "", "def", "_open_inside_zip", "(", "self", ",", "archive_path", ":", "str", ",", "member_path", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "cached_archive_path", "=", "cached_path", "(", "archive_path", ",", "cache_dir", "=", "self", ".", "_cache_dir", ")", "\n", "archive", "=", "zipfile", ".", "ZipFile", "(", "cached_archive_path", ",", "'r'", ")", "\n", "if", "member_path", "is", "None", ":", "\n", "            ", "members_list", "=", "archive", ".", "namelist", "(", ")", "\n", "member_path", "=", "self", ".", "_get_the_only_file_in_the_archive", "(", "members_list", ",", "archive_path", ")", "\n", "", "member_path", "=", "cast", "(", "str", ",", "member_path", ")", "\n", "member_file", "=", "archive", ".", "open", "(", "member_path", ",", "'r'", ")", "\n", "self", ".", "_handle", "=", "io", ".", "TextIOWrapper", "(", "member_file", ",", "encoding", "=", "self", ".", "_encoding", ")", "\n", "self", ".", "_archive_handle", "=", "archive", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._open_inside_tar": [[489, 500], ["stog.utils.file.cached_path", "tarfile.open", "typing.cast", "tarfile.open.getmember", "typing.cast", "io.TextIOWrapper", "tarfile.open.getnames", "torch.nn.functional.embedding.EmbeddingsTextFile._get_the_only_file_in_the_archive", "tarfile.open.extractfile"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._get_the_only_file_in_the_archive"], ["", "def", "_open_inside_tar", "(", "self", ",", "archive_path", ":", "str", ",", "member_path", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "cached_archive_path", "=", "cached_path", "(", "archive_path", ",", "cache_dir", "=", "self", ".", "_cache_dir", ")", "\n", "archive", "=", "tarfile", ".", "open", "(", "cached_archive_path", ",", "'r'", ")", "\n", "if", "member_path", "is", "None", ":", "\n", "            ", "members_list", "=", "archive", ".", "getnames", "(", ")", "\n", "member_path", "=", "self", ".", "_get_the_only_file_in_the_archive", "(", "members_list", ",", "archive_path", ")", "\n", "", "member_path", "=", "cast", "(", "str", ",", "member_path", ")", "\n", "member", "=", "archive", ".", "getmember", "(", "member_path", ")", "# raises exception if not present", "\n", "member_file", "=", "cast", "(", "IO", "[", "bytes", "]", ",", "archive", ".", "extractfile", "(", "member", ")", ")", "\n", "self", ".", "_handle", "=", "io", ".", "TextIOWrapper", "(", "member_file", ",", "encoding", "=", "self", ".", "_encoding", ")", "\n", "self", ".", "_archive_handle", "=", "archive", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.read": [[501, 503], ["None"], "methods", ["None"], ["", "def", "read", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "''", ".", "join", "(", "self", ".", "_iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.readline": [[504, 506], ["next"], "methods", ["None"], ["", "def", "readline", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "next", "(", "self", ".", "_iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close": [[507, 511], ["torch.nn.functional.embedding.EmbeddingsTextFile._handle.close", "torch.nn.functional.embedding.EmbeddingsTextFile._archive_handle.close"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_handle", ".", "close", "(", ")", "\n", "if", "self", ".", "_archive_handle", ":", "\n", "            ", "self", ".", "_archive_handle", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__enter__": [[512, 514], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", "->", "'EmbeddingsTextFile'", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__exit__": [[515, 517], ["torch.nn.functional.embedding.EmbeddingsTextFile.close"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", "->", "None", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__iter__": [[518, 520], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", "->", "'EmbeddingsTextFile'", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__next__": [[521, 523], ["next"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "next", "(", "self", ".", "_iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.__len__": [[524, 529], ["AttributeError"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "Optional", "[", "int", "]", ":", "\n", "        ", "\"\"\" Hack for tqdm: no need for explicitly passing ``total=file.num_tokens`` \"\"\"", "\n", "if", "self", ".", "num_tokens", ":", "\n", "            ", "return", "self", ".", "num_tokens", "\n", "", "raise", "AttributeError", "(", "'an object of type EmbeddingsTextFile has \"len()\" only if the underlying '", "\n", "'text file declares the number of tokens (i.e. the number of lines following)'", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._get_the_only_file_in_the_archive": [[532, 540], ["len", "ValueError", "embedding.format_embeddings_file_uri"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.format_embeddings_file_uri"], ["", "@", "staticmethod", "\n", "def", "_get_the_only_file_in_the_archive", "(", "members_list", ":", "Sequence", "[", "str", "]", ",", "archive_path", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "len", "(", "members_list", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'The archive %s contains multiple files, so you must select '", "\n", "'one of the files inside providing a uri of the type: %s'", "\n", "%", "(", "archive_path", ",", "format_embeddings_file_uri", "(", "'path_or_url_to_archive'", ",", "\n", "'path_inside_archive'", ")", ")", ")", "\n", "", "return", "members_list", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile._get_num_tokens_from_first_line": [[541, 557], ["line.split", "len", "max", "logger.info", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_num_tokens_from_first_line", "(", "line", ":", "str", ")", "->", "Optional", "[", "int", "]", ":", "\n", "        ", "\"\"\" This function takes in input a string and if it contains 1 or 2 integers, it assumes the\n        largest one it the number of tokens. Returns None if the line doesn't match that pattern. \"\"\"", "\n", "fields", "=", "line", ".", "split", "(", "' '", ")", "\n", "if", "1", "<=", "len", "(", "fields", ")", "<=", "2", ":", "\n", "            ", "try", ":", "\n", "                ", "int_fields", "=", "[", "int", "(", "x", ")", "for", "x", "in", "fields", "]", "\n", "", "except", "ValueError", ":", "\n", "                ", "return", "None", "\n", "", "else", ":", "\n", "                ", "num_tokens", "=", "max", "(", "int_fields", ")", "\n", "logger", ".", "info", "(", "'Recognized a header line in the embedding file with number of tokens: %d'", ",", "\n", "num_tokens", ")", "\n", "return", "num_tokens", "\n", "", "", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_pretrained_embeddings_file": [[220, 276], ["stog.utils.file.get_file_extension", "embedding._read_embeddings_from_text_file", "embedding._read_embeddings_from_hdf5"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_file_extension", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_embeddings_from_text_file", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_embeddings_from_hdf5"], ["", "", "def", "_read_pretrained_embeddings_file", "(", "file_uri", ":", "str", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "namespace", ":", "str", "=", "\"tokens\"", ",", "\n", "amr", ":", "bool", "=", "False", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Returns and embedding matrix for the given vocabulary using the pretrained embeddings\n    contained in the given file. Embeddings for tokens not found in the pretrained embedding file\n    are randomly initialized using a normal distribution with mean and standard deviation equal to\n    those of the pretrained embeddings.\n\n    We support two file formats:\n\n        * text format - utf-8 encoded text file with space separated fields: [word] [dim 1] [dim 2] ...\n          The text file can eventually be compressed, and even resides in an archive with multiple files.\n          If the file resides in an archive with other files, then ``embeddings_filename`` must\n          be a URI \"(archive_uri)#file_path_inside_the_archive\"\n\n        * hdf5 format - hdf5 file containing an embedding matrix in the form of a torch.Tensor.\n\n    If the filename ends with '.hdf5' or '.h5' then we load from hdf5, otherwise we assume\n    text format.\n\n    Parameters\n    ----------\n    file_uri : str, required.\n        It can be:\n\n        * a file system path or a URL of an eventually compressed text file or a zip/tar archive\n          containing a single file.\n\n        * URI of the type ``(archive_path_or_url)#file_path_inside_archive`` if the text file\n          is contained in a multi-file archive.\n\n    vocab : Vocabulary, required.\n        A Vocabulary object.\n    namespace : str, (optional, default=tokens)\n        The namespace of the vocabulary to find pretrained embeddings for.\n    trainable : bool, (optional, default=True)\n        Whether or not the embedding parameters should be optimized.\n\n    Returns\n    -------\n    A weight matrix with embeddings initialized from the read file.  The matrix has shape\n    ``(vocab.get_vocab_size(namespace), embedding_dim)``, where the indices of words appearing in\n    the pretrained embedding file are initialized to the pretrained embedding value.\n    \"\"\"", "\n", "file_ext", "=", "get_file_extension", "(", "file_uri", ")", "\n", "if", "file_ext", "in", "[", "'.h5'", ",", "'.hdf5'", "]", ":", "\n", "        ", "return", "_read_embeddings_from_hdf5", "(", "file_uri", ",", "\n", "embedding_dim", ",", "\n", "vocab", ",", "namespace", ",", "amr", ")", "\n", "\n", "", "return", "_read_embeddings_from_text_file", "(", "file_uri", ",", "\n", "embedding_dim", ",", "\n", "vocab", ",", "namespace", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_embeddings_from_text_file": [[278, 361], ["set", "vocab.get_token_to_index_vocabulary", "vocab.get_vocab_size", "logger.info", "numpy.asarray", "float", "float", "logger.info", "torch.FloatTensor().normal_", "vocab.get_index_to_token_vocabulary", "range", "logger.info", "set.add", "embedding.EmbeddingsTextFile", "stog.utils.tqdm.Tqdm.tqdm", "stog.utils.checks.ConfigurationError", "list", "numpy.mean", "numpy.std", "re.sub", "re.sub", "embeddings.values", "torch.FloatTensor", "torch.FloatTensor", "logger.debug", "line.split", "line.rstrip().split", "numpy.asarray", "re.sub", "re.sub", "logger.warning", "torch.FloatTensor", "line.rstrip", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_to_index_vocabulary", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_index_to_token_vocabulary", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm"], ["", "def", "_read_embeddings_from_text_file", "(", "file_uri", ":", "str", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "namespace", ":", "str", "=", "\"tokens\"", ",", "\n", "amr", ":", "bool", "=", "False", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Read pre-trained word vectors from an eventually compressed text file, possibly contained\n    inside an archive with multiple files. The text file is assumed to be utf-8 encoded with\n    space-separated fields: [word] [dim 1] [dim 2] ...\n\n    Lines that contain more numerical tokens than ``embedding_dim`` raise a warning and are skipped.\n\n    The remainder of the docstring is identical to ``_read_pretrained_embeddings_file``.\n    \"\"\"", "\n", "tokens_to_keep", "=", "set", "(", ")", "\n", "for", "token", "in", "vocab", ".", "get_token_to_index_vocabulary", "(", "namespace", ")", ":", "\n", "# TODO: Is there a better way to do this? Currently we have a very specific 'amr' param.", "\n", "        ", "if", "amr", ":", "\n", "            ", "token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "", "tokens_to_keep", ".", "add", "(", "token", ")", "\n", "\n", "", "vocab_size", "=", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "\n", "embeddings", "=", "{", "}", "\n", "\n", "# First we read the embeddings from the file, only keeping vectors for the words we need.", "\n", "logger", ".", "info", "(", "\"Reading pretrained embeddings from file\"", ")", "\n", "\n", "with", "EmbeddingsTextFile", "(", "file_uri", ")", "as", "embeddings_file", ":", "\n", "        ", "for", "line", "in", "Tqdm", ".", "tqdm", "(", "embeddings_file", ")", ":", "\n", "            ", "token", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "[", "0", "]", "\n", "if", "token", "in", "tokens_to_keep", ":", "\n", "                ", "fields", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "fields", ")", "-", "1", "!=", "embedding_dim", ":", "\n", "# Sometimes there are funny unicode parsing problems that lead to different", "\n", "# fields lengths (e.g., a word with a unicode space character that splits", "\n", "# into more than one column).  We skip those lines.  Note that if you have", "\n", "# some kind of long header, this could result in all of your lines getting", "\n", "# skipped.  It's hard to check for that here; you just have to look in the", "\n", "# embedding_misses_file and at the model summary to make sure things look", "\n", "# like they are supposed to.", "\n", "                    ", "logger", ".", "warning", "(", "\"Found line with wrong number of dimensions (expected: %d; actual: %d): %s\"", ",", "\n", "embedding_dim", ",", "len", "(", "fields", ")", "-", "1", ",", "line", ")", "\n", "continue", "\n", "\n", "", "vector", "=", "numpy", ".", "asarray", "(", "fields", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "embeddings", "[", "token", "]", "=", "vector", "\n", "\n", "", "", "", "if", "not", "embeddings", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\"No embeddings of correct dimension found; you probably \"", "\n", "\"misspecified your embedding_dim parameter, or didn't \"", "\n", "\"pre-populate your Vocabulary\"", ")", "\n", "\n", "", "all_embeddings", "=", "numpy", ".", "asarray", "(", "list", "(", "embeddings", ".", "values", "(", ")", ")", ")", "\n", "embeddings_mean", "=", "float", "(", "numpy", ".", "mean", "(", "all_embeddings", ")", ")", "\n", "embeddings_std", "=", "float", "(", "numpy", ".", "std", "(", "all_embeddings", ")", ")", "\n", "# Now we initialize the weight matrix for an embedding layer, starting with random vectors,", "\n", "# then filling in the word vectors we just read.", "\n", "logger", ".", "info", "(", "\"Initializing pre-trained embedding layer\"", ")", "\n", "embedding_matrix", "=", "torch", ".", "FloatTensor", "(", "vocab_size", ",", "embedding_dim", ")", ".", "normal_", "(", "embeddings_mean", ",", "\n", "embeddings_std", ")", "\n", "num_tokens_found", "=", "0", "\n", "index_to_token", "=", "vocab", ".", "get_index_to_token_vocabulary", "(", "namespace", ")", "\n", "for", "i", "in", "range", "(", "vocab_size", ")", ":", "\n", "        ", "token", "=", "index_to_token", "[", "i", "]", "\n", "\n", "# If we don't have a pre-trained vector for this word, we'll just leave this row alone,", "\n", "# so the word has a random initialization.", "\n", "if", "token", "in", "embeddings", ":", "\n", "            ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "token", "]", ")", "\n", "num_tokens_found", "+=", "1", "\n", "", "else", ":", "\n", "            ", "if", "amr", ":", "\n", "                ", "normalized_token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "if", "normalized_token", "in", "embeddings", ":", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "normalized_token", "]", ")", "\n", "num_tokens_found", "+=", "1", "\n", "", "", "logger", ".", "debug", "(", "\"Token %s was not found in the embedding file. Initialising randomly.\"", ",", "token", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Pretrained embeddings were found for %d out of %d tokens\"", ",", "\n", "num_tokens_found", ",", "vocab_size", ")", "\n", "\n", "return", "embedding_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding._read_embeddings_from_hdf5": [[363, 381], ["torch.FloatTensor", "h5py.File", "list", "stog.utils.checks.ConfigurationError", "vocab.get_vocab_size", "list", "vocab.get_vocab_size"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size"], ["", "def", "_read_embeddings_from_hdf5", "(", "embeddings_filename", ":", "str", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "namespace", ":", "str", "=", "\"tokens\"", ",", "\n", "amr", ":", "bool", "=", "False", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Reads from a hdf5 formatted file. The embedding matrix is assumed to\n    be keyed by 'embedding' and of size ``(num_tokens, embedding_dim)``.\n    \"\"\"", "\n", "with", "h5py", ".", "File", "(", "embeddings_filename", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "embeddings", "=", "fin", "[", "'embedding'", "]", "[", "...", "]", "\n", "\n", "", "if", "list", "(", "embeddings", ".", "shape", ")", "!=", "[", "vocab", ".", "get_vocab_size", "(", "namespace", ")", ",", "embedding_dim", "]", ":", "\n", "        ", "raise", "ConfigurationError", "(", "\n", "\"Read shape {0} embeddings from the file, but expected {1}\"", ".", "format", "(", "\n", "list", "(", "embeddings", ".", "shape", ")", ",", "[", "vocab", ".", "get_vocab_size", "(", "namespace", ")", ",", "embedding_dim", "]", ")", ")", "\n", "\n", "", "return", "torch", ".", "FloatTensor", "(", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.format_embeddings_file_uri": [[383, 388], ["None"], "function", ["None"], ["", "def", "format_embeddings_file_uri", "(", "main_file_path_or_url", ":", "str", ",", "\n", "path_inside_archive", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "str", ":", "\n", "    ", "if", "path_inside_archive", ":", "\n", "        ", "return", "\"({})#{}\"", ".", "format", "(", "main_file_path_or_url", ",", "path_inside_archive", ")", "\n", "", "return", "main_file_path_or_url", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.parse_embeddings_file_uri": [[395, 402], ["re.fullmatch", "re.fullmatch", "typing.cast", "embedding.EmbeddingsFileURI", "embedding.EmbeddingsFileURI", "re.fullmatch.groups"], "function", ["None"], ["", "def", "parse_embeddings_file_uri", "(", "uri", ":", "str", ")", "->", "'EmbeddingsFileURI'", ":", "\n", "    ", "match", "=", "re", ".", "fullmatch", "(", "'\\((.*)\\)#(.*)'", ",", "uri", ")", "# pylint: disable=anomalous-backslash-in-string", "\n", "if", "match", ":", "\n", "        ", "fields", "=", "cast", "(", "Tuple", "[", "str", ",", "str", "]", ",", "match", ".", "groups", "(", ")", ")", "\n", "return", "EmbeddingsFileURI", "(", "*", "fields", ")", "\n", "", "else", ":", "\n", "        ", "return", "EmbeddingsFileURI", "(", "uri", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.openai_transformer_embedder.OpenaiTransformerEmbedder.__init__": [[25, 34], ["allennlp.modules.token_embedders.token_embedder.TokenEmbedder.__init__", "allennlp.modules.scalar_mix.ScalarMix"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "transformer", ":", "OpenaiTransformer", ",", "\n", "top_layer_only", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_transformer", "=", "transformer", "\n", "self", ".", "_top_layer_only", "=", "top_layer_only", "\n", "if", "not", "top_layer_only", ":", "\n", "            ", "self", ".", "_scalar_mix", "=", "ScalarMix", "(", "transformer", ".", "num_output_layers", ",", "do_layer_norm", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.openai_transformer_embedder.OpenaiTransformerEmbedder.get_output_dim": [[35, 40], ["None"], "methods", ["None"], ["", "", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The last dimension of the output, not the shape.\n        \"\"\"", "\n", "return", "self", ".", "_transformer", ".", "embed", ".", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.openai_transformer_embedder.OpenaiTransformerEmbedder.forward": [[41, 101], ["inputs.size", "torch.stack", "openai_transformer_embedder.OpenaiTransformerEmbedder._transformer", "allennlp.nn.util.get_range_vector", "openai_transformer_embedder.OpenaiTransformerEmbedder._scalar_mix", "allennlp.nn.util.get_range_vector().unsqueeze", "positional_encodings.expand", "allennlp.nn.util.get_device_of", "allennlp.nn.util.get_range_vector", "allennlp.nn.util.get_device_of"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_range_vector", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of"], ["", "def", "forward", "(", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "offsets", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        inputs: ``torch.Tensor``, required\n            A ``(batch_size, num_timesteps)`` tensor representing the byte-pair encodings\n            for the current batch.\n        offsets: ``torch.Tensor``, required\n            A ``(batch_size, max_sequence_length)`` tensor representing the word offsets\n            for the current batch.\n\n        Returns\n        -------\n        ``[torch.Tensor]``\n            An embedding representation of the input sequence\n            having shape ``(batch_size, sequence_length, embedding_dim)``\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "batch_size", ",", "num_timesteps", "=", "inputs", ".", "size", "(", ")", "\n", "\n", "# the transformer embedding consists of the byte pair embeddings,", "\n", "# the special embeddings and the position embeddings.", "\n", "# the position embeddings are always at least self._transformer.n_ctx,", "\n", "# but may be longer.", "\n", "# the transformer \"vocab\" consists of the actual vocab and the", "\n", "# positional encodings. Here we want the count of just the former.", "\n", "vocab_size", "=", "self", ".", "_transformer", ".", "vocab_size", "-", "self", ".", "_transformer", ".", "n_ctx", "\n", "\n", "# vocab_size, vocab_size + 1, ...", "\n", "positional_encodings", "=", "get_range_vector", "(", "num_timesteps", ",", "device", "=", "get_device_of", "(", "inputs", ")", ")", "+", "vocab_size", "\n", "\n", "# Combine the inputs with positional encodings", "\n", "batch_tensor", "=", "torch", ".", "stack", "(", "[", "\n", "inputs", ",", "# (batch_size, num_timesteps)", "\n", "positional_encodings", ".", "expand", "(", "batch_size", ",", "num_timesteps", ")", "\n", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "byte_pairs_mask", "=", "inputs", "!=", "0", "\n", "\n", "# Embeddings is num_output_layers x (batch_size, num_timesteps, embedding_dim)", "\n", "layer_activations", "=", "self", ".", "_transformer", "(", "batch_tensor", ")", "\n", "\n", "# Output of scalar_mix is (batch_size, num_timesteps, embedding_dim)", "\n", "if", "self", ".", "_top_layer_only", ":", "\n", "            ", "mix", "=", "layer_activations", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "mix", "=", "self", ".", "_scalar_mix", "(", "layer_activations", ",", "byte_pairs_mask", ")", "\n", "\n", "# These embeddings are one per byte-pair, but we want one per original _word_.", "\n", "# So we choose the embedding corresponding to the last byte pair for each word,", "\n", "# which is captured by the ``offsets`` input.", "\n", "", "if", "offsets", "is", "not", "None", ":", "\n", "            ", "range_vector", "=", "get_range_vector", "(", "batch_size", ",", "device", "=", "get_device_of", "(", "mix", ")", ")", ".", "unsqueeze", "(", "1", ")", "\n", "last_byte_pair_embeddings", "=", "mix", "[", "range_vector", ",", "offsets", "]", "\n", "", "else", ":", "\n", "# allow to return all byte pairs by passing no offsets", "\n", "            ", "seq_len", "=", "(", "byte_pairs_mask", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "max", "(", ")", "\n", "last_byte_pair_embeddings", "=", "mix", "[", ":", ",", ":", "seq_len", "]", "\n", "\n", "", "return", "last_byte_pair_embeddings", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.text_field_embedder.TextFieldEmbedder.forward": [[26, 43], ["None"], "methods", ["None"], ["def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "text_field_input", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "num_wrapping_dims", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        text_field_input : ``Dict[str, torch.Tensor]``\n            A dictionary that was the output of a call to ``TextField.as_tensor``.  Each tensor in\n            here is assumed to have a shape roughly similar to ``(batch_size, sequence_length)``\n            (perhaps with an extra trailing dimension for the characters in each token).\n        num_wrapping_dims : ``int``, optional (default=0)\n            If you have a ``ListField[TextField]`` that created the ``text_field_input``, you'll\n            end up with tensors of shape ``(batch_size, wrapping_dim1, wrapping_dim2, ...,\n            sequence_length)``.  This parameter tells us how many wrapping dimensions there are, so\n            that we can correctly ``TimeDistribute`` the embedding of each named representation.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.text_field_embedder.TextFieldEmbedder.get_output_dim": [[44, 51], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the dimension of the vector representing each token in the output of this\n        ``TextFieldEmbedder``.  This is `not` the shape of the returned tensor, but the last element of\n        that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.__init__": [[48, 59], ["text_field_embedder.TextFieldEmbedder.__init__", "token_embedders.items", "basic_text_field_embedder.BasicTextFieldEmbedder.add_module"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["def", "__init__", "(", "self", ",", "\n", "token_embedders", ":", "Dict", "[", "str", ",", "TokenEmbedder", "]", ",", "\n", "embedder_to_indexer_map", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "allow_unmatched_keys", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "BasicTextFieldEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_token_embedders", "=", "token_embedders", "\n", "self", ".", "_embedder_to_indexer_map", "=", "embedder_to_indexer_map", "\n", "for", "key", ",", "embedder", "in", "token_embedders", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "'token_embedder_%s'", "%", "key", "\n", "self", ".", "add_module", "(", "name", ",", "embedder", ")", "\n", "", "self", ".", "_allow_unmatched_keys", "=", "allow_unmatched_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.get_output_dim": [[60, 66], ["basic_text_field_embedder.BasicTextFieldEmbedder._token_embedders.values", "embedder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.get_output_dim"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "output_dim", "=", "0", "\n", "for", "embedder", "in", "self", ".", "_token_embedders", ".", "values", "(", ")", ":", "\n", "            ", "output_dim", "+=", "embedder", ".", "get_output_dim", "(", ")", "\n", "", "return", "output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.forward": [[67, 92], ["sorted", "torch.cat", "basic_text_field_embedder.BasicTextFieldEmbedder._token_embedders.keys", "text_field_input.keys", "basic_text_field_embedder.BasicTextFieldEmbedder._token_embedders.keys", "getattr", "range", "allennlp.modules.time_distributed.TimeDistributed.", "embedded_representations.append", "allennlp.common.checks.ConfigurationError", "allennlp.modules.time_distributed.TimeDistributed", "str", "str", "basic_text_field_embedder.BasicTextFieldEmbedder._token_embedders.keys", "text_field_input.keys"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text_field_input", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "num_wrapping_dims", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "_token_embedders", ".", "keys", "(", ")", "!=", "text_field_input", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "self", ".", "_allow_unmatched_keys", ":", "\n", "                ", "message", "=", "\"Mismatched token keys: %s and %s\"", "%", "(", "str", "(", "self", ".", "_token_embedders", ".", "keys", "(", ")", ")", ",", "\n", "str", "(", "text_field_input", ".", "keys", "(", ")", ")", ")", "\n", "raise", "ConfigurationError", "(", "message", ")", "\n", "", "", "embedded_representations", "=", "[", "]", "\n", "keys", "=", "sorted", "(", "self", ".", "_token_embedders", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "keys", ":", "\n", "# If we pre-specified a mapping explictly, use that.", "\n", "            ", "if", "self", ".", "_embedder_to_indexer_map", "is", "not", "None", ":", "\n", "                ", "tensors", "=", "[", "text_field_input", "[", "indexer_key", "]", "for", "\n", "indexer_key", "in", "self", ".", "_embedder_to_indexer_map", "[", "key", "]", "]", "\n", "", "else", ":", "\n", "# otherwise, we assume the mapping between indexers and embedders", "\n", "# is bijective and just use the key directly.", "\n", "                ", "tensors", "=", "[", "text_field_input", "[", "key", "]", "]", "\n", "# Note: need to use getattr here so that the pytorch voodoo", "\n", "# with submodules works with multiple GPUs.", "\n", "", "embedder", "=", "getattr", "(", "self", ",", "'token_embedder_{}'", ".", "format", "(", "key", ")", ")", "\n", "for", "_", "in", "range", "(", "num_wrapping_dims", ")", ":", "\n", "                ", "embedder", "=", "TimeDistributed", "(", "embedder", ")", "\n", "", "token_vectors", "=", "embedder", "(", "*", "tensors", ")", "\n", "embedded_representations", ".", "append", "(", "token_vectors", ")", "\n", "", "return", "torch", ".", "cat", "(", "embedded_representations", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.from_params": [[94, 136], ["params.pop", "bool", "params.pop", "cls", "embedder_to_indexer_map.as_dict.as_dict.as_dict", "params.pop", "warnings.warn", "list", "stog.modules.token_embedders.embedding.Embedding.from_params", "DeprecationWarning", "params.keys", "params.pop", "stog.modules.token_embedders.embedding.Embedding.from_params", "params.pop.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "vocab", ":", "Vocabulary", ",", "params", ":", "Params", ")", "->", "'BasicTextFieldEmbedder'", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ,bad-super-call", "\n", "\n", "# The original `from_params` for this class was designed in a way that didn't agree", "\n", "# with the constructor. The constructor wants a 'token_embedders' parameter that is a", "\n", "# `Dict[str, TokenEmbedder]`, but the original `from_params` implementation expected those", "\n", "# key-value pairs to be top-level in the params object.", "\n", "#", "\n", "# This breaks our 'configuration wizard' and configuration checks. Hence, going forward,", "\n", "# the params need a 'token_embedders' key so that they line up with what the constructor wants.", "\n", "# For now, the old behavior is still supported, but produces a DeprecationWarning.", "\n", "\n", "        ", "embedder_to_indexer_map", "=", "params", ".", "pop", "(", "\"embedder_to_indexer_map\"", ",", "None", ")", "\n", "if", "embedder_to_indexer_map", "is", "not", "None", ":", "\n", "            ", "embedder_to_indexer_map", "=", "embedder_to_indexer_map", ".", "as_dict", "(", "quiet", "=", "True", ")", "\n", "", "allow_unmatched_keys", "=", "bool", "(", "params", ".", "pop", "(", "\"allow_unmatched_keys\"", ",", "False", ")", ")", "\n", "\n", "token_embedder_params", "=", "params", ".", "pop", "(", "'token_embedders'", ",", "None", ")", "\n", "\n", "if", "token_embedder_params", "is", "not", "None", ":", "\n", "# New way: explicitly specified, so use it.", "\n", "            ", "token_embedders", "=", "{", "\n", "name", ":", "Embedding", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "subparams", ")", "\n", "for", "name", ",", "subparams", "in", "token_embedder_params", ".", "items", "(", ")", "\n", "}", "\n", "\n", "", "else", ":", "\n", "# Warn that the original behavior is deprecated", "\n", "            ", "warnings", ".", "warn", "(", "DeprecationWarning", "(", "\"the token embedders for BasicTextFieldEmbedder should now \"", "\n", "\"be specified as a dict under the 'token_embedders' key, \"", "\n", "\"not as top-level key-value pairs\"", ")", ")", "\n", "\n", "token_embedders", "=", "{", "}", "\n", "keys", "=", "list", "(", "params", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "keys", ":", "\n", "                ", "embedder_params", "=", "params", ".", "pop", "(", "key", ")", "\n", "token_embedders", "[", "key", "]", "=", "Embedding", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "embedder_params", ")", "\n", "\n", "# TODO(pitrack): replace this line?", "\n", "# params.assert_empty(cls.__name__)", "\n", "", "", "return", "cls", "(", "token_embedders", ",", "embedder_to_indexer_map", ",", "allow_unmatched_keys", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.mlp_attention.MLPAttention.__init__": [[6, 18], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_hidden_size", ",", "encoder_hidden_size", ",", "attention_hidden_size", ",", "coverage", "=", "False", ",", "use_concat", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLPAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "attention_hidden_size", "\n", "self", ".", "query_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "decoder_hidden_size", ",", "self", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "context_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "encoder_hidden_size", ",", "self", ".", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "coverage_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "1", ",", "self", ".", "hidden_size", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "use_concat", "=", "use_concat", "\n", "if", "self", ".", "use_concat", ":", "\n", "            ", "self", ".", "concat_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "decoder_hidden_size", ",", "self", ".", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.mlp_attention.MLPAttention.forward": [[19, 60], ["decoder_input.size", "encoder_input.size", "mlp_attention.MLPAttention.query_linear", "decoder_features.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "mlp_attention.MLPAttention.context_linear", "encoder_features.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.tanh", "mlp_attention.MLPAttention.output_linear().squeeze", "mlp_attention.MLPAttention.coverage_linear().expand", "mlp_attention.MLPAttention.concat_linear", "decoder_features.unsqueeze().expand.unsqueeze().expand.unsqueeze", "encoder_features.unsqueeze().expand.unsqueeze().expand.unsqueeze", "decoder_input.unsqueeze().expand", "encoder_input.unsqueeze().expand", "mlp_attention.MLPAttention.output_linear", "mlp_attention.MLPAttention.coverage_linear", "coverage.view", "decoder_input.unsqueeze", "encoder_input.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "", "def", "forward", "(", "self", ",", "decoder_input", ",", "encoder_input", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param decoder_input:  [batch, decoder_seq_length, decoder_hidden_size]\n        :param encoder_input:  [batch, encoder_seq_length, encoder_hidden_size]\n        :param coverage: [batch, encoder_seq_length]\n        :return:  [batch, decoder_seq_length, encoder_seq_length]\n        \"\"\"", "\n", "batch_size", ",", "decoder_seq_length", ",", "decoder_hidden_size", "=", "decoder_input", ".", "size", "(", ")", "\n", "batch_size", ",", "encoder_seq_length", ",", "encoder_hidden_size", "=", "encoder_input", ".", "size", "(", ")", "\n", "\n", "decoder_features", "=", "self", ".", "query_linear", "(", "decoder_input", ")", "\n", "decoder_features", "=", "decoder_features", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "batch_size", ",", "decoder_seq_length", ",", "encoder_seq_length", ",", "self", ".", "hidden_size", ")", "\n", "encoder_features", "=", "self", ".", "context_linear", "(", "encoder_input", ")", "\n", "encoder_features", "=", "encoder_features", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "decoder_seq_length", ",", "encoder_seq_length", ",", "self", ".", "hidden_size", ")", "\n", "attn_features", "=", "decoder_features", "+", "encoder_features", "\n", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "coverage_features", "=", "self", ".", "coverage_linear", "(", "\n", "coverage", ".", "view", "(", "batch_size", ",", "1", ",", "encoder_seq_length", ",", "1", ")", ")", ".", "expand", "(", "\n", "batch_size", ",", "decoder_seq_length", ",", "encoder_seq_length", ",", "self", ".", "hidden_size", ")", "\n", "attn_features", "=", "attn_features", "+", "coverage_features", "\n", "\n", "", "if", "self", ".", "use_concat", ":", "\n", "# concat_input = torch.cat([", "\n", "#     decoder_input.unsqueeze(2).expand(", "\n", "#         batch_size, decoder_seq_length, encoder_seq_length, decoder_hid# den_size),", "\n", "#     encoder_input.unsqueeze(1).expand(", "\n", "#         batch_size, decoder_seq_length, encoder_seq_length, encoder_hidden_size)", "\n", "# ], dim=3)", "\n", "            ", "concat_input", "=", "(", "decoder_input", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "batch_size", ",", "decoder_seq_length", ",", "encoder_seq_length", ",", "decoder_hidden_size", ")", "*", "\n", "encoder_input", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "decoder_seq_length", ",", "encoder_seq_length", ",", "encoder_hidden_size", ")", ")", "\n", "concat_features", "=", "self", ".", "concat_linear", "(", "concat_input", ")", "\n", "attn_features", "=", "attn_features", "+", "concat_features", "\n", "\n", "", "e", "=", "torch", ".", "tanh", "(", "attn_features", ")", "\n", "scores", "=", "self", ".", "output_linear", "(", "e", ")", ".", "squeeze", "(", "3", ")", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.dot_production_attention.DotProductAttention.__init__": [[6, 12], ["super().__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_hidden_size", ",", "encoder_hidden_size", ",", "share_linear", "=", "True", ")", ":", "\n", "        ", "super", "(", "DotProductAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder_hidden_size", "=", "decoder_hidden_size", "\n", "self", ".", "encoder_hidden_size", "=", "encoder_hidden_size", "\n", "self", ".", "linear_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "decoder_hidden_size", ",", "encoder_hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "share_linear", "=", "share_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.dot_production_attention.DotProductAttention.forward": [[13, 25], ["dot_production_attention.DotProductAttention.linear_layer", "dot_production_attention.DotProductAttention.transpose", "torch.bmm", "dot_production_attention.DotProductAttention.linear_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_input", ",", "encoder_input", ")", ":", "\n", "        ", "\"\"\"\n        :param decoder_input:  [batch, decoder_seq_length, decoder_hidden_size]\n        :param encoder_input:  [batch, encoder_seq_length, encoder_hidden_size]\n        :return:  [batch, decoder_seq_length, encoder_seq_length]\n        \"\"\"", "\n", "decoder_input", "=", "self", ".", "linear_layer", "(", "decoder_input", ")", "\n", "if", "self", ".", "share_linear", ":", "\n", "            ", "encoder_input", "=", "self", ".", "linear_layer", "(", "encoder_input", ")", "\n", "\n", "", "encoder_input", "=", "encoder_input", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "torch", ".", "bmm", "(", "decoder_input", ",", "encoder_input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.biaffine_attention.BiaffineAttention.__init__": [[14, 42], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "biaffine_attention.BiaffineAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "biaffine_attention.BiaffineAttention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size_encoder", ",", "input_size_decoder", ",", "num_labels", "=", "1", ",", "biaffine", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_size_encoder: int\n                the dimension of the encoder input.\n            input_size_decoder: int\n                the dimension of the decoder input.\n            num_labels: int\n                the number of labels of the crf layer\n            biaffine: bool\n                if apply bi-affine parameter.\n            **kwargs:\n        \"\"\"", "\n", "super", "(", "BiaffineAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size_encoder", "=", "input_size_encoder", "\n", "self", ".", "input_size_decoder", "=", "input_size_decoder", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "biaffine", "=", "biaffine", "\n", "\n", "self", ".", "W_d", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ")", ")", "\n", "self", ".", "W_e", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "1", ",", "1", ")", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'U'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.biaffine_attention.BiaffineAttention.reset_parameters": [[43, 49], ["torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "W_d", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "W_e", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "b", ",", "0.", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.attention.biaffine_attention.BiaffineAttention.forward": [[50, 94], ["input_d.size", "input_e.size", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "input_d.size", "input_e.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "input_d.unsqueeze", "input_e.unsqueeze().transpose", "mask_e.unsqueeze().unsqueeze", "input_d.transpose", "input_e.transpose", "mask_d.unsqueeze().unsqueeze", "input_e.unsqueeze", "mask_e.unsqueeze", "mask_d.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "", "def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "mask_d", "=", "None", ",", "mask_e", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_d: Tensor\n                the decoder input tensor with shape = [batch, length_decoder, input_size]\n            input_e: Tensor\n                the child input tensor with shape = [batch, length_encoder, input_size]\n            mask_d: Tensor or None\n                the mask tensor for decoder with shape = [batch, length_decoder]\n            mask_e: Tensor or None\n                the mask tensor for encoder with shape = [batch, length_encoder]\n        Returns: Tensor\n            the energy tensor with shape = [batch, num_label, length, length]\n        \"\"\"", "\n", "assert", "input_d", ".", "size", "(", "0", ")", "==", "input_e", ".", "size", "(", "0", ")", ",", "'batch sizes of encoder and decoder are requires to be equal.'", "\n", "batch", ",", "length_decoder", ",", "_", "=", "input_d", ".", "size", "(", ")", "\n", "_", ",", "length_encoder", ",", "_", "=", "input_e", ".", "size", "(", ")", "\n", "\n", "# compute decoder part: [num_label, input_size_decoder] * [batch, input_size_decoder, length_decoder]", "\n", "# the output shape is [batch, num_label, length_decoder]", "\n", "out_d", "=", "torch", ".", "matmul", "(", "self", ".", "W_d", ",", "input_d", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "# compute decoder part: [num_label, input_size_encoder] * [batch, input_size_encoder, length_encoder]", "\n", "# the output shape is [batch, num_label, length_encoder]", "\n", "out_e", "=", "torch", ".", "matmul", "(", "self", ".", "W_e", ",", "input_e", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "if", "self", ".", "biaffine", ":", "\n", "# compute bi-affine part", "\n", "# [batch, 1, length_decoder, input_size_decoder] * [num_labels, input_size_decoder, input_size_encoder]", "\n", "# output shape [batch, num_label, length_decoder, input_size_encoder]", "\n", "            ", "output", "=", "torch", ".", "matmul", "(", "input_d", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "U", ")", "\n", "# [batch, num_label, length_decoder, input_size_encoder] * [batch, 1, input_size_encoder, length_encoder]", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "output", "=", "torch", ".", "matmul", "(", "output", ",", "input_e", ".", "unsqueeze", "(", "1", ")", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "output", "=", "output", "+", "out_d", "+", "out_e", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "            ", "output", "=", "out_d", "+", "out_d", "+", "self", ".", "b", "\n", "\n", "", "if", "mask_d", "is", "not", "None", "and", "mask_e", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "*", "mask_d", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.get_input_dim": [[16, 23], ["None"], "methods", ["None"], ["def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the dimension of the vector input for each element in the sequence input\n        to a ``Seq2SeqEncoder``. This is `not` the shape of the input tensor, but the\n        last element of that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.get_output_dim": [[24, 30], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the dimension of each vector in the sequence output by this ``Seq2SeqEncoder``.\n        This is `not` the shape of the returned tensor, but the last element of that shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.is_bidirectional": [[31, 38], ["None"], "methods", ["None"], ["", "def", "is_bidirectional", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns ``True`` if this encoder is bidirectional.  If so, we assume the forward direction\n        of the encoder is the first half of the final dimension, and the backward direction is the\n        second half.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_bert_encoder.Seq2SeqBertEncoder.__init__": [[8, 10], ["pytorch_pretrained_bert.modeling.BertModel.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Seq2SeqBertEncoder", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_bert_encoder.Seq2SeqBertEncoder.forward": [[11, 31], ["super().forward", "seq2seq_bert_encoder.Seq2SeqBertEncoder.average_pooling"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.forward", "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_bert_encoder.Seq2SeqBertEncoder.average_pooling"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "token_subword_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param input_ids: same as it in BertModel\n        :param token_type_ids: same as it in BertModel\n        :param attention_mask: same as it in BertModel\n        :param output_all_encoded_layers: same as it in BertModel\n        :param token_subword_index: [batch_size, num_tokens, num_subwords]\n        :return:\n        \"\"\"", "\n", "# encoded_layers: [batch_size, num_subword_pieces, hidden_size]", "\n", "encoded_layers", ",", "pooled_output", "=", "super", "(", "Seq2SeqBertEncoder", ",", "self", ")", ".", "forward", "(", "\n", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", ")", "\n", "if", "token_subword_index", "is", "None", ":", "\n", "            ", "return", "encoded_layers", ",", "pooled_output", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "average_pooling", "(", "encoded_layers", ",", "token_subword_index", ")", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_bert_encoder.Seq2SeqBertEncoder.average_pooling": [[32, 54], ["token_subword_index.size", "torch.arange().view().type_as", "torch.arange().view().type_as", "encoded_layers.size", "encoded_layers.unsqueeze().expand", "token_subword_index.eq().unsqueeze().expand", "token_reprs.masked_fill_", "torch.sum", "token_subword_index.ne().sum", "token_subword_index.ne().sum.eq().long", "torch.arange().view", "torch.arange().view", "encoded_layers.unsqueeze", "token_subword_index.eq().unsqueeze", "token_subword_index.ne", "token_subword_index.ne().sum.eq", "torch.arange", "torch.arange", "token_subword_index.eq"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "", "def", "average_pooling", "(", "self", ",", "encoded_layers", ",", "token_subword_index", ")", ":", "\n", "        ", "batch_size", ",", "num_tokens", ",", "num_subwords", "=", "token_subword_index", ".", "size", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "token_index", "=", "torch", ".", "arange", "(", "num_tokens", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "_", ",", "num_total_subwords", ",", "hidden_size", "=", "encoded_layers", ".", "size", "(", ")", "\n", "expanded_encoded_layers", "=", "encoded_layers", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_total_subwords", ",", "hidden_size", ")", "\n", "# [batch_size, num_tokens, num_subwords, hidden_size]", "\n", "token_reprs", "=", "expanded_encoded_layers", "[", "batch_index", ",", "token_index", ",", "token_subword_index", "]", "\n", "subword_pad_mask", "=", "token_subword_index", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_subwords", ",", "hidden_size", ")", "\n", "token_reprs", ".", "masked_fill_", "(", "subword_pad_mask", ",", "0", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "sum_token_reprs", "=", "torch", ".", "sum", "(", "token_reprs", ",", "dim", "=", "2", ")", "\n", "# [batch_size, num_tokens]", "\n", "num_valid_subwords", "=", "token_subword_index", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "pad_mask", "=", "num_valid_subwords", ".", "eq", "(", "0", ")", ".", "long", "(", ")", "\n", "# Add ones to arrays where there is no valid subword.", "\n", "divisor", "=", "(", "num_valid_subwords", "+", "pad_mask", ")", ".", "unsqueeze", "(", "2", ")", ".", "type_as", "(", "sum_token_reprs", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "avg_token_reprs", "=", "sum_token_reprs", "/", "divisor", "\n", "return", "avg_token_reprs", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.seq2seq_bert_encoder.Seq2SeqBertEncoder.max_pooling": [[55, 75], ["token_subword_index.size", "torch.arange().view().type_as", "torch.arange().view().type_as", "encoded_layers.size", "encoded_layers.unsqueeze().expand", "token_subword_index.eq().unsqueeze().expand", "token_reprs.masked_fill_", "torch.max", "token_subword_index.ne().sum", "token_subword_index.ne().sum.eq().unsqueeze().expand", "max_token_reprs.masked_fill", "torch.arange().view", "torch.arange().view", "encoded_layers.unsqueeze", "token_subword_index.eq().unsqueeze", "float", "token_subword_index.ne", "token_subword_index.ne().sum.eq().unsqueeze", "torch.arange", "torch.arange", "token_subword_index.eq", "token_subword_index.ne().sum.eq"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "max_pooling", "(", "self", ",", "encoded_layers", ",", "token_subword_index", ")", ":", "\n", "        ", "batch_size", ",", "num_tokens", ",", "num_subwords", "=", "token_subword_index", ".", "size", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "token_index", "=", "torch", ".", "arange", "(", "num_tokens", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "_", ",", "num_total_subwords", ",", "hidden_size", "=", "encoded_layers", ".", "size", "(", ")", "\n", "expanded_encoded_layers", "=", "encoded_layers", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_total_subwords", ",", "hidden_size", ")", "\n", "# [batch_size, num_tokens, num_subwords, hidden_size]", "\n", "token_reprs", "=", "expanded_encoded_layers", "[", "batch_index", ",", "token_index", ",", "token_subword_index", "]", "\n", "subword_pad_mask", "=", "token_subword_index", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_subwords", ",", "hidden_size", ")", "\n", "token_reprs", ".", "masked_fill_", "(", "subword_pad_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "max_token_reprs", ",", "_", "=", "torch", ".", "max", "(", "token_reprs", ",", "dim", "=", "2", ")", "\n", "# [batch_size, num_tokens]", "\n", "num_valid_subwords", "=", "token_subword_index", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "pad_mask", "=", "num_valid_subwords", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "hidden_size", ")", "\n", "max_token_reprs", ".", "masked_fill", "(", "pad_mask", ",", "0", ")", "\n", "return", "max_token_reprs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.__init__": [[34, 51], ["stog.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "module", ":", "torch", ".", "nn", ".", "Module", ",", "stateful", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "PytorchSeq2SeqWrapper", ",", "self", ")", ".", "__init__", "(", "stateful", ")", "\n", "self", ".", "_module", "=", "module", "\n", "try", ":", "\n", "            ", "if", "not", "self", ".", "_module", ".", "batch_first", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Our encoder semantics assumes batch is always first!\"", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "_is_bidirectional", "=", "self", ".", "_module", ".", "bidirectional", "\n", "", "except", "AttributeError", ":", "\n", "            ", "self", ".", "_is_bidirectional", "=", "False", "\n", "", "if", "self", ".", "_is_bidirectional", ":", "\n", "            ", "self", ".", "_num_directions", "=", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "_num_directions", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.get_input_dim": [[52, 55], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_module", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.get_output_dim": [[56, 59], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_module", ".", "hidden_size", "*", "self", ".", "_num_directions", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.is_bidirectional": [[60, 63], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "_is_bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.forward": [[64, 122], ["mask.size", "pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper.sort_and_run_forward", "torch.nn.utils.rnn.pad_packed_sequence", "torch.cat.size", "torch.cat.index_select", "ValueError", "ValueError", "torch.cat.size", "torch.cat.new_zeros", "torch.cat", "torch.cat.size", "torch.cat.new_zeros", "torch.cat", "pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper._update_states", "pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper._module", "isinstance", "torch.cat.size", "state.size", "state.new_zeros", "new_states.append", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.sort_and_run_forward", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase._update_states", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "if", "self", ".", "stateful", "and", "mask", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Always pass a mask with stateful RNNs.\"", ")", "\n", "", "if", "self", ".", "stateful", "and", "hidden_state", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Stateful RNNs provide their own initial hidden_state.\"", ")", "\n", "\n", "", "if", "mask", "is", "None", ":", "\n", "            ", "return", "self", ".", "_module", "(", "inputs", ",", "hidden_state", ")", "[", "0", "]", "\n", "\n", "", "batch_size", ",", "total_sequence_length", "=", "mask", ".", "size", "(", ")", "\n", "\n", "packed_sequence_output", ",", "final_states", ",", "restoration_indices", "=", "self", ".", "sort_and_run_forward", "(", "self", ".", "_module", ",", "inputs", ",", "mask", ",", "hidden_state", ")", "\n", "\n", "unpacked_sequence_tensor", ",", "_", "=", "pad_packed_sequence", "(", "packed_sequence_output", ",", "batch_first", "=", "True", ")", "\n", "\n", "num_valid", "=", "unpacked_sequence_tensor", ".", "size", "(", "0", ")", "\n", "# Some RNNs (GRUs) only return one state as a Tensor.  Others (LSTMs) return two.", "\n", "# If one state, use a single element list to handle in a consistent manner below.", "\n", "if", "not", "isinstance", "(", "final_states", ",", "(", "list", ",", "tuple", ")", ")", "and", "self", ".", "stateful", ":", "\n", "            ", "final_states", "=", "[", "final_states", "]", "\n", "\n", "# Add back invalid rows.", "\n", "", "if", "num_valid", "<", "batch_size", ":", "\n", "            ", "_", ",", "length", ",", "output_dim", "=", "unpacked_sequence_tensor", ".", "size", "(", ")", "\n", "zeros", "=", "unpacked_sequence_tensor", ".", "new_zeros", "(", "batch_size", "-", "num_valid", ",", "length", ",", "output_dim", ")", "\n", "unpacked_sequence_tensor", "=", "torch", ".", "cat", "(", "[", "unpacked_sequence_tensor", ",", "zeros", "]", ",", "0", ")", "\n", "\n", "# The states also need to have invalid rows added back.", "\n", "if", "self", ".", "stateful", ":", "\n", "                ", "new_states", "=", "[", "]", "\n", "for", "state", "in", "final_states", ":", "\n", "                    ", "num_layers", ",", "_", ",", "state_dim", "=", "state", ".", "size", "(", ")", "\n", "zeros", "=", "state", ".", "new_zeros", "(", "num_layers", ",", "batch_size", "-", "num_valid", ",", "state_dim", ")", "\n", "new_states", ".", "append", "(", "torch", ".", "cat", "(", "[", "state", ",", "zeros", "]", ",", "1", ")", ")", "\n", "", "final_states", "=", "new_states", "\n", "\n", "# It's possible to need to pass sequences which are padded to longer than the", "\n", "# max length of the sequence to a Seq2SeqEncoder. However, packing and unpacking", "\n", "# the sequences mean that the returned tensor won't include these dimensions, because", "\n", "# the RNN did not need to process them. We add them back on in the form of zeros here.", "\n", "", "", "sequence_length_difference", "=", "total_sequence_length", "-", "unpacked_sequence_tensor", ".", "size", "(", "1", ")", "\n", "if", "sequence_length_difference", ">", "0", ":", "\n", "            ", "zeros", "=", "unpacked_sequence_tensor", ".", "new_zeros", "(", "batch_size", ",", "\n", "sequence_length_difference", ",", "\n", "unpacked_sequence_tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "unpacked_sequence_tensor", "=", "torch", ".", "cat", "(", "[", "unpacked_sequence_tensor", ",", "zeros", "]", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "stateful", ":", "\n", "            ", "self", ".", "_update_states", "(", "final_states", ",", "restoration_indices", ")", "\n", "\n", "# Restore the original indices and return the sequence.", "\n", "", "return", "unpacked_sequence_tensor", ".", "index_select", "(", "0", ",", "restoration_indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.__init__": [[57, 133], ["stog.models.model.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["", "else", ":", "\n", "                    ", "nodes", ".", "append", "(", "self", ".", "_model", ".", "vocab", ".", "get_token_from_index", "(", "index", ",", "'decoder_token_ids'", ")", ")", "\n", "copy_indicators", ".", "append", "(", "0", ")", "\n", "# Lookup the head label.", "\n", "", "head_labels", ".", "append", "(", "self", ".", "_model", ".", "vocab", ".", "get_token_from_index", "(", "\n", "head_label_indexes", "[", "i", "]", ",", "'head_tags'", ")", ")", "\n", "\n", "", "if", "END_SYMBOL", "in", "nodes", ":", "\n", "                ", "nodes", "=", "nodes", "[", ":", "nodes", ".", "index", "(", "END_SYMBOL", ")", "]", "\n", "head_indexes", "=", "head_indexes", "[", ":", "len", "(", "nodes", ")", "]", "\n", "head_labels", "=", "head_labels", "[", ":", "len", "(", "nodes", ")", "]", "\n", "corefs", "=", "corefs", "[", ":", "len", "(", "nodes", ")", "]", "\n", "\n", "", "outputs", ".", "append", "(", "dict", "(", "\n", "nodes", "=", "nodes", ",", "\n", "heads", "=", "head_indexes", ",", "\n", "corefs", "=", "corefs", ",", "\n", "head_labels", "=", "head_labels", ",", "\n", "copy_indicators", "=", "copy_indicators", ",", "\n", "gold_amr", "=", "gold_amr", "\n", ")", ")", "\n", "\n", "", "return", "outputs", "\n", "\n", "", "@", "overrides", "\n", "def", "dump_line", "(", "self", ",", "output", ")", ":", "\n", "# return ' '.join(output['nodes']) + '\\n'", "\n", "        ", "pred_graph", "=", "AMRGraph", ".", "from_prediction", "(", "output", ")", "\n", "amr", "=", "output", "[", "'gold_amr'", "]", "\n", "gold_graph", "=", "amr", ".", "graph", "\n", "amr", ".", "graph", "=", "pred_graph", "\n", "\n", "string_to_print", "=", "str", "(", "amr", ")", ".", "replace", "(", "\n", "\"# ::save-date\"", ",", "\"# ::tgt_ref {}\\n# ::tgt_pred {}\\n# ::save-date\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "output", "[", "\"nodes\"", "]", ")", ",", "\n", "\" \"", ".", "join", "(", "gold_graph", ".", "get_tgt_tokens", "(", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "return", "string_to_print", "+", "'\\n\\n'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.set_beam_size": [[134, 136], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.set_decoder_token_indexers": [[137, 140], ["stog.data.tokenizers.character_tokenizer.CharacterTokenizer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.get_metrics": [[141, 152], ["dict", "stog.STOG.generator.metrics.get_metric", "stog.STOG.graph_decoder.metrics.get_metric", "stog.STOG.update", "stog.STOG.update", "stog.STOG.mimick_test"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.get_metric", "home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.get_metric", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.mimick_test"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.mimick_test": [[153, 190], ["stog.data.dataset_builder.load_dataset_reader", "stog.data.dataset_builder.load_dataset_reader.set_evaluation", "stog.commands.predict._PredictManager", "stog.STOG.test_config.get", "stog.predictors.predictor.Predictor.by_name", "logger.info", "stog.commands.predict._PredictManager.run", "logger.info", "subprocess.check_output().decode().split", "list", "dict", "logger.info", "logger.error", "map", "logger.info", "logger.error", "subprocess.check_output().decode", "subprocess.check_output"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset_reader", "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.set_evaluation", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.by_name", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager.run", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.print_batch_details": [[191, 216], ["print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "[].int", "enumerate", "enumerate", "enumerate", "enumerate", "[].tolist", "[].tolist"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.prepare_batch_input": [[217, 310], ["batch.get", "batch.get", "stog.utils.nn.get_text_field_mask", "dict", "[].contiguous", "[].contiguous", "[].contiguous", "[].contiguous.ne", "decoder_coref_inputs.masked_fill_", "dict", "[].contiguous", "dict", "torch.zeros_like", "torch.zeros_like.copy_", "dict", "bert_token_inputs.long.long.long", "encoder_token_subword_index.long.long.long", "torch.ones_like", "torch.arange().type_as().unsqueeze", "torch.arange().type_as", "stog.STOG.vocab.get_token_index", "torch.arange", "[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_text_field_mask", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.forward": [[311, 388], ["stog.STOG.prepare_batch_input", "stog.STOG.encode", "stog.STOG.decode_for_training", "stog.STOG.generator", "stog.STOG.generator.compute_loss", "stog.STOG.graph_decode", "dict", "dict", "dict", "batch.get", "set", "range", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.prepare_batch_input", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_for_training", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.generator.Generator.compute_loss", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.graph_decode", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode": [[390, 432], ["stog.STOG.encoder_token_embedding", "stog.STOG.encoder_pos_embedding", "torch.cat", "stog.STOG.encoder_embedding_dropout", "stog.STOG.encoder", "stog.STOG.encoder_output_dropout", "stog.STOG.encoder.reset_states", "dict", "bert_tokens.ne", "stog.STOG.bert_encoder", "stog.STOG.encoder_must_copy_embedding", "stog.STOG._get_encoder_char_cnn_output"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.reset_states", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._get_encoder_char_cnn_output"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_for_training": [[434, 465], ["stog.STOG.decoder_token_embedding", "stog.STOG.decoder_pos_embedding", "stog.STOG.decoder_coref_embedding", "stog.STOG.decoder_embedding_dropout", "stog.STOG.decoder", "dict", "stog.STOG._get_decoder_char_cnn_output", "torch.cat", "torch.cat", "stog.STOG.aux_encoder", "stog.STOG.aux_encoder_output_dropout", "stog.STOG.aux_encoder.reset_states", "tgt_mask[].byte"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._get_decoder_char_cnn_output", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.reset_states"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.graph_decode": [[467, 475], ["stog.STOG.graph_decoder", "torch.cat"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._get_encoder_char_cnn_output": [[476, 484], ["stog.STOG.encoder_char_embedding", "char_embeddings.view.view.size", "char_embeddings.view.view.view", "stog.STOG.encoder_char_cnn", "char_cnn_output.view.view.view"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._get_decoder_char_cnn_output": [[485, 493], ["stog.STOG.decoder_char_embedding", "char_embeddings.view.view.size", "char_embeddings.view.view.view", "stog.STOG.decoder_char_cnn", "char_cnn_output.view.view.view"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode": [[494, 522], ["stog.STOG.decode_with_graph_parser", "dict", "stog.STOG.decode_with_pointer_generator", "stog.STOG.beam_search_with_pointer_generator"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_with_graph_parser", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_with_pointer_generator", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.beam_search_with_pointer_generator"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.beam_search_with_pointer_generator": [[524, 939], ["memory_bank.size", "torch.arange().view().repeat().view().type_as", "stog.STOG.vocab.get_token_index", "stog.STOG.vocab.get_token_index", "stog.STOG.vocab.get_token_index", "mask.new_full", "memory_bank.new_zeros", "memory_bank.new_ones", "memory_bank.new_zeros", "beam_buffer[].new_full", "mask.new_full", "mask.new_zeros", "mask.new_full", "memory_bank.new_zeros", "mask.new_zeros", "invalid_indices.keys", "range", "enumerate", "[].keys", "torch.div", "list", "tensor.contiguous().view", "list", "tensor.view", "list", "list", "input.view().index_select().view", "list", "list", "input.index_select().view", "stog.STOG.decoder_token_embedding", "stog.STOG.decoder_pos_embedding", "stog.STOG.decoder_coref_embedding", "stog.STOG.decoder_embedding_dropout", "float", "stog.STOG.vocab.get_token_index", "item.index_select", "memory_bank.new_zeros", "stog.STOG.beam_search_with_pointer_generator.repeat_list_item"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_with_pointer_generator": [[943, 1076], ["memory_bank.size", "tokens.type_as().long.type_as().long.type_as().long", "pos_tags.type_as.type_as.type_as", "torch.zeros().type_as().long", "torch.zeros().type_as", "torch.zeros().type_as().long", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dict", "torch.ones", "stog.STOG.vocab.get_token_index", "torch.ones", "stog.STOG.vocab.get_token_index", "memory_bank.new_zeros", "stog.STOG.decoder_token_embedding", "stog.STOG.decoder_pos_embedding", "stog.STOG.decoder_coref_embedding", "stog.STOG.decoder_embedding_dropout", "stog.STOG.decoder", "stog.STOG.generator", "stog.STOG._update_maps_and_get_next_input", "torch.cat", "tokens.type_as().long.type_as().long.type_as", "torch.zeros().type_as", "torch.zeros", "torch.zeros().type_as", "memory_bank.size", "stog.character_tensor_from_token_tensor", "stog.STOG._get_decoder_char_cnn_output", "torch.cat", "torch.cat", "generator_output[].squeeze", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._update_maps_and_get_next_input", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.character_tensor_from_token_tensor", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._get_decoder_char_cnn_output"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG._update_maps_and_get_next_input": [[1078, 1165], ["predictions.size", "torch.arange().type_as", "torch.full_like", "predictions.lt", "predictions.ge().mul", "predictions.ge", "coref_index.masked_fill_", "coref_vocab_maps.gather().squeeze", "torch.full_like", "enumerate", "enumerate", "torch.zeros_like", "predictions.lt", "predictions.ge.long", "predictions.ge().mul.long", "stog.STOG.vocab.get_token_index", "copy_predictions.tolist", "copy_vocabs[].get_token_from_idx", "stog.STOG.vocab.get_token_index", "len", "torch.cat().long().sum().gt", "next_input.eq", "next_input.unsqueeze", "coref_resolved_preds.unsqueeze", "torch.full_like.unsqueeze", "coref_index.unsqueeze", "mask.unsqueeze", "torch.arange", "predictions.ge", "coref_vocab_maps.gather", "stog.STOG.vocab.get_token_index", "stog.STOG.vocab.get_token_from_index", "stog.utils.string.find_similar_token", "predictions.lt.long", "predictions.ge.long", "stog.STOG.vocab.get_token_index", "coref_vocab_maps.gather().squeeze.unsqueeze", "[].add", "list", "stog.STOG.vocab.get_token_index", "[].add", "predictions.ge.long", "predictions.ge().mul.long", "torch.cat().long().sum", "[].keys", "predictions.lt.long", "predictions.ge.long", "torch.cat().long", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_from_idx", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.find_similar_token", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.decode_with_graph_parser": [[1166, 1190], ["stog.STOG.graph_decoder._add_head_sentinel", "stog.STOG.graph_decoder.encode", "stog.STOG.graph_decoder._get_edge_node_scores", "stog.STOG.graph_decoder.mst_decode", "dict", "stog.STOG.aux_encoder", "stog.STOG.aux_encoder.reset_states", "torch.cat", "mask.float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._add_head_sentinel", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder._get_edge_node_scores", "home.repos.pwc.inspect_result.jcyk_gtos.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.mst_decode", "home.repos.pwc.inspect_result.jcyk_gtos.modules.encoder_base._EncoderBase.reset_states"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.from_params": [[1192, 1386], ["logger.info", "params.get", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.token_embedders.embedding.Embedding.from_params", "params.get", "stog.modules.input_variational_dropout.InputVariationalDropout", "stog.modules.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper", "stog.modules.input_variational_dropout.InputVariationalDropout", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.input_variational_dropout.InputVariationalDropout", "stog.modules.attention_layers.global_attention.GlobalAttention", "stog.modules.attention_layers.global_attention.GlobalAttention", "stog.modules.decoders.rnn_decoder.InputFeedRNNDecoder", "params.get", "stog.modules.decoders.pointer_generator.PointerGenerator", "stog.modules.decoders.deep_biaffine_graph_decoder.DeepBiaffineGraphDecoder.from_params", "vocab.get_token_index", "logger.info", "logger.info", "logger.info", "logger.info", "cls", "stog.modules.seq2seq_encoders.Seq2SeqBertEncoder.from_pretrained", "stog.modules.seq2seq_encoders.Seq2SeqBertEncoder.from_pretrained.parameters", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.seq2vec_encoders.cnn_encoder.CnnEncoder", "stog.modules.token_embedders.embedding.Embedding.from_params", "stog.modules.seq2vec_encoders.cnn_encoder.CnnEncoder", "stog.modules.attention.MLPAttention", "stog.modules.attention.DotProductAttention", "stog.modules.attention.MLPAttention", "stog.modules.seq2seq_encoders.pytorch_seq2seq_wrapper.PytorchSeq2SeqWrapper", "stog.modules.input_variational_dropout.InputVariationalDropout", "vocab.get_token_index", "stog.modules.stacked_bilstm.StackedBidirectionalLstm.from_params", "stog.modules.attention.BiaffineAttention", "stog.modules.attention.DotProductAttention", "stog.modules.stacked_lstm.StackedLstm.from_params", "stog.modules.input_variational_dropout.InputVariationalDropout", "vocab.get_vocab_size", "params[].get", "punctuation_ids.append", "vocab.get_vocab_size", "vocab.get_vocab_size", "vocab.get_vocab_size", "vocab.get_vocab_size", "params.get", "params.get", "params.get", "params.get", "params.get", "params[].get", "params[].get", "params[].get", "params[].get", "stog.modules.stacked_bilstm.StackedBidirectionalLstm.from_params", "params[].get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], []], "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.character_tensor_from_token_tensor": [[36, 53], ["dict", "max", "torch.tensor().view().type_as", "vocab.get_token_from_index", "enumerate", "indices.append", "token_tensor.view().tolist", "len", "vocab.get_token_index", "character_tokenizer.tokenize", "vocab.get_token_index", "torch.tensor().view", "range", "token_tensor.size", "token_tensor.size", "token_tensor.view", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["        ", "outputs", "=", "[", "]", "\n", "gen_vocab_size", "=", "self", ".", "_model", ".", "vocab", ".", "get_vocab_size", "(", "'decoder_token_ids'", ")", "\n", "_outputs", "=", "super", "(", "STOGPredictor", ",", "self", ")", ".", "predict_batch_instance", "(", "instances", ")", "\n", "for", "instance", ",", "output", "in", "zip", "(", "instances", ",", "_outputs", ")", ":", "\n", "            ", "gold_amr", "=", "instance", ".", "fields", "[", "'amr'", "]", ".", "metadata", "\n", "copy_vocab", "=", "instance", ".", "fields", "[", "'src_copy_vocab'", "]", ".", "metadata", "\n", "node_indexes", "=", "output", "[", "'nodes'", "]", "\n", "head_indexes", "=", "output", "[", "'heads'", "]", "\n", "head_label_indexes", "=", "output", "[", "'head_labels'", "]", "\n", "corefs", "=", "output", "[", "'corefs'", "]", "\n", "\n", "nodes", "=", "[", "]", "\n", "head_labels", "=", "[", "]", "\n", "copy_indicators", "=", "[", "]", "\n", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "node_indexes", ")", ":", "\n", "# Lookup the node.", "\n", "                ", "if", "index", ">=", "gen_vocab_size", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.__init__": [[51, 55], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "regularizer", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_regularizer", "=", "regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_regularization_penalty": [[56, 65], ["model.Model._regularizer"], "methods", ["None"], ["", "def", "get_regularization_penalty", "(", "self", ")", "->", "Union", "[", "float", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Computes the regularization penalty for the model.\n        Returns 0 if the model was not configured to use regularization.\n        \"\"\"", "\n", "if", "self", ".", "_regularizer", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_regularizer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_parameters_for_histogram_tensorboard_logging": [[66, 72], ["model.Model.named_parameters"], "methods", ["None"], ["", "", "def", "get_parameters_for_histogram_tensorboard_logging", "(", "# pylint: disable=invalid-name", "\n", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Returns the name of model parameters used for logging histograms to tensorboard.\n        \"\"\"", "\n", "return", "[", "name", "for", "name", ",", "_", "in", "self", ".", "named_parameters", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.forward": [[73, 108], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Defines the forward pass of the model. In addition, to facilitate easy training,\n        this method is designed to compute a loss function defined by a user.\n        The input is comprised of everything required to perform a\n        training update, `including` labels - you define the signature here!\n        It is down to the user to ensure that inference can be performed\n        without the presence of these labels. Hence, any inputs not available at\n        inference time should only be used inside a conditional block.\n        The intended sketch of this method is as follows::\n            def forward(self, input1, input2, targets=None):\n                ....\n                ....\n                output1 = self.layer1(input1)\n                output2 = self.layer2(input2)\n                output_dict = {\"output1\": output1, \"output2\": output2}\n                if targets is not None:\n                    # Function returning a scalar torch.Tensor, defined by the user.\n                    loss = self._compute_loss(output1, output2, targets)\n                    output_dict[\"loss\"] = loss\n                return output_dict\n        Parameters\n        ----------\n        inputs:\n            Tensors comprising everything needed to perform a training update, `including` labels,\n            which should be optional (i.e have a default value of ``None``).  At inference time,\n            simply pass the relevant inputs, not including the labels.\n        Returns\n        -------\n        output_dict: ``Dict[str, torch.Tensor]``\n            The outputs from the model. In order to train a model using the\n            :class:`~allennlp.training.Trainer` api, you must provide a \"loss\" key pointing to a\n            scalar ``torch.Tensor`` representing the loss to be optimized.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.forward_on_instance": [[109, 118], ["None"], "methods", ["None"], ["", "def", "forward_on_instance", "(", "self", ",", "instance", ")", "->", "Dict", "[", "str", ",", "numpy", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Takes an :class:`~allennlp.data.instance.Instance`, which typically has raw text in it,\n        converts that text into arrays using this model's :class:`Vocabulary`, passes those arrays\n        through :func:`self.forward()` and :func:`self.decode()` (which by default does nothing)\n        and returns the result.  Before returning the result, we convert any\n        ``torch.Tensors`` into numpy arrays and remove the batch dimension.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.forward_on_instances": [[119, 166], ["len", "torch.no_grad", "model.Model._get_prediction_device", "stog.data.dataset.Batch", "stog.data.dataset.Batch.index_instances", "stog.utils.environment.move_to_device", "model.Model.decode", "list", "stog.data.dataset.Batch.as_tensor_dict", "model.Model.", "model.Model.items", "isinstance", "zip", "output.unsqueeze.unsqueeze.detach().cpu().numpy", "output.unsqueeze.unsqueeze.dim", "output.unsqueeze.unsqueeze.unsqueeze", "output.unsqueeze.unsqueeze.size", "model.Model._maybe_warn_for_unseparable_batches", "len", "model.Model._maybe_warn_for_unseparable_batches", "output.unsqueeze.unsqueeze.detach().cpu", "output.unsqueeze.unsqueeze.detach"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._get_prediction_device", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.index_instances", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode", "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.as_tensor_dict", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._maybe_warn_for_unseparable_batches", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._maybe_warn_for_unseparable_batches"], ["", "def", "forward_on_instances", "(", "self", ",", "instances", ")", "->", "List", "[", "Dict", "[", "str", ",", "numpy", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of  :class:`~allennlp.data.instance.Instance`s, converts that text into\n        arrays using this model's :class:`Vocabulary`, passes those arrays through\n        :func:`self.forward()` and :func:`self.decode()` (which by default does nothing)\n        and returns the result.  Before returning the result, we convert any\n        ``torch.Tensors`` into numpy arrays and separate the\n        batched output into a list of individual dicts per instance. Note that typically\n        this will be faster on a GPU (and conditionally, on a CPU) than repeated calls to\n        :func:`forward_on_instance`.\n        Parameters\n        ----------\n        instances : List[Instance], required\n            The instances to run the model on.\n        cuda_device : int, required\n            The GPU device to use.  -1 means use the CPU.\n        Returns\n        -------\n        A list of the models output for each instance.\n        \"\"\"", "\n", "batch_size", "=", "len", "(", "instances", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "device", "=", "self", ".", "_get_prediction_device", "(", ")", "\n", "dataset", "=", "Batch", "(", "instances", ")", "\n", "dataset", ".", "index_instances", "(", "self", ".", "vocab", ")", "\n", "model_input", "=", "move_to_device", "(", "dataset", ".", "as_tensor_dict", "(", ")", ",", "device", ")", "\n", "outputs", "=", "self", ".", "decode", "(", "self", "(", "model_input", ")", ")", "\n", "\n", "instance_separated_output", ":", "List", "[", "Dict", "[", "str", ",", "numpy", ".", "ndarray", "]", "]", "=", "[", "{", "}", "for", "_", "in", "dataset", ".", "instances", "]", "\n", "for", "name", ",", "output", "in", "list", "(", "outputs", ".", "items", "(", ")", ")", ":", "\n", "                ", "if", "isinstance", "(", "output", ",", "torch", ".", "Tensor", ")", ":", "\n", "# NOTE(markn): This is a hack because 0-dim pytorch tensors are not iterable.", "\n", "# This occurs with batch size 1, because we still want to include the loss in that case.", "\n", "                    ", "if", "output", ".", "dim", "(", ")", "==", "0", ":", "\n", "                        ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "if", "output", ".", "size", "(", "0", ")", "!=", "batch_size", ":", "\n", "                        ", "self", ".", "_maybe_warn_for_unseparable_batches", "(", "name", ")", "\n", "continue", "\n", "", "output", "=", "output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "len", "(", "output", ")", "!=", "batch_size", ":", "\n", "                    ", "self", ".", "_maybe_warn_for_unseparable_batches", "(", "name", ")", "\n", "continue", "\n", "", "outputs", "[", "name", "]", "=", "output", "\n", "for", "instance_output", ",", "batch_element", "in", "zip", "(", "instance_separated_output", ",", "output", ")", ":", "\n", "                    ", "instance_output", "[", "name", "]", "=", "batch_element", "\n", "", "", "return", "instance_separated_output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.decode": [[167, 181], ["None"], "methods", ["None"], ["", "", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Takes the result of :func:`forward` and runs inference / decoding / whatever\n        post-processing you need to do your model.  The intent is that ``model.forward()`` should\n        produce potentials or probabilities, and then ``model.decode()`` can take those results and\n        run some kind of beam search or constrained inference or whatever is necessary.  This does\n        not handle all possible decoding use cases, but it at least handles simple kinds of\n        decoding.\n        This method `modifies` the input dictionary, and also `returns` the same dictionary.\n        By default in the base class we do nothing.  If your model has some special decoding step,\n        override this method.\n        \"\"\"", "\n", "# pylint: disable=no-self-use", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics": [[182, 196], ["None"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary of metrics. This method will be called by\n        :class:`allennlp.training.Trainer` in order to compute and use model metrics for early\n        stopping and model serialization.  We return an empty dictionary here rather than raising\n        as it is not required to implement metrics for a new model.  A boolean `reset` parameter is\n        passed, as frequently a metric accumulator will have some state which should be reset\n        between epochs. This is also compatible with :class:`~allennlp.training.Metric`s. Metrics\n        should be populated during the call to ``forward``, with the\n        :class:`~allennlp.training.Metric` handling the accumulation of the metric until this\n        method is called.\n        \"\"\"", "\n", "# pylint: disable=unused-argument,no-self-use", "\n", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._get_prediction_device": [[197, 215], ["stog.utils.nn.get_device_of", "len", "stog.utils.checks.ConfigurationError", "model.Model.parameters", "all", "torch.device", "torch.device", "str", "len", "devices.pop"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.get_device_of"], ["", "def", "_get_prediction_device", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This method checks the device of the model parameters to determine the cuda_device\n        this model should be run on for predictions.  If there are no parameters, it returns -1.\n        Returns\n        -------\n        The cuda device this model should run on for predictions.\n        \"\"\"", "\n", "devices", "=", "{", "get_device_of", "(", "param", ")", "for", "param", "in", "self", ".", "parameters", "(", ")", "}", "\n", "\n", "if", "len", "(", "devices", ")", ">", "1", ":", "\n", "            ", "devices_string", "=", "\", \"", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "devices", ")", "\n", "raise", "ConfigurationError", "(", "f\"Parameters have mismatching cuda_devices: {devices_string}\"", ")", "\n", "", "elif", "len", "(", "devices", ")", "==", "1", "and", "all", "(", "i", ">=", "0", "for", "i", "in", "devices", ")", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "devices", ".", "pop", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._maybe_warn_for_unseparable_batches": [[216, 229], ["logger.warning", "model.Model._warn_for_unseparable_batches.add"], "methods", ["None"], ["", "def", "_maybe_warn_for_unseparable_batches", "(", "self", ",", "output_key", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        This method warns once if a user implements a model which returns a dictionary with\n        values which we are unable to split back up into elements of the batch. This is controlled\n        by a class attribute ``_warn_for_unseperable_batches`` because it would be extremely verbose\n        otherwise.\n        \"\"\"", "\n", "if", "output_key", "not", "in", "self", ".", "_warn_for_unseparable_batches", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Encountered the {output_key} key in the model's return dictionary which \"", "\n", "\"couldn't be split by the batch size. Key will be ignored.\"", ")", "\n", "# We only want to warn once for this key,", "\n", "# so we set this to false so we don't warn again.", "\n", "self", ".", "_warn_for_unseparable_batches", ".", "add", "(", "output_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.set_vocab": [[230, 232], ["None"], "methods", ["None"], ["", "", "def", "set_vocab", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model._load": [[233, 266], ["os.path.join", "stog.data.vocabulary.Vocabulary.from_files", "stog.utils.params.remove_pretrained_embedding_params", "cls.from_params", "torch.load", "cls.from_params.load_state_dict", "cls.from_params.set_vocab", "cls.from_params.to", "os.path.join", "isinstance", "stog.utils.nn.device_mapping", "re.sub", "torch.load.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_files", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.remove_pretrained_embedding_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.set_vocab", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.device_mapping", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "classmethod", "\n", "def", "_load", "(", "cls", ",", "\n", "config", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "weights_file", ":", "str", "=", "None", ",", "\n", "device", "=", "None", ")", "->", "'Model'", ":", "\n", "        ", "\"\"\"\n        Instantiates an already-trained model, based on the experiment\n        configuration and some optional overrides.\n        \"\"\"", "\n", "weights_file", "=", "weights_file", "or", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", "\n", "\n", "# Load vocabulary from file", "\n", "vocab_dir", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'vocabulary'", ")", "\n", "# If the config specifies a vocabulary subclass, we need to use it.", "\n", "vocab", "=", "Vocabulary", ".", "from_files", "(", "vocab_dir", ")", "\n", "\n", "model_params", "=", "config", "[", "'model'", "]", "\n", "\n", "# The experiment config tells us how to _train_ a model, including where to get pre-trained", "\n", "# embeddings from.  We're now _loading_ the model, so those embeddings will already be", "\n", "# stored in our weights.  We don't need any pretrained weight file anymore, and we don't", "\n", "# want the code to look for it, so we remove it from the parameters here.", "\n", "remove_pretrained_embedding_params", "(", "model_params", ")", "\n", "model", "=", "cls", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "model_params", ")", "\n", "model_state", "=", "torch", ".", "load", "(", "weights_file", ",", "map_location", "=", "device_mapping", "(", "-", "1", ")", ")", "\n", "if", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model_state", "=", "{", "re", ".", "sub", "(", "r'^module\\.'", ",", "''", ",", "k", ")", ":", "v", "for", "k", ",", "v", "in", "model_state", ".", "items", "(", ")", "}", "\n", "", "model", ".", "load_state_dict", "(", "model_state", ")", "\n", "model", ".", "set_vocab", "(", "vocab", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load": [[267, 281], ["getattr()._load", "getattr"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph._load"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "\n", "config", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "weights_file", ":", "str", "=", "None", ",", "\n", "device", "=", "None", ")", "->", "'Model'", ":", "\n", "        ", "\"\"\"\n        Instantiates an already-trained model, based on the experiment\n        configuration and some optional overrides.\n        \"\"\"", "\n", "model_type", "=", "config", "[", "'model'", "]", "[", "'model_type'", "]", "\n", "\n", "return", "getattr", "(", "Models", ",", "model_type", ")", ".", "_load", "(", "\n", "config", ",", "serialization_dir", ",", "weights_file", ",", "device", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.__init__": [[18, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ",", "\n", "n_source_copies", "=", "0", ",", "n_correct_source_copies", "=", "0", ",", "n_correct_source_points", "=", "0", ",", "\n", "n_target_copies", "=", "0", ",", "n_correct_target_copies", "=", "0", ",", "n_correct_target_points", "=", "0", "\n", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "\n", "self", ".", "n_source_copies", "=", "n_source_copies", "\n", "self", ".", "n_correct_source_copies", "=", "n_correct_source_copies", "\n", "self", ".", "n_correct_source_points", "=", "n_correct_source_points", "\n", "\n", "self", ".", "n_target_copies", "=", "n_target_copies", "\n", "self", ".", "n_correct_target_copies", "=", "n_correct_target_copies", "\n", "self", ".", "n_correct_target_points", "=", "n_correct_target_points", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.__call__": [[34, 50], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "loss", ",", "n_words", ",", "n_correct", ",", "\n", "n_source_copies", "=", "0", ",", "n_correct_source_copies", "=", "0", ",", "n_correct_source_points", "=", "0", ",", "\n", "n_target_copies", "=", "0", ",", "n_correct_target_copies", "=", "0", ",", "n_correct_target_points", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n        \"\"\"", "\n", "self", ".", "loss", "+=", "loss", "\n", "self", ".", "n_words", "+=", "n_words", "\n", "self", ".", "n_correct", "+=", "n_correct", "\n", "self", ".", "n_source_copies", "+=", "n_source_copies", "\n", "self", ".", "n_correct_source_copies", "+=", "n_correct_source_copies", "\n", "self", ".", "n_correct_source_points", "+=", "n_correct_source_points", "\n", "self", ".", "n_target_copies", "+=", "n_target_copies", "\n", "self", ".", "n_correct_target_copies", "+=", "n_correct_target_copies", "\n", "self", ".", "n_correct_target_points", "+=", "n_correct_target_points", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.accuracy": [[51, 54], ["None"], "methods", ["None"], ["", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute accuracy \"\"\"", "\n", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.xent": [[55, 58], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "return", "self", ".", "loss", "/", "self", ".", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.ppl": [[59, 62], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.copy_accuracy": [[63, 68], ["None"], "methods", ["None"], ["", "def", "copy_accuracy", "(", "self", ",", "n_correct", ",", "n_copies", ")", ":", "\n", "        ", "if", "n_copies", "==", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "else", ":", "\n", "            ", "return", "100", "*", "(", "n_correct", "/", "n_copies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.get_metric": [[69, 81], ["dict", "seq2seq_metrics.Seq2SeqMetrics.reset", "seq2seq_metrics.Seq2SeqMetrics.accuracy", "seq2seq_metrics.Seq2SeqMetrics.copy_accuracy", "seq2seq_metrics.Seq2SeqMetrics.copy_accuracy", "seq2seq_metrics.Seq2SeqMetrics.ppl"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.reset", "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.accuracy", "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.copy_accuracy", "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.copy_accuracy", "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.ppl"], ["", "", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", ":", "\n", "        ", "metrics", "=", "dict", "(", "\n", "all_acc", "=", "self", ".", "accuracy", "(", ")", ",", "\n", "src_acc", "=", "self", ".", "copy_accuracy", "(", "self", ".", "n_correct_source_copies", ",", "self", ".", "n_source_copies", ")", ",", "\n", "tgt_acc", "=", "self", ".", "copy_accuracy", "(", "self", ".", "n_correct_target_copies", ",", "self", ".", "n_target_copies", ")", ",", "\n", "# bina_acc=self.binary_accuracy(),", "\n", "# xent=self.xent(),", "\n", "ppl", "=", "self", ".", "ppl", "(", ")", "\n", ")", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.seq2seq_metrics.Seq2SeqMetrics.reset": [[82, 93], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss", "=", "0", "\n", "self", ".", "n_words", "=", "0", "\n", "self", ".", "n_correct", "=", "0", "\n", "self", ".", "n_target_copies", "=", "0", "\n", "self", ".", "n_correct_target_copies", "=", "0", "\n", "self", ".", "n_correct_target_points", "=", "0", "\n", "self", ".", "n_source_copies", "=", "0", "\n", "self", ".", "n_correct_source_copies", "=", "0", "\n", "self", ".", "n_correct_source_points", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.attachment_score.AttachmentScores.__init__": [[21, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ignore_classes", ":", "List", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_labeled_correct", "=", "0.", "\n", "self", ".", "_unlabeled_correct", "=", "0.", "\n", "self", ".", "_exact_labeled_correct", "=", "0.", "\n", "self", ".", "_exact_unlabeled_correct", "=", "0.", "\n", "self", ".", "_total_words", "=", "0.", "\n", "self", ".", "_total_sentences", "=", "0.", "\n", "\n", "self", ".", "_total_loss", "=", "0.", "\n", "self", ".", "_total_edge_node_loss", "=", "0.", "\n", "self", ".", "_total_edge_label_loss", "=", "0.", "\n", "\n", "self", ".", "_ignore_classes", ":", "List", "[", "int", "]", "=", "ignore_classes", "or", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.attachment_score.AttachmentScores.__call__": [[35, 89], ["attachment_score.AttachmentScores.unwrap_to_tensors", "mask.long.long.long", "predicted_indices.long.long.long", "predicted_labels.long.long.long", "gold_indices.long.long.long", "gold_labels.long.long.long", "correct_indices.sum", "unlabeled_exact_match.sum", "correct_labels_and_indices.sum", "labeled_exact_match.sum", "correct_indices.size", "gold_labels.long.long.eq", "predicted_indices.long.long.eq().long", "predicted_labels.long.long.eq().long", "correct_indices.numel", "predicted_indices.long.long.eq", "predicted_labels.long.long.eq"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.unwrap_to_tensors", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "__call__", "(", "self", ",", "# type: ignore", "\n", "predicted_indices", ":", "torch", ".", "Tensor", ",", "\n", "predicted_labels", ":", "torch", ".", "Tensor", ",", "\n", "gold_indices", ":", "torch", ".", "Tensor", ",", "\n", "gold_labels", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "edge_node_loss", "=", "0", ",", "\n", "edge_label_loss", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        predicted_indices : ``torch.Tensor``, required.\n            A tensor of head index predictions of shape (batch_size, timesteps).\n        predicted_labels : ``torch.Tensor``, required.\n            A tensor of arc label predictions of shape (batch_size, timesteps).\n        gold_indices : ``torch.Tensor``, required.\n            A tensor of the same shape as ``predicted_indices``.\n        gold_labels : ``torch.Tensor``, required.\n            A tensor of the same shape as ``predicted_labels``.\n        mask: ``torch.Tensor``, optional (default = None).\n            A tensor of the same shape as ``predicted_indices``.\n        \"\"\"", "\n", "unwrapped", "=", "self", ".", "unwrap_to_tensors", "(", "predicted_indices", ",", "predicted_labels", ",", "\n", "gold_indices", ",", "gold_labels", ",", "mask", ")", "\n", "predicted_indices", ",", "predicted_labels", ",", "gold_indices", ",", "gold_labels", ",", "mask", "=", "unwrapped", "\n", "\n", "mask", "=", "mask", ".", "long", "(", ")", "\n", "predicted_indices", "=", "predicted_indices", ".", "long", "(", ")", "\n", "predicted_labels", "=", "predicted_labels", ".", "long", "(", ")", "\n", "gold_indices", "=", "gold_indices", ".", "long", "(", ")", "\n", "gold_labels", "=", "gold_labels", ".", "long", "(", ")", "\n", "\n", "# Multiply by a mask donoting locations of", "\n", "# gold labels which we should ignore.", "\n", "for", "label", "in", "self", ".", "_ignore_classes", ":", "\n", "            ", "label_mask", "=", "gold_labels", ".", "eq", "(", "label", ")", "\n", "mask", "=", "mask", "*", "(", "1", "-", "label_mask", ")", ".", "long", "(", ")", "\n", "\n", "", "correct_indices", "=", "predicted_indices", ".", "eq", "(", "gold_indices", ")", ".", "long", "(", ")", "*", "mask", "\n", "unlabeled_exact_match", "=", "(", "correct_indices", "+", "(", "1", "-", "mask", ")", ")", ".", "prod", "(", "dim", "=", "-", "1", ")", "\n", "correct_labels", "=", "predicted_labels", ".", "eq", "(", "gold_labels", ")", ".", "long", "(", ")", "*", "mask", "\n", "correct_labels_and_indices", "=", "correct_indices", "*", "correct_labels", "\n", "labeled_exact_match", "=", "(", "correct_labels_and_indices", "+", "(", "1", "-", "mask", ")", ")", ".", "prod", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "_unlabeled_correct", "+=", "correct_indices", ".", "sum", "(", ")", "\n", "self", ".", "_exact_unlabeled_correct", "+=", "unlabeled_exact_match", ".", "sum", "(", ")", "\n", "self", ".", "_labeled_correct", "+=", "correct_labels_and_indices", ".", "sum", "(", ")", "\n", "self", ".", "_exact_labeled_correct", "+=", "labeled_exact_match", ".", "sum", "(", ")", "\n", "self", ".", "_total_sentences", "+=", "correct_indices", ".", "size", "(", "0", ")", "\n", "self", ".", "_total_words", "+=", "correct_indices", ".", "numel", "(", ")", "-", "(", "1", "-", "mask", ")", ".", "sum", "(", ")", "\n", "\n", "self", ".", "_total_loss", "+=", "edge_node_loss", "+", "edge_label_loss", "\n", "self", ".", "_total_edge_node_loss", "+=", "edge_node_loss", "\n", "self", ".", "_total_edge_label_loss", "+=", "edge_label_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.attachment_score.AttachmentScores.get_metric": [[90, 120], ["attachment_score.AttachmentScores.reset", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.reset"], ["", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n        The accumulated metrics as a dictionary.\n        \"\"\"", "\n", "unlabeled_attachment_score", "=", "0.0", "\n", "labeled_attachment_score", "=", "0.0", "\n", "unlabeled_exact_match", "=", "0.0", "\n", "labeled_exact_match", "=", "0.0", "\n", "edge_loss", "=", "0.0", "\n", "edge_node_loss", "=", "0.0", "\n", "edge_label_loss", "=", "0.0", "\n", "if", "self", ".", "_total_words", ">", "0.0", ":", "\n", "            ", "unlabeled_attachment_score", "=", "float", "(", "self", ".", "_unlabeled_correct", ")", "/", "float", "(", "self", ".", "_total_words", ")", "\n", "labeled_attachment_score", "=", "float", "(", "self", ".", "_labeled_correct", ")", "/", "float", "(", "self", ".", "_total_words", ")", "\n", "edge_loss", "=", "float", "(", "self", ".", "_total_loss", ")", "/", "float", "(", "self", ".", "_total_words", ")", "\n", "edge_node_loss", "=", "float", "(", "self", ".", "_total_edge_node_loss", ")", "/", "float", "(", "self", ".", "_total_words", ")", "\n", "edge_label_loss", "=", "float", "(", "self", ".", "_total_edge_label_loss", ")", "/", "float", "(", "self", ".", "_total_words", ")", "\n", "", "if", "self", ".", "_total_sentences", ">", "0", ":", "\n", "            ", "unlabeled_exact_match", "=", "float", "(", "self", ".", "_exact_unlabeled_correct", ")", "/", "float", "(", "self", ".", "_total_sentences", ")", "\n", "labeled_exact_match", "=", "float", "(", "self", ".", "_exact_labeled_correct", ")", "/", "float", "(", "self", ".", "_total_sentences", ")", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "{", "\n", "\"UAS\"", ":", "unlabeled_attachment_score", ",", "\n", "\"LAS\"", ":", "labeled_attachment_score", ",", "\n", "# \"UEM\": unlabeled_exact_match,", "\n", "# \"LEM\": labeled_exact_match,", "\n", "\"EL\"", ":", "edge_loss", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.attachment_score.AttachmentScores.reset": [[122, 134], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_labeled_correct", "=", "0.", "\n", "self", ".", "_unlabeled_correct", "=", "0.", "\n", "self", ".", "_exact_labeled_correct", "=", "0.", "\n", "self", ".", "_exact_unlabeled_correct", "=", "0.", "\n", "self", ".", "_total_words", "=", "0.", "\n", "self", ".", "_total_sentences", "=", "0.", "\n", "\n", "self", ".", "_total_loss", "=", "0.", "\n", "self", ".", "_total_edge_node_loss", "=", "0.", "\n", "self", ".", "_total_edge_label_loss", "=", "0.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.__call__": [[11, 27], ["None"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "\n", "predictions", ":", "torch", ".", "Tensor", ",", "\n", "gold_labels", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        predictions : ``torch.Tensor``, required.\n            A tensor of predictions.\n        gold_labels : ``torch.Tensor``, required.\n            A tensor corresponding to some gold label to evaluate against.\n        mask: ``torch.Tensor``, optional (default = None).\n            A mask can be passed, in order to deal with metrics which are\n            computed over potentially padded elements, such as sequence labels.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.get_metric": [[28, 33], ["None"], "methods", ["None"], ["", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", ")", "->", "Union", "[", "float", ",", "Tuple", "[", "float", ",", "...", "]", ",", "Dict", "[", "str", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Compute and return the metric. Optionally also call :func:`self.reset`.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.reset": [[34, 39], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reset any accumulators or internal state.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.metric.Metric.unwrap_to_tensors": [[40, 49], ["isinstance", "x.detach().cpu", "x.detach"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "unwrap_to_tensors", "(", "*", "tensors", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        If you actually passed gradient-tracking Tensors to a Metric, there will be\n        a huge memory leak, because it will prevent garbage collection for the computation\n        graph. This method ensures that you're using tensors directly and that they are on\n        the CPU.\n        \"\"\"", "\n", "return", "(", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "else", "x", "for", "x", "in", "tensors", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.metrics.__init__.dump_metrics": [[11, 17], ["json.dumps", "open", "metrics_file.write", "logger.info"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], []], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._NamespaceDependentDefaultDict.__init__": [[62, 70], ["set", "collections.defaultdict.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "non_padded_namespaces", ":", "Iterable", "[", "str", "]", ",", "\n", "padded_function", ":", "Callable", "[", "[", "]", ",", "Any", "]", ",", "\n", "non_padded_function", ":", "Callable", "[", "[", "]", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "_non_padded_namespaces", "=", "set", "(", "non_padded_namespaces", ")", "\n", "self", ".", "_padded_function", "=", "padded_function", "\n", "self", ".", "_non_padded_function", "=", "non_padded_function", "\n", "super", "(", "_NamespaceDependentDefaultDict", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._NamespaceDependentDefaultDict.__missing__": [[71, 78], ["any", "dict.__setitem__", "vocabulary._NamespaceDependentDefaultDict._non_padded_function", "vocabulary._NamespaceDependentDefaultDict._padded_function", "stog.utils.string.namespace_match"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.__setitem__", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.namespace_match"], ["", "def", "__missing__", "(", "self", ",", "key", ":", "str", ")", ":", "\n", "        ", "if", "any", "(", "namespace_match", "(", "pattern", ",", "key", ")", "for", "pattern", "in", "self", ".", "_non_padded_namespaces", ")", ":", "\n", "            ", "value", "=", "self", ".", "_non_padded_function", "(", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "self", ".", "_padded_function", "(", ")", "\n", "", "dict", ".", "__setitem__", "(", "self", ",", "key", ",", "value", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._NamespaceDependentDefaultDict.add_non_padded_namespaces": [[79, 82], ["vocabulary._NamespaceDependentDefaultDict._non_padded_namespaces.update"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update"], ["", "def", "add_non_padded_namespaces", "(", "self", ",", "non_padded_namespaces", ":", "Set", "[", "str", "]", ")", ":", "\n", "# add non_padded_namespaces which weren't already present", "\n", "        ", "self", ".", "_non_padded_namespaces", ".", "update", "(", "non_padded_namespaces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._TokenToIndexDefaultDict.__init__": [[84, 88], ["vocabulary._NamespaceDependentDefaultDict.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "non_padded_namespaces", ":", "Set", "[", "str", "]", ",", "padding_token", ":", "str", ",", "oov_token", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", "_TokenToIndexDefaultDict", ",", "self", ")", ".", "__init__", "(", "non_padded_namespaces", ",", "\n", "lambda", ":", "{", "padding_token", ":", "0", ",", "oov_token", ":", "1", "}", ",", "\n", "lambda", ":", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._IndexToTokenDefaultDict.__init__": [[91, 95], ["vocabulary._NamespaceDependentDefaultDict.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "non_padded_namespaces", ":", "Set", "[", "str", "]", ",", "padding_token", ":", "str", ",", "oov_token", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", "_IndexToTokenDefaultDict", ",", "self", ")", ".", "__init__", "(", "non_padded_namespaces", ",", "\n", "lambda", ":", "{", "0", ":", "padding_token", ",", "1", ":", "oov_token", "}", ",", "\n", "lambda", ":", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.__init__": [[208, 236], ["set", "vocabulary._TokenToIndexDefaultDict", "vocabulary._IndexToTokenDefaultDict", "vocabulary.Vocabulary._extend"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary._extend"], ["def", "__init__", "(", "self", ",", "\n", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "min_count", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "max_vocab_size", ":", "Union", "[", "int", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "non_padded_namespaces", ":", "Iterable", "[", "str", "]", "=", "DEFAULT_NON_PADDED_NAMESPACES", ",", "\n", "pretrained_files", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "only_include_pretrained_words", ":", "bool", "=", "False", ",", "\n", "tokens_to_add", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "min_pretrained_embeddings", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_padding_token", "=", "DEFAULT_PADDING_TOKEN", "\n", "self", ".", "_oov_token", "=", "DEFAULT_OOV_TOKEN", "\n", "self", ".", "_non_padded_namespaces", "=", "set", "(", "non_padded_namespaces", ")", "\n", "self", ".", "_token_to_index", "=", "_TokenToIndexDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_index_to_token", "=", "_IndexToTokenDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_retained_counter", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "]", "=", "None", "\n", "# Made an empty vocabulary, now extend it.", "\n", "self", ".", "_extend", "(", "counter", ",", "\n", "min_count", ",", "\n", "max_vocab_size", ",", "\n", "non_padded_namespaces", ",", "\n", "pretrained_files", ",", "\n", "only_include_pretrained_words", ",", "\n", "tokens_to_add", ",", "\n", "min_pretrained_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.save_to_files": [[237, 262], ["os.makedirs", "os.listdir", "vocabulary.Vocabulary._index_to_token.items", "logging.warning", "codecs.open", "os.path.join", "print", "codecs.open", "len", "range", "os.path.join", "print", "mapping[].replace"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "save_to_files", "(", "self", ",", "directory", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Persist this Vocabulary to files so it can be reloaded later.\n        Each namespace corresponds to one file.\n\n        Parameters\n        ----------\n        directory : ``str``\n            The directory where we save the serialized vocabulary.\n        \"\"\"", "\n", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "if", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "            ", "logging", ".", "warning", "(", "\"vocabulary serialization directory %s is not empty\"", ",", "directory", ")", "\n", "\n", "", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "NAMESPACE_PADDING_FILE", ")", ",", "'w'", ",", "'utf-8'", ")", "as", "namespace_file", ":", "\n", "            ", "for", "namespace_str", "in", "self", ".", "_non_padded_namespaces", ":", "\n", "                ", "print", "(", "namespace_str", ",", "file", "=", "namespace_file", ")", "\n", "\n", "", "", "for", "namespace", ",", "mapping", "in", "self", ".", "_index_to_token", ".", "items", "(", ")", ":", "\n", "# Each namespace gets written to its own file, in index order.", "\n", "            ", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "namespace", "+", "'.txt'", ")", ",", "'w'", ",", "'utf-8'", ")", "as", "token_file", ":", "\n", "                ", "num_tokens", "=", "len", "(", "mapping", ")", "\n", "start_index", "=", "1", "if", "mapping", "[", "0", "]", "==", "self", ".", "_padding_token", "else", "0", "\n", "for", "i", "in", "range", "(", "start_index", ",", "num_tokens", ")", ":", "\n", "                    ", "print", "(", "mapping", "[", "i", "]", ".", "replace", "(", "'\\n'", ",", "'@@NEWLINE@@'", ")", ",", "file", "=", "token_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_files": [[263, 292], ["logger.info", "cls", "os.listdir", "codecs.open", "namespace_filename.replace", "any", "os.path.join", "cls.set_from_file", "os.path.join", "namespace_str.strip", "stog.utils.string.namespace_match"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.set_from_file", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.namespace_match"], ["", "", "", "", "@", "classmethod", "\n", "def", "from_files", "(", "cls", ",", "directory", ":", "str", ")", "->", "'Vocabulary'", ":", "\n", "        ", "\"\"\"\n        Loads a ``Vocabulary`` that was serialized using ``save_to_files``.\n\n        Parameters\n        ----------\n        directory : ``str``\n            The directory containing the serialized vocabulary.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Loading token dictionary from %s.\"", ",", "directory", ")", "\n", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "NAMESPACE_PADDING_FILE", ")", ",", "'r'", ",", "'utf-8'", ")", "as", "namespace_file", ":", "\n", "            ", "non_padded_namespaces", "=", "[", "namespace_str", ".", "strip", "(", ")", "for", "namespace_str", "in", "namespace_file", "]", "\n", "\n", "", "vocab", "=", "cls", "(", "non_padded_namespaces", "=", "non_padded_namespaces", ")", "\n", "\n", "# Check every file in the directory.", "\n", "for", "namespace_filename", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "            ", "if", "namespace_filename", "==", "NAMESPACE_PADDING_FILE", ":", "\n", "                ", "continue", "\n", "", "namespace", "=", "namespace_filename", ".", "replace", "(", "'.txt'", ",", "''", ")", "\n", "if", "any", "(", "namespace_match", "(", "pattern", ",", "namespace", ")", "for", "pattern", "in", "non_padded_namespaces", ")", ":", "\n", "                ", "is_padded", "=", "False", "\n", "", "else", ":", "\n", "                ", "is_padded", "=", "True", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "namespace_filename", ")", "\n", "vocab", ".", "set_from_file", "(", "filename", ",", "is_padded", ",", "namespace", "=", "namespace", ")", "\n", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.set_from_file": [[293, 344], ["codecs.open", "input_file.read().split", "enumerate", "line.replace", "input_file.read"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["", "def", "set_from_file", "(", "self", ",", "\n", "filename", ":", "str", ",", "\n", "is_padded", ":", "bool", "=", "True", ",", "\n", "oov_token", ":", "str", "=", "DEFAULT_OOV_TOKEN", ",", "\n", "namespace", ":", "str", "=", "\"tokens\"", ")", ":", "\n", "        ", "\"\"\"\n        If you already have a vocabulary file for a trained model somewhere, and you really want to\n        use that vocabulary file instead of just setting the vocabulary from a dataset, for\n        whatever reason, you can do that with this method.  You must specify the namespace to use,\n        and we assume that you want to use padding and OOV tokens for this.\n\n        Parameters\n        ----------\n        filename : ``str``\n            The file containing the vocabulary to load.  It should be formatted as one token per\n            line, with nothing else in the line.  The index we assign to the token is the line\n            number in the file (1-indexed if ``is_padded``, 0-indexed otherwise).  Note that this\n            file should contain the OOV token string!\n        is_padded : ``bool``, optional (default=True)\n            Is this vocabulary padded?  For token / word / character vocabularies, this should be\n            ``True``; while for tag or label vocabularies, this should typically be ``False``.  If\n            ``True``, we add a padding token with index 0, and we enforce that the ``oov_token`` is\n            present in the file.\n        oov_token : ``str``, optional (default=DEFAULT_OOV_TOKEN)\n            What token does this vocabulary use to represent out-of-vocabulary characters?  This\n            must show up as a line in the vocabulary file.  When we find it, we replace\n            ``oov_token`` with ``self._oov_token``, because we only use one OOV token across\n            namespaces.\n        namespace : ``str``, optional (default=\"tokens\")\n            What namespace should we overwrite with this vocab file?\n        \"\"\"", "\n", "if", "is_padded", ":", "\n", "            ", "self", ".", "_token_to_index", "[", "namespace", "]", "=", "{", "self", ".", "_padding_token", ":", "0", "}", "\n", "self", ".", "_index_to_token", "[", "namespace", "]", "=", "{", "0", ":", "self", ".", "_padding_token", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "_token_to_index", "[", "namespace", "]", "=", "{", "}", "\n", "self", ".", "_index_to_token", "[", "namespace", "]", "=", "{", "}", "\n", "", "with", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "'utf-8'", ")", "as", "input_file", ":", "\n", "            ", "lines", "=", "input_file", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "# Be flexible about having final newline or not", "\n", "if", "lines", "and", "lines", "[", "-", "1", "]", "==", "''", ":", "\n", "                ", "lines", "=", "lines", "[", ":", "-", "1", "]", "\n", "", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "index", "=", "i", "+", "1", "if", "is_padded", "else", "i", "\n", "token", "=", "line", ".", "replace", "(", "'@@NEWLINE@@'", ",", "'\\n'", ")", "\n", "if", "token", "==", "oov_token", ":", "\n", "                    ", "token", "=", "self", ".", "_oov_token", "\n", "", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "token", "]", "=", "index", "\n", "self", ".", "_index_to_token", "[", "namespace", "]", "[", "index", "]", "=", "token", "\n", "", "", "if", "is_padded", ":", "\n", "            ", "assert", "self", ".", "_oov_token", "in", "self", ".", "_token_to_index", "[", "namespace", "]", ",", "\"OOV token not found!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_instances": [[345, 374], ["logger.info", "collections.defaultdict", "stog.utils.tqdm.Tqdm.tqdm", "cls", "stog.data.instance.count_vocab_items", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "", "@", "classmethod", "\n", "def", "from_instances", "(", "cls", ",", "\n", "instances", ":", "Iterable", "[", "'adi.Instance'", "]", ",", "\n", "min_count", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "max_vocab_size", ":", "Union", "[", "int", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "non_padded_namespaces", ":", "Iterable", "[", "str", "]", "=", "DEFAULT_NON_PADDED_NAMESPACES", ",", "\n", "pretrained_files", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "only_include_pretrained_words", ":", "bool", "=", "False", ",", "\n", "tokens_to_add", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "min_pretrained_embeddings", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ")", "->", "'Vocabulary'", ":", "\n", "        ", "\"\"\"\n        Constructs a vocabulary given a collection of `Instances` and some parameters.\n        We count all of the vocabulary items in the instances, then pass those counts\n        and the other parameters, to :func:`__init__`.  See that method for a description\n        of what the other parameters do.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Fitting token dictionary from dataset.\"", ")", "\n", "namespace_token_counts", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "for", "instance", "in", "Tqdm", ".", "tqdm", "(", "instances", ")", ":", "\n", "            ", "instance", ".", "count_vocab_items", "(", "namespace_token_counts", ")", "\n", "\n", "", "return", "cls", "(", "counter", "=", "namespace_token_counts", ",", "\n", "min_count", "=", "min_count", ",", "\n", "max_vocab_size", "=", "max_vocab_size", ",", "\n", "non_padded_namespaces", "=", "non_padded_namespaces", ",", "\n", "pretrained_files", "=", "pretrained_files", ",", "\n", "only_include_pretrained_words", "=", "only_include_pretrained_words", ",", "\n", "tokens_to_add", "=", "tokens_to_add", ",", "\n", "min_pretrained_embeddings", "=", "min_pretrained_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params": [[376, 453], ["params.pop", "params.pop", "params.pop", "params.pop", "vocabulary.pop_max_vocab_size", "params.pop", "params.pop", "params.pop", "params.pop_bool", "params.pop", "params.assert_empty", "vocabulary.Vocabulary.from_instances", "cls.by_name().from_params", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError", "vocabulary.Vocabulary.from_files", "vocabulary.Vocabulary.from_files", "logger.info", "logger.info", "params.assert_empty", "cls.by_name"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.pop_max_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_instances", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_files", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_files", "home.repos.pwc.inspect_result.jcyk_gtos.utils.registrable.Registrable.by_name"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "params", ":", "Params", ",", "instances", ":", "Iterable", "[", "'adi.Instance'", "]", "=", "None", ")", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        There are two possible ways to build a vocabulary; from a\n        collection of instances, using :func:`Vocabulary.from_instances`, or\n        from a pre-saved vocabulary, using :func:`Vocabulary.from_files`.\n        You can also extend pre-saved vocabulary with collection of instances\n        using this method. This method wraps these options, allowing their\n        specification from a ``Params`` object, generated from a JSON\n        configuration file.\n\n        Parameters\n        ----------\n        params: Params, required.\n        instances: Iterable['adi.Instance'], optional\n            If ``params`` doesn't contain a ``directory_path`` key,\n            the ``Vocabulary`` can be built directly from a collection of\n            instances (i.e. a dataset). If ``extend`` key is set False,\n            dataset instances will be ignored and final vocabulary will be\n            one loaded from ``directory_path``. If ``extend`` key is set True,\n            dataset instances will be used to extend the vocabulary loaded\n            from ``directory_path`` and that will be final vocabulary used.\n\n        Returns\n        -------\n        A ``Vocabulary``.\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "# Vocabulary is ``Registrable`` so that you can configure a custom subclass,", "\n", "# but (unlike most of our registrables) almost everyone will want to use the", "\n", "# base implementation. So instead of having an abstract ``VocabularyBase`` or", "\n", "# such, we just add the logic for instantiating a registered subclass here,", "\n", "# so that most users can continue doing what they were doing.", "\n", "vocab_type", "=", "params", ".", "pop", "(", "\"type\"", ",", "None", ")", "\n", "if", "vocab_type", "is", "not", "None", ":", "\n", "            ", "return", "cls", ".", "by_name", "(", "vocab_type", ")", ".", "from_params", "(", "params", "=", "params", ",", "instances", "=", "instances", ")", "\n", "\n", "", "extend", "=", "params", ".", "pop", "(", "\"extend\"", ",", "False", ")", "\n", "vocabulary_directory", "=", "params", ".", "pop", "(", "\"directory_path\"", ",", "None", ")", "\n", "if", "not", "vocabulary_directory", "and", "not", "instances", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"You must provide either a Params object containing a \"", "\n", "\"vocab_directory key or a Dataset to build a vocabulary from.\"", ")", "\n", "", "if", "extend", "and", "not", "instances", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"'extend' is true but there are not instances passed to extend.\"", ")", "\n", "", "if", "extend", "and", "not", "vocabulary_directory", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"'extend' is true but there is not 'directory_path' to extend from.\"", ")", "\n", "\n", "", "if", "vocabulary_directory", "and", "instances", ":", "\n", "            ", "if", "extend", ":", "\n", "                ", "logger", ".", "info", "(", "\"Loading Vocab from files and extending it with dataset.\"", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"Loading Vocab from files instead of dataset.\"", ")", "\n", "\n", "", "", "if", "vocabulary_directory", ":", "\n", "            ", "vocab", "=", "Vocabulary", ".", "from_files", "(", "vocabulary_directory", ")", "\n", "if", "not", "extend", ":", "\n", "                ", "params", ".", "assert_empty", "(", "\"Vocabulary - from files\"", ")", "\n", "return", "vocab", "\n", "", "", "if", "extend", ":", "\n", "            ", "vocab", ".", "extend_from_instances", "(", "params", ",", "instances", "=", "instances", ")", "\n", "return", "vocab", "\n", "", "min_count", "=", "params", ".", "pop", "(", "\"min_count\"", ",", "None", ")", "\n", "max_vocab_size", "=", "pop_max_vocab_size", "(", "params", ")", "\n", "non_padded_namespaces", "=", "params", ".", "pop", "(", "\"non_padded_namespaces\"", ",", "DEFAULT_NON_PADDED_NAMESPACES", ")", "\n", "pretrained_files", "=", "params", ".", "pop", "(", "\"pretrained_files\"", ",", "{", "}", ")", "\n", "min_pretrained_embeddings", "=", "params", ".", "pop", "(", "\"min_pretrained_embeddings\"", ",", "None", ")", "\n", "only_include_pretrained_words", "=", "params", ".", "pop_bool", "(", "\"only_include_pretrained_words\"", ",", "False", ")", "\n", "tokens_to_add", "=", "params", ".", "pop", "(", "\"tokens_to_add\"", ",", "None", ")", "\n", "params", ".", "assert_empty", "(", "\"Vocabulary - from dataset\"", ")", "\n", "return", "Vocabulary", ".", "from_instances", "(", "instances", "=", "instances", ",", "\n", "min_count", "=", "min_count", ",", "\n", "max_vocab_size", "=", "max_vocab_size", ",", "\n", "non_padded_namespaces", "=", "non_padded_namespaces", ",", "\n", "pretrained_files", "=", "pretrained_files", ",", "\n", "only_include_pretrained_words", "=", "only_include_pretrained_words", ",", "\n", "tokens_to_add", "=", "tokens_to_add", ",", "\n", "min_pretrained_embeddings", "=", "min_pretrained_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary._extend": [[454, 533], ["set", "vocabulary.Vocabulary._token_to_index.add_non_padded_namespaces", "vocabulary.Vocabulary._index_to_token.add_non_padded_namespaces", "vocabulary.Vocabulary._non_padded_namespaces.update", "tokens_to_add.items", "isinstance", "collections.defaultdict", "list", "list.sort", "any", "any", "stog.utils.checks.ConfigurationError", "vocabulary._read_pretrained_tokens", "min_pretrained_embeddings.get", "set", "counter[].items", "vocabulary.Vocabulary.add_token_to_namespace", "tokens_to_add.get", "stog.utils.string.namespace_match", "stog.utils.string.namespace_match", "min_count.get", "vocabulary.Vocabulary.add_token_to_namespace", "vocabulary.Vocabulary.add_token_to_namespace", "vocabulary.Vocabulary.add_token_to_namespace", "min_count.get", "min_count.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._NamespaceDependentDefaultDict.add_non_padded_namespaces", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._NamespaceDependentDefaultDict.add_non_padded_namespaces", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._read_pretrained_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.add_token_to_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.namespace_match", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.namespace_match", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.add_token_to_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.add_token_to_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.add_token_to_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "_extend", "(", "self", ",", "\n", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "min_count", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "max_vocab_size", ":", "Union", "[", "int", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "non_padded_namespaces", ":", "Iterable", "[", "str", "]", "=", "DEFAULT_NON_PADDED_NAMESPACES", ",", "\n", "pretrained_files", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "only_include_pretrained_words", ":", "bool", "=", "False", ",", "\n", "tokens_to_add", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "min_pretrained_embeddings", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        This method can be used for extending already generated vocabulary.\n        It takes same parameters as Vocabulary initializer. The token2index\n        and indextotoken mappings of calling vocabulary will be retained.\n        It is an inplace operation so None will be returned.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "max_vocab_size", ",", "dict", ")", ":", "\n", "            ", "int_max_vocab_size", "=", "max_vocab_size", "\n", "max_vocab_size", "=", "defaultdict", "(", "lambda", ":", "int_max_vocab_size", ")", "# type: ignore", "\n", "", "min_count", "=", "min_count", "or", "{", "}", "\n", "pretrained_files", "=", "pretrained_files", "or", "{", "}", "\n", "min_pretrained_embeddings", "=", "min_pretrained_embeddings", "or", "{", "}", "\n", "non_padded_namespaces", "=", "set", "(", "non_padded_namespaces", ")", "\n", "counter", "=", "counter", "or", "{", "}", "\n", "tokens_to_add", "=", "tokens_to_add", "or", "{", "}", "\n", "\n", "self", ".", "_retained_counter", "=", "counter", "\n", "# Make sure vocabulary extension is safe.", "\n", "current_namespaces", "=", "{", "*", "self", ".", "_token_to_index", "}", "\n", "extension_namespaces", "=", "{", "*", "counter", ",", "*", "tokens_to_add", "}", "\n", "\n", "for", "namespace", "in", "current_namespaces", "&", "extension_namespaces", ":", "\n", "# if new namespace was already present", "\n", "# Either both should be padded or none should be.", "\n", "            ", "original_padded", "=", "not", "any", "(", "namespace_match", "(", "pattern", ",", "namespace", ")", "\n", "for", "pattern", "in", "self", ".", "_non_padded_namespaces", ")", "\n", "extension_padded", "=", "not", "any", "(", "namespace_match", "(", "pattern", ",", "namespace", ")", "\n", "for", "pattern", "in", "non_padded_namespaces", ")", "\n", "if", "original_padded", "!=", "extension_padded", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Common namespace {} has conflicting \"", ".", "format", "(", "namespace", ")", "+", "\n", "\"setting of padded = True/False. \"", "+", "\n", "\"Hence extension cannot be done.\"", ")", "\n", "\n", "# Add new non-padded namespaces for extension", "\n", "", "", "self", ".", "_token_to_index", ".", "add_non_padded_namespaces", "(", "non_padded_namespaces", ")", "\n", "self", ".", "_index_to_token", ".", "add_non_padded_namespaces", "(", "non_padded_namespaces", ")", "\n", "self", ".", "_non_padded_namespaces", ".", "update", "(", "non_padded_namespaces", ")", "\n", "\n", "for", "namespace", "in", "counter", ":", "\n", "            ", "if", "namespace", "in", "pretrained_files", ":", "\n", "                ", "pretrained_list", "=", "_read_pretrained_tokens", "(", "pretrained_files", "[", "namespace", "]", ")", "\n", "min_embeddings", "=", "min_pretrained_embeddings", ".", "get", "(", "namespace", ",", "0", ")", "\n", "if", "min_embeddings", ">", "0", ":", "\n", "                    ", "tokens_old", "=", "tokens_to_add", ".", "get", "(", "namespace", ",", "[", "]", ")", "\n", "tokens_new", "=", "pretrained_list", "[", ":", "min_embeddings", "]", "\n", "tokens_to_add", "[", "namespace", "]", "=", "tokens_old", "+", "tokens_new", "\n", "", "pretrained_set", "=", "set", "(", "pretrained_list", ")", "\n", "", "else", ":", "\n", "                ", "pretrained_set", "=", "None", "\n", "", "token_counts", "=", "list", "(", "counter", "[", "namespace", "]", ".", "items", "(", ")", ")", "\n", "token_counts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "try", ":", "\n", "                ", "max_vocab", "=", "max_vocab_size", "[", "namespace", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "max_vocab", "=", "None", "\n", "", "if", "max_vocab", ":", "\n", "                ", "token_counts", "=", "token_counts", "[", ":", "max_vocab", "]", "\n", "", "for", "token", ",", "count", "in", "token_counts", ":", "\n", "                ", "if", "pretrained_set", "is", "not", "None", ":", "\n", "                    ", "if", "only_include_pretrained_words", ":", "\n", "                        ", "if", "token", "in", "pretrained_set", "and", "count", ">=", "min_count", ".", "get", "(", "namespace", ",", "1", ")", ":", "\n", "                            ", "self", ".", "add_token_to_namespace", "(", "token", ",", "namespace", ")", "\n", "", "", "elif", "token", "in", "pretrained_set", "or", "count", ">=", "min_count", ".", "get", "(", "namespace", ",", "1", ")", ":", "\n", "                        ", "self", ".", "add_token_to_namespace", "(", "token", ",", "namespace", ")", "\n", "", "", "elif", "count", ">=", "min_count", ".", "get", "(", "namespace", ",", "1", ")", ":", "\n", "                    ", "self", ".", "add_token_to_namespace", "(", "token", ",", "namespace", ")", "\n", "\n", "", "", "", "for", "namespace", ",", "tokens", "in", "tokens_to_add", ".", "items", "(", ")", ":", "\n", "            ", "for", "token", "in", "tokens", ":", "\n", "                ", "self", ".", "add_token_to_namespace", "(", "token", ",", "namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.extend_from_instances": [[534, 561], ["params.pop", "vocabulary.pop_max_vocab_size", "params.pop", "params.pop", "params.pop", "params.pop_bool", "params.pop", "params.assert_empty", "logger.info", "collections.defaultdict", "stog.utils.tqdm.Tqdm.tqdm", "vocabulary.Vocabulary._extend", "stog.data.instance.count_vocab_items", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.pop_max_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary._extend", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "", "", "def", "extend_from_instances", "(", "self", ",", "\n", "params", ":", "Params", ",", "\n", "instances", ":", "Iterable", "[", "'adi.Instance'", "]", "=", "(", ")", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Extends an already generated vocabulary using a collection of instances.\n        \"\"\"", "\n", "min_count", "=", "params", ".", "pop", "(", "\"min_count\"", ",", "None", ")", "\n", "max_vocab_size", "=", "pop_max_vocab_size", "(", "params", ")", "\n", "non_padded_namespaces", "=", "params", ".", "pop", "(", "\"non_padded_namespaces\"", ",", "DEFAULT_NON_PADDED_NAMESPACES", ")", "\n", "pretrained_files", "=", "params", ".", "pop", "(", "\"pretrained_files\"", ",", "{", "}", ")", "\n", "min_pretrained_embeddings", "=", "params", ".", "pop", "(", "\"min_pretrained_embeddings\"", ",", "None", ")", "\n", "only_include_pretrained_words", "=", "params", ".", "pop_bool", "(", "\"only_include_pretrained_words\"", ",", "False", ")", "\n", "tokens_to_add", "=", "params", ".", "pop", "(", "\"tokens_to_add\"", ",", "None", ")", "\n", "params", ".", "assert_empty", "(", "\"Vocabulary - from dataset\"", ")", "\n", "\n", "logger", ".", "info", "(", "\"Fitting token dictionary from dataset.\"", ")", "\n", "namespace_token_counts", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "for", "instance", "in", "Tqdm", ".", "tqdm", "(", "instances", ")", ":", "\n", "            ", "instance", ".", "count_vocab_items", "(", "namespace_token_counts", ")", "\n", "", "self", ".", "_extend", "(", "counter", "=", "namespace_token_counts", ",", "\n", "min_count", "=", "min_count", ",", "\n", "max_vocab_size", "=", "max_vocab_size", ",", "\n", "non_padded_namespaces", "=", "non_padded_namespaces", ",", "\n", "pretrained_files", "=", "pretrained_files", ",", "\n", "only_include_pretrained_words", "=", "only_include_pretrained_words", ",", "\n", "tokens_to_add", "=", "tokens_to_add", ",", "\n", "min_pretrained_embeddings", "=", "min_pretrained_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.is_padded": [[562, 567], ["None"], "methods", ["None"], ["", "def", "is_padded", "(", "self", ",", "namespace", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns whether or not there are padding and OOV tokens added to the given namepsace.\n        \"\"\"", "\n", "return", "self", ".", "_index_to_token", "[", "namespace", "]", "[", "0", "]", "==", "self", ".", "_padding_token", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.add_token_to_namespace": [[568, 583], ["isinstance", "ValueError", "len", "repr", "type"], "methods", ["None"], ["", "def", "add_token_to_namespace", "(", "self", ",", "token", ":", "str", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Adds ``token`` to the index, if it is not already present.  Either way, we return the index of\n        the token.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "token", ",", "str", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Vocabulary tokens must be strings, or saving and loading will break.\"", "\n", "\"  Got %s (with type %s)\"", "%", "(", "repr", "(", "token", ")", ",", "type", "(", "token", ")", ")", ")", "\n", "", "if", "token", "not", "in", "self", ".", "_token_to_index", "[", "namespace", "]", ":", "\n", "            ", "index", "=", "len", "(", "self", ".", "_token_to_index", "[", "namespace", "]", ")", "\n", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "token", "]", "=", "index", "\n", "self", ".", "_index_to_token", "[", "namespace", "]", "[", "index", "]", "=", "token", "\n", "return", "index", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_index_to_token_vocabulary": [[584, 586], ["None"], "methods", ["None"], ["", "", "def", "get_index_to_token_vocabulary", "(", "self", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "Dict", "[", "int", ",", "str", "]", ":", "\n", "        ", "return", "self", ".", "_index_to_token", "[", "namespace", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_to_index_vocabulary": [[587, 589], ["None"], "methods", ["None"], ["", "def", "get_token_to_index_vocabulary", "(", "self", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "self", ".", "_token_to_index", "[", "namespace", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index": [[590, 600], ["logger.error", "logger.error"], "methods", ["None"], ["", "def", "get_token_index", "(", "self", ",", "token", ":", "str", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "int", ":", "\n", "        ", "if", "token", "in", "self", ".", "_token_to_index", "[", "namespace", "]", ":", "\n", "            ", "return", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "token", "]", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "self", ".", "_oov_token", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "logger", ".", "error", "(", "'Namespace: %s'", ",", "namespace", ")", "\n", "logger", ".", "error", "(", "'Token: %s'", ",", "token", ")", "\n", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index": [[601, 603], ["None"], "methods", ["None"], ["", "", "", "def", "get_token_from_index", "(", "self", ",", "index", ":", "int", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "_index_to_token", "[", "namespace", "]", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_tokens_from_list": [[604, 606], ["vocabulary.Vocabulary.get_token_from_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_from_index"], ["", "def", "get_tokens_from_list", "(", "self", ",", "t", ",", "namespace", ")", ":", "\n", "        ", "return", "[", "self", ".", "get_token_from_index", "(", "i", ",", "namespace", ")", "for", "i", "in", "t", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size": [[607, 609], ["len"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ",", "namespace", ":", "str", "=", "'tokens'", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "_token_to_index", "[", "namespace", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.__eq__": [[610, 614], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.__str__": [[615, 621], ["vocabulary.Vocabulary.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "base_string", "=", "f\"Vocabulary with namespaces:\\n\"", "\n", "non_padded_namespaces", "=", "f\"\\tNon Padded Namespaces: {self._non_padded_namespaces}\\n\"", "\n", "namespaces", "=", "[", "f\"\\tNamespace: {name}, Size: {self.get_vocab_size(name)} \\n\"", "\n", "for", "name", "in", "self", ".", "_index_to_token", "]", "\n", "return", "\" \"", ".", "join", "(", "[", "base_string", ",", "non_padded_namespaces", "]", "+", "namespaces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.print_statistics": [[622, 648], ["logger.info", "print", "logger.info", "list", "list.sort", "print", "list.sort", "print", "print", "reversed", "vocabulary.Vocabulary._retained_counter[].items", "print", "print", "print", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "print_statistics", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_retained_counter", ":", "\n", "            ", "logger", ".", "info", "(", "\"Printed vocabulary statistics are only for the part of the vocabulary generated \"", "\"from instances. If vocabulary is constructed by extending saved vocabulary with \"", "\"dataset instances, the directly loaded portion won't be considered here.\"", ")", "\n", "print", "(", "\"\\n\\n----Vocabulary Statistics----\\n\"", ")", "\n", "# Since we don't saved counter info, it is impossible to consider pre-saved portion.", "\n", "for", "namespace", "in", "self", ".", "_retained_counter", ":", "\n", "                ", "tokens_with_counts", "=", "list", "(", "self", ".", "_retained_counter", "[", "namespace", "]", ".", "items", "(", ")", ")", "\n", "tokens_with_counts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "f\"\\nTop 10 most frequent tokens in namespace '{namespace}':\"", ")", "\n", "for", "token", ",", "freq", "in", "tokens_with_counts", "[", ":", "10", "]", ":", "\n", "                    ", "print", "(", "f\"\\tToken: {token}\\t\\tFrequency: {freq}\"", ")", "\n", "# Now sort by token length, not frequency", "\n", "", "tokens_with_counts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "print", "(", "f\"\\nTop 10 longest tokens in namespace '{namespace}':\"", ")", "\n", "for", "token", ",", "freq", "in", "tokens_with_counts", "[", ":", "10", "]", ":", "\n", "                    ", "print", "(", "f\"\\tToken: {token}\\t\\tlength: {len(token)}\\tFrequency: {freq}\"", ")", "\n", "\n", "", "print", "(", "f\"\\nTop 10 shortest tokens in namespace '{namespace}':\"", ")", "\n", "for", "token", ",", "freq", "in", "reversed", "(", "tokens_with_counts", "[", "-", "10", ":", "]", ")", ":", "\n", "                    ", "print", "(", "f\"\\tToken: {token}\\t\\tlength: {len(token)}\\tFrequency: {freq}\"", ")", "\n", "", "", "", "else", ":", "\n", "# _retained_counter would be set only if instances were used for vocabulary construction.", "\n", "            ", "logger", ".", "info", "(", "\"Vocabulary statistics cannot be printed since \"", "\"dataset instances were not used for its construction.\"", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary._read_pretrained_tokens": [[97, 113], ["logger.info", "EmbeddingsTextFile", "enumerate", "stog.utils.tqdm.Tqdm.tqdm", "line.find", "tokens.append", "logger.warning", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm"], ["", "", "def", "_read_pretrained_tokens", "(", "embeddings_file_uri", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "# Moving this import to the top breaks everything (cycling import, I guess)", "\n", "    ", "from", "stog", ".", "modules", ".", "token_embedders", "import", "EmbeddingsTextFile", "\n", "\n", "logger", ".", "info", "(", "'Reading pretrained tokens from: %s'", ",", "embeddings_file_uri", ")", "\n", "tokens", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "with", "EmbeddingsTextFile", "(", "embeddings_file_uri", ")", "as", "embeddings_file", ":", "\n", "        ", "for", "line_number", ",", "line", "in", "enumerate", "(", "Tqdm", ".", "tqdm", "(", "embeddings_file", ")", ",", "start", "=", "1", ")", ":", "\n", "            ", "token_end", "=", "line", ".", "find", "(", "' '", ")", "\n", "if", "token_end", ">=", "0", ":", "\n", "                ", "token", "=", "line", "[", ":", "token_end", "]", "\n", "tokens", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "                ", "line_begin", "=", "line", "[", ":", "20", "]", "+", "'...'", "if", "len", "(", "line", ")", ">", "20", "else", "line", "\n", "logger", ".", "warning", "(", "f'Skipping line number %d: %s'", ",", "line_number", ",", "line_begin", ")", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.pop_max_vocab_size": [[115, 134], ["params.pop", "isinstance", "params.pop.as_dict", "int"], "function", ["None"], ["", "def", "pop_max_vocab_size", "(", "params", ":", "Params", ")", "->", "Union", "[", "int", ",", "Dict", "[", "str", ",", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    max_vocab_size is allowed to be either an int or a Dict[str, int] (or nothing).\n    But it could also be a string representing an int (in the case of environment variable\n    substitution). So we need some complex logic to handle it.\n    \"\"\"", "\n", "size", "=", "params", ".", "pop", "(", "\"max_vocab_size\"", ",", "None", ")", "\n", "\n", "if", "isinstance", "(", "size", ",", "Params", ")", ":", "\n", "# This is the Dict[str, int] case.", "\n", "        ", "return", "size", ".", "as_dict", "(", ")", "\n", "", "elif", "size", "is", "not", "None", ":", "\n", "# This is the int / str case.", "\n", "        ", "try", ":", "\n", "            ", "return", "int", "(", "size", ")", "\n", "", "except", ":", "\n", "            ", "return", "size", "\n", "", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset_reader": [[15, 30], ["stog.data.dataset_readers.AbstractMeaningRepresentationDatasetReader", "dict", "kwargs.get", "stog.data.token_indexers.SingleIdTokenIndexer", "stog.data.token_indexers.TokenCharactersIndexer", "stog.data.token_indexers.SingleIdTokenIndexer", "stog.data.token_indexers.TokenCharactersIndexer"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["def", "load_dataset_reader", "(", "dataset_type", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "dataset_type", "==", "\"AMR\"", ":", "\n", "        ", "dataset_reader", "=", "AbstractMeaningRepresentationDatasetReader", "(", "\n", "token_indexers", "=", "dict", "(", "\n", "encoder_tokens", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "\"encoder_token_ids\"", ")", ",", "\n", "encoder_characters", "=", "TokenCharactersIndexer", "(", "namespace", "=", "\"encoder_token_characters\"", ")", ",", "\n", "decoder_tokens", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "\"decoder_token_ids\"", ")", ",", "\n", "decoder_characters", "=", "TokenCharactersIndexer", "(", "namespace", "=", "\"decoder_token_characters\"", ")", "\n", ")", ",", "\n", "word_splitter", "=", "kwargs", ".", "get", "(", "'word_splitter'", ",", "None", ")", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "return", "dataset_reader", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset": [[32, 34], ["load_dataset_reader().read", "dataset_builder.load_dataset_reader"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset_reader"], ["", "def", "load_dataset", "(", "path", ",", "dataset_type", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "load_dataset_reader", "(", "dataset_type", ",", "*", "args", ",", "**", "kwargs", ")", ".", "read", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.dataset_from_params": [[36, 61], ["os.path.join", "os.path.join", "logger.info", "dataset_builder.load_dataset", "logger.info", "dataset_builder.load_dataset", "dict", "os.path.join", "logger.info", "dataset_builder.load_dataset"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset"], ["", "def", "dataset_from_params", "(", "params", ")", ":", "\n", "\n", "    ", "train_data", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'data_dir'", "]", ",", "params", "[", "'train_data'", "]", ")", "\n", "dev_data", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'data_dir'", "]", ",", "params", "[", "'dev_data'", "]", ")", "\n", "test_data", "=", "params", "[", "'test_data'", "]", "\n", "data_type", "=", "params", "[", "'data_type'", "]", "\n", "\n", "logger", ".", "info", "(", "\"Building train datasets ...\"", ")", "\n", "train_data", "=", "load_dataset", "(", "train_data", ",", "data_type", ",", "**", "params", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building dev datasets ...\"", ")", "\n", "dev_data", "=", "load_dataset", "(", "dev_data", ",", "data_type", ",", "**", "params", ")", "\n", "\n", "if", "test_data", ":", "\n", "        ", "test_data", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'data_dir'", "]", ",", "params", "[", "'test_data'", "]", ")", "\n", "logger", ".", "info", "(", "\"Building test datasets ...\"", ")", "\n", "test_data", "=", "load_dataset", "(", "test_data", ",", "data_type", ",", "**", "params", ")", "\n", "\n", "#logger.info(\"Building vocabulary ...\")", "\n", "#build_vocab(fields, train_data)", "\n", "\n", "", "return", "dict", "(", "\n", "train", "=", "train_data", ",", "\n", "dev", "=", "dev_data", ",", "\n", "test", "=", "test_data", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.iterator_from_params": [[64, 95], ["stog.data.iterators.BasicIterator", "stog.data.iterators.BasicIterator", "stog.data.iterators.BasicIterator.index_with", "stog.data.iterators.BasicIterator.index_with", "stog.data.iterators.BasicIterator.index_with", "stog.data.iterators.BucketIterator", "stog.data.iterators.BasicIterator", "list", "map", "params.get"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "iterator_from_params", "(", "vocab", ",", "params", ")", ":", "\n", "# TODO: There are some other options for iterator, I think we consider about it later.", "\n", "    ", "iter_type", "=", "params", "[", "'iter_type'", "]", "\n", "train_batch_size", "=", "params", "[", "'train_batch_size'", "]", "\n", "test_batch_size", "=", "params", "[", "'test_batch_size'", "]", "\n", "\n", "if", "iter_type", "==", "\"BucketIterator\"", ":", "\n", "        ", "train_iterator", "=", "BucketIterator", "(", "\n", "sorting_keys", "=", "list", "(", "map", "(", "tuple", ",", "params", ".", "get", "(", "'sorting_keys'", ",", "[", "]", ")", ")", ")", ",", "\n", "batch_size", "=", "train_batch_size", ",", "\n", ")", "\n", "", "elif", "iter_type", "==", "\"BasicIterator\"", ":", "\n", "        ", "train_iterator", "=", "BasicIterator", "(", "\n", "batch_size", "=", "train_batch_size", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "dev_iterator", "=", "BasicIterator", "(", "\n", "batch_size", "=", "train_batch_size", "\n", ")", "\n", "\n", "test_iterator", "=", "BasicIterator", "(", "\n", "batch_size", "=", "test_batch_size", "\n", ")", "\n", "\n", "train_iterator", ".", "index_with", "(", "vocab", ")", "\n", "dev_iterator", ".", "index_with", "(", "vocab", ")", "\n", "test_iterator", ".", "index_with", "(", "vocab", ")", "\n", "\n", "return", "train_iterator", ",", "dev_iterator", ",", "test_iterator", "\n", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.__init__": [[25, 34], ["typing.Iterable.__init__", "stog.utils.ensure_list", "dataset.Batch._check_types"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.ensure_list", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch._check_types"], ["def", "__init__", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        A Batch just takes an iterable of instances in its constructor and hangs onto them\n        in a list.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "instances", ":", "List", "[", "Instance", "]", "=", "ensure_list", "(", "instances", ")", "\n", "self", ".", "_check_types", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch._check_types": [[35, 45], ["all", "stog.utils.checks.ConfigurationError", "x.fields.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "_check_types", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Check that all the instances have the same types.\n        \"\"\"", "\n", "all_instance_fields_and_types", ":", "List", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "[", "{", "k", ":", "v", ".", "__class__", ".", "__name__", "\n", "for", "k", ",", "v", "in", "x", ".", "fields", ".", "items", "(", ")", "}", "\n", "for", "x", "in", "self", ".", "instances", "]", "\n", "# Check all the field names and Field types are the same for every instance.", "\n", "if", "not", "all", "(", "[", "all_instance_fields_and_types", "[", "0", "]", "==", "x", "for", "x", "in", "all_instance_fields_and_types", "]", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"You cannot construct a Batch with non-homogeneous Instances.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.get_padding_lengths": [[46, 70], ["collections.defaultdict", "collections.defaultdict", "all_field_lengths.items", "instance.get_padding_lengths", "instance_lengths.items", "field_lengths[].keys", "all_field_lengths[].append", "max"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Gets the maximum padding lengths from all ``Instances`` in this batch.  Each ``Instance``\n        has multiple ``Fields``, and each ``Field`` could have multiple things that need padding.\n        We look at all fields in all instances, and find the max values for each (field_name,\n        padding_key) pair, returning them in a dictionary.\n\n        This can then be used to convert this batch into arrays of consistent length, or to set\n        model parameters, etc.\n        \"\"\"", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "defaultdict", "(", "dict", ")", "\n", "all_instance_lengths", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "]", "=", "[", "instance", ".", "get_padding_lengths", "(", ")", "\n", "for", "instance", "in", "self", ".", "instances", "]", "\n", "if", "not", "all_instance_lengths", ":", "\n", "            ", "return", "{", "**", "padding_lengths", "}", "\n", "", "all_field_lengths", ":", "Dict", "[", "str", ",", "List", "[", "Dict", "[", "str", ",", "int", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "instance_lengths", "in", "all_instance_lengths", ":", "\n", "            ", "for", "field_name", ",", "instance_field_lengths", "in", "instance_lengths", ".", "items", "(", ")", ":", "\n", "                ", "all_field_lengths", "[", "field_name", "]", ".", "append", "(", "instance_field_lengths", ")", "\n", "", "", "for", "field_name", ",", "field_lengths", "in", "all_field_lengths", ".", "items", "(", ")", ":", "\n", "            ", "for", "padding_key", "in", "field_lengths", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                ", "max_value", "=", "max", "(", "x", "[", "padding_key", "]", "if", "padding_key", "in", "x", "else", "0", "for", "x", "in", "field_lengths", ")", "\n", "padding_lengths", "[", "field_name", "]", "[", "padding_key", "]", "=", "max_value", "\n", "", "", "return", "{", "**", "padding_lengths", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.as_tensor_dict": [[71, 149], ["dataset.Batch.get_padding_lengths", "collections.defaultdict", "dataset.Batch.items", "collections.defaultdict", "field_tensors.items", "collections.defaultdict", "logger.info", "logger.info", "logger.info", "instance_field_lengths.keys", "logger.info", "instance.as_tensor_dict().items", "field_classes[].batch_tensors", "len", "str", "str", "str", "field_tensors[].append", "padding_lengths[].get", "instance.as_tensor_dict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.batch_tensors", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.as_tensor_dict"], ["", "def", "as_tensor_dict", "(", "self", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "# This complex return type is actually predefined elsewhere as a DataArray,", "\n", "# but we can't use it because mypy doesn't like it.", "\n", "        ", "\"\"\"\n        This method converts this ``Batch`` into a set of pytorch Tensors that can be passed\n        through a model.  In order for the tensors to be valid tensors, all ``Instances`` in this\n        batch need to be padded to the same lengths wherever padding is necessary, so we do that\n        first, then we combine all of the tensors for each field in each instance into a set of\n        batched tensors for each field.\n\n        Parameters\n        ----------\n        padding_lengths : ``Dict[str, Dict[str, int]]``\n            If a key is present in this dictionary with a non-``None`` value, we will pad to that\n            length instead of the length calculated from the data.  This lets you, e.g., set a\n            maximum value for sentence length if you want to throw out long sequences.\n\n            Entries in this dictionary are keyed first by field name (e.g., \"question\"), then by\n            padding key (e.g., \"num_tokens\").\n        verbose : ``bool``, optional (default=``False``)\n            Should we output logging information when we're doing this padding?  If the batch is\n            large, this is nice to have, because padding a large batch could take a long time.\n            But if you're doing this inside of a data generator, having all of this output per\n            batch is a bit obnoxious (and really slow).\n\n        Returns\n        -------\n        tensors : ``Dict[str, DataArray]``\n            A dictionary of tensors, keyed by field name, suitable for passing as input to a model.\n            This is a `batch` of instances, so, e.g., if the instances have a \"question\" field and\n            an \"answer\" field, the \"question\" fields for all of the instances will be grouped\n            together into a single tensor, and the \"answer\" fields for all instances will be\n            similarly grouped in a parallel set of tensors, for batched computation. Additionally,\n            for complex ``Fields``, the value of the dictionary key is not necessarily a single\n            tensor.  For example, with the ``TextField``, the output is a dictionary mapping\n            ``TokenIndexer`` keys to tensors. The number of elements in this sub-dictionary\n            therefore corresponds to the number of ``TokenIndexers`` used to index the\n            ``TextField``.  Each ``Field`` class is responsible for batching its own output.\n        \"\"\"", "\n", "if", "padding_lengths", "is", "None", ":", "\n", "            ", "padding_lengths", "=", "defaultdict", "(", "dict", ")", "\n", "# First we need to decide _how much_ to pad.  To do that, we find the max length for all", "\n", "# relevant padding decisions from the instances themselves.  Then we check whether we were", "\n", "# given a max length for a particular field and padding key.  If we were, we use that", "\n", "# instead of the instance-based one.", "\n", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"Padding batch of size %d to lengths %s\"", ",", "len", "(", "self", ".", "instances", ")", ",", "str", "(", "padding_lengths", ")", ")", "\n", "logger", ".", "info", "(", "\"Getting max lengths from instances\"", ")", "\n", "", "instance_padding_lengths", "=", "self", ".", "get_padding_lengths", "(", ")", "\n", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"Instance max lengths: %s\"", ",", "str", "(", "instance_padding_lengths", ")", ")", "\n", "", "lengths_to_use", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "defaultdict", "(", "dict", ")", "\n", "for", "field_name", ",", "instance_field_lengths", "in", "instance_padding_lengths", ".", "items", "(", ")", ":", "\n", "            ", "for", "padding_key", "in", "instance_field_lengths", ".", "keys", "(", ")", ":", "\n", "                ", "if", "padding_lengths", "[", "field_name", "]", ".", "get", "(", "padding_key", ")", "is", "not", "None", ":", "\n", "                    ", "lengths_to_use", "[", "field_name", "]", "[", "padding_key", "]", "=", "padding_lengths", "[", "field_name", "]", "[", "padding_key", "]", "\n", "", "else", ":", "\n", "                    ", "lengths_to_use", "[", "field_name", "]", "[", "padding_key", "]", "=", "instance_field_lengths", "[", "padding_key", "]", "\n", "\n", "# Now we actually pad the instances to tensors.", "\n", "", "", "", "field_tensors", ":", "Dict", "[", "str", ",", "list", "]", "=", "defaultdict", "(", "list", ")", "\n", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"Now actually padding instances to length: %s\"", ",", "str", "(", "lengths_to_use", ")", ")", "\n", "", "for", "instance", "in", "self", ".", "instances", ":", "\n", "            ", "for", "field", ",", "tensors", "in", "instance", ".", "as_tensor_dict", "(", "lengths_to_use", ")", ".", "items", "(", ")", ":", "\n", "                ", "field_tensors", "[", "field", "]", ".", "append", "(", "tensors", ")", "\n", "\n", "# Finally, we combine the tensors that we got for each instance into one big tensor (or set", "\n", "# of tensors) per field.  The `Field` classes themselves have the logic for batching the", "\n", "# tensors together, so we grab a dictionary of field_name -> field class from the first", "\n", "# instance in the batch.", "\n", "", "", "field_classes", "=", "self", ".", "instances", "[", "0", "]", ".", "fields", "\n", "final_fields", "=", "{", "}", "\n", "for", "field_name", ",", "field_tensor_list", "in", "field_tensors", ".", "items", "(", ")", ":", "\n", "            ", "final_fields", "[", "field_name", "]", "=", "field_classes", "[", "field_name", "]", ".", "batch_tensors", "(", "field_tensor_list", ")", "\n", "", "return", "final_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.__iter__": [[150, 152], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "return", "iter", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.index_instances": [[153, 156], ["instance.index_fields"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.index_fields"], ["", "def", "index_instances", "(", "self", ",", "vocab", ":", "Vocabulary", ")", "->", "None", ":", "\n", "        ", "for", "instance", "in", "self", ".", "instances", ":", "\n", "            ", "instance", ".", "index_fields", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.print_statistics": [[157, 178], ["collections.defaultdict", "print", "sequence_field_lengths.items", "print", "list", "instance.get_padding_lengths().items", "print", "print", "numpy.random.randint", "print", "print", "stog.utils.checks.ConfigurationError", "field_padding_lengths.items", "len", "instance.get_padding_lengths", "sequence_field_lengths[].append", "numpy.mean", "numpy.std", "numpy.max", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths"], ["", "", "def", "print_statistics", "(", "self", ")", "->", "None", ":", "\n", "# Make sure if has been indexed first", "\n", "        ", "sequence_field_lengths", ":", "Dict", "[", "str", ",", "List", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "instance", "in", "self", ".", "instances", ":", "\n", "            ", "if", "not", "instance", ".", "indexed", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Instances must be indexed with vocabulary \"", "\n", "\"before asking to print dataset statistics.\"", ")", "\n", "", "for", "field", ",", "field_padding_lengths", "in", "instance", ".", "get_padding_lengths", "(", ")", ".", "items", "(", ")", ":", "\n", "                ", "for", "key", ",", "value", "in", "field_padding_lengths", ".", "items", "(", ")", ":", "\n", "                    ", "sequence_field_lengths", "[", "f\"{field}.{key}\"", "]", ".", "append", "(", "value", ")", "\n", "\n", "", "", "", "print", "(", "\"\\n\\n----Dataset Statistics----\\n\"", ")", "\n", "for", "name", ",", "lengths", "in", "sequence_field_lengths", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "f\"Statistics for {name}:\"", ")", "\n", "print", "(", "f\"\\tLengths: Mean: {numpy.mean(lengths)}, Standard Dev: {numpy.std(lengths)}, \"", "\n", "f\"Max: {numpy.max(lengths)}, Min: {numpy.min(lengths)}\"", ")", "\n", "\n", "", "print", "(", "\"\\n10 Random instances: \"", ")", "\n", "for", "i", "in", "list", "(", "numpy", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "instances", ")", ",", "size", "=", "10", ")", ")", ":", "\n", "            ", "print", "(", "f\"Instance {i}:\"", ")", "\n", "print", "(", "f\"\\t{self.instances[i]}\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.__init__": [[25, 28], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fields", ":", "MutableMapping", "[", "str", ",", "Field", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "fields", "=", "fields", "\n", "self", ".", "indexed", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.add_field": [[29, 38], ["field.index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "def", "add_field", "(", "self", ",", "field_name", ":", "str", ",", "field", ":", "Field", ",", "vocab", ":", "Vocabulary", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add the field to the existing fields mapping.\n        If we have already indexed the Instance, then we also index `field`, so\n        it is necessary to supply the vocab.\n        \"\"\"", "\n", "self", ".", "fields", "[", "field_name", "]", "=", "field", "\n", "if", "self", ".", "indexed", ":", "\n", "            ", "field", ".", "index", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.count_vocab_items": [[39, 46], ["instance.Instance.fields.values", "field.count_vocab_items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Increments counts in the given ``counter`` for all of the vocabulary items in all of the\n        ``Fields`` in this ``Instance``.\n        \"\"\"", "\n", "for", "field", "in", "self", ".", "fields", ".", "values", "(", ")", ":", "\n", "            ", "field", ".", "count_vocab_items", "(", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.index_fields": [[47, 61], ["instance.Instance.fields.values", "field.index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "", "def", "index_fields", "(", "self", ",", "vocab", ":", "Vocabulary", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Indexes all fields in this ``Instance`` using the provided ``Vocabulary``.\n        This `mutates` the current object, it does not return a new ``Instance``.\n        A ``DataIterator`` will call this on each pass through a dataset; we use the ``indexed``\n        flag to make sure that indexing only happens once.\n\n        This means that if for some reason you modify your vocabulary after you've\n        indexed your instances, you might get unexpected behavior.\n        \"\"\"", "\n", "if", "not", "self", ".", "indexed", ":", "\n", "            ", "self", ".", "indexed", "=", "True", "\n", "for", "field", "in", "self", ".", "fields", ".", "values", "(", ")", ":", "\n", "                ", "field", ".", "index", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.get_padding_lengths": [[62, 71], ["instance.Instance.fields.items", "field.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths"], ["", "", "", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary of padding lengths, keyed by field name.  Each ``Field`` returns a\n        mapping from padding keys to actual lengths, and we just key that dictionary by field name.\n        \"\"\"", "\n", "lengths", "=", "{", "}", "\n", "for", "field_name", ",", "field", "in", "self", ".", "fields", ".", "items", "(", ")", ":", "\n", "            ", "lengths", "[", "field_name", "]", "=", "field", ".", "get_padding_lengths", "(", ")", "\n", "", "return", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.as_tensor_dict": [[72, 87], ["instance.Instance.fields.items", "instance.Instance.get_padding_lengths", "field.as_tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.as_tensor"], ["", "def", "as_tensor_dict", "(", "self", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "DataArray", "]", ":", "\n", "        ", "\"\"\"\n        Pads each ``Field`` in this instance to the lengths given in ``padding_lengths`` (which is\n        keyed by field name, then by padding key, the same as the return value in\n        :func:`get_padding_lengths`), returning a list of torch tensors for each field.\n\n        If ``padding_lengths`` is omitted, we will call ``self.get_padding_lengths()`` to get the\n        sizes of the tensors to create.\n        \"\"\"", "\n", "padding_lengths", "=", "padding_lengths", "or", "self", ".", "get_padding_lengths", "(", ")", "\n", "tensors", "=", "{", "}", "\n", "for", "field_name", ",", "field", "in", "self", ".", "fields", ".", "items", "(", ")", ":", "\n", "            ", "tensors", "[", "field_name", "]", "=", "field", ".", "as_tensor", "(", "padding_lengths", "[", "field_name", "]", ")", "\n", "", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.__str__": [[89, 93], ["instance.Instance.fields.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "base_string", "=", "f\"Instance with fields:\\n\"", "\n", "return", "\" \"", ".", "join", "(", "[", "base_string", "]", "+", "[", "f\"\\t {name}: {field} \\n\"", "\n", "for", "name", ",", "field", "in", "self", ".", "fields", ".", "items", "(", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.character_tokenizer.CharacterTokenizer.__init__": [[35, 47], ["character_tokenizer.CharacterTokenizer._start_tokens.reverse"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "byte_encoding", ":", "str", "=", "None", ",", "\n", "lowercase_characters", ":", "bool", "=", "False", ",", "\n", "start_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "end_tokens", ":", "List", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_byte_encoding", "=", "byte_encoding", "\n", "self", ".", "_lowercase_characters", "=", "lowercase_characters", "\n", "self", ".", "_start_tokens", "=", "start_tokens", "or", "[", "]", "\n", "# We reverse the tokens here because we're going to insert them with `insert(0)` later;", "\n", "# this makes sure they show up in the right order.", "\n", "self", ".", "_start_tokens", ".", "reverse", "(", ")", "\n", "self", ".", "_end_tokens", "=", "end_tokens", "or", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.character_tokenizer.CharacterTokenizer.batch_tokenize": [[48, 51], ["character_tokenizer.CharacterTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize"], ["", "@", "overrides", "\n", "def", "batch_tokenize", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "return", "[", "self", ".", "tokenize", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.character_tokenizer.CharacterTokenizer.tokenize": [[52, 75], ["text.lower.lower.lower", "isinstance", "tokens.insert", "isinstance", "tokens.append", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "text.lower.lower.encode", "list"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode"], ["", "@", "overrides", "\n", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "if", "self", ".", "_lowercase_characters", ":", "\n", "            ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "if", "self", ".", "_byte_encoding", "is", "not", "None", ":", "\n", "# We add 1 here so that we can still use 0 for masking, no matter what bytes we get out", "\n", "# of this.", "\n", "            ", "tokens", "=", "[", "Token", "(", "text_id", "=", "c", "+", "1", ")", "for", "c", "in", "text", ".", "encode", "(", "self", ".", "_byte_encoding", ")", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "Token", "(", "t", ")", "for", "t", "in", "list", "(", "text", ")", "]", "\n", "", "for", "start_token", "in", "self", ".", "_start_tokens", ":", "\n", "            ", "if", "isinstance", "(", "start_token", ",", "int", ")", ":", "\n", "                ", "token", "=", "Token", "(", "text_id", "=", "start_token", ",", "idx", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "Token", "(", "text", "=", "start_token", ",", "idx", "=", "0", ")", "\n", "", "tokens", ".", "insert", "(", "0", ",", "token", ")", "\n", "", "for", "end_token", "in", "self", ".", "_end_tokens", ":", "\n", "            ", "if", "isinstance", "(", "end_token", ",", "int", ")", ":", "\n", "                ", "token", "=", "Token", "(", "text_id", "=", "end_token", ",", "idx", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "Token", "(", "text", "=", "end_token", ",", "idx", "=", "0", ")", "\n", "", "tokens", ".", "append", "(", "token", ")", "\n", "", "return", "tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.tokenizer.Tokenizer.batch_tokenize": [[26, 32], ["None"], "methods", ["None"], ["def", "batch_tokenize", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "\"\"\"\n        Batches together tokenization of several texts, in case that is faster for particular\n        tokenizers.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.tokenizer.Tokenizer.tokenize": [[33, 42], ["None"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Actually implements splitting words into tokens.\n\n        Returns\n        -------\n        tokens : ``List[Token]``\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_stemmer.WordStemmer.stem_word": [[20, 25], ["None"], "methods", ["None"], ["def", "stem_word", "(", "self", ",", "word", ":", "Token", ")", "->", "Token", ":", "\n", "        ", "\"\"\"\n        Returns a new ``Token`` with ``word.text`` replaced by a stemmed word.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_stemmer.PassThroughWordStemmer.stem_word": [[32, 35], ["None"], "methods", ["None"], ["@", "overrides", "\n", "def", "stem_word", "(", "self", ",", "word", ":", "Token", ")", "->", "Token", ":", "\n", "        ", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_stemmer.PorterStemmer.__init__": [[42, 44], ["nltk.stem.PorterStemmer"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "stemmer", "=", "NltkPorterStemmer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_stemmer.PorterStemmer.stem_word": [[45, 56], ["word_stemmer.PorterStemmer.stemmer.stem", "stog.data.tokenizers.token.Token", "getattr"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "stem_word", "(", "self", ",", "word", ":", "Token", ")", "->", "Token", ":", "\n", "        ", "new_text", "=", "self", ".", "stemmer", ".", "stem", "(", "word", ".", "text", ")", "\n", "return", "Token", "(", "text", "=", "new_text", ",", "\n", "idx", "=", "word", ".", "idx", ",", "\n", "lemma", "=", "word", ".", "lemma_", ",", "\n", "pos", "=", "word", ".", "pos_", ",", "\n", "tag", "=", "word", ".", "tag_", ",", "\n", "dep", "=", "word", ".", "dep_", ",", "\n", "ent_type", "=", "word", ".", "ent_type_", ",", "\n", "text_id", "=", "getattr", "(", "word", ",", "'text_id'", ",", "None", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.token.Token.__init__": [[33, 50], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "text", ":", "str", "=", "None", ",", "\n", "idx", ":", "int", "=", "None", ",", "\n", "lemma", ":", "str", "=", "None", ",", "\n", "pos", ":", "str", "=", "None", ",", "\n", "tag", ":", "str", "=", "None", ",", "\n", "dep", ":", "str", "=", "None", ",", "\n", "ent_type", ":", "str", "=", "None", ",", "\n", "text_id", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "idx", "=", "idx", "\n", "self", ".", "lemma_", "=", "lemma", "\n", "self", ".", "pos_", "=", "pos", "\n", "self", ".", "tag_", "=", "tag", "\n", "self", ".", "dep_", "=", "dep", "\n", "self", ".", "ent_type_", "=", "ent_type", "\n", "self", ".", "text_id", "=", "text_id", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.token.Token.__str__": [[51, 53], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.token.Token.__repr__": [[54, 56], ["token.Token.__str__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.__str__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.token.Token.__eq__": [[57, 61], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.token.show_token": [[63, 65], ["None"], "function", ["None"], ["", "", "def", "show_token", "(", "token", ":", "Token", ")", "->", "str", ":", "\n", "    ", "return", "(", "f\"{token.text} \"", "\n", "f\"(idx: {token.idx}) \"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.WordSplitter.batch_split_words": [[23, 31], ["word_splitter.WordSplitter.split_words"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.split_words"], ["def", "batch_split_words", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "\"\"\"\n        Spacy needs to do batch processing, or it can be really slow.  This method lets you take\n        advantage of that if you want.  Default implementation is to just iterate of the sentences\n        and call ``split_words``, but the ``SpacyWordSplitter`` will actually do batched\n        processing.\n        \"\"\"", "\n", "return", "[", "self", ".", "split_words", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.WordSplitter.split_words": [[32, 37], ["None"], "methods", ["None"], ["", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Splits ``sentence`` into a list of :class:`Token` objects.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter.__init__": [[47, 54], ["set", "set", "set", "set", "set", "x.replace"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# These are certainly incomplete.  But at least it's a start.", "\n", "        ", "self", ".", "special_cases", "=", "set", "(", "[", "'mr.'", ",", "'mrs.'", ",", "'etc.'", ",", "'e.g.'", ",", "'cf.'", ",", "'c.f.'", ",", "'eg.'", ",", "'al.'", "]", ")", "\n", "self", ".", "contractions", "=", "set", "(", "[", "\"n't\"", ",", "\"'s\"", ",", "\"'ve\"", ",", "\"'re\"", ",", "\"'ll\"", ",", "\"'d\"", ",", "\"'m\"", "]", ")", "\n", "self", ".", "contractions", "|=", "set", "(", "[", "x", ".", "replace", "(", "\"'\"", ",", "\"\u2019\"", ")", "for", "x", "in", "self", ".", "contractions", "]", ")", "\n", "self", ".", "ending_punctuation", "=", "set", "(", "[", "'\"'", ",", "\"'\"", ",", "'.'", ",", "','", ",", "';'", ",", "')'", ",", "']'", ",", "'}'", ",", "':'", ",", "'!'", ",", "'?'", ",", "'%'", ",", "'\u201d'", ",", "\"\u2019\"", "]", ")", "\n", "self", ".", "beginning_punctuation", "=", "set", "(", "[", "'\"'", ",", "\"'\"", ",", "'('", ",", "'['", ",", "'{'", ",", "'#'", ",", "'$'", ",", "'\u201c'", ",", "\"\u2018\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter.split_words": [[55, 96], ["sentence.split", "tokens.extend", "word_splitter.SimpleWordSplitter._can_split", "tokens.append", "word_splitter.SimpleWordSplitter._can_split", "add_at_end.insert", "tokens.append", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token", "word_splitter.SimpleWordSplitter._can_split", "field.lower().endswith", "add_at_end.insert", "stog.data.tokenizers.token.Token", "field.lower", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter._can_split", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter._can_split", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter._can_split"], ["", "@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Splits a sentence into word tokens.  We handle four kinds of things: words with punctuation\n        that should be ignored as a special case (Mr. Mrs., etc.), contractions/genitives (isn't,\n        don't, Matt's), and beginning and ending punctuation (\"antennagate\", (parentheticals), and\n        such.).\n\n        The basic outline is to split on whitespace, then check each of these cases.  First, we\n        strip off beginning punctuation, then strip off ending punctuation, then strip off\n        contractions.  When we strip something off the beginning of a word, we can add it to the\n        list of tokens immediately.  When we strip it off the end, we have to save it to be added\n        to after the word itself has been added.  Before stripping off any part of a token, we\n        first check to be sure the token isn't in our list of special cases.\n        \"\"\"", "\n", "fields", "=", "sentence", ".", "split", "(", ")", "\n", "tokens", ":", "List", "[", "Token", "]", "=", "[", "]", "\n", "for", "field", "in", "fields", ":", "\n", "            ", "add_at_end", ":", "List", "[", "Token", "]", "=", "[", "]", "\n", "while", "self", ".", "_can_split", "(", "field", ")", "and", "field", "[", "0", "]", "in", "self", ".", "beginning_punctuation", ":", "\n", "                ", "tokens", ".", "append", "(", "Token", "(", "field", "[", "0", "]", ")", ")", "\n", "field", "=", "field", "[", "1", ":", "]", "\n", "", "while", "self", ".", "_can_split", "(", "field", ")", "and", "field", "[", "-", "1", "]", "in", "self", ".", "ending_punctuation", ":", "\n", "                ", "add_at_end", ".", "insert", "(", "0", ",", "Token", "(", "field", "[", "-", "1", "]", ")", ")", "\n", "field", "=", "field", "[", ":", "-", "1", "]", "\n", "\n", "# There could (rarely) be several contractions in a word, but we check contractions", "\n", "# sequentially, in a random order.  If we've removed one, we need to check again to be", "\n", "# sure there aren't others.", "\n", "", "remove_contractions", "=", "True", "\n", "while", "remove_contractions", ":", "\n", "                ", "remove_contractions", "=", "False", "\n", "for", "contraction", "in", "self", ".", "contractions", ":", "\n", "                    ", "if", "self", ".", "_can_split", "(", "field", ")", "and", "field", ".", "lower", "(", ")", ".", "endswith", "(", "contraction", ")", ":", "\n", "                        ", "add_at_end", ".", "insert", "(", "0", ",", "Token", "(", "field", "[", "-", "len", "(", "contraction", ")", ":", "]", ")", ")", "\n", "field", "=", "field", "[", ":", "-", "len", "(", "contraction", ")", "]", "\n", "remove_contractions", "=", "True", "\n", "", "", "", "if", "field", ":", "\n", "                ", "tokens", ".", "append", "(", "Token", "(", "field", ")", ")", "\n", "", "tokens", ".", "extend", "(", "add_at_end", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SimpleWordSplitter._can_split": [[97, 99], ["token.lower"], "methods", ["None"], ["", "def", "_can_split", "(", "self", ",", "token", ":", "str", ")", ":", "\n", "        ", "return", "token", "and", "token", ".", "lower", "(", ")", "not", "in", "self", ".", "special_cases", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.LettersDigitsWordSplitter.split_words": [[107, 113], ["stog.data.tokenizers.token.Token", "m.group", "re.finditer", "m.start"], "methods", ["None"], ["@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "# We use the [^\\W\\d_] pattern as a trick to match unicode letters", "\n", "        ", "tokens", "=", "[", "Token", "(", "m", ".", "group", "(", ")", ",", "idx", "=", "m", ".", "start", "(", ")", ")", "\n", "for", "m", "in", "re", ".", "finditer", "(", "r'[^\\W\\d_]+|\\d+|\\S'", ",", "sentence", ")", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.JustSpacesWordSplitter.split_words": [[126, 129], ["stog.data.tokenizers.token.Token", "sentence.split"], "methods", ["None"], ["@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "return", "[", "Token", "(", "t", ")", "for", "t", "in", "sentence", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SpacyWordSplitter.__init__": [[140, 146], ["stog.utils.file.get_spacy_model"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_spacy_model"], ["def", "__init__", "(", "self", ",", "\n", "language", ":", "str", "=", "'en_core_web_sm'", ",", "\n", "pos_tags", ":", "bool", "=", "False", ",", "\n", "parse", ":", "bool", "=", "False", ",", "\n", "ner", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "spacy", "=", "get_spacy_model", "(", "language", ",", "pos_tags", ",", "parse", ",", "ner", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SpacyWordSplitter.batch_split_words": [[147, 151], ["word_splitter._remove_spaces", "word_splitter.SpacyWordSplitter.spacy.pipe"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter._remove_spaces"], ["", "@", "overrides", "\n", "def", "batch_split_words", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "return", "[", "_remove_spaces", "(", "tokens", ")", "\n", "for", "tokens", "in", "self", ".", "spacy", ".", "pipe", "(", "sentences", ",", "n_threads", "=", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.SpacyWordSplitter.split_words": [[152, 156], ["word_splitter._remove_spaces", "word_splitter.SpacyWordSplitter.spacy"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter._remove_spaces"], ["", "@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "# This works because our Token class matches spacy's.", "\n", "        ", "return", "_remove_spaces", "(", "self", ".", "spacy", "(", "sentence", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.__init__": [[162, 164], ["stog.utils.file.get_spacy_model"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.get_spacy_model"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "spacy", "=", "get_spacy_model", "(", "'en_core_web_sm'", ",", "False", ",", "False", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter._standardize": [[165, 168], ["stog.data.token_indexers.openai_transformer_byte_pair_indexer.text_standardize", "ftfy.fix_text"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.text_standardize"], ["", "@", "staticmethod", "\n", "def", "_standardize", "(", "text", ")", ":", "\n", "        ", "return", "text_standardize", "(", "ftfy", ".", "fix_text", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.batch_split_words": [[169, 174], ["word_splitter.OpenAISplitter._standardize", "word_splitter._remove_spaces", "word_splitter.OpenAISplitter.spacy.pipe"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter._standardize", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter._remove_spaces"], ["", "@", "overrides", "\n", "def", "batch_split_words", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "standardized_sentences", "=", "[", "self", ".", "_standardize", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "return", "[", "_remove_spaces", "(", "tokens", ")", "\n", "for", "tokens", "in", "self", ".", "spacy", ".", "pipe", "(", "standardized_sentences", ",", "n_threads", "=", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.split_words": [[175, 179], ["word_splitter._remove_spaces", "word_splitter.OpenAISplitter.spacy", "word_splitter.OpenAISplitter._standardize"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter._remove_spaces", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter._standardize"], ["", "@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "# This works because our Token class matches spacy's.", "\n", "        ", "return", "_remove_spaces", "(", "self", ".", "spacy", "(", "self", ".", "_standardize", "(", "sentence", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter._remove_spaces": [[131, 133], ["None"], "function", ["None"], ["", "", "def", "_remove_spaces", "(", "tokens", ":", "List", "[", "spacy", ".", "tokens", ".", "Token", "]", ")", "->", "List", "[", "spacy", ".", "tokens", ".", "Token", "]", ":", "\n", "    ", "return", "[", "token", "for", "token", "in", "tokens", "if", "not", "token", ".", "is_space", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer.__init__": [[38, 52], ["stog.data.tokenizers.word_filter.PassThroughWordFilter", "stog.data.tokenizers.word_stemmer.PassThroughWordStemmer", "word_tokenizer.WordTokenizer._start_tokens.reverse", "stog.data.tokenizers.word_splitter.SpacyWordSplitter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "word_splitter", ":", "WordSplitter", "=", "None", ",", "\n", "word_filter", ":", "WordFilter", "=", "PassThroughWordFilter", "(", ")", ",", "\n", "word_stemmer", ":", "WordStemmer", "=", "PassThroughWordStemmer", "(", ")", ",", "\n", "start_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "end_tokens", ":", "List", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_word_splitter", "=", "word_splitter", "or", "SpacyWordSplitter", "(", ")", "\n", "self", ".", "_word_filter", "=", "word_filter", "\n", "self", ".", "_word_stemmer", "=", "word_stemmer", "\n", "self", ".", "_start_tokens", "=", "start_tokens", "or", "[", "]", "\n", "# We reverse the tokens here because we're going to insert them with `insert(0)` later;", "\n", "# this makes sure they show up in the right order.", "\n", "self", ".", "_start_tokens", ".", "reverse", "(", ")", "\n", "self", ".", "_end_tokens", "=", "end_tokens", "or", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer.tokenize": [[53, 63], ["word_tokenizer.WordTokenizer._word_splitter.split_words", "word_tokenizer.WordTokenizer._filter_and_stem"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.split_words", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer._filter_and_stem"], ["", "@", "overrides", "\n", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Does whatever processing is required to convert a string of text into a sequence of tokens.\n\n        At a minimum, this uses a ``WordSplitter`` to split words into text.  It may also do\n        stemming or stopword removal, depending on the parameters given to the constructor.\n        \"\"\"", "\n", "words", "=", "self", ".", "_word_splitter", ".", "split_words", "(", "text", ")", "\n", "return", "self", ".", "_filter_and_stem", "(", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer.batch_tokenize": [[64, 68], ["word_tokenizer.WordTokenizer._word_splitter.batch_split_words", "word_tokenizer.WordTokenizer._filter_and_stem"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_splitter.OpenAISplitter.batch_split_words", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer._filter_and_stem"], ["", "@", "overrides", "\n", "def", "batch_tokenize", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "batched_words", "=", "self", ".", "_word_splitter", ".", "batch_split_words", "(", "texts", ")", "\n", "return", "[", "self", ".", "_filter_and_stem", "(", "words", ")", "for", "words", "in", "batched_words", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer._filter_and_stem": [[69, 77], ["word_tokenizer.WordTokenizer._word_filter.filter_words", "word_tokenizer.WordTokenizer._word_stemmer.stem_word", "stemmed_words.insert", "stemmed_words.append", "stog.data.tokenizers.token.Token", "stog.data.tokenizers.token.Token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_filter.StopwordFilter.filter_words", "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_stemmer.PorterStemmer.stem_word"], ["", "def", "_filter_and_stem", "(", "self", ",", "words", ":", "List", "[", "Token", "]", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "filtered_words", "=", "self", ".", "_word_filter", ".", "filter_words", "(", "words", ")", "\n", "stemmed_words", "=", "[", "self", ".", "_word_stemmer", ".", "stem_word", "(", "word", ")", "for", "word", "in", "filtered_words", "]", "\n", "for", "start_token", "in", "self", ".", "_start_tokens", ":", "\n", "            ", "stemmed_words", ".", "insert", "(", "0", ",", "Token", "(", "start_token", ",", "0", ")", ")", "\n", "", "for", "end_token", "in", "self", ".", "_end_tokens", ":", "\n", "            ", "stemmed_words", ".", "append", "(", "Token", "(", "end_token", ",", "-", "1", ")", ")", "\n", "", "return", "stemmed_words", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.__init__": [[11, 13], ["pytorch_pretrained_bert.tokenization.BertTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AMRBertTokenizer", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize": [[14, 38], ["numpy.array", "max", "numpy.zeros", "enumerate", "bert_tokenizer.AMRBertTokenizer.convert_tokens_to_ids", "enumerate", "_gather_indexes.append", "enumerate", "bert_tokenizer.AMRBertTokenizer.wordpiece_tokenizer.tokenize", "indexes.append", "split_tokens.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize"], ["", "@", "overrides", "\n", "def", "tokenize", "(", "self", ",", "tokens", ",", "split", "=", "False", ")", ":", "\n", "        ", "tokens", "=", "[", "'[CLS]'", "]", "+", "tokens", "+", "[", "'[SEP]'", "]", "\n", "if", "not", "split", ":", "\n", "            ", "split_tokens", "=", "[", "t", "if", "t", "in", "self", ".", "vocab", "else", "'[UNK]'", "for", "t", "in", "tokens", "]", "\n", "gather_indexes", "=", "None", "\n", "", "else", ":", "\n", "            ", "split_tokens", ",", "_gather_indexes", "=", "[", "]", ",", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "indexes", "=", "[", "]", "\n", "for", "i", ",", "sub_token", "in", "enumerate", "(", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ")", ":", "\n", "                    ", "indexes", ".", "append", "(", "len", "(", "split_tokens", ")", ")", "\n", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "_gather_indexes", ".", "append", "(", "indexes", ")", "\n", "\n", "", "_gather_indexes", "=", "_gather_indexes", "[", "1", ":", "-", "1", "]", "\n", "max_index_list_len", "=", "max", "(", "len", "(", "indexes", ")", "for", "indexes", "in", "_gather_indexes", ")", "\n", "gather_indexes", "=", "np", ".", "zeros", "(", "(", "len", "(", "_gather_indexes", ")", ",", "max_index_list_len", ")", ")", "\n", "for", "i", ",", "indexes", "in", "enumerate", "(", "_gather_indexes", ")", ":", "\n", "                ", "for", "j", ",", "index", "in", "enumerate", "(", "indexes", ")", ":", "\n", "                    ", "gather_indexes", "[", "i", ",", "j", "]", "=", "index", "\n", "\n", "", "", "", "token_ids", "=", "np", ".", "array", "(", "self", ".", "convert_tokens_to_ids", "(", "split_tokens", ")", ")", "\n", "return", "token_ids", ",", "gather_indexes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_filter.WordFilter.filter_words": [[19, 24], ["None"], "methods", ["None"], ["def", "filter_words", "(", "self", ",", "words", ":", "List", "[", "Token", "]", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Returns a filtered list of words.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_filter.PassThroughWordFilter.filter_words": [[31, 34], ["None"], "methods", ["None"], ["@", "overrides", "\n", "def", "filter_words", "(", "self", ",", "words", ":", "List", "[", "Token", "]", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_filter.StopwordFilter.__init__": [[41, 67], ["set"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# TODO(matt): Allow this to be specified somehow, either with a file, or with parameters,", "\n", "# or something.", "\n", "        ", "self", ".", "stopwords", "=", "set", "(", "[", "'I'", ",", "'a'", ",", "'aboard'", ",", "'about'", ",", "'above'", ",", "'accordance'", ",", "'according'", ",", "\n", "'across'", ",", "'after'", ",", "'against'", ",", "'along'", ",", "'alongside'", ",", "'also'", ",", "'am'", ",", "\n", "'amid'", ",", "'amidst'", ",", "'an'", ",", "'and'", ",", "'apart'", ",", "'are'", ",", "'around'", ",", "'as'", ",", "\n", "'aside'", ",", "'astride'", ",", "'at'", ",", "'atop'", ",", "'back'", ",", "'be'", ",", "'because'", ",", "'before'", ",", "\n", "'behind'", ",", "'below'", ",", "'beneath'", ",", "'beside'", ",", "'besides'", ",", "'between'", ",", "\n", "'beyond'", ",", "'but'", ",", "'by'", ",", "'concerning'", ",", "'do'", ",", "'down'", ",", "'due'", ",", "'during'", ",", "\n", "'either'", ",", "'except'", ",", "'exclusive'", ",", "'false'", ",", "'for'", ",", "'from'", ",", "'happen'", ",", "\n", "'he'", ",", "'her'", ",", "'hers'", ",", "'herself'", ",", "'him'", ",", "'himself'", ",", "'his'", ",", "'how'", ",", "\n", "'how many'", ",", "'how much'", ",", "'i'", ",", "'if'", ",", "'in'", ",", "'including'", ",", "'inside'", ",", "\n", "'instead'", ",", "'into'", ",", "'irrespective'", ",", "'is'", ",", "'it'", ",", "'its'", ",", "'itself'", ",", "\n", "'less'", ",", "'me'", ",", "'mine'", ",", "'minus'", ",", "'my'", ",", "'myself'", ",", "'neither'", ",", "'next'", ",", "\n", "'not'", ",", "'occur'", ",", "'of'", ",", "'off'", ",", "'on'", ",", "'onto'", ",", "'opposite'", ",", "'or'", ",", "'our'", ",", "\n", "'ours'", ",", "'ourselves'", ",", "'out'", ",", "'out of'", ",", "'outside'", ",", "'over'", ",", "'owing'", ",", "\n", "'per'", ",", "'prepatory'", ",", "'previous'", ",", "'prior'", ",", "'pursuant'", ",", "'regarding'", ",", "\n", "'s'", ",", "'sans'", ",", "'she'", ",", "'subsequent'", ",", "'such'", ",", "'than'", ",", "'thanks'", ",", "'that'", ",", "\n", "'the'", ",", "'their'", ",", "'theirs'", ",", "'them'", ",", "'themselves'", ",", "'then'", ",", "'these'", ",", "\n", "'they'", ",", "'this'", ",", "'those'", ",", "'through'", ",", "'throughout'", ",", "'thru'", ",", "'till'", ",", "\n", "'to'", ",", "'together'", ",", "'top'", ",", "'toward'", ",", "'towards'", ",", "'true'", ",", "'under'", ",", "\n", "'underneath'", ",", "'unlike'", ",", "'until'", ",", "'up'", ",", "'upon'", ",", "'us'", ",", "'using'", ",", "\n", "'versus'", ",", "'via'", ",", "'was'", ",", "'we'", ",", "'were'", ",", "'what'", ",", "'when'", ",", "'where'", ",", "\n", "'which'", ",", "'who'", ",", "'why'", ",", "'will'", ",", "'with'", ",", "'within'", ",", "'without'", ",", "'you'", ",", "\n", "'your'", ",", "'yours'", ",", "'yourself'", ",", "'yourselves'", ",", "\",\"", ",", "'.'", ",", "':'", ",", "'!'", ",", "';'", ",", "\n", "\"'\"", ",", "'\"'", ",", "'&'", ",", "'$'", ",", "'#'", ",", "'@'", ",", "'('", ",", "')'", ",", "'?'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_filter.StopwordFilter.filter_words": [[68, 71], ["word.text.lower"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "filter_words", "(", "self", ",", "words", ":", "List", "[", "Token", "]", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "return", "[", "word", "for", "word", "in", "words", "if", "word", ".", "text", ".", "lower", "(", ")", "not", "in", "self", ".", "stopwords", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.__init__": [[26, 29], ["set"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "namespace", ":", "str", "=", "'dep_labels'", ")", "->", "None", ":", "\n", "        ", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "_logged_errors", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.count_vocab_items": [[30, 39], ["logger.warning", "dep_label_indexer.DepLabelIndexer._logged_errors.add"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "dep_label", "=", "token", ".", "dep_", "\n", "if", "not", "dep_label", ":", "\n", "            ", "if", "token", ".", "text", "not", "in", "self", ".", "_logged_errors", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Token had no dependency label: %s\"", ",", "token", ".", "text", ")", "\n", "self", ".", "_logged_errors", ".", "add", "(", "token", ".", "text", ")", "\n", "", "dep_label", "=", "'NONE'", "\n", "", "counter", "[", "self", ".", "namespace", "]", "[", "dep_label", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.tokens_to_indices": [[40, 48], ["vocabulary.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "dep_labels", "=", "[", "token", ".", "dep_", "or", "'NONE'", "for", "token", "in", "tokens", "]", "\n", "\n", "return", "{", "index_name", ":", "[", "vocabulary", ".", "get_token_index", "(", "dep_label", ",", "self", ".", "namespace", ")", "for", "dep_label", "in", "dep_labels", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_token": [[49, 52], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_lengths": [[53, 56], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.dep_label_indexer.DepLabelIndexer.pad_token_sequence": [[57, 64], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.__init__": [[29, 33], ["set"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "namespace", ":", "str", "=", "'pos_tags'", ",", "coarse_tags", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_coarse_tags", "=", "coarse_tags", "\n", "self", ".", "_logged_errors", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.count_vocab_items": [[34, 46], ["logger.warning", "pos_tag_indexer.PosTagIndexer._logged_errors.add"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_coarse_tags", ":", "\n", "            ", "tag", "=", "token", ".", "pos_", "\n", "", "else", ":", "\n", "            ", "tag", "=", "token", ".", "tag_", "\n", "", "if", "not", "tag", ":", "\n", "            ", "if", "token", ".", "text", "not", "in", "self", ".", "_logged_errors", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Token had no POS tag: %s\"", ",", "token", ".", "text", ")", "\n", "self", ".", "_logged_errors", ".", "add", "(", "token", ".", "text", ")", "\n", "", "tag", "=", "'NONE'", "\n", "", "counter", "[", "self", ".", "_namespace", "]", "[", "tag", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.tokens_to_indices": [[47, 65], ["tags.append", "vocabulary.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "tags", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "self", ".", "_coarse_tags", ":", "\n", "                ", "tag", "=", "token", ".", "pos_", "\n", "", "else", ":", "\n", "                ", "tag", "=", "token", ".", "tag_", "\n", "", "if", "tag", "is", "None", ":", "\n", "                ", "tag", "=", "'NONE'", "\n", "\n", "", "tags", ".", "append", "(", "tag", ")", "\n", "\n", "", "return", "{", "index_name", ":", "[", "vocabulary", ".", "get_token_index", "(", "tag", ",", "self", ".", "_namespace", ")", "for", "tag", "in", "tags", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_token": [[66, 69], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_lengths": [[70, 73], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.pos_tag_indexer.PosTagIndexer.pad_token_sequence": [[74, 81], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.__init__": [[49, 104], ["stog.utils.checks.ConfigurationError", "stog.utils.file.cached_path", "set", "tarfile.open", "next", "tmp.extractfile", "next", "tmp.extractfile", "len", "openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.encoder.items", "enumerate", "json.loads", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError", "tmp.extractfile.read", "tmp.extractfile.read().decode().split", "tuple", "tmp.getmembers", "tmp.getmembers", "m.name.endswith", "line.split", "tmp.extractfile.read().decode", "tmp.extractfile.read"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["def", "__init__", "(", "self", ",", "\n", "encoder", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "byte_pairs", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "n_ctx", ":", "int", "=", "512", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "namespace", ":", "str", "=", "'openai_transformer'", ",", "\n", "tokens_to_add", ":", "List", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_added_to_vocabulary", "=", "False", "\n", "\n", "too_much_information", "=", "model_path", "and", "(", "encoder", "or", "byte_pairs", ")", "\n", "too_little_information", "=", "not", "model_path", "and", "not", "(", "encoder", "and", "byte_pairs", ")", "\n", "\n", "if", "too_much_information", "or", "too_little_information", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"must specify either model path or (encoder + byte_pairs) but not both\"", ")", "\n", "\n", "", "if", "model_path", ":", "\n", "            ", "model_path", "=", "cached_path", "(", "model_path", ")", "\n", "\n", "# Load encoder and byte_pairs from tar.gz", "\n", "with", "tarfile", ".", "open", "(", "model_path", ")", "as", "tmp", ":", "\n", "                ", "encoder_name", "=", "next", "(", "m", ".", "name", "for", "m", "in", "tmp", ".", "getmembers", "(", ")", "if", "'encoder_bpe'", "in", "m", ".", "name", ")", "\n", "encoder_info", "=", "tmp", ".", "extractfile", "(", "encoder_name", ")", "\n", "\n", "if", "encoder_info", ":", "\n", "                    ", "encoder", "=", "json", ".", "loads", "(", "encoder_info", ".", "read", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ConfigurationError", "(", "f\"expected encoder_bpe file in archive {model_path}\"", ")", "\n", "\n", "", "bpe_name", "=", "next", "(", "m", ".", "name", "for", "m", "in", "tmp", ".", "getmembers", "(", ")", "if", "m", ".", "name", ".", "endswith", "(", "'.bpe'", ")", ")", "\n", "bpe_info", "=", "tmp", ".", "extractfile", "(", "bpe_name", ")", "\n", "\n", "if", "bpe_info", ":", "\n", "# First line is \"version\", last line is blank", "\n", "                    ", "lines", "=", "bpe_info", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "# Convert \"b1 b2\" -> (b1, b2)", "\n", "byte_pairs", "=", "[", "tuple", "(", "line", ".", "split", "(", ")", ")", "for", "line", "in", "lines", "]", "# type: ignore", "\n", "", "else", ":", "\n", "                    ", "raise", "ConfigurationError", "(", "f\"expected .bpe file in archive {model_path}\"", ")", "\n", "\n", "", "", "", "if", "tokens_to_add", "is", "not", "None", ":", "\n", "            ", "for", "token", "in", "tokens_to_add", ":", "\n", "                ", "encoder", "[", "token", "+", "'</w>'", "]", "=", "len", "(", "encoder", ")", "\n", "", "self", ".", "tokens_to_add", "=", "set", "(", "tokens_to_add", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokens_to_add", "=", "None", "\n", "\n", "", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "{", "word_id", ":", "word", "for", "word", ",", "word_id", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "\n", "# Compute ranks", "\n", "self", ".", "bpe_ranks", "=", "{", "pair", ":", "idx", "for", "idx", ",", "pair", "in", "enumerate", "(", "byte_pairs", ")", "}", "\n", "\n", "self", ".", "cache", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "{", "}", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.count_vocab_items": [[105, 109], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If we only use pretrained models, we don't need to do anything here.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.byte_pair_encode": [[110, 185], ["word.append", "token.text.lower", "min", "zip", "len", "len", "word.index", "new_word.extend", "new_word.append", "new_word.append", "openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.bpe_ranks.get", "new_word.extend", "zip", "float", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "byte_pair_encode", "(", "self", ",", "token", ":", "Token", ",", "lowercase", ":", "bool", "=", "True", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "lowercase", ":", "\n", "            ", "text", "=", "token", ".", "text", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "token", ".", "text", "\n", "\n", "", "if", "text", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "text", "]", "\n", "\n", "", "if", "self", ".", "tokens_to_add", "and", "text", "in", "self", ".", "tokens_to_add", ":", "\n", "# this is a special token, and it's guaranteed to be a word", "\n", "            ", "word", "=", "[", "text", "+", "'</w>'", "]", "\n", "self", ".", "cache", "[", "text", "]", "=", "word", "\n", "return", "word", "\n", "\n", "# Split into letters, but add a `</w>` to the last", "\n", "", "word", "=", "[", "c", "for", "c", "in", "text", "[", ":", "-", "1", "]", "]", "\n", "word", ".", "append", "(", "text", "[", "-", "1", "]", "+", "'</w>'", ")", "\n", "\n", "# Get unique pairs (prev_symbol, next_symbol)", "\n", "pairs", "=", "{", "(", "prev_symbol", ",", "next_symbol", ")", "\n", "for", "prev_symbol", ",", "next_symbol", "in", "zip", "(", "word", ",", "word", "[", "1", ":", "]", ")", "}", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "[", "text", "+", "'</w>'", "]", "\n", "\n", "", "while", "True", ":", "\n", "# Find the highest ranked pair", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "\n", "# If that pair is not actually ranked, stop.", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "\n", "# Split up the pair", "\n", "", "first", ",", "second", "=", "bigram", "\n", "\n", "# and make a helper for a new word", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "\n", "# Iterate over the letters of the word", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "# Find first occurrence of `first` after i,", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "# add all the characters preceding it,", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "# and update i to j", "\n", "i", "=", "j", "\n", "", "except", "ValueError", ":", "\n", "# `first` didn't occur, so just add the rest", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "# out of while i < len(word)", "\n", "\n", "# At this point we know word[i] == first", "\n", "", "if", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "# out of while True", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "{", "(", "prev_symbol", ",", "next_symbol", ")", "\n", "for", "prev_symbol", ",", "next_symbol", "in", "zip", "(", "word", ",", "word", "[", "1", ":", "]", ")", "}", "\n", "\n", "", "", "if", "' '", ".", "join", "(", "word", ")", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "[", "'\\n</w>'", "]", "\n", "\n", "", "self", ".", "cache", "[", "text", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer._add_encoding_to_vocabulary": [[186, 191], ["openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.encoder.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "_add_encoding_to_vocabulary", "(", "self", ",", "vocabulary", ":", "Vocabulary", ")", "->", "None", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "for", "word", ",", "idx", "in", "self", ".", "encoder", ".", "items", "(", ")", ":", "\n", "            ", "vocabulary", ".", "_token_to_index", "[", "self", ".", "_namespace", "]", "[", "word", "]", "=", "idx", "\n", "vocabulary", ".", "_index_to_token", "[", "self", ".", "_namespace", "]", "[", "idx", "]", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.tokens_to_indices": [[192, 229], ["len", "text_tokens.extend", "openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer._add_encoding_to_vocabulary", "len", "offsets.append", "text_tokens.extend", "RuntimeError", "openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.encoder.get", "openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.byte_pair_encode", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer._add_encoding_to_vocabulary", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.byte_pair_encode"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_added_to_vocabulary", ":", "\n", "            ", "self", ".", "_add_encoding_to_vocabulary", "(", "vocabulary", ")", "\n", "self", ".", "_added_to_vocabulary", "=", "True", "\n", "\n", "", "text_tokens", "=", "[", "]", "\n", "offsets", "=", "[", "]", "\n", "offset", "=", "-", "1", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "bpe_tokens", "=", "[", "self", ".", "encoder", ".", "get", "(", "t", ",", "0", ")", "for", "t", "in", "self", ".", "byte_pair_encode", "(", "token", ")", "]", "\n", "offset", "+=", "len", "(", "bpe_tokens", ")", "\n", "offsets", ".", "append", "(", "offset", ")", "\n", "text_tokens", ".", "extend", "(", "bpe_tokens", ")", "\n", "\n", "", "num_tokens", "=", "len", "(", "text_tokens", ")", "\n", "\n", "# If there's too many tokens, that's going to cause problems.", "\n", "if", "num_tokens", ">", "self", ".", "n_ctx", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"The transformer model has a maximum sequence length of {self.n_ctx} \"", "\n", "f\"but your byte pair encoded sequence has length {num_tokens}. \"", "\n", "f\"The offending text input is {tokens}.\"", ")", "\n", "\n", "# If there's too few tokens, just pad with zeros.", "\n", "", "text_tokens", ".", "extend", "(", "0", "for", "_", "in", "range", "(", "self", ".", "n_ctx", "-", "num_tokens", ")", ")", "\n", "\n", "return", "{", "\n", "index_name", ":", "text_tokens", ",", "\n", "f\"{index_name}-offsets\"", ":", "offsets", ",", "\n", "# add mask here according to the original tokens,", "\n", "# because calling util.get_text_field_mask on the", "\n", "# \"byte pair\" tokens will produce the wrong shape", "\n", "\"mask\"", ":", "[", "1", "for", "_", "in", "offsets", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.get_padding_token": [[231, 234], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.get_padding_lengths": [[235, 238], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.OpenaiTransformerBytePairIndexer.pad_token_sequence": [[239, 246], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.openai_transformer_byte_pair_indexer.text_standardize": [[15, 29], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    Apply text standardization following original implementation.\n    \"\"\"", "\n", "# pylint: disable=anomalous-backslash-in-string", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.count_vocab_items": [[22, 32], ["None"], "methods", ["None"], ["def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        The :class:`Vocabulary` needs to assign indices to whatever strings we see in the training\n        data (possibly doing some frequency filtering and using an OOV, or out of vocabulary,\n        token).  This method takes a token and a dictionary of counts and increments counts for\n        whatever vocabulary items are present in the token.  If this is a single token ID\n        representation, the vocabulary item is likely the token itself.  If this is a token\n        characters representation, the vocabulary items are all of the characters in the token.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.tokens_to_indices": [[33, 45], ["None"], "methods", ["None"], ["", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "TokenType", "]", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of tokens and converts them to one or more sets of indices.\n        This could be just an ID for each token from the vocabulary.\n        Or it could split each token into characters and return one ID per character.\n        Or (for instance, in the case of byte-pair encoding) there might not be a clean\n        mapping from individual tokens to indices.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.get_padding_token": [[46, 52], ["None"], "methods", ["None"], ["", "def", "get_padding_token", "(", "self", ")", "->", "TokenType", ":", "\n", "        ", "\"\"\"\n        When we need to add padding tokens, what should they look like?  This method returns a\n        \"blank\" token of whatever type is returned by :func:`tokens_to_indices`.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.get_padding_lengths": [[53, 61], ["None"], "methods", ["None"], ["", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "TokenType", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        This method returns a padding dictionary for the given token that specifies lengths for\n        all arrays that need padding.  For example, for single ID tokens the returned dictionary\n        will be empty, but for a token characters representation, this will return the number\n        of characters in the token.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.pad_token_sequence": [[62, 76], ["None"], "methods", ["None"], ["", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "TokenType", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "TokenType", "]", "]", ":", "\n", "        ", "\"\"\"\n        This method pads a list of tokens to ``desired_num_tokens`` and returns a padded copy of the\n        input tokens.  If the input token list is longer than ``desired_num_tokens`` then it will be\n        truncated.\n\n        ``padding_lengths`` is used to provide supplemental padding parameters which are needed\n        in some cases.  For example, it contains the widths to pad characters to when doing\n        character-level padding.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.get_keys": [[77, 83], ["None"], "methods", ["None"], ["", "def", "get_keys", "(", "self", ",", "index_name", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Return a list of the keys this indexer return from ``tokens_to_indices``.\n        \"\"\"", "\n", "# pylint: disable=no-self-use", "\n", "return", "[", "index_name", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.__init__": [[26, 28], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "namespace", ":", "str", "=", "'ner_tags'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.count_vocab_items": [[29, 35], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "tag", "=", "token", ".", "ent_type_", "\n", "if", "not", "tag", ":", "\n", "            ", "tag", "=", "'NONE'", "\n", "", "counter", "[", "self", ".", "_namespace", "]", "[", "tag", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.tokens_to_indices": [[36, 44], ["vocabulary.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "tags", "=", "[", "'NONE'", "if", "token", ".", "ent_type_", "is", "None", "else", "token", ".", "ent_type_", "for", "token", "in", "tokens", "]", "\n", "\n", "return", "{", "index_name", ":", "[", "vocabulary", ".", "get_token_index", "(", "tag", ",", "self", ".", "_namespace", ")", "for", "tag", "in", "tags", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_token": [[45, 48], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_lengths": [[49, 52], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.ner_tag_indexer.NerTagIndexer.pad_token_sequence": [[53, 60], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.__init__": [[25, 28], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "namespace", ":", "str", "=", "'tokens'", ",", "lowercase_tokens", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "lowercase_tokens", "=", "lowercase_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.count_vocab_items": [[29, 38], ["getattr", "text.lower.lower.lower"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If `text_id` is set on the token (e.g., if we're using some kind of hash-based word", "\n", "# encoding), we will not be using the vocab for this token.", "\n", "        ", "if", "getattr", "(", "token", ",", "'text_id'", ",", "None", ")", "is", "None", ":", "\n", "            ", "text", "=", "token", ".", "text", "\n", "if", "self", ".", "lowercase_tokens", ":", "\n", "                ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "counter", "[", "self", ".", "namespace", "]", "[", "text", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.tokens_to_indices": [[39, 58], ["getattr", "indices.append", "indices.append", "text.lower.lower.lower", "vocabulary.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "indices", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "getattr", "(", "token", ",", "'text_id'", ",", "None", ")", "is", "not", "None", ":", "\n", "# `text_id` being set on the token means that we aren't using the vocab, we just use", "\n", "# this id instead.", "\n", "                ", "indices", ".", "append", "(", "token", ".", "text_id", ")", "\n", "", "else", ":", "\n", "                ", "text", "=", "token", ".", "text", "\n", "if", "self", ".", "lowercase_tokens", ":", "\n", "                    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "indices", ".", "append", "(", "vocabulary", ".", "get_token_index", "(", "text", ",", "self", ".", "namespace", ")", ")", "\n", "\n", "", "", "return", "{", "index_name", ":", "indices", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_token": [[59, 62], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_lengths": [[63, 66], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.pad_token_sequence": [[67, 74], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoCharacterMapper.convert_word_to_char_ids": [[59, 75], ["enumerate", "word.encode", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode"], ["@", "staticmethod", "\n", "def", "convert_word_to_char_ids", "(", "word", ":", "str", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "if", "word", "==", "ELMoCharacterMapper", ".", "bos_token", ":", "\n", "            ", "char_ids", "=", "ELMoCharacterMapper", ".", "beginning_of_sentence_characters", "\n", "", "elif", "word", "==", "ELMoCharacterMapper", ".", "eos_token", ":", "\n", "            ", "char_ids", "=", "ELMoCharacterMapper", ".", "end_of_sentence_characters", "\n", "", "else", ":", "\n", "            ", "word_encoded", "=", "word", ".", "encode", "(", "'utf-8'", ",", "'ignore'", ")", "[", ":", "(", "ELMoCharacterMapper", ".", "max_word_length", "-", "2", ")", "]", "\n", "char_ids", "=", "[", "ELMoCharacterMapper", ".", "padding_character", "]", "*", "ELMoCharacterMapper", ".", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "ELMoCharacterMapper", ".", "beginning_of_word_character", "\n", "for", "k", ",", "chr_id", "in", "enumerate", "(", "word_encoded", ",", "start", "=", "1", ")", ":", "\n", "                ", "char_ids", "[", "k", "]", "=", "chr_id", "\n", "", "char_ids", "[", "len", "(", "word_encoded", ")", "+", "1", "]", "=", "ELMoCharacterMapper", ".", "end_of_word_character", "\n", "\n", "# +1 one for masking", "\n", "", "return", "[", "c", "+", "1", "for", "c", "in", "char_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.__init__": [[87, 90], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "namespace", ":", "str", "=", "'elmo_characters'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.count_vocab_items": [[91, 94], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.tokens_to_indices": [[95, 107], ["any", "stog.utils.checks.ConfigurationError", "elmo_indexer.ELMoCharacterMapper.convert_word_to_char_ids"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoCharacterMapper.convert_word_to_char_ids"], ["", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "texts", "=", "[", "token", ".", "text", "for", "token", "in", "tokens", "]", "\n", "\n", "if", "any", "(", "text", "is", "None", "for", "text", "in", "texts", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'ELMoTokenCharactersIndexer needs a tokenizer '", "\n", "'that retains text'", ")", "\n", "", "return", "{", "index_name", ":", "[", "ELMoCharacterMapper", ".", "convert_word_to_char_ids", "(", "text", ")", "for", "text", "in", "texts", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_lengths": [[108, 112], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "List", "[", "int", "]", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_token": [[113, 116], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer._default_value_for_padding": [[117, 120], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_default_value_for_padding", "(", ")", ":", "\n", "        ", "return", "[", "0", "]", "*", "ELMoCharacterMapper", ".", "max_word_length", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.pad_token_sequence": [[121, 130], ["stog.utils.string.pad_sequence_to_length", "tokens.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "self", ".", "_default_value_for_padding", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.elmo_indexer._make_bos_eos": [[12, 24], ["None"], "function", ["None"], ["def", "_make_bos_eos", "(", "\n", "character", ":", "int", ",", "\n", "padding_character", ":", "int", ",", "\n", "beginning_of_word_character", ":", "int", ",", "\n", "end_of_word_character", ":", "int", ",", "\n", "max_word_length", ":", "int", "\n", ")", ":", "\n", "    ", "char_ids", "=", "[", "padding_character", "]", "*", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "beginning_of_word_character", "\n", "char_ids", "[", "1", "]", "=", "character", "\n", "char_ids", "[", "2", "]", "=", "end_of_word_character", "\n", "return", "char_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.__init__": [[31, 36], ["stog.data.tokenizers.character_tokenizer.CharacterTokenizer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "namespace", ":", "str", "=", "'token_characters'", ",", "\n", "character_tokenizer", ":", "CharacterTokenizer", "=", "CharacterTokenizer", "(", ")", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_character_tokenizer", "=", "character_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.count_vocab_items": [[37, 46], ["token_characters_indexer.TokenCharactersIndexer._character_tokenizer.tokenize", "stog.utils.checks.ConfigurationError", "getattr"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "token", ".", "text", "is", "None", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'TokenCharactersIndexer needs a tokenizer that retains text'", ")", "\n", "", "for", "character", "in", "self", ".", "_character_tokenizer", ".", "tokenize", "(", "token", ".", "text", ")", ":", "\n", "# If `text_id` is set on the character token (e.g., if we're using byte encoding), we", "\n", "# will not be using the vocab for this character.", "\n", "            ", "if", "getattr", "(", "character", ",", "'text_id'", ",", "None", ")", "is", "None", ":", "\n", "                ", "counter", "[", "self", ".", "_namespace", "]", "[", "character", ".", "text", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.tokens_to_indices": [[47, 67], ["token_characters_indexer.TokenCharactersIndexer._character_tokenizer.tokenize", "indices.append", "stog.utils.checks.ConfigurationError", "token_indices.append", "getattr", "vocabulary.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.bert_tokenizer.AMRBertTokenizer.tokenize", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "        ", "indices", ":", "List", "[", "List", "[", "int", "]", "]", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "token_indices", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "token", ".", "text", "is", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "'TokenCharactersIndexer needs a tokenizer that retains text'", ")", "\n", "", "for", "character", "in", "self", ".", "_character_tokenizer", ".", "tokenize", "(", "token", ".", "text", ")", ":", "\n", "                ", "if", "getattr", "(", "character", ",", "'text_id'", ",", "None", ")", "is", "not", "None", ":", "\n", "# `text_id` being set on the token means that we aren't using the vocab, we just", "\n", "# use this id instead.", "\n", "                    ", "index", "=", "character", ".", "text_id", "\n", "", "else", ":", "\n", "                    ", "index", "=", "vocabulary", ".", "get_token_index", "(", "character", ".", "text", ",", "self", ".", "_namespace", ")", "\n", "", "token_indices", ".", "append", "(", "index", ")", "\n", "", "indices", ".", "append", "(", "token_indices", ")", "\n", "", "return", "{", "index_name", ":", "indices", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_lengths": [[68, 71], ["len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "List", "[", "int", "]", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "'num_token_characters'", ":", "len", "(", "token", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_token": [[72, 75], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.pad_token_sequence": [[76, 105], ["stog.utils.string.pad_sequence_to_length", "max", "list", "list", "len", "list.append", "zip", "len", "list.pop", "tokens.keys", "list", "itertools.zip_longest"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "# Pad the tokens.", "\n", "# tokens has only one key...", "\n", "        ", "key", "=", "list", "(", "tokens", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "\n", "padded_tokens", "=", "pad_sequence_to_length", "(", "\n", "tokens", "[", "key", "]", ",", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "self", ".", "get_padding_token", "\n", ")", "\n", "\n", "# Pad the characters within the tokens.", "\n", "desired_token_length", "=", "padding_lengths", "[", "'num_token_characters'", "]", "\n", "longest_token", ":", "List", "[", "int", "]", "=", "max", "(", "tokens", "[", "key", "]", ",", "key", "=", "len", ",", "default", "=", "[", "]", ")", "\n", "padding_value", "=", "0", "\n", "if", "desired_token_length", ">", "len", "(", "longest_token", ")", ":", "\n", "# Since we want to pad to greater than the longest token, we add a", "\n", "# \"dummy token\" so we can take advantage of the fast implementation of itertools.zip_longest.", "\n", "            ", "padded_tokens", ".", "append", "(", "[", "padding_value", "]", "*", "desired_token_length", ")", "\n", "# pad the list of lists to the longest sublist, appending 0's", "\n", "", "padded_tokens", "=", "list", "(", "zip", "(", "*", "itertools", ".", "zip_longest", "(", "*", "padded_tokens", ",", "fillvalue", "=", "padding_value", ")", ")", ")", "\n", "if", "desired_token_length", ">", "len", "(", "longest_token", ")", ":", "\n", "# Removes the \"dummy token\".", "\n", "            ", "padded_tokens", ".", "pop", "(", ")", "\n", "# Truncates all the tokens to the desired length, and return the result.", "\n", "", "return", "{", "key", ":", "[", "list", "(", "token", "[", ":", "desired_token_length", "]", ")", "for", "token", "in", "padded_tokens", "]", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.__init__": [[30, 52], ["stog.data.dataset_readers.dataset_reader.DatasetReader.__init__", "stog.data.tokenizers.bert_tokenizer.AMRBertTokenizer.from_pretrained", "stog.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "word_splitter", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "skip_first_line", ":", "bool", "=", "True", ",", "\n", "evaluation", ":", "bool", "=", "False", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "lazy", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "if", "word_splitter", "is", "not", "None", ":", "\n", "            ", "self", ".", "_word_splitter", "=", "AMRBertTokenizer", ".", "from_pretrained", "(", "\n", "word_splitter", ",", "do_lower_case", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_word_splitter", "=", "None", "\n", "", "self", ".", "_skip_first_line", "=", "skip_first_line", "\n", "self", ".", "_evaluation", "=", "evaluation", "\n", "\n", "self", ".", "_number_bert_ids", "=", "0", "\n", "self", ".", "_number_bert_oov_ids", "=", "0", "\n", "self", ".", "_number_non_oov_pos_tags", "=", "0", "\n", "self", ".", "_number_pos_tags", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.report_coverage": [[53, 63], ["logger.info", "logger.info"], "methods", ["None"], ["", "def", "report_coverage", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_number_bert_ids", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'BERT OOV  rate: {0:.4f} ({1}/{2})'", ".", "format", "(", "\n", "self", ".", "_number_bert_oov_ids", "/", "self", ".", "_number_bert_ids", ",", "\n", "self", ".", "_number_bert_oov_ids", ",", "self", ".", "_number_bert_ids", "\n", ")", ")", "\n", "", "if", "self", ".", "_number_non_oov_pos_tags", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'POS tag coverage: {0:.4f} ({1}/{2})'", ".", "format", "(", "\n", "self", ".", "_number_non_oov_pos_tags", "/", "self", ".", "_number_pos_tags", ",", "\n", "self", ".", "_number_non_oov_pos_tags", ",", "self", ".", "_number_pos_tags", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.set_evaluation": [[65, 67], ["None"], "methods", ["None"], ["", "", "def", "set_evaluation", "(", "self", ")", ":", "\n", "        ", "self", ".", "_evaluation", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader._read": [[68, 76], ["stog.utils.file.cached_path", "logger.info", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.report_coverage", "abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.file.cached_path", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.report_coverage", "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "# if `file_path` is a URL, redirect to the cache", "\n", "        ", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "for", "amr", "in", "AMRIO", ".", "read", "(", "file_path", ")", ":", "\n", "            ", "yield", "self", ".", "text_to_instance", "(", "amr", ")", "\n", "", "self", ".", "report_coverage", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader.text_to_instance": [[77, 209], ["amr.graph.get_list_data", "stog.data.fields.TextField", "stog.data.fields.SequenceLabelField", "stog.data.fields.TextField", "stog.data.fields.SequenceLabelField", "stog.data.fields.SequenceLabelField", "len", "len", "stog.data.fields.SequenceLabelField", "stog.data.fields.SequenceLabelField", "stog.data.fields.AdjacencyField", "stog.data.fields.SequenceLabelField", "stog.data.fields.AdjacencyField", "stog.data.fields.SequenceLabelField", "stog.data.fields.SequenceLabelField", "stog.data.instance.Instance", "stog.data.fields.ArrayField", "len", "len", "stog.data.fields.ArrayField", "stog.data.fields.MetadataField", "stog.data.fields.MetadataField", "stog.data.fields.MetadataField", "stog.data.fields.MetadataField", "stog.data.fields.MetadataField", "stog.data.fields.MetadataField", "stog.data.fields.TextField", "amr.graph.get_list_data.get", "dict", "stog.data.tokenizers.Token", "stog.data.tokenizers.Token", "abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader._token_indexers.items", "abstract_meaning_representation.AbstractMeaningRepresentationDatasetReader._token_indexers.items", "stog.data.tokenizers.Token", "list_data[].get_special_tok_list"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_data", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_special_tok_list"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "amr", ")", "->", "Instance", ":", "\n", "# pylint: disable=arguments-differ", "\n", "\n", "        ", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "\n", "max_tgt_length", "=", "None", "if", "self", ".", "_evaluation", "else", "60", "\n", "\n", "list_data", "=", "amr", ".", "graph", ".", "get_list_data", "(", "\n", "amr", ",", "START_SYMBOL", ",", "END_SYMBOL", ",", "self", ".", "_word_splitter", ",", "max_tgt_length", ")", "\n", "\n", "# These four fields are used for seq2seq model and target side self copy", "\n", "fields", "[", "\"src_tokens\"", "]", "=", "TextField", "(", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "list_data", "[", "\"src_tokens\"", "]", "]", ",", "\n", "token_indexers", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", "if", "'encoder'", "in", "k", "}", "\n", ")", "\n", "\n", "if", "list_data", "[", "'src_token_ids'", "]", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'src_token_ids'", "]", "=", "ArrayField", "(", "list_data", "[", "'src_token_ids'", "]", ")", "\n", "self", ".", "_number_bert_ids", "+=", "len", "(", "list_data", "[", "'src_token_ids'", "]", ")", "\n", "self", ".", "_number_bert_oov_ids", "+=", "len", "(", "\n", "[", "bert_id", "for", "bert_id", "in", "list_data", "[", "'src_token_ids'", "]", "if", "bert_id", "==", "100", "]", ")", "\n", "\n", "", "if", "list_data", "[", "'src_token_subword_index'", "]", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'src_token_subword_index'", "]", "=", "ArrayField", "(", "\n", "list_data", "[", "'src_token_subword_index'", "]", ")", "\n", "\n", "", "fields", "[", "\"src_must_copy_tags\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"src_must_copy_tags\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"src_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"must_copy_tags\"", "\n", ")", "\n", "\n", "fields", "[", "\"tgt_tokens\"", "]", "=", "TextField", "(", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "list_data", "[", "\"tgt_tokens\"", "]", "]", ",", "\n", "token_indexers", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", "if", "'decoder'", "in", "k", "}", "\n", ")", "\n", "\n", "fields", "[", "\"src_pos_tags\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"src_pos_tags\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"src_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"pos_tags\"", "\n", ")", "\n", "\n", "fields", "[", "\"tgt_pos_tags\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"tgt_pos_tags\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"pos_tags\"", "\n", ")", "\n", "\n", "self", ".", "_number_pos_tags", "+=", "len", "(", "list_data", "[", "'tgt_pos_tags'", "]", ")", "\n", "self", ".", "_number_non_oov_pos_tags", "+=", "len", "(", "\n", "[", "tag", "for", "tag", "in", "list_data", "[", "'tgt_pos_tags'", "]", "if", "tag", "!=", "'@@UNKNOWN@@'", "]", ")", "\n", "\n", "fields", "[", "\"tgt_copy_indices\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"tgt_copy_indices\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"coref_tags\"", ",", "\n", ")", "\n", "\n", "fields", "[", "\"tgt_copy_mask\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"tgt_copy_mask\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"coref_mask_tags\"", ",", "\n", ")", "\n", "\n", "fields", "[", "\"tgt_copy_map\"", "]", "=", "AdjacencyField", "(", "\n", "indices", "=", "list_data", "[", "\"tgt_copy_map\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "padding_value", "=", "0", "\n", ")", "\n", "\n", "# These two fields for source copy", "\n", "fields", "[", "\"src_copy_indices\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"src_copy_indices\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"source_copy_target_tags\"", ",", "\n", ")", "\n", "\n", "fields", "[", "\"src_copy_map\"", "]", "=", "AdjacencyField", "(", "\n", "indices", "=", "list_data", "[", "\"src_copy_map\"", "]", ",", "\n", "sequence_field", "=", "TextField", "(", "\n", "[", "\n", "Token", "(", "x", ")", "for", "x", "in", "list_data", "[", "\"src_copy_vocab\"", "]", ".", "get_special_tok_list", "(", ")", "+", "list_data", "[", "\"src_tokens\"", "]", "\n", "]", ",", "\n", "None", "\n", ")", ",", "\n", "padding_value", "=", "0", "\n", ")", "\n", "\n", "# These two fields are used in biaffine parser", "\n", "fields", "[", "\"head_tags\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"head_tags\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"head_tags\"", ",", "\n", "strip_sentence_symbols", "=", "True", "\n", ")", "\n", "\n", "fields", "[", "\"head_indices\"", "]", "=", "SequenceLabelField", "(", "\n", "labels", "=", "list_data", "[", "\"head_indices\"", "]", ",", "\n", "sequence_field", "=", "fields", "[", "\"tgt_tokens\"", "]", ",", "\n", "label_namespace", "=", "\"head_index_tags\"", ",", "\n", "strip_sentence_symbols", "=", "True", "\n", ")", "\n", "\n", "if", "self", ".", "_evaluation", ":", "\n", "# Metadata fields, good for debugging", "\n", "            ", "fields", "[", "\"src_tokens_str\"", "]", "=", "MetadataField", "(", "\n", "list_data", "[", "\"src_tokens\"", "]", "\n", ")", "\n", "\n", "fields", "[", "\"tgt_tokens_str\"", "]", "=", "MetadataField", "(", "\n", "list_data", ".", "get", "(", "\"tgt_tokens\"", ",", "[", "]", ")", "\n", ")", "\n", "\n", "fields", "[", "\"src_copy_vocab\"", "]", "=", "MetadataField", "(", "\n", "list_data", "[", "\"src_copy_vocab\"", "]", "\n", ")", "\n", "\n", "fields", "[", "\"tag_lut\"", "]", "=", "MetadataField", "(", "\n", "dict", "(", "pos", "=", "list_data", "[", "\"pos_tag_lut\"", "]", ")", "\n", ")", "\n", "\n", "fields", "[", "\"source_copy_invalid_ids\"", "]", "=", "MetadataField", "(", "\n", "list_data", "[", "'src_copy_invalid_ids'", "]", "\n", ")", "\n", "\n", "fields", "[", "\"amr\"", "]", "=", "MetadataField", "(", "\n", "amr", "\n", ")", "\n", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader._LazyInstances.__init__": [[16, 19], ["typing.Iterable.__init__"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "instance_generator", ":", "Callable", "[", "[", "]", ",", "Iterator", "[", "Instance", "]", "]", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "instance_generator", "=", "instance_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader._LazyInstances.__iter__": [[20, 25], ["dataset_reader._LazyInstances.instance_generator", "isinstance", "stog.utils.checks.ConfigurationError"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "instances", "=", "self", ".", "instance_generator", "(", ")", "\n", "if", "isinstance", "(", "instances", ",", "list", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"For a lazy dataset reader, _read() must return a generator\"", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader.__init__": [[42, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "lazy", "=", "lazy", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader.read": [[45, 78], ["getattr", "logger.warning", "dataset_reader._LazyInstances", "dataset_reader.DatasetReader._read", "isinstance", "stog.utils.checks.ConfigurationError", "iter", "dataset_reader.DatasetReader._read", "stog.utils.tqdm.Tqdm.tqdm"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader._read", "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader._read", "home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm"], ["", "def", "read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "        ", "\"\"\"\n        Returns an ``Iterable`` containing all the instances\n        in the specified dataset.\n\n        If ``self.lazy`` is False, this calls ``self._read()``,\n        ensures that the result is a list, then returns the resulting list.\n\n        If ``self.lazy`` is True, this returns an object whose\n        ``__iter__`` method calls ``self._read()`` each iteration.\n        In this case your implementation of ``_read()`` must also be lazy\n        (that is, not load all instances into memory at once), otherwise\n        you will get a ``ConfigurationError``.\n\n        In either case, the returned ``Iterable`` can be iterated\n        over multiple times. It's unlikely you want to override this function,\n        but if you do your result should likewise be repeatedly iterable.\n        \"\"\"", "\n", "lazy", "=", "getattr", "(", "self", ",", "'lazy'", ",", "None", ")", "\n", "if", "lazy", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"DatasetReader.lazy is not set, \"", "\n", "\"did you forget to call the superclass constructor?\"", ")", "\n", "\n", "", "if", "lazy", ":", "\n", "            ", "return", "_LazyInstances", "(", "lambda", ":", "iter", "(", "self", ".", "_read", "(", "file_path", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "instances", "=", "self", ".", "_read", "(", "file_path", ")", "\n", "if", "not", "isinstance", "(", "instances", ",", "list", ")", ":", "\n", "                ", "instances", "=", "[", "instance", "for", "instance", "in", "Tqdm", ".", "tqdm", "(", "instances", ")", "]", "\n", "", "if", "not", "instances", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"No instances were read from the given filepath {}. \"", "\n", "\"Is the path correct?\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader._read": [[79, 87], ["None"], "methods", ["None"], ["", "", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "        ", "\"\"\"\n        Reads the instances from the given file_path and returns them as an\n        `Iterable` (which could be a list or could be a generator).\n        You are strongly encouraged to use a generator, so that users can\n        read a dataset in a lazy way, if they so choose.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.dataset_readers.dataset_reader.DatasetReader.text_to_instance": [[88, 106], ["None"], "methods", ["None"], ["", "def", "text_to_instance", "(", "self", ",", "*", "inputs", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Does whatever tokenization or processing is necessary to go from textual input to an\n        ``Instance``.  The primary intended use for this is with a\n        :class:`~stog.service.predictors.predictor.Predictor`, which gets text input as a JSON\n        object and needs to process it to be input to a model.\n\n        The intent here is to share code between :func:`_read` and what happens at\n        model serving time, or any other time you want to make a prediction from new data.  We need\n        to process the data in the same way it was done at training time.  Allowing the\n        ``DatasetReader`` to process new text lets us accomplish this, as we can just call\n        ``DatasetReader.text_to_instance`` when serving predictions.\n\n        The input type here is rather vaguely specified, unfortunately.  The ``Predictor`` will\n        have to make some assumptions about the kind of ``DatasetReader`` that it's using, in order\n        to pass it the right information.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader.__init__": [[11, 25], ["set", "dict", "propbank_reader.PropbankReader._load"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph._load"], ["    ", "def", "__init__", "(", "self", ",", "directory", ")", ":", "\n", "        ", "\"\"\"\n        Load Propbank frames from the given directory, and build two data structures:\n            frame_lemma_set: each frame consists of two parts, frame lemma and frame sense,\n                e.g., `run-01`. frame_lemma_set collects all frame lemmas.\n            lemma_map: besides frame lemmas, a frame could be invoked by other lemmas.\n                Here we build a dict that maps a lemma to a set of frames it could invoke.\n\n        :param directory: string.\n        \"\"\"", "\n", "self", ".", "frame_lemma_set", "=", "set", "(", ")", "\n", "self", ".", "lemma_map", "=", "dict", "(", ")", "\n", "self", ".", "directory", "=", "directory", "\n", "self", ".", "_load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._load": [[26, 34], ["os.listdir", "file_name.endswith", "os.path.join", "propbank_reader.PropbankReader._parse_file"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._parse_file"], ["", "def", "_load", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load Propbank frame files (.xml).\n        \"\"\"", "\n", "for", "file_name", "in", "os", ".", "listdir", "(", "self", ".", "directory", ")", ":", "\n", "            ", "if", "file_name", ".", "endswith", "(", "'.xml'", ")", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "file_name", ")", "\n", "self", ".", "_parse_file", "(", "file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._parse_file": [[35, 44], ["xml.parse", "xml.parse.getroot", "propbank_reader.PropbankReader._add_predicate"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._add_predicate"], ["", "", "", "def", "_parse_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse a propbank frame file.\n        :param file_path: the frame file path.\n        \"\"\"", "\n", "tree", "=", "ET", ".", "parse", "(", "file_path", ")", "\n", "for", "child", "in", "tree", ".", "getroot", "(", ")", ":", "\n", "            ", "if", "child", ".", "tag", "==", "'predicate'", ":", "\n", "                ", "self", ".", "_add_predicate", "(", "child", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._add_predicate": [[45, 79], ["node.attrib[].replace", "frame_id.replace().replace", "Frame", "propbank_reader.PropbankReader.frame_lemma_set.add", "propbank_reader.PropbankReader._update_lemma_map", "child.find", "frame_id.split", "frame_id.replace().split", "child.find.findall", "len", "parts[].replace", "frame_id.replace", "alias.text.replace", "frame_id.replace", "propbank_reader.PropbankReader._update_lemma_map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._update_lemma_map", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._update_lemma_map"], ["", "", "", "def", "_add_predicate", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\"\n        Update frame_lemma_set and lemma_map given this predicate.\n        \"\"\"", "\n", "# Get the primary lemma of the frame.", "\n", "lemma", "=", "node", ".", "attrib", "[", "'lemma'", "]", ".", "replace", "(", "'_'", ",", "'-'", ")", "# AMR use dash.", "\n", "for", "child", "in", "node", ":", "\n", "            ", "if", "child", ".", "tag", "==", "'roleset'", ":", "\n", "# Split sense from frame id; get `frame_lemma` and `sense`.", "\n", "                ", "frame_id", "=", "child", ".", "attrib", "[", "'id'", "]", "\n", "if", "'.'", "not", "in", "frame_id", ":", "\n", "                    ", "parts", "=", "frame_id", ".", "split", "(", "'-'", ")", "\n", "if", "len", "(", "parts", ")", "==", "1", ":", "\n", "                        ", "frame_lemma", "=", "parts", "[", "0", "]", ".", "replace", "(", "'_'", ",", "'-'", ")", "\n", "sense", "=", "None", "\n", "", "else", ":", "\n", "                        ", "frame_lemma", ",", "sense", "=", "parts", "\n", "", "", "else", ":", "\n", "                    ", "frame_lemma", ",", "sense", "=", "frame_id", ".", "replace", "(", "'_'", ",", "'-'", ")", ".", "split", "(", "'.'", ")", "\n", "# Get frame id in AMR convention.", "\n", "", "frame", "=", "frame_id", ".", "replace", "(", "'_'", ",", "'-'", ")", ".", "replace", "(", "'.'", ",", "'-'", ")", "# AMR use dash", "\n", "# Put them together.", "\n", "frame_obj", "=", "Frame", "(", "frame", ",", "frame_lemma", ",", "sense", ")", "\n", "\n", "# Update", "\n", "self", ".", "frame_lemma_set", ".", "add", "(", "frame_lemma", ")", "\n", "self", ".", "_update_lemma_map", "(", "self", ".", "lemma_map", ",", "lemma", ",", "frame_obj", ")", "\n", "\n", "aliases", "=", "child", ".", "find", "(", "'aliases'", ")", "\n", "if", "aliases", ":", "\n", "                    ", "for", "alias", "in", "aliases", ".", "findall", "(", "'alias'", ")", ":", "\n", "                        ", "alias_text", "=", "alias", ".", "text", ".", "replace", "(", "'_'", ",", "'-'", ")", "\n", "if", "alias_text", "!=", "frame_lemma", "and", "alias_text", "not", "in", "self", ".", "lemma_map", ":", "\n", "                            ", "self", ".", "_update_lemma_map", "(", "self", ".", "lemma_map", ",", "alias_text", ",", "frame_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.propbank_reader.PropbankReader._update_lemma_map": [[80, 84], ["obj[].add", "set"], "methods", ["None"], ["", "", "", "", "", "", "def", "_update_lemma_map", "(", "self", ",", "obj", ",", "key", ",", "value", ")", ":", "\n", "        ", "if", "key", "not", "in", "obj", ":", "\n", "            ", "obj", "[", "key", "]", "=", "set", "(", ")", "\n", "", "obj", "[", "key", "]", ".", "add", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.io.AMRIO.__init__": [[7, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.io.AMRIO.read": [[10, 52], ["open", "stog.data.dataset_readers.amr_parsing.amr.AMR", "line.rstrip.rstrip.rstrip", "len", "stog.data.dataset_readers.amr_parsing.amr.AMRGraph.decode", "stog.data.dataset_readers.amr_parsing.amr.AMR.graph.set_src_tokens", "line.rstrip.rstrip.startswith", "stog.data.dataset_readers.amr_parsing.amr.AMR.get_src_tokens", "len", "stog.data.dataset_readers.amr_parsing.amr.AMRGraph.decode", "stog.data.dataset_readers.amr_parsing.amr.AMR.graph.set_src_tokens", "stog.data.dataset_readers.amr_parsing.amr.AMR", "line.rstrip.rstrip.startswith", "graph_lines.append", "stog.data.dataset_readers.amr_parsing.amr.AMR.get_src_tokens", "line.rstrip.rstrip.startswith", "line.rstrip.rstrip.startswith", "len", "json.loads", "line.rstrip.rstrip.startswith", "len", "json.loads", "line.rstrip.rstrip.startswith", "json.loads", "line.rstrip.rstrip.startswith", "len", "json.loads", "line.rstrip.rstrip.startswith", "len", "json.loads", "misc_lines.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.set_src_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_src_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.set_src_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_src_tokens"], ["", "@", "staticmethod", "\n", "def", "read", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "amr", "=", "AMR", "(", ")", "\n", "graph_lines", "=", "[", "]", "\n", "misc_lines", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                    ", "if", "len", "(", "graph_lines", ")", "!=", "0", ":", "\n", "                        ", "amr", ".", "graph", "=", "AMRGraph", ".", "decode", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "amr", ".", "graph", ".", "set_src_tokens", "(", "amr", ".", "get_src_tokens", "(", ")", ")", "\n", "amr", ".", "misc", "=", "misc_lines", "\n", "yield", "amr", "\n", "amr", "=", "AMR", "(", ")", "\n", "", "graph_lines", "=", "[", "]", "\n", "misc_lines", "=", "[", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::'", ")", ":", "\n", "                    ", "if", "line", ".", "startswith", "(", "'# ::id '", ")", ":", "\n", "                        ", "amr", ".", "id", "=", "line", "[", "len", "(", "'# ::id '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::snt '", ")", ":", "\n", "                        ", "amr", ".", "sentence", "=", "line", "[", "len", "(", "'# ::snt '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::tokens '", ")", ":", "\n", "                        ", "amr", ".", "tokens", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::tokens '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::lemmas '", ")", ":", "\n", "                        ", "amr", ".", "lemmas", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::lemmas '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::pos_tags '", ")", ":", "\n", "                        ", "amr", ".", "pos_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::pos_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::ner_tags '", ")", ":", "\n", "                        ", "amr", ".", "ner_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::ner_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::abstract_map '", ")", ":", "\n", "                        ", "amr", ".", "abstract_map", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::abstract_map '", ")", ":", "]", ")", "\n", "", "else", ":", "\n", "                        ", "misc_lines", ".", "append", "(", "line", ")", "\n", "", "", "else", ":", "\n", "                    ", "graph_lines", ".", "append", "(", "line", ")", "\n", "\n", "", "", "if", "len", "(", "graph_lines", ")", "!=", "0", ":", "\n", "                ", "amr", ".", "graph", "=", "AMRGraph", ".", "decode", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "amr", ".", "graph", ".", "set_src_tokens", "(", "amr", ".", "get_src_tokens", "(", ")", ")", "\n", "amr", ".", "misc", "=", "misc_lines", "\n", "yield", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.io.AMRIO.dump": [[53, 57], ["f.write", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "", "", "@", "staticmethod", "\n", "def", "dump", "(", "amr_instances", ",", "f", ")", ":", "\n", "        ", "for", "amr", "in", "amr_instances", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "amr", ")", "+", "'\\n\\n'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.__init__": [[28, 40], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "senseless_node_counter", "=", "None", ",", "\n", "lemma_frame_counter", "=", "None", ",", "\n", "frame_lemma_counter", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "senseless_node_counter", "=", "senseless_node_counter", "\n", "self", ".", "lemma_frame_counter", "=", "lemma_frame_counter", "\n", "self", ".", "frame_lemma_counter", "=", "frame_lemma_counter", "\n", "\n", "self", ".", "frequent_senseless_nodes", "=", "None", "\n", "self", ".", "lemma_frame_map", "=", "None", "\n", "self", ".", "frame_lemma_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_lemmas": [[41, 53], ["re.sub", "list", "list.sort", "editdistance.eval"], "methods", ["None"], ["", "def", "get_lemmas", "(", "self", ",", "frame", ")", ":", "\n", "        ", "\"\"\"\n        Given a frame, find the most likely lemmas for the frame.\n        If no lemma is found, return a single element list [frame].\n        \"\"\"", "\n", "if", "frame", "not", "in", "self", ".", "frame_lemma_map", ":", "\n", "            ", "return", "[", "frame", "]", "\n", "", "else", ":", "\n", "            ", "frame_lemma", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "frame", ")", "\n", "lemmas", "=", "list", "(", "self", ".", "frame_lemma_map", "[", "frame", "]", ")", "\n", "lemmas", ".", "sort", "(", "key", "=", "lambda", "lemma", ":", "editdistance", ".", "eval", "(", "frame_lemma", ",", "lemma", ")", ",", "reverse", "=", "True", ")", "\n", "return", "lemmas", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_frames": [[54, 71], ["list", "list.sort", "editdistance.eval", "re.sub", "re.search", "int"], "methods", ["None"], ["", "", "def", "get_frames", "(", "self", ",", "lemma", ")", ":", "\n", "        ", "\"\"\"\n        Given a lemma, find the most likely frames for the lemma.\n        If no lemma is found or it should be a senseless node, return a single element list [lemma].\n        \"\"\"", "\n", "if", "lemma", "in", "self", ".", "frequent_senseless_nodes", "or", "lemma", "not", "in", "self", ".", "lemma_frame_map", ":", "\n", "            ", "return", "[", "lemma", "]", "\n", "", "else", ":", "\n", "            ", "frames", "=", "list", "(", "self", ".", "lemma_frame_map", "[", "lemma", "]", ")", "\n", "frames", ".", "sort", "(", "\n", "key", "=", "lambda", "frame", ":", "(", "\n", "editdistance", ".", "eval", "(", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "frame", ")", ",", "lemma", ")", ",", "\n", "-", "int", "(", "frame", "[", "-", "2", ":", "]", ")", "if", "re", ".", "search", "(", "r'-\\d\\d$'", ",", "frame", ")", "else", "0", "\n", ")", ",", "\n", "reverse", "=", "True", "\n", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.from_json": [[72, 88], ["cls", "cls._get_frequent_senseless_nodes", "cls._get_map_from_counter", "cls._get_map_from_counter", "open", "collections.Counter", "open", "json.load", "open", "json.load", "os.path.join", "json.load", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_frequent_senseless_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_map_from_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_map_from_counter", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "", "@", "classmethod", "\n", "def", "from_json", "(", "cls", ",", "json_dir", ",", "frequent_threshold", "=", "50", ")", ":", "\n", "        ", "nu", "=", "cls", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_dir", ",", "'senseless_node_counter.json'", ")", ")", "as", "f", ":", "\n", "            ", "nu", ".", "senseless_node_counter", "=", "Counter", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_dir", ",", "'lemma_frame_counter.json'", ")", ")", "as", "f", ":", "\n", "            ", "nu", ".", "lemma_frame_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_dir", ",", "'frame_lemma_counter.json'", ")", ")", "as", "f", ":", "\n", "            ", "nu", ".", "frame_lemma_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "nu", ".", "frequent_senseless_nodes", "=", "nu", ".", "_get_frequent_senseless_nodes", "(", "\n", "nu", ".", "senseless_node_counter", ",", "frequent_threshold", "\n", ")", "\n", "nu", ".", "lemma_frame_map", "=", "nu", ".", "_get_map_from_counter", "(", "nu", ".", "lemma_frame_counter", ")", "\n", "nu", ".", "frame_lemma_map", "=", "nu", ".", "_get_map_from_counter", "(", "nu", ".", "frame_lemma_counter", ")", "\n", "return", "nu", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.from_raw": [[89, 131], ["cls._get_senseless_node_counter", "dict", "dict", "cls", "cls._update_counter_from_train_files", "stog.data.dataset_readers.amr_parsing.propbank_reader.PropbankReader", "cls._update_counter_from_propbank", "cls._update_counter_from_verbalization", "cls._get_frequent_senseless_nodes", "cls._get_map_from_counter", "cls._get_map_from_counter", "cls.dump"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_senseless_node_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_train_files", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_propbank", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_verbalization", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_frequent_senseless_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_map_from_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_map_from_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "@", "classmethod", "\n", "def", "from_raw", "(", "cls", ",", "amr_train_files", ",", "propbank_dir", ",", "verbalization_file", ",", "dump_dir", ",", "\n", "# Hyperparameters", "\n", "train_file_base_freq", "=", "1", ",", "\n", "propbank_base_freq", "=", "1", ",", "\n", "propbank_bonus", "=", "10", ",", "\n", "verbalization_base_freq", "=", "1", ",", "\n", "verbalize_freq", "=", "100", ",", "\n", "maybe_verbalize_freq", "=", "1", ",", "\n", "verbalize_bonus", "=", "10", "\n", ")", ":", "\n", "\n", "# counter[senseless_node]: the occurrence of senseless_node", "\n", "        ", "senseless_node_counter", "=", "cls", ".", "_get_senseless_node_counter", "(", "amr_train_files", ")", "\n", "# counter[lemma][frame]: the co-occurrence of (lemma, frame)", "\n", "lemma_frame_counter", "=", "dict", "(", ")", "\n", "# counter[frame][lemma]: the co-occurrence of (frame, lemma)", "\n", "frame_lemma_counter", "=", "dict", "(", ")", "\n", "\n", "nu", "=", "cls", "(", "\n", "senseless_node_counter", "=", "senseless_node_counter", ",", "\n", "lemma_frame_counter", "=", "lemma_frame_counter", ",", "\n", "frame_lemma_counter", "=", "frame_lemma_counter", "\n", ")", "\n", "nu", ".", "_update_counter_from_train_files", "(", "amr_train_files", ",", "train_file_base_freq", ")", "\n", "propbank_reader", "=", "PropbankReader", "(", "propbank_dir", ")", "\n", "nu", ".", "_update_counter_from_propbank", "(", "propbank_reader", ",", "propbank_base_freq", ",", "propbank_bonus", ")", "\n", "nu", ".", "_update_counter_from_verbalization", "(", "\n", "verbalization_file", ",", "\n", "verbalization_base_freq", ",", "\n", "verbalize_freq", ",", "\n", "maybe_verbalize_freq", ",", "\n", "verbalize_bonus", "\n", ")", "\n", "\n", "nu", ".", "frequent_senseless_nodes", "=", "cls", ".", "_get_frequent_senseless_nodes", "(", "senseless_node_counter", ")", "\n", "nu", ".", "frame_lemma_map", "=", "nu", ".", "_get_map_from_counter", "(", "nu", ".", "frame_lemma_counter", ")", "\n", "nu", ".", "lemma_frame_map", "=", "nu", ".", "_get_map_from_counter", "(", "nu", ".", "lemma_frame_counter", ")", "\n", "\n", "nu", ".", "dump", "(", "dump_dir", ")", "\n", "\n", "return", "nu", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_senseless_node_counter": [[132, 142], ["logger.info", "collections.Counter", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "amr.graph.get_nodes", "node.get_senseless_attributes", "sense_less_nodes.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.get_senseless_attributes"], ["", "@", "staticmethod", "\n", "def", "_get_senseless_node_counter", "(", "amr_train_files", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Building the senseless node counter.'", ")", "\n", "sense_less_nodes", "=", "[", "]", "\n", "for", "amr_file", "in", "amr_train_files", ":", "\n", "            ", "for", "amr", "in", "AMRIO", ".", "read", "(", "amr_file", ")", ":", "\n", "                ", "for", "node", "in", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "                    ", "for", "attr", ",", "value", "in", "node", ".", "get_senseless_attributes", "(", ")", ":", "\n", "                        ", "sense_less_nodes", ".", "append", "(", "value", ")", "\n", "", "", "", "", "return", "Counter", "(", "sense_less_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_frequent_senseless_nodes": [[143, 150], ["set", "senseless_node_counter.most_common", "set.add"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_frequent_senseless_nodes", "(", "senseless_node_counter", ",", "threshold", "=", "50", ")", ":", "\n", "        ", "frequent_senseless_nodes", "=", "set", "(", ")", "\n", "for", "node", ",", "count", "in", "senseless_node_counter", ".", "most_common", "(", ")", ":", "\n", "            ", "if", "count", ">=", "threshold", ":", "# hard threshold", "\n", "                ", "frequent_senseless_nodes", ".", "add", "(", "node", ")", "\n", "", "", "return", "frequent_senseless_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_train_files": [[151, 160], ["logger.info", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "amr.graph.get_nodes", "node.get_frame_attributes", "re.sub", "node_utils.NodeUtilities._update_counter", "node_utils.NodeUtilities._update_counter"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.get_frame_attributes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter"], ["", "def", "_update_counter_from_train_files", "(", "self", ",", "amr_train_files", ",", "base_freq", "=", "1", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Updating (lemma, frame) counter from AMR train files.'", ")", "\n", "for", "file_path", "in", "amr_train_files", ":", "\n", "            ", "for", "amr", "in", "AMRIO", ".", "read", "(", "file_path", ")", ":", "\n", "                ", "for", "node", "in", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "                    ", "for", "_", ",", "frame", "in", "node", ".", "get_frame_attributes", "(", ")", ":", "\n", "                        ", "frame_lemma", "=", "re", ".", "sub", "(", "WORDSENSE_RE", ",", "''", ",", "frame", ")", "\n", "self", ".", "_update_counter", "(", "self", ".", "lemma_frame_counter", ",", "frame_lemma", ",", "frame", ",", "base_freq", ")", "\n", "self", ".", "_update_counter", "(", "self", ".", "frame_lemma_counter", ",", "frame", ",", "frame_lemma", ",", "base_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_propbank": [[161, 170], ["logger.info", "propbank_reader.lemma_map.items", "node_utils.NodeUtilities._update_counter", "node_utils.NodeUtilities._update_counter"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter"], ["", "", "", "", "", "def", "_update_counter_from_propbank", "(", "self", ",", "propbank_reader", ",", "base_freq", "=", "1", ",", "bonus", "=", "10", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Updating (lemma, frame) counter from Propbank.'", ")", "\n", "for", "lemma", ",", "frames", "in", "propbank_reader", ".", "lemma_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "frame", "in", "frames", ":", "\n", "                ", "freq", "=", "base_freq", "\n", "if", "lemma", "==", "frame", ".", "lemma", ":", "# bonus the frame lemma.", "\n", "                    ", "freq", "*=", "bonus", "\n", "", "self", ".", "_update_counter", "(", "self", ".", "lemma_frame_counter", ",", "lemma", ",", "frame", ".", "frame", ",", "freq", ")", "\n", "self", ".", "_update_counter", "(", "self", ".", "frame_lemma_counter", ",", "frame", ".", "frame", ",", "lemma", ",", "freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter_from_verbalization": [[171, 196], ["logger.info", "open", "line.strip().split", "re.sub", "node_utils.NodeUtilities._update_counter", "node_utils.NodeUtilities._update_counter", "line.strip", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "", "", "def", "_update_counter_from_verbalization", "(", "\n", "self", ",", "verbalization_file", ",", "\n", "base_freq", "=", "1", ",", "\n", "verbalize_freq", "=", "100", ",", "\n", "maybe_verbalize_freq", "=", "1", ",", "\n", "bonus", "=", "10", ",", "\n", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Updating (lemma, frame) counter from Verbalization.'", ")", "\n", "with", "open", "(", "verbalization_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "parts", ")", "==", "4", "and", "parts", "[", "0", "]", "in", "(", "'VERBALIZE'", ",", "'MAYBE-VERBALIZE'", ")", ":", "\n", "                    ", "lemma", "=", "parts", "[", "1", "]", "\n", "frame", "=", "parts", "[", "3", "]", "\n", "frame_lemma", "=", "re", ".", "sub", "(", "WORDSENSE_RE", ",", "''", ",", "frame", ")", "\n", "\n", "freq", "=", "verbalize_freq", "if", "parts", "[", "0", "]", "==", "'VERBALIZE'", "else", "maybe_verbalize_freq", "\n", "if", "lemma", "==", "frame_lemma", ":", "# bonus frame lemma", "\n", "                        ", "freq", "*=", "bonus", "\n", "", "self", ".", "_update_counter", "(", "self", ".", "lemma_frame_counter", ",", "lemma", ",", "frame", ",", "freq", ")", "\n", "\n", "freq", "=", "base_freq", "\n", "if", "lemma", "==", "frame_lemma", ":", "# bonus frame lemma", "\n", "                        ", "freq", "*=", "bonus", "\n", "", "self", ".", "_update_counter", "(", "self", ".", "frame_lemma_counter", ",", "frame", ",", "lemma", ",", "freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._get_map_from_counter": [[197, 211], ["set", "sorted", "counter[].items", "set.add"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "", "", "@", "staticmethod", "\n", "def", "_get_map_from_counter", "(", "counter", ")", ":", "\n", "        ", "map_dict", "=", "{", "}", "\n", "for", "key1", "in", "counter", ":", "\n", "            ", "freq_key2_set", "=", "set", "(", ")", "\n", "highest_freq", "=", "0", "\n", "for", "key2", ",", "freq", "in", "sorted", "(", "counter", "[", "key1", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ":", "\n", "                ", "if", "freq", ">=", "highest_freq", ":", "\n", "                    ", "highest_freq", "=", "freq", "\n", "freq_key2_set", ".", "add", "(", "key2", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "map_dict", "[", "key1", "]", "=", "freq_key2_set", "\n", "", "return", "map_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities._update_counter": [[212, 219], ["dict"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_update_counter", "(", "obj", ",", "key1", ",", "key2", ",", "value", ")", ":", "\n", "        ", "if", "key1", "not", "in", "obj", ":", "\n", "            ", "obj", "[", "key1", "]", "=", "dict", "(", ")", "\n", "", "if", "key2", "not", "in", "obj", "[", "key1", "]", ":", "\n", "            ", "obj", "[", "key1", "]", "[", "key2", "]", "=", "0", "\n", "", "obj", "[", "key1", "]", "[", "key2", "]", "+=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump": [[220, 245], ["logger.info", "open", "open", "json.dump", "open", "open", "json.dump", "open", "node_utils.NodeUtilities.senseless_node_counter.most_common", "open", "json.dump", "os.path.join", "f.write", "sorted", "f.write", "os.path.join", "os.path.join", "f.write", "sorted", "f.write", "os.path.join", "os.path.join", "f.write", "os.path.join", "node_utils.NodeUtilities.lemma_frame_counter[].items", "f.write", "node_utils.NodeUtilities.frame_lemma_counter[].items", "f.write"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "def", "dump", "(", "self", ",", "directory", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Dumping Node utilities to {}.'", ".", "format", "(", "directory", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'lemma_frame_counter'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "lemma", "in", "self", ".", "lemma_frame_counter", ":", "\n", "                ", "f", ".", "write", "(", "lemma", "+", "':\\n'", ")", "\n", "for", "frame", ",", "freq", "in", "sorted", "(", "self", ".", "lemma_frame_counter", "[", "lemma", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ":", "\n", "                    ", "f", ".", "write", "(", "'\\t{}\\t{}\\n'", ".", "format", "(", "frame", ",", "freq", ")", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'lemma_frame_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "lemma_frame_counter", ",", "f", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'frame_lemma_counter'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "frame", "in", "self", ".", "frame_lemma_counter", ":", "\n", "                ", "f", ".", "write", "(", "frame", "+", "':\\n'", ")", "\n", "for", "lemma", ",", "freq", "in", "sorted", "(", "self", ".", "frame_lemma_counter", "[", "frame", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ":", "\n", "                    ", "f", ".", "write", "(", "'\\t{}\\t{}\\n'", ".", "format", "(", "lemma", ",", "freq", ")", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'frame_lemma_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "frame_lemma_counter", ",", "f", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'senseless_node_counter'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "value", "in", "self", ".", "senseless_node_counter", ".", "most_common", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'senseless_node_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "senseless_node_counter", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.is_sense_string": [[18, 20], ["isinstance", "WORDSENSE_RE.search"], "function", ["None"], ["def", "is_sense_string", "(", "s", ")", ":", "\n", "    ", "return", "isinstance", "(", "s", ",", "str", ")", "and", "WORDSENSE_RE", ".", "search", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.is_quoted_string": [[22, 24], ["isinstance", "QUOTED_RE.search"], "function", ["None"], ["", "def", "is_quoted_string", "(", "s", ")", ":", "\n", "    ", "return", "isinstance", "(", "s", ",", "str", ")", "and", "QUOTED_RE", ".", "search", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.__init__": [[30, 51], ["None"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "node_list", "=", "None", ",", "node_value_list", "=", "None", ",", "relation_list", "=", "None", ",", "attribute_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.is_named_entity": [[52, 54], ["None"], "methods", ["None"], ["", "else", ":", "\n", "            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.get_named_entity_span": [[55, 69], ["span.append", "span.append", "amr.AMR.is_named_entity", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.is_named_entity"], ["                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list", "[", ":", "]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.find_span_indexes": [[70, 77], ["enumerate", "all", "list", "len", "len", "range", "len", "zip", "len"], "methods", ["None"], ["\n", "", "", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span": [[78, 87], ["None"], "methods", ["None"], ["for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "node_relations", "in", "self", ".", "relations", ":", "\n", "            ", "for", "i", ",", "l", "in", "enumerate", "(", "node_relations", ")", ":", "\n", "                ", "node_relations", "[", "i", "]", "[", "1", "]", "=", "node_map_dict", "[", "l", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.remove_span": [[88, 90], ["amr.AMR.replace_span"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.__repr__": [[91, 116], ["dict().items", "dict", "fields.append", "fields.append", "str", "isinstance", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# l[0] is relation name", "\n", "# l[1] is the other node this node has relation with", "\n", "for", "l", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "# l[0] is the attribute name", "\n", "# l[1] is the attribute value", "\n", "", "for", "l", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n", "\n", "\n", "", "def", "get_triples2", "(", "self", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.get_src_tokens": [[117, 119], ["amr.AMR.sentence.split"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.__init__": [[128, 137], ["None"], "methods", ["None"], ["# l[0] is relation name", "\n", "# l[1] is the other node this node has relation with", "\n", "for", "l", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "# l[0] is the attribute name", "\n", "# l[1] is the attribute value", "\n", "", "for", "l", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "l", "[", "0", "]", ",", "self", ".", "nodes", "[", "i", "]", ",", "l", "[", "1", "]", ")", ")", "\n", "", "", "return", "instance_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode._sort_attributes": [[138, 147], ["amr.AMRNode.attributes.sort", "re.search", "amr.AMRNode.attribute_priority.index", "len", "amr.AMRNode._sort_attributes.get_attr_priority"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["\n", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.__hash__": [[148, 150], ["hash"], "methods", ["None"], ["lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "relation", "in", "self", ".", "relations", "[", "i", "]", ":", "\n", "                ", "lines", ".", "append", "(", "\"Node \"", "+", "relation", "[", "1", "]", "+", "\" via \"", "+", "relation", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.__eq__": [[151, 155], ["isinstance"], "methods", ["None"], ["", "for", "attribute", "in", "self", ".", "attributes", "[", "i", "]", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "attribute", "[", "0", "]", "+", "\" value \"", "+", "attribute", "[", "1", "]", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.__repr__": [[156, 163], ["str"], "methods", ["None"], ["        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n", "", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", "(", "self", ".", "__str__", "(", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.__str__": [[164, 171], ["repr"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "get_amr_line", "(", "input_f", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.instance": [[172, 179], ["None"], "methods", ["None"], ["\n", "cur_amr", "=", "[", "]", "\n", "has_content", "=", "False", "\n", "for", "line", "in", "input_f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                ", "if", "not", "has_content", ":", "\n", "# empty lines before current AMR", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.ops": [[180, 189], ["len", "re.search", "ops.sort", "ops.append", "int"], "methods", ["None"], ["                    ", "continue", "\n", "", "else", ":", "\n", "# end of current AMR", "\n", "                    ", "break", "\n", "", "", "if", "line", ".", "strip", "(", ")", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "# ignore the comment line (starting with \"#\") in the AMR file", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "has_content", "=", "True", "\n", "cur_amr", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy": [[190, 197], ["amr.AMRNode"], "methods", ["None"], ["", "", "return", "\"\"", ".", "join", "(", "cur_amr", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.remove_attribute": [[198, 200], ["amr.AMRNode.attributes.remove"], "methods", ["None"], ["\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.add_attribute": [[201, 203], ["amr.AMRNode.attributes.append"], "methods", ["None"], ["# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.replace_attribute": [[204, 207], ["amr.AMRNode.attributes.index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "\n", "exceptions", "=", "set", "(", "[", "\"prep-on-behalf-of\"", ",", "\"prep-out-of\"", ",", "\"consist-of\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.get_frame_attributes": [[208, 212], ["isinstance", "re.search"], "methods", ["None"], ["def", "update_triple", "(", "node_relation_dict", ",", "triple", ")", ":", "\n", "# we detect a relation (r) between u and v, with direction u to v.", "\n", "# in most cases, if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.get_senseless_attributes": [[213, 217], ["isinstance", "re.search"], "methods", ["None"], ["# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "# but note some exceptions like \"prep-on-behalf-of\" and \"prep-out-of\"", "\n", "# also note relation \"mod\" is the reverse of \"domain\"", "\n", "            ", "u", ",", "r", ",", "v", "=", "triple", "\n", "if", "r", ".", "endswith", "(", "\"-of\"", ")", "and", "not", "r", "in", "exceptions", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.__init__": [[232, 238], ["penman.Graph.__init__", "amr.AMRGraph._build_extras"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._build_extras"], ["node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.__str__": [[239, 242], ["penman.alphanum_order", "amr_codec.encode"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.encode"], ["# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._build_extras": [[243, 279], ["networkx.DiGraph", "amr.AMRGraph.variables", "set", "amr.AMRGraph.edges", "amr.AMRNode", "networkx.DiGraph.add_node", "set.add", "networkx.DiGraph.add_edge", "type", "type", "target.copy.copy.copy", "amr.AMRGraph.attributes", "amr_codec.invert_relation"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.attributes"], ["# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", "(", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.attributes": [[280, 291], ["amr.AMRGraph.variables", "list", "filter", "amr.AMRGraph.triples"], "methods", ["None"], ["", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph": [[292, 296], ["amr.AMRGraph.variables"], "methods", ["None"], ["# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_name_node": [[297, 300], ["list", "any", "amr.AMRGraph._G.in_edges", "[].get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_type": [[301, 307], ["list", "amr.AMRGraph._G.in_edges", "[].get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_wiki": [[308, 318], ["list", "amr.AMRGraph._G.in_edges", "[].get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["                        ", "print", "(", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict2", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.set_name_node_wiki": [[319, 330], ["list", "amr.AMRGraph._G.in_edges", "amr.AMRGraph.add_node_attribute", "[].get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", "(", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_date_node": [[331, 333], ["None"], "methods", ["None"], ["# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge": [[334, 340], ["amr.AMRGraph._G.add_edge", "penman.Triple", "penman.alphanum_order", "amr.AMRGraph._update_penman_graph"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph"], ["node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge": [[341, 350], ["isinstance", "isinstance", "amr.AMRGraph._update_penman_graph", "isinstance", "isinstance", "amr.AMRGraph._G.remove_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge"], ["if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "2", "]", ",", "cur_relation_name", ",", "node_name", ")", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", "(", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.update_edge_label": [[351, 359], ["amr.AMRGraph._update_penman_graph", "triples.append", "penman.Triple"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph"], ["                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", "(", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node": [[360, 374], ["identifier.isalpha", "penman.alphanum_order", "amr.AMRNode", "amr.AMRGraph._G.add_node", "amr.AMRGraph.variables", "str", "amr.AMRGraph.variables", "penman.Triple", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node"], ["# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict2", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node": [[375, 379], ["amr.AMRGraph._G.remove_node", "amr.AMRGraph._update_penman_graph"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph"], ["", "else", ":", "\n", "                        ", "update_triple", "(", "node_relation_dict1", ",", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "# Last significant symbol is \"/\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute": [[380, 392], ["node.replace_attribute", "penman.alphanum_order", "triples.append", "penman.Triple"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.replace_attribute"], ["# we get \"nation\" here", "\n", "", "", "elif", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# map node name to its value", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# pop from stack, as the current node has been processed", "\n", "", "stack", ".", "pop", "(", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "state", "=", "0", "\n", "", "else", ":", "\n", "# not significant symbols, so we just shift.", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute": [[393, 397], ["node.remove_attribute", "amr.AMRGraph._update_penman_graph"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.remove_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph._update_penman_graph"], ["                ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "#create data structures to initialize an AMR", "\n", "", "", "node_value_list", "=", "[", "]", "\n", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute": [[398, 402], ["node.add_attribute", "penman.Triple", "penman.alphanum_order"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.add_attribute"], ["for", "v", "in", "node_name_list", ":", "\n", "            ", "if", "v", "not", "in", "node_dict", ":", "\n", "                ", "print", "(", "\"Error: Node name not found\"", ",", "v", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_ops": [[403, 410], ["re.search", "amr.AMRGraph.remove_node_attribute", "ops.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["                ", "node_value_list", ".", "append", "(", "node_dict", "[", "v", "]", ")", "\n", "# build relation list and attribute list for this node", "\n", "", "node_rel_list", "=", "[", "]", "\n", "node_attr_list", "=", "[", "]", "\n", "if", "v", "in", "node_relation_dict1", ":", "\n", "                ", "for", "v1", "in", "node_relation_dict1", "[", "v", "]", ":", "\n", "                    ", "node_rel_list", ".", "append", "(", "[", "v1", "[", "0", "]", ",", "v1", "[", "1", "]", "]", ")", "\n", "", "", "if", "v", "in", "node_relation_dict2", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree": [[411, 424], ["set", "list", "amr.AMRGraph._G.edges", "amr.AMRGraph.remove_edge", "children.append", "len", "amr.AMRGraph.remove_node", "set.add", "len", "set.update", "list", "list", "amr.AMRGraph.remove_subtree", "amr.AMRGraph._G.in_edges", "amr.AMRGraph._G.in_edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree"], ["                ", "for", "v2", "in", "node_relation_dict2", "[", "v", "]", ":", "\n", "# if value is in quote, it is a constant value", "\n", "# strip the quote and put it in attribute map", "\n", "                    ", "if", "v2", "[", "1", "]", "[", "0", "]", "==", "\"\\\"\"", "and", "v2", "[", "1", "]", "[", "-", "1", "]", "==", "\"\\\"\"", ":", "\n", "                        ", "assert", "True", "==", "False", "\n", "node_attr_list", ".", "append", "(", "[", "[", "v2", "[", "0", "]", "]", ",", "v2", "[", "1", "]", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "# if value is a node name", "\n", "", "elif", "v2", "[", "1", "]", "in", "node_dict", ":", "\n", "                        ", "node_rel_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                        ", "node_attr_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "# each node has a relation list and attribute list", "\n", "", "", "", "relation_list", ".", "append", "(", "node_rel_list", ")", "\n", "attribute_list", ".", "append", "(", "node_attr_list", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree": [[425, 435], ["amr.AMRGraph._G.edges", "len", "list", "amr.AMRGraph.get_subtree", "amr.AMRGraph._G.in_edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree"], ["# add TOP as an attribute. The attribute value is the top node value", "\n", "", "attribute_list", "[", "0", "]", ".", "append", "(", "[", "\"TOP\"", ",", "node_value_list", "[", "0", "]", "]", ")", "\n", "result_amr", "=", "AMR", "(", "node_name_list", ",", "node_value_list", ",", "relation_list", ",", "attribute_list", ")", "\n", "return", "result_amr", "\n", "\n", "# test AMR parsing", "\n", "# run by amr.py [file containing AMR]", "\n", "# a unittest can also be used.", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "if", "len", "(", "sys", ".", "argv", ")", "<", "2", ":", "\n", "        ", "print", "(", "\"No file given\"", ",", "file", "=", "ERROR_LOG", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes": [[436, 438], ["None"], "methods", ["None"], ["exit", "(", "1", ")", "\n", "", "amr_count", "=", "1", "\n", "for", "line", "in", "open", "(", "sys", ".", "argv", "[", "1", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_edges": [[439, 441], ["None"], "methods", ["None"], ["        ", "cur_line", "=", "line", ".", "strip", "(", ")", "\n", "if", "cur_line", "==", "\"\"", "or", "cur_line", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "            ", "continue", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.set_src_tokens": [[442, 446], ["type", "sentence.split.split.split"], "methods", ["None"], ["", "print", "(", "\"AMR\"", ",", "amr_count", ",", "file", "=", "DEBUG_LOG", ")", "\n", "current", "=", "AMR", ".", "parse_AMR_line", "(", "cur_line", ")", "\n", "current", ".", "output_amr", "(", ")", "\n", "amr_count", "+=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_src_tokens": [[447, 449], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node": [[450, 473], ["collections.defaultdict", "amr.AMRGraph.get_list_node.dfs"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.sort_edges": [[474, 476], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_tgt_tokens": [[477, 496], ["amr.AMRGraph.get_list_node", "collections.defaultdict", "tgt_token.append", "len", "str", "len", "tgt_token.append", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_data": [[499, 635], ["amr.AMRGraph.get_list_node", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict.items", "enumerate", "collections.Counter", "enumerate", "amr.AMRGraph.get_src_tokens", "amr.SourceCopyVocabulary", "amr.SourceCopyVocabulary.index_sequence", "amr.SourceCopyVocabulary.get_copy_map", "amr.AMRGraph.get_list_data.add_source_side_tags_to_target_side"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_src_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.index_sequence", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_copy_map"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode": [[637, 641], ["amr_codec.decode", "cls"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.decode"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.from_lists": [[642, 670], ["collections.defaultdict", "enumerate", "zip", "Triples.append", "Triples.append", "variables.append", "penman.Triple", "penman.Triple", "variables.append", "variables.append", "str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.from_prediction": [[673, 771], ["amr.AMRGraph.from_prediction.correct_multiroot"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.__init__": [[774, 792], ["type", "sentence.split.split.split"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_from_idx": [[793, 795], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_idx": [[796, 798], ["amr.SourceCopyVocabulary.token_to_idx.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.index_sequence": [[799, 801], ["amr.SourceCopyVocabulary.get_token_idx"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_idx"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_copy_map": [[802, 806], ["amr.SourceCopyVocabulary.index_sequence", "amr.SourceCopyVocabulary.get_token_idx", "enumerate"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.index_sequence", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_token_idx"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.get_special_tok_list": [[808, 810], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.SourceCopyVocabulary.__repr__": [[811, 813], ["json.dumps"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.__init__": [[23, 26], ["set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "graph", ")", ":", "\n", "        ", "self", ".", "graph", "=", "graph", "\n", "self", ".", "repaired_items", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.do": [[27, 32], ["graph_repair.GraphRepair", "graph_repair.GraphRepair.remove_redundant_edges", "graph_repair.GraphRepair.remove_unknown_nodes"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.remove_redundant_edges", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.remove_unknown_nodes"], ["", "@", "staticmethod", "\n", "def", "do", "(", "graph", ")", ":", "\n", "        ", "gr", "=", "GraphRepair", "(", "graph", ")", "\n", "gr", ".", "remove_redundant_edges", "(", ")", "\n", "gr", ".", "remove_unknown_nodes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.remove_unknown_nodes": [[33, 46], ["graph.get_nodes", "graph.remove_node_attribute", "len", "list", "graph.remove_node", "graph_repair.GraphRepair.repaired_items.add", "list", "graph._G.in_edges", "graph.remove_edge", "graph._G.edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge"], ["", "def", "remove_unknown_nodes", "(", "self", ")", ":", "\n", "        ", "graph", "=", "self", ".", "graph", "\n", "nodes", "=", "[", "node", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", "]", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "value", "==", "'@@UNKNOWN@@'", "and", "attr", "!=", "'instance'", ":", "\n", "                    ", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "", "", "if", "node", ".", "instance", "==", "'@@UNKNOWN@@'", ":", "\n", "                ", "if", "len", "(", "list", "(", "graph", ".", "_G", ".", "edges", "(", "node", ")", ")", ")", "==", "0", ":", "\n", "                    ", "for", "source", ",", "target", "in", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ")", ":", "\n", "                        ", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "", "graph", ".", "remove_node", "(", "node", ")", "\n", "self", ".", "repaired_items", ".", "add", "(", "'remove-unknown-node'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.GraphRepair.remove_redundant_edges": [[47, 107], ["set", "list", "collections.defaultdict", "collections.defaultdict.items", "graph.get_nodes", "graph._G.edges", "set", "enumerate", "edge_counter[].append", "len", "set.add", "groups.append", "max", "label.startswith", "label.startswith", "edge_counter[].append", "edge_counter[].append", "graph_repair.is_similar", "len", "graph.remove_edge", "set.update", "graph.remove_edge", "graph.remove_node", "set.add", "graph_repair.GraphRepair.repaired_items.add", "graph.get_subtree", "group.append", "set.add", "graph.remove_subtree", "len", "len", "graph.get_subtree", "len", "list", "list", "str", "graph._G.in_edges", "graph._G.edges", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.is_similar", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree"], ["", "", "", "", "def", "remove_redundant_edges", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Edge labels such as ARGx, ARGx-of, and 'opx' should only appear at most once\n        in each node's outgoing edges.\n        \"\"\"", "\n", "graph", "=", "self", ".", "graph", "\n", "nodes", "=", "[", "node", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", "]", "\n", "removed_nodes", "=", "set", "(", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "if", "node", "in", "removed_nodes", ":", "\n", "                ", "continue", "\n", "", "edges", "=", "list", "(", "graph", ".", "_G", ".", "edges", "(", "node", ")", ")", "\n", "edge_counter", "=", "defaultdict", "(", "list", ")", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "                ", "label", "=", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "# `name`, `ARGx`, and `ARGx-of` should only appear once.", "\n", "if", "label", "==", "'name'", ":", "# or label.startswith('ARG'):", "\n", "                    ", "edge_counter", "[", "label", "]", ".", "append", "(", "target", ")", "\n", "# the target of `opx' should only appear once.", "\n", "", "elif", "label", ".", "startswith", "(", "'op'", ")", "or", "label", ".", "startswith", "(", "'snt'", ")", ":", "\n", "                    ", "edge_counter", "[", "str", "(", "target", ".", "instance", ")", "]", ".", "append", "(", "target", ")", "\n", "", "else", ":", "\n", "                    ", "edge_counter", "[", "label", "+", "str", "(", "target", ".", "instance", ")", "]", ".", "append", "(", "target", ")", "\n", "", "", "for", "label", ",", "children", "in", "edge_counter", ".", "items", "(", ")", ":", "\n", "                ", "if", "len", "(", "children", ")", "==", "1", ":", "\n", "                    ", "continue", "\n", "", "if", "label", "==", "'name'", ":", "\n", "# remove redundant edges.", "\n", "                    ", "for", "target", "in", "children", "[", "1", ":", "]", ":", "\n", "                        ", "if", "len", "(", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "target", ")", ")", ")", "==", "1", "and", "len", "(", "list", "(", "graph", ".", "_G", ".", "edges", "(", "target", ")", ")", ")", "==", "0", ":", "\n", "                            ", "graph", ".", "remove_edge", "(", "node", ",", "target", ")", "\n", "graph", ".", "remove_node", "(", "target", ")", "\n", "removed_nodes", ".", "add", "(", "target", ")", "\n", "self", ".", "repaired_items", ".", "add", "(", "'remove-redundant-edge'", ")", "\n", "", "", "continue", "\n", "", "visited_children", "=", "set", "(", ")", "\n", "groups", "=", "[", "]", "\n", "for", "i", ",", "target", "in", "enumerate", "(", "children", ")", ":", "\n", "                    ", "if", "target", "in", "visited_children", ":", "\n", "                        ", "continue", "\n", "", "subtree_instances1", "=", "[", "n", ".", "instance", "for", "n", "in", "graph", ".", "get_subtree", "(", "target", ",", "5", ")", "]", "\n", "group", "=", "[", "(", "target", ",", "subtree_instances1", ")", "]", "\n", "visited_children", ".", "add", "(", "target", ")", "\n", "for", "_t", "in", "children", "[", "i", "+", "1", ":", "]", ":", "\n", "                        ", "if", "_t", "in", "visited_children", "or", "target", ".", "instance", "!=", "_t", ".", "instance", ":", "\n", "                            ", "continue", "\n", "", "subtree_instances2", "=", "[", "n", ".", "instance", "for", "n", "in", "graph", ".", "get_subtree", "(", "_t", ",", "5", ")", "]", "\n", "if", "is_similar", "(", "subtree_instances1", ",", "subtree_instances2", ")", ":", "\n", "                            ", "group", ".", "append", "(", "(", "_t", ",", "subtree_instances2", ")", ")", "\n", "visited_children", ".", "add", "(", "_t", ")", "\n", "", "", "groups", ".", "append", "(", "group", ")", "\n", "", "for", "group", "in", "groups", ":", "\n", "                    ", "if", "len", "(", "group", ")", "==", "1", ":", "\n", "                        ", "continue", "\n", "", "kept_target", ",", "_", "=", "max", "(", "group", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ")", "\n", "for", "target", ",", "_", "in", "group", ":", "\n", "                        ", "if", "target", "==", "kept_target", ":", "\n", "                            ", "continue", "\n", "", "graph", ".", "remove_edge", "(", "node", ",", "target", ")", "\n", "removed_nodes", ".", "update", "(", "graph", ".", "remove_subtree", "(", "target", ")", ")", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.graph_repair.is_similar": [[9, 19], ["len", "len", "sum", "len", "sum", "len"], "function", ["None"], ["def", "is_similar", "(", "instances1", ",", "instances2", ")", ":", "\n", "    ", "if", "len", "(", "instances1", ")", "<", "len", "(", "instances2", ")", ":", "\n", "        ", "small", "=", "instances1", "\n", "large", "=", "instances2", "\n", "", "else", ":", "\n", "        ", "small", "=", "instances2", "\n", "large", "=", "instances1", "\n", "", "coverage1", "=", "sum", "(", "1", "for", "x", "in", "small", "if", "x", "in", "large", ")", "/", "len", "(", "small", ")", "\n", "coverage2", "=", "sum", "(", "1", "for", "x", "in", "large", "if", "x", "in", "small", ")", "/", "len", "(", "large", ")", "\n", "return", "coverage1", ">", ".8", "and", "coverage2", ">", ".8", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.Alignment.__init__": [[6, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "node", ",", "url", ",", "amr", ",", "indexes", ",", "score", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "self", ".", "url", "=", "url", "\n", "self", ".", "amr", "=", "amr", "\n", "self", ".", "aligned_token_indexes", "=", "indexes", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.Alignment.__str__": [[13, 17], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'node: {}\\nurl: {}\\naligned_token_indexes: {}\\naligned_tokens: {}'", ".", "format", "(", "\n", "self", ".", "node", ",", "self", ".", "url", ",", "self", ".", "aligned_token_indexes", ",", "\n", "' '", ".", "join", "(", "[", "self", ".", "amr", ".", "lemmas", "[", "i", "]", "for", "i", "in", "self", ".", "aligned_token_indexes", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.Alignment.begin": [[18, 23], ["min", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "begin", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_token_indexes", ")", "==", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "min", "(", "self", ".", "aligned_token_indexes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.Alignment.end": [[24, 29], ["max", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "end", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_token_indexes", ")", "==", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "max", "(", "self", ".", "aligned_token_indexes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.__init__": [[33, 37], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "amr", ",", "dry", "=", "False", ")", ":", "\n", "        ", "self", ".", "amr", "=", "amr", "\n", "self", ".", "dry", "=", "dry", "\n", "self", ".", "alignments", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.abstract": [[38, 61], ["graph.get_list_node", "url.URL.abstract_url", "url.URL.remove_redundant_url", "url.URL.abstract_url_without_alignment", "url.URL.get_url_value", "url.URL.align_url", "url.Alignment", "url.URL.alignments.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.abstract_url", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.remove_redundant_url", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.abstract_url_without_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.get_url_value", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.align_url"], ["", "def", "abstract", "(", "self", ",", "align", "=", "True", ")", ":", "\n", "        ", "url_count", "=", "0", "\n", "graph", "=", "self", ".", "amr", ".", "graph", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "node", ".", "instance", "==", "'url-entity'", ":", "\n", "                ", "url_count", "+=", "1", "\n", "url_value", "=", "self", ".", "get_url_value", "(", "node", ")", "\n", "if", "url_value", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "if", "align", ":", "\n", "                    ", "alignment", "=", "self", ".", "align_url", "(", "node", ",", "url_value", ")", "\n", "", "else", ":", "\n", "                    ", "alignment", "=", "Alignment", "(", "node", ",", "url_value", ",", "self", ".", "amr", ",", "[", "]", ",", "1", ")", "\n", "", "if", "alignment", "is", "not", "None", "and", "alignment", ".", "score", ">", "0", ":", "\n", "                    ", "self", ".", "alignments", ".", "append", "(", "alignment", ")", "\n", "", "", "", "if", "align", ":", "\n", "            ", "abstract_count", "=", "self", ".", "abstract_url", "(", ")", "\n", "self", ".", "remove_redundant_url", "(", ")", "\n", "", "else", ":", "\n", "            ", "abstract_count", "=", "self", ".", "abstract_url_without_alignment", "(", ")", "\n", "", "return", "url_count", ",", "abstract_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.abstract_url_without_alignment": [[62, 74], ["enumerate", "dict", "url.URL.amr.graph.replace_node_attribute", "map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "abstract_url_without_alignment", "(", "self", ")", ":", "\n", "        ", "count", "=", "0", "\n", "for", "i", ",", "alignment", "in", "enumerate", "(", "self", ".", "alignments", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "abstract", "=", "'URL_{}'", ".", "format", "(", "i", "+", "1", ")", "\n", "span", "=", "[", "]", "\n", "self", ".", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "dict", "(", "\n", "type", "=", "'url-entity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "self", ".", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "value", "=", "alignment", ".", "url", ")", "\n", "self", ".", "amr", ".", "graph", ".", "replace_node_attribute", "(", "alignment", ".", "node", ",", "'value'", ",", "alignment", ".", "url", ",", "abstract", ")", "\n", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.get_url_value": [[75, 84], ["url.URL.fix_url_node", "re.search"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.fix_url_node"], ["", "def", "get_url_value", "(", "self", ",", "node", ")", ":", "\n", "        ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "            ", "if", "attr", "==", "'value'", ":", "\n", "                ", "assert", "re", ".", "search", "(", "r'^\".*\"$'", ",", "value", ")", "\n", "return", "value", "\n", "", "", "try", ":", "\n", "            ", "return", "self", ".", "fix_url_node", "(", "node", ")", "\n", "", "except", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.fix_url_node": [[85, 92], ["url.URL.amr.graph.remove_edge", "url.URL.amr.graph.remove_subtree", "url.URL.amr.graph.add_node_attribute", "list", "url.URL.amr.graph._G[].items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "def", "fix_url_node", "(", "self", ",", "node", ")", ":", "\n", "        ", "name_node", "=", "list", "(", "self", ".", "amr", ".", "graph", ".", "_G", "[", "node", "]", ".", "items", "(", ")", ")", "[", "0", "]", "[", "0", "]", "\n", "url", "=", "name_node", ".", "ops", "[", "0", "]", "\n", "self", ".", "amr", ".", "graph", ".", "remove_edge", "(", "node", ",", "name_node", ")", "\n", "self", ".", "amr", ".", "graph", ".", "remove_subtree", "(", "name_node", ")", "\n", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "node", ",", "'value'", ",", "url", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.align_url": [[93, 104], ["range", "candidate_alignments.sort", "len", "url.URL.maybe_align", "len", "url.Alignment", "candidate_alignments.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.maybe_align"], ["", "def", "align_url", "(", "self", ",", "node", ",", "url", ")", ":", "\n", "        ", "candidate_alignments", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "tokens", ")", ")", ":", "\n", "            ", "score", "=", "self", ".", "maybe_align", "(", "index", ",", "url", ")", "\n", "if", "score", ">", "0", ":", "\n", "                ", "alignment", "=", "Alignment", "(", "node", ",", "url", ",", "self", ".", "amr", ",", "[", "index", "]", ",", "score", ")", "\n", "candidate_alignments", ".", "append", "(", "alignment", ")", "\n", "", "", "if", "len", "(", "candidate_alignments", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "candidate_alignments", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", ".", "score", ")", "\n", "return", "candidate_alignments", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.maybe_align": [[105, 122], ["re.sub", "re.sub", "url[].lower().replace", "re.sub.lower", "url[].lower"], "methods", ["None"], ["", "def", "maybe_align", "(", "self", ",", "index", ",", "url", ")", ":", "\n", "        ", "url", "=", "re", ".", "sub", "(", "r'http:'", ",", "'https:'", ",", "url", "[", "1", ":", "-", "1", "]", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'-'", ")", ")", "\n", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "lemma", "=", "re", ".", "sub", "(", "r'http:'", ",", "'https:'", ",", "lemma", ".", "lower", "(", ")", ")", "\n", "if", "url", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "if", "url", "in", "lemma", ":", "\n", "            ", "return", "9", "\n", "", "elif", "url", "[", ":", "20", "]", "in", "lemma", "or", "url", "[", "-", "20", ":", "]", "in", "lemma", ":", "\n", "            ", "return", "8", "\n", "", "elif", "url", "[", ":", "10", "]", "in", "lemma", "or", "url", "[", "-", "10", ":", "]", "in", "lemma", ":", "\n", "            ", "return", "7", "\n", "", "elif", "url", "[", ":", "5", "]", "in", "lemma", "or", "url", "[", "-", "5", ":", "]", "in", "lemma", ":", "\n", "            ", "return", "6", "\n", "", "elif", "url", "==", "'https://www.christianforums.com'", "and", "lemma", "in", "(", "'cf'", ",", "'cfer'", ")", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.abstract_url": [[123, 138], ["url.URL.alignments.sort", "enumerate", "dict", "url.URL.amr.replace_span", "url.URL.amr.graph.replace_node_attribute", "len", "map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "abstract_url", "(", "self", ")", ":", "\n", "        ", "count", ",", "offset", "=", "0", ",", "0", "\n", "self", ".", "alignments", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "end", ")", "\n", "for", "i", ",", "alignment", "in", "enumerate", "(", "self", ".", "alignments", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "abstract", "=", "'URL_{}'", ".", "format", "(", "i", "+", "1", ")", "\n", "span", "=", "[", "index", "-", "offset", "for", "index", "in", "alignment", ".", "aligned_token_indexes", "]", "\n", "offset", "+=", "len", "(", "span", ")", "-", "1", "\n", "self", ".", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "dict", "(", "\n", "type", "=", "'url-entity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "self", ".", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "value", "=", "alignment", ".", "url", ")", "\n", "self", ".", "amr", ".", "replace_span", "(", "span", ",", "[", "abstract", "]", ",", "[", "'NN'", "]", ",", "[", "'URL'", "]", ")", "\n", "self", ".", "amr", ".", "graph", ".", "replace_node_attribute", "(", "alignment", ".", "node", ",", "'value'", ",", "alignment", ".", "url", ",", "abstract", ")", "\n", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.url.URL.remove_redundant_url": [[139, 148], ["range", "len", "re.search", "url.URL.amr.remove_span"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.remove_span"], ["", "def", "remove_redundant_url", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "lemmas", ")", ")", ":", "\n", "                ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "i", "]", "\n", "if", "re", ".", "search", "(", "'(https?:|<a.*href=|^</a>$)'", ",", "lemma", ")", ":", "\n", "                    ", "self", ".", "amr", ".", "remove_span", "(", "[", "i", "]", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.AlignedPairs.__init__": [[19, 26], ["float"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "quant_tokens", ",", "x", ",", "y", ",", "amr", ",", "score", "=", "0", ",", "near", "=", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "        ", "self", ".", "quant_tokens", "=", "quant_tokens", "\n", "self", ".", "quant_token_index", "=", "x", "\n", "self", ".", "snt_token_index", "=", "y", "\n", "self", ".", "amr", "=", "amr", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "near", "=", "near", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.AlignedPairs.__str__": [[27, 32], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'{}: {}({})'", ".", "format", "(", "\n", "self", ".", "quant_tokens", "[", "self", ".", "quant_token_index", "]", ",", "\n", "self", ".", "amr", ".", "tokens", "[", "self", ".", "snt_token_index", "]", ",", "\n", "self", ".", "snt_token_index", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.__init__": [[37, 43], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "node", ",", "attr", ",", "value", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "self", ".", "attr", "=", "attr", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "aligned_pairs", "=", "[", "]", "\n", "self", ".", "backup", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.__str__": [[44, 46], ["str", "list", "map"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "list", "(", "map", "(", "str", ",", "self", ".", "aligned_pairs", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.score": [[47, 52], ["sum", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "score", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_pairs", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "sum", "(", "p", ".", "score", "for", "p", "in", "self", ".", "aligned_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.near": [[53, 58], ["sum", "len", "float"], "methods", ["None"], ["", "@", "property", "\n", "def", "near", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_pairs", ")", "==", "0", ":", "\n", "            ", "return", "-", "float", "(", "'inf'", ")", "\n", "", "return", "sum", "(", "p", ".", "near", "for", "p", "in", "self", ".", "aligned_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.begin": [[59, 64], ["min", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "begin", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_pairs", ")", "==", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "min", "(", "p", ".", "snt_token_index", "for", "p", "in", "self", ".", "aligned_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.end": [[65, 70], ["len", "max"], "methods", ["None"], ["", "@", "property", "\n", "def", "end", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "aligned_pairs", ")", "==", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "max", "(", "p", ".", "snt_token_index", "for", "p", "in", "self", ".", "aligned_pairs", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.span": [[71, 74], ["range"], "methods", ["None"], ["", "@", "property", "\n", "def", "span", "(", "self", ")", ":", "\n", "        ", "return", "range", "(", "self", ".", "begin", ",", "self", ".", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.has_overlap_with": [[75, 78], ["any"], "methods", ["None"], ["", "def", "has_overlap_with", "(", "self", ",", "other", ")", ":", "\n", "        ", "index_list1", "=", "[", "p", ".", "snt_token_index", "for", "p", "in", "self", ".", "aligned_pairs", "]", "\n", "return", "any", "(", "p", ".", "snt_token_index", "in", "index_list1", "for", "p", "in", "other", ".", "aligned_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.QuantityCounter.__init__": [[82, 87], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "one", "=", "0", "\n", "self", ".", "ten", "=", "0", "\n", "self", ".", "hundred", "=", "0", "\n", "self", ".", "thousand", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.QuantityCounter.get_count": [[88, 104], ["float", "quantity.quantify"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.quantify"], ["", "def", "get_count", "(", "self", ",", "value", ")", ":", "\n", "        ", "value", "=", "float", "(", "quantify", "(", "value", ")", ")", "\n", "if", "0", "<=", "value", "<", "10", ":", "\n", "            ", "self", ".", "one", "+=", "1", "\n", "return", "self", ".", "one", "\n", "", "elif", "10", "<=", "value", "<", "100", ":", "\n", "            ", "self", ".", "ten", "+=", "10", "\n", "return", "self", ".", "ten", "\n", "", "elif", "100", "<=", "value", "<", "1000", ":", "\n", "            ", "self", ".", "hundred", "+=", "100", "\n", "return", "self", ".", "hundred", "\n", "", "elif", "value", ">=", "1000", ":", "\n", "            ", "self", ".", "thousand", "+=", "1000", "\n", "return", "self", ".", "thousand", "\n", "", "else", ":", "\n", "            ", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.__init__": [[135, 141], ["amr.graph.get_list_node"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node"], ["def", "__init__", "(", "self", ",", "amr", ",", "dry", "=", "False", ")", ":", "\n", "        ", "self", ".", "amr", "=", "amr", "\n", "self", ".", "dry", "=", "dry", "\n", "self", ".", "alignments", "=", "[", "]", "\n", "self", ".", "ordered_node_list", "=", "[", "n", "for", "n", ",", "_", ",", "_", "in", "amr", ".", "graph", ".", "get_list_node", "(", ")", "]", "\n", "self", ".", "quant_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract": [[142, 152], ["graph.get_nodes", "quantity.Quantity.group_alignment", "quantity.Quantity.abstract_group", "quantity.Quantity._abstract_without_alignment", "quantity.Quantity.align_node_attrs"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.group_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract_group", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity._abstract_without_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.align_node_attrs"], ["", "def", "abstract", "(", "self", ",", "align", "=", "True", ")", ":", "\n", "        ", "if", "not", "align", ":", "\n", "            ", "return", "self", ".", "_abstract_without_alignment", "(", ")", "\n", "", "graph", "=", "self", ".", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "self", ".", "align_node_attrs", "(", "node", ")", "\n", "", "groups", "=", "self", ".", "group_alignment", "(", ")", "\n", "return", "self", ".", "abstract_group", "(", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity._abstract_without_alignment": [[153, 174], ["quantity.QuantityCounter", "graph.get_nodes", "quantity.quantify", "str", "dict", "quantity.Quantity.amr.graph.replace_node_attribute", "quantity.QuantityCounter.get_count", "map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.quantify", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.QuantityCounter.get_count"], ["", "def", "_abstract_without_alignment", "(", "self", ")", ":", "\n", "        ", "graph", "=", "self", ".", "amr", ".", "graph", "\n", "\n", "count", "=", "0", "\n", "counter", "=", "QuantityCounter", "(", ")", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "q", "=", "quantify", "(", "value", ")", "\n", "if", "q", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "span", "=", "[", "]", "\n", "abstract", "=", "str", "(", "counter", ".", "get_count", "(", "value", ")", ")", "\n", "self", ".", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "dict", "(", "\n", "type", "=", "'quantity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "self", ".", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "value", "=", "value", ")", "\n", "self", ".", "amr", ".", "graph", ".", "replace_node_attribute", "(", "node", ",", "attr", ",", "value", ",", "abstract", ")", "\n", "count", "+=", "1", "\n", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.align_node_attrs": [[176, 199], ["quantity.Quantity.get_node_position", "quantity.quantify", "quantity.Quantity.get_alignment", "quantity.Quantity.normalize_quant", "quantity.Quantity.get_alignment", "backup.sort", "quantity.Quantity.alignments.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.get_node_position", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.quantify", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.get_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.normalize_quant", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.get_alignment"], ["", "def", "align_node_attrs", "(", "self", ",", "node", ")", ":", "\n", "        ", "node_position", "=", "self", ".", "get_node_position", "(", "node", ")", "\n", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "            ", "q", "=", "quantify", "(", "value", ")", "\n", "if", "q", "is", "None", ":", "\n", "                ", "continue", "\n", "", "self", ".", "quant_count", "+=", "1", "\n", "alignment", ",", "backup", "=", "self", ".", "get_alignment", "(", "[", "q", "]", ",", "node_position", ",", "node", ",", "attr", ",", "value", ")", "\n", "quant_tokens", "=", "self", ".", "normalize_quant", "(", "q", ")", "\n", "if", "quant_tokens", "is", "not", "None", ":", "\n", "                ", "alignment2", ",", "backup2", "=", "self", ".", "get_alignment", "(", "\n", "quant_tokens", ",", "node_position", ",", "node", ",", "attr", ",", "value", ")", "\n", "if", "(", "alignment2", ".", "score", ",", "alignment2", ".", "near", ")", ">", "(", "alignment", ".", "score", ",", "alignment", ".", "near", ")", ":", "\n", "                    ", "backup", "=", "[", "alignment", "]", "+", "backup", "+", "backup2", "\n", "alignment", "=", "alignment2", "\n", "", "else", ":", "\n", "                    ", "backup", "=", "[", "alignment2", "]", "+", "backup", "+", "backup2", "\n", "", "backup", ".", "sort", "(", "key", "=", "lambda", "x", ":", "(", "-", "x", ".", "score", ",", "-", "x", ".", "near", ")", ")", "\n", "", "alignment", ".", "backup", "=", "backup", "\n", "if", "alignment", ".", "score", ">", "0", ":", "\n", "                ", "self", ".", "alignments", ".", "append", "(", "alignment", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.group_alignment": [[200, 218], ["set", "enumerate", "set.add", "enumerate", "groups.append", "x.has_overlap_with", "len", "set.add", "group.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Alignment.has_overlap_with"], ["", "", "", "def", "group_alignment", "(", "self", ")", ":", "\n", "        ", "groups", "=", "[", "]", "\n", "visited", "=", "set", "(", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "self", ".", "alignments", ")", ":", "\n", "            ", "if", "i", "in", "visited", ":", "\n", "                ", "continue", "\n", "", "visited", ".", "add", "(", "i", ")", "\n", "group", "=", "[", "x", "]", "\n", "for", "j", ",", "y", "in", "enumerate", "(", "self", ".", "alignments", "[", "i", "+", "1", ":", "]", ",", "i", "+", "1", ")", ":", "\n", "                ", "if", "j", "in", "visited", ":", "\n", "                    ", "continue", "\n", "", "if", "x", ".", "has_overlap_with", "(", "y", ")", ":", "\n", "                    ", "visited", ".", "add", "(", "j", ")", "\n", "group", ".", "append", "(", "y", ")", "\n", "", "", "groups", ".", "append", "(", "group", ")", "\n", "if", "len", "(", "group", ")", ">", "1", ":", "\n", "                ", "continue", "\n", "", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract_group": [[219, 243], ["quantity.QuantityCounter", "zip", "enumerate", "len", "max", "str", "dict", "quantity.Quantity.amr.replace_span", "sorted", "quantity.QuantityCounter.get_count", "len", "quantity.Quantity.amr.graph.replace_node_attribute", "zip", "map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.QuantityCounter.get_count", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "abstract_group", "(", "self", ",", "groups", ")", ":", "\n", "        ", "if", "len", "(", "groups", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "count", ",", "offset", "=", "0", ",", "0", "\n", "counter", "=", "QuantityCounter", "(", ")", "\n", "representatives", "=", "[", "max", "(", "g", ",", "key", "=", "lambda", "x", ":", "x", ".", "end", "-", "x", ".", "begin", ")", "for", "g", "in", "groups", "]", "\n", "groups", ",", "representatives", "=", "zip", "(", "*", "sorted", "(", "\n", "zip", "(", "groups", ",", "representatives", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ".", "begin", ",", "x", "[", "1", "]", ".", "end", ")", ")", ")", "\n", "for", "i", ",", "alignment", "in", "enumerate", "(", "representatives", ")", ":", "\n", "            ", "abstract", "=", "str", "(", "counter", ".", "get_count", "(", "alignment", ".", "value", ")", ")", "\n", "span", "=", "[", "index", "-", "offset", "for", "index", "in", "alignment", ".", "span", "]", "\n", "offset", "+=", "len", "(", "span", ")", "-", "1", "\n", "self", ".", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "dict", "(", "\n", "type", "=", "'quantity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "self", ".", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "value", "=", "alignment", ".", "value", ")", "\n", "pos_tag", "=", "self", ".", "amr", ".", "pos_tags", "[", "span", "[", "0", "]", "]", "\n", "if", "pos_tag", "in", "(", "'0'", ",", "'O'", ")", ":", "\n", "                ", "pos_tag", "=", "'CD'", "\n", "", "self", ".", "amr", ".", "replace_span", "(", "span", ",", "[", "abstract", "]", ",", "[", "pos_tag", "]", ",", "[", "'NUMBER'", "]", ")", "\n", "for", "a", "in", "groups", "[", "i", "]", ":", "\n", "                ", "count", "+=", "1", "\n", "self", ".", "amr", ".", "graph", ".", "replace_node_attribute", "(", "a", ".", "node", ",", "a", ".", "attr", ",", "a", ".", "value", ",", "abstract", ")", "#", "\n", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.get_alignment": [[244, 259], ["range", "candidate_alignments.sort", "quantity.Alignment", "enumerate", "candidate_alignments.append", "range", "quantity.Quantity.maybe_align", "len", "len", "float", "Alignment.aligned_pairs.append", "len", "abs", "quantity.AlignedPairs"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.maybe_align"], ["", "def", "get_alignment", "(", "self", ",", "tokens", ",", "node_position", ",", "node", ",", "attr", ",", "value", ")", ":", "\n", "        ", "candidate_alignments", "=", "[", "]", "\n", "for", "start", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "tokens", ")", "-", "len", "(", "tokens", ")", "+", "1", ")", ":", "\n", "            ", "alignment", "=", "Alignment", "(", "node", ",", "attr", ",", "value", ")", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "range", "(", "start", ",", "start", "+", "len", "(", "tokens", ")", ")", ")", ":", "\n", "                ", "score", "=", "self", ".", "maybe_align", "(", "index", ",", "tokens", "[", "i", "]", ")", "\n", "near", "=", "-", "float", "(", "'inf'", ")", "\n", "if", "node_position", "!=", "-", "1", ":", "\n", "                    ", "near", "=", "-", "abs", "(", "node_position", "-", "index", ")", "\n", "", "if", "score", ">", "0", ":", "\n", "                    ", "alignment", ".", "aligned_pairs", ".", "append", "(", "\n", "AlignedPairs", "(", "tokens", ",", "i", ",", "index", ",", "self", ".", "amr", ",", "score", ",", "near", ")", ")", "\n", "", "", "candidate_alignments", ".", "append", "(", "alignment", ")", "\n", "", "candidate_alignments", ".", "sort", "(", "key", "=", "lambda", "x", ":", "(", "-", "x", ".", "score", ",", "-", "x", ".", "near", ")", ")", "\n", "return", "candidate_alignments", "[", "0", "]", ",", "candidate_alignments", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.get_node_position": [[260, 276], ["re.sub", "str", "lemmas.index", "quantity.Quantity.amr.graph._G.edges", "quantity.Quantity.ordered_node_list.index", "lemmas.index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "def", "get_node_position", "(", "self", ",", "node", ")", ":", "\n", "        ", "lemmas", "=", "self", ".", "amr", ".", "lemmas", "\n", "node_lemma", "=", "re", ".", "sub", "(", "r'-\\d+$'", ",", "''", ",", "str", "(", "node", ".", "instance", ")", ")", "\n", "position", "=", "-", "1", "\n", "if", "node_lemma", "in", "lemmas", ":", "\n", "            ", "position", "=", "lemmas", ".", "index", "(", "node_lemma", ")", "\n", "", "if", "position", "==", "-", "1", ":", "\n", "            ", "for", "_", ",", "child", "in", "self", ".", "amr", ".", "graph", ".", "_G", ".", "edges", "(", "node", ")", ":", "\n", "                ", "if", "self", ".", "amr", ".", "graph", ".", "_G", "[", "node", "]", "[", "child", "]", "[", "'label'", "]", "==", "'unit'", ":", "\n", "                    ", "instance", "=", "child", ".", "instance", "\n", "if", "instance", "in", "lemmas", ":", "\n", "                        ", "position", "=", "lemmas", ".", "index", "(", "instance", ")", "\n", "break", "\n", "", "", "", "", "if", "position", "==", "-", "1", ":", "\n", "            ", "position", "=", "self", ".", "ordered_node_list", ".", "index", "(", "node", ")", "\n", "", "return", "position", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.normalize_quant": [[277, 306], ["quantity.Quantity.normalize_dict.get", "q.startswith", "re.search", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "str", "int", "int", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "normalize_quant", "(", "self", ",", "q", ")", ":", "\n", "        ", "quant_tokens", "=", "self", ".", "normalize_dict", ".", "get", "(", "q", ",", "None", ")", "\n", "if", "quant_tokens", "is", "None", "and", "not", "re", ".", "search", "(", "r'[./]'", ",", "q", ")", ":", "\n", "            ", "billion", "=", "int", "(", "q", ")", "/", "1000000000", "\n", "if", "int", "(", "q", ")", "%", "1000000000", "==", "0", ":", "\n", "                ", "billion", "=", "int", "(", "billion", ")", "\n", "", "million", "=", "int", "(", "q", ")", "/", "1000000", "\n", "if", "int", "(", "q", ")", "%", "1000000", "==", "0", ":", "\n", "                ", "million", "=", "int", "(", "million", ")", "\n", "", "thousand", "=", "0", "\n", "if", "int", "(", "q", ")", "%", "1000", "==", "0", ":", "\n", "                ", "thousand", "=", "int", "(", "int", "(", "q", ")", "/", "1000", ")", "\n", "", "hundred", "=", "0", "\n", "if", "int", "(", "q", ")", "%", "100", "==", "0", ":", "\n", "                ", "hundred", "=", "int", "(", "int", "(", "q", ")", "/", "100", ")", "\n", "", "if", "billion", ">=", "1", ":", "\n", "                ", "quant_tokens", "=", "[", "str", "(", "billion", ")", ",", "'billion'", "]", "\n", "", "elif", "million", ">=", "1", ":", "\n", "                ", "quant_tokens", "=", "[", "str", "(", "million", ")", ",", "'million'", "]", "\n", "", "elif", "10", ">", "thousand", ">", "0", ":", "\n", "                ", "quant_tokens", "=", "[", "str", "(", "thousand", ")", ",", "'thousand'", "]", "\n", "", "elif", "10", "<=", "thousand", "<", "1000", ":", "\n", "                ", "quant_tokens", "=", "[", "str", "(", "thousand", ")", "+", "'k'", "]", "\n", "", "elif", "10", ">", "hundred", ">", "0", ":", "\n", "                ", "quant_tokens", "=", "[", "str", "(", "hundred", ")", ",", "'hundred'", "]", "\n", "\n", "", "", "if", "quant_tokens", "is", "None", "and", "q", ".", "startswith", "(", "'-'", ")", ":", "\n", "            ", "quant_tokens", "=", "[", "q", "[", "0", "]", ",", "q", "[", "1", ":", "]", "]", "\n", "", "return", "quant_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.maybe_align": [[307, 328], ["quantity.Quantity.amr.lemmas[].replace().lower", "re.search", "re.search", "quantity.Quantity.amr.lemmas[].replace", "float", "float"], "methods", ["None"], ["", "def", "maybe_align", "(", "self", ",", "index", ",", "token", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", ".", "replace", "(", "','", ",", "''", ")", ".", "lower", "(", ")", "\n", "if", "lemma", "==", "token", ":", "\n", "            ", "return", "10", "\n", "", "if", "lemma", "==", "token", "+", "'s'", "or", "lemma", "==", "token", "+", "'th'", ":", "\n", "            ", "return", "8", "\n", "", "if", "lemma", "==", "'per'", "and", "token", "==", "'1'", ":", "\n", "            ", "return", "8", "\n", "", "if", "lemma", "in", "(", "'firstly'", ",", ")", "and", "token", "==", "'1'", ":", "\n", "            ", "return", "5", "\n", "", "if", "lemma", "==", "'minus'", "and", "token", "==", "'-'", ":", "\n", "            ", "return", "8", "\n", "", "if", "re", ".", "search", "(", "r'^\\d+\\.\\d+$'", ",", "lemma", ")", "and", "re", ".", "search", "(", "r'^\\d+\\.\\d+$'", ",", "token", ")", "and", "float", "(", "lemma", ")", "==", "float", "(", "token", ")", ":", "\n", "            ", "return", "10", "\n", "", "if", "lemma", "==", "'secondly'", "and", "token", "==", "'2'", ":", "\n", "            ", "return", "5", "\n", "", "if", "lemma", "==", "'lastly'", "and", "token", "==", "'-1'", ":", "\n", "            ", "return", "5", "\n", "", "if", "lemma", "==", "'.'", "+", "token", ":", "\n", "            ", "return", "5", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.quantify": [[4, 15], ["isinstance", "isinstance", "str", "re.search", "x.split", "str", "re.search", "int", "int"], "function", ["None"], ["def", "quantify", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "int", ")", "or", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "        ", "return", "str", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "if", "re", ".", "search", "(", "r\"^[0-9]+/[0-9]+$\"", ",", "x", ")", ":", "\n", "            ", "numerator", ",", "denominator", "=", "x", ".", "split", "(", "'/'", ")", "\n", "return", "str", "(", "int", "(", "numerator", ")", "/", "int", "(", "denominator", ")", ")", "\n", "", "elif", "re", ".", "search", "(", "r\"^[0-9]+$\"", ",", "x", ")", ":", "\n", "            ", "return", "x", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Alignment.__init__": [[6, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "token_index", ",", "op_index", ",", "score", ")", ":", "\n", "        ", "self", ".", "token_index", "=", "token_index", "\n", "self", ".", "op_index", "=", "op_index", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal.__init__": [[41, 50], ["ordinal.Ordinal._get_ops", "ordinal.Ordinal._get_alignment", "ordinal.Ordinal._get_best_span"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score._get_best_span"], ["def", "__init__", "(", "self", ",", "node", ",", "amr", ",", "align", "=", "True", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "self", ".", "amr", "=", "amr", "\n", "self", ".", "value_node", "=", "None", "\n", "self", ".", "ops", "=", "self", ".", "_get_ops", "(", ")", "\n", "if", "align", ":", "\n", "            ", "self", ".", "alignment", "=", "self", ".", "_get_alignment", "(", ")", "\n", "self", ".", "span", "=", "self", ".", "_get_best_span", "(", "self", ".", "alignment", ")", "\n", "", "self", ".", "ner_type", "=", "'ORDINAL_ENTITY'", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal.to_dict": [[51, 56], ["map"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ",", "amr", ",", "span", ")", ":", "\n", "        ", "return", "{", "\n", "'type'", ":", "'ordinal-entity'", ",", "\n", "'span'", ":", "' '", ".", "join", "(", "map", "(", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "'ops'", ":", "self", ".", "ops", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_ops": [[57, 74], ["list", "list", "graph._G.edges", "map", "str"], "methods", ["None"], ["", "def", "_get_ops", "(", "self", ")", ":", "\n", "        ", "for", "attr", ",", "value", "in", "self", ".", "node", ".", "attributes", ":", "\n", "            ", "if", "attr", "==", "'value'", ":", "\n", "                ", "return", "[", "str", "(", "value", ")", "]", "\n", "# The ordinal value is not an attribute, try to find it in the children.", "\n", "", "", "value", "=", "None", "\n", "graph", "=", "self", ".", "amr", ".", "graph", "\n", "edges", "=", "list", "(", "graph", ".", "_G", ".", "edges", "(", "self", ".", "node", ")", ")", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "            ", "label", "=", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "label", "==", "'value'", ":", "\n", "                ", "value", "=", "target", "\n", "break", "\n", "", "", "if", "value", "is", "None", ":", "\n", "            ", "return", "[", "]", "\n", "", "self", ".", "value_node", "=", "value", "\n", "return", "list", "(", "map", "(", "str", ",", "value", ".", "ops", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_alignment": [[75, 89], ["enumerate", "re.search", "range", "len", "ordinal.Ordinal._maybe_align", "ordinal.Ordinal._get_coherence", "ordinal.Alignment"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_coherence"], ["", "def", "_get_alignment", "(", "self", ")", ":", "\n", "        ", "alignment", "=", "{", "}", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "self", ".", "ops", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "                ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "for", "j", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "tokens", ")", ")", ":", "\n", "                ", "alignment_score", "=", "self", ".", "_maybe_align", "(", "op", ",", "j", ")", "\n", "if", "alignment_score", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "coherence_score", "=", "self", ".", "_get_coherence", "(", "j", ")", "\n", "score", "=", "(", "alignment_score", ",", "coherence_score", ")", "\n", "if", "j", "not", "in", "alignment", "or", "alignment", "[", "j", "]", ".", "score", "<", "score", ":", "\n", "                    ", "alignment", "[", "j", "]", "=", "Alignment", "(", "j", ",", "i", ",", "score", ")", "\n", "", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_coherence": [[90, 92], ["None"], "methods", ["None"], ["", "def", "_get_coherence", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._maybe_align": [[93, 112], ["ordinal.Ordinal.amr.lemmas[].lower().replace", "ordinal.Ordinal.startswith", "ordinal.Ordinal.amr.lemmas[].lower"], "methods", ["None"], ["", "def", "_maybe_align", "(", "self", ",", "op", ",", "index", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", ".", "lower", "(", ")", ".", "replace", "(", "','", ",", "''", ")", "\n", "if", "op", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "if", "op", "+", "'th'", "==", "lemma", "or", "op", "+", "'rd'", "==", "lemma", "or", "op", "+", "'nd'", "==", "lemma", "or", "op", "+", "'st'", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "if", "op", "==", "'-1'", "and", "lemma", "in", "(", "'last'", ",", "'mast'", ",", "'final'", ",", "'lastly'", ")", ":", "\n", "            ", "return", "10", "\n", "", "if", "op", "==", "'-4'", "and", "lemma", "==", "'preantepenultimate'", ":", "\n", "            ", "return", "10", "\n", "", "if", "op", "==", "'2'", "and", "lemma", "==", "'latter'", ":", "\n", "            ", "return", "8", "\n", "", "if", "lemma", "in", "self", ".", "ORDINAL_MAP", "and", "self", ".", "ORDINAL_MAP", "[", "lemma", "]", "==", "op", ":", "\n", "            ", "return", "10", "\n", "", "if", "lemma", ".", "startswith", "(", "'-'", ")", "and", "lemma", "[", "1", ":", "]", "==", "op", ":", "\n", "            ", "return", "8", "\n", "", "if", "op", "in", "self", ".", "DIGIT_MAP", "and", "self", ".", "DIGIT_MAP", "[", "op", "]", "==", "lemma", ":", "\n", "            ", "return", "8", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal._get_best_span": [[113, 138], ["list", "list.sort", "len", "alignment.keys", "spans[].append", "max", "spans.append", "spans.append", "range", "sum", "spans[].append", "spans.append", "sum"], "methods", ["None"], ["", "def", "_get_best_span", "(", "self", ",", "alignment", ")", ":", "\n", "        ", "indexes", "=", "list", "(", "alignment", ".", "keys", "(", ")", ")", "\n", "indexes", ".", "sort", "(", ")", "\n", "spans", "=", "[", "]", "\n", "last_index", "=", "None", "\n", "for", "index", "in", "indexes", ":", "\n", "            ", "if", "last_index", "is", "None", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "elif", "index", "-", "last_index", ">", "2", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "last_index", "+", "1", ",", "index", ")", ":", "\n", "                    ", "if", "self", ".", "amr", ".", "lemmas", "[", "i", "]", "in", "(", "'-'", ",", "'to'", ")", ":", "\n", "                        ", "spans", "[", "-", "1", "]", ".", "append", "(", "index", "-", "1", ")", "\n", "", "else", ":", "\n", "                        ", "spans", ".", "append", "(", "[", "]", ")", "\n", "break", "\n", "", "", "", "last_index", "=", "index", "\n", "spans", "[", "-", "1", "]", ".", "append", "(", "index", ")", "\n", "", "if", "len", "(", "spans", ")", ":", "\n", "            ", "return", "max", "(", "spans", ",", "key", "=", "lambda", "x", ":", "(", "\n", "sum", "(", "[", "alignment", "[", "j", "]", ".", "score", "[", "0", "]", "for", "j", "in", "x", "if", "j", "in", "alignment", "]", ",", "\n", "sum", "(", "[", "alignment", "[", "j", "]", ".", "score", "[", "1", "]", "for", "j", "in", "x", "if", "j", "in", "alignment", "]", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal.collapse_ordinal_nodes": [[139, 168], ["ordinals.sort", "ordinal.to_dict", "amr.replace_span", "amr.graph.replace_node_attribute", "list", "amr.graph.remove_edge", "amr.graph.remove_subtree", "len", "amr.graph._G.in_edges", "amr.graph.remove_edge", "amr.graph.remove_subtree", "float", "amr.graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.to_dict", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "", "@", "staticmethod", "\n", "def", "collapse_ordinal_nodes", "(", "ordinals", ",", "amr", ")", ":", "\n", "        ", "node_count", "=", "0", "\n", "ordinals", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "span", "[", "-", "1", "]", "if", "x", ".", "span", "is", "not", "None", "else", "float", "(", "'inf'", ")", ")", "\n", "offset", "=", "0", "\n", "for", "ordinal", "in", "ordinals", ":", "\n", "            ", "if", "ordinal", ".", "span", "is", "not", "None", ":", "\n", "                ", "node_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "ordinal", ".", "ner_type", ",", "node_count", ")", "\n", "span", "=", "[", "index", "-", "offset", "for", "index", "in", "ordinal", ".", "span", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "ordinal", ".", "to_dict", "(", "amr", ",", "span", ")", "\n", "amr", ".", "replace_span", "(", "span", ",", "[", "abstract", "]", ",", "[", "'JJ'", "]", ",", "[", "ordinal", ".", "ner_type", "]", ")", "\n", "amr", ".", "stems", "=", "amr", ".", "stems", "[", ":", "span", "[", "0", "]", "]", "+", "[", "abstract", "]", "+", "amr", ".", "stems", "[", "span", "[", "-", "1", "]", "+", "1", ":", "]", "\n", "for", "attr", ",", "value", "in", "ordinal", ".", "node", ".", "attributes", ":", "\n", "                    ", "if", "attr", "==", "'value'", ":", "\n", "                        ", "amr", ".", "graph", ".", "remove_node_attribute", "(", "ordinal", ".", "node", ",", "attr", ",", "value", ")", "\n", "break", "\n", "", "", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "ordinal", ".", "node", ",", "'instance'", ",", "ordinal", ".", "node", ".", "instance", ",", "abstract", ")", "\n", "if", "ordinal", ".", "value_node", ":", "\n", "# Remove the value node.", "\n", "                    ", "amr", ".", "graph", ".", "remove_edge", "(", "ordinal", ".", "node", ",", "ordinal", ".", "value_node", ")", "\n", "amr", ".", "graph", ".", "remove_subtree", "(", "ordinal", ".", "value_node", ")", "\n", "", "offset", "+=", "len", "(", "ordinal", ".", "span", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "edges", "=", "list", "(", "amr", ".", "graph", ".", "_G", ".", "in_edges", "(", "ordinal", ".", "node", ")", ")", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "                    ", "amr", ".", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "amr", ".", "graph", ".", "remove_subtree", "(", "target", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.__init__": [[54, 62], ["polarity.Polarity.get_negated_nodes"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_negated_nodes"], ["def", "__init__", "(", "self", ",", "amr", ",", "dry", "=", "False", ")", ":", "\n", "        ", "self", ".", "amr", "=", "amr", "\n", "self", ".", "dry", "=", "dry", "\n", "self", ".", "nodes", "=", "self", ".", "get_negated_nodes", "(", ")", "\n", "self", ".", "negations", "=", "[", "]", "\n", "self", ".", "special_negations", "=", "[", "]", "\n", "self", ".", "true_positive", "=", "0", "\n", "self", ".", "false_positive", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.remove_polarity": [[63, 79], ["polarity.Polarity.get_negated_nodes", "polarity.Polarity.amr.graph.get_nodes", "polarity.Polarity.amr.graph.remove_node_attribute", "polarity.Polarity.amr.graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_negated_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "def", "remove_polarity", "(", "self", ")", ":", "\n", "        ", "count", "=", "0", "\n", "for", "node", "in", "self", ".", "get_negated_nodes", "(", ")", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'polarity'", ":", "\n", "                    ", "if", "not", "self", ".", "dry", ":", "\n", "                        ", "self", ".", "amr", ".", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "", "count", "+=", "1", "\n", "", "", "", "for", "node", "in", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "node", ".", "instance", "==", "'have-polarity-91'", ":", "\n", "                ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                    ", "if", "value", "==", "'-'", ":", "\n", "                        ", "if", "not", "self", ".", "dry", ":", "\n", "                            ", "self", ".", "amr", ".", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "", "count", "+=", "1", "\n", "", "", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.predict_polarity": [[80, 91], ["range", "len", "polarity.Polarity.is_negation", "polarity.Polarity.get_head", "polarity.Polarity.add_special_negation", "polarity.Polarity.negations.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_negation", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_head", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.add_special_negation"], ["", "def", "predict_polarity", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Use rules to predict polarity and its head.\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "tokens", ")", ")", ":", "\n", "            ", "if", "self", ".", "is_negation", "(", "i", ")", ":", "\n", "                ", "head", "=", "self", ".", "get_head", "(", "i", ")", "\n", "if", "head", "is", "not", "None", ":", "\n", "                    ", "self", ".", "negations", ".", "append", "(", "(", "i", ",", "head", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "add_special_negation", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.restore_polarity": [[92, 132], ["polarity.Polarity.get_node_instances", "list", "polarity.Polarity.amr.graph.get_nodes", "polarity.Polarity.amr.graph.get_nodes", "polarity.Polarity.items", "polarity.Polarity.items", "polarity.Polarity.is_match", "polarity.Polarity.is_match", "polarity.Polarity.sort_node_by_distance", "polarity.Polarity.sort_node_by_distance", "polarity.Polarity.amr.graph.add_node_attribute", "list.remove", "polarity.Polarity.restore_node_polarity", "list.remove", "polarity.Polarity.restore_node_polarity"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_node_instances", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.sort_node_by_distance", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.sort_node_by_distance", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.restore_node_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.restore_node_polarity"], ["", "", "", "def", "restore_polarity", "(", "self", ")", ":", "\n", "        ", "negations", "=", "self", ".", "negations", "\n", "special_negations", "=", "self", ".", "special_negations", "\n", "instance_map", "=", "self", ".", "get_node_instances", "(", ")", "\n", "remaining_nodes", "=", "list", "(", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ")", "\n", "for", "neg_index", ",", "head_index", "in", "negations", ":", "\n", "            ", "for", "instance", ",", "nodes", "in", "instance_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "self", ".", "is_match", "(", "head_index", ",", "instance", ")", ":", "\n", "                    ", "nodes", "=", "self", ".", "sort_node_by_distance", "(", "head_index", ",", "nodes", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "                        ", "if", "node", "not", "in", "remaining_nodes", ":", "\n", "                            ", "continue", "\n", "", "remaining_nodes", ".", "remove", "(", "node", ")", "\n", "self", ".", "restore_node_polarity", "(", "neg_index", ",", "head_index", ",", "node", ")", "\n", "break", "\n", "", "break", "\n", "\n", "", "", "", "for", "neg_index", ",", "head", "in", "special_negations", ":", "\n", "            ", "head_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "neg_index", "]", "\n", "for", "instance", ",", "nodes", "in", "instance_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "head_lemma", "==", "instance", ":", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "is_match", "(", "head", ",", "instance", ")", ":", "\n", "                    ", "nodes", "=", "self", ".", "sort_node_by_distance", "(", "neg_index", ",", "nodes", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "                        ", "if", "node", "not", "in", "remaining_nodes", ":", "\n", "                            ", "continue", "\n", "", "remaining_nodes", ".", "remove", "(", "node", ")", "\n", "self", ".", "restore_node_polarity", "(", "neg_index", ",", "head", ",", "node", ")", "\n", "break", "\n", "", "break", "\n", "\n", "", "", "", "for", "node", "in", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "node", ".", "instance", "==", "'have-polarity'", ":", "\n", "                ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                    ", "if", "attr", "==", "'ARG2'", "and", "value", "==", "'-'", ":", "\n", "                        ", "self", ".", "true_positive", "+=", "1", "\n", "break", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "node", ",", "'ARG2'", ",", "'-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.restore_node_polarity": [[133, 145], ["polarity.Polarity.special_restoration", "polarity.Polarity.amr.graph.add_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.special_restoration", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "", "", "", "def", "restore_node_polarity", "(", "self", ",", "neg_index", ",", "head", ",", "node", ")", ":", "\n", "        ", "if", "self", ".", "special_restoration", "(", "neg_index", ",", "head", ",", "node", ")", ":", "\n", "            ", "return", "\n", "", "if", "not", "self", ".", "dry", ":", "\n", "            ", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "node", ",", "'polarity'", ",", "'-'", ")", "\n", "", "else", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'polarity'", ":", "\n", "                    ", "self", ".", "true_positive", "+=", "1", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "false_positive", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.to_dict": [[146, 148], ["dict"], "methods", ["None"], ["", "", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "Negations", "=", "self", ".", "negations", ",", "SpecialNegations", "=", "self", ".", "special_negations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.special_restoration": [[149, 174], ["isinstance", "polarity.Polarity.amr.graph._G.in_edges", "polarity.Polarity.amr.graph.add_node_attribute", "polarity.Polarity.amr.graph.add_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "def", "special_restoration", "(", "self", ",", "neg_index", ",", "head", ",", "node", ")", ":", "\n", "        ", "head_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "head", "]", "if", "isinstance", "(", "head", ",", "int", ")", "else", "head", "\n", "if", "node", ".", "instance", "==", "'have-polarity'", ":", "\n", "            ", "if", "self", ".", "dry", ":", "\n", "                ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                    ", "if", "attr", "==", "'ARG2'", "and", "value", "==", "'-'", ":", "\n", "                        ", "self", ".", "true_positive", "+=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "                ", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "node", ",", "'ARG2'", ",", "'-'", ")", "\n", "", "return", "True", "\n", "\n", "", "if", "head_lemma", "==", "'face'", "and", "node", ".", "instance", "==", "'face'", ":", "\n", "            ", "for", "source", ",", "target", "in", "self", ".", "amr", ".", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ":", "\n", "                ", "if", "source", ".", "instance", "==", "'want'", ":", "\n", "                    ", "if", "self", ".", "dry", ":", "\n", "                        ", "for", "attr", ",", "value", "in", "source", ".", "attributes", ":", "\n", "                            ", "if", "attr", "==", "'polarity'", ":", "\n", "                                ", "self", ".", "true_positive", "+=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "                        ", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "source", ",", "'polarity'", ",", "'-'", ")", "\n", "", "break", "\n", "", "", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_negation": [[175, 184], ["len"], "methods", ["None"], ["", "def", "is_negation", "(", "self", ",", "index", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "next_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "1", "]", "if", "index", "+", "1", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "if", "lemma", "in", "(", "'not'", ",", "'never'", ",", "'without'", ",", "'no'", ",", "'dont'", ",", "'nowhere'", ",", "'none'", ",", "\n", "'neither'", ",", "'havent'", ",", "'didnt'", ",", "'wont'", ",", "'cant'", ",", "'doesnt'", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "lemma", "==", "'no-one'", "and", "next_lemma", "==", "'can'", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.add_special_negation": [[185, 198], ["re.search", "re.sub", "polarity.Polarity.special_negations.append", "re.search", "re.sub", "polarity.Polarity.special_negations.append", "polarity.Polarity.special_negations.append"], "methods", ["None"], ["", "def", "add_special_negation", "(", "self", ",", "index", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "last_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "-", "1", "]", "if", "index", "-", "1", ">=", "0", "else", "None", "\n", "if", "re", ".", "search", "(", "r'.+less$'", ",", "lemma", ")", ":", "\n", "            ", "head", "=", "re", ".", "sub", "(", "r'less$'", ",", "''", ",", "lemma", ")", "\n", "self", ".", "special_negations", ".", "append", "(", "(", "index", ",", "head", ")", ")", "\n", "", "elif", "re", ".", "search", "(", "r'^(non|un|il|irr|in|Non).+'", ",", "lemma", ")", ":", "\n", "            ", "head", "=", "re", ".", "sub", "(", "r'^(non|un|il|ir|in|Non)'", ",", "''", ",", "lemma", ")", "\n", "if", "head", "not", "in", "(", "'i'", ",", "'common'", ")", "and", "last_lemma", "!=", "'not'", ":", "\n", "                ", "self", ".", "special_negations", ".", "append", "(", "(", "index", ",", "head", ")", ")", "\n", "", "", "elif", "lemma", "==", "'asymmetrical'", ":", "\n", "            ", "head", "=", "'symmetrical'", "\n", "self", ".", "special_negations", ".", "append", "(", "(", "index", ",", "head", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_head": [[199, 217], ["re.search", "len"], "methods", ["None"], ["", "", "def", "is_head", "(", "self", ",", "index", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "token", "=", "self", ".", "amr", ".", "tokens", "[", "index", "]", "\n", "pos_tag", "=", "self", ".", "amr", ".", "pos_tags", "[", "index", "]", "\n", "next_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "1", "]", "if", "index", "+", "1", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "if", "re", ".", "search", "(", "r'^(^[^a-zA-Z0-9]+|be|the|a|so|that|any|person|this|stage|people|near|health)$'", ",", "lemma", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "token", "in", "(", "'remaining'", ",", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "pos_tag", "in", "(", "'PRP'", ",", "'.'", ",", "'IN'", ",", "'PRP$'", ",", "'POS'", ",", "'DT'", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "pos_tag", "in", "(", "'JJ'", ",", ")", "and", "next_lemma", "in", "[", "'measure'", "]", ":", "\n", "            ", "return", "False", "\n", "", "if", "pos_tag", "==", "'RB'", "and", "lemma", "not", "in", "(", "'there'", ",", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "lemma", "==", "'take'", "and", "next_lemma", "==", "'long'", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_head": [[218, 231], ["polarity.Polarity.get_special_head", "polarity.Polarity.is_false_positive", "len", "polarity.Polarity.is_head"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_special_head", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_false_positive", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_head"], ["", "def", "get_head", "(", "self", ",", "index", ")", ":", "\n", "        ", "head", "=", "self", ".", "get_special_head", "(", "index", ")", "\n", "if", "head", "is", "None", ":", "\n", "            ", "i", "=", "index", "+", "1", "\n", "head", "=", "None", "\n", "while", "i", "<", "len", "(", "self", ".", "amr", ".", "tokens", ")", ":", "\n", "                ", "if", "self", ".", "is_head", "(", "i", ")", ":", "\n", "                    ", "head", "=", "i", "\n", "break", "\n", "", "i", "+=", "1", "\n", "", "", "if", "self", ".", "is_false_positive", "(", "index", ",", "head", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_false_positive": [[232, 250], ["len", "len"], "methods", ["None"], ["", "def", "is_false_positive", "(", "self", ",", "index", ",", "head", ")", ":", "\n", "        ", "if", "head", "is", "None", ":", "\n", "            ", "return", "True", "\n", "", "last_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "-", "1", "]", "if", "index", "-", "1", ">=", "0", "else", "None", "\n", "next_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "1", "]", "if", "index", "+", "1", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "third_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "2", "]", "if", "index", "+", "2", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "head_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "head", "]", "\n", "if", "next_lemma", "and", "next_lemma", "in", "(", "'matter'", ",", "'address'", ",", "'other'", ",", "'only'", ",", "','", ",", "'.'", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "next_lemma", "==", "'-'", "and", "third_lemma", "!=", "'alignment'", ":", "\n", "            ", "return", "True", "\n", "", "if", "next_lemma", "==", "'like'", "and", "self", ".", "amr", ".", "pos_tags", "[", "index", "+", "1", "]", "==", "'IN'", ":", "\n", "            ", "return", "True", "\n", "", "if", "last_lemma", "and", "last_lemma", "in", "(", "'will'", ",", ")", "and", "next_lemma", "not", "in", "(", "'fade'", ",", "'get'", ",", "'make'", ",", "'succumb'", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "head_lemma", "in", "(", "'behave'", ",", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_special_head": [[251, 316], ["len", "len", "len"], "methods", ["None"], ["", "def", "get_special_head", "(", "self", ",", "index", ")", ":", "\n", "        ", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "last_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "-", "1", "]", "if", "index", "-", "1", ">=", "0", "else", "None", "\n", "llast_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "-", "2", "]", "if", "index", "-", "2", ">=", "0", "else", "None", "\n", "next_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "1", "]", "if", "index", "+", "1", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "third_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "2", "]", "if", "index", "+", "2", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "fourth_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "+", "3", "]", "if", "index", "+", "3", "<", "len", "(", "self", ".", "amr", ".", "lemmas", ")", "else", "None", "\n", "if", "lemma", "in", "(", "'cant'", ",", ")", ":", "\n", "            ", "return", "index", "\n", "", "if", "last_lemma", "in", "(", "'can'", ",", "'want'", ",", "'add'", ",", "'feel'", ",", "'strike'", ",", "'could'", ")", ":", "\n", "            ", "return", "index", "-", "1", "\n", "", "if", "last_lemma", "==", "'would'", ":", "\n", "            ", "if", "next_lemma", "in", "(", "'tell'", ",", "'read'", ",", "'worry'", ")", ":", "\n", "                ", "return", "index", "+", "1", "\n", "", "if", "next_lemma", "==", "'be'", "and", "third_lemma", "in", "(", "'know'", ",", "'interested'", ",", "'arrest'", ")", ":", "\n", "                ", "return", "index", "+", "2", "\n", "", "return", "index", "-", "1", "\n", "", "if", "last_lemma", "and", "next_lemma", "and", "last_lemma", "in", "(", "'have'", ",", ")", "and", "next_lemma", "in", "(", "\n", "'cohesion'", ",", "'access'", ",", "'more'", ",", "'enforcement'", ")", ":", "\n", "            ", "return", "index", "-", "1", "\n", "", "if", "next_lemma", "in", "(", "'because'", ",", "'alone'", ")", ":", "\n", "            ", "return", "index", "+", "1", "\n", "", "if", "next_lemma", "in", "(", "'as'", ",", ")", ":", "\n", "            ", "if", "third_lemma", "in", "(", "'much'", ",", "'severely'", ")", ":", "\n", "                ", "return", "index", "+", "2", "\n", "", "if", "third_lemma", "and", "self", ".", "amr", ".", "pos_tags", "[", "index", "+", "2", "]", "in", "(", "'RB'", ",", ")", ":", "\n", "                ", "return", "None", "\n", "", "return", "index", "+", "1", "\n", "", "if", "next_lemma", "==", "'new'", "and", "third_lemma", "==", "'initiative'", ":", "\n", "            ", "return", "index", "+", "8", "\n", "", "if", "next_lemma", "==", "'-'", "and", "third_lemma", "==", "'alignment'", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "next_lemma", "==", "'take'", "and", "third_lemma", "==", "'long'", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "next_lemma", "==", "'make'", "and", "fourth_lemma", "==", "'sense'", ":", "\n", "            ", "return", "index", "+", "3", "\n", "", "if", "next_lemma", "==", "'have'", "and", "fourth_lemma", "==", "'right'", ":", "\n", "            ", "return", "index", "+", "3", "\n", "", "if", "next_lemma", "==", "'to'", "and", "third_lemma", "in", "(", "'keep'", ",", "'worry'", ")", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "next_lemma", "==", "'to'", "and", "third_lemma", "in", "(", "'be'", ",", ")", ":", "\n", "            ", "return", "index", "+", "3", "\n", "", "if", "next_lemma", "==", "'on'", "and", "fourth_lemma", "==", "'way'", ":", "\n", "            ", "return", "index", "+", "5", "\n", "", "if", "next_lemma", "==", "'to'", "and", "third_lemma", "==", "'way'", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "next_lemma", "==", "'something'", "and", "third_lemma", "==", "'you'", ":", "\n", "            ", "return", "index", "+", "5", "\n", "", "if", "next_lemma", "==", "'negotiation'", "and", "third_lemma", "==", "'can'", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "next_lemma", "==", "'diplomatic'", "and", "third_lemma", "==", "'factor'", ":", "\n", "            ", "return", "index", "+", "2", "\n", "", "if", "third_lemma", "==", "'diplomat'", "and", "fourth_lemma", "==", "'nor'", ":", "\n", "            ", "return", "index", "+", "9", "\n", "", "if", "third_lemma", "==", "'hacking'", "and", "fourth_lemma", "==", "'claim'", ":", "\n", "            ", "return", "index", "+", "16", "\n", "", "if", "last_lemma", "==", "'off'", "and", "llast_lemma", "==", "'better'", ":", "\n", "            ", "return", "index", "\n", "", "if", "last_lemma", "==", "'would'", "and", "next_lemma", "in", "'like'", ":", "\n", "            ", "return", "index", "+", "1", "\n", "", "if", "next_lemma", "==", "'go'", "and", "third_lemma", "==", "'to'", ":", "\n", "            ", "return", "index", "+", "3", "\n", "", "if", "lemma", "==", "'neither'", "and", "fourth_lemma", "==", "'counseller'", ":", "\n", "            ", "return", "index", "+", "5", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_negated_nodes": [[317, 326], ["graph.get_nodes", "nodes.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes"], ["", "def", "get_negated_nodes", "(", "self", ")", ":", "\n", "        ", "graph", "=", "self", ".", "amr", ".", "graph", "\n", "nodes", "=", "[", "]", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'polarity'", ":", "\n", "                    ", "nodes", ".", "append", "(", "node", ")", "\n", "break", "\n", "", "", "", "return", "nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_node_instances": [[327, 335], ["polarity.Polarity.amr.graph.get_nodes", "re.sub", "instances[].append", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes"], ["", "def", "get_node_instances", "(", "self", ")", ":", "\n", "        ", "instances", "=", "{", "}", "\n", "for", "node", "in", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "instance", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "str", "(", "node", ".", "instance", ")", ")", "\n", "if", "instance", "not", "in", "instances", ":", "\n", "                ", "instances", "[", "instance", "]", "=", "[", "]", "\n", "", "instances", "[", "instance", "]", ".", "append", "(", "node", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.validate": [[336, 340], ["polarity.Polarity.get_precision", "polarity.Polarity.get_recall"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_precision", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_recall"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "p1", ",", "p2", "=", "self", ".", "get_precision", "(", ")", "\n", "r1", ",", "r2", "=", "self", ".", "get_recall", "(", ")", "\n", "return", "p1", ",", "p2", ",", "r1", ",", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.sort_node_by_distance": [[341, 372], ["zip", "len", "set", "polarity.Polarity.amr.graph._G.in_edges", "len", "polarity.Polarity.amr.graph.get_subtree", "len", "scores.append", "scores.append", "sorted", "set.add", "polarity.Polarity.amr.graph.get_subtree", "set.add", "sum", "valid_indexes.append", "min", "float", "zip", "lemmas.index", "set.add", "lemmas.index", "lemmas.index", "abs", "alignment.values"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "def", "sort_node_by_distance", "(", "self", ",", "head", ",", "nodes", ")", ":", "\n", "        ", "if", "len", "(", "nodes", ")", "<=", "1", ":", "\n", "            ", "return", "nodes", "\n", "", "lemmas", "=", "self", ".", "amr", ".", "lemmas", "\n", "scores", "=", "[", "]", "\n", "alignment", "=", "{", "}", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "aligned_indexes", "=", "set", "(", ")", "\n", "for", "n", "in", "self", ".", "amr", ".", "graph", ".", "get_subtree", "(", "node", ",", "max_depth", "=", "1", ")", "[", "1", ":", "]", ":", "\n", "                ", "if", "n", ".", "instance", "in", "lemmas", ":", "\n", "                    ", "aligned_indexes", ".", "add", "(", "lemmas", ".", "index", "(", "n", ".", "instance", ")", ")", "\n", "", "", "if", "len", "(", "aligned_indexes", ")", "==", "0", ":", "\n", "                ", "for", "n", "in", "self", ".", "amr", ".", "graph", ".", "get_subtree", "(", "node", ",", "max_depth", "=", "5", ")", "[", "1", ":", "]", ":", "\n", "                    ", "if", "n", ".", "instance", "in", "lemmas", ":", "\n", "                        ", "aligned_indexes", ".", "add", "(", "lemmas", ".", "index", "(", "n", ".", "instance", ")", ")", "\n", "", "", "", "for", "n", ",", "_", "in", "self", ".", "amr", ".", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ":", "\n", "                ", "if", "n", ".", "instance", "in", "lemmas", ":", "\n", "                    ", "aligned_indexes", ".", "add", "(", "lemmas", ".", "index", "(", "n", ".", "instance", ")", ")", "\n", "", "", "alignment", "[", "node", "]", "=", "aligned_indexes", "\n", "", "for", "node", "in", "nodes", ":", "\n", "            ", "aligned_indexes", "=", "alignment", "[", "node", "]", "\n", "valid_indexes", "=", "[", "]", "\n", "for", "index", "in", "aligned_indexes", ":", "\n", "                ", "if", "sum", "(", "1", "for", "indexes", "in", "alignment", ".", "values", "(", ")", "if", "index", "in", "indexes", ")", "==", "1", ":", "\n", "                    ", "valid_indexes", ".", "append", "(", "index", ")", "\n", "", "", "if", "len", "(", "valid_indexes", ")", ":", "\n", "                ", "scores", ".", "append", "(", "min", "(", "[", "abs", "(", "i", "-", "head", ")", "for", "i", "in", "valid_indexes", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "float", "(", "'inf'", ")", ")", "\n", "", "", "nodes", ",", "scores", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "nodes", ",", "scores", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", "\n", "return", "nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_precision": [[373, 415], ["polarity.Polarity.get_negated_nodes", "list", "polarity.Polarity.get_node_instances", "polarity.Polarity.amr.graph.get_nodes", "polarity.Polarity.items", "polarity.Polarity.items", "polarity.Polarity.is_match", "polarity.Polarity.is_match", "polarity.Polarity.sort_node_by_distance", "int", "int", "polarity.Polarity.sort_node_by_distance", "int", "int", "list.remove", "list.remove"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_negated_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_node_instances", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.sort_node_by_distance", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.sort_node_by_distance"], ["", "def", "get_precision", "(", "self", ")", ":", "\n", "        ", "neg_nodes", "=", "self", ".", "get_negated_nodes", "(", ")", "\n", "rest_nodes", "=", "list", "(", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ")", "\n", "match_count", ",", "correct_count", "=", "0", ",", "0", "\n", "instances", "=", "self", ".", "get_node_instances", "(", ")", "\n", "for", "neg", ",", "head", "in", "self", ".", "negations", ":", "\n", "            ", "match", ",", "correct", "=", "False", ",", "False", "\n", "for", "instance", ",", "nodes", "in", "instances", ".", "items", "(", ")", ":", "\n", "                ", "if", "self", ".", "is_match", "(", "head", ",", "instance", ")", ":", "\n", "                    ", "match", "=", "True", "\n", "nodes", "=", "self", ".", "sort_node_by_distance", "(", "head", ",", "nodes", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "                        ", "if", "node", "not", "in", "rest_nodes", ":", "\n", "                            ", "continue", "\n", "", "if", "node", "in", "neg_nodes", ":", "\n", "                            ", "correct", "=", "True", "\n", "", "rest_nodes", ".", "remove", "(", "node", ")", "\n", "break", "\n", "", "match_count", "+=", "int", "(", "match", ")", "\n", "correct_count", "+=", "int", "(", "correct", ")", "\n", "break", "\n", "\n", "", "", "", "for", "index", ",", "head", "in", "self", ".", "special_negations", ":", "\n", "            ", "match", ",", "correct", "=", "False", ",", "False", "\n", "head_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "for", "instance", ",", "nodes", "in", "instances", ".", "items", "(", ")", ":", "\n", "                ", "if", "head_lemma", "==", "instance", ":", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "is_match", "(", "head", ",", "instance", ")", ":", "\n", "                    ", "match", "=", "True", "\n", "nodes", "=", "self", ".", "sort_node_by_distance", "(", "index", ",", "nodes", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "                        ", "if", "node", "not", "in", "rest_nodes", ":", "\n", "                            ", "continue", "\n", "", "if", "node", "in", "neg_nodes", ":", "\n", "                            ", "correct", "=", "True", "\n", "", "rest_nodes", ".", "remove", "(", "node", ")", "\n", "break", "\n", "", "match_count", "+=", "int", "(", "match", ")", "\n", "correct_count", "+=", "int", "(", "correct", ")", "\n", "break", "\n", "", "", "", "return", "correct_count", ",", "match_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.get_recall": [[416, 437], ["len", "polarity.Polarity.is_match", "polarity.Polarity.is_match"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match"], ["", "def", "get_recall", "(", "self", ")", ":", "\n", "        ", "recall_count", "=", "0", "\n", "for", "node", "in", "self", ".", "nodes", ":", "\n", "            ", "recall", "=", "False", "\n", "for", "neg", ",", "head", "in", "self", ".", "negations", ":", "\n", "                ", "if", "self", ".", "is_match", "(", "head", ",", "node", ".", "instance", ")", ":", "\n", "                    ", "recall", "=", "True", "\n", "break", "\n", "", "", "if", "not", "recall", ":", "\n", "                ", "for", "index", ",", "head", "in", "self", ".", "special_negations", ":", "\n", "                    ", "head_lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "if", "head_lemma", "==", "node", ".", "instance", ":", "\n", "                        ", "continue", "\n", "", "if", "self", ".", "is_match", "(", "head", ",", "node", ".", "instance", ")", ":", "\n", "                        ", "recall", "=", "True", "\n", "break", "\n", "", "", "", "if", "recall", ":", "\n", "                ", "recall_count", "+=", "1", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "", "return", "recall_count", ",", "len", "(", "self", ".", "nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.is_match": [[438, 461], ["re.sub", "polarity.Polarity.strict_lemma_map.get", "isinstance", "polarity.Polarity.lemma_map.get", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "is_match", "(", "self", ",", "index", ",", "instance", ")", ":", "\n", "        ", "instance_lemma", "=", "re", ".", "sub", "(", "'-\\d\\d$'", ",", "''", ",", "instance", ")", "\n", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "if", "isinstance", "(", "index", ",", "int", ")", "else", "index", "\n", "lemma", "=", "self", ".", "strict_lemma_map", ".", "get", "(", "lemma", ",", "lemma", ")", "\n", "if", "self", ".", "lemma_map", ".", "get", "(", "lemma", ",", "None", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "lemma", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "instance_lemma", "+", "'ed'", "==", "lemma", "or", "instance_lemma", "+", "'d'", "==", "lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "'-'", "+", "instance_lemma", "==", "lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "sub", "(", "'ly$'", ",", "'le'", ",", "lemma", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "sub", "(", "'tive$'", ",", "'te'", ",", "lemma", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "sub", "(", "'tion$'", ",", "'te'", ",", "lemma", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "sub", "(", "'ied$'", ",", "'y'", ",", "lemma", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "sub", "(", "'ly$'", ",", "''", ",", "lemma", ")", "==", "instance_lemma", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.__str__": [[462, 466], ["str", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "lemmas", "=", "self", ".", "amr", ".", "lemmas", "\n", "negations", "=", "[", "(", "lemmas", "[", "i", "]", ",", "lemmas", "[", "j", "]", ")", "for", "i", ",", "j", "in", "self", ".", "negations", "]", "\n", "return", "'Negations: {}\\nSpecials:{}\\n'", ".", "format", "(", "str", "(", "negations", ")", ",", "str", "(", "self", ".", "special_negations", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.__init__": [[108, 116], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "span", "=", "None", ",", "node", "=", "None", ",", "ner_type", "=", "None", ",", "amr_type", "=", "None", ",", "confidence", "=", "0", ",", "alignment", "=", "None", ")", ":", "\n", "        ", "self", ".", "span", "=", "span", "\n", "self", ".", "node", "=", "node", "\n", "self", ".", "ner_type", "=", "ner_type", "\n", "self", ".", "amr_type", "=", "amr_type", "\n", "self", ".", "confidence", "=", "confidence", "\n", "self", ".", "alignment", "=", "alignment", "\n", "self", ".", "debug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.__str__": [[117, 119], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'node:{}\\nalignment:{}'", ".", "format", "(", "str", "(", "self", ".", "node", ")", ",", "self", ".", "alignment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_text_spans": [[120, 140], ["spans.append", "spans.append", "entity.rephrase_ops", "spans.append", "span.append", "str", "re.search", "span.append", "re.search", "span.append", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.rephrase_ops"], ["", "def", "get_text_spans", "(", "self", ",", "amr", ")", ":", "\n", "        ", "spans", "=", "[", "]", "\n", "span", "=", "[", "]", "\n", "for", "index", "in", "self", ".", "span", ":", "\n", "            ", "span", ".", "append", "(", "amr", ".", "tokens", "[", "index", "]", ")", "\n", "", "spans", ".", "append", "(", "' '", ".", "join", "(", "span", ")", ")", "\n", "span", "=", "[", "]", "\n", "for", "op", "in", "self", ".", "node", ".", "ops", ":", "\n", "            ", "op", "=", "str", "(", "op", ")", "\n", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "                ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "span", ".", "append", "(", "op", ")", "\n", "", "spans", ".", "append", "(", "' '", ".", "join", "(", "span", ")", ")", "\n", "span", "=", "[", "]", "\n", "for", "op", "in", "rephrase_ops", "(", "self", ".", "node", ".", "ops", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "                ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "span", ".", "append", "(", "op", ")", "\n", "", "spans", ".", "append", "(", "' '", ".", "join", "(", "span", ")", ")", "\n", "return", "[", "span", "for", "span", "in", "spans", "if", "len", "(", "span", ")", ">", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_ops": [[141, 149], ["str", "re.search", "ops.append"], "methods", ["None"], ["", "def", "get_ops", "(", "self", ")", ":", "\n", "        ", "ops", "=", "[", "]", "\n", "for", "op", "in", "self", ".", "node", ".", "ops", ":", "\n", "            ", "op", "=", "str", "(", "op", ")", "\n", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "                ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "ops", ".", "append", "(", "op", ")", "\n", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_aligned_entity": [[150, 167], ["cls.get_alignment_for_ops", "cls", "cls._get_aligned_info", "cls.get_alignment_for_ops", "cls", "cls._get_aligned_info", "len", "entity.rephrase_ops", "len", "cls.get_alignment_for_ops", "entity.tokenize_ops"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_alignment_for_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity._get_aligned_info", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_alignment_for_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity._get_aligned_info", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.rephrase_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_alignment_for_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.tokenize_ops"], ["", "@", "classmethod", "\n", "def", "get_aligned_entity", "(", "cls", ",", "node", ",", "amr", ",", "backup_ner_type", ",", "entity_type_lut", ")", ":", "\n", "        ", "if", "len", "(", "node", ".", "ops", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "alignment", "=", "cls", ".", "get_alignment_for_ops", "(", "rephrase_ops", "(", "node", ".", "ops", ")", ",", "amr", ")", "\n", "if", "len", "(", "alignment", ")", "==", "0", ":", "\n", "            ", "alignment", "=", "cls", ".", "get_alignment_for_ops", "(", "node", ".", "ops", ",", "amr", ")", "\n", "", "entity1", "=", "cls", "(", "node", "=", "node", ",", "alignment", "=", "alignment", ")", "\n", "entity1", ".", "_get_aligned_info", "(", "amr", ",", "backup_ner_type", ",", "entity_type_lut", ")", "\n", "\n", "alignment", "=", "cls", ".", "get_alignment_for_ops", "(", "tokenize_ops", "(", "node", ".", "ops", ")", ",", "amr", ")", "\n", "entity2", "=", "cls", "(", "node", "=", "node", ",", "alignment", "=", "alignment", ")", "\n", "entity2", ".", "_get_aligned_info", "(", "amr", ",", "backup_ner_type", ",", "entity_type_lut", ")", "\n", "\n", "entity", "=", "entity2", "if", "entity2", ".", "confidence", ">", "entity1", ".", "confidence", "else", "entity1", "\n", "\n", "return", "entity", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_alignment_for_ops": [[168, 178], ["enumerate", "enumerate", "entity.Entity.maybe_align_op_to"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.maybe_align_op_to"], ["", "@", "staticmethod", "\n", "def", "get_alignment_for_ops", "(", "ops", ",", "amr", ")", ":", "\n", "        ", "alignment", "=", "{", "}", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "ops", ")", ":", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "                ", "confidence", "=", "Entity", ".", "maybe_align_op_to", "(", "op", ",", "j", ",", "amr", ")", "\n", "if", "confidence", ">", "0", ":", "\n", "                    ", "if", "j", "not", "in", "alignment", "or", "(", "j", "in", "alignment", "and", "alignment", "[", "j", "]", "[", "1", "]", "<", "confidence", ")", ":", "\n", "                        ", "alignment", "[", "j", "]", "=", "(", "i", ",", "confidence", ")", "\n", "", "", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.maybe_align_op_to": [[179, 215], ["re.search", "str.lower", "amr.tokens[].lower", "amr.lemmas[].lower", "entity.strip_lemma", "isinstance", "str", "STEMMER", "amr.is_named_entity", "max", "entity.Entity.maybe_align_op_to"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.strip_lemma", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.is_named_entity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.maybe_align_op_to"], ["", "@", "staticmethod", "\n", "def", "maybe_align_op_to", "(", "op", ",", "index", ",", "amr", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "op", ",", "str", ")", ":", "\n", "            ", "op", "=", "str", "(", "op", ")", "\n", "", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "            ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "op_lower", "=", "op", ".", "lower", "(", ")", "\n", "token_lower", "=", "amr", ".", "tokens", "[", "index", "]", ".", "lower", "(", ")", "\n", "lemma_lower", "=", "amr", ".", "lemmas", "[", "index", "]", ".", "lower", "(", ")", "\n", "stripped_lemma_lower", "=", "strip_lemma", "(", "lemma_lower", ")", "\n", "# Exact match.", "\n", "if", "amr", ".", "tokens", "[", "index", "]", "==", "op", "or", "amr", ".", "lemmas", "[", "index", "]", "==", "op", ":", "\n", "            ", "return", "15", "\n", "", "elif", "op_lower", "==", "token_lower", "or", "op_lower", "==", "lemma_lower", "or", "op_lower", "==", "stripped_lemma_lower", ":", "\n", "            ", "return", "10", "\n", "# Stem exact match.", "\n", "", "elif", "STEMMER", "(", "op", ")", "==", "amr", ".", "stems", "[", "index", "]", ":", "\n", "            ", "return", "8", "\n", "# Tagged as named entity and match the first 3 chars.", "\n", "", "elif", "amr", ".", "is_named_entity", "(", "index", ")", "and", "(", "\n", "op_lower", "[", ":", "3", "]", "==", "token_lower", "[", ":", "3", "]", "or", "\n", "op_lower", "[", ":", "3", "]", "==", "lemma_lower", "[", ":", "3", "]", "or", "\n", "op_lower", "[", ":", "3", "]", "==", "stripped_lemma_lower", "[", ":", "3", "]", "\n", ")", ":", "\n", "            ", "return", "5", "\n", "# Match the first 3 chars.", "\n", "", "elif", "(", "op_lower", "[", ":", "3", "]", "==", "token_lower", "[", ":", "3", "]", "or", "\n", "op_lower", "[", ":", "3", "]", "==", "lemma_lower", "[", ":", "3", "]", "or", "\n", "op_lower", "[", ":", "3", "]", "==", "stripped_lemma_lower", "[", ":", "3", "]", "\n", ")", ":", "\n", "            ", "return", "1", "\n", "# Match after mapping.", "\n", "", "elif", "op", "in", "Entity", ".", "entity_map", ":", "\n", "            ", "return", "max", "(", "Entity", ".", "maybe_align_op_to", "(", "mapped_op", ",", "index", ",", "amr", ")", "for", "mapped_op", "in", "Entity", ".", "entity_map", "[", "op", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.collapse_name_nodes": [[216, 243], ["entities.sort", "len", "collections.defaultdict", "len", "entity.Entity.save_collapsed_name_node", "amr.replace_span", "amr.graph.remove_node_ops", "amr.graph.replace_node_attribute", "amr.graph.remove_node", "len", "len", "float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.save_collapsed_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node"], ["", "", "@", "staticmethod", "\n", "def", "collapse_name_nodes", "(", "entities", ",", "amr", ",", "type_counter", "=", "None", ")", ":", "\n", "        ", "if", "amr", ".", "abstract_map", "is", "None", ":", "\n", "            ", "amr", ".", "abstract_map", "=", "{", "}", "\n", "", "if", "len", "(", "entities", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "if", "type_counter", "is", "None", ":", "\n", "            ", "type_counter", "=", "defaultdict", "(", "int", ")", "\n", "", "entities", ".", "sort", "(", "key", "=", "lambda", "entity", ":", "entity", ".", "span", "[", "-", "1", "]", "if", "len", "(", "entity", ".", "span", ")", "else", "float", "(", "'inf'", ")", ")", "\n", "offset", "=", "0", "\n", "for", "entity", "in", "entities", ":", "\n", "            ", "if", "len", "(", "entity", ".", "span", ")", ">", "0", ":", "\n", "                ", "type_counter", "[", "entity", ".", "ner_type", "]", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "\n", "entity", ".", "ner_type", ",", "type_counter", "[", "entity", ".", "ner_type", "]", ")", "\n", "span_with_offset", "=", "[", "index", "-", "offset", "for", "index", "in", "entity", ".", "span", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "Entity", ".", "save_collapsed_name_node", "(", "\n", "entity", ",", "span_with_offset", ",", "amr", ")", "\n", "amr", ".", "replace_span", "(", "span_with_offset", ",", "[", "abstract", "]", ",", "[", "'NNP'", "]", ",", "[", "entity", ".", "ner_type", "]", ")", "\n", "amr", ".", "stems", "=", "amr", ".", "stems", "[", ":", "span_with_offset", "[", "0", "]", "]", "+", "[", "abstract", "]", "+", "amr", ".", "stems", "[", "span_with_offset", "[", "-", "1", "]", "+", "1", ":", "]", "\n", "amr", ".", "graph", ".", "remove_node_ops", "(", "entity", ".", "node", ")", "\n", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "entity", ".", "node", ",", "'instance'", ",", "entity", ".", "node", ".", "instance", ",", "abstract", ")", "\n", "offset", "+=", "len", "(", "entity", ".", "span", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "amr", ".", "graph", ".", "remove_node", "(", "entity", ".", "node", ")", "\n", "", "", "return", "type_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.save_collapsed_name_node": [[244, 250], ["dict", "map", "entity.get_ops"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.get_ops"], ["", "@", "staticmethod", "\n", "def", "save_collapsed_name_node", "(", "entity", ",", "span", ",", "amr", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "type", "=", "'named-entity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "ops", "=", "' '", ".", "join", "(", "entity", ".", "get_ops", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity._get_aligned_info": [[252, 293], ["entity.group_indexes_to_spans", "entity.Entity.sort", "entity.Entity._clean_span", "amr.graph.get_name_node_type", "len", "entity.Entity.alignment.keys", "sum", "candidate_spans.append", "max", "set", "list", "max", "len", "token[].isupper", "list.add", "len", "list", "entity_type_lut[].items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.group_indexes_to_spans", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._clean_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "_get_aligned_info", "(", "self", ",", "amr", ",", "backup_ner_type", ",", "entity_type_lut", ")", ":", "\n", "        ", "spans", "=", "group_indexes_to_spans", "(", "self", ".", "alignment", ".", "keys", "(", ")", ",", "amr", ")", "\n", "spans", ".", "sort", "(", "key", "=", "lambda", "span", ":", "len", "(", "span", ")", ",", "reverse", "=", "True", ")", "\n", "spans", "=", "self", ".", "_clean_span", "(", "spans", ",", "amr", ")", "\n", "amr_type", "=", "amr", ".", "graph", ".", "get_name_node_type", "(", "self", ".", "node", ")", "\n", "candidate_spans", "=", "[", "]", "\n", "for", "span", "in", "spans", ":", "\n", "            ", "confidence", "=", "sum", "(", "self", ".", "alignment", "[", "j", "]", "[", "1", "]", "for", "j", "in", "span", "if", "j", "in", "self", ".", "alignment", ")", "\n", "candidate_spans", ".", "append", "(", "(", "span", ",", "confidence", ")", ")", "\n", "", "if", "len", "(", "candidate_spans", ")", ":", "\n", "            ", "best_span", ",", "confidence", "=", "max", "(", "candidate_spans", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "# Default is backup ner type.", "\n", "ner_type", "=", "backup_ner_type", "\n", "\n", "# If all tokens have the same ner type, use it.", "\n", "possible_ner_types", "=", "set", "(", ")", "\n", "for", "index", "in", "best_span", ":", "\n", "                ", "token", "=", "amr", ".", "tokens", "[", "index", "]", "\n", "ner_tag", "=", "amr", ".", "ner_tags", "[", "index", "]", "\n", "if", "ner_tag", "not", "in", "(", "'0'", ",", "'O'", ")", "or", "token", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "                    ", "possible_ner_types", ".", "add", "(", "ner_tag", ")", "\n", "", "", "possible_ner_types", "=", "list", "(", "possible_ner_types", ")", "\n", "if", "len", "(", "possible_ner_types", ")", "==", "1", "and", "possible_ner_types", "[", "0", "]", "not", "in", "(", "'O'", ",", "'0'", ")", ":", "\n", "                ", "ner_type", "=", "list", "(", "possible_ner_types", ")", "[", "0", "]", "\n", "\n", "# Get the high-frequency ner type from lut.", "\n", "", "entity_mention", "=", "' '", ".", "join", "(", "[", "amr", ".", "tokens", "[", "index", "]", "for", "index", "in", "best_span", "]", ")", ".", "lower", "(", ")", "\n", "if", "entity_mention", "in", "entity_type_lut", ":", "\n", "                ", "entity_type", ",", "freq", "=", "max", "(", "entity_type_lut", "[", "entity_mention", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "if", "freq", ">", "50", ":", "\n", "                    ", "ner_type", "=", "entity_type", "\n", "\n", "", "", "self", ".", "span", "=", "best_span", "\n", "self", ".", "ner_type", "=", "ner_type", "\n", "self", ".", "amr_type", "=", "amr_type", "\n", "self", ".", "confidence", "=", "confidence", "\n", "", "else", ":", "\n", "            ", "self", ".", "span", "=", "[", "]", "\n", "self", ".", "ner_type", "=", "backup_ner_type", "\n", "self", ".", "amr_type", "=", "amr_type", "\n", "self", ".", "confidence", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity._clean_span": [[294, 318], ["entity.group_indexes_to_spans", "clean_spans.append", "entity.strip_span", "max", "len", "ret_spans.append", "trivial_indexes.append", "_align.values", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.group_indexes_to_spans", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.strip_span"], ["", "", "def", "_clean_span", "(", "self", ",", "spans", ",", "amr", ")", ":", "\n", "# Make sure each op only appears once in a span.", "\n", "        ", "clean_spans", "=", "[", "]", "\n", "for", "span", "in", "spans", ":", "\n", "            ", "_align", "=", "{", "}", "\n", "trivial_indexes", "=", "[", "]", "\n", "for", "index", "in", "span", ":", "\n", "                ", "if", "index", "not", "in", "self", ".", "alignment", ":", "\n", "                    ", "trivial_indexes", ".", "append", "(", "index", ")", "\n", "continue", "\n", "", "op", ",", "confidence", "=", "self", ".", "alignment", "[", "index", "]", "\n", "if", "op", "not", "in", "_align", "or", "(", "op", "in", "_align", "and", "_align", "[", "op", "]", "[", "1", "]", "<", "confidence", ")", ":", "\n", "                    ", "_align", "[", "op", "]", "=", "(", "index", ",", "confidence", ")", "\n", "", "", "indexes", "=", "[", "i", "for", "i", ",", "_", "in", "_align", ".", "values", "(", ")", "]", "+", "trivial_indexes", "\n", "_spans", "=", "group_indexes_to_spans", "(", "indexes", ",", "amr", ")", "\n", "clean_spans", ".", "append", "(", "max", "(", "_spans", ",", "key", "=", "lambda", "s", ":", "len", "(", "s", ")", ")", ")", "\n", "\n", "# Strip trivial tokens", "\n", "", "ret_spans", "=", "[", "]", "\n", "for", "span", "in", "clean_spans", ":", "\n", "            ", "span", "=", "strip_span", "(", "span", ",", "amr", ".", "tokens", ")", "\n", "if", "len", "(", "span", ")", ">", "0", ":", "\n", "                ", "ret_spans", ".", "append", "(", "span", ")", "\n", "", "", "return", "ret_spans", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.strip_lemma": [[10, 18], ["len", "len"], "function", ["None"], ["def", "strip_lemma", "(", "lemma", ")", ":", "\n", "# Remove twitter '@'.", "\n", "    ", "if", "len", "(", "lemma", ")", "and", "lemma", "[", "0", "]", "==", "'@'", ":", "\n", "        ", "lemma", "=", "lemma", "[", "1", ":", "]", "\n", "# Remove '-$' suffix.", "\n", "", "if", "len", "(", "lemma", ")", "and", "lemma", "[", "-", "1", "]", "==", "'$'", ":", "\n", "        ", "lemma", "=", "lemma", "[", ":", "-", "1", "]", "\n", "", "return", "lemma", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.strip_span": [[20, 34], ["len", "len", "re.search", "re.search"], "function", ["None"], ["", "def", "strip_span", "(", "span", ",", "tokens", ")", ":", "\n", "    ", "start", "=", "0", "\n", "while", "start", "<", "len", "(", "span", ")", ":", "\n", "        ", "token", "=", "tokens", "[", "span", "[", "start", "]", "]", "\n", "if", "not", "re", ".", "search", "(", "r'^(in|of|at|-|,)$'", ",", "token", ")", ":", "\n", "            ", "break", "\n", "", "start", "+=", "1", "\n", "", "end", "=", "len", "(", "span", ")", "-", "1", "\n", "while", "end", ">", "start", ":", "\n", "        ", "token", "=", "tokens", "[", "span", "[", "end", "]", "]", "\n", "if", "not", "re", ".", "search", "(", "r'^(in|of|at|-|,)$'", ",", "token", ")", ":", "\n", "            ", "break", "\n", "", "end", "-=", "1", "\n", "", "return", "span", "[", "start", ":", "end", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.rephrase_ops": [[36, 50], ["map", "ret.append", "ret.append", "ret.append", "ret.append", "ret.append"], "function", ["None"], ["", "def", "rephrase_ops", "(", "ops", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "joined_ops", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "ops", ")", ")", "\n", "if", "joined_ops", "==", "'\"United\" \"States\"'", ":", "\n", "        ", "ret", ".", "append", "(", "'\"America\"'", ")", "\n", "", "elif", "joined_ops", "==", "'\"World\" \"War\" \"II\"'", ":", "\n", "        ", "ret", ".", "append", "(", "'\"WWII\"'", ")", "\n", "", "elif", "joined_ops", "==", "'\"Republican\" \"National\" \"Convention\"'", ":", "\n", "        ", "ret", ".", "append", "(", "'\"RNC\"'", ")", "\n", "", "elif", "joined_ops", "==", "'\"Grand\" \"Old\" \"Party\"'", ":", "\n", "        ", "ret", ".", "append", "(", "'\"GOP\"'", ")", "\n", "", "elif", "joined_ops", "==", "'\"United\" \"Nations\"'", ":", "\n", "        ", "ret", ".", "append", "(", "'\"U.N.\"'", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.tokenize_ops": [[52, 62], ["re.search", "re.split", "isinstance"], "function", ["None"], ["", "def", "tokenize_ops", "(", "ops", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "op", "in", "ops", ":", "\n", "        ", "if", "not", "isinstance", "(", "op", ",", "str", ")", ":", "\n", "            ", "ret", "+=", "[", "op", "]", "\n", "continue", "\n", "", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "op", ")", ":", "\n", "            ", "op", "=", "op", "[", "1", ":", "-", "1", "]", "\n", "", "ret", "+=", "re", ".", "split", "(", "r\"(-|'s|n't|')\"", ",", "op", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.group_indexes_to_spans": [[64, 80], ["list", "list.sort", "spans[].append", "spans.append", "re.search", "spans[].append", "spans.append"], "function", ["None"], ["", "def", "group_indexes_to_spans", "(", "indexes", ",", "amr", ")", ":", "\n", "    ", "indexes", "=", "list", "(", "indexes", ")", "\n", "indexes", ".", "sort", "(", ")", "\n", "spans", "=", "[", "]", "\n", "last_index", "=", "None", "\n", "for", "idx", "in", "indexes", ":", "\n", "        ", "if", "last_index", "is", "None", "or", "idx", "-", "last_index", ">", "2", ":", "\n", "            ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "elif", "idx", "-", "last_index", "==", "2", ":", "\n", "            ", "if", "re", ".", "search", "(", "r\"(,|'s|of|'|-|in)\"", ",", "amr", ".", "tokens", "[", "idx", "-", "1", "]", ")", ":", "\n", "                ", "spans", "[", "-", "1", "]", ".", "append", "(", "idx", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "", "last_index", "=", "idx", "\n", "spans", "[", "-", "1", "]", ".", "append", "(", "idx", ")", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.__init__": [[2, 8], ["score.Score._get_alignment", "score.Score._get_best_span"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score._get_best_span"], ["    ", "def", "__init__", "(", "self", ",", "node", ",", "amr", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "self", ".", "amr", "=", "amr", "\n", "self", ".", "alignment", "=", "self", ".", "_get_alignment", "(", ")", "\n", "self", ".", "span", "=", "self", ".", "_get_best_span", "(", "self", ".", "alignment", ")", "\n", "self", ".", "ner_type", "=", "'SCORE_ENTITY'", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.to_dict": [[9, 14], ["map"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ",", "amr", ",", "span", ")", ":", "\n", "        ", "return", "{", "\n", "'type'", ":", "'score-entity'", ",", "\n", "'span'", ":", "' '", ".", "join", "(", "map", "(", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "'ops'", ":", "self", ".", "node", ".", "ops", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score._get_alignment": [[15, 24], ["enumerate", "enumerate", "score.Score._maybe_align"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align"], ["", "def", "_get_alignment", "(", "self", ")", ":", "\n", "        ", "alignment", "=", "{", "}", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "self", ".", "node", ".", "ops", ")", ":", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "self", ".", "amr", ".", "tokens", ")", ":", "\n", "                ", "confidence", "=", "self", ".", "_maybe_align", "(", "op", ",", "j", ")", "\n", "if", "confidence", ">", "0", ":", "\n", "                    ", "if", "j", "not", "in", "alignment", "or", "alignment", "[", "j", "]", "[", "1", "]", "<", "confidence", ":", "\n", "                        ", "alignment", "[", "j", "]", "=", "(", "i", ",", "confidence", ")", "\n", "", "", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score._maybe_align": [[25, 30], ["str"], "methods", ["None"], ["", "def", "_maybe_align", "(", "self", ",", "op", ",", "index", ")", ":", "\n", "        ", "op", "=", "str", "(", "op", ")", "\n", "if", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "in", "(", "op", ",", "'-'", "+", "op", ")", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score._get_best_span": [[31, 54], ["list", "list.sort", "len", "alignment.keys", "spans[].append", "max", "spans.append", "spans.append", "range", "sum", "spans[].append", "spans.append"], "methods", ["None"], ["", "def", "_get_best_span", "(", "self", ",", "alignment", ")", ":", "\n", "        ", "indexes", "=", "list", "(", "alignment", ".", "keys", "(", ")", ")", "\n", "indexes", ".", "sort", "(", ")", "\n", "spans", "=", "[", "]", "\n", "last_index", "=", "None", "\n", "for", "index", "in", "indexes", ":", "\n", "            ", "if", "last_index", "is", "None", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "elif", "index", "-", "last_index", ">", "3", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "last_index", "+", "1", ",", "index", ")", ":", "\n", "                    ", "if", "self", ".", "amr", ".", "lemmas", "[", "i", "]", "in", "(", "'-'", ",", "'to'", ",", "':'", ",", "'vote'", ")", ":", "\n", "                        ", "spans", "[", "-", "1", "]", ".", "append", "(", "index", "-", "1", ")", "\n", "", "else", ":", "\n", "                        ", "spans", ".", "append", "(", "[", "]", ")", "\n", "break", "\n", "", "", "", "last_index", "=", "index", "\n", "spans", "[", "-", "1", "]", ".", "append", "(", "index", ")", "\n", "", "if", "len", "(", "spans", ")", ":", "\n", "            ", "return", "max", "(", "spans", ",", "key", "=", "lambda", "x", ":", "sum", "(", "[", "alignment", "[", "i", "]", "[", "1", "]", "for", "i", "in", "x", "if", "i", "in", "alignment", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.collapse_score_nodes": [[55, 74], ["scores.sort", "score.to_dict", "amr.replace_span", "amr.graph.remove_node_ops", "amr.graph.replace_node_attribute", "amr.graph.remove_node", "len", "float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.to_dict", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node"], ["", "", "@", "staticmethod", "\n", "def", "collapse_score_nodes", "(", "scores", ",", "amr", ")", ":", "\n", "        ", "score_node_count", "=", "0", "\n", "scores", ".", "sort", "(", "key", "=", "lambda", "score", ":", "score", ".", "span", "[", "-", "1", "]", "if", "score", ".", "span", "is", "not", "None", "else", "float", "(", "'inf'", ")", ")", "\n", "offset", "=", "0", "\n", "for", "score", "in", "scores", ":", "\n", "            ", "if", "score", ".", "span", "is", "not", "None", ":", "\n", "                ", "score_node_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "score", ".", "ner_type", ",", "score_node_count", ")", "\n", "span", "=", "[", "index", "-", "offset", "for", "index", "in", "score", ".", "span", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "score", ".", "to_dict", "(", "amr", ",", "span", ")", "\n", "amr", ".", "replace_span", "(", "span", ",", "[", "abstract", "]", ",", "[", "'NNP'", "]", ",", "[", "score", ".", "ner_type", "]", ")", "\n", "amr", ".", "stems", "=", "amr", ".", "stems", "[", ":", "span", "[", "0", "]", "]", "+", "[", "abstract", "]", "+", "amr", ".", "stems", "[", "span", "[", "-", "1", "]", "+", "1", ":", "]", "\n", "amr", ".", "graph", ".", "remove_node_ops", "(", "score", ".", "node", ")", "\n", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "score", ".", "node", ",", "'instance'", ",", "score", ".", "node", ".", "instance", ",", "abstract", ")", "\n", "offset", "+=", "len", "(", "score", ".", "span", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "amr", ".", "graph", ".", "remove_node", "(", "score", ".", "node", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.__init__": [[32, 38], ["date.Date._get_attributes_and_edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_attributes_and_edges"], ["def", "__init__", "(", "self", ",", "node", ",", "graph", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "self", ".", "attributes", ",", "self", ".", "edges", "=", "self", ".", "_get_attributes_and_edges", "(", "node", ",", "graph", ")", "\n", "self", ".", "span", "=", "None", "\n", "self", ".", "confidence", "=", "0", "\n", "self", ".", "ner_type", "=", "'DATE_ATTRS'", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.collapsable": [[39, 47], ["any", "list", "graph._G.edges"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collapsable", "(", "node", ",", "graph", ")", ":", "\n", "        ", "if", "any", "(", "attr", "in", "Date", ".", "attribute_list", "for", "attr", ",", "_", "in", "node", ".", "attributes", ")", ":", "\n", "            ", "return", "True", "\n", "", "edges", "=", "list", "(", "graph", ".", "_G", ".", "edges", "(", "node", ")", ")", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "            ", "if", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "in", "Date", ".", "edge_list", ":", "\n", "                ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.collapse_date_nodes": [[48, 78], ["dates.sort", "Date.save_collapsed_date_node", "amr.replace_span", "list", "amr.graph.replace_node_attribute", "date.attributes.items", "date.attributes.items", "amr.graph._G.edges", "amr.graph.remove_node_attribute", "len", "amr.graph.remove_node_attribute", "float", "amr.graph.remove_edge", "amr.graph.remove_subtree"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.save_collapsed_date_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree"], ["", "", "", "@", "staticmethod", "\n", "def", "collapse_date_nodes", "(", "dates", ",", "amr", ")", ":", "\n", "        ", "if", "amr", ".", "abstract_map", "is", "None", ":", "\n", "            ", "amr", ".", "abstract_map", "=", "{", "}", "\n", "", "dates", ".", "sort", "(", "key", "=", "lambda", "date", ":", "date", ".", "span", "[", "-", "1", "]", "if", "date", ".", "span", "else", "float", "(", "'inf'", ")", ")", "\n", "offset", "=", "0", "\n", "align_count", "=", "0", "\n", "for", "date", "in", "dates", ":", "\n", "            ", "if", "date", ".", "span", ":", "\n", "                ", "align_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "date", ".", "ner_type", ",", "align_count", ")", "\n", "span_with_offset", "=", "[", "index", "-", "offset", "for", "index", "in", "date", ".", "span", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "Date", ".", "save_collapsed_date_node", "(", "\n", "date", ",", "span_with_offset", ",", "amr", ")", "\n", "amr", ".", "replace_span", "(", "span_with_offset", ",", "[", "abstract", "]", ",", "[", "'NNP'", "]", ",", "[", "date", ".", "ner_type", "]", ")", "\n", "# Remove edges", "\n", "for", "source", ",", "target", "in", "list", "(", "amr", ".", "graph", ".", "_G", ".", "edges", "(", "date", ".", "node", ")", ")", ":", "\n", "                    ", "edge_label", "=", "amr", ".", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "edge_label", "in", "Date", ".", "edge_list", ":", "\n", "                        ", "amr", ".", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "amr", ".", "graph", ".", "remove_subtree", "(", "target", ")", "\n", "# Update instance", "\n", "", "", "amr", ".", "graph", ".", "replace_node_attribute", "(", "date", ".", "node", ",", "'instance'", ",", "'date-entity'", ",", "abstract", ")", "\n", "# Remove attributes", "\n", "for", "attr", ",", "value", "in", "date", ".", "attributes", ".", "items", "(", ")", ":", "\n", "                    ", "amr", ".", "graph", ".", "remove_node_attribute", "(", "date", ".", "node", ",", "attr", ",", "value", ")", "\n", "", "offset", "+=", "len", "(", "date", ".", "span", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "for", "attr", ",", "value", "in", "date", ".", "attributes", ".", "items", "(", ")", ":", "\n", "                    ", "amr", ".", "graph", ".", "remove_node_attribute", "(", "date", ".", "node", ",", "attr", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.save_collapsed_date_node": [[79, 86], ["dict", "map"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "save_collapsed_date_node", "(", "date", ",", "span", ",", "amr", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "type", "=", "'date-entity'", ",", "\n", "span", "=", "' '", ".", "join", "(", "map", "(", "amr", ".", "tokens", ".", "__getitem__", ",", "span", ")", ")", ",", "\n", "attrs", "=", "date", ".", "attributes", ",", "\n", "edges", "=", "date", ".", "edges", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_attributes_and_edges": [[88, 96], ["graph._G.edges"], "methods", ["None"], ["", "def", "_get_attributes_and_edges", "(", "self", ",", "node", ",", "graph", ")", ":", "\n", "        ", "attributes", "=", "{", "attr", ":", "value", "for", "attr", ",", "value", "in", "node", ".", "attributes", "if", "attr", "in", "self", ".", "attribute_list", "}", "\n", "edges", "=", "{", "}", "\n", "for", "source", ",", "target", "in", "graph", ".", "_G", ".", "edges", "(", "node", ")", ":", "\n", "            ", "label", "=", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "label", "in", "self", ".", "edge_list", ":", "\n", "                ", "edges", "[", "label", "]", "=", "target", ".", "instance", "\n", "", "", "return", "attributes", ",", "edges", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._is_covered": [[97, 105], ["date.Date.attributes.copy", "len", "date.Date.pop"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy"], ["", "def", "_is_covered", "(", "self", ",", "alignment", ")", ":", "\n", "        ", "attributes", "=", "self", ".", "attributes", ".", "copy", "(", ")", "\n", "for", "index", "in", "self", ".", "span", ":", "\n", "            ", "if", "index", "in", "alignment", ":", "\n", "                ", "for", "item", ",", "_", "in", "alignment", "[", "index", "]", ":", "\n", "                    ", "if", "item", "[", "0", "]", "in", "attributes", ":", "\n", "                        ", "attributes", ".", "pop", "(", "item", "[", "0", "]", ")", "\n", "", "", "", "", "return", "len", "(", "attributes", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_alignment": [[106, 115], ["collections.defaultdict", "list", "list", "range", "date.Date.attributes.items", "date.Date.edges.items", "len", "date.Date._maybe_align", "alignment[].append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align"], ["", "def", "_get_alignment", "(", "self", ",", "amr", ")", ":", "\n", "        ", "alignment", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "list", "(", "self", ".", "attributes", ".", "items", "(", ")", ")", "+", "list", "(", "self", ".", "edges", ".", "items", "(", ")", ")", ":", "\n", "            ", "attr", ",", "value", "=", "item", "\n", "for", "i", "in", "range", "(", "len", "(", "amr", ".", "tokens", ")", ")", ":", "\n", "                ", "confidence", "=", "self", ".", "_maybe_align", "(", "attr", ",", "value", ",", "i", ",", "amr", ")", "\n", "if", "confidence", "!=", "0", ":", "\n", "                    ", "alignment", "[", "i", "]", ".", "append", "(", "(", "item", ",", "confidence", ")", ")", "\n", "", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_span": [[116, 132], ["date.Date.group_indexes_to_spans", "span_scores.sort", "len", "alignment.keys", "set", "span_scores.append", "max", "sum", "len", "len", "set.add", "sum", "max", "max"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.group_indexes_to_spans"], ["", "def", "_get_span", "(", "self", ",", "alignment", ",", "amr", ")", ":", "\n", "        ", "spans", "=", "self", ".", "group_indexes_to_spans", "(", "alignment", ".", "keys", "(", ")", ",", "amr", ")", "\n", "span_scores", "=", "[", "]", "\n", "for", "span", "in", "spans", ":", "\n", "            ", "attr_set", "=", "set", "(", ")", "\n", "for", "index", "in", "span", ":", "\n", "                ", "if", "index", "in", "alignment", ":", "\n", "                    ", "for", "item", ",", "_", "in", "alignment", "[", "index", "]", ":", "\n", "                        ", "attr_set", ".", "add", "(", "item", "[", "0", "]", ")", "\n", "", "", "", "span_scores", ".", "append", "(", "(", "span", ",", "len", "(", "span", ")", ",", "len", "(", "attr_set", ")", ")", ")", "\n", "", "span_scores", ".", "sort", "(", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "x", "[", "2", "]", ")", ",", "reverse", "=", "True", ")", "\n", "spans", "=", "[", "span", "for", "span", ",", "_", ",", "_", "in", "span_scores", "]", "\n", "if", "len", "(", "spans", ")", ":", "\n", "            ", "self", ".", "span", "=", "max", "(", "spans", ",", "key", "=", "lambda", "span", ":", "sum", "(", "\n", "max", "(", "alignment", "[", "i", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "[", "1", "]", "for", "i", "in", "span", "if", "i", "in", "alignment", ")", ")", "\n", "self", ".", "confidence", "=", "sum", "(", "max", "(", "alignment", "[", "i", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "[", "1", "]", "for", "i", "in", "self", ".", "span", "if", "i", "in", "alignment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._clean_span": [[133, 150], ["date.Date.group_indexes_to_spans", "clean_spans.append", "max", "trivial_indexes.append", "_align.values", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.group_indexes_to_spans"], ["", "", "def", "_clean_span", "(", "self", ",", "spans", ",", "alignment", ",", "amr", ")", ":", "\n", "# Make sure each op only appears once in a span.", "\n", "        ", "clean_spans", "=", "[", "]", "\n", "for", "span", "in", "spans", ":", "\n", "            ", "_align", "=", "{", "}", "\n", "trivial_indexes", "=", "[", "]", "\n", "for", "index", "in", "span", ":", "\n", "                ", "if", "index", "not", "in", "alignment", ":", "\n", "                    ", "trivial_indexes", ".", "append", "(", "index", ")", "\n", "continue", "\n", "", "for", "item", ",", "confidence", "in", "alignment", "[", "index", "]", ":", "\n", "                    ", "if", "item", "not", "in", "_align", "or", "_align", "[", "item", "]", "[", "1", "]", "<", "confidence", ":", "\n", "                        ", "_align", "[", "item", "]", "=", "(", "index", ",", "confidence", ")", "\n", "", "", "", "indexes", "=", "[", "i", "for", "i", ",", "_", "in", "_align", ".", "values", "(", ")", "]", "+", "trivial_indexes", "\n", "_spans", "=", "self", ".", "group_indexes_to_spans", "(", "indexes", ",", "amr", ")", "\n", "clean_spans", ".", "append", "(", "max", "(", "_spans", ",", "key", "=", "lambda", "s", ":", "len", "(", "s", ")", ")", ")", "\n", "", "return", "clean_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align": [[151, 174], ["date.Date._maybe_align_year", "date.Date._maybe_align_month", "date.Date._maybe_align_day", "date.Date._maybe_align_decade", "date.Date._maybe_align_time", "date.Date._maybe_align_century", "date.Date._maybe_align_era", "date.Date._maybe_align_quant", "date.Date._maybe_align_quarter", "date.Date._maybe_align_weekday", "date.Date._maybe_align_basic"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_year", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_month", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_day", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_decade", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_time", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_century", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_era", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_quant", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_quarter", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_weekday", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align", "(", "self", ",", "attr", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "if", "attr", "==", "'year'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_year", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'month'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_month", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'day'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_day", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'decade'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_decade", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'time'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_time", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'century'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_century", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'era'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_era", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'quant'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_quant", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'quarter'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_quarter", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "elif", "attr", "==", "'weekday'", ":", "\n", "            ", "return", "self", ".", "_maybe_align_weekday", "(", "value", ",", "index", ",", "amr", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic": [[175, 187], ["str().lower", "re.search", "date.Date._strip_date_lemma", "str().lower.endswith", "str", "amr.tokens[].lower", "amr.lemmas[].lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._strip_date_lemma"], ["", "", "def", "_maybe_align_basic", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", ".", "lower", "(", ")", "\n", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "value", ")", ":", "\n", "            ", "value", "=", "value", "[", "1", ":", "-", "1", "]", "\n", "", "if", "amr", ".", "tokens", "[", "index", "]", ".", "lower", "(", ")", "==", "value", "or", "amr", ".", "lemmas", "[", "index", "]", ".", "lower", "(", ")", "==", "value", ":", "\n", "            ", "return", "10", "\n", "", "stripped_lemma", "=", "self", ".", "_strip_date_lemma", "(", "amr", ".", "lemmas", "[", "index", "]", ")", "\n", "if", "stripped_lemma", "==", "value", ":", "\n", "            ", "return", "10", "\n", "", "elif", "value", ".", "endswith", "(", "stripped_lemma", ")", ":", "\n", "            ", "return", "8", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._strip_date_lemma": [[188, 195], ["len", "len"], "methods", ["None"], ["", "def", "_strip_date_lemma", "(", "self", ",", "lemma", ")", ":", "\n", "# Remove '-'.", "\n", "        ", "if", "len", "(", "lemma", ")", "and", "lemma", "[", "0", "]", "==", "'-'", ":", "\n", "            ", "lemma", "=", "lemma", "[", "1", ":", "]", "\n", "", "if", "len", "(", "lemma", ")", "and", "lemma", "[", "-", "1", "]", "==", "'-'", ":", "\n", "            ", "lemma", "=", "lemma", "[", ":", "-", "1", "]", "\n", "", "return", "lemma", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_year": [[196, 212], ["date.Date._maybe_align_basic", "date.Date._strip_date_lemma", "str", "str", "lemma.startswith", "date.Date.startswith"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._strip_date_lemma"], ["", "def", "_maybe_align_year", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "stripped_lemma", "=", "self", ".", "_strip_date_lemma", "(", "lemma", ")", "\n", "year_short", "=", "str", "(", "value", ")", "[", "-", "2", ":", "]", "\n", "if", "':'", "not", "in", "lemma", "and", "(", "lemma", ".", "startswith", "(", "year_short", ")", "or", "stripped_lemma", ".", "startswith", "(", "year_short", ")", ")", ":", "\n", "            ", "return", "10", "\n", "", "year_with_s", "=", "str", "(", "value", ")", "+", "'s'", "\n", "if", "year_with_s", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "year_with_stroke", "=", "\"'\"", "+", "year_short", "\n", "if", "year_with_stroke", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_month": [[213, 226], ["date.Date._maybe_align_basic", "month.lower", "lemma.lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_month", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "if", "0", "<", "value", "<", "13", ":", "\n", "            ", "for", "month", "in", "self", ".", "month_map", "[", "value", "-", "1", "]", ":", "\n", "                ", "if", "month", ".", "lower", "(", ")", "==", "lemma", ".", "lower", "(", ")", ":", "\n", "                    ", "return", "15", "\n", "", "", "", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "month_fixed_length", "=", "'{:02d}'", ".", "format", "(", "value", ")", "\n", "if", "month_fixed_length", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_day": [[227, 250], ["date.Date._maybe_align_basic", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_day", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "day_fixed_length", "=", "'{:02d}'", ".", "format", "(", "value", ")", "\n", "if", "day_fixed_length", "==", "lemma", ":", "\n", "            ", "return", "10", "\n", "", "day", "=", "str", "(", "value", ")", "\n", "if", "(", "day", "+", "'th'", "==", "lemma", "or", "\n", "day", "+", "'st'", "==", "lemma", "or", "\n", "day", "+", "'nd'", "==", "lemma", "or", "\n", "day", "+", "'rd'", "==", "lemma", "or", "\n", "day", "+", "'sr'", "==", "lemma", "\n", ")", ":", "\n", "            ", "return", "10", "\n", "", "if", "value", "==", "1", "and", "lemma", "==", "'first'", ":", "\n", "            ", "return", "8", "\n", "", "if", "value", "==", "2", "and", "lemma", "==", "'second'", ":", "\n", "            ", "return", "8", "\n", "", "if", "value", "==", "3", "and", "lemma", "==", "'third'", ":", "\n", "            ", "return", "8", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_decade": [[251, 269], ["date.Date._maybe_align_basic", "date.Date._maybe_align_year", "lemma.endswith", "str", "str", "w2n.word_to_num"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_year"], ["", "def", "_maybe_align_decade", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "year_confidence", "=", "self", ".", "_maybe_align_year", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "year_confidence", "!=", "0", ":", "\n", "            ", "return", "year_confidence", "\n", "", "try", ":", "\n", "            ", "w2n_number", "=", "str", "(", "w2n", ".", "word_to_num", "(", "amr", ".", "lemmas", "[", "index", "]", ")", ")", "\n", "", "except", ":", "\n", "            ", "w2n_number", "=", "None", "\n", "", "decade_short", "=", "str", "(", "value", ")", "[", "-", "2", ":", "]", "\n", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "if", "lemma", ".", "endswith", "(", "decade_short", "+", "'s'", ")", ":", "\n", "            ", "return", "10", "\n", "", "if", "decade_short", "==", "w2n_number", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_time": [[270, 295], ["re.search", "date.Date._maybe_align_basic", "re.search", "re.search", "str", "re.search", "re.search.group", "re.search.group", "re.search.group", "re.search.group", "re.search.group", "re.search.group", "re.search.group", "int", "re.search.group", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_time", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "value", ")", ":", "\n", "            ", "value", "=", "value", "[", "1", ":", "-", "1", "]", "\n", "", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "m", "=", "re", ".", "search", "(", "r'^(\\d{2})(\\d{2})(\\d{0,2})$'", ",", "lemma", ")", "\n", "if", "m", "is", "None", "or", "m", ".", "group", "(", "1", ")", "==", "''", ":", "\n", "            ", "m", "=", "re", ".", "search", "(", "r'-?(\\d{1,2})[:.]?(\\d{0,2})[:.]?(\\d{0,2}).*$'", ",", "lemma", ")", "\n", "if", "m", "is", "None", "or", "m", ".", "group", "(", "1", ")", "==", "''", ":", "\n", "                ", "return", "0", "\n", "", "", "_hour", ",", "_min", ",", "_sec", "=", "m", ".", "group", "(", "1", ")", ",", "m", ".", "group", "(", "2", ")", ",", "m", ".", "group", "(", "3", ")", "\n", "m", "=", "re", ".", "search", "(", "r'(\\d*)[:.]?(\\d*)[:.]?(\\d*)$'", ",", "value", ")", "\n", "hour", ",", "min", ",", "sec", "=", "m", ".", "group", "(", "1", ")", ",", "m", ".", "group", "(", "2", ")", ",", "m", ".", "group", "(", "3", ")", "\n", "hour_in_12", "=", "str", "(", "int", "(", "hour", ")", "-", "12", ")", "\n", "if", "(", "(", "_sec", "==", "'00'", "or", "_sec", "==", "''", ")", "and", "(", "sec", "==", "'00'", "or", "sec", "==", "''", ")", ")", "or", "_sec", "==", "sec", ":", "\n", "            ", "if", "(", "(", "_min", "==", "'00'", "or", "_min", "==", "''", ")", "and", "(", "min", "==", "'00'", "or", "min", "==", "''", ")", ")", "or", "_min", "==", "min", ":", "\n", "                ", "if", "_hour", "==", "hour", "or", "int", "(", "_hour", ")", "==", "int", "(", "hour", ")", ":", "\n", "                    ", "return", "10", "\n", "", "elif", "_hour", "==", "hour_in_12", "or", "int", "(", "_hour", ")", "==", "int", "(", "hour_in_12", ")", ":", "\n", "                    ", "return", "8", "\n", "", "elif", "_hour", "==", "'12'", "and", "hour", "==", "'0'", ":", "\n", "                    ", "return", "8", "\n", "", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_century": [[296, 306], ["str", "date.Date._maybe_align_basic", "re.search", "re.search.group"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_century", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", "\n", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "m", "=", "re", ".", "search", "(", "r'^(\\d+)(st|nd|rd|th)?(century)?$'", ",", "lemma", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "1", ")", "==", "value", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_era": [[307, 318], ["str", "date.Date._maybe_align_basic", "amr.lemmas[].replace", "re.search", "date.Date.era_map.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "_maybe_align_era", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", "\n", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", ".", "replace", "(", "'.'", ",", "''", ")", "\n", "if", "re", ".", "search", "(", "r'^\".*\"$'", ",", "value", ")", ":", "\n", "            ", "value", "=", "value", "[", "1", ":", "-", "1", "]", "\n", "", "if", "value", "==", "lemma", "or", "lemma", "in", "self", ".", "era_map", ".", "get", "(", "value", ",", "[", "]", ")", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_quant": [[319, 328], ["str", "date.Date._maybe_align_basic"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_quant", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", "\n", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "if", "value", "==", "'1'", "and", "(", "lemma", "==", "'one'", "or", "lemma", "==", "'a'", ")", ":", "\n", "            ", "return", "8", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_quarter": [[329, 342], ["str", "date.Date._maybe_align_basic", "str", "w2n.word_to_num"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_quarter", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", "\n", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "try", ":", "\n", "            ", "w2n_number", "=", "str", "(", "w2n", ".", "word_to_num", "(", "lemma", ")", ")", "\n", "", "except", ":", "\n", "            ", "w2n_number", "=", "None", "\n", "", "if", "w2n_number", "==", "lemma", ":", "\n", "            ", "return", "8", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_weekday": [[343, 352], ["str().lower", "date.Date._maybe_align_basic", "amr.lemmas[].lower", "str().lower.startswith", "amr.lemmas[].lower.startswith", "amr.lemmas[].lower.endswith", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._maybe_align_basic"], ["", "def", "_maybe_align_weekday", "(", "self", ",", "value", ",", "index", ",", "amr", ")", ":", "\n", "        ", "value", "=", "str", "(", "value", ")", ".", "lower", "(", ")", "\n", "basic_confidence", "=", "self", ".", "_maybe_align_basic", "(", "value", ",", "index", ",", "amr", ")", "\n", "if", "basic_confidence", "!=", "0", ":", "\n", "            ", "return", "basic_confidence", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", ".", "lower", "(", ")", "\n", "if", "value", ".", "startswith", "(", "lemma", ")", "or", "lemma", ".", "startswith", "(", "value", ")", "or", "lemma", ".", "endswith", "(", "value", ")", ":", "\n", "            ", "return", "10", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.group_indexes_to_spans": [[353, 373], ["list", "list.sort", "spans[].append", "spans.append", "range", "re.search", "list", "spans.append", "range"], "methods", ["None"], ["", "def", "group_indexes_to_spans", "(", "self", ",", "indexes", ",", "amr", ")", ":", "\n", "        ", "indexes", "=", "list", "(", "indexes", ")", "\n", "indexes", ".", "sort", "(", ")", "\n", "spans", "=", "[", "]", "\n", "last_index", "=", "None", "\n", "for", "idx", "in", "indexes", ":", "\n", "            ", "if", "last_index", "is", "None", "or", "idx", "-", "last_index", ">", "3", ":", "\n", "                ", "spans", ".", "append", "(", "[", "]", ")", "\n", "", "elif", "idx", "-", "last_index", "<=", "3", ":", "\n", "                ", "for", "i", "in", "range", "(", "last_index", "+", "1", ",", "idx", ")", ":", "\n", "                    ", "if", "re", ".", "search", "(", "r\"(,|'s|of|'|-|in|at|on|about|the|every|\\(|\\))\"", ",", "amr", ".", "tokens", "[", "idx", "-", "1", "]", ")", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "spans", ".", "append", "(", "[", "]", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                    ", "spans", "[", "-", "1", "]", "+=", "list", "(", "range", "(", "last_index", "+", "1", ",", "idx", ")", ")", "\n", "", "", "last_index", "=", "idx", "\n", "spans", "[", "-", "1", "]", ".", "append", "(", "idx", ")", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.__init__": [[10, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "amr", ",", "dry", "=", "False", ")", ":", "\n", "        ", "self", ".", "amr", "=", "amr", "\n", "self", ".", "dry", "=", "dry", "\n", "self", ".", "heads", "=", "[", "]", "\n", "self", ".", "true_positive", "=", "0", "\n", "self", ".", "false_positive", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.remove_polite": [[17, 26], ["polite.Polite.amr.graph.get_nodes", "polite.Polite.amr.graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "def", "remove_polite", "(", "self", ")", ":", "\n", "        ", "count", "=", "0", "\n", "for", "node", "in", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'polite'", ":", "\n", "                    ", "if", "not", "self", ".", "dry", ":", "\n", "                        ", "self", ".", "amr", ".", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "", "count", "+=", "1", "\n", "", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.predict_polite": [[27, 36], ["range", "len", "polite.Polite.heads.append", "polite.Polite.heads.append", "polite.Polite.heads.append"], "methods", ["None"], ["", "def", "predict_polite", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "amr", ".", "tokens", ")", ")", ":", "\n", "            ", "if", "self", ".", "amr", ".", "lemmas", "[", "i", "]", "==", "'please'", ":", "\n", "                ", "if", "self", ".", "amr", ".", "lemmas", "[", "i", "+", "1", ":", "i", "+", "3", "]", "==", "[", "'take'", ",", "'a'", "]", ":", "\n", "                    ", "self", ".", "heads", ".", "append", "(", "(", "i", ",", "i", "+", "3", ")", ")", "\n", "", "elif", "i", "-", "2", ">=", "0", "and", "self", ".", "amr", ".", "lemmas", "[", "i", "-", "2", "]", "==", "'can'", ":", "\n", "                    ", "self", ".", "heads", ".", "append", "(", "(", "i", ",", "i", "-", "2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "heads", ".", "append", "(", "(", "i", ",", "i", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.restore_polite": [[37, 42], ["polite.Polite.amr.graph.get_nodes", "polite.Polite.is_match", "polite.Polite.restore_node_polite"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.restore_node_polite"], ["", "", "", "", "def", "restore_polite", "(", "self", ")", ":", "\n", "        ", "for", "polite_index", ",", "head_index", "in", "self", ".", "heads", ":", "\n", "            ", "for", "node", "in", "self", ".", "amr", ".", "graph", ".", "get_nodes", "(", ")", ":", "\n", "                ", "if", "self", ".", "is_match", "(", "head_index", ",", "node", ")", ":", "\n", "                    ", "self", ".", "restore_node_polite", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.restore_node_polite": [[43, 53], ["polite.Polite.amr.graph.add_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "", "", "", "def", "restore_node_polite", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "self", ".", "dry", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'polite'", ":", "\n", "                    ", "self", ".", "true_positive", "+=", "1", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "false_positive", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "amr", ".", "graph", ".", "add_node_attribute", "(", "node", ",", "'polite'", ",", "'+'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.is_match": [[54, 61], ["re.sub", "polite.Polite.lemma_map.get", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "", "def", "is_match", "(", "self", ",", "index", ",", "node", ")", ":", "\n", "        ", "instance_lemma", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "str", "(", "node", ".", "instance", ")", ")", "\n", "lemma", "=", "self", ".", "amr", ".", "lemmas", "[", "index", "]", "\n", "lemma", "=", "self", ".", "lemma_map", ".", "get", "(", "lemma", ",", "lemma", ")", "\n", "if", "instance_lemma", "==", "lemma", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.node_restore.NodeRestore.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "node_utils", ")", ":", "\n", "        ", "self", ".", "node_utils", "=", "node_utils", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.node_restore.NodeRestore.restore_instance": [[9, 17], ["graph.get_nodes", "node_restore.NodeRestore.node_utils.get_frames", "graph.replace_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_frames", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "restore_instance", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "instance", "=", "node", ".", "instance", "\n", "new_instance", "=", "self", ".", "node_utils", ".", "get_frames", "(", "instance", ")", "[", "0", "]", "\n", "if", "instance", "!=", "new_instance", ":", "\n", "                ", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "instance", ",", "new_instance", ")", "\n", "", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.node_restore.NodeRestore.restore_file": [[18, 22], ["stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "node_restore.NodeRestore.restore_instance"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.node_restore.NodeRestore.restore_instance"], ["", "", "def", "restore_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "amr", "in", "AMRIO", ".", "read", "(", "file_path", ")", ":", "\n", "            ", "self", ".", "restore_instance", "(", "amr", ")", "\n", "yield", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.__init__": [[32, 39], ["collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "util_dir", ")", ":", "\n", "        ", "self", ".", "util_dir", "=", "util_dir", "\n", "self", ".", "wiki_span_cooccur_counter", "=", "None", "\n", "self", ".", "spotlight_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "nationality_map", "=", "{", "}", "\n", "self", ".", "name_node_count", "=", "0", "\n", "self", ".", "correct_wikification_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.reset_stats": [[40, 43], ["None"], "methods", ["None"], ["", "def", "reset_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "name_node_count", "=", "0", "\n", "self", ".", "correct_wikification_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.print_stats": [[44, 47], ["logger.info"], "methods", ["None"], ["", "def", "print_stats", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Correctly wikify {}/{} name nodes.'", ".", "format", "(", "\n", "self", ".", "correct_wikification_count", ",", "self", ".", "name_node_count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify_file": [[48, 52], ["enumerate", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "wikification.Wikification.wikify_graph"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify_graph"], ["", "def", "wikify_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ")", ":", "\n", "            ", "self", ".", "wikify_graph", "(", "amr", ")", "\n", "yield", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify_graph": [[53, 77], ["graph.get_nodes", "wikification.strip", "graph.set_name_node_wiki", "strip.lower", "wikification.Wikification.wikify", "wikification.Wikification.wikify", "wikification.joint_dash", "wikification.Wikification.wikify", "strip.lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.set_name_node_wiki", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.joint_dash", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify"], ["", "", "def", "wikify_graph", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "abstract_map", "=", "amr", ".", "abstract_map", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "instance", "=", "node", ".", "instance", "\n", "if", "instance", "in", "abstract_map", ":", "\n", "                ", "saved_dict", "=", "abstract_map", "[", "instance", "]", "\n", "instance_type", "=", "saved_dict", "[", "'type'", "]", "\n", "# amr_type = graph.get_name_node_type(node)", "\n", "#!!! the following line has been changed by Deng Cai", "\n", "cached_wiki", "=", "self", ".", "_spotlight_wiki", "[", "amr", ".", "sentence", "]", "if", "amr", ".", "sentence", "in", "self", ".", "_spotlight_wiki", "else", "None", "#self.spotlight_wiki(amr.sentence)", "\n", "if", "instance_type", "==", "'named-entity'", ":", "\n", "                    ", "self", ".", "name_node_count", "+=", "1", "\n", "wiki", "=", "'-'", "\n", "span", "=", "strip", "(", "saved_dict", "[", "'span'", "]", ")", "\n", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "nationality_map", ":", "\n", "                        ", "country", "=", "self", ".", "nationality_map", "[", "span", ".", "lower", "(", ")", "]", "\n", "wiki", "=", "self", ".", "wikify", "(", "country", ",", "cached_wiki", ")", "\n", "", "if", "wiki", "==", "'-'", ":", "\n", "                        ", "wiki", "=", "self", ".", "wikify", "(", "span", ",", "cached_wiki", ")", "\n", "", "if", "wiki", "==", "'-'", ":", "\n", "                        ", "span_no_space", "=", "joint_dash", "(", "span", ")", "\n", "wiki", "=", "self", ".", "wikify", "(", "span_no_space", ",", "cached_wiki", ")", "\n", "", "graph", ".", "set_name_node_wiki", "(", "node", ",", "wiki", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.wikify": [[78, 100], ["text.lower.lower.lower", "text.lower.lower.split", "max", "cached_wiki.values", "max", "len", "wikification.Wikification.wiki_span_cooccur_counter[].items", "wikification.Wikification.spotlight_cooccur_counter[].items", "mention.split", "wiki.lower().split", "max", "abs", "abs", "wikification.Wikification.spotlight_cooccur_counter[].items", "wiki.lower", "len", "len", "len", "len", "abs", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "", "", "def", "wikify", "(", "self", ",", "text", ",", "cached_wiki", "=", "None", ")", ":", "\n", "        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "if", "text", "in", "self", ".", "wiki_span_cooccur_counter", ":", "\n", "            ", "return", "max", "(", "self", ".", "wiki_span_cooccur_counter", "[", "text", "]", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "abs", "(", "len", "(", "text", ")", "-", "len", "(", "x", "[", "0", "]", ")", ")", ")", ")", "[", "0", "]", "\n", "", "elif", "cached_wiki", "is", "not", "None", ":", "\n", "            ", "for", "wiki", "in", "cached_wiki", ".", "values", "(", ")", ":", "\n", "                ", "if", "text", "==", "' '", ".", "join", "(", "wiki", ".", "lower", "(", ")", ".", "split", "(", "'_'", ")", ")", ":", "\n", "                    ", "return", "wiki", "\n", "", "", "", "if", "text", "in", "self", ".", "spotlight_cooccur_counter", ":", "\n", "            ", "return", "max", "(", "self", ".", "spotlight_cooccur_counter", "[", "text", "]", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "abs", "(", "len", "(", "text", ")", "-", "len", "(", "x", "[", "0", "]", ")", ")", ")", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "text", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", ">", "1", ":", "\n", "                ", "s_token", ",", "e_token", "=", "tokens", "[", "0", "]", ",", "tokens", "[", "-", "1", "]", "\n", "for", "mention", "in", "self", ".", "spotlight_cooccur_counter", ":", "\n", "                    ", "m", "=", "mention", ".", "split", "(", ")", "\n", "if", "m", "[", "0", "]", "==", "s_token", "and", "m", "[", "-", "1", "]", "==", "e_token", ":", "\n", "                        ", "return", "max", "(", "self", ".", "spotlight_cooccur_counter", "[", "mention", "]", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "abs", "(", "len", "(", "mention", ")", "-", "len", "(", "x", "[", "0", "]", ")", ")", ")", ")", "[", "0", "]", "\n", "", "", "", "return", "'-'", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.load_utils": [[101, 124], ["json.load.values", "open", "json.load", "open", "json.load", "cached_wiki.items", "open", "json.load", "os.path.join", "os.path.join", "os.path.join", "n.strip", "nationalities.remove", "country[].split", "len", "nationality.lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "", "def", "load_utils", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'wiki_span_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "wiki_span_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'spotlight_wiki.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "spotlight_wiki", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "_spotlight_wiki", "=", "spotlight_wiki", "\n", "for", "cached_wiki", "in", "spotlight_wiki", ".", "values", "(", ")", ":", "\n", "            ", "for", "mention", ",", "wiki", "in", "cached_wiki", ".", "items", "(", ")", ":", "\n", "                ", "if", "mention", "==", "'xp'", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "spotlight_cooccur_counter", "[", "mention", "]", "[", "wiki", "]", "+=", "1", "\n", "\n", "# The country list is downloaded from github:", "\n", "# https://github.com/Dinu/country-nationality-list", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'countries.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "countries", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "country", "in", "countries", ":", "\n", "                ", "nationalities", "=", "[", "n", ".", "strip", "(", ")", "for", "n", "in", "country", "[", "'nationality'", "]", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "nationalities", ")", ">", "1", "and", "'Chinese'", "in", "nationalities", ":", "\n", "                    ", "nationalities", ".", "remove", "(", "'Chinese'", ")", "\n", "", "for", "nationality", "in", "nationalities", ":", "\n", "                    ", "self", ".", "nationality_map", "[", "nationality", ".", "lower", "(", ")", "]", "=", "country", "[", "'en_short_name'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.spotlight_wiki": [[125, 146], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "logger.info", "requests.post", "wiki_tag.get().split", "logger.info", "time.sleep", "wiki_tag.string.lower", "wiki_tag.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "", "", "", "@", "staticmethod", "\n", "def", "spotlight_wiki", "(", "sent", ",", "confidence", "=", "0.5", ")", ":", "\n", "        ", "success", "=", "False", "\n", "while", "not", "success", ":", "\n", "            ", "try", ":", "\n", "                ", "spotlight", "=", "requests", ".", "post", "(", "\n", "\"http://model.dbpedia-spotlight.org/en/annotate\"", ",", "\n", "data", "=", "{", "'text'", ":", "sent", ",", "'confidence'", ":", "confidence", "}", "\n", ")", "\n", "spotlight", ".", "encoding", "=", "'utf-8'", "\n", "", "except", "requests", ".", "exceptions", ".", "ConnectionError", ":", "\n", "                ", "logger", ".", "info", "(", "'sleeping a bit (spotlight overload) - if this keeps happening server is down or changed'", ")", "\n", "sleep", "(", "0.1", ")", "\n", "continue", "\n", "", "success", "=", "True", "\n", "", "parsed_spotlight", "=", "BeautifulSoup", "(", "spotlight", ".", "text", ",", "'lxml'", ")", "\n", "mention_map", "=", "{", "}", "\n", "for", "wiki_tag", "in", "parsed_spotlight", ".", "find_all", "(", "'a'", ")", ":", "\n", "            ", "mention_map", "[", "wiki_tag", ".", "string", ".", "lower", "(", ")", "]", "=", "wiki_tag", ".", "get", "(", "'href'", ")", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "", "logger", ".", "info", "(", "mention_map", ")", "\n", "return", "mention_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.dump_spotlight_wiki": [[147, 158], ["enumerate", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "wikification.Wikification.spotlight_wiki", "time.sleep", "open", "json.dump", "print", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.Wikification.spotlight_wiki", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "def", "dump_spotlight_wiki", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "sent_map", "=", "{", "}", "\n", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ",", "1", ")", ":", "\n", "            ", "if", "i", "%", "20", "==", "0", ":", "\n", "                ", "print", "(", "'+'", ",", "end", "=", "''", ")", "\n", "", "sent", "=", "amr", ".", "sentence", "\n", "wiki", "=", "self", ".", "spotlight_wiki", "(", "sent", ")", "\n", "sent_map", "[", "sent", "]", "=", "wiki", "\n", "sleep", "(", "0.1", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'spotlight_wiki.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "sent_map", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip": [[16, 24], ["text[].strip", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["def", "strip", "(", "text", ")", ":", "\n", "    ", "start", "=", "0", "\n", "while", "text", "[", "start", "]", "==", "'-'", "and", "start", "<", "len", "(", "text", ")", "-", "1", ":", "\n", "        ", "start", "+=", "1", "\n", "", "end", "=", "len", "(", "text", ")", "-", "1", "\n", "while", "text", "[", "end", "]", "==", "'-'", "and", "end", ">", "start", ":", "\n", "        ", "end", "-=", "1", "\n", "", "return", "text", "[", "start", ":", "end", "+", "1", "]", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.joint_dash": [[26, 28], ["text.replace"], "function", ["None"], ["", "def", "joint_dash", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "replace", "(", "' - '", ",", "'-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.__init__": [[36, 48], ["expander.Expander._load_utils"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._load_utils"], ["    ", "def", "__init__", "(", "self", ",", "util_dir", ")", ":", "\n", "        ", "self", ".", "util_dir", "=", "util_dir", "\n", "self", ".", "name_ops_map", "=", "{", "}", "\n", "self", ".", "nationality_map", "=", "{", "}", "\n", "self", ".", "_load_utils", "(", ")", "\n", "self", ".", "name_node_expand_count", "=", "0", "\n", "self", ".", "date_node_expand_count", "=", "0", "\n", "self", ".", "score_node_expand_count", "=", "0", "\n", "self", ".", "url_expand_count", "=", "0", "\n", "self", ".", "ordinal_node_expand_count", "=", "0", "\n", "self", ".", "quantity_expand_count", "=", "0", "\n", "self", ".", "correctly_restored_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.reset_stats": [[49, 56], ["None"], "methods", ["None"], ["", "def", "reset_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "name_node_expand_count", "=", "0", "\n", "self", ".", "date_node_expand_count", "=", "0", "\n", "self", ".", "score_node_expand_count", "=", "0", "\n", "self", ".", "quantity_expand_count", "=", "0", "\n", "self", ".", "url_expand_count", "=", "0", "\n", "self", ".", "ordinal_node_expand_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.print_stats": [[57, 65], ["logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info"], "methods", ["None"], ["", "def", "print_stats", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Restored {} name nodes.'", ".", "format", "(", "self", ".", "correctly_restored_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} name nodes.'", ".", "format", "(", "self", ".", "name_node_expand_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} date nodes.'", ".", "format", "(", "self", ".", "date_node_expand_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} score nodes.'", ".", "format", "(", "self", ".", "score_node_expand_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} ordinal nodes.'", ".", "format", "(", "self", ".", "ordinal_node_expand_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} quantities.'", ".", "format", "(", "self", ".", "quantity_expand_count", ")", ")", "\n", "logger", ".", "info", "(", "'Expanded {} urls.'", ".", "format", "(", "self", ".", "url_expand_count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_file": [[66, 71], ["enumerate", "expander.Expander.print_stats", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "expander.Expander.expand_graph"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.print_stats", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_graph"], ["", "def", "expand_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ")", ":", "\n", "            ", "self", ".", "expand_graph", "(", "amr", ")", "\n", "yield", "amr", "\n", "", "self", ".", "print_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_graph": [[72, 106], ["expander.Expander.restore_polarity", "list", "abstract_map.items", "graph.get_nodes", "expander.Expander.expand_name_node", "expander.Expander.expand_date_node", "expander.Expander.expand_score_node", "expander.Expander.expand_ordinal_node", "str", "graph.replace_node_attribute", "graph.replace_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.restore_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_date_node", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_score_node", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_ordinal_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "expand_graph", "(", "self", ",", "amr", ")", ":", "\n", "        ", "self", ".", "restore_polarity", "(", "amr", ")", "\n", "graph", "=", "amr", ".", "graph", "\n", "abstract_map", "=", "amr", ".", "abstract_map", "\n", "nodes", "=", "list", "(", "graph", ".", "get_nodes", "(", ")", ")", "\n", "for", "abstract", ",", "saved_dict", "in", "abstract_map", ".", "items", "(", ")", ":", "\n", "            ", "abstract_type", "=", "saved_dict", "[", "'type'", "]", "\n", "for", "node", "in", "nodes", ":", "\n", "                ", "if", "node", ".", "instance", "==", "abstract", ":", "\n", "                    ", "if", "abstract_type", "==", "'named-entity'", ":", "\n", "                        ", "self", ".", "expand_name_node", "(", "node", ",", "saved_dict", ",", "amr", ")", "\n", "self", ".", "name_node_expand_count", "+=", "1", "\n", "\n", "", "if", "abstract_type", "==", "'date-entity'", ":", "\n", "                        ", "self", ".", "expand_date_node", "(", "node", ",", "saved_dict", ",", "amr", ")", "\n", "self", ".", "date_node_expand_count", "+=", "1", "\n", "\n", "", "if", "abstract_type", "==", "'score-entity'", ":", "\n", "                        ", "self", ".", "expand_score_node", "(", "node", ",", "saved_dict", ",", "amr", ")", "\n", "self", ".", "score_node_expand_count", "+=", "1", "\n", "\n", "", "if", "abstract_type", "==", "'ordinal-entity'", ":", "\n", "                        ", "self", ".", "expand_ordinal_node", "(", "node", ",", "saved_dict", ",", "amr", ")", "\n", "self", ".", "ordinal_node_expand_count", "+=", "1", "\n", "\n", "", "", "for", "attr", ",", "value", "in", "node", ".", "attributes", "[", ":", "]", ":", "\n", "                    ", "if", "str", "(", "value", ")", "==", "abstract", ":", "\n", "                        ", "if", "abstract_type", "==", "'quantity'", ":", "\n", "                            ", "graph", ".", "replace_node_attribute", "(", "node", ",", "attr", ",", "value", ",", "saved_dict", "[", "'value'", "]", ")", "\n", "self", ".", "quantity_expand_count", "+=", "1", "\n", "\n", "", "if", "abstract_type", "==", "'url-entity'", ":", "\n", "                            ", "graph", ".", "replace_node_attribute", "(", "node", ",", "attr", ",", "value", ",", "saved_dict", "[", "'value'", "]", ")", "\n", "self", ".", "url_expand_count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.restore_polarity": [[107, 114], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity.predict_polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity.restore_polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite.predict_polite", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite.restore_polite"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.predict_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.restore_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.predict_polite", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.restore_polite"], ["", "", "", "", "", "", "def", "restore_polarity", "(", "self", ",", "amr", ")", ":", "\n", "        ", "polarity", "=", "Polarity", "(", "amr", ")", "\n", "polarity", ".", "predict_polarity", "(", ")", "\n", "polarity", ".", "restore_polarity", "(", ")", "\n", "polite", "=", "Polite", "(", "amr", ")", "\n", "polite", ".", "predict_polite", "(", ")", "\n", "polite", ".", "restore_polite", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.get_ops": [[115, 138], ["normalize_text.split", "normalize_text.lower", "normalize_text.lower", "expander.normalize_text", "re.search", "ops.append", "max", "normalize_text.lower", "normalize_text.lower", "expander.Expander.name_ops_map[].items", "float", "int", "normalize_text.lower", "normalize_text.lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.normalize_text", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "def", "get_ops", "(", "self", ",", "saved_dict", ")", ":", "\n", "        ", "span", "=", "saved_dict", "[", "'span'", "]", "\n", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "nationality_map", ":", "\n", "            ", "span", "=", "self", ".", "nationality_map", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "name_ops_map", ":", "\n", "            ", "span", "=", "max", "(", "self", ".", "name_ops_map", "[", "span", ".", "lower", "(", ")", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "span", "=", "normalize_text", "(", "span", ")", "\n", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "nationality_map", ":", "\n", "                ", "span", "=", "self", ".", "nationality_map", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "", "ops", "=", "[", "]", "\n", "for", "op", "in", "span", ".", "split", "(", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^\\d*\\.*\\d*$'", ",", "op", ")", ":", "\n", "                ", "if", "'.'", "in", "op", ":", "\n", "                    ", "op", "=", "float", "(", "op", ")", "\n", "", "else", ":", "\n", "                    ", "op", "=", "int", "(", "op", ")", "\n", "", "", "else", ":", "\n", "                ", "op", "=", "'\"{}\"'", ".", "format", "(", "op", ")", "\n", "", "ops", ".", "append", "(", "op", ")", "\n", "", "if", "span", "==", "saved_dict", "[", "'ops'", "]", ":", "\n", "            ", "self", ".", "correctly_restored_count", "+=", "1", "\n", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_name_node": [[139, 146], ["expander.Expander.get_ops", "graph.replace_node_attribute", "enumerate", "graph.add_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.get_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "def", "expand_name_node", "(", "self", ",", "node", ",", "saved_dict", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "ops", "=", "self", ".", "get_ops", "(", "saved_dict", ")", "\n", "old", "=", "node", ".", "instance", "\n", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "old", ",", "'name'", ")", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "ops", ",", "1", ")", ":", "\n", "            ", "graph", ".", "add_node_attribute", "(", "node", ",", "'op{}'", ".", "format", "(", "i", ")", ",", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_date_node": [[147, 157], ["graph.replace_node_attribute", "attrs.items", "edges.items", "graph.add_node_attribute", "graph.add_node", "graph.add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge"], ["", "", "def", "expand_date_node", "(", "self", ",", "node", ",", "saved_dict", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "attrs", "=", "saved_dict", "[", "'attrs'", "]", "\n", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "node", ".", "instance", ",", "'date-entity'", ")", "\n", "for", "key", ",", "value", "in", "attrs", ".", "items", "(", ")", ":", "\n", "            ", "graph", ".", "add_node_attribute", "(", "node", ",", "key", ",", "value", ")", "\n", "", "edges", "=", "saved_dict", "[", "'edges'", "]", "\n", "for", "label", ",", "instance", "in", "edges", ".", "items", "(", ")", ":", "\n", "            ", "target", "=", "graph", ".", "add_node", "(", "instance", ")", "\n", "graph", ".", "add_edge", "(", "node", ",", "target", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_score_node": [[158, 163], ["graph.replace_node_attribute", "enumerate", "graph.add_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "", "def", "expand_score_node", "(", "self", ",", "node", ",", "saved_dict", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "node", ".", "instance", ",", "'score-entity'", ")", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "saved_dict", "[", "'ops'", "]", ",", "1", ")", ":", "\n", "            ", "graph", ".", "add_node_attribute", "(", "node", ",", "'op{}'", ".", "format", "(", "i", ")", ",", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.expand_ordinal_node": [[164, 168], ["graph.replace_node_attribute", "graph.add_node_attribute", "int"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node_attribute"], ["", "", "def", "expand_ordinal_node", "(", "self", ",", "node", ",", "saved_dict", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "node", ".", "instance", ",", "'ordinal-entity'", ")", "\n", "graph", ".", "add_node_attribute", "(", "node", ",", "'value'", ",", "int", "(", "saved_dict", "[", "'ops'", "]", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander._load_utils": [[169, 195], ["open", "json.load", "expander.Expander.name_ops_map[].pop", "open", "json.load", "os.path.join", "os.path.join", "n.strip", "nationalities.remove", "country[].split", "len", "nationality.lower"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "_load_utils", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'name_op_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "name_ops_map", "=", "json", ".", "load", "(", "f", ")", "\n", "self", ".", "name_ops_map", "[", "'u.n.'", "]", ".", "pop", "(", "'United Nations'", ")", "\n", "\n", "# The country list is downloaded from github:", "\n", "# https://github.com/Dinu/country-nationality-list", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "util_dir", ",", "'countries.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "countries", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "country", "in", "countries", ":", "\n", "                ", "nationalities", "=", "[", "n", ".", "strip", "(", ")", "for", "n", "in", "country", "[", "'nationality'", "]", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "nationalities", ")", ">", "1", "and", "'Chinese'", "in", "nationalities", ":", "\n", "                    ", "nationalities", ".", "remove", "(", "'Chinese'", ")", "\n", "", "for", "nationality", "in", "nationalities", ":", "\n", "                    ", "self", ".", "nationality_map", "[", "nationality", ".", "lower", "(", ")", "]", "=", "country", "[", "'en_short_name'", "]", "\n", "", "", "", "self", ".", "nationality_map", "[", "'american'", "]", "=", "'United States'", "\n", "self", ".", "nationality_map", "[", "'british'", "]", "=", "'Britain'", "\n", "self", ".", "nationality_map", "[", "'brazilians'", "]", "=", "'Brazil'", "\n", "self", ".", "nationality_map", "[", "'russian'", "]", "=", "'Russia'", "\n", "self", ".", "nationality_map", "[", "'north korean'", "]", "=", "'North Korea'", "\n", "self", ".", "nationality_map", "[", "'south korean'", "]", "=", "'South Korea'", "\n", "self", ".", "nationality_map", "[", "'himalayan'", "]", "=", "'Himalaya'", "\n", "self", ".", "nationality_map", "[", "'venezuelan'", "]", "=", "'Venezuela'", "\n", "self", ".", "nationality_map", "[", "'kirghizian'", "]", "=", "'Kirghizia'", "\n", "self", ".", "nationality_map", "[", "'venezuelans'", "]", "=", "'Venezuela'", "\n", "self", ".", "nationality_map", "[", "'shiites'", "]", "=", "'Shiite'", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.normalize_text": [[17, 32], ["text.capitalize.replace().replace().replace", "text.capitalize.split", "any", "[].islower", "text.capitalize.capitalize", "tokens[].isupper", "tokens[].isalpha", "text.capitalize.replace().replace", "t[].isupper", "n_tokens.append", "len", "len", "len", "token[].upper", "token[].lower", "text.capitalize.replace", "any", "token[].upper", "c.isupper"], "function", ["None"], ["def", "normalize_text", "(", "text", ")", ":", "\n", "    ", "text", "=", "text", ".", "replace", "(", "' - '", ",", "'-'", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "' , '", ",", "', '", ")", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "if", "any", "(", "t", "[", "0", "]", ".", "isupper", "(", ")", "for", "t", "in", "tokens", ")", ":", "\n", "        ", "n_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "token", "not", "in", "TRIVIAL_TOKENS", "and", "not", "any", "(", "c", ".", "isupper", "(", ")", "for", "c", "in", "token", ")", ":", "\n", "                ", "token", "=", "token", "[", "0", "]", ".", "upper", "(", ")", "+", "token", "[", "1", ":", "]", "\n", "", "n_tokens", ".", "append", "(", "token", ")", "\n", "", "text", "=", "' '", ".", "join", "(", "n_tokens", ")", "\n", "", "if", "len", "(", "tokens", ")", "==", "1", "and", "tokens", "[", "0", "]", "[", "0", "]", ".", "islower", "(", ")", ":", "\n", "        ", "text", "=", "text", ".", "capitalize", "(", ")", "\n", "", "if", "len", "(", "tokens", ")", "==", "1", "and", "tokens", "[", "0", "]", ".", "isupper", "(", ")", "and", "tokens", "[", "0", "]", ".", "isalpha", "(", ")", "and", "len", "(", "tokens", "[", "0", "]", ")", ">", "6", ":", "\n", "        ", "text", "=", "token", "[", "0", "]", ".", "upper", "(", ")", "+", "token", "[", "1", ":", "]", ".", "lower", "(", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph.__init__": [[12, 16], ["collections.defaultdict", "morph.Morph._load"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph._load"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "self", ".", "morph_dict", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "_load", "(", "file_path", ")", "\n", "self", ".", "morph_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph._load": [[17, 35], ["open", "enumerate", "line.strip().split", "part.strip().split", "line.strip", "part.strip", "morph.Morph.morph_dict[].append", "morph.Morph.morph_dict[].append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "_load", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'::DERIV-'", ")", "[", "1", ":", "]", "\n", "key", "=", "None", "\n", "for", "part", "in", "parts", ":", "\n", "                    ", "token_type", ",", "token", "=", "part", ".", "strip", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "token", "=", "token", "[", "1", ":", "-", "1", "]", "\n", "if", "token_type", "==", "'VERB'", ":", "\n", "                        ", "key", "=", "token", "\n", "", "elif", "token_type", "==", "'NOUN'", "and", "'-'", "not", "in", "token", "and", "token", "!=", "key", ":", "\n", "                        ", "assert", "key", "is", "not", "None", "\n", "self", ".", "morph_dict", "[", "token", "]", ".", "append", "(", "[", "key", "]", ")", "\n", "", "elif", "token_type", "==", "'NOUN-ACTOR'", "and", "'-'", "not", "in", "token", ":", "\n", "                        ", "assert", "key", "is", "not", "None", "\n", "self", ".", "morph_dict", "[", "token", "]", ".", "append", "(", "[", "key", ",", "'person'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph.read": [[36, 39], ["stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "morph.Morph."], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["", "", "", "", "", "def", "read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "amr", "in", "AMRIO", ".", "read", "(", "file_path", ")", ":", "\n", "            ", "yield", "self", "(", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.morph.Morph.__call__": [[40, 61], ["range", "len", "amr.replace_span", "len", "ner.append", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "__call__", "(", "self", ",", "amr", ")", ":", "\n", "        ", "offset", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "amr", ".", "tokens", ")", ")", ":", "\n", "            ", "index", "=", "i", "+", "offset", "\n", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "token", "=", "amr", ".", "tokens", "[", "index", "]", "\n", "morphed_lemmas", "=", "None", "\n", "if", "lemma", "in", "self", ".", "morph_dict", ":", "\n", "                ", "morphed_lemmas", "=", "self", ".", "morph_dict", "[", "lemma", "]", "[", "0", "]", "\n", "", "elif", "token", "in", "self", ".", "morph_dict", ":", "\n", "                ", "morphed_lemmas", "=", "self", ".", "morph_dict", "[", "token", "]", "[", "0", "]", "\n", "", "if", "morphed_lemmas", "is", "not", "None", ":", "\n", "                ", "pos", "=", "[", "amr", ".", "pos_tags", "[", "index", "]", "]", "\n", "ner", "=", "[", "amr", ".", "ner_tags", "[", "index", "]", "]", "\n", "if", "len", "(", "morphed_lemmas", ")", "==", "2", ":", "\n", "                    ", "pos", "=", "[", "'VBG'", ",", "'NN'", "]", "\n", "ner", ".", "append", "(", "'O'", ")", "\n", "", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "morphed_lemmas", ",", "pos", ",", "ner", ")", "\n", "offset", "+=", "len", "(", "morphed_lemmas", ")", "-", "1", "\n", "self", ".", "morph_count", "+=", "1", "\n", "", "", "return", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.clean": [[31, 53], ["input_cleaner.correct_errors", "input_cleaner.normalize_tokens", "input_cleaner.join_model_name", "input_cleaner.split_entity_with_slash", "input_cleaner.split_entity_with_non", "input_cleaner.split_entity_prefix", "input_cleaner.split_entity_prefix", "input_cleaner.split_entity_prefix", "input_cleaner.split_entity_prefix", "input_cleaner.replace_NT_dollar_abbr", "input_cleaner.join_time_description", "input_cleaner.split_date_duration", "input_cleaner.split_numerical_date", "input_cleaner.split_year_month", "input_cleaner.split_era", "input_cleaner.split_911", "input_cleaner.split_ratio", "input_cleaner.split_unit_with_number", "input_cleaner.split_number_with_dash_prefix"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.correct_errors", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.normalize_tokens", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.join_model_name", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_with_slash", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_with_non", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_prefix", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_prefix", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_prefix", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_prefix", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.replace_NT_dollar_abbr", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.join_time_description", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_date_duration", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_numerical_date", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_year_month", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_era", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_911", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_ratio", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_unit_with_number", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_number_with_dash_prefix"], ["def", "clean", "(", "amr", ")", ":", "\n", "    ", "correct_errors", "(", "amr", ")", "\n", "normalize_tokens", "(", "amr", ")", "\n", "# Named entity", "\n", "join_model_name", "(", "amr", ")", "\n", "split_entity_with_slash", "(", "amr", ")", "\n", "split_entity_with_non", "(", "amr", ")", "\n", "split_entity_prefix", "(", "amr", ",", "'anti'", ")", "\n", "split_entity_prefix", "(", "amr", ",", "'ex'", ")", "\n", "split_entity_prefix", "(", "amr", ",", "'cross'", ")", "\n", "split_entity_prefix", "(", "amr", ",", "'pro'", ")", "\n", "replace_NT_dollar_abbr", "(", "amr", ")", "\n", "# Date", "\n", "join_time_description", "(", "amr", ")", "\n", "split_date_duration", "(", "amr", ")", "\n", "split_numerical_date", "(", "amr", ")", "\n", "split_year_month", "(", "amr", ")", "\n", "split_era", "(", "amr", ")", "\n", "split_911", "(", "amr", ")", "\n", "split_ratio", "(", "amr", ")", "\n", "split_unit_with_number", "(", "amr", ")", "\n", "split_number_with_dash_prefix", "(", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.correct_errors": [[55, 265], ["enumerate", "amr.replace_span", "isinstance", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "list", "amr.id.startswith", "list", "token.lower", "amr.id.startswith", "amr.id.startswith", "amr.id.startswith", "range", "range", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "def", "correct_errors", "(", "amr", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "if", "token", "==", "'570000'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'2005'", ",", "'07'", "]", "\n", "pos", "=", "[", "'CD'", ",", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", ",", "'DATE'", "]", "\n", "break", "\n", "", "if", "token", "==", "'990000'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'1999'", "]", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG'", ")", "else", "[", "'1990'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "token", "==", "'860000'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'1986'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "token", "==", "'-20040824'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'2004'", ",", "'07'", ",", "'24'", "]", "\n", "pos", "=", "[", "'CD'", ",", "'CD'", ",", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", ",", "'DATE'", ",", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_XIN_ENG_20030709_0070.6'", ")", "and", "token", "==", "'July'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'June'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_APW_ENG_20080826_0891.5'", ")", "and", "token", "==", "'August'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'July'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_LTW_ENG_20070514_0055.19'", ")", "and", "token", "==", "'May'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'March'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070430_0038.8'", ")", "and", "token", "==", "'February'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'April'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070504_0296.10'", ")", "and", "token", "==", "'070513'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'20130513'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070504_0296.10'", ")", "and", "token", "==", "'070514'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'20130514'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070607_0366.8'", ")", "and", "token", "==", "'April'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'June'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070612_0538.6'", ")", "and", "token", "==", "'June'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'December'", "]", "\n", "pos", "=", "[", "'NNP'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070612_0538.6'", ")", "and", "token", "==", "'12'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'6'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070620_0032.14'", ")", "and", "token", "==", "'June'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'6'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070906_0523'", ")", "and", "token", "==", "'September'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'9'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070910_0544'", ")", "and", "token", "==", "'September'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'9'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20071204_0145.25'", ")", "and", "token", "==", "'200'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'2000'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20071206_0630.5'", ")", "and", "token", "==", "'November'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'10'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_APW_ENG_20080112_0264.5'", ")", "and", "token", "==", "'080112'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'20081112'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'DATE'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_XIN_ENG_20021123_0156.20'", ")", "and", "token", "==", "'a-third-party'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'a'", ",", "'third'", ",", "'party'", "]", "\n", "pos", "=", "[", "'DT'", ",", "'JJ'", ",", "'NN'", "]", "\n", "ner", "=", "[", "'O'", ",", "'ORDINAL'", ",", "'O'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'DF-225-195986-849_0460.9'", ")", "and", "token", "==", "'2most'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'2'", ",", "'most'", "]", "\n", "pos", "=", "[", "'CD'", ",", "'JJS'", "]", "\n", "ner", "=", "[", "'ORDINAL'", ",", "'O'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'DF-200-192400-625_7557.16'", ")", "and", "token", "==", "'what'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'want'", "]", "\n", "pos", "=", "[", "'VBP'", "]", "\n", "ner", "=", "[", "'O'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'DF-200-192392-456_1160.5'", ")", "and", "token", "==", "'couting'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'count'", "]", "\n", "pos", "=", "[", "'VBG'", "]", "\n", "ner", "=", "[", "'O'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'bolt-eng-DF-170-181103-8882248_0182.50'", ")", "and", "token", "==", "'31:10-31'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'31'", ",", "':'", ",", "'10'", ",", "'-'", ",", "'31'", "]", "\n", "pos", "=", "[", "'CD'", ",", "':'", ",", "'CD'", ",", "':'", ",", "'CD'", "]", "\n", "ner", "=", "[", "'ORDINAL'", ",", "'O'", ",", "'O'", ",", "'O'", ",", "'O'", "]", "\n", "break", "\n", "", "if", "(", "(", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20071030_0313.5'", ")", "or", "\n", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20071030_0313.10'", ")", ")", "\n", "and", "token", "==", "'approximately'", ")", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "]", "\n", "pos", "=", "[", "]", "\n", "ner", "=", "[", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20050603_0056.11'", ")", "and", "token", "==", "'first'", "and", "amr", ".", "tokens", "[", "i", "-", "1", "]", "==", "\"'s\"", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'firstly'", ",", "'first'", "]", "\n", "pos", "=", "[", "'NN'", ",", "'NN'", "]", "\n", "ner", "=", "[", "'ORDINAL'", ",", "'O'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_AFP_ENG_20070327_0002.14'", ")", "and", "token", "==", "'first'", "and", "amr", ".", "tokens", "[", "i", "+", "1", "]", "==", "'time'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'first'", ",", "'firstly'", "]", "\n", "pos", "=", "[", "'NN'", ",", "'JJ'", "]", "\n", "ner", "=", "[", "'O'", ",", "'ORDINAL'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'DF-200-192400-625_7046.5'", ")", "and", "token", "==", "'my'", "and", "amr", ".", "tokens", "[", "i", "+", "1", "]", "==", "'counsellers'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'my'", ",", "'2'", "]", "\n", "pos", "=", "[", "'PRP$'", ",", "'CD'", "]", "\n", "ner", "=", "[", "'O'", ",", "'NUMBER'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_LTW_ENG_20081115_0076.19'", ")", "and", "token", "==", "'a'", "and", "amr", ".", "tokens", "[", "i", "+", "1", "]", "==", "'year'", ":", "\n", "                ", "index", "=", "list", "(", "range", "(", "i", ",", "i", "+", "5", ")", ")", "\n", "tokens", "=", "[", "'1.5'", ",", "'year'", "]", "\n", "pos", "=", "[", "'CD'", ",", "'NN'", "]", "\n", "ner", "=", "[", "'NUMBER'", ",", "'DURATION'", "]", "\n", "break", "\n", "", "if", "amr", ".", "id", ".", "startswith", "(", "'PROXY_XIN_ENG_20020905_0122.11'", ")", "and", "token", "==", "'separate'", "and", "amr", ".", "tokens", "[", "i", "+", "1", "]", "==", "'bomb'", ":", "\n", "                ", "index", "=", "list", "(", "range", "(", "i", ",", "i", "+", "2", ")", ")", "\n", "tokens", "=", "[", "'separate'", ",", "'two'", ",", "'bomb'", "]", "\n", "pos", "=", "[", "'JJ'", ",", "'CD'", ",", "'JJ'", "]", "\n", "ner", "=", "[", "'O'", ",", "'NUMBER'", ",", "'O'", "]", "\n", "break", "\n", "", "if", "(", "token", "==", "'second'", "and", "i", "+", "2", "<", "len", "(", "amr", ".", "tokens", ")", "and", "\n", "amr", ".", "tokens", "[", "i", "+", "1", "]", "==", "'to'", "and", "amr", ".", "tokens", "[", "i", "+", "2", "]", "==", "'last'", ")", ":", "\n", "                ", "index", "=", "[", "i", ",", "i", "+", "1", ",", "i", "+", "2", "]", "\n", "tokens", "=", "[", "'-2'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'ORDINAL'", "]", "\n", "break", "\n", "", "if", "token", ".", "lower", "(", ")", "==", "'tonight'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'today'", ",", "'night'", "]", "\n", "pos", "=", "[", "'NN'", ",", "'NN'", "]", "\n", "ner", "=", "[", "'DATE'", ",", "'DATE'", "]", "\n", "break", "\n", "", "if", "token", "==", "'1ps'", ":", "\n", "                ", "index", "=", "i", "\n", "tokens", "=", "[", "'1'", ",", "'pence'", "]", "\n", "pos", "=", "[", "'CD'", ",", "'NN'", "]", "\n", "ner", "=", "[", "'NUMBER'", ",", "'O'", "]", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "if", "not", "isinstance", "(", "index", ",", "list", ")", ":", "\n", "            ", "index", "=", "[", "index", "]", "\n", "", "amr", ".", "replace_span", "(", "index", ",", "tokens", ",", "pos", ",", "ner", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.normalize_tokens": [[267, 300], ["enumerate", "amr.replace_span", "lemma.lower", "amr.tokens[].lower", "str", "str"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "normalize_tokens", "(", "amr", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "span", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "lemma_lower", "=", "lemma", ".", "lower", "(", ")", "\n", "token_lower", "=", "amr", ".", "tokens", "[", "i", "]", ".", "lower", "(", ")", "\n", "if", "lemma_lower", "==", "'midnight'", ":", "\n", "                ", "span", "=", "[", "i", "]", "\n", "tokens", "=", "[", "'0:00'", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'TIME'", "]", "\n", "break", "\n", "", "if", "token_lower", "in", "DECADE_MAP", ":", "\n", "                ", "span", "=", "[", "i", "]", "\n", "tokens", "=", "[", "str", "(", "DECADE_MAP", "[", "token_lower", "]", ")", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'TIME'", "]", "\n", "break", "\n", "", "if", "lemma_lower", "in", "ORDINAL_MAP", ":", "\n", "                ", "span", "=", "[", "i", "]", "\n", "tokens", "=", "[", "str", "(", "ORDINAL_MAP", "[", "lemma_lower", "]", ")", "]", "\n", "pos", "=", "[", "'CD'", "]", "\n", "ner", "=", "[", "'ORDINAL'", "]", "\n", "break", "\n", "", "if", "lemma_lower", "==", "'quarter'", "and", "i", ">", "0", "and", "amr", ".", "pos_tags", "[", "i", "-", "1", "]", "==", "'CD'", ":", "\n", "                ", "span", "=", "[", "i", "-", "1", ",", "i", "]", "\n", "tokens", "=", "[", "amr", ".", "tokens", "[", "i", "-", "1", "]", "]", "\n", "pos", "=", "[", "amr", ".", "pos_tags", "[", "i", "-", "1", "]", "]", "\n", "ner", "=", "[", "amr", ".", "ner_tags", "[", "i", "-", "1", "]", "]", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "span", ",", "tokens", ",", "pos", ",", "ner", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.join_model_name": [[302, 319], ["range", "amr.replace_span", "len", "len", "x.isalpha", "x.isupper", "re.search", "list", "range"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "join_model_name", "(", "amr", ")", ":", "\n", "# Joint the words starting with a cap letter which is followed by '^-\\d+$'", "\n", "    ", "while", "True", ":", "\n", "        ", "span", "=", "None", "\n", "if", "len", "(", "amr", ".", "tokens", ")", "<", "2", ":", "\n", "            ", "break", "\n", "", "for", "i", "in", "range", "(", "len", "(", "amr", ".", "tokens", ")", "-", "1", ")", ":", "\n", "            ", "x", ",", "y", "=", "amr", ".", "tokens", "[", "i", ":", "i", "+", "2", "]", "\n", "if", "x", ".", "isalpha", "(", ")", "and", "x", ".", "isupper", "(", ")", "and", "re", ".", "search", "(", "r'^-\\d+$'", ",", "y", ")", ":", "\n", "                ", "span", "=", "list", "(", "range", "(", "i", ",", "i", "+", "2", ")", ")", "\n", "joined_tokens", "=", "''", ".", "join", "(", "[", "x", ",", "y", "]", ")", "\n", "if", "joined_tokens", "in", "(", "'K-12'", ")", ":", "\n", "                    ", "continue", "\n", "", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "span", ",", "[", "joined_tokens", "]", ",", "[", "'NNP'", "]", ",", "[", "'ENTITY'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.join_time_description": [[321, 391], ["range", "amr.replace_span", "len", "len", "re.search", "list", "w2n.word_to_num.isalpha", "str", "list", "list", "re.search", "y.lower", "range", "y.lower", "word2number.w2n.word_to_num", "range", "len", "range", "list", "re.search.group", "range", "list", "re.search.group", "y.lower", "range", "w2n.word_to_num.lower", "list", "range", "w2n.word_to_num.lower", "list", "list", "range", "word2number.w2n.word_to_num", "range", "y.lower"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "join_time_description", "(", "amr", ")", ":", "\n", "# 4 o'clock; 4 am; 4 a.m., etc.", "\n", "    ", "while", "True", ":", "\n", "        ", "span", "=", "None", "\n", "if", "len", "(", "amr", ".", "tokens", ")", "<", "2", ":", "\n", "            ", "break", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "amr", ".", "tokens", ")", ")", ":", "\n", "            ", "x", ",", "y", "=", "amr", ".", "tokens", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "if", "y", ".", "lower", "(", ")", "in", "(", "\"o'clock\"", ",", "'am'", ",", "'a.m.'", ",", "'pm'", ",", "'p.m'", ")", "and", "re", ".", "search", "(", "r'^\\d+[.:]?\\d*[.:]?\\d*$'", ",", "x", ")", ":", "\n", "                ", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "''", ".", "join", "(", "[", "x", ",", "y", "]", ")", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "if", "y", ".", "lower", "(", ")", "in", "(", "\"o'clock\"", ",", "'am'", ",", "'a.m.'", ",", "'pm'", ",", "'p.m'", ")", "and", "x", ".", "isalpha", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "x", "=", "w2n", ".", "word_to_num", "(", "x", ")", "\n", "", "except", ":", "\n", "                    ", "continue", "\n", "", "x", "=", "str", "(", "x", ")", "\n", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "''", ".", "join", "(", "[", "x", ",", "y", "]", ")", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "if", "y", "==", "'Greenwich'", "and", "i", "+", "2", "<", "len", "(", "amr", ".", "tokens", ")", "and", "amr", ".", "tokens", "[", "i", "+", "1", ":", "i", "+", "3", "]", "==", "[", "'Mean'", ",", "'Time'", "]", ":", "\n", "                ", "span", "=", "list", "(", "range", "(", "i", ",", "i", "+", "3", ")", ")", "\n", "joined_tokens", "=", "'GMT'", "\n", "pos", "=", "'NNP'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "if", "y", "in", "(", "'century'", ",", "'Century'", ")", ":", "\n", "                ", "m", "=", "re", ".", "search", "(", "r'^(\\d+)(st|nd|rd|th)?$'", ",", "x", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "1", ")", "!=", "''", ":", "\n", "                    ", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "''", ".", "join", "(", "[", "m", ".", "group", "(", "1", ")", ",", "y", ".", "lower", "(", ")", "]", ")", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "elif", "x", "==", "'first'", "and", "amr", ".", "tokens", "[", "i", "-", "2", "]", "==", "'-'", "and", "amr", ".", "tokens", "[", "i", "-", "3", "]", "==", "'twenty'", ":", "\n", "                    ", "span", "=", "list", "(", "range", "(", "i", "-", "3", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "'21century'", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "elif", "x", ".", "lower", "(", ")", "==", "'eighth'", ":", "\n", "                    ", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "'8century'", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "elif", "x", ".", "lower", "(", ")", "==", "'fifth'", ":", "\n", "                    ", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "'5century'", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "try", ":", "\n", "                        ", "x", "=", "w2n", ".", "word_to_num", "(", "x", ")", "\n", "", "except", ":", "\n", "                        ", "continue", "\n", "", "span", "=", "list", "(", "range", "(", "i", "-", "1", ",", "i", "+", "1", ")", ")", "\n", "joined_tokens", "=", "''", ".", "join", "(", "[", "x", ",", "y", ".", "lower", "(", ")", "]", ")", "\n", "pos", "=", "'CD'", "\n", "ner", "=", "'TIME'", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "span", ",", "[", "joined_tokens", "]", ",", "[", "pos", "]", ",", "[", "ner", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_with_slash": [[393, 410], ["enumerate", "amr.tokens[].split", "amr.replace_span", "len", "token[].isupper", "token[].isupper", "len", "token.index", "token.index"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "", "def", "split_entity_with_slash", "(", "amr", ")", ":", "\n", "# Split named entity word with '/', e.g. 'Romney/McDonnell'.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "if", "(", "len", "(", "token", ")", "and", "token", "[", "0", "]", ".", "isupper", "(", ")", "and", "'/'", "in", "token", "and", "\n", "token", ".", "index", "(", "'/'", ")", "+", "1", "<", "len", "(", "token", ")", "and", "\n", "token", "[", "token", ".", "index", "(", "'/'", ")", "+", "1", "]", ".", "isupper", "(", ")", "\n", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "pos", "=", "amr", ".", "pos_tags", "[", "index", "]", "\n", "ner", "=", "amr", ".", "ner_tags", "[", "index", "]", "\n", "x", ",", "y", "=", "amr", ".", "tokens", "[", "index", "]", ".", "split", "(", "'/'", ",", "1", ")", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "x", ",", "'/'", ",", "y", "]", ",", "[", "pos", ",", "'SYM'", ",", "pos", "]", ",", "[", "ner", ",", "ner", ",", "ner", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_with_non": [[412, 426], ["enumerate", "amr.replace_span", "token.startswith", "token[].isupper", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_entity_with_non", "(", "amr", ")", ":", "\n", "# Split named entity word with 'non', e.g. 'nonRomney'.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "if", "token", ".", "startswith", "(", "'non'", ")", "and", "len", "(", "token", ")", ">", "3", "and", "token", "[", "3", "]", ".", "isupper", "(", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "pos", "=", "amr", ".", "pos_tags", "[", "index", "]", "\n", "ner", "=", "amr", ".", "ner_tags", "[", "index", "]", "\n", "x", "=", "amr", ".", "tokens", "[", "index", "]", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "'non'", ",", "x", "[", "3", ":", "]", "]", ",", "[", "'JJ'", ",", "pos", "]", ",", "[", "'O'", ",", "ner", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_entity_prefix": [[428, 445], ["enumerate", "amr.lemmas[].split", "lemma.lower().startswith", "amr.replace_span", "amr.replace_span", "lemma.lower"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_entity_prefix", "(", "amr", ",", "prefix", ")", ":", "\n", "# Split word with 'anti-' prefix.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "lemma", ".", "lower", "(", ")", ".", "startswith", "(", "prefix", "+", "'-'", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "pos", "=", "amr", ".", "pos_tags", "[", "index", "]", "\n", "ner", "=", "amr", ".", "ner_tags", "[", "index", "]", "\n", "_", ",", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", ".", "split", "(", "'-'", ",", "1", ")", "\n", "if", "lemma", "==", "''", ":", "\n", "            ", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "prefix", "]", ",", "[", "'JJ'", "]", ",", "[", "'O'", "]", ")", "\n", "", "else", ":", "\n", "            ", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "prefix", ",", "lemma", "]", ",", "[", "'JJ'", ",", "pos", "]", ",", "[", "ner", ",", "ner", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_unit_with_number": [[447, 461], ["enumerate", "amr.replace_span", "re.search", "re.split", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "", "def", "split_unit_with_number", "(", "amr", ")", ":", "\n", "# Split unit with number, e.g. '30pence'.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^\\d+(ps|pence)$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "x", "=", "re", ".", "split", "(", "r'(ps|pence)$'", ",", "lemma", ")", "[", "0", "]", "\n", "y", "=", "lemma", "[", "len", "(", "x", ")", ":", "]", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "x", ",", "y", "]", ",", "[", "'CD'", ",", "'NN'", "]", ",", "[", "'NUMBER'", ",", "'O'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_ratio": [[463, 476], ["enumerate", "lemma.split", "amr.replace_span", "re.search"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_ratio", "(", "amr", ")", ":", "\n", "# Split ratio with number, e.g. '1:1.4'.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "'.'", "in", "lemma", "and", "re", ".", "search", "(", "r'^\\d+\\.?\\d*:\\d+\\.?\\d*$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "x", ",", "y", "=", "lemma", ".", "split", "(", "':'", ")", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "x", ",", "':'", ",", "y", "]", ",", "[", "'CD'", ",", "':'", ",", "'CD'", "]", ",", "[", "'NUMBER'", ",", "'O'", ",", "'NUMBER'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_number_with_dash_prefix": [[478, 495], ["enumerate", "amr.replace_span", "re.search"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_number_with_dash_prefix", "(", "amr", ")", ":", "\n", "# Split number with dash prefix, e.g. '-6'", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^-\\d+$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "ner_tag", "=", "amr", ".", "ner_tags", "[", "index", "]", "\n", "if", "ner_tag", "in", "(", "'0'", ",", "'O'", ")", ":", "\n", "            ", "ner_tag", "=", "'NUMBER'", "\n", "", "x", "=", "lemma", "[", "0", "]", "\n", "y", "=", "lemma", "[", "1", ":", "]", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "x", ",", "y", "]", ",", "[", "':'", ",", "'CD'", "]", ",", "[", "'O'", ",", "ner_tag", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_date_duration": [[497, 510], ["enumerate", "amr.replace_span", "re.search", "re.search", "lemma.split"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_date_duration", "(", "amr", ")", ":", "\n", "# 201005-201006", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "x", "=", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^-\\d{8}$'", ",", "lemma", ")", "or", "re", ".", "search", "(", "r'^-\\d{6}$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "_", ",", "x", "=", "lemma", ".", "split", "(", "'-'", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "x", "]", ",", "[", "'CD'", "]", ",", "[", "'DATE'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_numerical_date": [[513, 562], ["enumerate", "amr.replace_span", "re.search", "str", "str", "str", "int", "int", "int", "int", "int", "int", "re.search", "int", "int", "int", "int", "re.search", "int", "re.search", "int", "int", "int", "int", "lemma.split", "re.search", "lemma.split"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_numerical_date", "(", "amr", ")", ":", "\n", "# Split the numerical date, e.g. 20080710.", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "year", ",", "month", ",", "day", "=", "None", ",", "None", ",", "None", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "(", "re", ".", "search", "(", "r'^\\d{8}$'", ",", "lemma", ")", "and", "\n", "1000", "<", "int", "(", "lemma", "[", ":", "4", "]", ")", "<", "2100", "and", "# year", "\n", "0", "<", "int", "(", "lemma", "[", "4", ":", "6", "]", ")", "<", "13", "and", "# month", "\n", "0", "<", "int", "(", "lemma", "[", "6", ":", "]", ")", "<", "32", "# day", "\n", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", ",", "day", "=", "int", "(", "lemma", "[", ":", "4", "]", ")", ",", "int", "(", "lemma", "[", "4", ":", "6", "]", ")", ",", "int", "(", "lemma", "[", "6", ":", "]", ")", "\n", "month", "=", "'{:02d}'", ".", "format", "(", "month", ")", "\n", "day", "=", "'{:02d}'", ".", "format", "(", "day", ")", "\n", "break", "\n", "", "elif", "(", "re", ".", "search", "(", "r'^\\d{5}$'", ",", "lemma", ")", "and", "\n", "0", "<", "int", "(", "lemma", "[", "1", ":", "3", "]", ")", "<", "13", "and", "# month", "\n", "0", "<", "int", "(", "lemma", "[", "3", ":", "]", ")", "<", "32", "# day", "\n", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", ",", "day", "=", "'0'", "+", "lemma", "[", "0", "]", ",", "int", "(", "lemma", "[", "1", ":", "3", "]", ")", ",", "int", "(", "lemma", "[", "3", ":", "]", ")", "\n", "month", "=", "'{:02d}'", ".", "format", "(", "month", ")", "\n", "day", "=", "'{:02d}'", ".", "format", "(", "day", ")", "\n", "break", "\n", "", "elif", "(", "re", ".", "search", "(", "r'^\\d{6}$'", ",", "lemma", ")", "and", "\n", "0", "<", "int", "(", "lemma", "[", "2", ":", "4", "]", ")", "<", "13", "and", "# month", "\n", "0", "<=", "int", "(", "lemma", "[", "4", ":", "]", ")", "<", "32", "# day", "\n", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", "=", "int", "(", "lemma", "[", ":", "2", "]", ")", "\n", "month", ",", "day", "=", "int", "(", "lemma", "[", "2", ":", "4", "]", ")", ",", "int", "(", "lemma", "[", "4", ":", "]", ")", "\n", "year", "=", "'{:02d}'", ".", "format", "(", "year", ")", "\n", "month", "=", "'{:02d}'", ".", "format", "(", "month", ")", "\n", "day", "=", "'{:02d}'", ".", "format", "(", "day", ")", "\n", "break", "\n", "", "elif", "re", ".", "search", "(", "r'^\\d+/\\d+/\\d+$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", ",", "day", "=", "lemma", ".", "split", "(", "'/'", ")", "\n", "break", "\n", "", "elif", "re", ".", "search", "(", "r'^\\d+-/\\d+-/\\d+$'", ",", "lemma", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", ",", "day", "=", "lemma", ".", "split", "(", "'-'", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "pos", "=", "'CD'", "\n", "ner", "=", "'DATE'", "\n", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "str", "(", "year", ")", ",", "str", "(", "month", ")", ",", "str", "(", "day", ")", "]", ",", "[", "pos", "]", "*", "3", ",", "[", "ner", "]", "*", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_year_month": [[564, 582], ["enumerate", "amr.replace_span", "re.search", "re.search", "re.search.group", "re.search.group", "re.search.group", "re.search.group"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_year_month", "(", "amr", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "year", ",", "month", "=", "None", ",", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "m", "=", "re", ".", "search", "(", "r'^(\\d+)/(\\d+)-*$'", ",", "token", ")", "\n", "if", "m", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", "=", "m", ".", "group", "(", "1", ")", ",", "m", ".", "group", "(", "2", ")", "\n", "break", "\n", "", "m", "=", "re", ".", "search", "(", "r'^(\\d{4})(\\d{2})00$'", ",", "token", ")", "\n", "if", "m", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "month", "=", "m", ".", "group", "(", "1", ")", ",", "m", ".", "group", "(", "2", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "year", ",", "month", "]", ",", "[", "'CD'", ",", "'CD'", "]", ",", "[", "'DATE'", ",", "'DATE'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_era": [[584, 596], ["enumerate", "amr.replace_span", "re.search"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_era", "(", "amr", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "year", ",", "era", "=", "None", ",", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "if", "re", ".", "search", "(", "r'^\\d{4}BC$'", ",", "token", ")", ":", "\n", "                ", "index", "=", "i", "\n", "year", ",", "era", "=", "token", "[", ":", "4", "]", ",", "token", "[", "4", ":", "]", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "year", ",", "era", "]", ",", "[", "'CD'", ",", "'NN'", "]", ",", "[", "'DATE'", ",", "'DATE'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.split_911": [[598, 608], ["enumerate", "amr.replace_span"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "split_911", "(", "amr", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "index", "=", "None", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "            ", "if", "token", "==", "'911'", ":", "\n", "                ", "index", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "break", "\n", "", "amr", ".", "replace_span", "(", "[", "index", "]", ",", "[", "'09'", ",", "'11'", "]", ",", "[", "'CD'", ",", "'CD'", "]", ",", "[", "'DATE'", ",", "'DATE'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.input_cleaner.replace_NT_dollar_abbr": [[610, 615], ["enumerate", "amr.replace_span", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span"], ["", "", "def", "replace_NT_dollar_abbr", "(", "amr", ")", ":", "\n", "# Replace 'NT' in front of '$' with 'Taiwan'.", "\n", "    ", "for", "i", ",", "token", "in", "enumerate", "(", "amr", ".", "tokens", ")", ":", "\n", "        ", "if", "token", "==", "'NT'", "and", "len", "(", "amr", ".", "tokens", ")", ">", "i", "+", "1", "and", "amr", ".", "tokens", "[", "i", "+", "1", "]", "in", "(", "'$'", ",", "'dollars'", ",", "'dollar'", ")", ":", "\n", "            ", "amr", ".", "replace_span", "(", "[", "i", "]", ",", "[", "'Taiwan'", "]", ",", "[", "'NNP'", "]", ",", "[", "'COUNTRY'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor.__init__": [[28, 50], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "text_maps", ":", "Dict", ",", "\n", "priority_lists", ":", "List", ",", "\n", "_VNE", ":", "str", ",", "\n", "_LOCEN1", ":", "List", ",", "\n", "_LOCEN2", ":", "List", ",", "\n", "_N", ":", "List", ",", "\n", "_M", ":", "List", ",", "\n", "_R", ":", "List", ",", "\n", "_INVP", ":", "List", ",", "\n", "_INVS", ":", "List", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_text_maps", "=", "text_maps", "\n", "self", ".", "_priority_lists", "=", "priority_lists", "\n", "self", ".", "_VNE", "=", "_VNE", "\n", "self", ".", "_LOCEN1", "=", "_LOCEN1", "\n", "self", ".", "_LOCEN2", "=", "_LOCEN2", "\n", "self", ".", "_N", "=", "_N", "\n", "self", ".", "_M", "=", "_M", "\n", "self", ".", "_R", "=", "_R", "\n", "self", ".", "_INVP", "=", "_INVP", "\n", "self", ".", "_INVS", "=", "_INVS", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor.__call__": [[51, 59], ["text_anonymizor.TextAnonymizor._text_maps.items", "len", "anonymization_map.update", "max", "text_anonymizor.TextAnonymizor._abstract"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._abstract"], ["", "def", "__call__", "(", "self", ",", "amr", ":", "AMR", ")", "->", "Dict", ":", "\n", "        ", "anonymization_map", "=", "{", "}", "\n", "for", "anonym_type", ",", "(", "text_map", ",", "pos_tag", ")", "in", "self", ".", "_text_maps", ".", "items", "(", ")", ":", "\n", "            ", "max_length", "=", "len", "(", "max", "(", "text_map", ",", "key", "=", "len", ")", ")", "\n", "anonymization_map", ".", "update", "(", "self", ".", "_abstract", "(", "\n", "amr", ",", "text_map", ",", "max_length", ",", "anonym_type", ",", "pos_tag", "\n", ")", ")", "\n", "", "return", "anonymization_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._abstract": [[60, 104], ["set", "text_anonymizor.TextAnonymizor._get_ignored_spans", "collections.defaultdict", "enumerate", "text_anonymizor.TextAnonymizor._replace_span", "lemma.rsplit", "lemma.rsplit", "str", "str", "str", "re.search", "int", "float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._get_ignored_spans", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._replace_span"], ["", "def", "_abstract", "(", "self", ",", "\n", "amr", ":", "AMR", ",", "\n", "text_map", ":", "Dict", ",", "\n", "max_length", ":", "int", ",", "\n", "anonym_type", ":", "str", ",", "\n", "pos_tag", ":", "str", ")", "->", "Dict", ":", "\n", "        ", "replaced_spans", "=", "{", "}", "\n", "collected_entities", "=", "set", "(", ")", "\n", "ignored_spans", "=", "self", ".", "_get_ignored_spans", "(", "amr", ")", "\n", "while", "True", ":", "\n", "            ", "done", "=", "self", ".", "_replace_span", "(", "\n", "amr", ",", "\n", "text_map", ",", "\n", "max_length", ",", "\n", "anonym_type", ",", "\n", "pos_tag", ",", "\n", "ignored_spans", ",", "\n", "replaced_spans", ",", "\n", "collected_entities", ",", "\n", ")", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "", "", "ner_counter", "=", "defaultdict", "(", "int", ")", "\n", "anonymization_map", "=", "{", "}", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "amr", ".", "lemmas", ")", ":", "\n", "            ", "if", "lemma", "in", "replaced_spans", ":", "\n", "                ", "if", "anonym_type", "==", "'quantity'", ":", "\n", "                    ", "ner", "=", "lemma", ".", "rsplit", "(", "'_'", ",", "2", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "ner", "=", "lemma", ".", "rsplit", "(", "'_'", ",", "1", ")", "[", "0", "]", "\n", "", "ner_counter", "[", "ner", "]", "+=", "1", "\n", "\n", "if", "anonym_type", "==", "'quantity'", ":", "\n", "                    ", "if", "ner", "in", "(", "'1'", ",", "'10'", ",", "'100'", ",", "'1000'", ")", "or", "not", "re", ".", "search", "(", "r\"[\\./]\"", ",", "ner", ")", ":", "\n", "                        ", "anonym_lemma", "=", "str", "(", "int", "(", "ner", ")", "*", "ner_counter", "[", "ner", "]", ")", "\n", "", "else", ":", "\n", "                        ", "anonym_lemma", "=", "str", "(", "float", "(", "ner", ")", "*", "ner_counter", "[", "ner", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "anonym_lemma", "=", "ner", "+", "'_'", "+", "str", "(", "ner_counter", "[", "ner", "]", ")", "\n", "\n", "", "amr", ".", "lemmas", "[", "i", "]", "=", "anonym_lemma", "\n", "amr", ".", "tokens", "[", "i", "]", "=", "anonym_lemma", "\n", "anonymization_map", "[", "anonym_lemma", "]", "=", "replaced_spans", "[", "lemma", "]", "\n", "", "", "return", "anonymization_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._leave_as_is": [[105, 164], ["text_anonymizor.next_token_is", "amr.pos_tags[].startswith", "text_anonymizor.is_anonym_type", "text_anonymizor.next_token_is", "text_anonymizor.next_token_is", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "amr.lemmas[].isdigit", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "text_anonymizor.next_token_is", "text_anonymizor.next_token_is", "text_anonymizor.is_anonym_type", "text_anonymizor.next_token_is", "amr.lemmas[].isdigit", "amr.lemmas[].isalpha", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "amr.lemmas[].isdigit", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "text_anonymizor.next_token_is", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "text_anonymizor.prev_token_is", "len", "text_anonymizor.next_token_is", "text_anonymizor.next_token_is", "text_anonymizor.prev_token_is", "text_anonymizor.prev_token_is", "len", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "text_anonymizor.prev_token_is", "text_anonymizor.next_token_is", "len", "len", "text_anonymizor.next_token_is", "len", "text_anonymizor.next_token_is"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.is_anonym_type", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.is_anonym_type", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is"], ["", "def", "_leave_as_is", "(", "self", ",", "\n", "index", ":", "int", ",", "\n", "amr", ":", "AMR", ",", "\n", "text_map", ":", "Dict", ",", "\n", "anonym_type", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "anonym_type", "==", "'named-entity'", ":", "\n", "            ", "if", "amr", ".", "pos_tags", "[", "index", "]", ".", "startswith", "(", "'V'", ")", "and", "not", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_VNE", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "(", "is_anonym_type", "(", "index", ",", "amr", ",", "text_map", ",", "[", "\"LOCATION\"", ",", "\"ENTITY\"", "]", ")", "\n", "and", "next_token_is", "(", "index", ",", "0", ",", "amr", ",", "self", ".", "_LOCEN1", "[", "0", "]", ")", "and", "(", "\n", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_LOCEN1", "[", "1", "]", ")", "or", "\n", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_LOCEN1", "[", "2", "]", ")", ")", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "next_token_is", "(", "index", ",", "0", ",", "amr", ",", "self", ".", "_LOCEN2", "[", "0", "]", ")", "and", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_LOCEN2", "[", "1", "]", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "if", "anonym_type", "==", "'ordinal-entity'", ":", "\n", "            ", "if", "next_token_is", "(", "index", ",", "0", ",", "amr", ",", "r\"^\\d+th$\"", ")", "and", "not", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_M", ")", ":", "\n", "                ", "return", "False", "\n", "", "if", "len", "(", "amr", ".", "lemmas", "[", "index", "]", ")", "==", "1", "and", "amr", ".", "lemmas", "[", "index", "]", ".", "isdigit", "(", ")", "and", "(", "\n", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_R", "[", "0", "]", ")", "or", "next_token_is", "(", "index", ",", "2", ",", "amr", ",", "self", ".", "_R", "[", "1", "]", ")", ")", ":", "\n", "                ", "return", "False", "\n", "", "if", "index", "==", "len", "(", "amr", ".", "lemmas", ")", "-", "2", "and", "amr", ".", "pos_tags", "[", "index", "+", "1", "]", "in", "'.,!?'", ":", "\n", "                ", "return", "True", "\n", "", "if", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVP", "[", "0", "]", ")", "or", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVS", "[", "0", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "not", "prev_token_is", "(", "index", ",", "2", ",", "amr", ",", "self", ".", "_INVP", "[", "1", "]", ")", "and", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVS", "[", "1", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_R", "[", "1", "]", ")", "and", "(", "\n", "not", "next_token_is", "(", "index", ",", "3", ",", "amr", ",", "self", ".", "_VNE", ")", "or", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "r\"^ORDINAL\"", ")", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "if", "anonym_type", "==", "'date-entity'", ":", "\n", "            ", "if", "is_anonym_type", "(", "index", ",", "amr", ",", "text_map", ",", "[", "'DATE_ATTRS'", "]", ")", "and", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "r\"^''$\"", ")", ":", "\n", "                    ", "return", "True", "\n", "", "if", "(", "amr", ".", "lemmas", "[", "index", "]", ".", "isdigit", "(", ")", "and", "len", "(", "amr", ".", "lemmas", "[", "index", "]", ")", "<", "4", "and", "(", "\n", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVP", "[", "2", "]", ")", "or", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVS", "[", "2", "]", ")", ")", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "amr", ".", "lemmas", "[", "index", "]", ".", "isalpha", "(", ")", "and", "(", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVP", "[", "3", "]", ")", "or", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVS", "[", "3", "]", ")", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "if", "anonym_type", "==", "'quantity'", ":", "\n", "            ", "if", "len", "(", "amr", ".", "lemmas", "[", "index", "]", ")", "==", "1", "and", "prev_token_is", "(", "index", ",", "2", ",", "amr", ",", "self", ".", "_INVP", "[", "4", "]", ")", "and", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVP", "[", "4", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "if", "' '", ".", "join", "(", "amr", ".", "lemmas", "[", "index", "-", "2", ":", "index", "+", "2", "]", ")", "in", "self", ".", "_N", "[", "2", ":", "4", "]", ":", "\n", "                ", "return", "True", "\n", "", "", "else", ":", "\n", "            ", "if", "index", "==", "0", "and", "len", "(", "amr", ".", "lemmas", "[", "index", "]", ")", "==", "1", "and", "amr", ".", "lemmas", "[", "index", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "if", "anonym_type", "!=", "'ordinal-entity'", ":", "\n", "            ", "if", "amr", ".", "ner_tags", "[", "index", "]", "==", "'ORDINAL'", "and", "not", "next_token_is", "(", "index", ",", "0", ",", "amr", ",", "self", ".", "_N", "[", "1", "]", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "if", "next_token_is", "(", "index", ",", "0", ",", "amr", ",", "self", ".", "_N", "[", "0", "]", ")", "and", "(", "\n", "prev_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVP", "[", "5", "]", ")", "or", "next_token_is", "(", "index", ",", "1", ",", "amr", ",", "self", ".", "_INVS", "[", "5", "]", ")", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._replace_span": [[165, 197], ["range", "range", "text_anonymizor.TextAnonymizor._leave_as_is", "amr.replace_span", "len", "text_map.get", "text_map.get", "str", "list", "collected_entities.add", "len", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._leave_as_is", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMR.replace_span", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "_replace_span", "(", "self", ",", "\n", "amr", ":", "AMR", ",", "\n", "text_map", ":", "Dict", ",", "\n", "max_length", ":", "int", ",", "\n", "anonym_type", ":", "str", ",", "\n", "pos_tag", ":", "str", ",", "\n", "ignored_spans", ":", "Set", ",", "\n", "replaced_spans", ":", "Dict", ",", "\n", "collected_entities", ":", "Set", ")", "->", "bool", ":", "\n", "        ", "for", "length", "in", "range", "(", "max_length", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "for", "start", "in", "range", "(", "len", "(", "amr", ".", "lemmas", ")", "+", "1", "-", "length", ")", ":", "\n", "                ", "if", "length", "==", "1", "and", "self", ".", "_leave_as_is", "(", "start", ",", "amr", ",", "text_map", ",", "anonym_type", ")", ":", "\n", "                    ", "continue", "\n", "", "span1", "=", "' '", ".", "join", "(", "amr", ".", "tokens", "[", "start", ":", "start", "+", "length", "]", ")", "\n", "span2", "=", "' '", ".", "join", "(", "amr", ".", "lemmas", "[", "start", ":", "start", "+", "length", "]", ")", "\n", "if", "span1", "in", "ignored_spans", "or", "span2", "in", "ignored_spans", ":", "\n", "                    ", "continue", "\n", "", "if", "span1", "in", "text_map", "or", "span2", "in", "text_map", ":", "\n", "                    ", "value", "=", "text_map", ".", "get", "(", "span1", ",", "None", ")", "or", "text_map", ".", "get", "(", "span2", ",", "None", ")", "\n", "if", "anonym_type", "==", "'named-entity'", ":", "\n", "                        ", "entity_name", "=", "value", "[", "'lemma'", "]", "if", "'lemma'", "in", "value", "else", "value", "[", "'ops'", "]", "\n", "if", "entity_name", "in", "collected_entities", ":", "\n", "                            ", "continue", "\n", "", "else", ":", "\n", "                            ", "collected_entities", ".", "add", "(", "entity_name", ")", "\n", "", "", "anonym_lemma", "=", "value", "[", "'ner'", "]", "+", "'_'", "+", "str", "(", "len", "(", "replaced_spans", ")", ")", "\n", "pos_tag", "=", "amr", ".", "pos_tags", "[", "start", "]", "if", "anonym_type", "==", "'quantity'", "else", "pos_tag", "\n", "ner", "=", "'NUMBER'", "if", "anonym_type", "==", "'quantity'", "else", "value", "[", "'ner'", "]", "\n", "replaced_spans", "[", "anonym_lemma", "]", "=", "value", "\n", "amr", ".", "replace_span", "(", "list", "(", "range", "(", "start", ",", "start", "+", "length", ")", ")", ",", "[", "anonym_lemma", "]", ",", "[", "pos_tag", "]", ",", "[", "ner", "]", ")", "\n", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor._get_ignored_spans": [[198, 212], ["set", "enumerate", "span.split", "len", "set.update", "set.update"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update"], ["", "def", "_get_ignored_spans", "(", "self", ",", "amr", ":", "AMR", ")", "->", "Set", ":", "\n", "        ", "ignored_spans", "=", "set", "(", ")", "\n", "for", "spans", "in", "self", ".", "_priority_lists", ":", "\n", "            ", "for", "i", ",", "span", "in", "enumerate", "(", "spans", ")", ":", "\n", "                ", "tokens", "=", "span", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", ">", "1", ":", "\n", "                    ", "if", "span", "+", "' '", "in", "' '", ".", "join", "(", "amr", ".", "lemmas", ")", "or", "span", "+", "' '", "in", "' '", ".", "join", "(", "amr", ".", "tokens", ")", ":", "\n", "                        ", "ignored_spans", ".", "update", "(", "spans", "[", "i", "+", "1", ":", "]", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                    ", "if", "span", "in", "amr", ".", "lemmas", "or", "span", "in", "amr", ".", "tokens", ":", "\n", "                        ", "ignored_spans", ".", "update", "(", "spans", "[", "i", "+", "1", ":", "]", ")", "\n", "break", "\n", "", "", "", "", "return", "ignored_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.TextAnonymizor.from_json": [[213, 228], ["cls", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "@", "classmethod", "\n", "def", "from_json", "(", "cls", ",", "file_path", ":", "str", ")", "->", "'TextAnonymizor'", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "d", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "cls", "(", "\n", "text_maps", "=", "d", "[", "\"text_maps\"", "]", ",", "\n", "priority_lists", "=", "d", "[", "\"priority_lists\"", "]", ",", "\n", "_VNE", "=", "d", "[", "\"VNE\"", "]", ",", "\n", "_LOCEN1", "=", "d", "[", "\"LOCEN1\"", "]", ",", "\n", "_LOCEN2", "=", "d", "[", "\"LOCEN2\"", "]", ",", "\n", "_N", "=", "d", "[", "\"N\"", "]", ",", "\n", "_M", "=", "d", "[", "\"M\"", "]", ",", "\n", "_R", "=", "d", "[", "\"R\"", "]", ",", "\n", "_INVP", "=", "d", "[", "\"INVP\"", "]", ",", "\n", "_INVS", "=", "d", "[", "\"INVS\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.prev_token_is": [[11, 14], ["re.match"], "function", ["None"], ["def", "prev_token_is", "(", "index", ":", "int", ",", "k", ":", "int", ",", "amr", ":", "AMR", ",", "pattern", ":", "str", ")", ":", "\n", "    ", "if", "index", "-", "k", ">=", "0", ":", "\n", "        ", "return", "re", ".", "match", "(", "pattern", ",", "amr", ".", "lemmas", "[", "index", "-", "k", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.next_token_is": [[16, 19], ["len", "re.match"], "function", ["None"], ["", "", "def", "next_token_is", "(", "index", ":", "int", ",", "k", ":", "int", ",", "amr", ":", "AMR", ",", "pattern", ":", "str", ")", ":", "\n", "    ", "if", "index", "+", "k", "<", "len", "(", "amr", ".", "lemmas", ")", ":", "\n", "        ", "return", "re", ".", "match", "(", "pattern", ",", "amr", ".", "lemmas", "[", "index", "+", "k", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.text_anonymizor.is_anonym_type": [[21, 24], ["None"], "function", ["None"], ["", "", "def", "is_anonym_type", "(", "index", ":", "int", ",", "amr", ":", "AMR", ",", "text_map", ":", "Dict", ",", "types", ":", "List", ")", "->", "bool", ":", "\n", "    ", "lemma", "=", "amr", ".", "lemmas", "[", "index", "]", "\n", "return", "lemma", "in", "text_map", "and", "text_map", "[", "lemma", "]", "[", "'ner'", "]", "in", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.__init__": [[49, 77], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "nltk.stem.SnowballStemmer", "recategorizer.Recategorizer._build_utils", "recategorizer.Recategorizer._dump_utils", "recategorizer.Recategorizer._load_utils", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._build_utils", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._dump_utils", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._load_utils"], ["    ", "def", "__init__", "(", "self", ",", "train_data", "=", "None", ",", "build_utils", "=", "False", ",", "util_dir", "=", "None", ")", ":", "\n", "        ", "self", ".", "stemmer", "=", "nltk", ".", "stem", ".", "SnowballStemmer", "(", "'english'", ")", ".", "stem", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "build_utils", "=", "build_utils", "\n", "self", ".", "named_entity_count", "=", "0", "\n", "self", ".", "recat_named_entity_count", "=", "0", "\n", "self", ".", "date_entity_count", "=", "0", "\n", "self", ".", "recat_date_entity_count", "=", "0", "\n", "self", ".", "score_entity_count", "=", "0", "\n", "self", ".", "recat_score_entity_count", "=", "0", "\n", "self", ".", "ordinal_entity_count", "=", "0", "\n", "self", ".", "recat_ordinal_entity_count", "=", "0", "\n", "self", ".", "quantity_count", "=", "0", "\n", "self", ".", "recat_quantity_count", "=", "0", "\n", "self", ".", "url_count", "=", "0", "\n", "self", ".", "recat_url_count", "=", "0", "\n", "self", ".", "removed_wiki_count", "=", "0", "\n", "\n", "self", ".", "name_type_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "name_op_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "wiki_span_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "build_entity_map", "=", "False", "\n", "self", ".", "entity_type_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "if", "build_utils", ":", "\n", "            ", "self", ".", "_build_utils", "(", ")", "\n", "self", ".", "_dump_utils", "(", "util_dir", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_load_utils", "(", "util_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._print_statistics": [[78, 104], ["logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info"], "methods", ["None"], ["", "", "def", "_print_statistics", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "named_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Named entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_named_entity_count", "/", "self", ".", "named_entity_count", ",", "\n", "self", ".", "recat_named_entity_count", ",", "self", ".", "named_entity_count", ")", ")", "\n", "", "if", "self", ".", "date_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Dated entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_date_entity_count", "/", "self", ".", "date_entity_count", ",", "\n", "self", ".", "recat_date_entity_count", ",", "self", ".", "date_entity_count", ")", ")", "\n", "", "if", "self", ".", "score_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Score entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_score_entity_count", "/", "self", ".", "score_entity_count", ",", "\n", "self", ".", "recat_score_entity_count", ",", "self", ".", "score_entity_count", ")", ")", "\n", "", "if", "self", ".", "ordinal_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Ordinal entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_ordinal_entity_count", "/", "self", ".", "ordinal_entity_count", ",", "\n", "self", ".", "recat_ordinal_entity_count", ",", "self", ".", "ordinal_entity_count", ")", ")", "\n", "", "if", "self", ".", "quantity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Quantity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_quantity_count", "/", "self", ".", "quantity_count", ",", "\n", "self", ".", "recat_quantity_count", ",", "self", ".", "quantity_count", ")", ")", "\n", "", "if", "self", ".", "url_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'URL collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_url_count", "/", "self", ".", "url_count", ",", "\n", "self", ".", "recat_url_count", ",", "self", ".", "url_count", ")", ")", "\n", "", "logger", ".", "info", "(", "'Removed {} wikis.'", ".", "format", "(", "self", ".", "removed_wiki_count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.reset_statistics": [[105, 119], ["None"], "methods", ["None"], ["", "def", "reset_statistics", "(", "self", ")", ":", "\n", "        ", "self", ".", "named_entity_count", "=", "0", "\n", "self", ".", "recat_named_entity_count", "=", "0", "\n", "self", ".", "date_entity_count", "=", "0", "\n", "self", ".", "recat_date_entity_count", "=", "0", "\n", "self", ".", "score_entity_count", "=", "0", "\n", "self", ".", "recat_score_entity_count", "=", "0", "\n", "self", ".", "ordinal_entity_count", "=", "0", "\n", "self", ".", "recat_ordinal_entity_count", "=", "0", "\n", "self", ".", "quantity_count", "=", "0", "\n", "self", ".", "recat_quantity_count", "=", "0", "\n", "self", ".", "url_count", "=", "0", "\n", "self", ".", "recat_url_count", "=", "0", "\n", "self", ".", "removed_wiki_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._build_utils": [[120, 131], ["logger.info", "recategorizer.Recategorizer.recategorize_file", "logger.info", "logger.info", "recategorizer.Recategorizer.reset_statistics", "recategorizer.Recategorizer.recategorize_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_file", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.reset_statistics", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_file"], ["", "def", "_build_utils", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Building name_type_cooccur_counter and wiki_span_cooccur_counter...'", ")", "\n", "for", "_", "in", "self", ".", "recategorize_file", "(", "self", ".", "train_data", ")", ":", "\n", "            ", "pass", "\n", "", "self", ".", "build_entity_map", "=", "True", "\n", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "logger", ".", "info", "(", "'Building entity_type_cooccur_counter...'", ")", "\n", "self", ".", "reset_statistics", "(", ")", "\n", "for", "_", "in", "self", ".", "recategorize_file", "(", "self", ".", "train_data", ")", ":", "\n", "            ", "pass", "\n", "", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._dump_utils": [[132, 141], ["open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "def", "_dump_utils", "(", "self", ",", "directory", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_type_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "name_type_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_op_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "name_op_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'wiki_span_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "wiki_span_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'entity_type_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "entity_type_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._load_utils": [[142, 151], ["open", "json.load", "open", "json.load", "open", "json.load", "open", "json.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "", "def", "_load_utils", "(", "self", ",", "directory", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_type_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "name_type_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_op_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "name_op_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'wiki_span_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "wiki_span_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'entity_type_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "entity_type_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._map_name_node_type": [[152, 162], ["max", "recategorizer.Recategorizer.name_type_cooccur_counter[].keys"], "methods", ["None"], ["", "", "def", "_map_name_node_type", "(", "self", ",", "name_node_type", ")", ":", "\n", "        ", "if", "not", "self", ".", "build_utils", "and", "name_node_type", "in", "self", ".", "name_type_cooccur_counter", ":", "\n", "            ", "ner_type", "=", "max", "(", "self", ".", "name_type_cooccur_counter", "[", "name_node_type", "]", ".", "keys", "(", ")", ",", "\n", "key", "=", "lambda", "ner_type", ":", "self", ".", "name_type_cooccur_counter", "[", "name_node_type", "]", "[", "ner_type", "]", ")", "\n", "if", "ner_type", "in", "(", "'0'", ",", "'O'", ")", ":", "\n", "                ", "return", "Entity", ".", "unknown_entity_type", "\n", "", "else", ":", "\n", "                ", "return", "ner_type", "\n", "", "", "else", ":", "\n", "            ", "return", "Entity", ".", "unknown_entity_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_file": [[163, 170], ["enumerate", "logger.info", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "recategorizer.Recategorizer.recategorize_graph", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_graph"], ["", "", "def", "recategorize_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ",", "1", ")", ":", "\n", "            ", "self", ".", "recategorize_graph", "(", "amr", ")", "\n", "yield", "amr", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'Processed {} examples.'", ".", "format", "(", "i", ")", ")", "\n", "", "", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_graph": [[171, 184], ["recategorizer.Recategorizer.resolve_name_node_reentrancy", "recategorizer.Recategorizer.recategorize_name_nodes", "recategorizer.Recategorizer.remove_wiki", "recategorizer.Recategorizer.recategorize_date_nodes", "recategorizer.Recategorizer.recategorize_score_nodes", "recategorizer.Recategorizer.recategorize_ordinal_nodes", "recategorizer.Recategorizer.recategorize_quantities", "recategorizer.Recategorizer.recategorize_urls", "recategorizer.Recategorizer.stemmer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.resolve_name_node_reentrancy", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_name_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.remove_wiki", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_date_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_score_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_ordinal_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_quantities", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_urls"], ["", "def", "recategorize_graph", "(", "self", ",", "amr", ")", ":", "\n", "        ", "amr", ".", "stems", "=", "[", "self", ".", "stemmer", "(", "l", ")", "for", "l", "in", "amr", ".", "lemmas", "]", "\n", "self", ".", "resolve_name_node_reentrancy", "(", "amr", ")", "\n", "self", ".", "recategorize_name_nodes", "(", "amr", ")", "\n", "if", "self", ".", "build_utils", ":", "\n", "            ", "return", "\n", "", "self", ".", "remove_wiki", "(", "amr", ")", "\n", "#self.remove_negation(amr)", "\n", "self", ".", "recategorize_date_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_score_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_ordinal_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_quantities", "(", "amr", ")", "\n", "self", ".", "recategorize_urls", "(", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.resolve_name_node_reentrancy": [[185, 200], ["graph.get_nodes", "graph.is_name_node", "list", "graph._G.in_edges", "graph.remove_edge", "graph.add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge"], ["", "def", "resolve_name_node_reentrancy", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "graph", ".", "is_name_node", "(", "node", ")", ":", "\n", "                ", "edges", "=", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ")", "\n", "name_head", "=", "None", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "                    ", "if", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "==", "'name'", ":", "\n", "                        ", "name_head", "=", "source", "\n", "break", "\n", "", "", "for", "source", ",", "target", "in", "edges", ":", "\n", "                    ", "label", "=", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "label", "!=", "'name'", ":", "\n", "                        ", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "graph", ".", "add_edge", "(", "source", ",", "name_head", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.remove_wiki": [[201, 208], ["graph.get_nodes", "node.attributes.copy", "graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "", "", "", "", "def", "remove_wiki", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ".", "copy", "(", ")", ":", "\n", "                ", "if", "attr", "==", "'wiki'", ":", "\n", "                    ", "self", ".", "removed_wiki_count", "+=", "1", "\n", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.remove_negation": [[209, 214], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity.remove_polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite.remove_polite"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.remove_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.remove_polite"], ["", "", "", "", "def", "remove_negation", "(", "self", ",", "amr", ")", ":", "\n", "        ", "polarity", "=", "Polarity", "(", "amr", ")", "\n", "polarity", ".", "remove_polarity", "(", ")", "\n", "polite", "=", "Polite", "(", "amr", ")", "\n", "polite", ".", "remove_polite", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_name_nodes": [[215, 243], ["graph.get_list_node", "recategorizer.resolve_conflict_entities", "graph.is_name_node", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity.collapse_name_nodes", "recategorizer.Recategorizer._update_utils", "list", "all", "amr.graph.get_name_node_type", "recategorizer.Recategorizer._map_name_node_type", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity.get_aligned_entity", "len", "entities.append", "amr.graph.get_name_node_type", "recategorizer.Recategorizer._map_name_node_type", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity.get_aligned_entity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity.collapse_name_nodes", "graph._G.in_edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.resolve_conflict_entities", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.collapse_name_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._update_utils", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._map_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_aligned_entity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._map_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_aligned_entity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.collapse_name_nodes"], ["", "def", "recategorize_name_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "entities", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "graph", ".", "is_name_node", "(", "node", ")", ":", "\n", "                ", "edges", "=", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ")", "\n", "assert", "all", "(", "graph", ".", "_G", "[", "s", "]", "[", "t", "]", "[", "'label'", "]", "==", "'name'", "for", "s", ",", "t", "in", "edges", ")", "\n", "self", ".", "named_entity_count", "+=", "1", "\n", "amr_type", "=", "amr", ".", "graph", ".", "get_name_node_type", "(", "node", ")", "\n", "backup_ner_type", "=", "self", ".", "_map_name_node_type", "(", "amr_type", ")", "\n", "entity", "=", "Entity", ".", "get_aligned_entity", "(", "\n", "node", ",", "amr", ",", "backup_ner_type", ",", "self", ".", "entity_type_cooccur_counter", ")", "\n", "if", "len", "(", "entity", ".", "span", ")", ":", "\n", "                    ", "self", ".", "recat_named_entity_count", "+=", "1", "\n", "", "entities", ".", "append", "(", "entity", ")", "\n", "", "", "entities", ",", "removed_entities", "=", "resolve_conflict_entities", "(", "entities", ")", "\n", "if", "not", "self", ".", "build_utils", ":", "\n", "            ", "type_counter", "=", "Entity", ".", "collapse_name_nodes", "(", "entities", ",", "amr", ")", "\n", "for", "entity", "in", "removed_entities", ":", "\n", "                ", "amr_type", "=", "amr", ".", "graph", ".", "get_name_node_type", "(", "entity", ".", "node", ")", "\n", "backup_ner_type", "=", "self", ".", "_map_name_node_type", "(", "amr_type", ")", "\n", "entity", "=", "Entity", ".", "get_aligned_entity", "(", "\n", "entity", ".", "node", ",", "amr", ",", "backup_ner_type", ",", "self", ".", "entity_type_cooccur_counter", ")", "\n", "Entity", ".", "collapse_name_nodes", "(", "[", "entity", "]", ",", "amr", ",", "type_counter", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_update_utils", "(", "entities", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_date_nodes": [[244, 258], ["graph.get_list_node", "recategorizer.resolve_conflict_entities", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date.collapse_date_nodes", "graph.is_date_node", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date.collapsable", "recategorizer.Recategorizer._get_aligned_date", "dates.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.resolve_conflict_entities", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.collapse_date_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_date_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.collapsable", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._get_aligned_date"], ["", "", "def", "recategorize_date_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "dates", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "graph", ".", "is_date_node", "(", "node", ")", "and", "Date", ".", "collapsable", "(", "node", ",", "graph", ")", ":", "\n", "                ", "self", ".", "date_entity_count", "+=", "1", "\n", "date", "=", "self", ".", "_get_aligned_date", "(", "node", ",", "amr", ")", "\n", "if", "date", ".", "span", "is", "not", "None", ":", "\n", "                    ", "self", ".", "recat_date_entity_count", "+=", "1", "\n", "", "dates", ".", "append", "(", "date", ")", "\n", "", "", "dates", ",", "removed_dates", "=", "resolve_conflict_entities", "(", "dates", ")", "\n", "Date", ".", "collapse_date_nodes", "(", "dates", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_score_nodes": [[259, 272], ["graph.get_list_node", "stog.data.dataset_readers.amr_parsing.amr_concepts.Score.collapse_score_nodes", "stog.data.dataset_readers.amr_parsing.amr_concepts.Score", "scores.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.collapse_score_nodes"], ["", "def", "recategorize_score_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "scores", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "node", ".", "instance", "==", "'score-entity'", ":", "\n", "                ", "self", ".", "score_entity_count", "+=", "1", "\n", "score", "=", "Score", "(", "node", ",", "amr", ")", "\n", "if", "score", ".", "span", "is", "not", "None", ":", "\n", "                    ", "self", ".", "recat_score_entity_count", "+=", "1", "\n", "", "scores", ".", "append", "(", "score", ")", "\n", "", "", "Score", ".", "collapse_score_nodes", "(", "scores", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_ordinal_nodes": [[273, 286], ["graph.get_list_node", "stog.data.dataset_readers.amr_parsing.amr_concepts.Ordinal.collapse_ordinal_nodes", "stog.data.dataset_readers.amr_parsing.amr_concepts.Ordinal", "ordinals.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.ordinal.Ordinal.collapse_ordinal_nodes"], ["", "def", "recategorize_ordinal_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "ordinals", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "node", ".", "instance", "==", "'ordinal-entity'", ":", "\n", "                ", "self", ".", "ordinal_entity_count", "+=", "1", "\n", "ordinal", "=", "Ordinal", "(", "node", ",", "amr", ")", "\n", "if", "ordinal", ".", "span", "is", "not", "None", ":", "\n", "                    ", "self", ".", "recat_ordinal_entity_count", "+=", "1", "\n", "", "ordinals", ".", "append", "(", "ordinal", ")", "\n", "", "", "Ordinal", ".", "collapse_ordinal_nodes", "(", "ordinals", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_quantities": [[287, 291], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Quantity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Quantity.abstract"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract"], ["", "def", "recategorize_quantities", "(", "self", ",", "amr", ")", ":", "\n", "        ", "quantity", "=", "Quantity", "(", "amr", ")", "\n", "self", ".", "recat_quantity_count", "+=", "quantity", ".", "abstract", "(", ")", "\n", "self", ".", "quantity_count", "+=", "quantity", ".", "quant_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer.recategorize_urls": [[292, 297], ["stog.data.dataset_readers.amr_parsing.amr_concepts.URL", "stog.data.dataset_readers.amr_parsing.amr_concepts.URL.abstract"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract"], ["", "def", "recategorize_urls", "(", "self", ",", "amr", ")", ":", "\n", "        ", "url", "=", "URL", "(", "amr", ")", "\n", "url_count", ",", "recat_url_count", "=", "url", ".", "abstract", "(", ")", "\n", "self", ".", "url_count", "+=", "url_count", "\n", "self", ".", "recat_url_count", "+=", "recat_url_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._get_aligned_date": [[298, 305], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Date", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date._get_alignment", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date._get_span", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_alignment", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date._get_span"], ["", "def", "_get_aligned_date", "(", "self", ",", "node", ",", "amr", ")", ":", "\n", "        ", "date", "=", "Date", "(", "node", ",", "amr", ".", "graph", ")", "\n", "if", "len", "(", "date", ".", "attributes", ")", "+", "len", "(", "date", ".", "edges", ")", "==", "0", ":", "\n", "            ", "return", "date", "\n", "", "alignment", "=", "date", ".", "_get_alignment", "(", "amr", ")", "\n", "date", ".", "_get_span", "(", "alignment", ",", "amr", ")", "\n", "return", "date", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.Recategorizer._update_utils": [[306, 328], ["amr.graph.get_name_node_wiki", "entity.get_text_spans", "text_span.lower.lower.lower", "len", "len", "entity.get_ops"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_wiki", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.get_text_spans", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.expander.Expander.get_ops"], ["", "def", "_update_utils", "(", "self", ",", "entities", ",", "amr", ")", ":", "\n", "        ", "if", "not", "self", ".", "build_entity_map", ":", "\n", "            ", "for", "entity", "in", "entities", ":", "\n", "                ", "wiki_title", "=", "amr", ".", "graph", ".", "get_name_node_wiki", "(", "entity", ".", "node", ")", "\n", "if", "wiki_title", "is", "None", ":", "\n", "                    ", "wiki_title", "=", "'-'", "\n", "", "for", "text_span", "in", "entity", ".", "get_text_spans", "(", "amr", ")", ":", "\n", "                    ", "text_span", "=", "text_span", ".", "lower", "(", ")", "\n", "self", ".", "wiki_span_cooccur_counter", "[", "text_span", "]", "[", "wiki_title", "]", "+=", "1", "\n", "self", ".", "name_op_cooccur_counter", "[", "text_span", "]", "[", "' '", ".", "join", "(", "entity", ".", "get_ops", "(", ")", ")", "]", "+=", "1", "\n", "\n", "", "if", "len", "(", "entity", ".", "span", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "entity_text", "=", "' '", ".", "join", "(", "amr", ".", "tokens", "[", "index", "]", "for", "index", "in", "entity", ".", "span", ")", ".", "lower", "(", ")", "\n", "self", ".", "entity_type_cooccur_counter", "[", "entity_text", "]", "[", "entity", ".", "ner_type", "]", "+=", "1", "\n", "\n", "", "", "else", ":", "\n", "            ", "for", "entity", "in", "entities", ":", "\n", "                ", "if", "len", "(", "entity", ".", "span", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "if", "entity", ".", "ner_type", "!=", "Entity", ".", "unknown_entity_type", ":", "\n", "                    ", "self", ".", "name_type_cooccur_counter", "[", "entity", ".", "amr_type", "]", "[", "entity", ".", "ner_type", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.recategorizer.resolve_conflict_entities": [[15, 45], ["index_entity_map.values", "removed_entities.append", "empty_entities.append", "list", "node_entity_map.values"], "function", ["None"], ["def", "resolve_conflict_entities", "(", "entities", ")", ":", "\n", "# If there's overlap between any two entities,", "\n", "# remove the one that has lower confidence.", "\n", "    ", "index_entity_map", "=", "{", "}", "\n", "empty_entities", "=", "[", "]", "\n", "for", "entity", "in", "entities", ":", "\n", "        ", "if", "not", "entity", ".", "span", ":", "\n", "            ", "empty_entities", ".", "append", "(", "entity", ")", "\n", "continue", "\n", "\n", "", "for", "index", "in", "entity", ".", "span", ":", "\n", "            ", "if", "index", "in", "index_entity_map", ":", "\n", "                ", "_entity", "=", "index_entity_map", "[", "index", "]", "\n", "if", "_entity", ".", "confidence", "<", "entity", ".", "confidence", ":", "\n", "                    ", "index_entity_map", "[", "index", "]", "=", "entity", "\n", "", "", "else", ":", "\n", "                ", "index_entity_map", "[", "index", "]", "=", "entity", "\n", "", "", "", "node_entity_map", "=", "{", "}", "\n", "for", "entity", "in", "index_entity_map", ".", "values", "(", ")", ":", "\n", "        ", "node_entity_map", "[", "entity", ".", "node", "]", "=", "entity", "\n", "\n", "", "removed_entities", "=", "[", "]", "\n", "for", "entity", "in", "entities", ":", "\n", "        ", "if", "not", "entity", ".", "span", ":", "\n", "            ", "continue", "\n", "", "if", "entity", ".", "node", "in", "node_entity_map", ":", "\n", "            ", "continue", "\n", "", "removed_entities", ".", "append", "(", "entity", ")", "\n", "\n", "", "return", "list", "(", "node_entity_map", ".", "values", "(", ")", ")", "+", "empty_entities", ",", "removed_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.__init__": [[16, 44], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "nltk.stem.SnowballStemmer", "graph_anonymizor.GraphAnonymizor._build_utils", "graph_anonymizor.GraphAnonymizor._dump_utils", "graph_anonymizor.GraphAnonymizor._load_utils", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._build_utils", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._dump_utils", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._load_utils"], ["    ", "def", "__init__", "(", "self", ",", "train_data", "=", "None", ",", "build_utils", "=", "False", ",", "util_dir", "=", "None", ")", ":", "\n", "        ", "self", ".", "stemmer", "=", "nltk", ".", "stem", ".", "SnowballStemmer", "(", "'english'", ")", ".", "stem", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "build_utils", "=", "build_utils", "\n", "self", ".", "named_entity_count", "=", "0", "\n", "self", ".", "recat_named_entity_count", "=", "0", "\n", "self", ".", "date_entity_count", "=", "0", "\n", "self", ".", "recat_date_entity_count", "=", "0", "\n", "self", ".", "score_entity_count", "=", "0", "\n", "self", ".", "recat_score_entity_count", "=", "0", "\n", "self", ".", "ordinal_entity_count", "=", "0", "\n", "self", ".", "recat_ordinal_entity_count", "=", "0", "\n", "self", ".", "quantity_count", "=", "0", "\n", "self", ".", "recat_quantity_count", "=", "0", "\n", "self", ".", "url_count", "=", "0", "\n", "self", ".", "recat_url_count", "=", "0", "\n", "self", ".", "removed_wiki_count", "=", "0", "\n", "\n", "self", ".", "name_type_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "name_op_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "wiki_span_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "build_entity_map", "=", "False", "\n", "self", ".", "entity_type_cooccur_counter", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "if", "build_utils", ":", "\n", "            ", "self", ".", "_build_utils", "(", ")", "\n", "self", ".", "_dump_utils", "(", "util_dir", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_load_utils", "(", "util_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._print_statistics": [[45, 71], ["logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info"], "methods", ["None"], ["", "", "def", "_print_statistics", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "named_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Named entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_named_entity_count", "/", "self", ".", "named_entity_count", ",", "\n", "self", ".", "recat_named_entity_count", ",", "self", ".", "named_entity_count", ")", ")", "\n", "", "if", "self", ".", "date_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Dated entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_date_entity_count", "/", "self", ".", "date_entity_count", ",", "\n", "self", ".", "recat_date_entity_count", ",", "self", ".", "date_entity_count", ")", ")", "\n", "", "if", "self", ".", "score_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Score entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_score_entity_count", "/", "self", ".", "score_entity_count", ",", "\n", "self", ".", "recat_score_entity_count", ",", "self", ".", "score_entity_count", ")", ")", "\n", "", "if", "self", ".", "ordinal_entity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Ordinal entity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_ordinal_entity_count", "/", "self", ".", "ordinal_entity_count", ",", "\n", "self", ".", "recat_ordinal_entity_count", ",", "self", ".", "ordinal_entity_count", ")", ")", "\n", "", "if", "self", ".", "quantity_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Quantity collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_quantity_count", "/", "self", ".", "quantity_count", ",", "\n", "self", ".", "recat_quantity_count", ",", "self", ".", "quantity_count", ")", ")", "\n", "", "if", "self", ".", "url_count", "!=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'URL collapse rate: {} ({}/{})'", ".", "format", "(", "\n", "self", ".", "recat_url_count", "/", "self", ".", "url_count", ",", "\n", "self", ".", "recat_url_count", ",", "self", ".", "url_count", ")", ")", "\n", "", "logger", ".", "info", "(", "'Removed {} wikis.'", ".", "format", "(", "self", ".", "removed_wiki_count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.reset_statistics": [[72, 86], ["None"], "methods", ["None"], ["", "def", "reset_statistics", "(", "self", ")", ":", "\n", "        ", "self", ".", "named_entity_count", "=", "0", "\n", "self", ".", "recat_named_entity_count", "=", "0", "\n", "self", ".", "date_entity_count", "=", "0", "\n", "self", ".", "recat_date_entity_count", "=", "0", "\n", "self", ".", "score_entity_count", "=", "0", "\n", "self", ".", "recat_score_entity_count", "=", "0", "\n", "self", ".", "ordinal_entity_count", "=", "0", "\n", "self", ".", "recat_ordinal_entity_count", "=", "0", "\n", "self", ".", "quantity_count", "=", "0", "\n", "self", ".", "recat_quantity_count", "=", "0", "\n", "self", ".", "url_count", "=", "0", "\n", "self", ".", "recat_url_count", "=", "0", "\n", "self", ".", "removed_wiki_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._build_utils": [[87, 98], ["logger.info", "graph_anonymizor.GraphAnonymizor.recategorize_file", "logger.info", "logger.info", "graph_anonymizor.GraphAnonymizor.reset_statistics", "graph_anonymizor.GraphAnonymizor.recategorize_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_file", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.reset_statistics", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_file"], ["", "def", "_build_utils", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Building name_type_cooccur_counter and wiki_span_cooccur_counter...'", ")", "\n", "for", "_", "in", "self", ".", "recategorize_file", "(", "self", ".", "train_data", ")", ":", "\n", "            ", "pass", "\n", "", "self", ".", "build_entity_map", "=", "True", "\n", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "logger", ".", "info", "(", "'Building entity_type_cooccur_counter...'", ")", "\n", "self", ".", "reset_statistics", "(", ")", "\n", "for", "_", "in", "self", ".", "recategorize_file", "(", "self", ".", "train_data", ")", ":", "\n", "            ", "pass", "\n", "", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._dump_utils": [[99, 108], ["open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "def", "_dump_utils", "(", "self", ",", "directory", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_type_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "name_type_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_op_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "name_op_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'wiki_span_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "wiki_span_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'entity_type_cooccur_counter.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "entity_type_cooccur_counter", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._load_utils": [[109, 118], ["open", "json.load", "open", "json.load", "open", "json.load", "open", "json.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load"], ["", "", "def", "_load_utils", "(", "self", ",", "directory", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_type_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "name_type_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'name_op_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "name_op_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'wiki_span_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "wiki_span_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'entity_type_cooccur_counter.json'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "self", ".", "entity_type_cooccur_counter", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._map_name_node_type": [[119, 129], ["max", "graph_anonymizor.GraphAnonymizor.name_type_cooccur_counter[].keys"], "methods", ["None"], ["", "", "def", "_map_name_node_type", "(", "self", ",", "name_node_type", ")", ":", "\n", "        ", "if", "not", "self", ".", "build_utils", "and", "name_node_type", "in", "self", ".", "name_type_cooccur_counter", ":", "\n", "            ", "ner_type", "=", "max", "(", "self", ".", "name_type_cooccur_counter", "[", "name_node_type", "]", ".", "keys", "(", ")", ",", "\n", "key", "=", "lambda", "ner_type", ":", "self", ".", "name_type_cooccur_counter", "[", "name_node_type", "]", "[", "ner_type", "]", ")", "\n", "if", "ner_type", "in", "(", "'0'", ",", "'O'", ")", ":", "\n", "                ", "return", "Entity", ".", "unknown_entity_type", "\n", "", "else", ":", "\n", "                ", "return", "ner_type", "\n", "", "", "else", ":", "\n", "            ", "return", "Entity", ".", "unknown_entity_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_file": [[130, 137], ["enumerate", "logger.info", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "graph_anonymizor.GraphAnonymizor.recategorize_graph", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_graph"], ["", "", "def", "recategorize_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ",", "1", ")", ":", "\n", "            ", "self", ".", "recategorize_graph", "(", "amr", ")", "\n", "yield", "amr", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'Processed {} examples.'", ".", "format", "(", "i", ")", ")", "\n", "", "", "logger", ".", "info", "(", "'Done.\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_graph": [[138, 151], ["graph_anonymizor.GraphAnonymizor.resolve_name_node_reentrancy", "graph_anonymizor.GraphAnonymizor.recategorize_name_nodes", "graph_anonymizor.GraphAnonymizor.remove_wiki", "graph_anonymizor.GraphAnonymizor.recategorize_date_nodes", "graph_anonymizor.GraphAnonymizor.recategorize_score_nodes", "graph_anonymizor.GraphAnonymizor.recategorize_ordinal_nodes", "graph_anonymizor.GraphAnonymizor.recategorize_quantities", "graph_anonymizor.GraphAnonymizor.recategorize_urls"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.resolve_name_node_reentrancy", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_name_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.remove_wiki", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_date_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_score_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_ordinal_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_quantities", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_urls"], ["", "def", "recategorize_graph", "(", "self", ",", "amr", ")", ":", "\n", "#amr.stems = [self.stemmer(l) for l in amr.lemmas]", "\n", "        ", "self", ".", "resolve_name_node_reentrancy", "(", "amr", ")", "\n", "self", ".", "recategorize_name_nodes", "(", "amr", ")", "\n", "if", "self", ".", "build_utils", ":", "\n", "            ", "return", "\n", "", "self", ".", "remove_wiki", "(", "amr", ")", "\n", "#self.remove_negation(amr)", "\n", "self", ".", "recategorize_date_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_score_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_ordinal_nodes", "(", "amr", ")", "\n", "self", ".", "recategorize_quantities", "(", "amr", ")", "\n", "self", ".", "recategorize_urls", "(", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.resolve_name_node_reentrancy": [[152, 167], ["graph.get_nodes", "graph.is_name_node", "list", "graph._G.in_edges", "graph.remove_edge", "graph.add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge"], ["", "def", "resolve_name_node_reentrancy", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "graph", ".", "is_name_node", "(", "node", ")", ":", "\n", "                ", "edges", "=", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ")", "\n", "name_head", "=", "None", "\n", "for", "source", ",", "target", "in", "edges", ":", "\n", "                    ", "if", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "==", "'name'", ":", "\n", "                        ", "name_head", "=", "source", "\n", "break", "\n", "", "", "for", "source", ",", "target", "in", "edges", ":", "\n", "                    ", "label", "=", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "label", "!=", "'name'", ":", "\n", "                        ", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "graph", ".", "add_edge", "(", "source", ",", "name_head", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.remove_wiki": [[168, 175], ["graph.get_nodes", "node.attributes.copy", "graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRNode.copy", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "", "", "", "", "def", "remove_wiki", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "for", "attr", ",", "value", "in", "node", ".", "attributes", ".", "copy", "(", ")", ":", "\n", "                ", "if", "attr", "==", "'wiki'", ":", "\n", "                    ", "self", ".", "removed_wiki_count", "+=", "1", "\n", "graph", ".", "remove_node_attribute", "(", "node", ",", "attr", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.remove_negation": [[176, 181], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polarity.remove_polarity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite", "stog.data.dataset_readers.amr_parsing.amr_concepts.Polite.remove_polite"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polarity.Polarity.remove_polarity", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.polite.Polite.remove_polite"], ["", "", "", "", "def", "remove_negation", "(", "self", ",", "amr", ")", ":", "\n", "        ", "polarity", "=", "Polarity", "(", "amr", ")", "\n", "polarity", ".", "remove_polarity", "(", ")", "\n", "polite", "=", "Polite", "(", "amr", ")", "\n", "polite", ".", "remove_polite", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_name_nodes": [[182, 197], ["graph.get_list_node", "graph_anonymizor.GraphAnonymizor._collapse_name_nodes", "graph.is_name_node", "list", "all", "amr.graph.get_name_node_type", "graph_anonymizor.GraphAnonymizor._map_name_node_type", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity", "entities.append", "graph._G.in_edges"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_name_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_name_node_type", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._map_name_node_type"], ["", "def", "recategorize_name_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "entities", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "graph", ".", "is_name_node", "(", "node", ")", ":", "\n", "                ", "edges", "=", "list", "(", "graph", ".", "_G", ".", "in_edges", "(", "node", ")", ")", "\n", "assert", "all", "(", "graph", ".", "_G", "[", "s", "]", "[", "t", "]", "[", "'label'", "]", "==", "'name'", "for", "s", ",", "t", "in", "edges", ")", "\n", "self", ".", "named_entity_count", "+=", "1", "\n", "amr_type", "=", "amr", ".", "graph", ".", "get_name_node_type", "(", "node", ")", "\n", "backup_ner_type", "=", "self", ".", "_map_name_node_type", "(", "amr_type", ")", "\n", "entity", "=", "Entity", "(", "node", "=", "node", ",", "ner_type", "=", "backup_ner_type", ")", "\n", "entities", ".", "append", "(", "entity", ")", "\n", "", "", "type_counter", "=", "self", ".", "_collapse_name_nodes", "(", "entities", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_name_nodes": [[198, 218], ["len", "collections.defaultdict", "stog.data.dataset_readers.amr_parsing.amr_concepts.Entity.save_collapsed_name_node", "amr.graph.remove_node_ops", "amr.graph.replace_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.entity.Entity.save_collapsed_name_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "_collapse_name_nodes", "(", "self", ",", "entities", ",", "amr", ",", "type_counter", "=", "None", ")", ":", "\n", "        ", "if", "amr", ".", "abstract_map", "is", "None", ":", "\n", "            ", "amr", ".", "abstract_map", "=", "{", "}", "\n", "", "if", "len", "(", "entities", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "if", "type_counter", "is", "None", ":", "\n", "            ", "type_counter", "=", "defaultdict", "(", "int", ")", "\n", "\n", "", "for", "entity", "in", "entities", ":", "\n", "            ", "type_counter", "[", "entity", ".", "ner_type", "]", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "\n", "entity", ".", "ner_type", ",", "type_counter", "[", "entity", ".", "ner_type", "]", ")", "\n", "span_with_offset", "=", "[", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "Entity", ".", "save_collapsed_name_node", "(", "\n", "entity", ",", "span_with_offset", ",", "amr", ")", "\n", "amr", ".", "graph", ".", "remove_node_ops", "(", "entity", ".", "node", ")", "\n", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "entity", ".", "node", ",", "'instance'", ",", "entity", ".", "node", ".", "instance", ",", "abstract", ")", "\n", "\n", "", "return", "type_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_date_nodes": [[219, 230], ["graph.get_list_node", "graph_anonymizor.GraphAnonymizor._collapse_date_nodes", "graph.is_date_node", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date.collapsable", "stog.data.dataset_readers.amr_parsing.amr_concepts.Date", "dates.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_date_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.is_date_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.collapsable"], ["", "def", "recategorize_date_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "dates", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "graph", ".", "is_date_node", "(", "node", ")", "and", "Date", ".", "collapsable", "(", "node", ",", "graph", ")", ":", "\n", "                ", "self", ".", "date_entity_count", "+=", "1", "\n", "date", "=", "Date", "(", "node", "=", "node", ",", "graph", "=", "graph", ")", "\n", "dates", ".", "append", "(", "date", ")", "\n", "", "", "self", ".", "_collapse_date_nodes", "(", "dates", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_date_nodes": [[231, 254], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Date.save_collapsed_date_node", "list", "amr.graph.replace_node_attribute", "date.attributes.items", "amr.graph._G.edges", "amr.graph.remove_node_attribute", "amr.graph.remove_edge", "amr.graph.remove_subtree"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.date.Date.save_collapsed_date_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree"], ["", "def", "_collapse_date_nodes", "(", "self", ",", "dates", ",", "amr", ")", ":", "\n", "        ", "if", "amr", ".", "abstract_map", "is", "None", ":", "\n", "            ", "amr", ".", "abstract_map", "=", "{", "}", "\n", "\n", "", "align_count", "=", "0", "\n", "for", "date", "in", "dates", ":", "\n", "            ", "align_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "date", ".", "ner_type", ",", "align_count", ")", "\n", "span_with_offset", "=", "[", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "Date", ".", "save_collapsed_date_node", "(", "\n", "date", ",", "span_with_offset", ",", "amr", ")", "\n", "\n", "# Remove edges", "\n", "for", "source", ",", "target", "in", "list", "(", "amr", ".", "graph", ".", "_G", ".", "edges", "(", "date", ".", "node", ")", ")", ":", "\n", "                ", "edge_label", "=", "amr", ".", "graph", ".", "_G", "[", "source", "]", "[", "target", "]", "[", "'label'", "]", "\n", "if", "edge_label", "in", "Date", ".", "edge_list", ":", "\n", "                    ", "amr", ".", "graph", ".", "remove_edge", "(", "source", ",", "target", ")", "\n", "amr", ".", "graph", ".", "remove_subtree", "(", "target", ")", "\n", "# Update instance", "\n", "", "", "amr", ".", "graph", ".", "replace_node_attribute", "(", "date", ".", "node", ",", "'instance'", ",", "'date-entity'", ",", "abstract", ")", "\n", "# Remove attributes", "\n", "for", "attr", ",", "value", "in", "date", ".", "attributes", ".", "items", "(", ")", ":", "\n", "                ", "amr", ".", "graph", ".", "remove_node_attribute", "(", "date", ".", "node", ",", "attr", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_score_nodes": [[255, 264], ["graph.get_list_node", "graph_anonymizor.GraphAnonymizor._collapse_score_nodes", "scores.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_score_nodes"], ["", "", "", "def", "recategorize_score_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "scores", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "node", ".", "instance", "==", "'score-entity'", ":", "\n", "                ", "scores", ".", "append", "(", "node", ")", "\n", "", "", "self", ".", "_collapse_score_nodes", "(", "scores", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_score_nodes": [[265, 276], ["amr.graph.remove_node_ops", "amr.graph.replace_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_ops", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute"], ["", "def", "_collapse_score_nodes", "(", "self", ",", "scores", ",", "amr", ")", ":", "\n", "        ", "score_node_count", "=", "0", "\n", "for", "score", "in", "scores", ":", "\n", "            ", "score_node_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "'SCORE_ENTITY'", ",", "score_node_count", ")", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "{", "'type'", ":", "'score-entity'", ",", "\n", "'span'", ":", "''", ",", "\n", "'ops'", ":", "score", ".", "ops", "}", "\n", "amr", ".", "graph", ".", "remove_node_ops", "(", "score", ")", "\n", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "score", ",", "'instance'", ",", "score", ".", "instance", ",", "abstract", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_ordinal_nodes": [[277, 287], ["graph.get_list_node", "graph_anonymizor.GraphAnonymizor._collapse_ordinal_nodes", "stog.data.dataset_readers.amr_parsing.amr_concepts.Ordinal", "ordinals.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_list_node", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_ordinal_nodes"], ["", "", "def", "recategorize_ordinal_nodes", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "ordinals", "=", "[", "]", "\n", "for", "node", ",", "_", ",", "_", "in", "graph", ".", "get_list_node", "(", "replace_copy", "=", "False", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "if", "node", ".", "instance", "==", "'ordinal-entity'", ":", "\n", "                ", "ordinal", "=", "Ordinal", "(", "node", ",", "amr", ",", "align", "=", "False", ")", "\n", "ordinals", ".", "append", "(", "ordinal", ")", "\n", "", "", "self", ".", "_collapse_ordinal_nodes", "(", "ordinals", ",", "amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor._collapse_ordinal_nodes": [[288, 305], ["ordinal.to_dict", "amr.graph.replace_node_attribute", "amr.graph.remove_edge", "amr.graph.remove_subtree", "amr.graph.remove_node_attribute"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.score.Score.to_dict", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_subtree", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.remove_node_attribute"], ["", "def", "_collapse_ordinal_nodes", "(", "self", ",", "ordinals", ",", "amr", ")", ":", "\n", "        ", "node_count", "=", "0", "\n", "for", "ordinal", "in", "ordinals", ":", "\n", "            ", "node_count", "+=", "1", "\n", "abstract", "=", "'{}_{}'", ".", "format", "(", "ordinal", ".", "ner_type", ",", "node_count", ")", "\n", "span", "=", "[", "]", "\n", "amr", ".", "abstract_map", "[", "abstract", "]", "=", "ordinal", ".", "to_dict", "(", "amr", ",", "span", ")", "\n", "for", "attr", ",", "value", "in", "ordinal", ".", "node", ".", "attributes", ":", "\n", "                ", "if", "attr", "==", "'value'", ":", "\n", "                    ", "amr", ".", "graph", ".", "remove_node_attribute", "(", "ordinal", ".", "node", ",", "attr", ",", "value", ")", "\n", "break", "\n", "", "", "amr", ".", "graph", ".", "replace_node_attribute", "(", "\n", "ordinal", ".", "node", ",", "'instance'", ",", "ordinal", ".", "node", ".", "instance", ",", "abstract", ")", "\n", "if", "ordinal", ".", "value_node", ":", "\n", "# Remove the value node.", "\n", "                ", "amr", ".", "graph", ".", "remove_edge", "(", "ordinal", ".", "node", ",", "ordinal", ".", "value_node", ")", "\n", "amr", ".", "graph", ".", "remove_subtree", "(", "ordinal", ".", "value_node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_quantities": [[306, 310], ["stog.data.dataset_readers.amr_parsing.amr_concepts.Quantity", "stog.data.dataset_readers.amr_parsing.amr_concepts.Quantity.abstract"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract"], ["", "", "", "def", "recategorize_quantities", "(", "self", ",", "amr", ")", ":", "\n", "        ", "quantity", "=", "Quantity", "(", "amr", ")", "\n", "self", ".", "recat_quantity_count", "+=", "quantity", ".", "abstract", "(", "align", "=", "False", ")", "\n", "self", ".", "quantity_count", "+=", "quantity", ".", "quant_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.graph_anonymizor.GraphAnonymizor.recategorize_urls": [[311, 316], ["stog.data.dataset_readers.amr_parsing.amr_concepts.URL", "stog.data.dataset_readers.amr_parsing.amr_concepts.URL.abstract"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_concepts.quantity.Quantity.abstract"], ["", "def", "recategorize_urls", "(", "self", ",", "amr", ")", ":", "\n", "        ", "url", "=", "URL", "(", "amr", ")", "\n", "url_count", ",", "recat_url_count", "=", "url", ".", "abstract", "(", "align", "=", "False", ")", "\n", "self", ".", "url_count", "+=", "url_count", "\n", "self", ".", "recat_url_count", "+=", "recat_url_count", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.__init__": [[17, 27], ["pycorenlp.StanfordCoreNLP", "feature_annotator.FeatureAnnotator.load_compound_map"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.load_compound_map"], ["def", "__init__", "(", "self", ",", "url", ",", "compound_map_file", ")", ":", "\n", "        ", "self", ".", "nlp", "=", "StanfordCoreNLP", "(", "url", ")", "\n", "self", ".", "nlp_properties", "=", "{", "\n", "'annotators'", ":", "\"tokenize,ssplit,pos,lemma,ner\"", ",", "\n", "\"tokenize.options\"", ":", "\"splitHyphenated=true,normalizeParentheses=false\"", ",", "\n", "\"tokenize.whitespace\"", ":", "False", ",", "\n", "'ssplit.isOneSentence'", ":", "True", ",", "\n", "'outputFormat'", ":", "'json'", "\n", "}", "\n", "self", ".", "compound_map", "=", "self", ".", "load_compound_map", "(", "compound_map_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.load_compound_map": [[28, 51], ["open", "line.split", "compound_map[].append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_compound_map", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"Load a compound map from partial compound word to a list of possible next token in the compound.\n\n        :param file_path: the compound map file.\n        \"https://github.com/ChunchuanLv/AMR_AS_GRAPH_PREDICTION/blob/master/data/joints.txt\"\n        :return: a dict from string to list.\n        \"\"\"", "\n", "compound_map", "=", "{", "}", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "compounds", "=", "line", ".", "split", "(", ")", "\n", "precedents", "=", "''", "\n", "for", "token", "in", "compounds", ":", "\n", "                    ", "if", "len", "(", "precedents", ")", ">", "0", ":", "\n", "                        ", "_precedents", "=", "precedents", "[", ":", "-", "1", "]", "# exclude dash", "\n", "", "else", ":", "\n", "                        ", "_precedents", "=", "''", "\n", "", "if", "_precedents", "not", "in", "compound_map", ":", "\n", "                        ", "compound_map", "[", "_precedents", "]", "=", "[", "]", "\n", "", "compound_map", "[", "_precedents", "]", ".", "append", "(", "token", ")", "\n", "precedents", "+=", "token", "+", "'-'", "\n", "", "", "", "return", "compound_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.assert_equal_length": [[52, 61], ["len", "len", "len", "len", "list", "zip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "assert_equal_length", "(", "annotation", ")", ":", "\n", "        ", "tokens", "=", "annotation", "[", "'tokens'", "]", "\n", "for", "key", "in", "annotation", ":", "\n", "            ", "if", "key", "==", "'tokens'", ":", "\n", "                ", "continue", "\n", "", "value", "=", "annotation", "[", "key", "]", "\n", "assert", "len", "(", "tokens", ")", "==", "len", "(", "value", ")", ",", "(", "\n", "len", "(", "tokens", ")", ",", "len", "(", "value", ")", ",", "'\\n'", ",", "list", "(", "zip", "(", "tokens", ",", "value", ")", ")", ",", "tokens", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.annotate": [[62, 73], ["dict", "output[].append", "output[].append", "output[].append", "output[].append", "feature_annotator.FeatureAnnotator.nlp.annotate", "text.strip"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.annotate", "home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "", "def", "annotate", "(", "self", ",", "text", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "nlp", ".", "annotate", "(", "text", ".", "strip", "(", ")", ",", "self", ".", "nlp_properties", ")", "[", "'sentences'", "]", "[", "0", "]", "[", "'tokens'", "]", "\n", "output", "=", "dict", "(", "\n", "tokens", "=", "[", "]", ",", "lemmas", "=", "[", "]", ",", "pos_tags", "=", "[", "]", ",", "ner_tags", "=", "[", "]", "\n", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "output", "[", "'tokens'", "]", ".", "append", "(", "token", "[", "'word'", "]", ")", "\n", "output", "[", "'lemmas'", "]", ".", "append", "(", "token", "[", "'lemma'", "]", ")", "\n", "output", "[", "'pos_tags'", "]", ".", "append", "(", "token", "[", "'pos'", "]", ")", "\n", "output", "[", "'ner_tags'", "]", ".", "append", "(", "token", "[", "'ner'", "]", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.__call__": [[74, 82], ["feature_annotator.FeatureAnnotator.annotate", "feature_annotator.FeatureAnnotator._combine_compounds", "feature_annotator.FeatureAnnotator._combine_numbers", "feature_annotator.FeatureAnnotator._tag_url_and_split_number"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.annotate", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._combine_compounds", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._combine_numbers", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._tag_url_and_split_number"], ["", "def", "__call__", "(", "self", ",", "text", ")", ":", "\n", "        ", "annotation", "=", "self", ".", "annotate", "(", "text", ")", "\n", "original", "=", "annotation", "[", "'tokens'", "]", "\n", "annotation", "=", "self", ".", "_combine_compounds", "(", "annotation", ")", "\n", "annotation", "=", "self", ".", "_combine_numbers", "(", "annotation", ")", "\n", "annotation", "=", "self", ".", "_tag_url_and_split_number", "(", "annotation", ")", "\n", "annotation", "[", "'original'", "]", "=", "original", "\n", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._combine_compounds": [[83, 118], ["enumerate", "dict", "feature_annotator.FeatureAnnotator.assert_equal_length", "len", "feature_annotator.FeatureAnnotator.compound_map.get", "lemmas.append", "tokens.append", "pos_tags.append", "ner_tags.append", "len", "feature_annotator.FeatureAnnotator.compound_map.get", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.assert_equal_length", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "_combine_compounds", "(", "self", ",", "annotation", ")", ":", "\n", "# Combine tokens in compounds, e.g., 'make up' -> 'make-up'.", "\n", "        ", "tokens", "=", "[", "]", "\n", "lemmas", "=", "[", "]", "\n", "pos_tags", "=", "[", "]", "\n", "ner_tags", "=", "[", "]", "\n", "skip", "=", "False", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "annotation", "[", "'lemmas'", "]", ")", ":", "\n", "            ", "if", "skip", ":", "\n", "                ", "skip", "=", "False", "\n", "", "elif", "len", "(", "lemmas", ")", ">", "0", "and", "lemma", "in", "self", ".", "compound_map", ".", "get", "(", "lemmas", "[", "-", "1", "]", ",", "[", "]", ")", ":", "\n", "# lemma belongs to a compound.", "\n", "                ", "lemmas", "[", "-", "1", "]", "=", "lemmas", "[", "-", "1", "]", "+", "'-'", "+", "lemma", "\n", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "\"-\"", "+", "annotation", "[", "'tokens'", "]", "[", "i", "]", "\n", "pos_tags", "[", "-", "1", "]", "=", "\"COMP\"", "\n", "ner_tags", "[", "-", "1", "]", "=", "\"0\"", "\n", "", "elif", "len", "(", "lemmas", ")", ">", "0", "and", "lemma", "==", "\"-\"", "and", "i", "<", "len", "(", "annotation", "[", "'lemmas'", "]", ")", "-", "1", "and", "annotation", "[", "'lemmas'", "]", "[", "i", "+", "1", "]", "in", "self", ".", "compound_map", ".", "get", "(", "lemmas", "[", "-", "1", "]", ",", "[", "]", ")", ":", "\n", "# lemma is a dash and the next lemma belongs to a compound.", "\n", "                ", "lemmas", "[", "-", "1", "]", "=", "lemmas", "[", "-", "1", "]", "+", "'-'", "+", "annotation", "[", "'lemmas'", "]", "[", "i", "+", "1", "]", "\n", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "'-'", "+", "annotation", "[", "'tokens'", "]", "[", "i", "+", "1", "]", "\n", "pos_tags", "[", "-", "1", "]", "=", "\"COMP\"", "\n", "ner_tags", "[", "-", "1", "]", "=", "\"0\"", "\n", "skip", "=", "True", "# skip the next lemma.", "\n", "", "else", ":", "\n", "                ", "lemmas", ".", "append", "(", "lemma", ")", "\n", "tokens", ".", "append", "(", "annotation", "[", "'tokens'", "]", "[", "i", "]", ")", "\n", "pos_tags", ".", "append", "(", "annotation", "[", "'pos_tags'", "]", "[", "i", "]", ")", "\n", "ner_tags", ".", "append", "(", "annotation", "[", "'ner_tags'", "]", "[", "i", "]", ")", "\n", "\n", "", "", "output", "=", "dict", "(", "\n", "tokens", "=", "tokens", ",", "lemmas", "=", "lemmas", ",", "pos_tags", "=", "pos_tags", ",", "ner_tags", "=", "ner_tags", "\n", ")", "\n", "self", ".", "assert_equal_length", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._combine_numbers": [[119, 149], ["enumerate", "dict", "feature_annotator.FeatureAnnotator.assert_equal_length", "feature_annotator.FeatureAnnotator._combine_numbers.combinable"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.assert_equal_length"], ["", "def", "_combine_numbers", "(", "self", ",", "annotation", ")", ":", "\n", "\n", "        ", "def", "two_combinable_numbers", "(", "x", ",", "y", ")", ":", "\n", "            ", "return", "x", "in", "self", ".", "NumberTexts", "and", "y", "!=", "\"-\"", "\n", "\n", "", "def", "combinable", "(", "i", ",", "tag", ")", ":", "\n", "            ", "return", "len", "(", "lemmas", ")", ">", "0", "and", "tag", "==", "'CD'", "and", "pos_tags", "[", "-", "1", "]", "==", "'CD'", "and", "two_combinable_numbers", "(", "lemmas", "[", "-", "1", "]", ",", "annotation", "[", "'lemmas'", "]", "[", "i", "]", ")", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "lemmas", "=", "[", "]", "\n", "pos_tags", "=", "[", "]", "\n", "ner_tags", "=", "[", "]", "\n", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "annotation", "[", "'pos_tags'", "]", ")", ":", "\n", "            ", "if", "combinable", "(", "i", ",", "tag", ")", ":", "\n", "                ", "lemmas", "[", "-", "1", "]", "=", "lemmas", "[", "-", "1", "]", "+", "','", "+", "annotation", "[", "'lemmas'", "]", "[", "i", "]", "\n", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "','", "+", "annotation", "[", "'tokens'", "]", "[", "i", "]", "\n", "pos_tags", "[", "-", "1", "]", "=", "\"CD\"", "\n", "", "else", ":", "\n", "                ", "lemmas", ".", "append", "(", "annotation", "[", "'lemmas'", "]", "[", "i", "]", ")", "\n", "tokens", ".", "append", "(", "annotation", "[", "'tokens'", "]", "[", "i", "]", ")", "\n", "pos_tags", ".", "append", "(", "annotation", "[", "'pos_tags'", "]", "[", "i", "]", ")", "\n", "ner_tags", ".", "append", "(", "annotation", "[", "'ner_tags'", "]", "[", "i", "]", ")", "\n", "\n", "", "", "output", "=", "dict", "(", "\n", "tokens", "=", "tokens", ",", "lemmas", "=", "lemmas", ",", "pos_tags", "=", "pos_tags", ",", "ner_tags", "=", "ner_tags", "\n", ")", "\n", "self", ".", "assert_equal_length", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator._tag_url_and_split_number": [[150, 186], ["enumerate", "dict", "feature_annotator.FeatureAnnotator.assert_equal_length", "lemmas.append", "tokens.append", "pos_tags.append", "ner_tags.append", "re.match", "lemma.replace().split", "[].replace().split", "lemmas.append", "tokens.append", "pos_tags.append", "ner_tags.append", "len", "len", "lemma.replace", "[].replace", "pos_tags.append", "ner_tags.append", "pos_tags.append", "ner_tags.append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.preprocess.feature_annotator.FeatureAnnotator.assert_equal_length"], ["", "def", "_tag_url_and_split_number", "(", "self", ",", "annotation", ")", ":", "\n", "        ", "tokens", "=", "[", "]", "\n", "lemmas", "=", "[", "]", "\n", "pos_tags", "=", "[", "]", "\n", "ner_tags", "=", "[", "]", "\n", "\n", "for", "i", ",", "lemma", "in", "enumerate", "(", "annotation", "[", "'lemmas'", "]", ")", ":", "\n", "            ", "if", "'http'", "in", "lemma", "or", "'www.'", "in", "lemma", ":", "\n", "                ", "lemmas", ".", "append", "(", "lemma", ")", "\n", "tokens", ".", "append", "(", "annotation", "[", "'tokens'", "]", "[", "i", "]", ")", "\n", "pos_tags", ".", "append", "(", "annotation", "[", "'pos_tags'", "]", "[", "i", "]", ")", "\n", "ner_tags", ".", "append", "(", "\"URL\"", ")", "\n", "", "elif", "re", ".", "match", "(", "self", ".", "DashedNumbers", ",", "lemma", ")", "and", "annotation", "[", "'ner_tags'", "]", "[", "i", "]", "==", "'DATE'", ":", "\n", "                ", "_lemmas", "=", "lemma", ".", "replace", "(", "'-'", ",", "' - '", ")", ".", "split", "(", ")", "\n", "_tokens", "=", "annotation", "[", "'tokens'", "]", "[", "i", "]", ".", "replace", "(", "'-'", ",", "' - '", ")", ".", "split", "(", ")", "\n", "assert", "len", "(", "_lemmas", ")", "==", "len", "(", "_tokens", ")", ",", "annotation", "\n", "for", "l", "in", "_lemmas", ":", "\n", "                    ", "if", "l", "!=", "'-'", ":", "\n", "                        ", "pos_tags", ".", "append", "(", "annotation", "[", "'pos_tags'", "]", "[", "i", "]", ")", "\n", "ner_tags", ".", "append", "(", "annotation", "[", "'ner_tags'", "]", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "pos_tags", ".", "append", "(", "':'", ")", "\n", "ner_tags", ".", "append", "(", "'0'", ")", "\n", "", "", "lemmas", "=", "lemmas", "+", "_lemmas", "\n", "tokens", "=", "tokens", "+", "_tokens", "\n", "", "else", ":", "\n", "                ", "lemmas", ".", "append", "(", "annotation", "[", "'lemmas'", "]", "[", "i", "]", ")", "\n", "tokens", ".", "append", "(", "annotation", "[", "'tokens'", "]", "[", "i", "]", ")", "\n", "pos_tags", ".", "append", "(", "annotation", "[", "'pos_tags'", "]", "[", "i", "]", ")", "\n", "ner_tags", ".", "append", "(", "annotation", "[", "'ner_tags'", "]", "[", "i", "]", ")", "\n", "\n", "", "", "output", "=", "dict", "(", "\n", "tokens", "=", "tokens", ",", "lemmas", "=", "lemmas", ",", "pos_tags", "=", "pos_tags", ",", "ner_tags", "=", "ner_tags", "\n", ")", "\n", "self", ".", "assert_equal_length", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.__init__": [[17, 25], ["set", "nltk.stem.SnowballStemmer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "node_utils", ")", ":", "\n", "        ", "self", ".", "node_utils", "=", "node_utils", "\n", "self", ".", "stemmer", "=", "nltk", ".", "stem", ".", "SnowballStemmer", "(", "'english'", ")", ".", "stem", "\n", "\n", "self", ".", "removed_instance_count", "=", "0", "\n", "self", ".", "amr_instance_count", "=", "0", "\n", "self", ".", "restore_count", "=", "0", "\n", "self", ".", "not_removed_instances", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.remove_file": [[26, 32], ["enumerate", "stog.data.dataset_readers.amr_parsing.io.AMRIO.read", "sense_remover.SenseRemover.remove_graph", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.remove_graph"], ["", "def", "remove_file", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "for", "i", ",", "amr", "in", "enumerate", "(", "AMRIO", ".", "read", "(", "file_path", ")", ",", "1", ")", ":", "\n", "            ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'Processed {} examples.'", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "remove_graph", "(", "amr", ")", "\n", "yield", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.remove_graph": [[33, 45], ["graph.get_nodes", "re.sub", "sense_remover.SenseRemover.update_graph", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.get_nodes", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.update_graph"], ["", "", "def", "remove_graph", "(", "self", ",", "amr", ")", ":", "\n", "        ", "graph", "=", "amr", ".", "graph", "\n", "for", "node", "in", "graph", ".", "get_nodes", "(", ")", ":", "\n", "            ", "if", "node", ".", "copy_of", "is", "not", "None", ":", "\n", "                ", "continue", "\n", "", "instance", "=", "node", ".", "instance", "\n", "instance_lemma", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "str", "(", "instance", ")", ")", "\n", "#lemmas = self.map_instance_to_lemmas(instance)", "\n", "#lemma = self.find_corresponding_lemma(instance, lemmas, amr)", "\n", "#if lemma is None:", "\n", "#    lemma = self.remove_sense(instance)", "\n", "self", ".", "update_graph", "(", "graph", ",", "node", ",", "instance", ",", "instance_lemma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.map_instance_to_lemmas": [[46, 58], ["re.search", "str", "sense_remover.SenseRemover.node_utils.get_lemmas", "isinstance", "re.search"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_lemmas"], ["", "", "def", "map_instance_to_lemmas", "(", "self", ",", "instance", ")", ":", "\n", "        ", "\"\"\"\n        Get the candidate lemmas which can be used to represent the instance.\n        \"\"\"", "\n", "# Make sure it's a string and not quoted.", "\n", "if", "not", "(", "isinstance", "(", "instance", ",", "str", ")", "and", "not", "re", ".", "search", "(", "r'^\".*\"$'", ",", "instance", ")", ")", ":", "\n", "            ", "instance", "=", "str", "(", "instance", ")", "\n", "", "if", "re", ".", "search", "(", "r'-\\d\\d$'", ",", "instance", ")", ":", "# frame", "\n", "            ", "lemmas", "=", "self", ".", "node_utils", ".", "get_lemmas", "(", "instance", ")", "\n", "", "else", ":", "\n", "            ", "lemmas", "=", "[", "instance", "]", "\n", "", "return", "lemmas", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.find_corresponding_lemma": [[59, 79], ["sense_remover.SenseRemover.not_removed_instances.add", "sense_remover.SenseRemover.node_utils.get_frames"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_frames"], ["", "def", "find_corresponding_lemma", "(", "self", ",", "instance", ",", "lemmas", ",", "amr", ")", ":", "\n", "        ", "self", ".", "amr_instance_count", "+=", "1", "\n", "input_lemma", "=", "None", "\n", "for", "lemma", "in", "lemmas", ":", "\n", "            ", "if", "lemma", "in", "amr", ".", "lemmas", ":", "\n", "                ", "input_lemma", "=", "lemma", "\n", "break", "\n", "\n", "# Make sure it can be correctly restored.", "\n", "", "", "if", "input_lemma", "is", "not", "None", ":", "\n", "            ", "restored_frame", "=", "self", ".", "node_utils", ".", "get_frames", "(", "input_lemma", ")", "[", "0", "]", "\n", "if", "restored_frame", "!=", "instance", ":", "\n", "                ", "input_lemma", "=", "None", "\n", "\n", "", "", "if", "input_lemma", "is", "None", ":", "\n", "            ", "self", ".", "not_removed_instances", ".", "add", "(", "instance", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "removed_instance_count", "+=", "1", "\n", "\n", "", "return", "input_lemma", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.remove_sense": [[80, 86], ["re.sub", "str", "sense_remover.SenseRemover.node_utils.get_frames"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_frames"], ["", "def", "remove_sense", "(", "self", ",", "instance", ")", ":", "\n", "        ", "instance_lemma", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "str", "(", "instance", ")", ")", "\n", "restored", "=", "self", ".", "node_utils", ".", "get_frames", "(", "instance_lemma", ")", "[", "0", "]", "\n", "if", "restored", "==", "instance", ":", "\n", "            ", "return", "instance_lemma", "\n", "", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.update_graph": [[87, 93], ["graph.replace_node_attribute", "sense_remover.SenseRemover.try_restore", "sense_remover.SenseRemover.try_restore", "str"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.replace_node_attribute", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.try_restore", "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.try_restore"], ["", "def", "update_graph", "(", "self", ",", "graph", ",", "node", ",", "old", ",", "new", ")", ":", "\n", "        ", "if", "new", "is", "not", "None", ":", "\n", "            ", "graph", ".", "replace_node_attribute", "(", "node", ",", "'instance'", ",", "old", ",", "new", ")", "\n", "self", ".", "try_restore", "(", "str", "(", "old", ")", ",", "new", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "try_restore", "(", "old", ",", "old", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.try_restore": [[94, 97], ["int", "sense_remover.SenseRemover.node_utils.get_frames"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.get_frames"], ["", "", "def", "try_restore", "(", "self", ",", "old", ",", "new", ")", ":", "\n", "        ", "_old", "=", "self", ".", "node_utils", ".", "get_frames", "(", "new", ")", "[", "0", "]", "\n", "self", ".", "restore_count", "+=", "int", "(", "old", "==", "_old", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.reset_statistics": [[98, 103], ["set"], "methods", ["None"], ["", "def", "reset_statistics", "(", "self", ")", ":", "\n", "        ", "self", ".", "removed_instance_count", "=", "0", "\n", "self", ".", "amr_instance_count", "=", "0", "\n", "self", ".", "restore_count", "=", "0", "\n", "self", ".", "no_removed_instances", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.preprocess.sense_remover.SenseRemover.print_statistics": [[104, 112], ["logger.info", "logger.info", "logger.info", "len"], "methods", ["None"], ["", "def", "print_statistics", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'sense remove rate: {}% ({}/{})'", ".", "format", "(", "\n", "self", ".", "removed_instance_count", "/", "self", ".", "amr_instance_count", ",", "\n", "self", ".", "removed_instance_count", ",", "self", ".", "amr_instance_count", ")", ")", "\n", "logger", ".", "info", "(", "'restore rate: {}% ({}/{})'", ".", "format", "(", "\n", "self", ".", "restore_count", "/", "self", ".", "amr_instance_count", ",", "\n", "self", ".", "restore_count", ",", "self", ".", "amr_instance_count", ")", ")", "\n", "logger", ".", "info", "(", "'size of not removed lemma set: {}'", ".", "format", "(", "len", "(", "self", ".", "not_removed_instances", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.bucket_iterator.BucketIterator.__init__": [[86, 108], ["stog.data.iterators.data_iterator.DataIterator.__init__", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "\n", "padding_noise", ":", "float", "=", "0.1", ",", "\n", "biggest_batch_first", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "instances_per_epoch", ":", "int", "=", "None", ",", "\n", "max_instances_in_memory", ":", "int", "=", "None", ",", "\n", "cache_instances", ":", "bool", "=", "False", ",", "\n", "track_epoch", ":", "bool", "=", "False", ",", "\n", "maximum_samples_per_batch", ":", "Tuple", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "not", "sorting_keys", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"BucketIterator requires sorting_keys to be specified\"", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "cache_instances", "=", "cache_instances", ",", "\n", "track_epoch", "=", "track_epoch", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "instances_per_epoch", "=", "instances_per_epoch", ",", "\n", "max_instances_in_memory", "=", "max_instances_in_memory", ",", "\n", "maximum_samples_per_batch", "=", "maximum_samples_per_batch", ")", "\n", "self", ".", "_sorting_keys", "=", "sorting_keys", "\n", "self", ".", "_padding_noise", "=", "padding_noise", "\n", "self", ".", "_biggest_batch_first", "=", "biggest_batch_first", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.bucket_iterator.BucketIterator._create_batches": [[109, 137], ["bucket_iterator.BucketIterator._memory_sized_lists", "bucket_iterator.sort_by_padding", "stog.utils.lazy_groups_of", "iter", "bucket_iterator.BucketIterator._ensure_batch_is_sufficiently_small", "batches.pop", "batches.pop", "random.shuffle", "batches.insert", "batches.insert", "batches.append", "len", "stog.data.dataset.Batch"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._memory_sized_lists", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.bucket_iterator.sort_by_padding", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._ensure_batch_is_sufficiently_small"], ["", "@", "overrides", "\n", "def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "for", "instance_list", "in", "self", ".", "_memory_sized_lists", "(", "instances", ")", ":", "\n", "\n", "            ", "instance_list", "=", "sort_by_padding", "(", "instance_list", ",", "\n", "self", ".", "_sorting_keys", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "_padding_noise", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "batch_instances", "in", "lazy_groups_of", "(", "iter", "(", "instance_list", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                ", "for", "possibly_smaller_batches", "in", "self", ".", "_ensure_batch_is_sufficiently_small", "(", "batch_instances", ")", ":", "\n", "                    ", "batches", ".", "append", "(", "Batch", "(", "possibly_smaller_batches", ")", ")", "\n", "\n", "", "", "move_to_front", "=", "self", ".", "_biggest_batch_first", "and", "len", "(", "batches", ")", ">", "1", "\n", "if", "move_to_front", ":", "\n", "# We'll actually pop the last _two_ batches, because the last one might not be full.", "\n", "                ", "last_batch", "=", "batches", ".", "pop", "(", ")", "\n", "penultimate_batch", "=", "batches", ".", "pop", "(", ")", "\n", "", "if", "shuffle", ":", "\n", "# NOTE: if shuffle is false, the data will still be in a different order", "\n", "# because of the bucket sorting.", "\n", "                ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "if", "move_to_front", ":", "\n", "                ", "batches", ".", "insert", "(", "0", ",", "penultimate_batch", ")", "\n", "batches", ".", "insert", "(", "0", ",", "last_batch", ")", "\n", "\n", "", "yield", "from", "batches", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.bucket_iterator.sort_by_padding": [[16, 41], ["instances_with_lengths.sort", "instance.index_fields", "typing.cast", "instances_with_lengths.append", "instance.get_padding_lengths", "typing.cast.items", "stog.utils.add_noise_to_dict_values"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.index_fields", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.add_noise_to_dict_values"], ["def", "sort_by_padding", "(", "instances", ":", "List", "[", "Instance", "]", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "# pylint: disable=invalid-sequence-index", "\n", "vocab", ":", "Vocabulary", ",", "\n", "padding_noise", ":", "float", "=", "0.0", ")", "->", "List", "[", "Instance", "]", ":", "\n", "    ", "\"\"\"\n    Sorts the instances by their padding lengths, using the keys in\n    ``sorting_keys`` (in the order in which they are provided).  ``sorting_keys`` is a list of\n    ``(field_name, padding_key)`` tuples.\n    \"\"\"", "\n", "instances_with_lengths", "=", "[", "]", "\n", "for", "instance", "in", "instances", ":", "\n", "# Make sure instance is indexed before calling .get_padding", "\n", "        ", "instance", ".", "index_fields", "(", "vocab", ")", "\n", "padding_lengths", "=", "cast", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "instance", ".", "get_padding_lengths", "(", ")", ")", "\n", "if", "padding_noise", ">", "0.0", ":", "\n", "            ", "noisy_lengths", "=", "{", "}", "\n", "for", "field_name", ",", "field_lengths", "in", "padding_lengths", ".", "items", "(", ")", ":", "\n", "                ", "noisy_lengths", "[", "field_name", "]", "=", "add_noise_to_dict_values", "(", "field_lengths", ",", "padding_noise", ")", "\n", "", "padding_lengths", "=", "noisy_lengths", "\n", "", "instance_with_lengths", "=", "(", "[", "padding_lengths", "[", "field_name", "]", "[", "padding_key", "]", "\n", "for", "(", "field_name", ",", "padding_key", ")", "in", "sorting_keys", "]", ",", "\n", "instance", ")", "\n", "instances_with_lengths", ".", "append", "(", "instance_with_lengths", ")", "\n", "", "instances_with_lengths", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "return", "[", "instance_with_lengths", "[", "-", "1", "]", "for", "instance_with_lengths", "in", "instances_with_lengths", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.epoch_tracking_bucket_iterator.EpochTrackingBucketIterator.__init__": [[25, 44], ["stog.data.iterators.bucket_iterator.BucketIterator.__init__", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "\n", "padding_noise", ":", "float", "=", "0.1", ",", "\n", "biggest_batch_first", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "instances_per_epoch", ":", "int", "=", "None", ",", "\n", "max_instances_in_memory", ":", "int", "=", "None", ",", "\n", "cache_instances", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sorting_keys", "=", "sorting_keys", ",", "\n", "padding_noise", "=", "padding_noise", ",", "\n", "biggest_batch_first", "=", "biggest_batch_first", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "instances_per_epoch", "=", "instances_per_epoch", ",", "\n", "max_instances_in_memory", "=", "max_instances_in_memory", ",", "\n", "track_epoch", "=", "True", ",", "\n", "cache_instances", "=", "cache_instances", ")", "\n", "warnings", ".", "warn", "(", "\"EpochTrackingBucketIterator is deprecated, \"", "\n", "\"please just use BucketIterator with track_epoch=True\"", ",", "\n", "DeprecationWarning", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator.MultiprocessIterator.__init__": [[72, 93], ["stog.data.iterators.data_iterator.DataIterator.__init__", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "\n", "base_iterator", ":", "DataIterator", ",", "\n", "num_workers", ":", "int", "=", "1", ",", "\n", "output_queue_size", ":", "int", "=", "1000", ")", "->", "None", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "batch_size", "=", "base_iterator", ".", "_batch_size", "\n", "self", ".", "output_queue_size", "=", "output_queue_size", "\n", "\n", "# These two options make the iterator stateful, which means it can't be shared", "\n", "# across multiple processes.", "\n", "if", "base_iterator", ".", "_cache_instances", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"cannot use Multiprocess iterator with cache_instances\"", ")", "\n", "", "if", "base_iterator", ".", "_instances_per_epoch", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"cannot use instances_per_epoch with Multiprocess iterator\"", ")", "\n", "\n", "", "self", ".", "iterator", "=", "base_iterator", "\n", "\n", "self", ".", "processes", ":", "List", "[", "Process", "]", "=", "[", "]", "\n", "self", ".", "queuer", ":", "Optional", "[", "Process", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator.MultiprocessIterator._create_batches": [[94, 96], ["RuntimeError"], "methods", ["None"], ["", "def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"MultiprocessIterator doesn't use create_batches\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator.MultiprocessIterator.index_with": [[97, 99], ["multiprocess_iterator.MultiprocessIterator.iterator.index_with"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with"], ["", "def", "index_with", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "self", ".", "iterator", ".", "index_with", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator.MultiprocessIterator.__call__": [[100, 141], ["torch.multiprocessing.Manager", "torch.multiprocessing.Manager.Queue", "torch.multiprocessing.Manager.Queue", "torch.multiprocessing.Process", "multiprocess_iterator.MultiprocessIterator.queuer.start", "range", "multiprocess_iterator.MultiprocessIterator.processes.clear", "stog.utils.checks.ConfigurationError", "torch.multiprocessing.Process", "torch.multiprocessing.Process.start", "multiprocess_iterator.MultiprocessIterator.processes.append", "torch.multiprocessing.Manager.Queue.get", "isinstance", "torch.multiprocessing.Process.join", "multiprocess_iterator.MultiprocessIterator.queuer.join", "logger.info"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "def", "__call__", "(", "self", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "num_epochs", ":", "int", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ")", "->", "Iterator", "[", "TensorDict", "]", ":", "\n", "\n", "# If you run it forever, the multiprocesses won't shut down correctly.", "\n", "# TODO(joelgrus) find a solution for this", "\n", "        ", "if", "num_epochs", "is", "None", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Multiprocess Iterator must be run for a fixed number of epochs\"", ")", "\n", "\n", "", "manager", "=", "Manager", "(", ")", "\n", "output_queue", "=", "manager", ".", "Queue", "(", "self", ".", "output_queue_size", ")", "\n", "input_queue", "=", "manager", ".", "Queue", "(", "self", ".", "output_queue_size", "*", "self", ".", "batch_size", ")", "\n", "\n", "# Start process that populates the queue.", "\n", "self", ".", "queuer", "=", "Process", "(", "target", "=", "_queuer", ",", "args", "=", "(", "instances", ",", "input_queue", ",", "self", ".", "num_workers", ",", "num_epochs", ")", ")", "\n", "self", ".", "queuer", ".", "start", "(", ")", "\n", "\n", "# Start the tensor-dict workers.", "\n", "for", "i", "in", "range", "(", "self", ".", "num_workers", ")", ":", "\n", "            ", "args", "=", "(", "input_queue", ",", "output_queue", ",", "self", ".", "iterator", ",", "shuffle", ",", "i", ")", "\n", "process", "=", "Process", "(", "target", "=", "_create_tensor_dicts", ",", "args", "=", "args", ")", "\n", "process", ".", "start", "(", ")", "\n", "self", ".", "processes", ".", "append", "(", "process", ")", "\n", "\n", "", "num_finished", "=", "0", "\n", "while", "num_finished", "<", "self", ".", "num_workers", ":", "\n", "            ", "item", "=", "output_queue", ".", "get", "(", ")", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "                ", "num_finished", "+=", "1", "\n", "logger", ".", "info", "(", "f\"worker {item} finished ({num_finished} / {self.num_workers})\"", ")", "\n", "", "else", ":", "\n", "                ", "yield", "item", "\n", "\n", "", "", "for", "process", "in", "self", ".", "processes", ":", "\n", "            ", "process", ".", "join", "(", ")", "\n", "", "self", ".", "processes", ".", "clear", "(", ")", "\n", "\n", "if", "self", ".", "queuer", "is", "not", "None", ":", "\n", "            ", "self", ".", "queuer", ".", "join", "(", ")", "\n", "self", ".", "queuer", "=", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator._create_tensor_dicts": [[15, 35], ["iterator", "output_queue.put", "input_queue.get", "multiprocess_iterator._create_tensor_dicts.instances"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["def", "_create_tensor_dicts", "(", "input_queue", ":", "Queue", ",", "\n", "output_queue", ":", "Queue", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "shuffle", ":", "bool", ",", "\n", "index", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Pulls at most ``max_instances_in_memory`` from the input_queue,\n    groups them into batches of size ``batch_size``, converts them\n    to ``TensorDict`` s, and puts them on the ``output_queue``.\n    \"\"\"", "\n", "def", "instances", "(", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "instance", "=", "input_queue", ".", "get", "(", ")", "\n", "while", "instance", "is", "not", "None", ":", "\n", "            ", "yield", "instance", "\n", "instance", "=", "input_queue", ".", "get", "(", ")", "\n", "\n", "", "", "for", "tensor_dict", "in", "iterator", "(", "instances", "(", ")", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "shuffle", ")", ":", "\n", "        ", "output_queue", ".", "put", "(", "tensor_dict", ")", "\n", "\n", "", "output_queue", ".", "put", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.multiprocess_iterator._queuer": [[36, 54], ["range", "input_queue.put", "input_queue.put"], "function", ["None"], ["", "def", "_queuer", "(", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "input_queue", ":", "Queue", ",", "\n", "num_workers", ":", "int", ",", "\n", "num_epochs", ":", "Optional", "[", "int", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Reads Instances from the iterable and puts them in the input_queue.\n    \"\"\"", "\n", "epoch", "=", "0", "\n", "\n", "while", "num_epochs", "is", "None", "or", "epoch", "<", "num_epochs", ":", "\n", "        ", "epoch", "+=", "1", "\n", "for", "instance", "in", "instances", ":", "\n", "            ", "input_queue", ".", "put", "(", "instance", ")", "\n", "\n", "# Now put a None for each worker, since each needs to receive one", "\n", "# to know that it's done.", "\n", "", "", "for", "_", "in", "range", "(", "num_workers", ")", ":", "\n", "        ", "input_queue", ".", "put", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.basic_iterator.BasicIterator._create_batches": [[20, 31], ["basic_iterator.BasicIterator._memory_sized_lists", "iter", "stog.utils.lazy_groups_of", "random.shuffle", "basic_iterator.BasicIterator._ensure_batch_is_sufficiently_small", "stog.data.dataset.Batch"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._memory_sized_lists", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._ensure_batch_is_sufficiently_small"], ["def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "# First break the dataset into memory-sized lists:", "\n", "        ", "for", "instance_list", "in", "self", ".", "_memory_sized_lists", "(", "instances", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "instance_list", ")", "\n", "", "iterator", "=", "iter", "(", "instance_list", ")", "\n", "# Then break each memory-sized list into batches.", "\n", "for", "batch_instances", "in", "lazy_groups_of", "(", "iterator", ",", "self", ".", "_batch_size", ")", ":", "\n", "                ", "for", "possibly_smaller_batches", "in", "self", ".", "_ensure_batch_is_sufficiently_small", "(", "batch_instances", ")", ":", "\n", "                    ", "batch", "=", "Batch", "(", "possibly_smaller_batches", ")", "\n", "yield", "batch", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.__init__": [[59, 86], ["collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "instances_per_epoch", ":", "int", "=", "None", ",", "\n", "max_instances_in_memory", ":", "int", "=", "None", ",", "\n", "cache_instances", ":", "bool", "=", "False", ",", "\n", "track_epoch", ":", "bool", "=", "False", ",", "\n", "maximum_samples_per_batch", ":", "Tuple", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "vocab", ":", "Vocabulary", "=", "None", "\n", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_max_instances_in_memory", "=", "max_instances_in_memory", "\n", "self", ".", "_instances_per_epoch", "=", "instances_per_epoch", "\n", "self", ".", "_maximum_samples_per_batch", "=", "maximum_samples_per_batch", "\n", "\n", "# We might want to cache the instances in memory.", "\n", "self", ".", "_cache_instances", "=", "cache_instances", "\n", "self", ".", "_cache", ":", "Dict", "[", "int", ",", "List", "[", "TensorDict", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "\n", "# We also might want to add the epoch number to each instance.", "\n", "self", ".", "_track_epoch", "=", "track_epoch", "\n", "self", ".", "_epochs", ":", "Dict", "[", "int", ",", "int", "]", "=", "defaultdict", "(", "int", ")", "\n", "\n", "# We also might want to keep track of cursors;", "\n", "# for example, if each epoch represents less than one pass through the dataset,", "\n", "# we want to remember where we left off. As `Iterator`s are not necessarily hashable,", "\n", "# we use their id() as the key.", "\n", "self", ".", "_cursors", ":", "Dict", "[", "int", ",", "Iterator", "[", "Instance", "]", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.__call__": [[88, 159], ["id", "itertools.count", "range", "data_iterator.DataIterator._create_batches", "random.shuffle", "batch.get_padding_lengths", "logger.debug", "logger.debug", "batch.as_tensor_dict", "epoch_tensor.fill_", "data_iterator.add_epoch_number", "batch.index_instances", "str", "len", "data_iterator.DataIterator._cache[].append"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._create_batches", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.as_tensor_dict", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.add_epoch_number", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset.Batch.index_instances"], ["", "def", "__call__", "(", "self", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "num_epochs", ":", "int", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ")", "->", "Iterator", "[", "TensorDict", "]", ":", "\n", "        ", "\"\"\"\n        Returns a generator that yields batches over the given dataset\n        for the given number of epochs. If ``num_epochs`` is not specified,\n        it will yield batches forever.\n\n        Parameters\n        ----------\n        instances : ``Iterable[Instance]``\n            The instances in the dataset. IMPORTANT: this must be able to be\n            iterated over *multiple times*. That is, it must be either a List\n            or some other object whose ``__iter__`` method returns a fresh iterator\n            each time it's called.\n        num_epochs : ``int``, optional (default=``None``)\n            How times should we iterate over this dataset?  If ``None``, we will iterate over it\n            forever.\n        shuffle : ``bool``, optional (default=``True``)\n            If ``True``, we will shuffle the instances in ``dataset`` before constructing batches\n            and iterating over the data.\n        \"\"\"", "\n", "# Instances is likely to be a list, which cannot be used as a key,", "\n", "# so we take the object id instead.", "\n", "key", "=", "id", "(", "instances", ")", "\n", "starting_epoch", "=", "self", ".", "_epochs", "[", "key", "]", "\n", "\n", "if", "num_epochs", "is", "None", ":", "\n", "            ", "epochs", ":", "Iterable", "[", "int", "]", "=", "itertools", ".", "count", "(", "starting_epoch", ")", "\n", "", "else", ":", "\n", "            ", "epochs", "=", "range", "(", "starting_epoch", ",", "starting_epoch", "+", "num_epochs", ")", "\n", "\n", "", "for", "epoch", "in", "epochs", ":", "\n", "            ", "self", ".", "_epochs", "[", "key", "]", "=", "epoch", "\n", "\n", "if", "self", ".", "_cache_instances", "and", "key", "in", "self", ".", "_cache", ":", "\n", "# Serve the results from the cache.", "\n", "                ", "tensor_dicts", "=", "self", ".", "_cache", "[", "key", "]", "\n", "\n", "if", "shuffle", ":", "\n", "                    ", "random", ".", "shuffle", "(", "tensor_dicts", ")", "\n", "", "for", "tensor_dict", "in", "tensor_dicts", ":", "\n", "                    ", "if", "self", ".", "_track_epoch", ":", "\n", "# The tensor_dict already has an \"epoch_num\" tensor,", "\n", "# so just fill it with the right value.", "\n", "                        ", "epoch_tensor", ":", "torch", ".", "Tensor", "=", "tensor_dict", "[", "'epoch_num'", "]", "\n", "epoch_tensor", ".", "fill_", "(", "epoch", ")", "\n", "", "yield", "tensor_dict", "\n", "", "", "else", ":", "\n", "                ", "batches", "=", "self", ".", "_create_batches", "(", "instances", ",", "shuffle", ")", "\n", "\n", "# Should we add the instances to the cache this epoch?", "\n", "add_to_cache", "=", "self", ".", "_cache_instances", "and", "key", "not", "in", "self", ".", "_cache", "\n", "\n", "for", "batch", "in", "batches", ":", "\n", "                    ", "if", "self", ".", "_track_epoch", ":", "\n", "                        ", "add_epoch_number", "(", "batch", ",", "epoch", ")", "\n", "\n", "", "if", "self", ".", "vocab", "is", "not", "None", ":", "\n", "                        ", "batch", ".", "index_instances", "(", "self", ".", "vocab", ")", "\n", "\n", "", "padding_lengths", "=", "batch", ".", "get_padding_lengths", "(", ")", "\n", "logger", ".", "debug", "(", "\"Batch padding lengths: %s\"", ",", "str", "(", "padding_lengths", ")", ")", "\n", "logger", ".", "debug", "(", "\"Batch size: %d\"", ",", "len", "(", "batch", ".", "instances", ")", ")", "\n", "tensor_dict", "=", "batch", ".", "as_tensor_dict", "(", "padding_lengths", ")", "\n", "\n", "if", "add_to_cache", ":", "\n", "                        ", "self", ".", "_cache", "[", "key", "]", ".", "append", "(", "tensor_dict", ")", "\n", "\n", "", "yield", "tensor_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._take_instances": [[160, 190], ["id", "data_iterator.DataIterator._cursors.get", "iter", "iter", "next", "iter"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["", "", "", "", "def", "_take_instances", "(", "self", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "max_instances", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "\"\"\"\n        Take the next `max_instances` instances from the given dataset.\n        If `max_instances` is `None`, then just take all instances from the dataset.\n        If `max_instances` is not `None`, each call resumes where the previous one\n        left off, and when you get to the end of the dataset you start again from the beginning.\n        \"\"\"", "\n", "# If max_instances isn't specified, just iterate once over the whole dataset", "\n", "if", "max_instances", "is", "None", ":", "\n", "            ", "yield", "from", "iter", "(", "instances", ")", "\n", "", "else", ":", "\n", "# If we don't have a cursor for this dataset, create one. We use ``id()``", "\n", "# for the key because ``instances`` could be a list, which can't be used as a key.", "\n", "            ", "key", "=", "id", "(", "instances", ")", "\n", "iterator", "=", "self", ".", "_cursors", ".", "get", "(", "key", ",", "iter", "(", "instances", ")", ")", "\n", "\n", "while", "max_instances", ">", "0", ":", "\n", "                ", "try", ":", "\n", "# If there are instances left on this iterator,", "\n", "# yield one and decrement max_instances.", "\n", "                    ", "yield", "next", "(", "iterator", ")", "\n", "max_instances", "-=", "1", "\n", "", "except", "StopIteration", ":", "\n", "# None left, so start over again at the beginning of the dataset.", "\n", "                    ", "iterator", "=", "iter", "(", "instances", ")", "\n", "\n", "# We may have a new iterator, so update the cursor.", "\n", "", "", "self", ".", "_cursors", "[", "key", "]", "=", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._memory_sized_lists": [[191, 226], ["stog.utils.is_lazy", "data_iterator.DataIterator._take_instances", "stog.utils.lazy_groups_of", "stog.utils.lazy_groups_of", "stog.utils.ensure_list", "list"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.is_lazy", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._take_instances", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.ensure_list"], ["", "", "def", "_memory_sized_lists", "(", "self", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ")", "->", "Iterable", "[", "List", "[", "Instance", "]", "]", ":", "\n", "        ", "\"\"\"\n        Breaks the dataset into \"memory-sized\" lists of instances,\n        which it yields up one at a time until it gets through a full epoch.\n\n        For example, if the dataset is already an in-memory list, and each epoch\n        represents one pass through the dataset, it just yields back the dataset.\n        Whereas if the dataset is lazily read from disk and we've specified to\n        load 1000 instances at a time, then it yields lists of 1000 instances each.\n        \"\"\"", "\n", "lazy", "=", "is_lazy", "(", "instances", ")", "\n", "\n", "# Get an iterator over the next epoch worth of instances.", "\n", "iterator", "=", "self", ".", "_take_instances", "(", "instances", ",", "self", ".", "_instances_per_epoch", ")", "\n", "\n", "# We have four different cases to deal with:", "\n", "\n", "# With lazy instances and no guidance about how many to load into memory,", "\n", "# we just load ``batch_size`` instances at a time:", "\n", "if", "lazy", "and", "self", ".", "_max_instances_in_memory", "is", "None", ":", "\n", "            ", "yield", "from", "lazy_groups_of", "(", "iterator", ",", "self", ".", "_batch_size", ")", "\n", "# If we specified max instances in memory, lazy or not, we just", "\n", "# load ``max_instances_in_memory`` instances at a time:", "\n", "", "elif", "self", ".", "_max_instances_in_memory", "is", "not", "None", ":", "\n", "            ", "yield", "from", "lazy_groups_of", "(", "iterator", ",", "self", ".", "_max_instances_in_memory", ")", "\n", "# If we have non-lazy instances, and we want all instances each epoch,", "\n", "# then we just yield back the list of instances:", "\n", "", "elif", "self", ".", "_instances_per_epoch", "is", "None", ":", "\n", "            ", "yield", "ensure_list", "(", "instances", ")", "\n", "# In the final case we have non-lazy instances, we want a specific number", "\n", "# of instances each epoch, and we didn't specify how to many instances to load", "\n", "# into memory. So we convert the whole iterator to a list:", "\n", "", "else", ":", "\n", "            ", "yield", "list", "(", "iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._ensure_batch_is_sufficiently_small": [[228, 268], ["list", "instance.get_padding_lengths", "instance.get_padding_lengths.items", "math.ceil", "math.ceil", "list", "instance.index_fields", "len", "len", "len", "shrunk_batches.append", "max", "float", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.data.instance.Instance.index_fields"], ["", "", "def", "_ensure_batch_is_sufficiently_small", "(", "self", ",", "batch_instances", ":", "Iterable", "[", "Instance", "]", ")", "->", "List", "[", "List", "[", "Instance", "]", "]", ":", "\n", "        ", "\"\"\"\n        If self._maximum_samples_per_batch is specified, then split the batch into smaller\n        sub-batches if it exceeds the maximum size.\n        \"\"\"", "\n", "if", "self", ".", "_maximum_samples_per_batch", "is", "None", ":", "\n", "            ", "return", "[", "list", "(", "batch_instances", ")", "]", "\n", "\n", "# check if we need to break into smaller chunks", "\n", "", "key", ",", "limit", "=", "self", ".", "_maximum_samples_per_batch", "\n", "padding_length", "=", "-", "1", "\n", "list_batch_instances", "=", "list", "(", "batch_instances", ")", "\n", "for", "instance", "in", "list_batch_instances", ":", "\n", "            ", "if", "self", ".", "vocab", "is", "not", "None", ":", "\n", "# we index here to ensure that shape information is available,", "\n", "# as in some cases (with self._maximum_samples_per_batch)", "\n", "# we need access to shaping information before batches are constructed)", "\n", "                ", "instance", ".", "index_fields", "(", "self", ".", "vocab", ")", "\n", "", "field_lengths", "=", "instance", ".", "get_padding_lengths", "(", ")", "\n", "for", "_", ",", "lengths", "in", "field_lengths", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "padding_length", "=", "max", "(", "padding_length", ",", "\n", "lengths", "[", "key", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "if", "padding_length", "*", "len", "(", "list_batch_instances", ")", ">", "limit", ":", "\n", "# need to shrink", "\n", "            ", "num_samples", "=", "padding_length", "*", "len", "(", "list_batch_instances", ")", "\n", "num_shrunk_batches", "=", "math", ".", "ceil", "(", "num_samples", "/", "float", "(", "limit", ")", ")", "\n", "shrunk_batch_size", "=", "math", ".", "ceil", "(", "len", "(", "list_batch_instances", ")", "/", "num_shrunk_batches", ")", "\n", "shrunk_batches", "=", "[", "]", "\n", "start", "=", "0", "\n", "while", "start", "<", "len", "(", "list_batch_instances", ")", ":", "\n", "                ", "end", "=", "start", "+", "shrunk_batch_size", "\n", "shrunk_batches", ".", "append", "(", "list_batch_instances", "[", "start", ":", "end", "]", ")", "\n", "start", "=", "end", "\n", "", "return", "shrunk_batches", "\n", "", "else", ":", "\n", "            ", "return", "[", "list_batch_instances", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.get_num_batches": [[270, 284], ["stog.utils.is_lazy", "math.ceil", "math.ceil", "len", "stog.utils.ensure_list"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.is_lazy", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.ensure_list"], ["", "", "def", "get_num_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the number of batches that ``dataset`` will be split into; if you want to track\n        progress through the batch with the generator produced by ``__call__``, this could be\n        useful.\n        \"\"\"", "\n", "if", "is_lazy", "(", "instances", ")", "and", "self", ".", "_instances_per_epoch", "is", "None", ":", "\n", "# Unable to compute num batches, so just return 1.", "\n", "            ", "return", "1", "\n", "", "elif", "self", ".", "_instances_per_epoch", "is", "not", "None", ":", "\n", "            ", "return", "math", ".", "ceil", "(", "self", ".", "_instances_per_epoch", "/", "self", ".", "_batch_size", ")", "\n", "", "else", ":", "\n", "# Not lazy, so can compute the list length.", "\n", "            ", "return", "math", ".", "ceil", "(", "len", "(", "ensure_list", "(", "instances", ")", ")", "/", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator._create_batches": [[286, 291], ["None"], "methods", ["None"], ["", "", "def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "\"\"\"\n        This method should return one epoch worth of batches.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with": [[292, 294], ["None"], "methods", ["None"], ["", "def", "index_with", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.add_epoch_number": [[22, 29], ["stog.data.fields.MetadataField"], "function", ["None"], ["def", "add_epoch_number", "(", "batch", ":", "Batch", ",", "epoch", ":", "int", ")", "->", "Batch", ":", "\n", "    ", "\"\"\"\n    Add the epoch number to the batch instances as a MetadataField.\n    \"\"\"", "\n", "for", "instance", "in", "batch", ".", "instances", ":", "\n", "        ", "instance", ".", "fields", "[", "'epoch_num'", "]", "=", "MetadataField", "(", "epoch", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.__init__": [[48, 73], ["adjacency_field.AdjacencyField._maybe_warn_for_namespace", "sequence_field.sequence_length", "len", "len", "stog.utils.checks.ConfigurationError", "all", "stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError", "set", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField._maybe_warn_for_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["def", "__init__", "(", "self", ",", "\n", "indices", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "sequence_field", ":", "SequenceField", ",", "\n", "labels", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "label_namespace", ":", "str", "=", "'labels'", ",", "\n", "padding_value", ":", "int", "=", "-", "1", ")", "->", "None", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "sequence_field", "=", "sequence_field", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_padding_value", "=", "padding_value", "\n", "self", ".", "_indexed_labels", ":", "List", "[", "int", "]", "=", "None", "\n", "\n", "self", ".", "_maybe_warn_for_namespace", "(", "label_namespace", ")", "\n", "field_length", "=", "sequence_field", ".", "sequence_length", "(", ")", "\n", "\n", "if", "len", "(", "set", "(", "indices", ")", ")", "!=", "len", "(", "indices", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Indices must be unique, but found {indices}\"", ")", "\n", "\n", "", "if", "not", "all", "(", "[", "0", "<=", "index", "[", "1", "]", "<", "field_length", "and", "0", "<=", "index", "[", "0", "]", "<", "field_length", "for", "index", "in", "indices", "]", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Label indices and sequence length \"", "\n", "f\"are incompatible: {indices} and {field_length}\"", ")", "\n", "\n", "", "if", "labels", "is", "not", "None", "and", "len", "(", "indices", ")", "!=", "len", "(", "labels", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Labelled indices were passed, but their lengths do not match: \"", "\n", "f\" {labels}, {indices}\"", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField._maybe_warn_for_namespace": [[75, 84], ["adjacency_field.AdjacencyField._label_namespace.endswith", "adjacency_field.AdjacencyField._label_namespace.endswith", "logger.warning", "adjacency_field.AdjacencyField._already_warned_namespaces.add"], "methods", ["None"], ["", "", "def", "_maybe_warn_for_namespace", "(", "self", ",", "label_namespace", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "not", "(", "self", ".", "_label_namespace", ".", "endswith", "(", "\"labels\"", ")", "or", "self", ".", "_label_namespace", ".", "endswith", "(", "\"tags\"", ")", ")", ":", "\n", "            ", "if", "label_namespace", "not", "in", "self", ".", "_already_warned_namespaces", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Your label namespace was '%s'. We recommend you use a namespace \"", "\n", "\"ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by \"", "\n", "\"default to your vocabulary.  See documentation for \"", "\n", "\"`non_padded_namespaces` parameter in Vocabulary.\"", ",", "\n", "self", ".", "_label_namespace", ")", "\n", "self", ".", "_already_warned_namespaces", ".", "add", "(", "label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.count_vocab_items": [[85, 90], ["None"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", "and", "self", ".", "labels", "is", "not", "None", ":", "\n", "            ", "for", "label", "in", "self", ".", "labels", ":", "\n", "                ", "counter", "[", "self", ".", "_label_namespace", "]", "[", "label", "]", "+=", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.index": [[91, 96], ["vocab.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", "and", "self", ".", "labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "_indexed_labels", "=", "[", "vocab", ".", "get_token_index", "(", "label", ",", "self", ".", "_label_namespace", ")", "\n", "for", "label", "in", "self", ".", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.get_padding_lengths": [[97, 100], ["adjacency_field.AdjacencyField.sequence_field.sequence_length"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "'num_tokens'", ":", "self", ".", "sequence_field", ".", "sequence_length", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.as_tensor": [[101, 110], ["zip", "torch.ones", "range", "len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "desired_num_tokens", "=", "padding_lengths", "[", "'num_tokens'", "]", "\n", "tensor", "=", "torch", ".", "ones", "(", "desired_num_tokens", ",", "desired_num_tokens", ")", "*", "self", ".", "_padding_value", "\n", "labels", "=", "self", ".", "_indexed_labels", "or", "[", "1", "for", "_", "in", "range", "(", "len", "(", "self", ".", "indices", ")", ")", "]", "\n", "\n", "for", "index", ",", "label", "in", "zip", "(", "self", ".", "indices", ",", "labels", ")", ":", "\n", "            ", "tensor", "[", "index", "]", "=", "label", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.empty_field": [[111, 120], ["AdjacencyField.AdjacencyField", "AdjacencyField.AdjacencyField.sequence_field.empty_field"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "'AdjacencyField'", ":", "\n", "# pylint: disable=protected-access", "\n", "# The empty_list here is needed for mypy", "\n", "        ", "empty_list", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "[", "]", "\n", "adjacency_field", "=", "AdjacencyField", "(", "empty_list", ",", "\n", "self", ".", "sequence_field", ".", "empty_field", "(", ")", ",", "\n", "padding_value", "=", "self", ".", "_padding_value", ")", "\n", "return", "adjacency_field", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.adjacency_field.AdjacencyField.__str__": [[121, 128], ["adjacency_field.AdjacencyField.sequence_field.sequence_length", "textwrap.wrap", "textwrap.wrap", "repr", "repr"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "length", "=", "self", ".", "sequence_field", ".", "sequence_length", "(", ")", "\n", "formatted_labels", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "labels", "+", "\"\\n\"", "\n", "for", "labels", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "labels", ")", ",", "100", ")", "]", ")", "\n", "formatted_indices", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "index", "+", "\"\\n\"", "\n", "for", "index", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "indices", ")", ",", "100", ")", "]", ")", "\n", "return", "f\"AdjacencyField of length {length}\\n\"", "f\"\\t\\twith indices:\\n {formatted_indices}\\n\""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.__init__": [[86, 151], ["tokenizer.batch_tokenize", "getattr", "knowledge_graph_field.KnowledgeGraphField._feature_extractors.append", "zip", "zip", "zip", "knowledge_graph_field.KnowledgeGraphField._compute_linking_features", "knowledge_graph.entity_text[].lower", "allennlp.common.checks.ConfigurationError", "set", "set"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.tokenizers.word_tokenizer.WordTokenizer.batch_tokenize", "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._compute_linking_features"], ["def", "__init__", "(", "self", ",", "\n", "knowledge_graph", ":", "KnowledgeGraph", ",", "\n", "utterance_tokens", ":", "List", "[", "Token", "]", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "feature_extractors", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "entity_tokens", ":", "List", "[", "List", "[", "Token", "]", "]", "=", "None", ",", "\n", "linking_features", ":", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", "=", "None", ",", "\n", "include_in_vocab", ":", "bool", "=", "True", ",", "\n", "max_table_tokens", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "knowledge_graph", "=", "knowledge_graph", "\n", "if", "not", "entity_tokens", ":", "\n", "            ", "entity_texts", "=", "[", "knowledge_graph", ".", "entity_text", "[", "entity", "]", ".", "lower", "(", ")", "\n", "for", "entity", "in", "knowledge_graph", ".", "entities", "]", "\n", "# TODO(mattg): Because we do tagging on each of these entities in addition to just", "\n", "# tokenizations, this is quite slow, and about half of our data processing time just", "\n", "# goes to this (~15 minutes when there are 7k instances).  The reason we do tagging is", "\n", "# so that we can add lemma features.  If we can remove the need for lemma / other", "\n", "# hand-written features, like with a CNN, we can cut down our data processing time by a", "\n", "# factor of 2.", "\n", "self", ".", "entity_texts", "=", "tokenizer", ".", "batch_tokenize", "(", "entity_texts", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "entity_texts", "=", "entity_tokens", "\n", "", "self", ".", "utterance_tokens", "=", "utterance_tokens", "\n", "self", ".", "_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "token_indexers", "\n", "self", ".", "_include_in_vocab", "=", "include_in_vocab", "\n", "self", ".", "_indexed_entity_texts", ":", "Dict", "[", "str", ",", "TokenList", "]", "=", "None", "\n", "self", ".", "_max_table_tokens", "=", "max_table_tokens", "\n", "\n", "feature_extractors", "=", "feature_extractors", "if", "feature_extractors", "is", "not", "None", "else", "[", "\n", "'number_token_match'", ",", "\n", "'exact_token_match'", ",", "\n", "'contains_exact_token_match'", ",", "\n", "'lemma_match'", ",", "\n", "'contains_lemma_match'", ",", "\n", "'edit_distance'", ",", "\n", "'related_column'", ",", "\n", "'related_column_lemma'", ",", "\n", "'span_overlap_fraction'", ",", "\n", "'span_lemma_overlap_fraction'", ",", "\n", "]", "\n", "self", ".", "_feature_extractors", ":", "List", "[", "Callable", "[", "[", "str", ",", "List", "[", "Token", "]", ",", "Token", ",", "int", ",", "List", "[", "Token", "]", "]", ",", "float", "]", "]", "=", "[", "]", "\n", "for", "feature_extractor_name", "in", "feature_extractors", ":", "\n", "            ", "extractor", "=", "getattr", "(", "self", ",", "'_'", "+", "feature_extractor_name", ",", "None", ")", "\n", "if", "not", "extractor", ":", "\n", "                ", "raise", "ConfigurationError", "(", "f\"Invalid feature extractor name: {feature_extractor_name}\"", ")", "\n", "", "self", ".", "_feature_extractors", ".", "append", "(", "extractor", ")", "\n", "\n", "", "if", "not", "linking_features", ":", "\n", "# For quicker lookups in our feature functions, we'll additionally store some", "\n", "# dictionaries that map entity strings to useful information about the entity.", "\n", "            ", "self", ".", "_entity_text_map", ":", "Dict", "[", "str", ",", "List", "[", "Token", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_map", "[", "entity", "]", "=", "entity_text", "\n", "\n", "", "self", ".", "_entity_text_exact_text", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_exact_text", "[", "entity", "]", "=", "set", "(", "e", ".", "text", "for", "e", "in", "entity_text", ")", "\n", "\n", "", "self", ".", "_entity_text_lemmas", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_lemmas", "[", "entity", "]", "=", "set", "(", "e", ".", "lemma_", "for", "e", "in", "entity_text", ")", "\n", "", "self", ".", "linking_features", "=", "self", ".", "_compute_linking_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linking_features", "=", "linking_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.count_vocab_items": [[152, 159], ["knowledge_graph_field.KnowledgeGraphField._token_indexers.values", "indexer.count_vocab_items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_include_in_vocab", ":", "\n", "            ", "for", "indexer", "in", "self", ".", "_token_indexers", ".", "values", "(", ")", ":", "\n", "                ", "for", "entity_text", "in", "self", ".", "entity_texts", ":", "\n", "                    ", "for", "token", "in", "entity_text", ":", "\n", "                        ", "indexer", ".", "count_vocab_items", "(", "token", ",", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.index": [[160, 171], ["knowledge_graph_field.KnowledgeGraphField._token_indexers.items", "collections.defaultdict", "knowledge_graph_field.KnowledgeGraphField._indexed_entity_texts.update", "indexer.tokens_to_indices().items", "indexer_arrays[].append", "indexer.tokens_to_indices"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.tokens_to_indices"], ["", "", "", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "self", ".", "_indexed_entity_texts", "=", "{", "}", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "indexer_arrays", ":", "Dict", "[", "str", ",", "List", "]", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "entity_text", "in", "self", ".", "entity_texts", ":", "\n", "                ", "for", "index_name", ",", "indexed", "in", "indexer", ".", "tokens_to_indices", "(", "entity_text", ",", "vocab", ",", "indexer_name", ")", ".", "items", "(", ")", ":", "\n", "                    ", "indexer_arrays", "[", "index_name", "]", ".", "append", "(", "indexed", ")", "\n", "\n", "", "", "self", ".", "_indexed_entity_texts", ".", "update", "(", "indexer_arrays", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths": [[172, 209], ["len", "max", "knowledge_graph_field.KnowledgeGraphField._token_indexers.items", "len", "entity_lengths[].keys", "lengths.append", "max", "len", "int", "indexer.get_padding_lengths", "max", "d.keys"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "num_entities", "=", "len", "(", "self", ".", "entity_texts", ")", "\n", "num_entity_tokens", "=", "max", "(", "len", "(", "entity_text", ")", "for", "entity_text", "in", "self", ".", "entity_texts", ")", "\n", "\n", "if", "self", ".", "_max_table_tokens", ":", "\n", "# This truncates the number of entity tokens used, enabling larger tables (either in", "\n", "# the number of entities in the table, or the number of tokens per entity) to fit in", "\n", "# memory, particularly when using ELMo.", "\n", "            ", "if", "num_entities", "*", "num_entity_tokens", ">", "self", ".", "_max_table_tokens", ":", "\n", "                ", "num_entity_tokens", "=", "int", "(", "self", ".", "_max_table_tokens", "/", "num_entities", ")", "\n", "\n", "", "", "padding_lengths", "=", "{", "'num_entities'", ":", "num_entities", ",", "\n", "'num_utterance_tokens'", ":", "len", "(", "self", ".", "utterance_tokens", ")", "}", "\n", "padding_lengths", "[", "'num_entity_tokens'", "]", "=", "num_entity_tokens", "\n", "lengths", "=", "[", "]", "\n", "assert", "self", ".", "_indexed_entity_texts", "is", "not", "None", ",", "(", "\"This field is not indexed yet. Call \"", "\n", "\".index(vocab) before determining padding \"", "\n", "\"lengths.\"", ")", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "indexer_lengths", "=", "{", "}", "\n", "\n", "# This is a list of dicts, one for each token in the field.", "\n", "entity_lengths", "=", "[", "indexer", ".", "get_padding_lengths", "(", "token", ")", "\n", "for", "entity_text", "in", "self", ".", "_indexed_entity_texts", "[", "indexer_name", "]", "\n", "for", "token", "in", "entity_text", "]", "\n", "# Iterate over the keys in the first element of the list.  This is fine as for a given", "\n", "# indexer, all entities will return the same keys, so we can just use the first one.", "\n", "for", "key", "in", "entity_lengths", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                ", "indexer_lengths", "[", "key", "]", "=", "max", "(", "x", "[", "key", "]", "if", "key", "in", "x", "else", "0", "for", "x", "in", "entity_lengths", ")", "\n", "", "lengths", ".", "append", "(", "indexer_lengths", ")", "\n", "\n", "# Get all the keys which have been used for padding.", "\n", "", "padding_keys", "=", "{", "key", "for", "d", "in", "lengths", "for", "key", "in", "d", ".", "keys", "(", ")", "}", "\n", "for", "padding_key", "in", "padding_keys", ":", "\n", "            ", "padding_lengths", "[", "padding_key", "]", "=", "max", "(", "x", "[", "padding_key", "]", "if", "padding_key", "in", "x", "else", "0", "for", "x", "in", "lengths", ")", "\n", "", "return", "padding_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor": [[210, 240], ["knowledge_graph_field.KnowledgeGraphField._token_indexers.items", "allennlp.common.util.pad_sequence_to_length", "torch.FloatTensor", "allennlp.common.util.pad_sequence_to_length", "torch.LongTensor", "allennlp.common.util.pad_sequence_to_length", "padded_linking_arrays.append", "padded_arrays.append", "len", "indexer.pad_token_sequence"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.pad_token_sequence"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "tensors", "=", "{", "}", "\n", "desired_num_entities", "=", "padding_lengths", "[", "'num_entities'", "]", "\n", "desired_num_entity_tokens", "=", "padding_lengths", "[", "'num_entity_tokens'", "]", "\n", "desired_num_utterance_tokens", "=", "padding_lengths", "[", "'num_utterance_tokens'", "]", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "padded_entities", "=", "util", ".", "pad_sequence_to_length", "(", "self", ".", "_indexed_entity_texts", "[", "indexer_name", "]", ",", "\n", "desired_num_entities", ",", "\n", "default_value", "=", "lambda", ":", "[", "]", ")", "\n", "padded_arrays", "=", "[", "]", "\n", "for", "padded_entity", "in", "padded_entities", ":", "\n", "                ", "padded_array", "=", "indexer", ".", "pad_token_sequence", "(", "{", "'key'", ":", "padded_entity", "}", ",", "\n", "{", "'key'", ":", "desired_num_entity_tokens", "}", ",", "\n", "padding_lengths", ")", "[", "'key'", "]", "\n", "padded_arrays", ".", "append", "(", "padded_array", ")", "\n", "", "tensor", "=", "torch", ".", "LongTensor", "(", "padded_arrays", ")", "\n", "tensors", "[", "indexer_name", "]", "=", "tensor", "\n", "", "padded_linking_features", "=", "util", ".", "pad_sequence_to_length", "(", "self", ".", "linking_features", ",", "\n", "desired_num_entities", ",", "\n", "default_value", "=", "lambda", ":", "[", "]", ")", "\n", "padded_linking_arrays", "=", "[", "]", "\n", "default_feature_value", "=", "lambda", ":", "[", "0.0", "]", "*", "len", "(", "self", ".", "_feature_extractors", ")", "\n", "for", "linking_features", "in", "padded_linking_features", ":", "\n", "            ", "padded_features", "=", "util", ".", "pad_sequence_to_length", "(", "linking_features", ",", "\n", "desired_num_utterance_tokens", ",", "\n", "default_value", "=", "default_feature_value", ")", "\n", "padded_linking_arrays", ".", "append", "(", "padded_features", ")", "\n", "", "linking_features_tensor", "=", "torch", ".", "FloatTensor", "(", "padded_linking_arrays", ")", "\n", "return", "{", "'text'", ":", "tensors", ",", "'linking'", ":", "linking_features_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._compute_linking_features": [[241, 256], ["zip", "enumerate", "linking_features.append", "entity_features.append", "token_features.append", "feature_extractor"], "methods", ["None"], ["", "def", "_compute_linking_features", "(", "self", ")", "->", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "linking_features", "=", "[", "]", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "self", ".", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "            ", "entity_features", "=", "[", "]", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "self", ".", "utterance_tokens", ")", ":", "\n", "                ", "token_features", "=", "[", "]", "\n", "for", "feature_extractor", "in", "self", ".", "_feature_extractors", ":", "\n", "                    ", "token_features", ".", "append", "(", "feature_extractor", "(", "entity", ",", "\n", "entity_text", ",", "\n", "token", ",", "\n", "token_index", ",", "\n", "self", ".", "utterance_tokens", ")", ")", "\n", "", "entity_features", ".", "append", "(", "token_features", ")", "\n", "", "linking_features", ".", "append", "(", "entity_features", ")", "\n", "", "return", "linking_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.empty_field": [[257, 260], ["knowledge_graph_field.KnowledgeGraphField", "allennlp.semparse.contexts.knowledge_graph.KnowledgeGraph", "set"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "'KnowledgeGraphField'", ":", "\n", "        ", "return", "KnowledgeGraphField", "(", "KnowledgeGraph", "(", "set", "(", ")", ",", "{", "}", ")", ",", "[", "]", ",", "self", ".", "_token_indexers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField.batch_tensors": [[261, 267], ["allennlp.nn.util.batch_tensor_dicts", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.batch_tensor_dicts"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=no-self-use", "\n", "        ", "batched_text", "=", "nn_util", ".", "batch_tensor_dicts", "(", "tensor", "[", "'text'", "]", "for", "tensor", "in", "tensor_list", ")", "# type: ignore", "\n", "batched_linking", "=", "torch", ".", "stack", "(", "[", "tensor", "[", "'linking'", "]", "for", "tensor", "in", "tensor_list", "]", ")", "\n", "return", "{", "'text'", ":", "batched_text", ",", "'linking'", ":", "batched_linking", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._number_token_match": [[291, 311], ["entity.startswith", "knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], ["", "def", "_number_token_match", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "# PNP had a \"spanFeatures\" function that said whether an entity was a-priori known to link", "\n", "# to a token or set of tokens in the question.  This was only used for numbers, and it's", "\n", "# not totally clear to me how this number feature overlapped with the token match features", "\n", "# in the original implementation (I think in most cases it was the same, except for things", "\n", "# like \"four million\", because the token match is derived from the entity name, which would", "\n", "# be 4000000, and wouldn't match \"four million\").", "\n", "#", "\n", "# Our implementation basically just adds a duplicate token match feature that's specific to", "\n", "# numbers.  It'll break in some rare cases (e.g., \"Which four had four million ...\"), but", "\n", "# those shouldn't be a big deal.", "\n", "        ", "if", "entity", ".", "startswith", "(", "'fb:'", ")", ":", "\n", "# This check works because numbers are the only entities that don't start with \"fb:\".", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_exact_token_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._exact_token_match": [[312, 321], ["knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], ["", "def", "_exact_token_match", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "len", "(", "entity_text", ")", "!=", "1", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_exact_token_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match": [[322, 331], ["None"], "methods", ["None"], ["", "def", "_contains_exact_token_match", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._lemma_match": [[332, 341], ["knowledge_graph_field.KnowledgeGraphField._contains_lemma_match", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._contains_lemma_match"], ["", "def", "_lemma_match", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "len", "(", "entity_text", ")", "!=", "1", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_lemma_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._contains_lemma_match": [[342, 353], ["None"], "methods", ["None"], ["", "def", "_contains_lemma_match", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "if", "token", ".", "lemma_", "in", "self", ".", "_entity_text_lemmas", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._edit_distance": [[354, 362], ["float", "editdistance.eval", "len"], "methods", ["None"], ["", "def", "_edit_distance", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "edit_distance", "=", "float", "(", "editdistance", ".", "eval", "(", "' '", ".", "join", "(", "e", ".", "text", "for", "e", "in", "entity_text", ")", ",", "token", ".", "text", ")", ")", "\n", "return", "1.0", "-", "edit_distance", "/", "len", "(", "token", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._related_column": [[363, 375], ["entity.startswith"], "methods", ["None"], ["", "def", "_related_column", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "not", "entity", ".", "startswith", "(", "'fb:row.row'", ")", ":", "\n", "            ", "return", "0.0", "\n", "", "for", "neighbor", "in", "self", ".", "knowledge_graph", ".", "neighbors", "[", "entity", "]", ":", "\n", "            ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._related_column_lemma": [[376, 390], ["entity.startswith"], "methods", ["None"], ["", "def", "_related_column_lemma", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "if", "not", "entity", ".", "startswith", "(", "'fb:row.row'", ")", ":", "\n", "            ", "return", "0.0", "\n", "", "for", "neighbor", "in", "self", ".", "knowledge_graph", ".", "neighbors", "[", "entity", "]", ":", "\n", "            ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "if", "token", ".", "lemma_", "in", "self", ".", "_entity_text_lemmas", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._span_overlap_fraction": [[391, 410], ["set", "set", "set.add", "set.add", "len", "len", "len"], "methods", ["None"], ["", "def", "_span_overlap_fraction", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "entity_words", "=", "set", "(", "entity_token", ".", "text", "for", "entity_token", "in", "entity_text", ")", "\n", "if", "not", "entity_words", ":", "\n", "# Some tables have empty cells.", "\n", "            ", "return", "0", "\n", "", "seen_entity_words", "=", "set", "(", ")", "\n", "token_index_left", "=", "token_index", "\n", "while", "token_index", "<", "len", "(", "tokens", ")", "and", "tokens", "[", "token_index", "]", ".", "text", "in", "entity_words", ":", "\n", "            ", "seen_entity_words", ".", "add", "(", "tokens", "[", "token_index", "]", ".", "text", ")", "\n", "token_index", "+=", "1", "\n", "", "while", "token_index_left", ">=", "0", "and", "tokens", "[", "token_index_left", "]", ".", "text", "in", "entity_words", ":", "\n", "            ", "seen_entity_words", ".", "add", "(", "tokens", "[", "token_index_left", "]", ".", "text", ")", "\n", "token_index_left", "-=", "1", "\n", "", "return", "len", "(", "seen_entity_words", ")", "/", "len", "(", "entity_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.knowledge_graph_field.KnowledgeGraphField._span_lemma_overlap_fraction": [[411, 430], ["set", "set", "set.add", "set.add", "len", "len", "len"], "methods", ["None"], ["", "def", "_span_lemma_overlap_fraction", "(", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ")", "->", "float", ":", "\n", "        ", "entity_lemmas", "=", "set", "(", "entity_token", ".", "lemma_", "for", "entity_token", "in", "entity_text", ")", "\n", "if", "not", "entity_lemmas", ":", "\n", "# Some tables have empty cells.", "\n", "            ", "return", "0", "\n", "", "seen_entity_lemmas", "=", "set", "(", ")", "\n", "token_index_left", "=", "token_index", "\n", "while", "token_index", "<", "len", "(", "tokens", ")", "and", "tokens", "[", "token_index", "]", ".", "lemma_", "in", "entity_lemmas", ":", "\n", "            ", "seen_entity_lemmas", ".", "add", "(", "tokens", "[", "token_index", "]", ".", "lemma_", ")", "\n", "token_index", "+=", "1", "\n", "", "while", "token_index_left", ">=", "0", "and", "tokens", "[", "token_index_left", "]", ".", "lemma_", "in", "entity_lemmas", ":", "\n", "            ", "seen_entity_lemmas", ".", "add", "(", "tokens", "[", "token_index_left", "]", ".", "lemma_", ")", "\n", "token_index_left", "-=", "1", "\n", "", "return", "len", "(", "seen_entity_lemmas", ")", "/", "len", "(", "entity_lemmas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.__init__": [[47, 68], ["sequence_label_field.SequenceLabelField._maybe_warn_for_namespace", "all", "stog.utils.checks.ConfigurationError", "len", "sequence_field.sequence_length", "isinstance", "all", "stog.utils.checks.ConfigurationError", "len", "sequence_field.sequence_length", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField._maybe_warn_for_namespace", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["def", "__init__", "(", "self", ",", "\n", "labels", ":", "Union", "[", "List", "[", "str", "]", ",", "List", "[", "int", "]", "]", ",", "\n", "sequence_field", ":", "SequenceField", ",", "\n", "label_namespace", ":", "str", "=", "'labels'", ",", "\n", "strip_sentence_symbols", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "labels", "=", "labels", "\n", "self", ".", "sequence_field", "=", "sequence_field", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_indexed_labels", "=", "None", "\n", "self", ".", "_maybe_warn_for_namespace", "(", "label_namespace", ")", "\n", "if", "len", "(", "labels", ")", "!=", "sequence_field", ".", "sequence_length", "(", ")", "and", "not", "strip_sentence_symbols", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"Label length and sequence length \"", "\n", "\"don't match: %d and %d\"", "%", "(", "len", "(", "labels", ")", ",", "sequence_field", ".", "sequence_length", "(", ")", ")", ")", "\n", "\n", "", "if", "all", "(", "[", "isinstance", "(", "x", ",", "int", ")", "for", "x", "in", "labels", "]", ")", ":", "\n", "            ", "self", ".", "_indexed_labels", "=", "labels", "\n", "\n", "", "elif", "not", "all", "(", "[", "isinstance", "(", "x", ",", "str", ")", "for", "x", "in", "labels", "]", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"SequenceLabelFields must be passed either all \"", "\n", "\"strings or all ints. Found labels {} with \"", "\n", "\"types: {}.\"", ".", "format", "(", "labels", ",", "[", "type", "(", "x", ")", "for", "x", "in", "labels", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField._maybe_warn_for_namespace": [[69, 78], ["sequence_label_field.SequenceLabelField._label_namespace.endswith", "sequence_label_field.SequenceLabelField._label_namespace.endswith", "logger.warning", "sequence_label_field.SequenceLabelField._already_warned_namespaces.add"], "methods", ["None"], ["", "", "def", "_maybe_warn_for_namespace", "(", "self", ",", "label_namespace", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "not", "(", "self", ".", "_label_namespace", ".", "endswith", "(", "\"labels\"", ")", "or", "self", ".", "_label_namespace", ".", "endswith", "(", "\"tags\"", ")", ")", ":", "\n", "            ", "if", "label_namespace", "not", "in", "self", ".", "_already_warned_namespaces", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Your label namespace was '%s'. We recommend you use a namespace \"", "\n", "\"ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by \"", "\n", "\"default to your vocabulary.  See documentation for \"", "\n", "\"`non_padded_namespaces` parameter in Vocabulary.\"", ",", "\n", "self", ".", "_label_namespace", ")", "\n", "self", ".", "_already_warned_namespaces", ".", "add", "(", "label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.count_vocab_items": [[79, 84], ["None"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", ":", "\n", "            ", "for", "label", "in", "self", ".", "labels", ":", "\n", "                ", "counter", "[", "self", ".", "_label_namespace", "]", "[", "label", "]", "+=", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.index": [[85, 90], ["vocab.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", ":", "\n", "            ", "self", ".", "_indexed_labels", "=", "[", "vocab", ".", "get_token_index", "(", "label", ",", "self", ".", "_label_namespace", ")", "# type: ignore", "\n", "for", "label", "in", "self", ".", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.get_padding_lengths": [[91, 94], ["sequence_label_field.SequenceLabelField.sequence_field.sequence_length"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "'num_tokens'", ":", "self", ".", "sequence_field", ".", "sequence_length", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.as_tensor": [[95, 101], ["stog.utils.string.pad_sequence_to_length", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "desired_num_tokens", "=", "padding_lengths", "[", "'num_tokens'", "]", "\n", "padded_tags", "=", "pad_sequence_to_length", "(", "self", ".", "_indexed_labels", ",", "desired_num_tokens", ")", "\n", "tensor", "=", "torch", ".", "LongTensor", "(", "padded_tags", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.empty_field": [[102, 110], ["SequenceLabelField.SequenceLabelField", "SequenceLabelField.SequenceLabelField.sequence_field.empty_field"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "'SequenceLabelField'", ":", "# pylint: disable=no-self-use", "\n", "# pylint: disable=protected-access", "\n", "# The empty_list here is needed for mypy", "\n", "        ", "empty_list", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "sequence_label_field", "=", "SequenceLabelField", "(", "empty_list", ",", "self", ".", "sequence_field", ".", "empty_field", "(", ")", ")", "\n", "sequence_label_field", ".", "_indexed_labels", "=", "empty_list", "\n", "return", "sequence_label_field", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_label_field.SequenceLabelField.__str__": [[111, 116], ["sequence_label_field.SequenceLabelField.sequence_field.sequence_length", "textwrap.wrap", "repr"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "length", "=", "self", ".", "sequence_field", ".", "sequence_length", "(", ")", "\n", "formatted_labels", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "labels", "+", "\"\\n\"", "\n", "for", "labels", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "labels", ")", ",", "100", ")", "]", ")", "\n", "return", "f\"SequenceLabelField of length {length} with \"", "f\"labels:\\n {formatted_labels} \\t\\tin namespace: '{self._label_namespace}'.\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.__init__": [[64, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "rule", ":", "str", ",", "\n", "is_global_rule", ":", "bool", ",", "\n", "vocab_namespace", ":", "str", "=", "'rule_labels'", ")", "->", "None", ":", "\n", "        ", "self", ".", "rule", "=", "rule", "\n", "self", ".", "is_global_rule", "=", "is_global_rule", "\n", "self", ".", "_vocab_namespace", "=", "vocab_namespace", "\n", "self", ".", "_rule_id", ":", "int", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.count_vocab_items": [[73, 77], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "is_global_rule", ":", "\n", "            ", "counter", "[", "self", ".", "_vocab_namespace", "]", "[", "self", ".", "rule", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.index": [[78, 82], ["vocab.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "is_global_rule", "and", "self", ".", "_rule_id", "is", "None", ":", "\n", "            ", "self", ".", "_rule_id", "=", "vocab", ".", "get_token_index", "(", "self", ".", "rule", ",", "self", ".", "_vocab_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.get_padding_lengths": [[83, 87], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "# pylint: disable=no-self-use", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.as_tensor": [[88, 96], ["torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "ProductionRuleArray", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "if", "self", ".", "is_global_rule", ":", "\n", "            ", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "_rule_id", "]", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "None", "\n", "", "return", "(", "self", ".", "rule", ",", "self", ".", "is_global_rule", ",", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.empty_field": [[97, 103], ["production_rule_field.ProductionRuleField"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "# pylint: disable=no-self-use", "\n", "# This _does_ get called, because we don't want to bother with modifying the ListField to", "\n", "# ignore padding for these.  We just make sure the rule is the empty string, which the", "\n", "# model will use to know that this rule is just padding.", "\n", "        ", "return", "ProductionRuleField", "(", "rule", "=", "''", ",", "is_global_rule", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.batch_tensors": [[104, 108], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "ProductionRuleArray", "]", ")", "->", "ProductionRuleArray", ":", "\n", "# pylint: disable=no-self-use", "\n", "        ", "return", "tensor_list", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.production_rule_field.ProductionRuleField.__str__": [[109, 111], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"ProductionRuleField with rule: {self.rule} (is_global_rule: \"", "f\"{self.is_global_rule}) in namespace: '{self._vocab_namespace}'.'\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_field.SequenceField.sequence_length": [[11, 16], ["None"], "methods", ["None"], ["def", "sequence_length", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        How many elements are there in this sequence?\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.sequence_field.SequenceField.empty_field": [[17, 19], ["None"], "methods", ["None"], ["", "def", "empty_field", "(", "self", ")", "->", "'SequenceField'", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.__init__": [[45, 64], ["label_field.LabelField._maybe_warn_for_namespace", "isinstance", "stog.utils.checks.ConfigurationError", "isinstance", "stog.utils.checks.ConfigurationError", "type"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField._maybe_warn_for_namespace"], ["def", "__init__", "(", "self", ",", "\n", "label", ":", "Union", "[", "str", ",", "int", "]", ",", "\n", "label_namespace", ":", "str", "=", "'labels'", ",", "\n", "skip_indexing", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_label_id", "=", "None", "\n", "self", ".", "_maybe_warn_for_namespace", "(", "label_namespace", ")", "\n", "\n", "if", "skip_indexing", ":", "\n", "            ", "if", "not", "isinstance", "(", "label", ",", "int", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"In order to skip indexing, your labels must be integers. \"", "\n", "\"Found label = {}\"", ".", "format", "(", "label", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_label_id", "=", "label", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "label", ",", "str", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"LabelFields must be passed a string label if skip_indexing=False. \"", "\n", "\"Found label: {} with type: {}.\"", ".", "format", "(", "label", ",", "type", "(", "label", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField._maybe_warn_for_namespace": [[65, 74], ["label_field.LabelField._label_namespace.endswith", "label_field.LabelField._label_namespace.endswith", "logger.warning", "label_field.LabelField._already_warned_namespaces.add"], "methods", ["None"], ["", "", "", "def", "_maybe_warn_for_namespace", "(", "self", ",", "label_namespace", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "not", "(", "self", ".", "_label_namespace", ".", "endswith", "(", "\"labels\"", ")", "or", "self", ".", "_label_namespace", ".", "endswith", "(", "\"tags\"", ")", ")", ":", "\n", "            ", "if", "label_namespace", "not", "in", "self", ".", "_already_warned_namespaces", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Your label namespace was '%s'. We recommend you use a namespace \"", "\n", "\"ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by \"", "\n", "\"default to your vocabulary.  See documentation for \"", "\n", "\"`non_padded_namespaces` parameter in Vocabulary.\"", ",", "\n", "self", ".", "_label_namespace", ")", "\n", "self", ".", "_already_warned_namespaces", ".", "add", "(", "label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.count_vocab_items": [[75, 79], ["None"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_label_id", "is", "None", ":", "\n", "            ", "counter", "[", "self", ".", "_label_namespace", "]", "[", "self", ".", "label", "]", "+=", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.index": [[80, 84], ["vocab.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "_label_id", "is", "None", ":", "\n", "            ", "self", ".", "_label_id", "=", "vocab", ".", "get_token_index", "(", "self", ".", "label", ",", "self", ".", "_label_namespace", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.get_padding_lengths": [[85, 88], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=no-self-use", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.as_tensor": [[89, 94], ["torch.tensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=unused-argument,not-callable", "\n", "        ", "tensor", "=", "torch", ".", "tensor", "(", "self", ".", "_label_id", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.empty_field": [[95, 98], ["label_field.LabelField"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "        ", "return", "LabelField", "(", "-", "1", ",", "self", ".", "_label_namespace", ",", "skip_indexing", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.label_field.LabelField.__str__": [[99, 101], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"LabelField with label: {self.label} in namespace: '{self._label_namespace}'.'\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.array_field.ArrayField.__init__": [[16, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "array", ":", "numpy", ".", "ndarray", ",", "padding_value", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "self", ".", "array", "=", "array", "\n", "self", ".", "padding_value", "=", "padding_value", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.array_field.ArrayField.get_padding_lengths": [[20, 24], ["str", "enumerate"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "\"dimension_\"", "+", "str", "(", "i", ")", ":", "shape", "\n", "for", "i", ",", "shape", "in", "enumerate", "(", "self", ".", "array", ".", "shape", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.array_field.ArrayField.as_tensor": [[25, 41], ["list", "tuple", "torch.from_numpy", "numpy.ones", "len", "len", "range", "slice", "len", "range", "len", "len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "max_shape", "=", "[", "padding_lengths", "[", "\"dimension_{}\"", ".", "format", "(", "i", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "padding_lengths", ")", ")", "]", "\n", "\n", "return_array", "=", "numpy", ".", "ones", "(", "max_shape", ",", "\"float32\"", ")", "*", "self", ".", "padding_value", "\n", "\n", "# If the tensor has a different shape from the largest tensor, pad dimensions with zeros to", "\n", "# form the right shaped list of slices for insertion into the final tensor.", "\n", "slicing_shape", "=", "list", "(", "self", ".", "array", ".", "shape", ")", "\n", "if", "len", "(", "self", ".", "array", ".", "shape", ")", "<", "len", "(", "max_shape", ")", ":", "\n", "            ", "slicing_shape", "=", "slicing_shape", "+", "[", "0", "for", "_", "in", "range", "(", "len", "(", "max_shape", ")", "-", "len", "(", "self", ".", "array", ".", "shape", ")", ")", "]", "\n", "", "slices", "=", "tuple", "(", "[", "slice", "(", "0", ",", "x", ")", "for", "x", "in", "slicing_shape", "]", ")", "\n", "return_array", "[", "slices", "]", "=", "self", ".", "array", "\n", "tensor", "=", "torch", ".", "from_numpy", "(", "return_array", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.array_field.ArrayField.empty_field": [[42, 47], ["array_field.ArrayField", "numpy.array"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "# pylint: disable=no-self-use", "\n", "# Pass the padding_value, so that any outer field, e.g., `ListField[ArrayField]` uses the", "\n", "# same padding_value in the padded ArrayFields", "\n", "        ", "return", "ArrayField", "(", "numpy", ".", "array", "(", "[", "]", ",", "dtype", "=", "\"float32\"", ")", ",", "padding_value", "=", "self", ".", "padding_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.array_field.ArrayField.__str__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"ArrayField with shape: {self.array.shape}.\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.__init__": [[52, 79], ["multilabel_field.MultiLabelField._maybe_warn_for_namespace", "all", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "all", "allennlp.common.checks.ConfigurationError", "all", "allennlp.common.checks.ConfigurationError", "isinstance", "isinstance", "typing.cast"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField._maybe_warn_for_namespace"], ["def", "__init__", "(", "self", ",", "\n", "labels", ":", "Sequence", "[", "Union", "[", "str", ",", "int", "]", "]", ",", "\n", "label_namespace", ":", "str", "=", "'labels'", ",", "\n", "skip_indexing", ":", "bool", "=", "False", ",", "\n", "num_labels", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "labels", "=", "labels", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_label_ids", "=", "None", "\n", "self", ".", "_maybe_warn_for_namespace", "(", "label_namespace", ")", "\n", "self", ".", "_num_labels", "=", "num_labels", "\n", "\n", "if", "skip_indexing", ":", "\n", "            ", "if", "not", "all", "(", "isinstance", "(", "label", ",", "int", ")", "for", "label", "in", "labels", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"In order to skip indexing, your labels must be integers. \"", "\n", "\"Found labels = {}\"", ".", "format", "(", "labels", ")", ")", "\n", "", "if", "not", "num_labels", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"In order to skip indexing, num_labels can't be None.\"", ")", "\n", "\n", "", "if", "not", "all", "(", "cast", "(", "int", ",", "label", ")", "<", "num_labels", "for", "label", "in", "labels", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"All labels should be < num_labels. \"", "\n", "\"Found num_labels = {} and labels = {} \"", ".", "format", "(", "num_labels", ",", "labels", ")", ")", "\n", "\n", "", "self", ".", "_label_ids", "=", "labels", "\n", "", "else", ":", "\n", "            ", "if", "not", "all", "(", "isinstance", "(", "label", ",", "str", ")", "for", "label", "in", "labels", ")", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"MultiLabelFields expects string labels if skip_indexing=False. \"", "\n", "\"Found labels: {}\"", ".", "format", "(", "labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField._maybe_warn_for_namespace": [[80, 89], ["label_namespace.endswith", "label_namespace.endswith", "logger.warning", "multilabel_field.MultiLabelField._already_warned_namespaces.add"], "methods", ["None"], ["", "", "", "def", "_maybe_warn_for_namespace", "(", "self", ",", "label_namespace", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "not", "(", "label_namespace", ".", "endswith", "(", "\"labels\"", ")", "or", "label_namespace", ".", "endswith", "(", "\"tags\"", ")", ")", ":", "\n", "            ", "if", "label_namespace", "not", "in", "self", ".", "_already_warned_namespaces", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Your label namespace was '%s'. We recommend you use a namespace \"", "\n", "\"ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by \"", "\n", "\"default to your vocabulary.  See documentation for \"", "\n", "\"`non_padded_namespaces` parameter in Vocabulary.\"", ",", "\n", "self", ".", "_label_namespace", ")", "\n", "self", ".", "_already_warned_namespaces", ".", "add", "(", "label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.count_vocab_items": [[90, 95], ["None"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_label_ids", "is", "None", ":", "\n", "            ", "for", "label", "in", "self", ".", "labels", ":", "\n", "                ", "counter", "[", "self", ".", "_label_namespace", "]", "[", "label", "]", "+=", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.index": [[96, 103], ["vocab.get_vocab_size", "vocab.get_token_index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_vocab_size", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.get_token_index"], ["", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "_label_ids", "is", "None", ":", "\n", "            ", "self", ".", "_label_ids", "=", "[", "vocab", ".", "get_token_index", "(", "label", ",", "self", ".", "_label_namespace", ")", "# type: ignore", "\n", "for", "label", "in", "self", ".", "labels", "]", "\n", "", "if", "not", "self", ".", "_num_labels", ":", "\n", "            ", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "self", ".", "_label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.get_padding_lengths": [[104, 107], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=no-self-use", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.as_tensor": [[108, 117], ["torch.zeros", "torch.zeros.scatter_", "torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=unused-argument", "\n", "\n", "        ", "tensor", "=", "torch", ".", "zeros", "(", "self", ".", "_num_labels", ")", "# vector of zeros", "\n", "if", "self", ".", "_label_ids", ":", "\n", "            ", "tensor", ".", "scatter_", "(", "0", ",", "torch", ".", "LongTensor", "(", "self", ".", "_label_ids", ")", ",", "1", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.empty_field": [[118, 121], ["multilabel_field.MultiLabelField"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "        ", "return", "MultiLabelField", "(", "[", "]", ",", "self", ".", "_label_namespace", ",", "skip_indexing", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.multilabel_field.MultiLabelField.__str__": [[122, 124], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"MultiLabelField with labels: {self.labels} in namespace: '{self._label_namespace}'.'\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.count_vocab_items": [[25, 49], ["None"], "methods", ["None"], ["def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        If there are strings in this field that need to be converted into integers through a\n        :class:`Vocabulary`, here is where we count them, to determine which tokens are in or out\n        of the vocabulary.\n\n        If your ``Field`` does not have any strings that need to be converted into indices, you do\n        not need to implement this method.\n\n        A note on this ``counter``: because ``Fields`` can represent conceptually different things,\n        we separate the vocabulary items by `namespaces`.  This way, we can use a single shared\n        mechanism to handle all mappings from strings to integers in all fields, while keeping\n        words in a ``TextField`` from sharing the same ids with labels in a ``LabelField`` (e.g.,\n        \"entailment\" or \"contradiction\" are labels in an entailment task)\n\n        Additionally, a single ``Field`` might want to use multiple namespaces - ``TextFields`` can\n        be represented as a combination of word ids and character ids, and you don't want words and\n        characters to share the same vocabulary - \"a\" as a word should get a different id from \"a\"\n        as a character, and the vocabulary sizes of words and characters are very different.\n\n        Because of this, the first key in the ``counter`` object is a `namespace`, like \"tokens\",\n        \"token_characters\", \"tags\", or \"labels\", and the second key is the actual vocabulary item.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.index": [[50, 59], ["None"], "methods", ["None"], ["", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "\"\"\"\n        Given a :class:`Vocabulary`, converts all strings in this field into (typically) integers.\n        This `modifies` the ``Field`` object, it does not return anything.\n\n        If your ``Field`` does not have any strings that need to be converted into indices, you do\n        not need to implement this method.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.get_padding_lengths": [[60, 70], ["None"], "methods", ["None"], ["", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        If there are things in this field that need padding, note them here.  In order to pad a\n        batch of instance, we get all of the lengths from the batch, take the max, and pad\n        everything to that length (or use a pre-specified maximum length).  The return value is a\n        dictionary mapping keys to lengths, like {'num_tokens': 13}.\n\n        This is always called after :func:`index`.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.as_tensor": [[71, 85], ["None"], "methods", ["None"], ["", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "DataArray", ":", "\n", "        ", "\"\"\"\n        Given a set of specified padding lengths, actually pad the data in this field and return a\n        torch Tensor (or a more complex data structure) of the correct shape.  We also take a\n        couple of parameters that are important when constructing torch Tensors.\n\n        Parameters\n        ----------\n        padding_lengths : ``Dict[str, int]``\n            This dictionary will have the same keys that were produced in\n            :func:`get_padding_lengths`.  The values specify the lengths to use when padding each\n            relevant dimension, aggregated across all instances in a batch.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.empty_field": [[86, 98], ["None"], "methods", ["None"], ["", "def", "empty_field", "(", "self", ")", "->", "'Field'", ":", "\n", "        ", "\"\"\"\n        So that ``ListField`` can pad the number of fields in a list (e.g., the number of answer\n        option ``TextFields``), we need a representation of an empty field of each type.  This\n        returns that.  This will only ever be called when we're to the point of calling\n        :func:`as_tensor`, so you don't need to worry about ``get_padding_lengths``,\n        ``count_vocab_items``, etc., being called on this empty field.\n\n        We make this an instance method instead of a static method so that if there is any state\n        in the Field, we can copy it over (e.g., the token indexers in ``TextField``).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.field.Field.batch_tensors": [[99, 112], ["torch.stack"], "methods", ["None"], ["", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "DataArray", "]", ")", "->", "DataArray", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        Takes the output of ``Field.as_tensor()`` from a list of ``Instances`` and merges it into\n        one batched tensor for this ``Field``.  The default implementation here in the base class\n        handles cases where ``as_tensor`` returns a single torch tensor per instance.  If your\n        subclass returns something other than this, you need to override this method.\n\n        This operation does not modify ``self``, but in some cases we need the information\n        contained in ``self`` in order to perform the batching, so this is an instance method, not\n        a class method.\n        \"\"\"", "\n", "# pylint: disable=no-self-use", "\n", "return", "torch", ".", "stack", "(", "tensor_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.__init__": [[27, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metadata", ":", "Any", ")", "->", "None", ":", "\n", "        ", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.get_padding_lengths": [[30, 33], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.as_tensor": [[34, 38], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "DataArray", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "return", "self", ".", "metadata", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.empty_field": [[39, 42], ["metadata_field.MetadataField"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "'MetadataField'", ":", "\n", "        ", "return", "MetadataField", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.batch_tensors": [[43, 47], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "@", "overrides", "\n", "def", "batch_tensors", "(", "cls", ",", "tensor_list", ":", "List", "[", "DataArray", "]", ")", "->", "DataArray", ":", "# type: ignore", "\n", "        ", "return", "tensor_list", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.metadata_field.MetadataField.__str__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"MetadataField (print field.metadata to see specific information).\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.__init__": [[27, 33], ["set", "len", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "field_list", ":", "List", "[", "Field", "]", ")", "->", "None", ":", "\n", "        ", "field_class_set", "=", "set", "(", "[", "field", ".", "__class__", "for", "field", "in", "field_list", "]", ")", "\n", "assert", "len", "(", "field_class_set", ")", "==", "1", ",", "\"ListFields must contain a single field type, found \"", "+", "str", "(", "field_class_set", ")", "\n", "# Not sure why mypy has a hard time with this type...", "\n", "self", ".", "field_list", ":", "List", "[", "Field", "]", "=", "field_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.count_vocab_items": [[34, 38], ["field.count_vocab_items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "for", "field", "in", "self", ".", "field_list", ":", "\n", "            ", "field", ".", "count_vocab_items", "(", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.index": [[39, 43], ["field.index"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index"], ["", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "for", "field", "in", "self", ".", "field_list", ":", "\n", "            ", "field", ".", "index", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.get_padding_lengths": [[44, 62], ["set", "field.get_padding_lengths", "len", "max", "list", "field_length.keys"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "field_lengths", "=", "[", "field", ".", "get_padding_lengths", "(", ")", "for", "field", "in", "self", ".", "field_list", "]", "\n", "padding_lengths", "=", "{", "'num_fields'", ":", "len", "(", "self", ".", "field_list", ")", "}", "\n", "\n", "# We take the set of all possible padding keys for all fields, rather", "\n", "# than just a random key, because it is possible for fields to be empty", "\n", "# when we pad ListFields.", "\n", "possible_padding_keys", "=", "[", "key", "for", "field_length", "in", "field_lengths", "\n", "for", "key", "in", "list", "(", "field_length", ".", "keys", "(", ")", ")", "]", "\n", "\n", "for", "key", "in", "set", "(", "possible_padding_keys", ")", ":", "\n", "# In order to be able to nest ListFields, we need to scope the padding length keys", "\n", "# appropriately, so that nested ListFields don't all use the same \"num_fields\" key.  So", "\n", "# when we construct the dictionary from the list of fields, we add something to the", "\n", "# name, and we remove it when padding the list of fields.", "\n", "            ", "padding_lengths", "[", "'list_'", "+", "key", "]", "=", "max", "(", "x", "[", "key", "]", "if", "key", "in", "x", "else", "0", "for", "x", "in", "field_lengths", ")", "\n", "", "return", "padding_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.sequence_length": [[63, 66], ["len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "sequence_length", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "field_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.as_tensor": [[67, 80], ["stog.utils.string.pad_sequence_to_length", "list_field.ListField.field_list[].batch_tensors", "key.replace", "field.as_tensor", "padding_lengths.items", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.string.pad_sequence_to_length", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.batch_tensors", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.as_tensor", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "DataArray", ":", "\n", "        ", "padded_field_list", "=", "pad_sequence_to_length", "(", "self", ".", "field_list", ",", "\n", "padding_lengths", "[", "'num_fields'", "]", ",", "\n", "self", ".", "field_list", "[", "0", "]", ".", "empty_field", ")", "\n", "# Here we're removing the scoping on the padding length keys that we added in", "\n", "# `get_padding_lengths`; see the note there for more detail.", "\n", "child_padding_lengths", "=", "{", "key", ".", "replace", "(", "'list_'", ",", "''", ",", "1", ")", ":", "value", "\n", "for", "key", ",", "value", "in", "padding_lengths", ".", "items", "(", ")", "\n", "if", "key", ".", "startswith", "(", "'list_'", ")", "}", "\n", "padded_fields", "=", "[", "field", ".", "as_tensor", "(", "child_padding_lengths", ")", "\n", "for", "field", "in", "padded_field_list", "]", "\n", "return", "self", ".", "field_list", "[", "0", "]", ".", "batch_tensors", "(", "padded_fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.empty_field": [[81, 91], ["list_field.ListField", "list_field.ListField.field_list[].empty_field"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "# Our \"empty\" list field will actually have a single field in the list, so that we can", "\n", "# correctly construct nested lists.  For example, if we have a type that is", "\n", "# `ListField[ListField[LabelField]]`, we need the top-level `ListField` to know to", "\n", "# construct a `ListField[LabelField]` when it's padding, and the nested `ListField` needs", "\n", "# to know that it's empty objects are `LabelFields`.  Having an \"empty\" list actually have", "\n", "# length one makes this all work out, and we'll always be padding to at least length 1,", "\n", "# anyway.", "\n", "        ", "return", "ListField", "(", "[", "self", ".", "field_list", "[", "0", "]", ".", "empty_field", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.batch_tensors": [[92, 96], ["list_field.ListField.field_list[].batch_tensors"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.batch_tensors"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "DataArray", "]", ")", "->", "DataArray", ":", "\n", "# We defer to the class we're wrapping in a list to handle the batching.", "\n", "        ", "return", "self", ".", "field_list", "[", "0", "]", ".", "batch_tensors", "(", "tensor_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.list_field.ListField.__str__": [[97, 101], ["len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "field_class", "=", "self", ".", "field_list", "[", "0", "]", ".", "__class__", ".", "__name__", "\n", "base_string", "=", "f\"ListField of {len(self.field_list)} {field_class}s : \\n\"", "\n", "return", "\" \"", ".", "join", "(", "[", "base_string", "]", "+", "[", "f\"\\t {field} \\n\"", "for", "field", "in", "self", ".", "field_list", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.index_field.IndexField.__init__": [[29, 36], ["isinstance", "allennlp.common.checks.ConfigurationError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index", ":", "int", ",", "sequence_field", ":", "SequenceField", ")", "->", "None", ":", "\n", "        ", "self", ".", "sequence_index", "=", "index", "\n", "self", ".", "sequence_field", "=", "sequence_field", "\n", "\n", "if", "not", "isinstance", "(", "index", ",", "int", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"IndexFields must be passed integer indices. \"", "\n", "\"Found index: {} with type: {}.\"", ".", "format", "(", "index", ",", "type", "(", "index", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.index_field.IndexField.get_padding_lengths": [[37, 41], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "# pylint: disable=no-self-use", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.index_field.IndexField.as_tensor": [[42, 47], ["torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "sequence_index", "]", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.index_field.IndexField.empty_field": [[48, 51], ["index_field.IndexField", "index_field.IndexField.sequence_field.empty_field"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "        ", "return", "IndexField", "(", "-", "1", ",", "self", ".", "sequence_field", ".", "empty_field", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.index_field.IndexField.__str__": [[52, 54], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"IndexField with index: {self.sequence_index}.\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.span_field.SpanField.__init__": [[27, 42], ["TypeError", "ValueError", "ValueError", "isinstance", "isinstance", "span_field.SpanField.sequence_field.sequence_length", "type", "type", "span_field.SpanField.sequence_field.sequence_length"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["def", "__init__", "(", "self", ",", "span_start", ":", "int", ",", "span_end", ":", "int", ",", "sequence_field", ":", "SequenceField", ")", "->", "None", ":", "\n", "        ", "self", ".", "span_start", "=", "span_start", "\n", "self", ".", "span_end", "=", "span_end", "\n", "self", ".", "sequence_field", "=", "sequence_field", "\n", "\n", "if", "not", "isinstance", "(", "span_start", ",", "int", ")", "or", "not", "isinstance", "(", "span_end", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f\"SpanFields must be passed integer indices. Found span indices: \"", "\n", "f\"({span_start}, {span_end}) with types \"", "\n", "f\"({type(span_start)} {type(span_end)})\"", ")", "\n", "", "if", "span_start", ">", "span_end", ":", "\n", "            ", "raise", "ValueError", "(", "f\"span_start must be less than span_end, \"", "\n", "f\"but found ({span_start}, {span_end}).\"", ")", "\n", "\n", "", "if", "span_end", ">", "self", ".", "sequence_field", ".", "sequence_length", "(", ")", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"span_end must be < len(sequence_length) - 1, but found \"", "\n", "f\"{span_end} and {self.sequence_field.sequence_length() - 1} respectively.\"", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.span_field.SpanField.get_padding_lengths": [[44, 48], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "# pylint: disable=no-self-use", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.span_field.SpanField.as_tensor": [[49, 54], ["torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "span_start", ",", "self", ".", "span_end", "]", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.span_field.SpanField.empty_field": [[55, 58], ["span_field.SpanField", "span_field.SpanField.sequence_field.empty_field"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "        ", "return", "SpanField", "(", "-", "1", ",", "-", "1", ",", "self", ".", "sequence_field", ".", "empty_field", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.span_field.SpanField.__str__": [[59, 61], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"SpanField with spans: ({self.span_start}, {self.span_end}).\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.__init__": [[37, 46], ["all", "stog.utils.checks.ConfigurationError", "isinstance", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokens", ":", "List", "[", "Token", "]", ",", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "_indexed_tokens", ":", "Optional", "[", "Dict", "[", "str", ",", "TokenList", "]", "]", "=", "None", "\n", "self", ".", "_indexer_name_to_indexed_token", ":", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "]", "=", "None", "\n", "\n", "if", "not", "all", "(", "[", "isinstance", "(", "x", ",", "(", "Token", ",", "SpacyToken", ")", ")", "for", "x", "in", "tokens", "]", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"TextFields must be passed Tokens. \"", "\n", "\"Found: {} with types {}.\"", ".", "format", "(", "tokens", ",", "[", "type", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items": [[47, 52], ["text_field.TextField._token_indexers.values", "indexer.count_vocab_items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.count_vocab_items"], ["", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "for", "indexer", "in", "self", ".", "_token_indexers", ".", "values", "(", ")", ":", "\n", "            ", "for", "token", "in", "self", ".", "tokens", ":", "\n", "                ", "indexer", ".", "count_vocab_items", "(", "token", ",", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.index": [[53, 63], ["text_field.TextField._token_indexers.items", "indexer.tokens_to_indices", "token_arrays.update", "list", "indexer.tokens_to_indices.keys"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.tokens_to_indices", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update"], ["", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "token_arrays", ":", "Dict", "[", "str", ",", "TokenList", "]", "=", "{", "}", "\n", "indexer_name_to_indexed_token", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "{", "}", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "token_indices", "=", "indexer", ".", "tokens_to_indices", "(", "self", ".", "tokens", ",", "vocab", ",", "indexer_name", ")", "\n", "token_arrays", ".", "update", "(", "token_indices", ")", "\n", "indexer_name_to_indexed_token", "[", "indexer_name", "]", "=", "list", "(", "token_indices", ".", "keys", "(", ")", ")", "\n", "", "self", ".", "_indexed_tokens", "=", "token_arrays", "\n", "self", ".", "_indexer_name_to_indexed_token", "=", "indexer_name_to_indexed_token", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths": [[64, 115], ["text_field.TextField._token_indexers.items", "stog.utils.checks.ConfigurationError", "lengths.append", "len", "len", "max", "max", "text_field.TextField._indexed_tokens.items", "set", "d.keys", "indexer.get_padding_lengths", "indexer_sequence_lengths.values", "list", "indexer_sequence_lengths.values"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.get_padding_lengths"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        The ``TextField`` has a list of ``Tokens``, and each ``Token`` gets converted into arrays by\n        (potentially) several ``TokenIndexers``.  This method gets the max length (over tokens)\n        associated with each of these arrays.\n        \"\"\"", "\n", "# Our basic outline: we will iterate over `TokenIndexers`, and aggregate lengths over tokens", "\n", "# for each indexer separately.  Then we will combine the results for each indexer into a single", "\n", "# dictionary, resolving any (unlikely) key conflicts by taking a max.", "\n", "lengths", "=", "[", "]", "\n", "if", "self", ".", "_indexed_tokens", "is", "None", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"You must call .index(vocabulary) on a \"", "\n", "\"field before determining padding lengths.\"", ")", "\n", "\n", "# Each indexer can return a different sequence length, and for indexers that return", "\n", "# multiple arrays each can have a different length.  We'll keep track of them here.", "\n", "", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "indexer_lengths", "=", "{", "}", "\n", "\n", "for", "indexed_tokens_key", "in", "self", ".", "_indexer_name_to_indexed_token", "[", "indexer_name", "]", ":", "\n", "# This is a list of dicts, one for each token in the field.", "\n", "                ", "token_lengths", "=", "[", "indexer", ".", "get_padding_lengths", "(", "token", ")", "\n", "for", "token", "in", "self", ".", "_indexed_tokens", "[", "indexed_tokens_key", "]", "]", "\n", "", "if", "not", "token_lengths", ":", "\n", "# This is a padding edge case and occurs when we want to pad a ListField of", "\n", "# TextFields. In order to pad the list field, we need to be able to have an", "\n", "# _empty_ TextField, but if this is the case, token_lengths will be an empty", "\n", "# list, so we add the default empty padding dictionary to the list instead.", "\n", "                ", "token_lengths", "=", "[", "{", "}", "]", "\n", "# Iterate over the keys and find the maximum token length.", "\n", "# It's fine to iterate over the keys of the first token since all tokens have the same keys.", "\n", "", "for", "key", "in", "token_lengths", "[", "0", "]", ":", "\n", "                ", "indexer_lengths", "[", "key", "]", "=", "max", "(", "x", "[", "key", "]", "if", "key", "in", "x", "else", "0", "for", "x", "in", "token_lengths", ")", "\n", "", "lengths", ".", "append", "(", "indexer_lengths", ")", "\n", "\n", "", "indexer_sequence_lengths", "=", "{", "key", ":", "len", "(", "val", ")", "for", "key", ",", "val", "in", "self", ".", "_indexed_tokens", ".", "items", "(", ")", "}", "\n", "# Get the padding lengths for sequence lengths.", "\n", "if", "len", "(", "set", "(", "indexer_sequence_lengths", ".", "values", "(", ")", ")", ")", "==", "1", ":", "\n", "# This is the default case where all indexers return the same length.", "\n", "# Keep the existing 'num_tokens' key for backward compatibility with existing config files.", "\n", "            ", "padding_lengths", "=", "{", "'num_tokens'", ":", "list", "(", "indexer_sequence_lengths", ".", "values", "(", ")", ")", "[", "0", "]", "}", "\n", "", "else", ":", "\n", "# The indexers return different lengths.", "\n", "            ", "padding_lengths", "=", "indexer_sequence_lengths", "\n", "\n", "# Get all keys which have been used for padding for each indexer and take the max if there are duplicates.", "\n", "", "padding_keys", "=", "{", "key", "for", "d", "in", "lengths", "for", "key", "in", "d", ".", "keys", "(", ")", "}", "\n", "for", "padding_key", "in", "padding_keys", ":", "\n", "            ", "padding_lengths", "[", "padding_key", "]", "=", "max", "(", "x", "[", "padding_key", "]", "if", "padding_key", "in", "x", "else", "0", "for", "x", "in", "lengths", ")", "\n", "", "return", "padding_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length": [[116, 119], ["len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "sequence_length", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.as_tensor": [[120, 149], ["padding_lengths.get", "text_field.TextField._token_indexers.items", "indexer.pad_token_sequence", "tensors.update", "torch.LongTensor", "indexer.pad_token_sequence.items"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_characters_indexer.TokenCharactersIndexer.pad_token_sequence", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "tensors", "=", "{", "}", "\n", "num_tokens", "=", "padding_lengths", ".", "get", "(", "'num_tokens'", ")", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "if", "num_tokens", "is", "None", ":", "\n", "# The indexers return different lengths.", "\n", "# Get the desired_num_tokens for this indexer.", "\n", "                ", "desired_num_tokens", "=", "{", "\n", "indexed_tokens_key", ":", "padding_lengths", "[", "indexed_tokens_key", "]", "\n", "for", "indexed_tokens_key", "in", "self", ".", "_indexer_name_to_indexed_token", "[", "indexer_name", "]", "\n", "}", "\n", "", "else", ":", "\n", "                ", "desired_num_tokens", "=", "{", "indexer_name", ":", "num_tokens", "}", "\n", "\n", "", "indices_to_pad", "=", "{", "indexed_tokens_key", ":", "self", ".", "_indexed_tokens", "[", "indexed_tokens_key", "]", "\n", "for", "indexed_tokens_key", "in", "self", ".", "_indexer_name_to_indexed_token", "[", "indexer_name", "]", "}", "\n", "padded_array", "=", "indexer", ".", "pad_token_sequence", "(", "indices_to_pad", ",", "\n", "desired_num_tokens", ",", "padding_lengths", ")", "\n", "# We use the key of the indexer to recognise what the tensor corresponds to within the", "\n", "# field (i.e. the result of word indexing, or the result of character indexing, for", "\n", "# example).", "\n", "# TODO(mattg): we might someday have a TokenIndexer that needs to use something other", "\n", "# than a LongTensor here, and it's not clear how to signal that.  Maybe we'll need to", "\n", "# add a class method to TokenIndexer to tell us the type?  But we can worry about that", "\n", "# when there's a compelling use case for it.", "\n", "indexer_tensors", "=", "{", "key", ":", "torch", ".", "LongTensor", "(", "array", ")", "for", "key", ",", "array", "in", "padded_array", ".", "items", "(", ")", "}", "\n", "tensors", ".", "update", "(", "indexer_tensors", ")", "\n", "", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.empty_field": [[150, 162], ["TextField.TextField", "TextField.TextField._token_indexers.items", "indexer.get_keys"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.token_indexers.token_indexer.TokenIndexer.get_keys"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "text_field", "=", "TextField", "(", "[", "]", ",", "self", ".", "_token_indexers", ")", "\n", "text_field", ".", "_indexed_tokens", "=", "{", "}", "\n", "text_field", ".", "_indexer_name_to_indexed_token", "=", "{", "}", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "array_keys", "=", "indexer", ".", "get_keys", "(", "indexer_name", ")", "\n", "for", "key", "in", "array_keys", ":", "\n", "                ", "text_field", ".", "_indexed_tokens", "[", "key", "]", "=", "[", "]", "\n", "", "text_field", ".", "_indexer_name_to_indexed_token", "[", "indexer_name", "]", "=", "array_keys", "\n", "", "return", "text_field", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.batch_tensors": [[163, 169], ["stog.utils.nn.batch_tensor_dicts"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.nn.batch_tensor_dicts"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=no-self-use", "\n", "# This is creating a dict of {token_indexer_key: batch_tensor} for each token indexer used", "\n", "# to index this field.", "\n", "        ", "return", "batch_tensor_dicts", "(", "tensor_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.__str__": [[170, 177], ["text_field.TextField._token_indexers.items", "text_field.TextField.sequence_length", "textwrap.wrap", "repr"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.fields.text_field.TextField.sequence_length"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "indexers", "=", "{", "name", ":", "indexer", ".", "__class__", ".", "__name__", "for", "name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", "}", "\n", "\n", "# Double tab to indent under the header.", "\n", "formatted_text", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "text", "+", "\"\\n\"", "\n", "for", "text", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "tokens", ")", ",", "100", ")", "]", ")", "\n", "return", "f\"TextField of length {self.sequence_length()} with \"", "f\"text: \\n {formatted_text} \\t\\tand TokenIndexers : {indexers}\"", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict.Predict.add_subparser": [[57, 91], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_mutually_exclusive_group", "parser.add_parser.add_mutually_exclusive_group.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_mutually_exclusive_group", "parser.add_parser.add_mutually_exclusive_group.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "methods", ["None"], ["    ", "def", "add_subparser", "(", "self", ",", "name", ":", "str", ",", "parser", ":", "argparse", ".", "_SubParsersAction", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "description", "=", "'''Run the specified model against a JSON-lines input file.'''", "\n", "subparser", "=", "parser", ".", "add_parser", "(", "\n", "name", ",", "description", "=", "description", ",", "help", "=", "'Use a trained model to make predictions.'", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "'--archive-file'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "'the archived model to make predictions with'", ")", "\n", "subparser", ".", "add_argument", "(", "'--input-file'", ",", "type", "=", "str", ",", "help", "=", "'path to input file'", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "'--output-file'", ",", "type", "=", "str", ",", "help", "=", "'path to output file'", ")", "\n", "subparser", ".", "add_argument", "(", "'--weights-file'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'a path that overrides which weights file to use'", ")", "\n", "\n", "batch_size", "=", "subparser", ".", "add_mutually_exclusive_group", "(", "required", "=", "False", ")", "\n", "batch_size", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'The batch size to use for processing'", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "'--silent'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not print output to stdout'", ")", "\n", "\n", "cuda_device", "=", "subparser", ".", "add_mutually_exclusive_group", "(", "required", "=", "False", ")", "\n", "cuda_device", ".", "add_argument", "(", "'--cuda-device'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'id of GPU to use (if any)'", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "'--use-dataset-reader'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to use the dataset reader of the original model to load Instances'", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "'-o'", ",", "'--overrides'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "'a JSON structure used to override the experiment configuration'", ")", "\n", "\n", "subparser", ".", "set_defaults", "(", "func", "=", "_predict", ")", "\n", "\n", "return", "subparser", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager.__init__": [[105, 132], ["open", "type", "predict._PredictManager._predictor._model.set_beam_size", "predict._PredictManager._predictor._model.set_decoder_token_indexers"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.set_beam_size", "home.repos.pwc.inspect_result.jcyk_gtos.models.stog.STOG.set_decoder_token_indexers"], ["    ", "def", "__init__", "(", "self", ",", "\n", "predictor", ":", "Predictor", ",", "\n", "input_file", ":", "str", ",", "\n", "output_file", ":", "Optional", "[", "str", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "print_to_console", ":", "bool", ",", "\n", "has_dataset_reader", ":", "bool", ",", "\n", "beam_size", ":", "int", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "_predictor", "=", "predictor", "\n", "self", ".", "_input_file", "=", "input_file", "\n", "if", "output_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_file", "=", "open", "(", "output_file", ",", "\"w\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_output_file", "=", "None", "\n", "", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_print_to_console", "=", "print_to_console", "\n", "if", "has_dataset_reader", ":", "\n", "            ", "self", ".", "_dataset_reader", "=", "predictor", ".", "_dataset_reader", "# pylint: disable=protected-access", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dataset_reader", "=", "None", "\n", "\n", "# TODO: there should be better ways to do this", "\n", "", "if", "type", "(", "predictor", ")", "in", "(", "STOGPredictor", ",", ")", ":", "\n", "            ", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "_predictor", ".", "_model", ".", "set_beam_size", "(", "self", ".", "beam_size", ")", "\n", "self", ".", "_predictor", ".", "_model", ".", "set_decoder_token_indexers", "(", "self", ".", "_dataset_reader", ".", "_token_indexers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._predict_json": [[133, 140], ["len", "predict._PredictManager._predictor.predict_batch_json", "predict._PredictManager._predictor.predict_json", "predict._PredictManager._predictor.dump_line"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_batch_json", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_json", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.dump_line"], ["", "", "def", "_predict_json", "(", "self", ",", "batch_data", ":", "List", "[", "JsonDict", "]", ")", "->", "Iterator", "[", "str", "]", ":", "\n", "        ", "if", "len", "(", "batch_data", ")", "==", "1", ":", "\n", "            ", "results", "=", "[", "self", ".", "_predictor", ".", "predict_json", "(", "batch_data", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "_predictor", ".", "predict_batch_json", "(", "batch_data", ")", "\n", "", "for", "output", "in", "results", ":", "\n", "            ", "yield", "self", ".", "_predictor", ".", "dump_line", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._predict_instances": [[141, 148], ["len", "predict._PredictManager._predictor.predict_batch_instance", "predict._PredictManager._predictor.predict_instance", "predict._PredictManager._predictor.dump_line"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.predict_batch_instance", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.predict_instance", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.stog.STOGPredictor.dump_line"], ["", "", "def", "_predict_instances", "(", "self", ",", "batch_data", ":", "List", "[", "Instance", "]", ")", "->", "Iterator", "[", "str", "]", ":", "\n", "        ", "if", "len", "(", "batch_data", ")", "==", "1", ":", "\n", "            ", "results", "=", "[", "self", ".", "_predictor", ".", "predict_instance", "(", "batch_data", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "_predictor", ".", "predict_batch_instance", "(", "batch_data", ")", "\n", "", "for", "output", "in", "results", ":", "\n", "            ", "yield", "self", ".", "_predictor", ".", "dump_line", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._maybe_print_to_console_and_file": [[149, 158], ["print", "predict._PredictManager._output_file.write", "print"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["", "", "def", "_maybe_print_to_console_and_file", "(", "self", ",", "\n", "prediction", ":", "str", ",", "\n", "model_input", ":", "str", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_print_to_console", ":", "\n", "            ", "if", "model_input", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"input: \"", ",", "model_input", ")", "\n", "", "print", "(", "\"prediction: \"", ",", "prediction", ")", "\n", "", "if", "self", ".", "_output_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_file", ".", "write", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._get_json_data": [[159, 169], ["open", "line.isspace", "predict._PredictManager._predictor.load_line", "line.isspace", "predict._PredictManager._predictor.load_line"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.load_line", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.load_line"], ["", "", "def", "_get_json_data", "(", "self", ")", "->", "Iterator", "[", "JsonDict", "]", ":", "\n", "        ", "if", "self", ".", "_input_file", "==", "\"-\"", ":", "\n", "            ", "for", "line", "in", "sys", ".", "stdin", ":", "\n", "                ", "if", "not", "line", ".", "isspace", "(", ")", ":", "\n", "                    ", "yield", "self", ".", "_predictor", ".", "load_line", "(", "line", ")", "\n", "", "", "", "else", ":", "\n", "            ", "with", "open", "(", "self", ".", "_input_file", ",", "\"r\"", ")", "as", "file_input", ":", "\n", "                ", "for", "line", "in", "file_input", ":", "\n", "                    ", "if", "not", "line", ".", "isspace", "(", ")", ":", "\n", "                        ", "yield", "self", ".", "_predictor", ".", "load_line", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._get_instance_data": [[170, 177], ["stog.utils.checks.ConfigurationError", "stog.utils.checks.ConfigurationError", "predict._PredictManager._dataset_reader.read"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["", "", "", "", "", "def", "_get_instance_data", "(", "self", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "if", "self", ".", "_input_file", "==", "\"-\"", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"stdin is not an option when using a DatasetReader.\"", ")", "\n", "", "elif", "self", ".", "_dataset_reader", "is", "None", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"To generate instances directly, pass a DatasetReader.\"", ")", "\n", "", "else", ":", "\n", "            ", "yield", "from", "self", ".", "_dataset_reader", ".", "read", "(", "self", ".", "_input_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager.run": [[178, 191], ["stog.utils.lazy_groups_of", "stog.utils.lazy_groups_of", "predict._PredictManager._output_file.close", "predict._PredictManager._get_instance_data", "zip", "predict._PredictManager._get_json_data", "zip", "predict._PredictManager._predict_instances", "predict._PredictManager._maybe_print_to_console_and_file", "predict._PredictManager._predict_json", "predict._PredictManager._maybe_print_to_console_and_file", "str", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.utils.__init__.lazy_groups_of", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._get_instance_data", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._get_json_data", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._predict_instances", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._maybe_print_to_console_and_file", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._predict_json", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager._maybe_print_to_console_and_file"], ["", "", "def", "run", "(", "self", ")", "->", "None", ":", "\n", "        ", "has_reader", "=", "self", ".", "_dataset_reader", "is", "not", "None", "\n", "if", "has_reader", ":", "\n", "            ", "for", "batch", "in", "lazy_groups_of", "(", "self", ".", "_get_instance_data", "(", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                ", "for", "model_input_instance", ",", "result", "in", "zip", "(", "batch", ",", "self", ".", "_predict_instances", "(", "batch", ")", ")", ":", "\n", "                    ", "self", ".", "_maybe_print_to_console_and_file", "(", "result", ",", "str", "(", "model_input_instance", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "batch_json", "in", "lazy_groups_of", "(", "self", ".", "_get_json_data", "(", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                ", "for", "model_input_json", ",", "result", "in", "zip", "(", "batch_json", ",", "self", ".", "_predict_json", "(", "batch_json", ")", ")", ":", "\n", "                    ", "self", ".", "_maybe_print_to_console_and_file", "(", "result", ",", "json", ".", "dumps", "(", "model_input_json", ")", ")", "\n", "\n", "", "", "", "if", "self", ".", "_output_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._get_predictor": [[93, 101], ["load_archive", "stog.predictors.predictor.Predictor.from_archive"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.load_archive", "home.repos.pwc.inspect_result.jcyk_gtos.predictors.predictor.Predictor.from_archive"], ["", "", "def", "_get_predictor", "(", "args", ":", "argparse", ".", "Namespace", ")", "->", "Predictor", ":", "\n", "    ", "from", "stog", ".", "utils", ".", "archival", "import", "load_archive", "\n", "# check_for_gpu(args.cuda_device)", "\n", "archive", "=", "load_archive", "(", "args", ".", "archive_file", ",", "\n", "device", "=", "args", ".", "cuda_device", ",", "\n", "weights_file", "=", "args", ".", "weights_file", ")", "\n", "\n", "return", "Predictor", ".", "from_archive", "(", "archive", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._predict": [[193, 209], ["predict._get_predictor", "predict._PredictManager", "predict._PredictManager.run", "print", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._get_predictor", "home.repos.pwc.inspect_result.jcyk_gtos.commands.predict._PredictManager.run"], ["", "", "", "def", "_predict", "(", "args", ":", "argparse", ".", "Namespace", ")", "->", "None", ":", "\n", "    ", "predictor", "=", "_get_predictor", "(", "args", ")", "\n", "\n", "if", "args", ".", "silent", "and", "not", "args", ".", "output_file", ":", "\n", "        ", "print", "(", "\"--silent specified without --output-file.\"", ")", "\n", "print", "(", "\"Exiting early because no output will be created.\"", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "", "manager", "=", "_PredictManager", "(", "predictor", ",", "\n", "args", ".", "input_file", ",", "\n", "args", ".", "output_file", ",", "\n", "args", ".", "batch_size", ",", "\n", "not", "args", ".", "silent", ",", "\n", "args", ".", "use_dataset_reader", ",", "\n", "args", ".", "beam_size", ")", "\n", "manager", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.evaluate.evaluate": [[17, 41], ["torch.no_grad", "model.eval", "iterator", "logger.info", "stog.utils.tqdm.Tqdm.tqdm", "model.get_metrics", "stog.utils.environment.move_to_device", "model", "model.get_metrics", "Tqdm.tqdm.set_description", "iterator.get_num_batches", "model.get_metrics.items"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.tqdm.Tqdm.tqdm", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.get_metrics", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.get_num_batches", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["def", "evaluate", "(", "model", ",", "instances", ",", "iterator", ",", "device", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "model", ".", "decode_type", "=", "'mst'", "\n", "\n", "test_generator", "=", "iterator", "(", "\n", "instances", "=", "instances", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_epochs", "=", "1", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Iterating over dataset\"", ")", "\n", "generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "\n", "test_generator", ",", "\n", "total", "=", "iterator", ".", "get_num_batches", "(", "instances", ")", "\n", ")", "\n", "for", "batch", "in", "generator_tqdm", ":", "\n", "            ", "batch", "=", "move_to_device", "(", "batch", ",", "device", ")", "\n", "model", "(", "batch", ",", "for_training", "=", "True", ")", "\n", "metrics", "=", "model", ".", "get_metrics", "(", ")", "\n", "description", "=", "', '", ".", "join", "(", "[", "\"%s: %.2f\"", "%", "(", "name", ",", "value", ")", "for", "name", ",", "value", "in", "metrics", ".", "items", "(", ")", "]", ")", "+", "\" ||\"", "\n", "generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "", "return", "model", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.evaluate.evaluate_from_args": [[43, 89], ["stog.utils.archival.load_archive", "stog.utils.environment.set_seed", "stog.utils.environment.prepare_global_logging", "model.eval", "logger.info", "stog.data.dataset_builder.load_dataset", "stog.data.iterators.BasicIterator", "stog.data.iterators.BasicIterator.index_with", "evaluate.evaluate", "logger.info", "logger.info", "evaluate.items", "torch.device", "torch.device", "os.path.join", "logger.info", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.load_archive", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.set_seed", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.prepare_global_logging", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.load_dataset", "home.repos.pwc.inspect_result.jcyk_gtos.iterators.data_iterator.DataIterator.index_with", "home.repos.pwc.inspect_result.jcyk_gtos.commands.evaluate.evaluate", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.node_utils.NodeUtilities.dump"], ["", "", "def", "evaluate_from_args", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "cuda_device", ">", "-", "1", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "args", ".", "cuda_device", ")", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "# Load from archive", "\n", "", "archive", "=", "load_archive", "(", "args", ".", "archive_file", ",", "device", ",", "args", ".", "weights_file", ")", "\n", "config", "=", "archive", ".", "config", "\n", "\n", "# Set up the environment.", "\n", "environment_params", "=", "config", "[", "'environment'", "]", "\n", "environment", ".", "set_seed", "(", "environment_params", ")", "\n", "environment", ".", "prepare_global_logging", "(", "environment_params", ")", "\n", "\n", "model", "=", "archive", ".", "model", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Load the evaluation data", "\n", "# Try to use the validation dataset reader if there is one - otherwise fall back", "\n", "# to the default dataset_reader used for both training and validation.", "\n", "data_type", "=", "config", "[", "'data'", "]", "[", "'data_type'", "]", "\n", "if", "args", ".", "input_file", ":", "\n", "        ", "evaluation_data_path", "=", "args", ".", "input_file", "\n", "", "else", ":", "\n", "        ", "evaluation_data_path", "=", "os", ".", "path", ".", "join", "(", "config", "[", "'data'", "]", "[", "'data_dir'", "]", ",", "config", "[", "'data'", "]", "[", "'test_data'", "]", ")", "\n", "", "batch_size", "=", "args", ".", "batch_size", "if", "args", ".", "batch_size", "!=", "-", "1", "else", "config", "[", "'data'", "]", "[", "'test_batch_size'", "]", "\n", "\n", "logger", ".", "info", "(", "\"Reading evaluation data from %s\"", ",", "evaluation_data_path", ")", "\n", "instances", "=", "load_dataset", "(", "evaluation_data_path", ",", "data_type", ",", "**", "config", "[", "'data'", "]", ")", "\n", "\n", "iterator", "=", "BasicIterator", "(", "batch_size", "=", "batch_size", ")", "\n", "iterator", ".", "index_with", "(", "model", ".", "vocab", ")", "\n", "\n", "metrics", "=", "evaluate", "(", "model", ",", "instances", ",", "iterator", ",", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Finished evaluating.\"", ")", "\n", "logger", ".", "info", "(", "\"Metrics:\"", ")", "\n", "for", "key", ",", "metric", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"%s: %s\"", ",", "key", ",", "metric", ")", "\n", "\n", "", "output_file", "=", "args", ".", "output_file", "\n", "if", "output_file", ":", "\n", "        ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "file", ":", "\n", "            ", "json", ".", "dump", "(", "metrics", ",", "file", ",", "indent", "=", "4", ")", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.train.create_serialization_dir": [[23, 65], ["os.path.exists", "os.listdir", "logger.info", "os.path.join", "os.makedirs", "params.to_file", "stog.utils.checks.ConfigurationError", "os.path.exists", "stog.utils.checks.ConfigurationError", "stog.utils.params.Params.from_file", "stog.utils.params.remove_pretrained_embedding_params", "stog.utils.checks.ConfigurationError", "os.path.join", "stog.utils.checks.ConfigurationError"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.to_file", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.from_file", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.remove_pretrained_embedding_params"], ["parser", ".", "add_argument", "(", "'--pretrained_file'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# concept/token encoders", "\n", "parser", ".", "add_argument", "(", "'--token_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--token_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# char-cnn", "\n", "parser", ".", "add_argument", "(", "'--cnn_filters'", ",", "type", "=", "int", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--char2word_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--char2concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# relation encoder", "\n", "parser", ".", "add_argument", "(", "'--rel_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_hidden_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_num_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# core architecture", "\n", "parser", ".", "add_argument", "(", "'--embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ff_embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_heads'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--snt_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--graph_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--inference_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# dropout/unk ", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--unk_rate'", ",", "type", "=", "float", ")", "\n", "\n", "# IO", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--train_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ")", "\n", "\n", "# distributed training", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.train.train_model": [[67, 155], ["stog.utils.environment.set_seed", "train.create_serialization_dir", "stog.utils.environment.prepare_global_logging", "stog.utils.environment.check_for_gpu", "stog.data.dataset_builder.dataset_from_params", "stog.data.dataset_builder.dataset_from_params.get", "stog.data.dataset_builder.dataset_from_params.get", "params.get", "stog.data.vocabulary.Vocabulary.from_instances", "Vocabulary.from_instances.save_to_files", "stog.data.dataset_builder.iterator_from_params", "getattr().from_params", "logger.info", "getattr().from_params.named_parameters", "stog.utils.environment.get_frozen_and_tunable_parameter_names", "logger.info", "logger.info", "stog.training.trainer.Trainer.from_params", "stog.utils.archival.archive_model", "logger.info", "os.path.join", "torch.load", "best_model.load_state_dict", "torch.device", "stog.utils.environment.occupy_gpu", "torch.device", "os.path.join", "any", "logger.info", "logger.info", "Trainer.from_params.train", "isinstance", "getattr", "parameter.requires_grad_", "os.path.exists", "re.sub", "re.search", "os.path.join", "logger.info", "stog.utils.archival.archive_model", "torch.load.items"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.set_seed", "home.repos.pwc.inspect_result.jcyk_gtos.commands.train.create_serialization_dir", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.prepare_global_logging", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.check_for_gpu", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.dataset_from_params", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_instances", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.save_to_files", "home.repos.pwc.inspect_result.jcyk_gtos.data.dataset_builder.iterator_from_params", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.get_frozen_and_tunable_parameter_names", "home.repos.pwc.inspect_result.jcyk_gtos.data.vocabulary.Vocabulary.from_params", "home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.archive_model", "home.repos.pwc.inspect_result.jcyk_gtos.models.model.Model.load", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.jcyk_gtos.utils.environment.occupy_gpu", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.utils.archival.archive_model", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_ADDR'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_PORT'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--start_rank'", ",", "type", "=", "int", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "", "def", "average_gradients", "(", "model", ")", ":", "\n", "    ", "size", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "param", ".", "grad", ".", "data", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "param", ".", "grad", ".", "data", "/=", "size", "\n", "\n", "", "", "", "def", "update_lr", "(", "optimizer", ",", "embed_size", ",", "steps", ",", "warmup_steps", ")", ":", "\n", "    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "embed_size", "**", "-", "0.5", "*", "min", "(", "steps", "**", "-", "0.5", ",", "steps", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ")", "\n", "\n", "", "", "def", "main", "(", "args", ",", "local_rank", ")", ":", "\n", "    ", "vocabs", "=", "dict", "(", ")", "\n", "vocabs", "[", "'concept'", "]", "=", "Vocab", "(", "args", ".", "concept_vocab", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'token'", "]", "=", "Vocab", "(", "args", ".", "token_vocab", ",", "5", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'predictable_token'", "]", "=", "Vocab", "(", "args", ".", "predictable_token_vocab", ",", "5", ",", "[", "END", "]", ")", "\n", "vocabs", "[", "'token_char'", "]", "=", "Vocab", "(", "args", ".", "token_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'concept_char'", "]", "=", "Vocab", "(", "args", ".", "concept_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'relation'", "]", "=", "Vocab", "(", "args", ".", "relation_vocab", ",", "5", ",", "[", "CLS", ",", "rCLS", ",", "SEL", ",", "TL", "]", ")", "\n", "lexical_mapping", "=", "LexicalMap", "(", ")", "\n", "\n", "for", "name", "in", "vocabs", ":", "\n", "        ", "print", "(", "(", "name", ",", "vocabs", "[", "name", "]", ".", "size", ",", "vocabs", "[", "name", "]", ".", "coverage", ")", ")", "\n", "\n", "", "torch", ".", "manual_seed", "(", "19940117", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", ")", "\n", "random", ".", "seed", "(", "19940117", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "local_rank", ")", "\n", "model", "=", "Generator", "(", "vocabs", ",", "\n", "args", ".", "token_char_dim", ",", "args", ".", "token_dim", ",", "\n", "args", ".", "concept_char_dim", ",", "args", ".", "concept_dim", ",", "\n", "args", ".", "cnn_filters", ",", "args", ".", "char2word_dim", ",", "args", ".", "char2concept_dim", ",", "\n", "args", ".", "rel_dim", ",", "args", ".", "rnn_hidden_size", ",", "args", ".", "rnn_num_layers", ",", "\n", "args", ".", "embed_dim", ",", "args", ".", "ff_embed_dim", ",", "args", ".", "num_heads", ",", "args", ".", "dropout", ",", "\n", "args", ".", "snt_layers", ",", "args", ".", "graph_layers", ",", "args", ".", "inference_layers", ",", "\n", "args", ".", "pretrained_file", ",", "\n", "device", ")", "\n", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "random", ".", "seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "\n", "", "model", "=", "model", ".", "cuda", "(", "device", ")", "\n", "train_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "train_data", ",", "args", ".", "train_batch_size", ",", "for_train", "=", "True", ")", "\n", "dev_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "dev_data", ",", "args", ".", "dev_batch_size", ",", "for_train", "=", "False", ")", "\n", "train_data", ".", "set_unk_rate", "(", "args", ".", "unk_rate", ")", "\n", "\n", "weight_decay_params", "=", "[", "]", "\n", "no_weight_decay_params", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", ".", "endswith", "(", "'bias'", ")", "or", "'layer_norm'", "in", "name", ":", "\n", "            ", "no_weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "", "grouped_params", "=", "[", "{", "'params'", ":", "weight_decay_params", ",", "'weight_decay'", ":", "1e-4", "}", ",", "\n", "{", "'params'", ":", "no_weight_decay_params", ",", "'weight_decay'", ":", "0.", "}", "]", "\n", "optimizer", "=", "AdamWeightDecayOptimizer", "(", "grouped_params", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ")", "\n", "\n", "batches_acm", ",", "loss_acm", "=", "0", ",", "0", "\n", "discarded_batches_acm", "=", "0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "for", "batch", "in", "train_data", ":", "\n", "            ", "batch", "=", "move_to_cuda", "(", "batch", ",", "device", ")", "\n", "loss", "=", "model", "(", "batch", ")", "\n", "loss_value", "=", "loss", ".", "item", "(", ")", "\n", "if", "batches_acm", ">", "args", ".", "warmup_steps", "and", "loss_value", ">", "5.", "*", "(", "loss_acm", "/", "batches_acm", ")", ":", "\n", "                ", "discarded_batches_acm", "+=", "1", "\n", "print", "(", "'abnormal'", ",", "loss_value", ")", "\n", "continue", "\n", "", "loss_acm", "+=", "loss_value", "\n", "batches_acm", "+=", "1", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "                ", "average_gradients", "(", "model", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "update_lr", "(", "optimizer", ",", "args", ".", "embed_dim", ",", "batches_acm", ",", "args", ".", "warmup_steps", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "world_size", "==", "1", "or", "(", "dist", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.commands.subcommand.Subcommand.add_subparser": [[16, 19], ["None"], "methods", ["None"], ["def", "add_subparser", "(", "self", ",", "name", ":", "str", ",", "parser", ":", "argparse", ".", "_SubParsersAction", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.RelationEncoder.__init__": [[67, 85], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "rel_dim", ",", "embed_dim", ",", "hidden_size", ",", "num_layers", ",", "dropout", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "super", "(", "RelationEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rel_embed", "=", "AMREmbedding", "(", "vocab", ",", "rel_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "\n", "input_size", "=", "rel_dim", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout", "if", "num_layers", ">", "1", "else", "0.", ",", "\n", "bidirectional", "=", "bidirectional", "\n", ")", "\n", "tot_dim", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.RelationEncoder.reset_parameters": [[86, 89], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.RelationEncoder.forward": [[90, 120], ["src_tokens.size", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "src_tokens.index_select", "encoder.RelationEncoder.rel_embed", "torch.dropout", "torch.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.dropout.data.new().zero_", "encoder.RelationEncoder.rnn", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "combine_bidir.index_select", "encoder.RelationEncoder.out_proj", "sorted_src_lengths.data.tolist", "encoder.RelationEncoder.forward.combine_bidir"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "seq_len", ",", "bsz", "=", "src_tokens", ".", "size", "(", ")", "\n", "###", "\n", "sorted_src_lengths", ",", "indices", "=", "torch", ".", "sort", "(", "src_lengths", ",", "descending", "=", "True", ")", "\n", "sorted_src_tokens", "=", "src_tokens", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "###", "\n", "x", "=", "self", ".", "rel_embed", "(", "sorted_src_tokens", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "packed_x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "sorted_src_lengths", ".", "data", ".", "tolist", "(", ")", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "state_size", "=", "2", "*", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "else", ":", "\n", "            ", "state_size", "=", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "h0", "=", "x", ".", "data", ".", "new", "(", "*", "state_size", ")", ".", "zero_", "(", ")", "\n", "_", ",", "final_h", "=", "self", ".", "rnn", "(", "packed_x", ",", "h0", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "def", "combine_bidir", "(", "outs", ")", ":", "\n", "                ", "return", "outs", ".", "view", "(", "self", ".", "num_layers", ",", "2", ",", "bsz", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "num_layers", ",", "bsz", ",", "-", "1", ")", "\n", "", "final_h", "=", "combine_bidir", "(", "final_h", ")", "\n", "\n", "###", "\n", "", "_", ",", "positions", "=", "torch", ".", "sort", "(", "indices", ")", "\n", "final_h", "=", "final_h", ".", "index_select", "(", "1", ",", "positions", ")", "# num_layers x bsz x hidden_size", "\n", "\n", "output", "=", "self", ".", "out_proj", "(", "final_h", "[", "-", "1", "]", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.TokenEncoder.__init__": [[124, 136], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "encoder.AMREmbedding", "encoder.CNNEncoder", "torch.nn.Linear", "torch.nn.Linear", "encoder.TokenEncoder.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "token_vocab", ",", "char_vocab", ",", "char_dim", ",", "token_dim", ",", "embed_dim", ",", "filters", ",", "char2token_dim", ",", "dropout", ",", "pretrained_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "TokenEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "char_embed", "=", "AMREmbedding", "(", "char_vocab", ",", "char_dim", ")", "\n", "self", ".", "token_embed", "=", "AMREmbedding", "(", "token_vocab", ",", "token_dim", ",", "pretrained_file", ")", "\n", "self", ".", "char2token", "=", "CNNEncoder", "(", "filters", ",", "char_dim", ",", "char2token_dim", ")", "\n", "tot_dim", "=", "char2token_dim", "+", "token_dim", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "self", ".", "char_dim", "=", "char_dim", "\n", "self", ".", "token_dim", "=", "token_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.TokenEncoder.reset_parameters": [[137, 140], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.TokenEncoder.forward": [[141, 150], ["char_input.size", "encoder.TokenEncoder.char_embed", "encoder.TokenEncoder.char2token().view", "encoder.TokenEncoder.token_embed", "torch.dropout", "torch.dropout", "encoder.TokenEncoder.out_proj", "char_input.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.TokenEncoder.char2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "token_input", ",", "char_input", ")", ":", "\n", "        ", "seq_len", ",", "bsz", ",", "_", "=", "char_input", ".", "size", "(", ")", "\n", "char_repr", "=", "self", ".", "char_embed", "(", "char_input", ".", "view", "(", "seq_len", "*", "bsz", ",", "-", "1", ")", ")", "\n", "char_repr", "=", "self", ".", "char2token", "(", "char_repr", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "token_repr", "=", "self", ".", "token_embed", "(", "token_input", ")", "\n", "\n", "token", "=", "F", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "char_repr", ",", "token_repr", "]", ",", "-", "1", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "token", "=", "self", ".", "out_proj", "(", "token", ")", "\n", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.CNNEncoder.__init__": [[152, 161], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "sum", "encoder.Highway", "torch.nn.Linear", "torch.nn.Linear", "encoder.CNNEncoder.reset_parameters", "encoder.CNNEncoder.convolutions.append", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "filters", ",", "input_dim", ",", "output_dim", ",", "highway_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "width", ",", "out_c", "in", "filters", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "nn", ".", "Conv1d", "(", "input_dim", ",", "out_c", ",", "kernel_size", "=", "width", ")", ")", "\n", "", "final_dim", "=", "sum", "(", "f", "[", "1", "]", "for", "f", "in", "filters", ")", "\n", "self", ".", "highway", "=", "Highway", "(", "final_dim", ",", "highway_layers", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "final_dim", ",", "output_dim", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.CNNEncoder.reset_parameters": [[162, 165], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.CNNEncoder.forward": [[166, 179], ["input.transpose", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.CNNEncoder.highway", "encoder.CNNEncoder.out_proj", "conv", "torch.max", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "encoder.CNNEncoder.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# input: batch_size x seq_len x input_dim", "\n", "        ", "x", "=", "input", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conv_result", "=", "[", "]", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convolutions", ")", ":", "\n", "            ", "y", "=", "conv", "(", "x", ")", "\n", "y", ",", "_", "=", "torch", ".", "max", "(", "y", ",", "-", "1", ")", "\n", "y", "=", "F", ".", "relu", "(", "y", ")", "\n", "conv_result", ".", "append", "(", "y", ")", "\n", "\n", "", "conv_result", "=", "torch", ".", "cat", "(", "conv_result", ",", "dim", "=", "-", "1", ")", "\n", "conv_result", "=", "self", ".", "highway", "(", "conv_result", ")", "\n", "return", "self", ".", "out_proj", "(", "conv_result", ")", "#  batch_size x output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.Highway.__init__": [[181, 187], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "encoder.Highway.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "layers", ")", ":", "\n", "        ", "super", "(", "Highway", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", "*", "2", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "]", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.Highway.reset_parameters": [[188, 193], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", "self", ".", "input_dim", ":", "]", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", ":", "self", ".", "input_dim", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.Highway.forward": [[194, 202], ["layer", "torch.relu.chunk", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "new_x", "=", "layer", "(", "x", ")", "\n", "new_x", ",", "gate", "=", "new_x", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "new_x", "=", "F", ".", "relu", "(", "new_x", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "x", "=", "gate", "*", "x", "+", "(", "1", "-", "gate", ")", "*", "new_x", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.encoder.AMREmbedding": [[9, 65], ["set", "range", "numpy.asarray", "print", "float", "float", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "range", "embedding_matrix[].fill_", "torch.nn.Embedding.from_pretrained", "transformer.Embedding", "vocab.idx2token", "set.add", "open", "open", "embeddings_file.readlines", "open.close", "list", "numpy.mean", "numpy.std", "vocab.idx2token", "re.sub", "line.rstrip().split", "embeddings.values", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.asarray", "re.sub", "line.rstrip", "len", "open.write", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["def", "AMREmbedding", "(", "vocab", ",", "embedding_dim", ",", "pretrained_file", "=", "None", ",", "amr", "=", "False", ",", "dump_file", "=", "None", ")", ":", "\n", "    ", "if", "pretrained_file", "is", "None", ":", "\n", "        ", "return", "Embedding", "(", "vocab", ".", "size", ",", "embedding_dim", ",", "vocab", ".", "padding_idx", ")", "\n", "\n", "", "tokens_to_keep", "=", "set", "(", ")", "\n", "for", "idx", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "idx", ")", "\n", "# TODO: Is there a better way to do this? Currently we have a very specific 'amr' param.", "\n", "if", "amr", ":", "\n", "            ", "token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "", "tokens_to_keep", ".", "add", "(", "token", ")", "\n", "\n", "", "embeddings", "=", "{", "}", "\n", "\n", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", "=", "open", "(", "dump_file", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "\n", "\n", "", "with", "open", "(", "pretrained_file", ",", "encoding", "=", "'utf8'", ")", "as", "embeddings_file", ":", "\n", "        ", "for", "line", "in", "embeddings_file", ".", "readlines", "(", ")", ":", "\n", "            ", "fields", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "fields", ")", "-", "1", "!=", "embedding_dim", ":", "\n", "                ", "continue", "\n", "", "token", "=", "fields", "[", "0", "]", "\n", "if", "token", "in", "tokens_to_keep", ":", "\n", "                ", "if", "dump_file", "is", "not", "None", ":", "\n", "                    ", "fo", ".", "write", "(", "line", ")", "\n", "", "vector", "=", "np", ".", "asarray", "(", "fields", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "embeddings", "[", "token", "]", "=", "vector", "\n", "\n", "", "", "", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", ".", "close", "(", ")", "\n", "\n", "", "all_embeddings", "=", "np", ".", "asarray", "(", "list", "(", "embeddings", ".", "values", "(", ")", ")", ")", "\n", "print", "(", "'pretrained'", ",", "all_embeddings", ".", "shape", ")", "\n", "embeddings_mean", "=", "float", "(", "np", ".", "mean", "(", "all_embeddings", ")", ")", "\n", "embeddings_std", "=", "float", "(", "np", ".", "std", "(", "all_embeddings", ")", ")", "\n", "# Now we initialize the weight matrix for an embedding layer, starting with random vectors,", "\n", "# then filling in the word vectors we just read.", "\n", "embedding_matrix", "=", "torch", ".", "FloatTensor", "(", "vocab", ".", "size", ",", "embedding_dim", ")", ".", "normal_", "(", "embeddings_mean", ",", "\n", "embeddings_std", ")", "\n", "\n", "for", "i", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "i", ")", "\n", "\n", "# If we don't have a pre-trained vector for this word, we'll just leave this row alone,", "\n", "# so the word has a random initialization.", "\n", "if", "token", "in", "embeddings", ":", "\n", "            ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "token", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "amr", ":", "\n", "                ", "normalized_token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "if", "normalized_token", "in", "embeddings", ":", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "normalized_token", "]", ")", "\n", "", "", "", "", "embedding_matrix", "[", "vocab", ".", "padding_idx", "]", ".", "fill_", "(", "0.", ")", "\n", "\n", "return", "nn", ".", "Embedding", ".", "from_pretrained", "(", "embedding_matrix", ",", "freeze", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.work.parse_config": [[12, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--max_time_step'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--output_suffix'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.work.generate_batch": [[26, 39], ["utils.move_to_device", "dict", "model.work", "token_batch.append", "score_batch.append", "beam.get_k_best"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.work", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.get_k_best"], ["", "def", "generate_batch", "(", "model", ",", "batch", ",", "beam_size", ",", "alpha", ",", "max_time_step", ")", ":", "\n", "    ", "batch", "=", "move_to_cuda", "(", "batch", ",", "model", ".", "device", ")", "\n", "res", "=", "dict", "(", ")", "\n", "token_batch", ",", "score_batch", "=", "[", "]", ",", "[", "]", "\n", "beams", "=", "model", ".", "work", "(", "batch", ",", "beam_size", ",", "max_time_step", ")", "\n", "for", "beam", "in", "beams", ":", "\n", "        ", "best_hyp", "=", "beam", ".", "get_k_best", "(", "1", ",", "alpha", ")", "[", "0", "]", "\n", "predicted_token", "=", "[", "token", "for", "token", "in", "best_hyp", ".", "seq", "[", "1", ":", "-", "1", "]", "]", "\n", "token_batch", ".", "append", "(", "predicted_token", ")", "\n", "score_batch", ".", "append", "(", "best_hyp", ".", "score", ")", "\n", "", "res", "[", "'token'", "]", "=", "token_batch", "\n", "res", "[", "'score'", "]", "=", "score_batch", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.work.validate": [[40, 62], ["postprocess.PostProcess", "sacrebleu.corpus_chrf", "work.generate_batch", "sys_stream.extend", "ref_stream.extend", "len", "len", "postprocess.PostProcess.post_process", "sacrebleu.corpus_bleu"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.work.generate_batch", "home.repos.pwc.inspect_result.jcyk_gtos.translator.postprocess.PostProcess.post_process"], ["", "def", "validate", "(", "model", ",", "test_data", ",", "golden_file", ",", "beam_size", "=", "8", ",", "alpha", "=", "0.6", ",", "max_time_step", "=", "100", ")", ":", "\n", "    ", "\"\"\"For development Only\"\"\"", "\n", "pp", "=", "PostProcess", "(", ")", "\n", "\n", "ref_stream", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "golden_file", "+", "'.input_clean'", ")", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'# ::tokens '", ")", ":", "\n", "            ", "o", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::tokens '", ")", ":", "]", ".", "strip", "(", ")", ")", "\n", "ref_stream", ".", "append", "(", "' '", ".", "join", "(", "o", ")", ".", "lower", "(", ")", ")", "\n", "# gold model output", "\n", "", "", "graph", ",", "gold_sys_stream", ",", "_", ",", "abstract", "=", "read_file", "(", "golden_file", "+", "'.preproc'", ")", "\n", "ref_streams", "=", "[", "ref_stream", "]", "\n", "\n", "sys_stream", "=", "[", "]", "\n", "for", "batch", "in", "test_data", ":", "\n", "        ", "res", "=", "generate_batch", "(", "model", ",", "batch", ",", "beam_size", ",", "alpha", ",", "max_time_step", ")", "\n", "sys_stream", ".", "extend", "(", "res", "[", "'token'", "]", ")", "\n", "\n", "", "assert", "len", "(", "sys_stream", ")", "==", "len", "(", "ref_stream", ")", "\n", "sys_stream", "=", "[", "pp", ".", "post_process", "(", "o", ",", "abstract", "[", "i", "]", ",", "graph", "[", "i", "]", ")", "for", "i", ",", "o", "in", "enumerate", "(", "sys_stream", ")", "]", "\n", "\n", "bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "sys_stream", ",", "ref_streams", ",", "\n", "force", "=", "True", ",", "lowercase", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformer.__init__": [[8, 13], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "graph_transformer.GraphTransformer.layers.append", "graph_transformer.GraphTransformerLayer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "GraphTransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformer.forward": [[14, 19], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", "=", "layer", "(", "x", ",", "relation", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformer.get_attn_weights": [[20, 28], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "attns.append"], "methods", ["None"], ["", "def", "get_attn_weights", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ")", ":", "\n", "        ", "attns", "=", "[", "]", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "attn", "=", "layer", "(", "x", ",", "relation", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "need_weights", "=", "True", ")", "\n", "attns", ".", "append", "(", "attn", ")", "\n", "", "attn", "=", "torch", ".", "stack", "(", "attns", ")", "\n", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformerLayer.__init__": [[31, 40], ["torch.nn.Module.__init__", "graph_transformer.RelationMultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "graph_transformer.GraphTransformerLayer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphTransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "RelationMultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformerLayer.reset_parameters": [[41, 46], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformerLayer.forward": [[47, 67], ["torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.fc2", "torch.dropout", "torch.dropout", "graph_transformer.GraphTransformerLayer.ff_layer_norm", "graph_transformer.GraphTransformerLayer.self_attn", "graph_transformer.GraphTransformerLayer.self_attn", "graph_transformer.GraphTransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "relation", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "need_weights", "=", "False", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "relation", "=", "relation", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "relation", "=", "relation", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.__init__": [[69, 85], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "graph_transformer.RelationMultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "RelationMultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "self", ".", "relation_in_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "2", "*", "embed_dim", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.reset_parameters": [[86, 92], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "relation_in_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.forward": [[93, 175], ["query.size", "key.size", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.contiguous().view", "graph_transformer.RelationMultiheadAttention.relation_in_proj().chunk", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.softmax", "torch.softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.dropout.transpose().contiguous().view", "graph_transformer.RelationMultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "graph_transformer.RelationMultiheadAttention.in_proj_qkv", "graph_transformer.RelationMultiheadAttention.unsqueeze", "graph_transformer.RelationMultiheadAttention.unsqueeze", "list", "attn_weights.view.view.masked_fill_", "attn_weights.view.view.view", "attn_weights.view.view.masked_fill_", "attn_weights.view.view.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.view.view.view", "graph_transformer.RelationMultiheadAttention.in_proj_q", "graph_transformer.RelationMultiheadAttention.in_proj_kv", "graph_transformer.RelationMultiheadAttention.in_proj_q", "graph_transformer.RelationMultiheadAttention.in_proj_k", "graph_transformer.RelationMultiheadAttention.in_proj_v", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.contiguous", "graph_transformer.RelationMultiheadAttention.relation_in_proj", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "attn_weights.view.view.size", "attn_mask.unsqueeze", "float", "key_padding_mask.unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "ra.contiguous().view().transpose.contiguous().view().transpose.contiguous", "rb.contiguous().view().transpose.contiguous().view().transpose.contiguous", "key_padding_mask.unsqueeze", "torch.dropout.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "relation", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "False", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            relation:  tgt_len x src_len x bsz x dim\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "src_len", "=", "key", ".", "size", "(", "0", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "\n", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "\n", "ra", ",", "rb", "=", "self", ".", "relation_in_proj", "(", "relation", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "ra", "=", "ra", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "rb", "=", "rb", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "q", "=", "q", ".", "unsqueeze", "(", "1", ")", "+", "ra", "\n", "k", "=", "k", ".", "unsqueeze", "(", "0", ")", "+", "rb", "\n", "q", "*=", "self", ".", "scaling", "\n", "# q: tgt_len x src_len x bsz*heads x dim", "\n", "# k: tgt_len x src_len x bsz*heads x dim", "\n", "# v: src_len x bsz*heads x dim", "\n", "\n", "attn_weights", "=", "torch", ".", "einsum", "(", "'ijbn,ijbn->ijb'", ",", "[", "q", ",", "k", "]", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", ",", "self", ".", "num_heads", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# attn_weights: tgt_len x src_len x bsz*heads", "\n", "# v: src_len x bsz*heads x dim", "\n", "", "attn", "=", "torch", ".", "einsum", "(", "'ijb,jbn->bin'", ",", "[", "attn_weights", ",", "v", "]", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads ", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "tgt_len", ",", "src_len", ",", "bsz", ",", "self", ".", "num_heads", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.in_proj_qkv": [[176, 178], ["graph_transformer.RelationMultiheadAttention._in_proj().chunk", "graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.in_proj_kv": [[179, 181], ["graph_transformer.RelationMultiheadAttention._in_proj().chunk", "graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.in_proj_q": [[182, 184], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.in_proj_k": [[185, 187], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention.in_proj_v": [[188, 190], ["graph_transformer.RelationMultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.RelationMultiheadAttention._in_proj": [[191, 200], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.parse_config": [[14, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# vocabs", "\n", "parser", ".", "add_argument", "(", "'--token_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--predictable_token_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--token_char_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--relation_vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_file'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# concept/token encoders", "\n", "parser", ".", "add_argument", "(", "'--token_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--token_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_char_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# char-cnn", "\n", "parser", ".", "add_argument", "(", "'--cnn_filters'", ",", "type", "=", "int", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--char2word_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--char2concept_dim'", ",", "type", "=", "int", ")", "\n", "\n", "# relation encoder", "\n", "parser", ".", "add_argument", "(", "'--rel_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_hidden_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_num_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# core architecture", "\n", "parser", ".", "add_argument", "(", "'--embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ff_embed_dim'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_heads'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--snt_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--graph_layers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--inference_layers'", ",", "type", "=", "int", ")", "\n", "\n", "# dropout/unk ", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--unk_rate'", ",", "type", "=", "float", ")", "\n", "\n", "# IO", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--train_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ")", "\n", "\n", "# distributed training", "\n", "parser", ".", "add_argument", "(", "'--world_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_ADDR'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--MASTER_PORT'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--start_rank'", ",", "type", "=", "int", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.average_gradients": [[74, 80], ["float", "model.parameters", "torch.get_world_size", "torch.all_reduce"], "function", ["None"], ["", "def", "average_gradients", "(", "model", ")", ":", "\n", "    ", "size", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "param", ".", "grad", ".", "data", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "param", ".", "grad", ".", "data", "/=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.update_lr": [[81, 84], ["min"], "function", ["None"], ["", "", "", "def", "update_lr", "(", "optimizer", ",", "embed_size", ",", "steps", ",", "warmup_steps", ")", ":", "\n", "    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "embed_size", "**", "-", "0.5", "*", "min", "(", "steps", "**", "-", "0.5", ",", "steps", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.data_proc": [[85, 90], ["queue.put", "queue.put"], "function", ["None"], ["", "", "def", "main", "(", "args", ",", "local_rank", ")", ":", "\n", "    ", "vocabs", "=", "dict", "(", ")", "\n", "vocabs", "[", "'concept'", "]", "=", "Vocab", "(", "args", ".", "concept_vocab", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'token'", "]", "=", "Vocab", "(", "args", ".", "token_vocab", ",", "5", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'predictable_token'", "]", "=", "Vocab", "(", "args", ".", "predictable_token_vocab", ",", "5", ",", "[", "END", "]", ")", "\n", "vocabs", "[", "'token_char'", "]", "=", "Vocab", "(", "args", ".", "token_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.main": [[91, 184], ["dict", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "data.Vocab", "extract.LexicalMap", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "random.seed", "torch.device", "torch.device", "torch.device", "generator.Generator", "model.to.to", "data.DataLoader", "data.DataLoader.set_unk_rate", "model.to.named_parameters", "adam.AdamWeightDecayOptimizer", "torch.Queue", "torch.Process", "mp.Process.start", "model.to.train", "print", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "random.seed", "mp.Queue.get", "isinstance", "utils.move_to_device", "model.to.", "model.item", "model.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "train.update_lr", "adam.AdamWeightDecayOptimizer.step", "adam.AdamWeightDecayOptimizer.zero_grad", "name.endswith", "no_weight_decay_params.append", "weight_decay_params.append", "print", "print", "train.average_gradients", "model.to.parameters", "torch.get_rank", "torch.get_rank", "torch.get_rank", "torch.get_rank", "print", "model.to.train", "torch.save", "torch.save", "torch.save", "model.to.train", "model.to.state_dict"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.set_unk_rate", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.update_lr", "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.zero_grad", "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.average_gradients", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.jcyk_gtos.modules.optimizer.Optimizer.state_dict"], ["vocabs", "[", "'concept_char'", "]", "=", "Vocab", "(", "args", ".", "concept_char_vocab", ",", "100", ",", "[", "STR", ",", "END", "]", ")", "\n", "vocabs", "[", "'relation'", "]", "=", "Vocab", "(", "args", ".", "relation_vocab", ",", "5", ",", "[", "CLS", ",", "rCLS", ",", "SEL", ",", "TL", "]", ")", "\n", "lexical_mapping", "=", "LexicalMap", "(", ")", "\n", "\n", "for", "name", "in", "vocabs", ":", "\n", "        ", "print", "(", "(", "name", ",", "vocabs", "[", "name", "]", ".", "size", ",", "vocabs", "[", "name", "]", ".", "coverage", ")", ")", "\n", "\n", "", "torch", ".", "manual_seed", "(", "19940117", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", ")", "\n", "random", ".", "seed", "(", "19940117", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "local_rank", ")", "\n", "model", "=", "Generator", "(", "vocabs", ",", "\n", "args", ".", "token_char_dim", ",", "args", ".", "token_dim", ",", "\n", "args", ".", "concept_char_dim", ",", "args", ".", "concept_dim", ",", "\n", "args", ".", "cnn_filters", ",", "args", ".", "char2word_dim", ",", "args", ".", "char2concept_dim", ",", "\n", "args", ".", "rel_dim", ",", "args", ".", "rnn_hidden_size", ",", "args", ".", "rnn_num_layers", ",", "\n", "args", ".", "embed_dim", ",", "args", ".", "ff_embed_dim", ",", "args", ".", "num_heads", ",", "args", ".", "dropout", ",", "\n", "args", ".", "snt_layers", ",", "args", ".", "graph_layers", ",", "args", ".", "inference_layers", ",", "\n", "args", ".", "pretrained_file", ",", "\n", "device", ")", "\n", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "random", ".", "seed", "(", "19940117", "+", "dist", ".", "get_rank", "(", ")", ")", "\n", "\n", "", "model", "=", "model", ".", "cuda", "(", "device", ")", "\n", "train_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "train_data", ",", "args", ".", "train_batch_size", ",", "for_train", "=", "True", ")", "\n", "dev_data", "=", "DataLoader", "(", "vocabs", ",", "lexical_mapping", ",", "args", ".", "dev_data", ",", "args", ".", "dev_batch_size", ",", "for_train", "=", "False", ")", "\n", "train_data", ".", "set_unk_rate", "(", "args", ".", "unk_rate", ")", "\n", "\n", "weight_decay_params", "=", "[", "]", "\n", "no_weight_decay_params", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", ".", "endswith", "(", "'bias'", ")", "or", "'layer_norm'", "in", "name", ":", "\n", "            ", "no_weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "weight_decay_params", ".", "append", "(", "param", ")", "\n", "", "", "grouped_params", "=", "[", "{", "'params'", ":", "weight_decay_params", ",", "'weight_decay'", ":", "1e-4", "}", ",", "\n", "{", "'params'", ":", "no_weight_decay_params", ",", "'weight_decay'", ":", "0.", "}", "]", "\n", "optimizer", "=", "AdamWeightDecayOptimizer", "(", "grouped_params", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ")", "\n", "\n", "batches_acm", ",", "loss_acm", "=", "0", ",", "0", "\n", "discarded_batches_acm", "=", "0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "for", "batch", "in", "train_data", ":", "\n", "            ", "batch", "=", "move_to_cuda", "(", "batch", ",", "device", ")", "\n", "loss", "=", "model", "(", "batch", ")", "\n", "loss_value", "=", "loss", ".", "item", "(", ")", "\n", "if", "batches_acm", ">", "args", ".", "warmup_steps", "and", "loss_value", ">", "5.", "*", "(", "loss_acm", "/", "batches_acm", ")", ":", "\n", "                ", "discarded_batches_acm", "+=", "1", "\n", "print", "(", "'abnormal'", ",", "loss_value", ")", "\n", "continue", "\n", "", "loss_acm", "+=", "loss_value", "\n", "batches_acm", "+=", "1", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "                ", "average_gradients", "(", "model", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "update_lr", "(", "optimizer", ",", "args", ".", "embed_dim", ",", "batches_acm", ",", "args", ".", "warmup_steps", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "world_size", "==", "1", "or", "(", "dist", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "                ", "if", "batches_acm", "%", "args", ".", "print_every", "==", "-", "1", "%", "args", ".", "print_every", ":", "\n", "                    ", "print", "(", "'Train Epoch %d, Batch %d, Discarded Batch %d, loss %.3f'", "%", "(", "epoch", ",", "batches_acm", ",", "discarded_batches_acm", ",", "loss_acm", "/", "batches_acm", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "", "if", "batches_acm", ">", "args", ".", "warmup_steps", "and", "batches_acm", "%", "args", ".", "eval_every", "==", "-", "1", "%", "args", ".", "eval_every", ":", "\n", "                    ", "model", ".", "eval", "(", ")", "\n", "bleu", ",", "chrf", "=", "validate", "(", "model", ",", "dev_data", ",", "args", ".", "dev_data", "[", ":", "-", "len", "(", "'.preproc.json'", ")", "]", ")", "\n", "print", "(", "\"epoch\"", ",", "\"batch\"", ",", "\"bleu\"", ",", "\"chrf\"", ")", "\n", "print", "(", "epoch", ",", "batches_acm", ",", "bleu", ",", "chrf", ")", "\n", "torch", ".", "save", "(", "{", "'args'", ":", "args", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", "}", ",", "'%s/epoch%d_batch%d'", "%", "(", "args", ".", "ckpt", ",", "epoch", ",", "batches_acm", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "", "", "", "", "", "def", "init_processes", "(", "args", ",", "local_rank", ",", "backend", "=", "'nccl'", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "args", ".", "MASTER_ADDR", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "args", ".", "MASTER_PORT", "\n", "dist", ".", "init_process_group", "(", "backend", ",", "rank", "=", "args", ".", "start_rank", "+", "local_rank", ",", "world_size", "=", "args", ".", "world_size", ")", "\n", "main", "(", "args", ",", "local_rank", ")", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parse_config", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "ckpt", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "ckpt", ")", "\n", "", "assert", "len", "(", "args", ".", "cnn_filters", ")", "%", "2", "==", "0", "\n", "args", ".", "cnn_filters", "=", "list", "(", "zip", "(", "args", ".", "cnn_filters", "[", ":", "-", "1", ":", "2", "]", ",", "args", ".", "cnn_filters", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "\n", "if", "args", ".", "world_size", "==", "1", ":", "\n", "        ", "main", "(", "args", ",", "0", ")", "\n", "exit", "(", "0", ")", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "/", "args", ".", "world_size", "\n", "processes", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.train.init_processes": [[185, 190], ["torch.init_process_group", "train.main"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.main"], ["for", "rank", "in", "range", "(", "args", ".", "gpus", ")", ":", "\n", "        ", "p", "=", "mp", ".", "Process", "(", "target", "=", "init_processes", ",", "args", "=", "(", "args", ",", "rank", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "processes", ".", "append", "(", "p", ")", "\n", "", "for", "p", "in", "processes", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_characters": [[38, 40], ["list", "line.strip().replace", "line.strip"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["def", "separate_characters", "(", "line", ")", ":", "\n", "    ", "return", "list", "(", "line", ".", "strip", "(", ")", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_punctuation": [[41, 58], ["line.strip().split", "line.strip", "len", "tokenized.append", "tokenized.append"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.postprocess.wikification.strip"], ["", "def", "separate_punctuation", "(", "line", ")", ":", "\n", "    ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "tokenized", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "len", "(", "w", ")", "==", "1", ":", "\n", "            ", "tokenized", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "            ", "lastChar", "=", "w", "[", "-", "1", "]", "\n", "firstChar", "=", "w", "[", "0", "]", "\n", "if", "lastChar", "in", "string", ".", "punctuation", ":", "\n", "                ", "tokenized", "+=", "[", "w", "[", ":", "-", "1", "]", ",", "lastChar", "]", "\n", "", "elif", "firstChar", "in", "string", ".", "punctuation", ":", "\n", "                ", "tokenized", "+=", "[", "firstChar", ",", "w", "[", "1", ":", "]", "]", "\n", "", "else", ":", "\n", "                ", "tokenized", ".", "append", "(", "w", ")", "\n", "\n", "", "", "", "return", "tokenized", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts": [[59, 69], ["collections.defaultdict", "len", "range", "range", "collections.defaultdict", "tuple"], "function", ["None"], ["", "def", "ngram_counts", "(", "wordList", ",", "order", ")", ":", "\n", "    ", "counts", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "float", ")", ")", "\n", "nWords", "=", "len", "(", "wordList", ")", "\n", "for", "i", "in", "range", "(", "nWords", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "order", "+", "1", ")", ":", "\n", "            ", "if", "i", "+", "j", "<=", "nWords", ":", "\n", "                ", "ngram", "=", "tuple", "(", "wordList", "[", "i", ":", "i", "+", "j", "]", ")", "\n", "counts", "[", "j", "-", "1", "]", "[", "ngram", "]", "+=", "1", "\n", "\n", "", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_matches": [[70, 85], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "min"], "function", ["None"], ["", "def", "ngram_matches", "(", "ref_ngrams", ",", "hyp_ngrams", ")", ":", "\n", "    ", "matchingNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "totalRefNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "totalHypNgramCount", "=", "defaultdict", "(", "float", ")", "\n", "\n", "for", "order", "in", "ref_ngrams", ":", "\n", "        ", "for", "ngram", "in", "hyp_ngrams", "[", "order", "]", ":", "\n", "            ", "totalHypNgramCount", "[", "order", "]", "+=", "hyp_ngrams", "[", "order", "]", "[", "ngram", "]", "\n", "", "for", "ngram", "in", "ref_ngrams", "[", "order", "]", ":", "\n", "            ", "totalRefNgramCount", "[", "order", "]", "+=", "ref_ngrams", "[", "order", "]", "[", "ngram", "]", "\n", "if", "ngram", "in", "hyp_ngrams", "[", "order", "]", ":", "\n", "                ", "matchingNgramCount", "[", "order", "]", "+=", "min", "(", "ref_ngrams", "[", "order", "]", "[", "ngram", "]", ",", "hyp_ngrams", "[", "order", "]", "[", "ngram", "]", ")", "\n", "\n", "\n", "", "", "", "return", "matchingNgramCount", ",", "totalRefNgramCount", ",", "totalHypNgramCount", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf": [[87, 110], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "function", ["None"], ["", "def", "ngram_precrecf", "(", "matching", ",", "reflen", ",", "hyplen", ",", "beta", ")", ":", "\n", "    ", "ngramPrec", "=", "defaultdict", "(", "float", ")", "\n", "ngramRec", "=", "defaultdict", "(", "float", ")", "\n", "ngramF", "=", "defaultdict", "(", "float", ")", "\n", "\n", "factor", "=", "beta", "**", "2", "\n", "\n", "for", "order", "in", "matching", ":", "\n", "        ", "if", "hyplen", "[", "order", "]", ">", "0", ":", "\n", "            ", "ngramPrec", "[", "order", "]", "=", "matching", "[", "order", "]", "/", "hyplen", "[", "order", "]", "\n", "", "else", ":", "\n", "            ", "ngramPrec", "[", "order", "]", "=", "1e-16", "\n", "", "if", "reflen", "[", "order", "]", ">", "0", ":", "\n", "            ", "ngramRec", "[", "order", "]", "=", "matching", "[", "order", "]", "/", "reflen", "[", "order", "]", "\n", "", "else", ":", "\n", "            ", "ngramRec", "[", "order", "]", "=", "1e-16", "\n", "", "denom", "=", "factor", "*", "ngramPrec", "[", "order", "]", "+", "ngramRec", "[", "order", "]", "\n", "if", "denom", ">", "0", ":", "\n", "            ", "ngramF", "[", "order", "]", "=", "(", "1", "+", "factor", ")", "*", "ngramPrec", "[", "order", "]", "*", "ngramRec", "[", "order", "]", "/", "denom", "\n", "", "else", ":", "\n", "            ", "ngramF", "[", "order", "]", "=", "1e-16", "\n", "\n", "", "", "return", "ngramF", ",", "ngramRec", ",", "ngramPrec", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.computeChrF": [[111, 195], ["float", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "zip", "chrF++.ngram_precrecf", "chrF++.ngram_precrecf", "chrF++.ngram_counts", "chrF++.ngram_counts", "rline.split", "range", "range", "chrF++.separate_punctuation", "chrF++.separate_characters", "chrF++.ngram_counts", "chrF++.ngram_counts", "chrF++.ngram_matches", "chrF++.ngram_matches", "chrF++.ngram_precrecf", "chrF++.ngram_precrecf", "sentence_level_scores.write", "sum", "sum", "sum", "sum", "sum", "sum", "chrF++.separate_punctuation", "chrF++.separate_characters", "totalChrNgramF.values", "totalNgramF.values", "totalChrNgramRec.values", "totalNgramRec.values", "totalChrNgramPrec.values", "totalNgramPrec.values", "sum", "sum", "sum", "sum", "sum", "sum", "chrNgramRec.values", "ngramRec.values", "chrNgramPrec.values", "ngramPrec.values", "chrNgramF.values", "ngramF.values"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_punctuation", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_characters", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_counts", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_matches", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_matches", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.ngram_precrecf", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_punctuation", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.separate_characters"], ["", "def", "computeChrF", "(", "fpRef", ",", "fpHyp", ",", "nworder", ",", "ncorder", ",", "beta", ",", "sentence_level_scores", "=", "None", ")", ":", "\n", "    ", "norder", "=", "float", "(", "nworder", "+", "ncorder", ")", "\n", "\n", "# initialisation of document level scores", "\n", "totalMatchingCount", "=", "defaultdict", "(", "float", ")", "\n", "totalRefCount", "=", "defaultdict", "(", "float", ")", "\n", "totalHypCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrMatchingCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrRefCount", "=", "defaultdict", "(", "float", ")", "\n", "totalChrHypCount", "=", "defaultdict", "(", "float", ")", "\n", "averageTotalF", "=", "0.0", "\n", "\n", "nsent", "=", "0", "\n", "for", "hline", ",", "rline", "in", "zip", "(", "fpHyp", ",", "fpRef", ")", ":", "\n", "        ", "nsent", "+=", "1", "\n", "\n", "# preparation for multiple references", "\n", "maxF", "=", "0.0", "\n", "bestWordMatchingCount", "=", "None", "\n", "bestCharMatchingCount", "=", "None", "\n", "\n", "hypNgramCounts", "=", "ngram_counts", "(", "separate_punctuation", "(", "hline", ")", ",", "nworder", ")", "\n", "hypChrNgramCounts", "=", "ngram_counts", "(", "separate_characters", "(", "hline", ")", ",", "ncorder", ")", "\n", "\n", "# going through multiple references", "\n", "\n", "refs", "=", "rline", ".", "split", "(", "\"*#\"", ")", "\n", "\n", "for", "ref", "in", "refs", ":", "\n", "            ", "refNgramCounts", "=", "ngram_counts", "(", "separate_punctuation", "(", "ref", ")", ",", "nworder", ")", "\n", "refChrNgramCounts", "=", "ngram_counts", "(", "separate_characters", "(", "ref", ")", ",", "ncorder", ")", "\n", "\n", "# number of overlapping n-grams, total number of ref n-grams, total number of hyp n-grams", "\n", "matchingNgramCounts", ",", "totalRefNgramCount", ",", "totalHypNgramCount", "=", "ngram_matches", "(", "refNgramCounts", ",", "hypNgramCounts", ")", "\n", "matchingChrNgramCounts", ",", "totalChrRefNgramCount", ",", "totalChrHypNgramCount", "=", "ngram_matches", "(", "refChrNgramCounts", ",", "hypChrNgramCounts", ")", "\n", "\n", "# n-gram f-scores, recalls and precisions", "\n", "ngramF", ",", "ngramRec", ",", "ngramPrec", "=", "ngram_precrecf", "(", "matchingNgramCounts", ",", "totalRefNgramCount", ",", "totalHypNgramCount", ",", "beta", ")", "\n", "chrNgramF", ",", "chrNgramRec", ",", "chrNgramPrec", "=", "ngram_precrecf", "(", "matchingChrNgramCounts", ",", "totalChrRefNgramCount", ",", "totalChrHypNgramCount", ",", "beta", ")", "\n", "\n", "sentRec", "=", "(", "sum", "(", "chrNgramRec", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramRec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "sentPrec", "=", "(", "sum", "(", "chrNgramPrec", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramPrec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "sentF", "=", "(", "sum", "(", "chrNgramF", ".", "values", "(", ")", ")", "+", "sum", "(", "ngramF", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "\n", "if", "sentF", ">", "maxF", ":", "\n", "                ", "maxF", "=", "sentF", "\n", "bestMatchingCount", "=", "matchingNgramCounts", "\n", "bestRefCount", "=", "totalRefNgramCount", "\n", "bestHypCount", "=", "totalHypNgramCount", "\n", "bestChrMatchingCount", "=", "matchingChrNgramCounts", "\n", "bestChrRefCount", "=", "totalChrRefNgramCount", "\n", "bestChrHypCount", "=", "totalChrHypNgramCount", "\n", "# all the references are done", "\n", "\n", "\n", "# write sentence level scores", "\n", "", "", "if", "sentence_level_scores", ":", "\n", "            ", "sentence_level_scores", ".", "write", "(", "\"%i::c%i+w%i-F%i\\t%.4f\\n\"", "%", "(", "nsent", ",", "ncorder", ",", "nworder", ",", "beta", ",", "100", "*", "maxF", ")", ")", "\n", "\n", "\n", "# collect document level ngram counts", "\n", "", "for", "order", "in", "range", "(", "nworder", ")", ":", "\n", "            ", "totalMatchingCount", "[", "order", "]", "+=", "bestMatchingCount", "[", "order", "]", "\n", "totalRefCount", "[", "order", "]", "+=", "bestRefCount", "[", "order", "]", "\n", "totalHypCount", "[", "order", "]", "+=", "bestHypCount", "[", "order", "]", "\n", "", "for", "order", "in", "range", "(", "ncorder", ")", ":", "\n", "            ", "totalChrMatchingCount", "[", "order", "]", "+=", "bestChrMatchingCount", "[", "order", "]", "\n", "totalChrRefCount", "[", "order", "]", "+=", "bestChrRefCount", "[", "order", "]", "\n", "totalChrHypCount", "[", "order", "]", "+=", "bestChrHypCount", "[", "order", "]", "\n", "\n", "", "averageTotalF", "+=", "maxF", "\n", "\n", "# all sentences are done", "\n", "\n", "# total precision, recall and F (aritmetic mean of all ngrams)", "\n", "", "totalNgramF", ",", "totalNgramRec", ",", "totalNgramPrec", "=", "ngram_precrecf", "(", "totalMatchingCount", ",", "totalRefCount", ",", "totalHypCount", ",", "beta", ")", "\n", "totalChrNgramF", ",", "totalChrNgramRec", ",", "totalChrNgramPrec", "=", "ngram_precrecf", "(", "totalChrMatchingCount", ",", "totalChrRefCount", ",", "totalChrHypCount", ",", "beta", ")", "\n", "\n", "totalF", "=", "(", "sum", "(", "totalChrNgramF", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramF", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "averageTotalF", "=", "averageTotalF", "/", "nsent", "\n", "totalRec", "=", "(", "sum", "(", "totalChrNgramRec", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramRec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "totalPrec", "=", "(", "sum", "(", "totalChrNgramPrec", ".", "values", "(", ")", ")", "+", "sum", "(", "totalNgramPrec", ".", "values", "(", ")", ")", ")", "/", "norder", "\n", "\n", "return", "totalF", ",", "averageTotalF", ",", "totalPrec", ",", "totalRec", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.main": [[197, 229], ["sys.stdout.write", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "open", "open", "chrF++.computeChrF", "sys.stdout.write", "sys.stdout.write", "sys.stdout.write", "open.close", "open.close", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.translator.chrF++.computeChrF", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close", "home.repos.pwc.inspect_result.jcyk_gtos.token_embedders.embedding.EmbeddingsTextFile.close"], ["", "def", "main", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "\"start_time:\\t%i\\n\"", "%", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "\n", "argParser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argParser", ".", "add_argument", "(", "\"-R\"", ",", "\"--reference\"", ",", "help", "=", "\"reference translation\"", ",", "required", "=", "True", ")", "\n", "argParser", ".", "add_argument", "(", "\"-H\"", ",", "\"--hypothesis\"", ",", "help", "=", "\"hypothesis translation\"", ",", "required", "=", "True", ")", "\n", "argParser", ".", "add_argument", "(", "\"-nc\"", ",", "\"--ncorder\"", ",", "help", "=", "\"character n-gram order (default=6)\"", ",", "type", "=", "int", ",", "default", "=", "6", ")", "\n", "argParser", ".", "add_argument", "(", "\"-nw\"", ",", "\"--nworder\"", ",", "help", "=", "\"word n-gram order (default=2)\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "argParser", ".", "add_argument", "(", "\"-b\"", ",", "\"--beta\"", ",", "help", "=", "\"beta parameter (default=2)\"", ",", "type", "=", "float", ",", "default", "=", "2.0", ")", "\n", "argParser", ".", "add_argument", "(", "\"-s\"", ",", "\"--sent\"", ",", "help", "=", "\"show sentence level scores\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "args", "=", "argParser", ".", "parse_args", "(", ")", "\n", "\n", "rtxt", "=", "open", "(", "args", ".", "reference", ",", "'r'", ")", "\n", "htxt", "=", "open", "(", "args", ".", "hypothesis", ",", "'r'", ")", "\n", "\n", "sentence_level_scores", "=", "None", "\n", "if", "args", ".", "sent", ":", "\n", "        ", "sentence_level_scores", "=", "sys", ".", "stdout", "# Or stderr?", "\n", "\n", "", "totalF", ",", "averageTotalF", ",", "totalPrec", ",", "totalRec", "=", "computeChrF", "(", "rtxt", ",", "htxt", ",", "args", ".", "nworder", ",", "args", ".", "ncorder", ",", "args", ".", "beta", ",", "sentence_level_scores", ")", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "\"c%i+w%i-F%i\\t%.4f\\n\"", "%", "(", "args", ".", "ncorder", ",", "args", ".", "nworder", ",", "args", ".", "beta", ",", "100", "*", "totalF", ")", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"c%i+w%i-avgF%i\\t%.4f\\n\"", "%", "(", "args", ".", "ncorder", ",", "args", ".", "nworder", ",", "args", ".", "beta", ",", "100", "*", "averageTotalF", ")", ")", "\n", "#sys.stdout.write(\"c%i+w%i-Prec\\t%.4f\\n\" % (args.ncorder, args.nworder, 100*totalPrec))", "\n", "#sys.stdout.write(\"c%i+w%i-Rec\\t%.4f\\n\"  % (args.ncorder, args.nworder, 100*totalRec))", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "\"end_time:\\t%i\\n\"", "%", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "htxt", ".", "close", "(", ")", "\n", "rtxt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.decoder.TokenGenerator.__init__": [[11, 21], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "decoder.TokenGenerator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "embed_dim", ",", "token_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "TokenGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alignment_layer", "=", "MultiheadAttention", "(", "embed_dim", ",", "1", ",", "dropout", ",", "weights_dropout", "=", "False", ")", "\n", "self", ".", "alignment_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "transfer", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "token_size", ")", "\n", "self", ".", "generator", "=", "nn", ".", "Linear", "(", "token_size", ",", "vocabs", "[", "'predictable_token'", "]", ".", "size", ")", "\n", "self", ".", "diverter", "=", "nn", ".", "Linear", "(", "token_size", ",", "2", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.decoder.TokenGenerator.reset_parameters": [[22, 29], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "transfer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "diverter", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "diverter", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "transfer", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "generator", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.decoder.TokenGenerator.forward": [[30, 66], ["decoder.TokenGenerator.alignment_layer", "torch.dropout", "torch.dropout", "decoder.TokenGenerator.alignment_layer_norm", "decoder.TokenGenerator.size", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.softmax().chunk", "torch.softmax().chunk", "torch.cat.size", "torch.cat.size", "copy_seq.transpose().contiguous().view().expand", "torch.cat.scatter_add_", "torch.cat.scatter_add_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "token_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "decoder.TokenGenerator.transfer", "torch.softmax", "torch.softmax", "copy_seq.max().item", "torch.cat.new_zeros().expand", "torch.cat.new_zeros().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log.gather().squeeze", "torch.log.gather().squeeze", "torch.softmax", "torch.softmax", "decoder.TokenGenerator.generator", "copy_seq.transpose().contiguous().view", "token_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "decoder.TokenGenerator.diverter", "copy_seq.max", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.log.gather", "torch.log.gather", "copy_seq.transpose().contiguous", "target.unsqueeze", "copy_seq.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "\n", "target", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "        ", "x", ",", "alignment_weight", "=", "self", ".", "alignment_layer", "(", "outs", ",", "graph_state", ",", "graph_state", ",", "\n", "key_padding_mask", "=", "graph_padding_mask", ",", "\n", "need_weights", "=", "True", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "alignment_layer_norm", "(", "outs", "+", "x", ")", "\n", "\n", "seq_len", ",", "bsz", ",", "_", "=", "outs", ".", "size", "(", ")", "\n", "outs_token", "=", "torch", ".", "tanh", "(", "self", ".", "transfer", "(", "outs", ")", ")", "\n", "outs_token", "=", "F", ".", "dropout", "(", "outs_token", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "gen_gate", ",", "copy_gate", "=", "F", ".", "softmax", "(", "self", ".", "diverter", "(", "outs_token", ")", ",", "-", "1", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "probs", "=", "gen_gate", "*", "F", ".", "softmax", "(", "self", ".", "generator", "(", "outs_token", ")", ",", "-", "1", ")", "\n", "\n", "tot_ext", "=", "1", "+", "copy_seq", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "vocab_size", "=", "probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "tot_ext", "-", "vocab_size", ">", "0", ":", "\n", "            ", "ext_probs", "=", "probs", ".", "new_zeros", "(", "(", "1", ",", "1", ",", "tot_ext", "-", "vocab_size", ")", ")", ".", "expand", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "torch", ".", "cat", "(", "[", "probs", ",", "ext_probs", "]", ",", "-", "1", ")", "\n", "\n", "", "index", "=", "copy_seq", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "bsz", ",", "-", "1", ")", ".", "expand", "(", "seq_len", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "copy_probs", "=", "(", "copy_gate", "*", "alignment_weight", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "probs", ".", "scatter_add_", "(", "-", "1", ",", "index", ",", "copy_probs", ")", "\n", "ll", "=", "torch", ".", "log", "(", "probs", "+", "1e-12", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "return", "ll", "\n", "\n", "", "token_loss", "=", "-", "ll", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "token_mask", "=", "torch", ".", "eq", "(", "target", ",", "self", ".", "vocabs", "[", "'predictable_token'", "]", ".", "padding_idx", ")", "\n", "token_loss", "=", "token_loss", ".", "masked_fill_", "(", "token_mask", ",", "0.", ")", ".", "sum", "(", "0", ")", "\n", "return", "token_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.decoder.DecodeLayer.__init__": [[69, 75], ["torch.nn.Module.__init__", "transformer.Transformer", "decoder.TokenGenerator"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "token_size", ",", "rel_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "DecodeLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inference_core", "=", "Transformer", "(", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "True", ")", "\n", "self", ".", "token_generator", "=", "TokenGenerator", "(", "vocabs", ",", "embed_dim", ",", "token_size", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.decoder.DecodeLayer.forward": [[76, 95], ["torch.dropout", "torch.dropout", "decoder.DecodeLayer.inference_core", "decoder.DecodeLayer.token_generator", "decoder.DecodeLayer.mean", "decoder.DecodeLayer.token_generator", "snt_padding_mask.size", "snt_padding_mask.float().sum", "snt_padding_mask.float"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "probe", ",", "graph_state", ",", "snt_state", ",", "\n", "graph_padding_mask", ",", "snt_padding_mask", ",", "attn_mask", ",", "\n", "copy_seq", ",", "target", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "# probe: tgt_len x bsz x embed_dim", "\n", "# snt_state, graph_state: seq_len x bsz x embed_dim", "\n", "\n", "        ", "outs", "=", "F", ".", "dropout", "(", "probe", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "inference_core", "(", "outs", ",", "kv", "=", "snt_state", ",", "\n", "self_padding_mask", "=", "snt_padding_mask", ",", "self_attn_mask", "=", "attn_mask", ",", "\n", "external_memories", "=", "graph_state", ",", "external_padding_mask", "=", "graph_padding_mask", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "concept_ll", "=", "self", ".", "token_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "return", "concept_ll", "\n", "\n", "", "token_loss", "=", "self", ".", "token_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "copy_seq", ",", "target", "=", "target", ",", "work", "=", "False", ")", "\n", "token_tot", "=", "snt_padding_mask", ".", "size", "(", "0", ")", "-", "snt_padding_mask", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "token_loss", "=", "token_loss", "/", "token_tot", "\n", "return", "token_loss", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.__init__": [[14, 35], ["dict", "open().readlines", "dict", "int", "zip", "open", "line.rstrip().split", "int", "idx2token.append", "range", "print", "len", "line.rstrip"], "methods", ["None"], ["        ", "idx2token", "=", "[", "PAD", ",", "UNK", "]", "+", "(", "specials", "if", "specials", "is", "not", "None", "else", "[", "]", ")", "\n", "self", ".", "_priority", "=", "dict", "(", ")", "\n", "num_tot_tokens", "=", "0", "\n", "num_vocab_tokens", "=", "0", "\n", "for", "line", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "token", ",", "cnt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "cnt", "=", "int", "(", "cnt", ")", "\n", "num_tot_tokens", "+=", "cnt", "\n", "", "except", ":", "\n", "                ", "print", "(", "line", ")", "\n", "", "if", "cnt", ">=", "min_occur_cnt", ":", "\n", "                ", "idx2token", ".", "append", "(", "token", ")", "\n", "num_vocab_tokens", "+=", "cnt", "\n", "", "self", ".", "_priority", "[", "token", "]", "=", "int", "(", "cnt", ")", "\n", "", "self", ".", "coverage", "=", "num_vocab_tokens", "/", "num_tot_tokens", "\n", "self", ".", "_token2idx", "=", "dict", "(", "zip", "(", "idx2token", ",", "range", "(", "len", "(", "idx2token", ")", ")", ")", ")", "\n", "self", ".", "_idx2token", "=", "idx2token", "\n", "self", ".", "_padding_idx", "=", "self", ".", "_token2idx", "[", "PAD", "]", "\n", "self", ".", "_unk_idx", "=", "self", ".", "_token2idx", "[", "UNK", "]", "\n", "\n", "", "def", "priority", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.priority": [[36, 38], ["data.Vocab._priority.get"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get"], ["        ", "return", "self", ".", "_priority", ".", "get", "(", "x", ",", "0", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size": [[39, 42], ["len"], "methods", ["None"], ["def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_idx2token", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.unk_idx": [[43, 46], ["None"], "methods", ["None"], ["def", "unk_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_unk_idx", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.padding_idx": [[47, 50], ["None"], "methods", ["None"], ["def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_padding_idx", "\n", "\n", "", "def", "idx2token", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token": [[51, 55], ["isinstance", "data.Vocab.idx2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "idx2token", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_idx2token", "[", "x", "]", "\n", "\n", "", "def", "token2idx", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx": [[56, 60], ["isinstance", "data.Vocab._token2idx.get", "data.Vocab.token2idx"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "token2idx", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_token2idx", ".", "get", "(", "x", ",", "self", ".", "unk_idx", ")", "\n", "\n", "", "", "def", "_back_to_txt_for_check", "(", "tensor", ",", "vocab", ",", "local_idx2token", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.__init__": [[208, 217], ["extract.read_file"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.read_file"], ["                            ", "path", "=", "[", "TL", "]", "\n", "", "path", "=", "tuple", "(", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "path", ")", ")", "\n", "rtype", "=", "all_relations", ".", "get", "(", "path", ",", "len", "(", "all_relations", ")", ")", "\n", "if", "rtype", "==", "len", "(", "all_relations", ")", ":", "\n", "                            ", "all_relations", "[", "path", "]", "=", "len", "(", "all_relations", ")", "\n", "", "all_r", ".", "append", "(", "rtype", ")", "\n", "", "record", ".", "append", "(", "len", "(", "all_r", ")", ")", "\n", "num_paths", "=", "max", "(", "len", "(", "all_r", ")", ",", "num_paths", ")", "\n", "rs", ".", "append", "(", "all_r", ")", "\n", "", "brs", ".", "append", "(", "rs", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.set_unk_rate": [[218, 220], ["None"], "methods", ["None"], ["", "_relation_type", ".", "append", "(", "brs", ")", "\n", "", "bsz", "=", "len", "(", "_relation_type", ")", "\n", "_relation_matrix", "=", "np", ".", "zeros", "(", "(", "bsz", ",", "num_concepts", ",", "num_concepts", ",", "num_paths", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.record": [[221, 223], ["None"], "methods", ["None"], ["for", "b", ",", "x", "in", "enumerate", "(", "_relation_type", ")", ":", "\n", "            ", "for", "i", ",", "y", "in", "enumerate", "(", "x", ")", ":", "\n", "                ", "for", "j", ",", "z", "in", "enumerate", "(", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.DataLoader.__iter__": [[224, 268], ["list", "range", "random.shuffle", "list.sort", "len", "batch.append", "batches.append", "random.shuffle", "graph.collect_concepts_and_relations", "data.DataLoader.lex_map.get", "len", "batches.append", "data.DataLoader.__iter__.work"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.collect_concepts_and_relations", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.work"], ["                    ", "for", "k", ",", "r", "in", "enumerate", "(", "z", ")", ":", "\n", "                        ", "_relation_matrix", "[", "b", ",", "i", ",", "j", ",", "k", "]", "=", "r", "\n", "", "", "", "", "_relation_type", "=", "torch", ".", "from_numpy", "(", "_relation_matrix", ")", ".", "transpose_", "(", "0", ",", "2", ")", ".", "long", "(", ")", "\n", "\n", "B", "=", "len", "(", "all_relations", ")", "\n", "_relation_bank", "=", "dict", "(", ")", "\n", "_relation_length", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "all_relations", ".", "items", "(", ")", ":", "\n", "            ", "_relation_bank", "[", "v", "]", "=", "np", ".", "array", "(", "k", ",", "dtype", "=", "np", ".", "int", ")", "\n", "_relation_length", "[", "v", "]", "=", "len", "(", "k", ")", "\n", "", "_relation_bank", "=", "[", "_relation_bank", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_length", "=", "[", "_relation_length", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_bank", "=", "ArraysToTensor", "(", "_relation_bank", ")", ".", "t_", "(", ")", "\n", "_relation_length", "=", "torch", ".", "LongTensor", "(", "_relation_length", ")", "\n", "\n", "", "local_token2idx", "=", "[", "x", "[", "'token2idx'", "]", "for", "x", "in", "data", "]", "\n", "local_idx2token", "=", "[", "x", "[", "'idx2token'", "]", "for", "x", "in", "data", "]", "\n", "\n", "augmented_token", "=", "[", "[", "STR", "]", "+", "x", "[", "'token'", "]", "+", "[", "END", "]", "for", "x", "in", "data", "]", "\n", "\n", "_token_in", "=", "ListsToTensor", "(", "augmented_token", ",", "vocabs", "[", "'token'", "]", ",", "unk_rate", "=", "unk_rate", ")", "[", ":", "-", "1", "]", "\n", "_token_char_in", "=", "ListsofStringToTensor", "(", "augmented_token", ",", "vocabs", "[", "'token_char'", "]", ")", "[", ":", "-", "1", "]", "\n", "\n", "_token_out", "=", "ListsToTensor", "(", "augmented_token", ",", "vocabs", "[", "'predictable_token'", "]", ",", "local_token2idx", ")", "[", "1", ":", "]", "\n", "_cp_seq", "=", "ListsToTensor", "(", "[", "x", "[", "'cp_seq'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'predictable_token'", "]", ",", "local_token2idx", ")", "\n", "\n", "abstract", "=", "[", "x", "[", "'abstract'", "]", "for", "x", "in", "data", "]", "\n", "\n", "ret", "=", "{", "\n", "'concept'", ":", "_conc", ",", "\n", "'concept_char'", ":", "_conc_char", ",", "\n", "'concept_depth'", ":", "_depth", ",", "\n", "'relation'", ":", "_relation_type", ",", "\n", "'relation_bank'", ":", "_relation_bank", ",", "\n", "'relation_length'", ":", "_relation_length", ",", "\n", "'local_idx2token'", ":", "local_idx2token", ",", "\n", "'local_token2idx'", ":", "local_token2idx", ",", "\n", "'token_in'", ":", "_token_in", ",", "\n", "'token_char_in'", ":", "_token_char_in", ",", "\n", "'token_out'", ":", "_token_out", ",", "\n", "'cp_seq'", ":", "_cp_seq", ",", "\n", "'abstract'", ":", "abstract", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data._back_to_txt_for_check": [[61, 76], ["enumerate", "tensor.t().tolist", "print", "txt.append", "tensor.t", "vocab.idx2token"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["    ", "for", "bid", ",", "xs", "in", "enumerate", "(", "tensor", ".", "t", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "txt", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "            ", "if", "x", "==", "vocab", ".", "padding_idx", ":", "\n", "                ", "break", "\n", "", "if", "x", ">=", "vocab", ".", "size", ":", "\n", "                ", "assert", "local_idx2token", "is", "not", "None", "\n", "assert", "local_idx2token", "[", "bid", "]", "is", "not", "None", "\n", "tok", "=", "local_idx2token", "[", "bid", "]", "[", "x", "]", "\n", "", "else", ":", "\n", "                ", "tok", "=", "vocab", ".", "idx2token", "(", "x", ")", "\n", "", "txt", ".", "append", "(", "tok", ")", "\n", "", "txt", "=", "' '", ".", "join", "(", "txt", ")", "\n", "print", "(", "txt", ")", "\n", "\n", "", "", "def", "ListsToTensor", "(", "xs", ",", "vocab", "=", "None", ",", "local_vocabs", "=", "None", ",", "unk_rate", "=", "0.", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor": [[77, 100], ["max", "enumerate", "numpy.transpose", "isinstance", "vocab.token2idx", "ys.append", "numpy.array", "random.random", "len", "data.ListsToTensor.toIdx"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["    ", "pad", "=", "vocab", ".", "padding_idx", "if", "vocab", "else", "0", "\n", "\n", "def", "toIdx", "(", "w", ",", "i", ")", ":", "\n", "        ", "if", "vocab", "is", "None", ":", "\n", "            ", "return", "w", "\n", "", "if", "isinstance", "(", "w", ",", "list", ")", ":", "\n", "            ", "return", "[", "toIdx", "(", "_", ",", "i", ")", "for", "_", "in", "w", "]", "\n", "", "if", "random", ".", "random", "(", ")", "<", "unk_rate", ":", "\n", "            ", "return", "vocab", ".", "unk_idx", "\n", "", "if", "local_vocabs", "is", "not", "None", ":", "\n", "            ", "local_vocab", "=", "local_vocabs", "[", "i", "]", "\n", "if", "(", "local_vocab", "is", "not", "None", ")", "and", "(", "w", "in", "local_vocab", ")", ":", "\n", "                ", "return", "local_vocab", "[", "w", "]", "\n", "", "", "return", "vocab", ".", "token2idx", "(", "w", ")", "\n", "\n", "", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "y", "=", "toIdx", "(", "x", ",", "i", ")", "+", "[", "pad", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "ys", ".", "append", "(", "y", ")", "\n", "", "data", "=", "torch", ".", "LongTensor", "(", "ys", ")", ".", "t_", "(", ")", ".", "contiguous", "(", ")", "\n", "return", "data", "\n", "\n", "", "def", "ListsofStringToTensor", "(", "xs", ",", "vocab", ",", "max_string_len", "=", "20", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor": [[101, 114], ["max", "numpy.transpose", "ys.append", "numpy.array", "len", "list", "zs.append", "len", "vocab.token2idx", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["    ", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "        ", "y", "=", "x", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "zs", "=", "[", "]", "\n", "for", "z", "in", "y", ":", "\n", "            ", "z", "=", "list", "(", "z", "[", ":", "max_string_len", "]", ")", "\n", "zs", ".", "append", "(", "vocab", ".", "token2idx", "(", "[", "STR", "]", "+", "z", "+", "[", "END", "]", ")", "+", "[", "vocab", ".", "padding_idx", "]", "*", "(", "max_string_len", "-", "len", "(", "z", ")", ")", ")", "\n", "", "ys", ".", "append", "(", "zs", ")", "\n", "\n", "", "data", "=", "torch", ".", "LongTensor", "(", "ys", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "data", "\n", "\n", "", "def", "ArraysToTensor", "(", "xs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor": [[115, 126], ["numpy.array", "numpy.zeros", "enumerate", "list", "list", "tuple", "list", "len", "np.array.max", "slice", "slice"], "function", ["None"], ["    ", "\"list of numpy array, each has the same demonsionality\"", "\n", "x", "=", "np", ".", "array", "(", "[", "list", "(", "x", ".", "shape", ")", "for", "x", "in", "xs", "]", ")", "\n", "shape", "=", "[", "len", "(", "xs", ")", "]", "+", "list", "(", "x", ".", "max", "(", "axis", "=", "0", ")", ")", "\n", "data", "=", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "slicing_shape", "=", "list", "(", "x", ".", "shape", ")", "\n", "slices", "=", "tuple", "(", "[", "slice", "(", "i", ",", "i", "+", "1", ")", "]", "+", "[", "slice", "(", "0", ",", "x", ")", "for", "x", "in", "slicing_shape", "]", ")", "\n", "data", "[", "slices", "]", "=", "x", "\n", "tensor", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "long", "(", ")", "\n", "", "return", "tensor", "\n", "\n", "", "def", "batchify", "(", "data", ",", "vocabs", ",", "unk_rate", "=", "0.", ",", "train", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.batchify": [[127, 206], ["data.ListsToTensor", "data.ListsofStringToTensor", "data.ListsToTensor", "dict", "vocabs[].token2idx", "vocabs[].token2idx", "vocabs[].token2idx", "enumerate", "numpy.transpose", "len", "dict", "dict", "dict.items", "numpy.transpose", "numpy.array", "data.ListsToTensor", "len", "range", "numpy.stack", "np.transpose.append", "data.ArraysToTensor", "numpy.array", "len", "data.ArraysToTensor", "data.ListsToTensor", "data.ListsofStringToTensor", "data.ListsToTensor", "tuple", "tuple", "tuple", "range", "numpy.array", "np.stack.append", "range", "range", "tuple", "dict.get", "np.array.append", "len", "len", "random.choice", "len", "len", "vocabs[].token2idx", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ArraysToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["    ", "_conc", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'concept'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'concept'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_conc_char", "=", "ListsofStringToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'concept'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'concept_char'", "]", ")", "\n", "_depth", "=", "ListsToTensor", "(", "[", "[", "0", "]", "+", "x", "[", "'depth'", "]", "for", "x", "in", "data", "]", ")", "\n", "\n", "\n", "if", "train", ":", "\n", "\n", "        ", "all_relations", "=", "dict", "(", ")", "\n", "cls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "CLS", ")", "\n", "rcls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "rCLS", ")", "\n", "self_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "SEL", ")", "\n", "all_relations", "[", "tuple", "(", "[", "cls_idx", "]", ")", "]", "=", "0", "\n", "all_relations", "[", "tuple", "(", "[", "rcls_idx", "]", ")", "]", "=", "1", "\n", "all_relations", "[", "tuple", "(", "[", "self_idx", "]", ")", "]", "=", "2", "\n", "\n", "_relation_type", "=", "[", "]", "\n", "for", "bidx", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "n", "=", "len", "(", "x", "[", "'concept'", "]", ")", "\n", "brs", "=", "[", "[", "2", "]", "+", "[", "0", "]", "*", "(", "n", ")", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "rs", "=", "[", "1", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                    ", "all_path", "=", "x", "[", "'relation'", "]", "[", "str", "(", "i", ")", "]", "[", "str", "(", "j", ")", "]", "\n", "path", "=", "random", ".", "choice", "(", "all_path", ")", "[", "'edge'", "]", "\n", "if", "len", "(", "path", ")", "==", "0", ":", "# self loop", "\n", "                        ", "path", "=", "[", "SEL", "]", "\n", "", "if", "len", "(", "path", ")", ">", "8", ":", "# too long distance", "\n", "                        ", "path", "=", "[", "TL", "]", "\n", "", "path", "=", "tuple", "(", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "path", ")", ")", "\n", "rtype", "=", "all_relations", ".", "get", "(", "path", ",", "len", "(", "all_relations", ")", ")", "\n", "if", "rtype", "==", "len", "(", "all_relations", ")", ":", "\n", "                        ", "all_relations", "[", "path", "]", "=", "len", "(", "all_relations", ")", "\n", "", "rs", ".", "append", "(", "rtype", ")", "\n", "", "rs", "=", "np", ".", "array", "(", "rs", ",", "dtype", "=", "np", ".", "int", ")", "\n", "brs", ".", "append", "(", "rs", ")", "\n", "", "brs", "=", "np", ".", "stack", "(", "brs", ")", "\n", "_relation_type", ".", "append", "(", "brs", ")", "\n", "", "_relation_type", "=", "ArraysToTensor", "(", "_relation_type", ")", ".", "transpose_", "(", "0", ",", "2", ")", "\n", "# _relation_bank[_relation_type[i][j][b]] => from j to i go through what ", "\n", "\n", "B", "=", "len", "(", "all_relations", ")", "\n", "_relation_bank", "=", "dict", "(", ")", "\n", "_relation_length", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "all_relations", ".", "items", "(", ")", ":", "\n", "            ", "_relation_bank", "[", "v", "]", "=", "np", ".", "array", "(", "k", ",", "dtype", "=", "np", ".", "int", ")", "\n", "_relation_length", "[", "v", "]", "=", "len", "(", "k", ")", "\n", "", "_relation_bank", "=", "[", "_relation_bank", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_length", "=", "[", "_relation_length", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "all_relations", ")", ")", "]", "\n", "_relation_bank", "=", "ArraysToTensor", "(", "_relation_bank", ")", ".", "t_", "(", ")", "\n", "_relation_length", "=", "torch", ".", "LongTensor", "(", "_relation_length", ")", "\n", "", "else", ":", "\n", "        ", "all_relations", "=", "dict", "(", ")", "\n", "cls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "CLS", ")", "\n", "rcls_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "rCLS", ")", "\n", "self_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "SEL", ")", "\n", "pad_idx", "=", "vocabs", "[", "'relation'", "]", ".", "token2idx", "(", "PAD", ")", "\n", "all_relations", "[", "tuple", "(", "[", "pad_idx", "]", ")", "]", "=", "0", "\n", "all_relations", "[", "tuple", "(", "[", "cls_idx", "]", ")", "]", "=", "1", "\n", "all_relations", "[", "tuple", "(", "[", "rcls_idx", "]", ")", "]", "=", "2", "\n", "all_relations", "[", "tuple", "(", "[", "self_idx", "]", ")", "]", "=", "3", "\n", "\n", "_relation_type", "=", "[", "]", "\n", "record", "=", "[", "]", "\n", "bsz", ",", "num_concepts", ",", "num_paths", "=", "0", ",", "0", ",", "0", "\n", "for", "bidx", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "n", "=", "len", "(", "x", "[", "'concept'", "]", ")", "\n", "num_concepts", "=", "max", "(", "n", "+", "1", ",", "num_concepts", ")", "\n", "brs", "=", "[", "[", "[", "3", "]", "]", "+", "[", "[", "1", "]", "]", "*", "(", "n", ")", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "rs", "=", "[", "[", "2", "]", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                    ", "all_r", "=", "[", "]", "\n", "all_path", "=", "x", "[", "'relation'", "]", "[", "str", "(", "i", ")", "]", "[", "str", "(", "j", ")", "]", "\n", "path0", "=", "all_path", "[", "0", "]", "[", "'edge'", "]", "\n", "if", "len", "(", "path0", ")", "==", "0", "or", "len", "(", "path0", ")", ">", "8", ":", "\n", "                        ", "all_path", "=", "all_path", "[", ":", "1", "]", "\n", "", "for", "path", "in", "all_path", ":", "\n", "                        ", "path", "=", "path", "[", "'edge'", "]", "\n", "if", "len", "(", "path", ")", "==", "0", ":", "# self loop", "\n", "                            ", "path", "=", "[", "SEL", "]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.parse_config": [[269, 283], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "class", "DataLoader", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "lex_map", ",", "filename", ",", "batch_size", ",", "for_train", ")", ":", "\n", "        ", "self", ".", "data", "=", "json", ".", "load", "(", "open", "(", "filename", ",", "encoding", "=", "'utf8'", ")", ")", "\n", "for", "d", "in", "self", ".", "data", ":", "\n", "            ", "cp_seq", ",", "token2idx", ",", "idx2token", "=", "lex_map", ".", "get", "(", "d", "[", "'concept'", "]", ",", "vocabs", "[", "'predictable_token'", "]", ")", "\n", "d", "[", "'cp_seq'", "]", "=", "cp_seq", "\n", "d", "[", "'token2idx'", "]", "=", "token2idx", "\n", "d", "[", "'idx2token'", "]", "=", "idx2token", "\n", "", "print", "(", "\"Get %d AMR-English pairs from %s\"", "%", "(", "len", "(", "self", ".", "data", ")", ",", "filename", ")", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "train", "=", "for_train", "\n", "self", ".", "unk_rate", "=", "0.", "\n", "self", ".", "record_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.__init__": [[15, 48], ["torch.nn.Module.__init__", "encoder.TokenEncoder", "encoder.RelationEncoder", "encoder.TokenEncoder", "graph_transformer.GraphTransformer", "transformer.Transformer", "math.sqrt", "transformer.SinusoidalPositionalEmbedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.SelfAttentionMask", "decoder.DecodeLayer", "torch.nn.Linear", "torch.nn.Linear", "generator.Generator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["word_char_dim", ",", "word_dim", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "char2concept_dim", ",", "\n", "rel_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "\n", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "\n", "snt_layers", ",", "graph_layers", ",", "inference_layers", ",", "\n", "pretrained_file", ",", "device", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "concept_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'concept'", "]", ",", "vocabs", "[", "'concept_char'", "]", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2concept_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "self", ".", "relation_encoder", "=", "RelationEncoder", "(", "vocabs", "[", "'relation'", "]", ",", "rel_dim", ",", "embed_dim", ",", "rnn_hidden_size", ",", "rnn_num_layers", ",", "dropout", ")", "\n", "self", ".", "token_encoder", "=", "TokenEncoder", "(", "vocabs", "[", "'token'", "]", ",", "vocabs", "[", "'token_char'", "]", ",", "\n", "word_char_dim", ",", "word_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "\n", "self", ".", "graph_encoder", "=", "GraphTransformer", "(", "graph_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "snt_encoder", "=", "Transformer", "(", "snt_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "True", ")", "\n", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "token_position", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ",", "device", ")", "\n", "self", ".", "concept_depth", "=", "nn", ".", "Embedding", "(", "32", ",", "embed_dim", ")", "\n", "self", ".", "token_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "concept_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "self_attn_mask", "=", "SelfAttentionMask", "(", "device", ")", "\n", "self", ".", "decoder", "=", "DecodeLayer", "(", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "concept_dim", ",", "rel_dim", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "probe_generator", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.reset_parameters": [[49, 53], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "probe_generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "probe_generator", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "concept_depth", ".", "weight", ",", "0.", ")", "\n", "\n", "", "def", "encoder_attn", "(", "self", ",", "inp", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encoder_attn": [[54, 66], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "generator.Generator.concept_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.relation_encoder", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select().contiguous().view", "generator.Generator.graph_encoder.get_attn_weights", "generator.Generator.concept_depth", "generator.Generator.concept_encoder", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select().contiguous", "inp[].size", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select", "inp[].contiguous().view", "inp[].contiguous"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.graph_transformer.GraphTransformer.get_attn_weights", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "inp", "[", "'concept'", "]", ",", "inp", "[", "'concept_char'", "]", ")", "+", "self", ".", "concept_depth", "(", "inp", "[", "'concept_depth'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "inp", "[", "'concept'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "\n", "relation", "=", "self", ".", "relation_encoder", "(", "inp", "[", "'relation_bank'", "]", ",", "inp", "[", "'relation_length'", "]", ")", "\n", "relation", "[", "0", ",", ":", "]", "=", "0.", "\n", "relation", "=", "relation", "[", "inp", "[", "'relation'", "]", "]", "\n", "sum_relation", "=", "relation", ".", "sum", "(", "dim", "=", "3", ")", "\n", "num_valid_paths", "=", "inp", "[", "'relation'", "]", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "3", ")", ".", "clamp_", "(", "min", "=", "1", ")", "\n", "divisor", "=", "(", "num_valid_paths", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "sum_relation", ")", "\n", "relation", "=", "sum_relation", "/", "divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encode_step": [[67, 81], ["generator.Generator.concept_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.relation_encoder", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select().contiguous().view", "generator.Generator.graph_encoder", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "generator.Generator.concept_depth", "generator.Generator.probe_generator", "generator.Generator.concept_encoder", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select().contiguous", "inp[].size", "relation.index_select().contiguous().view.index_select().contiguous().view.index_select", "inp[].contiguous().view", "inp[].contiguous"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["attn", "=", "self", ".", "graph_encoder", ".", "get_attn_weights", "(", "concept_repr", ",", "relation", ",", "self_padding_mask", "=", "concept_mask", ")", "\n", "# nlayers x tgt_len x src_len x  bsz x num_heads", "\n", "", "return", "attn", "\n", "\n", "", "def", "encode_step", "(", "self", ",", "inp", ",", "train", "=", "True", ")", ":", "\n", "        ", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "inp", "[", "'concept'", "]", ",", "inp", "[", "'concept_char'", "]", ")", "+", "self", ".", "concept_depth", "(", "inp", "[", "'concept_depth'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "inp", "[", "'concept'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "\n", "relation", "=", "self", ".", "relation_encoder", "(", "inp", "[", "'relation_bank'", "]", ",", "inp", "[", "'relation_length'", "]", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "relation", "=", "relation", ".", "index_select", "(", "0", ",", "inp", "[", "'relation'", "]", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "*", "inp", "[", "'relation'", "]", ".", "size", "(", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "#pick = inp['relation'][:,:,:,0]", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.work": [[82, 97], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "generator.Generator.encode_step", "search.Hypothesis", "concept_repr.size", "search.search_by_batch", "search.Beam", "range"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encode_step", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.search_by_batch"], ["#relation = relation.index_select(0, pick.view(-1)).view(*pick.size(), -1)", "\n", "            ", "relation", "[", "0", ",", ":", "]", "=", "0.", "\n", "relation", "=", "relation", "[", "inp", "[", "'relation'", "]", "]", "# i x j x bsz x num x dim", "\n", "sum_relation", "=", "relation", ".", "sum", "(", "dim", "=", "3", ")", "# i x j x bsz x dim", "\n", "num_valid_paths", "=", "inp", "[", "'relation'", "]", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "3", ")", ".", "clamp_", "(", "min", "=", "1", ")", "# i x j x bsz ", "\n", "divisor", "=", "(", "num_valid_paths", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "sum_relation", ")", "\n", "relation", "=", "sum_relation", "/", "divisor", "\n", "\n", "", "concept_repr", "=", "self", ".", "graph_encoder", "(", "concept_repr", ",", "relation", ",", "self_padding_mask", "=", "concept_mask", ")", "\n", "\n", "probe", "=", "torch", ".", "tanh", "(", "self", ".", "probe_generator", "(", "concept_repr", "[", ":", "1", "]", ")", ")", "\n", "concept_repr", "=", "concept_repr", "[", "1", ":", "]", "\n", "concept_mask", "=", "concept_mask", "[", "1", ":", "]", "\n", "return", "concept_repr", ",", "concept_mask", ",", "probe", "\n", "\n", "", "def", "work", "(", "self", ",", "data", ",", "beam_size", ",", "max_time_step", ",", "min_time_step", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.prepare_incremental_input": [[99, 104], ["data.ListsToTensor", "data.ListsofStringToTensor", "utils.move_to_device", "utils.move_to_device"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.ListsofStringToTensor", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device"], ["            ", "concept_repr", ",", "concept_mask", ",", "probe", "=", "self", ".", "encode_step", "(", "data", ",", "train", "=", "False", ")", "\n", "\n", "mem_dict", "=", "{", "'graph_state'", ":", "concept_repr", ",", "\n", "'graph_padding_mask'", ":", "concept_mask", ",", "\n", "'probe'", ":", "probe", ",", "\n", "'local_idx2token'", ":", "data", "[", "'local_idx2token'", "]", ",", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.decode_step": [[105, 153], ["graph_repr.size", "generator.Generator.token_embed_layer_norm", "enumerate", "generator.Generator.decoder", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "zip", "generator.Generator.token_position", "layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "generator.Generator.vocabs[].idx2token", "generator.Generator.squeeze", "topk_scores.tolist", "topk_token.tolist", "zip", "results.append", "generator.Generator.token_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "res.append", "generator.Generator.decode_step.idx2token"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.idx2token"], ["'cp_seq'", ":", "data", "[", "'cp_seq'", "]", "}", "\n", "init_state_dict", "=", "{", "}", "\n", "init_hyp", "=", "Hypothesis", "(", "init_state_dict", ",", "[", "STR", "]", ",", "0.", ")", "\n", "bsz", "=", "concept_repr", ".", "size", "(", "1", ")", "\n", "beams", "=", "[", "Beam", "(", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "[", "init_hyp", "]", ",", "self", ".", "device", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "search_by_batch", "(", "self", ",", "beams", ",", "mem_dict", ")", "\n", "", "return", "beams", "\n", "\n", "\n", "", "def", "prepare_incremental_input", "(", "self", ",", "step_seq", ")", ":", "\n", "        ", "token", "=", "ListsToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'token'", "]", ")", "\n", "token_char", "=", "ListsofStringToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'token_char'", "]", ")", "\n", "token", ",", "token_char", "=", "token", ".", "cuda", "(", "self", ".", "device", ")", ",", "token_char", ".", "cuda", "(", "self", ".", "device", ")", "\n", "return", "token", ",", "token_char", "\n", "\n", "", "def", "decode_step", "(", "self", ",", "inp", ",", "state_dict", ",", "mem_dict", ",", "offset", ",", "topk", ")", ":", "\n", "        ", "step_token", ",", "step_token_char", "=", "inp", "\n", "graph_repr", "=", "mem_dict", "[", "'graph_state'", "]", "\n", "graph_padding_mask", "=", "mem_dict", "[", "'graph_padding_mask'", "]", "\n", "probe", "=", "mem_dict", "[", "'probe'", "]", "\n", "copy_seq", "=", "mem_dict", "[", "'cp_seq'", "]", "\n", "local_vocabs", "=", "mem_dict", "[", "'local_idx2token'", "]", "\n", "_", ",", "bsz", ",", "_", "=", "graph_repr", ".", "size", "(", ")", "\n", "\n", "new_state_dict", "=", "{", "}", "\n", "\n", "token_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "token_encoder", "(", "step_token", ",", "step_token_char", ")", "+", "self", ".", "token_position", "(", "step_token", ",", "offset", ")", "\n", "token_repr", "=", "self", ".", "token_embed_layer_norm", "(", "token_repr", ")", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "snt_encoder", ".", "layers", ")", ":", "\n", "            ", "name_i", "=", "'token_repr_%d'", "%", "idx", "\n", "if", "name_i", "in", "state_dict", ":", "\n", "                ", "prev_token_repr", "=", "state_dict", "[", "name_i", "]", "\n", "new_token_repr", "=", "torch", ".", "cat", "(", "[", "prev_token_repr", ",", "token_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "new_token_repr", "=", "token_repr", "\n", "\n", "", "new_state_dict", "[", "name_i", "]", "=", "new_token_repr", "\n", "token_repr", ",", "_", ",", "_", "=", "layer", "(", "token_repr", ",", "kv", "=", "new_token_repr", ",", "external_memories", "=", "graph_repr", ",", "external_padding_mask", "=", "graph_padding_mask", ")", "\n", "", "name", "=", "'token_state'", "\n", "if", "name", "in", "state_dict", ":", "\n", "            ", "prev_token_state", "=", "state_dict", "[", "name", "]", "\n", "new_token_state", "=", "torch", ".", "cat", "(", "[", "prev_token_state", ",", "token_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "new_token_state", "=", "token_repr", "\n", "", "new_state_dict", "[", "name", "]", "=", "new_token_state", "\n", "LL", "=", "self", ".", "decoder", "(", "probe", ",", "graph_repr", ",", "new_token_state", ",", "graph_padding_mask", ",", "None", ",", "None", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "\n", "\n", "def", "idx2token", "(", "idx", ",", "local_vocab", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.forward": [[154, 168], ["generator.Generator.encode_step", "generator.Generator.token_embed_layer_norm", "torch.dropout", "torch.dropout", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "generator.Generator.self_attn_mask", "generator.Generator.snt_encoder", "probe.expand_as.expand_as.expand_as", "generator.Generator.decoder", "generator.Generator.token_position", "data[].size", "generator.Generator.token_encoder"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encode_step", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["            ", "if", "idx", "in", "local_vocab", ":", "\n", "                ", "return", "local_vocab", "[", "idx", "]", "\n", "", "return", "self", ".", "vocabs", "[", "'predictable_token'", "]", ".", "idx2token", "(", "idx", ")", "\n", "\n", "", "topk_scores", ",", "topk_token", "=", "torch", ".", "topk", "(", "LL", ".", "squeeze", "(", "0", ")", ",", "topk", ",", "1", ")", "# bsz x k", "\n", "\n", "results", "=", "[", "]", "\n", "for", "s", ",", "t", ",", "local_vocab", "in", "zip", "(", "topk_scores", ".", "tolist", "(", ")", ",", "topk_token", ".", "tolist", "(", ")", ",", "local_vocabs", ")", ":", "\n", "            ", "res", "=", "[", "]", "\n", "for", "score", ",", "token", "in", "zip", "(", "s", ",", "t", ")", ":", "\n", "                ", "res", ".", "append", "(", "(", "idx2token", "(", "token", ",", "local_vocab", ")", ",", "score", ")", ")", "\n", "", "results", ".", "append", "(", "res", ")", "\n", "\n", "", "return", "new_state_dict", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.postprocess.PostProcess.__init__": [[5, 7], ["None"], "methods", ["None"], ["\n", "class", "PostProcess", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.postprocess.PostProcess.post_process": [[8, 10], ["re.sub"], "methods", ["None"], ["    ", "month_map", "=", "{", "\n", "1", ":", "'January'", ",", "\n", "2", ":", "'February'", ",", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.postprocess.parse_config": [[11, 19], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["3", ":", "'March'", ",", "\n", "4", ":", "'April'", ",", "\n", "5", ":", "'May'", ",", "\n", "6", ":", "'June'", ",", "\n", "7", ":", "'July'", ",", "\n", "8", ":", "'August'", ",", "\n", "9", ":", "'September'", ",", "\n", "10", ":", "'October'", ",", "\n", "11", ":", "'November'", ",", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.record.parse_config": [[12, 22], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--output_suffix'", ",", "type", "=", "str", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.record.record_batch": [[23, 32], ["utils.move_to_device", "model.encoder_attn", "enumerate", "attn[].cpu", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.encoder_attn"], ["", "def", "record_batch", "(", "model", ",", "batch", ",", "data", ")", ":", "\n", "    ", "batch", "=", "move_to_cuda", "(", "batch", ",", "model", ".", "device", ")", "\n", "attn", "=", "model", ".", "encoder_attn", "(", "batch", ")", "\n", "#nlayers x tgt_len x src_len x  bsz x num_heads", "\n", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "L", "=", "len", "(", "x", "[", "'concept'", "]", ")", "+", "1", "\n", "x", "[", "'attn'", "]", "=", "attn", "[", ":", ",", ":", "L", ",", ":", "L", ",", "i", ",", ":", "]", ".", "cpu", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Hypothesis.__init__": [[13, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "state_dict", ",", "seq", ",", "score", ")", ":", "\n", "#state_dict: hidden states of the last step (has not yet consider seq[-1])", "\n", "#seq: current generated sequence", "\n", "#score: accumlated score so far", "\n", "        ", "self", ".", "state_dict", "=", "state_dict", "\n", "self", ".", "seq", "=", "seq", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Hypothesis.is_completed": [[21, 28], ["None"], "methods", ["None"], ["", "def", "is_completed", "(", "self", ")", ":", "\n", "###########", "\n", "##rewrite##", "\n", "###########", "\n", "        ", "if", "self", ".", "seq", "[", "-", "1", "]", "==", "END", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Hypothesis.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.__init__": [[34, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "hypotheses", ",", "device", ")", ":", "\n", "# hypotheses are the collection of alive hypotheses", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "min_time_step", "=", "min_time_step", "\n", "self", ".", "max_time_step", "=", "max_time_step", "\n", "self", ".", "completed_hypotheses", "=", "[", "]", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "hypotheses", "=", "hypotheses", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.merge_score": [[44, 56], ["float"], "methods", ["None"], ["", "def", "merge_score", "(", "self", ",", "prev_hyp", ",", "step", ")", ":", "\n", "# step has two attributes: token and score", "\n", "###########", "\n", "##rewrite##", "\n", "###########", "\n", "        ", "token", ",", "score", "=", "step", "\n", "prefix", "=", "prev_hyp", ".", "seq", "\n", "\n", "if", "token", "==", "UNK", ":", "\n", "            ", "return", "float", "(", "'-inf'", ")", "\n", "", "new_score", "=", "prev_hyp", ".", "score", "+", "score", "\n", "return", "new_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.update": [[57, 93], ["enumerate", "candidates.sort", "torch.tensor().cuda", "dict", "new_states.items", "enumerate", "len", "v.index_select().split", "dict", "dict.items", "new_hyps.append", "hyp.is_completed", "search.Beam.merge_score", "candidates.append", "torch.tensor", "search.Hypothesis", "search.Beam.hypotheses.append", "len", "v.index_select", "search.Beam.completed_hypotheses.append", "v.size", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Hypothesis.is_completed", "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.merge_score", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "update", "(", "self", ",", "new_states", ",", "last_steps", ")", ":", "\n", "# last_steps: list (#num_hypotheses) of list (#beam_size) of (token, score) ", "\n", "        ", "candidates", "=", "[", "]", "\n", "for", "prev_hyp_idx", ",", "steps", "in", "enumerate", "(", "last_steps", ")", ":", "\n", "            ", "for", "step", "in", "steps", ":", "\n", "                ", "token", "=", "step", "[", "0", "]", "\n", "score", "=", "self", ".", "merge_score", "(", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ",", "step", ")", "\n", "candidates", ".", "append", "(", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", ")", "\n", "\n", "", "", "candidates", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "live_nyp_num", "=", "self", ".", "beam_size", "-", "len", "(", "self", ".", "completed_hypotheses", ")", "\n", "candidates", "=", "candidates", "[", ":", "live_nyp_num", "]", "\n", "# candidates: list of triples (prev_hyp_idx, token, score)", "\n", "\n", "new_hyps", "=", "[", "]", "\n", "_prev_hyp_idx", "=", "torch", ".", "tensor", "(", "[", "x", "[", "0", "]", "for", "x", "in", "candidates", "]", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "_split_state", "=", "dict", "(", ")", "# key => list", "\n", "for", "k", ",", "v", "in", "new_states", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "_split_state", "[", "k", "]", "=", "v", ".", "index_select", "(", "split_dim", ",", "_prev_hyp_idx", ")", ".", "split", "(", "1", ",", "dim", "=", "split_dim", ")", "\n", "\n", "", "for", "idx", ",", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", "in", "enumerate", "(", "candidates", ")", ":", "\n", "            ", "state", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "_split_state", ".", "items", "(", ")", ":", "\n", "                ", "state", "[", "k", "]", "=", "_split_state", "[", "k", "]", "[", "idx", "]", "\n", "", "seq", "=", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ".", "seq", "+", "[", "token", "]", "\n", "new_hyps", ".", "append", "(", "Hypothesis", "(", "state", ",", "seq", ",", "score", ")", ")", "\n", "\n", "", "self", ".", "hypotheses", "=", "[", "]", "\n", "for", "hyp", "in", "new_hyps", ":", "\n", "            ", "if", "hyp", ".", "is_completed", "(", ")", ":", "\n", "                ", "if", "len", "(", "hyp", ")", "-", "2", ">=", "self", ".", "min_time_step", ":", "\n", "                    ", "self", ".", "completed_hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "self", ".", "steps", "+=", "1", "\n", "#self.print_everything()", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.completed": [[95, 99], ["len"], "methods", ["None"], ["", "def", "completed", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "<", "self", ".", "beam_size", "and", "self", ".", "steps", "<", "self", ".", "max_time_step", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.get_k_best": [[100, 105], ["search.Beam.completed_hypotheses.sort", "len", "len"], "methods", ["None"], ["", "def", "get_k_best", "(", "self", ",", "k", ",", "alpha", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "==", "0", ":", "\n", "            ", "self", ".", "completed_hypotheses", "=", "self", ".", "hypotheses", "\n", "", "self", ".", "completed_hypotheses", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "score", "/", "(", "(", "1", "+", "len", "(", "x", ".", "seq", ")", ")", "**", "alpha", ")", ",", "reverse", "=", "True", ")", "\n", "return", "self", ".", "completed_hypotheses", "[", ":", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.Beam.print_everything": [[106, 113], ["print", "print", "print", "print"], "methods", ["None"], ["", "def", "print_everything", "(", "self", ")", ":", "\n", "        ", "print", "(", "'alive:'", ")", "\n", "for", "x", "in", "self", ".", "hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "", "print", "(", "'completed:'", ")", "\n", "for", "x", "in", "self", ".", "completed_hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.search.search_by_batch": [[114, 169], ["model.prepare_incremental_input", "dict", "dict.items", "enumerate", "torch.tensor().cuda", "search.search_by_batch.ready_to_submit"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.generator.Generator.prepare_incremental_input", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items"], ["", "", "", "def", "search_by_batch", "(", "model", ",", "beams", ",", "mem_dict", ")", ":", "\n", "\n", "    ", "def", "ready_to_submit", "(", "hypotheses", ")", ":", "\n", "        ", "inp", "=", "model", ".", "prepare_incremental_input", "(", "[", "hyp", ".", "seq", "[", "-", "1", ":", "]", "for", "hyp", "in", "hypotheses", "]", ")", "\n", "concat_hyps", "=", "dict", "(", ")", "\n", "for", "hyp", "in", "hypotheses", ":", "\n", "            ", "for", "k", ",", "v", "in", "hyp", ".", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "concat_hyps", ".", "get", "(", "k", ",", "[", "]", ")", "+", "[", "v", "]", "\n", "", "", "for", "k", ",", "v", "in", "concat_hyps", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "v", "[", "0", "]", ".", "size", "(", ")", ")", ">=", "3", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "0", ")", "\n", "", "", "return", "concat_hyps", ",", "inp", "\n", "\n", "", "while", "True", ":", "\n", "        ", "hypotheses", "=", "[", "]", "\n", "indices", "=", "[", "]", "\n", "offset", "=", "-", "1", "\n", "for", "idx", ",", "beam", "in", "enumerate", "(", "beams", ")", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "for", "hyp", "in", "beam", ".", "hypotheses", ":", "\n", "                    ", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "indices", ".", "append", "(", "idx", ")", "\n", "offset", "=", "len", "(", "hyp", ".", "seq", ")", "-", "1", "\n", "", "", "", "if", "not", "hypotheses", ":", "\n", "            ", "break", "\n", "\n", "", "indices", "=", "torch", ".", "tensor", "(", "indices", ")", ".", "cuda", "(", "beams", "[", "0", "]", ".", "device", ")", "\n", "state_dict", ",", "inp", "=", "ready_to_submit", "(", "hypotheses", ")", "\n", "cur_mem_dict", "=", "dict", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "mem_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "list", ")", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "[", "v", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "", "else", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "v", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "\n", "", "", "state_dict", ",", "results", "=", "model", ".", "decode_step", "(", "inp", ",", "state_dict", ",", "cur_mem_dict", ",", "offset", ",", "beams", "[", "0", "]", ".", "beam_size", ")", "\n", "_len_each_beam", "=", "[", "len", "(", "beam", ".", "hypotheses", ")", "for", "beam", "in", "beams", "if", "not", "beam", ".", "completed", "(", ")", "]", "\n", "_state_dict_each_beam", "=", "[", "dict", "(", ")", "for", "_", "in", "_len_each_beam", "]", "\n", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "v", ".", "split", "(", "_len_each_beam", ",", "dim", "=", "split_dim", ")", ")", ":", "\n", "                ", "_state_dict_each_beam", "[", "i", "]", "[", "k", "]", "=", "x", "\n", "\n", "", "", "_pos", "=", "0", "\n", "_idx", "=", "0", "\n", "for", "beam", "in", "beams", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "_len", "=", "len", "(", "beam", ".", "hypotheses", ")", "\n", "beam", ".", "update", "(", "_state_dict_each_beam", "[", "_idx", "]", ",", "results", "[", "_pos", ":", "_pos", "+", "_len", "]", ")", "\n", "_pos", "+=", "_len", "\n", "_idx", "+=", "1", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.__init__": [[9, 22], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "AdamWeightDecayOptimizer", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.__setstate__": [[23, 27], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdamWeightDecayOptimizer", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.adam.AdamWeightDecayOptimizer.step": [[28, 89], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "torch.zeros_like", "exp_avg.mul_", "exp_avg_sq.mul_", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "", "amsgrad", "=", "group", "[", "'amsgrad'", "]", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "'max_exp_avg_sq'", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want ot decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "", "update", "=", "(", "exp_avg", "/", "denom", ")", ".", "add_", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", ",", "update", ")", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.__init__": [[8, 25], ["networkx.DiGraph", "enumerate", "enumerate", "dependencyGraph.dependencyGraph.graph.add_node", "zip", "dependencyGraph.dependencyGraph._add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph._add_edge"], ["    ", "def", "__init__", "(", "self", ",", "dep", ",", "head", ",", "tok", ",", "tgt", ")", ":", "\n", "# transform graph from original conll format into our own data structure", "\n", "        ", "self", ".", "graph", "=", "nx", ".", "DiGraph", "(", ")", "\n", "self", ".", "name2concept", "=", "tok", "\n", "self", ".", "root", "=", "None", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "head", ")", ":", "\n", "            ", "if", "x", "==", "0", ":", "\n", "                ", "assert", "self", ".", "root", "is", "None", "\n", "self", ".", "root", "=", "i", "\n", "", "self", ".", "graph", ".", "add_node", "(", "i", ")", "\n", "\n", "", "for", "src", ",", "(", "des1", ",", "rel", ")", "in", "enumerate", "(", "zip", "(", "head", ",", "dep", ")", ")", ":", "\n", "            ", "des", "=", "des1", "-", "1", "\n", "if", "des", "<", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "_add_edge", "(", "rel", ",", "src", ",", "des", ")", "\n", "", "self", ".", "target", "=", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.__len__": [[27, 29], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "name2concept", ")", "**", "2", "+", "len", "(", "self", ".", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph._add_edge": [[30, 35], ["dependencyGraph.dependencyGraph.graph.add_node", "dependencyGraph.dependencyGraph.graph.add_node", "dependencyGraph.dependencyGraph.graph.add_edge", "dependencyGraph.dependencyGraph.graph.add_edge"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_node", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge", "home.repos.pwc.inspect_result.jcyk_gtos.amr_parsing.amr.AMRGraph.add_edge"], ["", "def", "_add_edge", "(", "self", ",", "rel", ",", "src", ",", "des", ")", ":", "\n", "        ", "self", ".", "graph", ".", "add_node", "(", "src", ")", "\n", "self", ".", "graph", ".", "add_node", "(", "des", ")", "\n", "self", ".", "graph", ".", "add_edge", "(", "src", ",", "des", ",", "label", "=", "rel", ")", "\n", "self", ".", "graph", ".", "add_edge", "(", "des", ",", "src", ",", "label", "=", "rel", "+", "'_r_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.bfs": [[36, 53], ["set", "len", "g.neighbors", "len", "g.number_of_nodes", "queue.append", "depths.append", "set.add"], "methods", ["None"], ["", "def", "bfs", "(", "self", ")", ":", "\n", "        ", "g", "=", "self", ".", "graph", "\n", "queue", "=", "[", "self", ".", "root", "]", "\n", "depths", "=", "[", "0", "]", "\n", "visited", "=", "set", "(", "queue", ")", "\n", "step", "=", "0", "\n", "while", "step", "<", "len", "(", "queue", ")", ":", "\n", "            ", "u", "=", "queue", "[", "step", "]", "\n", "depth", "=", "depths", "[", "step", "]", "\n", "step", "+=", "1", "\n", "for", "v", "in", "g", ".", "neighbors", "(", "u", ")", ":", "\n", "                ", "if", "v", "not", "in", "visited", ":", "\n", "                    ", "queue", ".", "append", "(", "v", ")", "\n", "depths", ".", "append", "(", "depth", "+", "1", ")", "\n", "visited", ".", "add", "(", "v", ")", "\n", "", "", "", "is_connected", "=", "(", "len", "(", "queue", ")", "==", "g", ".", "number_of_nodes", "(", ")", ")", "\n", "return", "queue", ",", "depths", ",", "is_connected", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.collect_concepts_and_relations": [[54, 75], ["dependencyGraph.dependencyGraph.bfs", "dict", "enumerate", "dict", "networkx.single_source_shortest_path", "enumerate", "list", "dict", "len", "[].append", "range", "len"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.dependencyGraph.dependencyGraph.bfs"], ["", "def", "collect_concepts_and_relations", "(", "self", ")", ":", "\n", "        ", "g", "=", "self", ".", "graph", "\n", "nodes", ",", "depths", ",", "is_connected", "=", "self", ".", "bfs", "(", ")", "\n", "concepts", "=", "[", "self", ".", "name2concept", "[", "n", "]", "for", "n", "in", "nodes", "]", "\n", "relations", "=", "dict", "(", ")", "\n", "for", "i", ",", "src", "in", "enumerate", "(", "nodes", ")", ":", "\n", "            ", "relations", "[", "i", "]", "=", "dict", "(", ")", "\n", "paths", "=", "nx", ".", "single_source_shortest_path", "(", "g", ",", "src", ")", "\n", "for", "j", ",", "tgt", "in", "enumerate", "(", "nodes", ")", ":", "\n", "                ", "relations", "[", "i", "]", "[", "j", "]", "=", "list", "(", ")", "\n", "assert", "tgt", "in", "paths", "\n", "path", "=", "paths", "[", "tgt", "]", "\n", "info", "=", "dict", "(", ")", "\n", "#info['node'] = path[1:-1]", "\n", "info", "[", "'edge'", "]", "=", "[", "g", "[", "path", "[", "i", "]", "]", "[", "path", "[", "i", "+", "1", "]", "]", "[", "'label'", "]", "for", "i", "in", "range", "(", "len", "(", "path", ")", "-", "1", ")", "]", "\n", "info", "[", "'length'", "]", "=", "len", "(", "info", "[", "'edge'", "]", ")", "\n", "relations", "[", "i", "]", "[", "j", "]", ".", "append", "(", "info", ")", "\n", "\n", "## TODO, we just use the sequential order", "\n", "", "", "depths", "=", "nodes", "\n", "return", "concepts", ",", "depths", ",", "relations", ",", "is_connected", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Transformer.__init__": [[9, 14], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "transformer.Transformer.layers.append", "transformer.TransformerLayer"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "TransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Transformer.forward": [[15, 21], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", ",", "_", "=", "layer", "(", "x", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "external_memories", ",", "external_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.TransformerLayer.__init__": [[24, 37], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerLayer.reset_parameters", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "with_external", "=", "with_external", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "self", ".", "external_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "external_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.TransformerLayer.reset_parameters": [[38, 43], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.TransformerLayer.forward": [[44, 73], ["torch.dropout", "torch.dropout", "transformer.TransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.fc2", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.ff_layer_norm", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.external_attn", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.external_layer_norm", "transformer.TransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "False", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "residual", "=", "x", "\n", "x", ",", "external_attn", "=", "self", ".", "external_attn", "(", "query", "=", "x", ",", "key", "=", "external_memories", ",", "value", "=", "external_memories", ",", "key_padding_mask", "=", "external_padding_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "external_layer_norm", "(", "residual", "+", "x", ")", "\n", "", "else", ":", "\n", "            ", "external_attn", "=", "None", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", ",", "external_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.__init__": [[76, 91], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "transformer.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.reset_parameters": [[92, 97], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.forward": [[98, 174], ["query.size", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout.transpose().contiguous().view", "transformer.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "transformer.MultiheadAttention.in_proj_qkv", "transformer.MultiheadAttention.transpose", "list", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.max", "attn_weights.transpose.transpose.transpose", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_kv", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_k", "transformer.MultiheadAttention.in_proj_v", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "attn_weights.transpose.transpose.size", "attn_mask.unsqueeze", "float", "key_padding_mask.transpose().unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "key_padding_mask.transpose().unsqueeze", "torch.dropout.transpose", "key_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "False", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "# k,v: bsz*heads x src_len x dim", "\n", "# q: bsz*heads x tgt_len x dim ", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "0", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads ", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "attn_weights", ",", "_", "=", "attn_weights", ".", "max", "(", "dim", "=", "1", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_qkv": [[175, 177], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_kv": [[178, 180], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_q": [[181, 183], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_k": [[184, 186], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention.in_proj_v": [[187, 189], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.MultiheadAttention._in_proj": [[190, 197], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.__init__": [[205, 209], ["torch.nn.Module.__init__", "transformer.SelfAttentionMask.get_mask"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.get_mask"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "init_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "SelfAttentionMask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "init_size", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.get_mask": [[210, 214], ["torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_mask", "(", "size", ")", ":", "\n", "        ", "weights", "=", "torch", ".", "ones", "(", "(", "size", ",", "size", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "triu_", "(", "1", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.forward": [[215, 220], ["transformer.SelfAttentionMask.weights[].detach().to().detach", "transformer.SelfAttentionMask.get_mask", "transformer.SelfAttentionMask.weights.size", "transformer.SelfAttentionMask.weights[].detach().to", "transformer.SelfAttentionMask.weights[].detach"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SelfAttentionMask.get_mask", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "self", ".", "weights", "is", "None", "or", "size", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "size", ")", "\n", "", "res", "=", "self", ".", "weights", "[", ":", "size", ",", ":", "size", "]", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.__init__": [[224, 229], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformer.LearnedPositionalEmbedding.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "device", ",", "max_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Embedding", "(", "max_size", ",", "embedding_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.reset_parameters": [[230, 232], ["torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weights", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.LearnedPositionalEmbedding.forward": [[233, 239], ["input.size", "transformer.LearnedPositionalEmbedding.weights().unsqueeze().expand", "transformer.LearnedPositionalEmbedding.weights().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.LearnedPositionalEmbedding.weights"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "positions", "=", "(", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "res", "=", "self", ".", "weights", "(", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.__init__": [[243, 251], ["torch.nn.Module.__init__", "transformer.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "device", ",", "init_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.get_embedding": [[252, 267], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.forward": [[268, 282], ["input.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach().to().detach", "transformer.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.SinusoidalPositionalEmbedding.weights.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach().to", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "transformer.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size", "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "\n", "self", ".", "embedding_dim", ",", "\n", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding": [[198, 203], ["torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.__init__": [[8, 10], ["None"], "methods", ["None"], ["from", "multiprocessing", "import", "Pool", "\n", "\n", "class", "AMRIO", ":", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read": [[11, 28], ["open().readlines", "line.rstrip().split", "open", "line.rstrip", "int", "len", "len", "len", "dependencyGraph.dependencyGraph.dependencyGraph"], "methods", ["None"], ["\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "@", "staticmethod", "\n", "def", "read", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::id '", ")", ":", "\n", "                    ", "amr_id", "=", "line", "[", "len", "(", "'# ::id '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::snt '", ")", ":", "\n", "                    ", "sentence", "=", "line", "[", "len", "(", "'# ::snt '", ")", ":", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::tokens '", ")", ":", "\n", "                    ", "tokens", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::tokens '", ")", ":", "]", ")", "\n", "tokens", "=", "[", "to", "if", "_is_abs_form", "(", "to", ")", "else", "to", ".", "lower", "(", ")", "for", "to", "in", "tokens", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::lemmas '", ")", ":", "\n", "                    ", "lemmas", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::lemmas '", ")", ":", "]", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read1": [[29, 46], ["open().readlines", "line.rstrip().split", "open", "line.rstrip", "int", "len", "len", "len"], "methods", ["None"], ["lemmas", "=", "[", "le", "if", "_is_abs_form", "(", "le", ")", "else", "le", ".", "lower", "(", ")", "for", "le", "in", "lemmas", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::pos_tags '", ")", ":", "\n", "                    ", "pos_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::pos_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::ner_tags '", ")", ":", "\n", "                    ", "ner_tags", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::ner_tags '", ")", ":", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::abstract_map '", ")", ":", "\n", "                    ", "abstract_map", "=", "json", ".", "loads", "(", "line", "[", "len", "(", "'# ::abstract_map '", ")", ":", "]", ")", "\n", "graph_line", "=", "AMR", ".", "get_amr_line", "(", "f", ")", "\n", "amr", "=", "AMR", ".", "parse_AMR_line", "(", "graph_line", ")", "\n", "myamr", "=", "AMRGraph", "(", "amr", ")", "\n", "yield", "tokens", ",", "lemmas", ",", "abstract_map", ",", "myamr", "\n", "\n", "", "", "", "", "", "class", "LexicalMap", "(", "object", ")", ":", "\n", "\n", "# build our lexical mapping (from concept to token/lemma), useful for copy mechanism.", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.__init__": [[50, 52], ["None"], "methods", ["None"], ["for", "conc", "in", "concept", ":", "\n", "            ", "cp_seq", ".", "append", "(", "conc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.LexicalMap.get": [[54, 71], ["set", "cp_seq.append", "dict", "dict", "vocab.token2idx"], "methods", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.token2idx"], ["            ", "return", "cp_seq", "\n", "\n", "", "new_tokens", "=", "set", "(", "cp", "for", "cp", "in", "cp_seq", "if", "vocab", ".", "token2idx", "(", "cp", ")", "==", "vocab", ".", "unk_idx", ")", "\n", "token2idx", ",", "idx2token", "=", "dict", "(", ")", ",", "dict", "(", ")", "\n", "nxt", "=", "vocab", ".", "size", "\n", "for", "x", "in", "new_tokens", ":", "\n", "            ", "token2idx", "[", "x", "]", "=", "nxt", "\n", "idx2token", "[", "nxt", "]", "=", "x", "\n", "nxt", "+=", "1", "\n", "", "return", "cp_seq", ",", "token2idx", ",", "idx2token", "\n", "\n", "\n", "", "", "def", "read_file", "(", "filename", ")", ":", "\n", "# read preprocessed amr file", "\n", "    ", "token", ",", "lemma", ",", "abstract", ",", "amrs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "_tok", ",", "_lem", ",", "_abstract", ",", "_myamr", "in", "AMRIO", ".", "read", "(", "filename", ")", ":", "\n", "        ", "token", ".", "append", "(", "_tok", ")", "\n", "lemma", ".", "append", "(", "_lem", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.read_file": [[73, 80], ["extract.IO.read", "print", "data.append", "len"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.IO.read"], ["amrs", ".", "append", "(", "_myamr", ")", "\n", "", "print", "(", "'read from %s, %d amrs'", "%", "(", "filename", ",", "len", "(", "token", ")", ")", ")", "\n", "return", "amrs", ",", "token", ",", "lemma", ",", "abstract", "\n", "\n", "", "def", "make_vocab", "(", "batch_seq", ",", "char_level", "=", "False", ")", ":", "\n", "    ", "cnt", "=", "Counter", "(", ")", "\n", "for", "seq", "in", "batch_seq", ":", "\n", "        ", "cnt", ".", "update", "(", "seq", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.make_vocab": [[81, 89], ["collections.Counter", "cnt.most_common", "list"], "function", ["None"], ["", "if", "not", "char_level", ":", "\n", "        ", "return", "cnt", "\n", "", "char_cnt", "=", "Counter", "(", ")", "\n", "for", "x", ",", "y", "in", "cnt", ".", "most_common", "(", ")", ":", "\n", "        ", "for", "ch", "in", "list", "(", "x", ")", ":", "\n", "            ", "char_cnt", "[", "ch", "]", "+=", "y", "\n", "", "", "return", "cnt", ",", "char_cnt", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.write_vocab": [[91, 95], ["open", "vocab.most_common", "fo.write"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.utils.logging.TeeLogger.write"], ["    ", "with", "open", "(", "path", ",", "'w'", ")", "as", "fo", ":", "\n", "        ", "for", "x", ",", "y", "in", "vocab", ".", "most_common", "(", ")", ":", "\n", "            ", "fo", ".", "write", "(", "'%s\\t%d\\n'", "%", "(", "x", ",", "y", ")", ")", "\n", "\n", "", "", "", "import", "argparse", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.extract.parse_config": [[97, 102], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--amr_files'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--nprocessors'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device": [[6, 20], ["torch.is_tensor", "maybe_tensor.to", "isinstance", "torch.from_numpy().to().contiguous", "isinstance", "isinstance", "torch.from_numpy().to", "utils.move_to_device", "maybe_tensor.items", "utils.move_to_device", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device", "home.repos.pwc.inspect_result.jcyk_gtos.utils.params.Params.items", "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.move_to_device"], ["    ", "if", "torch", ".", "is_tensor", "(", "maybe_tensor", ")", ":", "\n", "        ", "return", "maybe_tensor", ".", "cuda", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "dict", ")", ":", "\n", "        ", "return", "{", "\n", "key", ":", "move_to_cuda", "(", "value", ",", "device", ")", "\n", "for", "key", ",", "value", "in", "maybe_tensor", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "list", ")", ":", "\n", "        ", "return", "[", "move_to_cuda", "(", "x", ",", "device", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "else", ":", "\n", "        ", "return", "maybe_tensor", "\n", "\n", "", "", "def", "compute_f_by_tensor", "(", "input", ",", "target", ",", "mask", ")", ":", "\n", "    ", "input", "=", "input", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.compute_f_by_tensor": [[21, 47], ["input.view().tolist.view().tolist", "target.view().tolist.view().tolist", "mask.view().tolist.view().tolist", "zip", "input.view().tolist.view", "target.view().tolist.view", "mask.view().tolist.view"], "function", ["None"], ["mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "tp", ",", "fp", ",", "tn", ",", "fn", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "for", "i", ",", "t", ",", "m", "in", "zip", "(", "input", ",", "target", ",", "mask", ")", ":", "\n", "        ", "if", "m", "==", "1", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "if", "i", "==", "1", ":", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "tp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "fp", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "fn", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "tn", "+=", "1", "\n", "", "", "", "", "if", "tp", "==", "0", ":", "\n", "        ", "return", "0.", ",", "0.", ",", "0.", "\n", "\n", "", "P", "=", "tp", "/", "(", "tp", "+", "fp", ")", "\n", "R", "=", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "F", "=", "2", "*", "P", "*", "R", "/", "(", "P", "+", "R", ")", "\n", "return", "P", ",", "R", ",", "F", "\n", "\n", "", "def", "gelu_fast", "(", "x", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "gelu_fast", ",", "\"_a\"", ")", ":", "\n", "        ", "gelu_fast", ".", "_a", "=", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.gelu_fast": [[48, 52], ["hasattr", "math.sqrt", "torch.tanh", "torch.pow"], "function", ["None"], ["", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "gelu_fast", ".", "_a", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n", "", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.gelu": [[53, 55], ["torch.erf", "math.sqrt"], "function", ["None"], ["\n", "", "def", "label_smoothed_nll_loss", "(", "log_probs", ",", "target", ",", "eps", ")", ":", "\n", "#log_probs: N x C", "\n"]], "home.repos.pwc.inspect_result.jcyk_gtos.translator.utils.label_smoothed_nll_loss": [[57, 67], ["log_probs.gather().squeeze", "log_probs.sum", "log_probs.size", "log_probs.gather", "target.unsqueeze"], "function", ["home.repos.pwc.inspect_result.jcyk_gtos.translator.data.Vocab.size"], ["    ", "nll_loss", "=", "-", "log_probs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "if", "eps", "==", "0.", ":", "\n", "        ", "return", "nll_loss", "\n", "", "smooth_loss", "=", "-", "log_probs", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "eps_i", "=", "eps", "/", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.", "-", "eps", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", "\n", "", ""]]}