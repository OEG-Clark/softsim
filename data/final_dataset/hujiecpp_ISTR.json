{"home.repos.pwc.inspect_result.hujiecpp_ISTR.None.setup.get_version": [[18, 39], ["os.path.join", "open().readlines", "[].strip().strip", "os.getenv", "os.path.abspath", "os.getenv", "datetime.today().strftime", "new_init_py.append", "os.path.dirname", "open", "l.strip", "[].strip", "open", "f.write", "l.startswith", "datetime.today", "l.startswith", "version_line.split"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["def", "get_version", "(", ")", ":", "\n", "    ", "init_py_path", "=", "path", ".", "join", "(", "path", ".", "abspath", "(", "path", ".", "dirname", "(", "__file__", ")", ")", ",", "\"detectron2\"", ",", "\"__init__.py\"", ")", "\n", "init_py", "=", "open", "(", "init_py_path", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "version_line", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "init_py", "if", "l", ".", "startswith", "(", "\"__version__\"", ")", "]", "[", "0", "]", "\n", "version", "=", "version_line", ".", "split", "(", "\"=\"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", ".", "strip", "(", "\"'\\\"\"", ")", "\n", "\n", "# The following is used to build release packages.", "\n", "# Users should never use it.", "\n", "suffix", "=", "os", ".", "getenv", "(", "\"D2_VERSION_SUFFIX\"", ",", "\"\"", ")", "\n", "version", "=", "version", "+", "suffix", "\n", "if", "os", ".", "getenv", "(", "\"BUILD_NIGHTLY\"", ",", "\"0\"", ")", "==", "\"1\"", ":", "\n", "        ", "from", "datetime", "import", "datetime", "\n", "\n", "date_str", "=", "datetime", ".", "today", "(", ")", ".", "strftime", "(", "\"%y%m%d\"", ")", "\n", "version", "=", "version", "+", "\".dev\"", "+", "date_str", "\n", "\n", "new_init_py", "=", "[", "l", "for", "l", "in", "init_py", "if", "not", "l", ".", "startswith", "(", "\"__version__\"", ")", "]", "\n", "new_init_py", ".", "append", "(", "'__version__ = \"{}\"\\n'", ".", "format", "(", "version", ")", ")", "\n", "with", "open", "(", "init_py_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\"", ".", "join", "(", "new_init_py", ")", ")", "\n", "", "", "return", "version", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.None.setup.get_extensions": [[41, 150], ["os.path.dirname", "os.path.join", "os.path.join", "glob.glob", "os.path.abspath", "os.path.join", "hasattr", "torch.utils.hipify.hipify_python.hipify", "shutil.copy", "shutil.copy", "extension", "int", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "torch.cuda.is_available", "os.getenv", "os.environ.get", "torch.utils.hipify.__version__.split", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "extra_compile_args[].append", "s.endswith"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "get_extensions", "(", ")", ":", "\n", "    ", "this_dir", "=", "path", ".", "dirname", "(", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "extensions_dir", "=", "path", ".", "join", "(", "this_dir", ",", "\"detectron2\"", ",", "\"layers\"", ",", "\"csrc\"", ")", "\n", "\n", "main_source", "=", "path", ".", "join", "(", "extensions_dir", ",", "\"vision.cpp\"", ")", "\n", "sources", "=", "glob", ".", "glob", "(", "path", ".", "join", "(", "extensions_dir", ",", "\"**\"", ",", "\"*.cpp\"", ")", ")", "\n", "\n", "from", "torch", ".", "utils", ".", "cpp_extension", "import", "ROCM_HOME", "\n", "\n", "is_rocm_pytorch", "=", "(", "\n", "True", "if", "(", "(", "torch", ".", "version", ".", "hip", "is", "not", "None", ")", "and", "(", "ROCM_HOME", "is", "not", "None", ")", ")", "else", "False", "\n", ")", "\n", "\n", "hipify_ver", "=", "(", "\n", "[", "int", "(", "x", ")", "for", "x", "in", "torch", ".", "utils", ".", "hipify", ".", "__version__", ".", "split", "(", "\".\"", ")", "]", "\n", "if", "hasattr", "(", "torch", ".", "utils", ".", "hipify", ",", "\"__version__\"", ")", "\n", "else", "[", "0", ",", "0", ",", "0", "]", "\n", ")", "\n", "\n", "if", "is_rocm_pytorch", "and", "hipify_ver", "<", "[", "1", ",", "0", ",", "0", "]", ":", "# TODO not needed since pt1.8", "\n", "\n", "# Earlier versions of hipification and extension modules were not", "\n", "# transparent, i.e. would require an explicit call to hipify, and the", "\n", "# hipification would introduce \"hip\" subdirectories, possibly changing", "\n", "# the relationship between source and header files.", "\n", "# This path is maintained for backwards compatibility.", "\n", "\n", "        ", "hipify_python", ".", "hipify", "(", "\n", "project_directory", "=", "this_dir", ",", "\n", "output_directory", "=", "this_dir", ",", "\n", "includes", "=", "\"/detectron2/layers/csrc/*\"", ",", "\n", "show_detailed", "=", "True", ",", "\n", "is_pytorch_extension", "=", "True", ",", "\n", ")", "\n", "\n", "source_cuda", "=", "glob", ".", "glob", "(", "path", ".", "join", "(", "extensions_dir", ",", "\"**\"", ",", "\"hip\"", ",", "\"*.hip\"", ")", ")", "+", "glob", ".", "glob", "(", "\n", "path", ".", "join", "(", "extensions_dir", ",", "\"hip\"", ",", "\"*.hip\"", ")", "\n", ")", "\n", "\n", "shutil", ".", "copy", "(", "\n", "\"detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_utils.h\"", ",", "\n", "\"detectron2/layers/csrc/box_iou_rotated/hip/box_iou_rotated_utils.h\"", ",", "\n", ")", "\n", "shutil", ".", "copy", "(", "\n", "\"detectron2/layers/csrc/deformable/deform_conv.h\"", ",", "\n", "\"detectron2/layers/csrc/deformable/hip/deform_conv.h\"", ",", "\n", ")", "\n", "\n", "sources", "=", "[", "main_source", "]", "+", "sources", "\n", "sources", "=", "[", "\n", "s", "\n", "for", "s", "in", "sources", "\n", "if", "not", "is_rocm_pytorch", "or", "torch_ver", "<", "[", "1", ",", "7", "]", "or", "not", "s", ".", "endswith", "(", "\"hip/vision.cpp\"", ")", "\n", "]", "\n", "\n", "", "else", ":", "\n", "\n", "# common code between cuda and rocm platforms,", "\n", "# for hipify version [1,0,0] and later.", "\n", "\n", "        ", "source_cuda", "=", "glob", ".", "glob", "(", "path", ".", "join", "(", "extensions_dir", ",", "\"**\"", ",", "\"*.cu\"", ")", ")", "+", "glob", ".", "glob", "(", "\n", "path", ".", "join", "(", "extensions_dir", ",", "\"*.cu\"", ")", "\n", ")", "\n", "\n", "sources", "=", "[", "main_source", "]", "+", "sources", "\n", "\n", "", "extension", "=", "CppExtension", "\n", "\n", "extra_compile_args", "=", "{", "\"cxx\"", ":", "[", "]", "}", "\n", "define_macros", "=", "[", "]", "\n", "\n", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "(", "(", "CUDA_HOME", "is", "not", "None", ")", "or", "is_rocm_pytorch", ")", ")", "or", "os", ".", "getenv", "(", "\n", "\"FORCE_CUDA\"", ",", "\"0\"", "\n", ")", "==", "\"1\"", ":", "\n", "        ", "extension", "=", "CUDAExtension", "\n", "sources", "+=", "source_cuda", "\n", "\n", "if", "not", "is_rocm_pytorch", ":", "\n", "            ", "define_macros", "+=", "[", "(", "\"WITH_CUDA\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "\n", "\"-O3\"", ",", "\n", "\"-DCUDA_HAS_FP16=1\"", ",", "\n", "\"-D__CUDA_NO_HALF_OPERATORS__\"", ",", "\n", "\"-D__CUDA_NO_HALF_CONVERSIONS__\"", ",", "\n", "\"-D__CUDA_NO_HALF2_OPERATORS__\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "define_macros", "+=", "[", "(", "\"WITH_HIP\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "]", "\n", "\n", "", "if", "torch_ver", "<", "[", "1", ",", "7", "]", ":", "\n", "# supported by https://github.com/pytorch/pytorch/pull/43931", "\n", "            ", "CC", "=", "os", ".", "environ", ".", "get", "(", "\"CC\"", ",", "None", ")", "\n", "if", "CC", "is", "not", "None", ":", "\n", "                ", "extra_compile_args", "[", "\"nvcc\"", "]", ".", "append", "(", "\"-ccbin={}\"", ".", "format", "(", "CC", ")", ")", "\n", "\n", "", "", "", "include_dirs", "=", "[", "extensions_dir", "]", "\n", "\n", "ext_modules", "=", "[", "\n", "extension", "(", "\n", "\"detectron2._C\"", ",", "\n", "sources", ",", "\n", "include_dirs", "=", "include_dirs", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ",", "\n", ")", "\n", "]", "\n", "\n", "return", "ext_modules", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.None.setup.get_model_zoo_configs": [[152, 181], ["os.path.join", "os.path.join", "os.path.exists", "glob.glob", "os.path.dirname", "os.path.dirname", "os.path.islink", "os.path.exists", "os.path.realpath", "os.path.realpath", "os.unlink", "os.path.isdir", "os.symlink", "shutil.rmtree", "shutil.copytree"], "function", ["None"], ["", "def", "get_model_zoo_configs", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Return a list of configs to include in package for model zoo. Copy over these configs inside\n    detectron2/model_zoo.\n    \"\"\"", "\n", "\n", "# Use absolute paths while symlinking.", "\n", "source_configs_dir", "=", "path", ".", "join", "(", "path", ".", "dirname", "(", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "\"configs\"", ")", "\n", "destination", "=", "path", ".", "join", "(", "\n", "path", ".", "dirname", "(", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "\"detectron2\"", ",", "\"model_zoo\"", ",", "\"configs\"", "\n", ")", "\n", "# Symlink the config directory inside package to have a cleaner pip install.", "\n", "\n", "# Remove stale symlink/directory from a previous build.", "\n", "if", "path", ".", "exists", "(", "source_configs_dir", ")", ":", "\n", "        ", "if", "path", ".", "islink", "(", "destination", ")", ":", "\n", "            ", "os", ".", "unlink", "(", "destination", ")", "\n", "", "elif", "path", ".", "isdir", "(", "destination", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "destination", ")", "\n", "\n", "", "", "if", "not", "path", ".", "exists", "(", "destination", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "symlink", "(", "source_configs_dir", ",", "destination", ")", "\n", "", "except", "OSError", ":", "\n", "# Fall back to copying if symlink fails: ex. on Windows.", "\n", "            ", "shutil", ".", "copytree", "(", "source_configs_dir", ",", "destination", ")", "\n", "\n", "", "", "config_paths", "=", "glob", ".", "glob", "(", "\"configs/**/*.yaml\"", ",", "recursive", "=", "True", ")", "\n", "return", "config_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.demo.setup_cfg": [[21, 41], ["detectron2.config.get_cfg", "add_ISTR_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.get_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.config.add_ISTR_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze"], ["def", "setup_cfg", "(", "args", ")", ":", "\n", "# load config from file and command-line arguments", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "# To use demo for Panoptic-DeepLab, please uncomment the following two lines.", "\n", "# from detectron2.projects.panoptic_deeplab import add_panoptic_deeplab_config  # noqa", "\n", "# add_panoptic_deeplab_config(cfg)", "\n", "\n", "# -----", "\n", "from", "projects", ".", "ISTR", ".", "istr", "import", "add_ISTR_config", "\n", "add_ISTR_config", "(", "cfg", ")", "\n", "# -----", "\n", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "# Set score_threshold for builtin models", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "SCORE_THRESH_TEST", "=", "args", ".", "confidence_threshold", "\n", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "SCORE_THRESH_TEST", "=", "args", ".", "confidence_threshold", "\n", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "INSTANCES_CONFIDENCE_THRESH", "=", "args", ".", "confidence_threshold", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.demo.get_parser": [[43, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Detectron2 demo for builtin configs\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--webcam\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Take inputs from webcam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--video-input\"", ",", "help", "=", "\"Path to video file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"A list of space separated input images; \"", "\n", "\"or a single glob pattern such as 'directory/*.jpg'\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "help", "=", "\"A file or directory to save output visualizations. \"", "\n", "\"If not given, will show output in an OpenCV window.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--confidence-threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "\"Minimum score for instance predictions to be shown\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line 'KEY VALUE' pairs\"", ",", "\n", "default", "=", "[", "]", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.VisualizationDemo.__init__": [[16, 36], ["detectron2.data.MetadataCatalog.get", "torch.device", "torch.cuda.device_count", "predictor.AsyncPredictor", "detectron2.engine.defaults.DefaultPredictor", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ",", "parallel", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            instance_mode (ColorMode):\n            parallel (bool): whether to run the model in different processes from visualization.\n                Useful since the visualization logic can be slow.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\n", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", "if", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "else", "\"__unused\"", "\n", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "instance_mode", "=", "instance_mode", "\n", "\n", "self", ".", "parallel", "=", "parallel", "\n", "if", "parallel", ":", "\n", "            ", "num_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "self", ".", "predictor", "=", "AsyncPredictor", "(", "cfg", ",", "num_gpus", "=", "num_gpu", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "predictor", "=", "DefaultPredictor", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.VisualizationDemo.run_on_image": [[37, 69], ["predictor.VisualizationDemo.predictor", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.draw_panoptic_seg_predictions", "panoptic_seg.to", "detectron2.utils.visualizer.Visualizer.draw_sem_seg", "predictions[].to", "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "predictions[].argmax().to", "predictions[].argmax"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_sem_seg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_instance_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "", "def", "run_on_image", "(", "self", ",", "image", ",", "confidence_threshold", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n                This is the format used by OpenCV.\n\n        Returns:\n            predictions (dict): the output of the model.\n            vis_output (VisImage): the visualized image output.\n        \"\"\"", "\n", "vis_output", "=", "None", "\n", "predictions", "=", "self", ".", "predictor", "(", "image", ")", "\n", "# Convert image from OpenCV BGR format to Matplotlib RGB format.", "\n", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "visualizer", "=", "Visualizer", "(", "image", ",", "self", ".", "metadata", ",", "instance_mode", "=", "self", ".", "instance_mode", ")", "\n", "if", "\"panoptic_seg\"", "in", "predictions", ":", "\n", "            ", "panoptic_seg", ",", "segments_info", "=", "predictions", "[", "\"panoptic_seg\"", "]", "\n", "vis_output", "=", "visualizer", ".", "draw_panoptic_seg_predictions", "(", "\n", "panoptic_seg", ".", "to", "(", "self", ".", "cpu_device", ")", ",", "segments_info", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "\"sem_seg\"", "in", "predictions", ":", "\n", "                ", "vis_output", "=", "visualizer", ".", "draw_sem_seg", "(", "\n", "predictions", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", ")", "\n", "", "if", "\"instances\"", "in", "predictions", ":", "\n", "                ", "instances", "=", "predictions", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", "instances", "=", "instances", "[", "instances", ".", "scores", ">", "confidence_threshold", "]", "\n", "predictions", "[", "\"instances\"", "]", "=", "instances", "\n", "vis_output", "=", "visualizer", ".", "draw_instance_predictions", "(", "predictions", "=", "instances", ")", "\n", "\n", "", "", "return", "predictions", ",", "vis_output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.VisualizationDemo._frame_from_video": [[70, 77], ["video.isOpened", "video.read"], "methods", ["None"], ["", "def", "_frame_from_video", "(", "self", ",", "video", ")", ":", "\n", "        ", "while", "video", ".", "isOpened", "(", ")", ":", "\n", "            ", "success", ",", "frame", "=", "video", ".", "read", "(", ")", "\n", "if", "success", ":", "\n", "                ", "yield", "frame", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.VisualizationDemo.run_on_video": [[78, 133], ["detectron2.utils.video_visualizer.VideoVisualizer", "predictor.VisualizationDemo._frame_from_video", "cv2.cvtColor", "cv2.cvtColor", "collections.deque", "enumerate", "len", "detectron2.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions", "detectron2.utils.video_visualizer.VideoVisualizer.draw_sem_seg.get_image", "collections.deque.append", "predictor.VisualizationDemo.predictor.put", "collections.deque.popleft", "predictor.VisualizationDemo.predictor.get", "panoptic_seg.to", "predictions[].to", "detectron2.utils.video_visualizer.VideoVisualizer.draw_instance_predictions", "collections.deque.popleft", "predictor.VisualizationDemo.predictor.get", "predictor.VisualizationDemo.run_on_video.process_predictions"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.VisualizationDemo._frame_from_video", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.put", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_instance_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "", "def", "run_on_video", "(", "self", ",", "video", ",", "confidence_threshold", ")", ":", "\n", "        ", "\"\"\"\n        Visualizes predictions on frames of the input video.\n\n        Args:\n            video (cv2.VideoCapture): a :class:`VideoCapture` object, whose source can be\n                either a webcam or a video file.\n\n        Yields:\n            ndarray: BGR visualizations of each video frame.\n        \"\"\"", "\n", "video_visualizer", "=", "VideoVisualizer", "(", "self", ".", "metadata", ",", "self", ".", "instance_mode", ")", "\n", "\n", "def", "process_predictions", "(", "frame", ",", "predictions", ")", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "if", "\"panoptic_seg\"", "in", "predictions", ":", "\n", "                ", "panoptic_seg", ",", "segments_info", "=", "predictions", "[", "\"panoptic_seg\"", "]", "\n", "vis_frame", "=", "video_visualizer", ".", "draw_panoptic_seg_predictions", "(", "\n", "frame", ",", "panoptic_seg", ".", "to", "(", "self", ".", "cpu_device", ")", ",", "segments_info", "\n", ")", "\n", "", "elif", "\"instances\"", "in", "predictions", ":", "\n", "                ", "predictions", "=", "predictions", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", "predictions", "=", "predictions", "[", "predictions", ".", "scores", ">", "confidence_threshold", "]", "\n", "vis_frame", "=", "video_visualizer", ".", "draw_instance_predictions", "(", "frame", ",", "predictions", ")", "\n", "", "elif", "\"sem_seg\"", "in", "predictions", ":", "\n", "                ", "vis_frame", "=", "video_visualizer", ".", "draw_sem_seg", "(", "\n", "frame", ",", "predictions", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", ")", "\n", "\n", "# Converts Matplotlib RGB format to OpenCV BGR format", "\n", "", "vis_frame", "=", "cv2", ".", "cvtColor", "(", "vis_frame", ".", "get_image", "(", ")", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "return", "vis_frame", "\n", "\n", "", "frame_gen", "=", "self", ".", "_frame_from_video", "(", "video", ")", "\n", "if", "self", ".", "parallel", ":", "\n", "            ", "buffer_size", "=", "self", ".", "predictor", ".", "default_buffer_size", "\n", "\n", "frame_data", "=", "deque", "(", ")", "\n", "\n", "for", "cnt", ",", "frame", "in", "enumerate", "(", "frame_gen", ")", ":", "\n", "                ", "frame_data", ".", "append", "(", "frame", ")", "\n", "self", ".", "predictor", ".", "put", "(", "frame", ")", "\n", "\n", "if", "cnt", ">=", "buffer_size", ":", "\n", "                    ", "frame", "=", "frame_data", ".", "popleft", "(", ")", "\n", "predictions", "=", "self", ".", "predictor", ".", "get", "(", ")", "\n", "yield", "process_predictions", "(", "frame", ",", "predictions", ")", "\n", "\n", "", "", "while", "len", "(", "frame_data", ")", ":", "\n", "                ", "frame", "=", "frame_data", ".", "popleft", "(", ")", "\n", "predictions", "=", "self", ".", "predictor", ".", "get", "(", ")", "\n", "yield", "process_predictions", "(", "frame", ",", "predictions", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "frame", "in", "frame_gen", ":", "\n", "                ", "yield", "process_predictions", "(", "frame", ",", "self", ".", "predictor", "(", "frame", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.__init__": [[163, 189], ["max", "multiprocessing.Queue", "multiprocessing.Queue", "range", "atexit.register", "max", "cfg.clone.clone.clone", "cfg.clone.clone.defrost", "predictor.AsyncPredictor.procs.append", "p.start", "AsyncPredictor._PredictWorker"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["", "", "", "def", "__init__", "(", "self", ",", "cfg", ",", "num_gpus", ":", "int", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            num_gpus (int): if 0, will run on CPU\n        \"\"\"", "\n", "num_workers", "=", "max", "(", "num_gpus", ",", "1", ")", "\n", "self", ".", "task_queue", "=", "mp", ".", "Queue", "(", "maxsize", "=", "num_workers", "*", "3", ")", "\n", "self", ".", "result_queue", "=", "mp", ".", "Queue", "(", "maxsize", "=", "num_workers", "*", "3", ")", "\n", "self", ".", "procs", "=", "[", "]", "\n", "for", "gpuid", "in", "range", "(", "max", "(", "num_gpus", ",", "1", ")", ")", ":", "\n", "            ", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cuda:{}\"", ".", "format", "(", "gpuid", ")", "if", "num_gpus", ">", "0", "else", "\"cpu\"", "\n", "self", ".", "procs", ".", "append", "(", "\n", "AsyncPredictor", ".", "_PredictWorker", "(", "cfg", ",", "self", ".", "task_queue", ",", "self", ".", "result_queue", ")", "\n", ")", "\n", "\n", "", "self", ".", "put_idx", "=", "0", "\n", "self", ".", "get_idx", "=", "0", "\n", "self", ".", "result_rank", "=", "[", "]", "\n", "self", ".", "result_data", "=", "[", "]", "\n", "\n", "for", "p", "in", "self", ".", "procs", ":", "\n", "            ", "p", ".", "start", "(", ")", "\n", "", "atexit", ".", "register", "(", "self", ".", "shutdown", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.put": [[190, 193], ["predictor.AsyncPredictor.task_queue.put"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.put"], ["", "def", "put", "(", "self", ",", "image", ")", ":", "\n", "        ", "self", ".", "put_idx", "+=", "1", "\n", "self", ".", "task_queue", ".", "put", "(", "(", "self", ".", "put_idx", ",", "image", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.get": [[194, 209], ["len", "predictor.AsyncPredictor.result_queue.get", "bisect.bisect", "predictor.AsyncPredictor.result_rank.insert", "predictor.AsyncPredictor.result_data.insert"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "self", ".", "get_idx", "+=", "1", "# the index needed for this request", "\n", "if", "len", "(", "self", ".", "result_rank", ")", "and", "self", ".", "result_rank", "[", "0", "]", "==", "self", ".", "get_idx", ":", "\n", "            ", "res", "=", "self", ".", "result_data", "[", "0", "]", "\n", "del", "self", ".", "result_data", "[", "0", "]", ",", "self", ".", "result_rank", "[", "0", "]", "\n", "return", "res", "\n", "\n", "", "while", "True", ":", "\n", "# make sure the results are returned in the correct order", "\n", "            ", "idx", ",", "res", "=", "self", ".", "result_queue", ".", "get", "(", ")", "\n", "if", "idx", "==", "self", ".", "get_idx", ":", "\n", "                ", "return", "res", "\n", "", "insert", "=", "bisect", ".", "bisect", "(", "self", ".", "result_rank", ",", "idx", ")", "\n", "self", ".", "result_rank", ".", "insert", "(", "insert", ",", "idx", ")", "\n", "self", ".", "result_data", ".", "insert", "(", "insert", ",", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.__len__": [[210, 212], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "put_idx", "-", "self", ".", "get_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.__call__": [[213, 216], ["predictor.AsyncPredictor.put", "predictor.AsyncPredictor.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.put", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "self", ".", "put", "(", "image", ")", "\n", "return", "self", ".", "get", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.shutdown": [[217, 220], ["predictor.AsyncPredictor.task_queue.put", "AsyncPredictor._StopToken"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.put"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "for", "_", "in", "self", ".", "procs", ":", "\n", "            ", "self", ".", "task_queue", ".", "put", "(", "AsyncPredictor", ".", "_StopToken", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.demo.predictor.AsyncPredictor.default_buffer_size": [[221, 224], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "default_buffer_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "procs", ")", "*", "5", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.serialize.PicklableWrapper.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "self", ".", "_obj", "=", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.serialize.PicklableWrapper.__reduce__": [[18, 21], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "s", "=", "cloudpickle", ".", "dumps", "(", "self", ".", "_obj", ")", "\n", "return", "cloudpickle", ".", "loads", ",", "(", "s", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.serialize.PicklableWrapper.__call__": [[22, 24], ["serialize.PicklableWrapper._obj"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_obj", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.serialize.PicklableWrapper.__getattr__": [[25, 30], ["getattr", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "# Ensure that the wrapped object can be used seamlessly as the previous object.", "\n", "        ", "if", "attr", "not", "in", "[", "\"_obj\"", "]", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "_obj", ",", "attr", ")", "\n", "", "return", "getattr", "(", "self", ",", "attr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.colormap": [[95, 109], ["None"], "function", ["None"], ["def", "colormap", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a float32 array of Nx3 colors, in range [0, 255] or [0, 1]\n    \"\"\"", "\n", "assert", "maximum", "in", "[", "255", ",", "1", "]", ",", "maximum", "\n", "c", "=", "_COLORS", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "c", "=", "c", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.random_color": [[111, 125], ["numpy.random.randint", "len"], "function", ["None"], ["", "def", "random_color", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a vector of 3 numbers\n    \"\"\"", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "_COLORS", ")", ")", "\n", "ret", "=", "_COLORS", "[", "idx", "]", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "ret", "=", "ret", "[", ":", ":", "-", "1", "]", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventWriter.write": [[43, 45], ["None"], "methods", ["None"], ["def", "write", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventWriter.close": [[46, 48], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.JSONWriter.__init__": [[94, 104], ["detectron2.utils.file_io.PathManager.open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "json_file", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            json_file (str): path to the json file. New data will be appended if the file exists.\n            window_size (int): the window size of median smoothing for the scalars whose\n                `smoothing_hint` are True.\n        \"\"\"", "\n", "self", ".", "_file_handle", "=", "PathManager", ".", "open", "(", "json_file", ",", "\"a\"", ")", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.JSONWriter.write": [[105, 126], ["events.get_event_storage", "collections.defaultdict", "get_event_storage.latest_with_smoothing_hint().items", "len", "collections.defaultdict.items", "events.JSONWriter._file_handle.flush", "sorted", "max", "events.JSONWriter._file_handle.write", "os.fsync", "get_event_storage.latest_with_smoothing_hint", "collections.defaultdict.keys", "events.JSONWriter._file_handle.fileno", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "to_save", "=", "defaultdict", "(", "dict", ")", "\n", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "# keep scalars that have not been written", "\n", "            ", "if", "iter", "<=", "self", ".", "_last_write", ":", "\n", "                ", "continue", "\n", "", "to_save", "[", "iter", "]", "[", "k", "]", "=", "v", "\n", "", "if", "len", "(", "to_save", ")", ":", "\n", "            ", "all_iters", "=", "sorted", "(", "to_save", ".", "keys", "(", ")", ")", "\n", "self", ".", "_last_write", "=", "max", "(", "all_iters", ")", "\n", "\n", "", "for", "itr", ",", "scalars_per_iter", "in", "to_save", ".", "items", "(", ")", ":", "\n", "            ", "scalars_per_iter", "[", "\"iteration\"", "]", "=", "itr", "\n", "self", ".", "_file_handle", ".", "write", "(", "json", ".", "dumps", "(", "scalars_per_iter", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", ")", "\n", "", "self", ".", "_file_handle", ".", "flush", "(", ")", "\n", "try", ":", "\n", "            ", "os", ".", "fsync", "(", "self", ".", "_file_handle", ".", "fileno", "(", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.JSONWriter.close": [[127, 129], ["events.JSONWriter._file_handle.close"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "_file_handle", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.__init__": [[136, 149], ["SummaryWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "log_dir", ":", "str", ",", "window_size", ":", "int", "=", "20", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            log_dir (str): the directory to save the output events\n            window_size (int): the scalars will be median-smoothed by this window size\n\n            kwargs: other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n        \"\"\"", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "from", "torch", ".", "utils", ".", "tensorboard", "import", "SummaryWriter", "\n", "\n", "self", ".", "_writer", "=", "SummaryWriter", "(", "log_dir", ",", "**", "kwargs", ")", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.write": [[150, 175], ["events.get_event_storage", "get_event_storage.latest_with_smoothing_hint().items", "len", "get_event_storage.clear_images", "len", "get_event_storage.clear_histograms", "get_event_storage.latest_with_smoothing_hint", "events.TensorboardXWriter._writer.add_scalar", "max", "events.TensorboardXWriter._writer.add_image", "events.TensorboardXWriter._writer.add_histogram_raw"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.clear_images", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.clear_histograms", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.latest_with_smoothing_hint", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "new_last_write", "=", "self", ".", "_last_write", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "iter", ">", "self", ".", "_last_write", ":", "\n", "                ", "self", ".", "_writer", ".", "add_scalar", "(", "k", ",", "v", ",", "iter", ")", "\n", "new_last_write", "=", "max", "(", "new_last_write", ",", "iter", ")", "\n", "", "", "self", ".", "_last_write", "=", "new_last_write", "\n", "\n", "# storage.put_{image,histogram} is only meant to be used by", "\n", "# tensorboard writer. So we access its internal fields directly from here.", "\n", "if", "len", "(", "storage", ".", "_vis_data", ")", ">=", "1", ":", "\n", "            ", "for", "img_name", ",", "img", ",", "step_num", "in", "storage", ".", "_vis_data", ":", "\n", "                ", "self", ".", "_writer", ".", "add_image", "(", "img_name", ",", "img", ",", "step_num", ")", "\n", "# Storage stores all image data and rely on this writer to clear them.", "\n", "# As a result it assumes only one writer will use its image data.", "\n", "# An alternative design is to let storage store limited recent", "\n", "# data (e.g. only the most recent image) that all writers can access.", "\n", "# In that case a writer may not see all image data if its period is long.", "\n", "", "storage", ".", "clear_images", "(", ")", "\n", "\n", "", "if", "len", "(", "storage", ".", "_histograms", ")", ">=", "1", ":", "\n", "            ", "for", "params", "in", "storage", ".", "_histograms", ":", "\n", "                ", "self", ".", "_writer", ".", "add_histogram_raw", "(", "**", "params", ")", "\n", "", "storage", ".", "clear_histograms", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close": [[176, 179], ["hasattr", "events.TensorboardXWriter._writer.close"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"_writer\"", ")", ":", "# doesn't exist when the code fails at import", "\n", "            ", "self", ".", "_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.__init__": [[191, 202], ["logging.getLogger"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ":", "Optional", "[", "int", "]", "=", "None", ",", "window_size", ":", "int", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            max_iter: the maximum number of iterations to train.\n                Used to compute ETA. If not given, ETA will not be printed.\n            window_size (int): the losses will be median-smoothed by this window size\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "None", "# (step, time) of last call to write(). Used to compute ETA", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter._get_eta": [[203, 222], ["storage.put_scalar", "str", "storage.history().median", "datetime.timedelta", "str", "time.perf_counter", "storage.history", "int", "datetime.timedelta", "time.perf_counter", "int"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.history"], ["", "def", "_get_eta", "(", "self", ",", "storage", ")", "->", "Optional", "[", "str", "]", ":", "\n", "        ", "if", "self", ".", "_max_iter", "is", "None", ":", "\n", "            ", "return", "\"\"", "\n", "", "iteration", "=", "storage", ".", "iter", "\n", "try", ":", "\n", "            ", "eta_seconds", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "median", "(", "1000", ")", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "storage", ".", "put_scalar", "(", "\"eta_seconds\"", ",", "eta_seconds", ",", "smoothing_hint", "=", "False", ")", "\n", "return", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "# estimate eta on our own - more noisy", "\n", "            ", "eta_string", "=", "None", "\n", "if", "self", ".", "_last_write", "is", "not", "None", ":", "\n", "                ", "estimate_iter_time", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_last_write", "[", "1", "]", ")", "/", "(", "\n", "iteration", "-", "self", ".", "_last_write", "[", "0", "]", "\n", ")", "\n", "eta_seconds", "=", "estimate_iter_time", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "self", ".", "_last_write", "=", "(", "iteration", ",", "time", ".", "perf_counter", "(", ")", ")", "\n", "return", "eta_string", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write": [[223, 270], ["events.get_event_storage", "events.CommonMetricPrinter._get_eta", "torch.cuda.is_available", "events.CommonMetricPrinter.logger.info", "get_event_storage.history().avg", "get_event_storage.history().global_avg", "get_event_storage.history().latest", "get_event_storage.history", "get_event_storage.history", "torch.cuda.max_memory_allocated", "get_event_storage.history", "v.median", "get_event_storage.histories().items", "get_event_storage.histories"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter._get_eta", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.avg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.global_avg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.latest", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.histories"], ["", "", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "iteration", "=", "storage", ".", "iter", "\n", "if", "iteration", "==", "self", ".", "_max_iter", ":", "\n", "# This hook only reports training progress (loss, ETA, etc) but not other data,", "\n", "# therefore do not write anything after training succeeds, even if this method", "\n", "# is called.", "\n", "            ", "return", "\n", "\n", "", "try", ":", "\n", "            ", "data_time", "=", "storage", ".", "history", "(", "\"data_time\"", ")", ".", "avg", "(", "20", ")", "\n", "", "except", "KeyError", ":", "\n", "# they may not exist in the first few iterations (due to warmup)", "\n", "# or when SimpleTrainer is not used", "\n", "            ", "data_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "iter_time", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "global_avg", "(", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "iter_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "lr", "=", "\"{:.5g}\"", ".", "format", "(", "storage", ".", "history", "(", "\"lr\"", ")", ".", "latest", "(", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "lr", "=", "\"N/A\"", "\n", "\n", "", "eta_string", "=", "self", ".", "_get_eta", "(", "storage", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "max_mem_mb", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", "\n", "", "else", ":", "\n", "            ", "max_mem_mb", "=", "None", "\n", "\n", "# NOTE: max_mem is parsed by grep in \"dev/parse_results.sh\"", "\n", "", "self", ".", "logger", ".", "info", "(", "\n", "\" {eta}iter: {iter}  {losses}  {time}{data_time}lr: {lr}  {memory}\"", ".", "format", "(", "\n", "eta", "=", "f\"eta: {eta_string}  \"", "if", "eta_string", "else", "\"\"", ",", "\n", "iter", "=", "iteration", ",", "\n", "losses", "=", "\"  \"", ".", "join", "(", "\n", "[", "\n", "\"{}: {:.4g}\"", ".", "format", "(", "k", ",", "v", ".", "median", "(", "self", ".", "_window_size", ")", ")", "\n", "for", "k", ",", "v", "in", "storage", ".", "histories", "(", ")", ".", "items", "(", ")", "\n", "if", "\"loss\"", "in", "k", "\n", "]", "\n", ")", ",", "\n", "time", "=", "\"time: {:.4f}  \"", ".", "format", "(", "iter_time", ")", "if", "iter_time", "is", "not", "None", "else", "\"\"", ",", "\n", "data_time", "=", "\"data_time: {:.4f}  \"", ".", "format", "(", "data_time", ")", "if", "data_time", "is", "not", "None", "else", "\"\"", ",", "\n", "lr", "=", "lr", ",", "\n", "memory", "=", "\"max_mem: {:.0f}M\"", ".", "format", "(", "max_mem_mb", ")", "if", "max_mem_mb", "is", "not", "None", "else", "\"\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.__init__": [[281, 293], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter (int): the iteration number to start with\n        \"\"\"", "\n", "self", ".", "_history", "=", "defaultdict", "(", "HistoryBuffer", ")", "\n", "self", ".", "_smoothing_hints", "=", "{", "}", "\n", "self", ".", "_latest_scalars", "=", "{", "}", "\n", "self", ".", "_iter", "=", "start_iter", "\n", "self", ".", "_current_prefix", "=", "\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_image": [[294, 308], ["events.EventStorage._vis_data.append"], "methods", ["None"], ["", "def", "put_image", "(", "self", ",", "img_name", ",", "img_tensor", ")", ":", "\n", "        ", "\"\"\"\n        Add an `img_tensor` associated with `img_name`, to be shown on\n        tensorboard.\n\n        Args:\n            img_name (str): The name of the image to put into tensorboard.\n            img_tensor (torch.Tensor or numpy.array): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is\n                3. The image format should be RGB. The elements in img_tensor\n                can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                The `img_tensor` will be visualized in tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", ".", "append", "(", "(", "img_name", ",", "img_tensor", ",", "self", ".", "_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar": [[309, 335], ["float", "history.update", "events.EventStorage._smoothing_hints.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "put_scalar", "(", "self", ",", "name", ",", "value", ",", "smoothing_hint", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Add a scalar `value` to the `HistoryBuffer` associated with `name`.\n\n        Args:\n            smoothing_hint (bool): a 'hint' on whether this scalar is noisy and should be\n                smoothed when logged. The hint will be accessible through\n                :meth:`EventStorage.smoothing_hints`.  A writer may ignore the hint\n                and apply custom smoothing rule.\n\n                It defaults to True because most scalars we save need to be smoothed to\n                provide any useful signal.\n        \"\"\"", "\n", "name", "=", "self", ".", "_current_prefix", "+", "name", "\n", "history", "=", "self", ".", "_history", "[", "name", "]", "\n", "value", "=", "float", "(", "value", ")", "\n", "history", ".", "update", "(", "value", ",", "self", ".", "_iter", ")", "\n", "self", ".", "_latest_scalars", "[", "name", "]", "=", "(", "value", ",", "self", ".", "_iter", ")", "\n", "\n", "existing_hint", "=", "self", ".", "_smoothing_hints", ".", "get", "(", "name", ")", "\n", "if", "existing_hint", "is", "not", "None", ":", "\n", "            ", "assert", "(", "\n", "existing_hint", "==", "smoothing_hint", "\n", ")", ",", "\"Scalar {} was put with a different smoothing_hint!\"", ".", "format", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_smoothing_hints", "[", "name", "]", "=", "smoothing_hint", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalars": [[336, 346], ["kwargs.items", "events.EventStorage.put_scalar"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar"], ["", "", "def", "put_scalars", "(", "self", ",", "*", ",", "smoothing_hint", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Put multiple scalars from keyword arguments.\n\n        Examples:\n\n            storage.put_scalars(loss=my_loss, accuracy=my_accuracy, smoothing_hint=True)\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "put_scalar", "(", "k", ",", "v", ",", "smoothing_hint", "=", "smoothing_hint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_histogram": [[347, 376], ["torch.histc", "torch.linspace", "dict", "events.EventStorage._histograms.append", "hist_tensor.min().item", "hist_tensor.max().item", "len", "float", "float", "hist_edges[].tolist", "torch.histc.tolist", "hist_tensor.min", "hist_tensor.max", "hist_tensor.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "", "def", "put_histogram", "(", "self", ",", "hist_name", ",", "hist_tensor", ",", "bins", "=", "1000", ")", ":", "\n", "        ", "\"\"\"\n        Create a histogram from a tensor.\n\n        Args:\n            hist_name (str): The name of the histogram to put into tensorboard.\n            hist_tensor (torch.Tensor): A Tensor of arbitrary shape to be converted\n                into a histogram.\n            bins (int): Number of histogram bins.\n        \"\"\"", "\n", "ht_min", ",", "ht_max", "=", "hist_tensor", ".", "min", "(", ")", ".", "item", "(", ")", ",", "hist_tensor", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Create a histogram with PyTorch", "\n", "hist_counts", "=", "torch", ".", "histc", "(", "hist_tensor", ",", "bins", "=", "bins", ")", "\n", "hist_edges", "=", "torch", ".", "linspace", "(", "start", "=", "ht_min", ",", "end", "=", "ht_max", ",", "steps", "=", "bins", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Parameter for the add_histogram_raw function of SummaryWriter", "\n", "hist_params", "=", "dict", "(", "\n", "tag", "=", "hist_name", ",", "\n", "min", "=", "ht_min", ",", "\n", "max", "=", "ht_max", ",", "\n", "num", "=", "len", "(", "hist_tensor", ")", ",", "\n", "sum", "=", "float", "(", "hist_tensor", ".", "sum", "(", ")", ")", ",", "\n", "sum_squares", "=", "float", "(", "torch", ".", "sum", "(", "hist_tensor", "**", "2", ")", ")", ",", "\n", "bucket_limits", "=", "hist_edges", "[", "1", ":", "]", ".", "tolist", "(", ")", ",", "\n", "bucket_counts", "=", "hist_counts", ".", "tolist", "(", ")", ",", "\n", "global_step", "=", "self", ".", "_iter", ",", "\n", ")", "\n", "self", ".", "_histograms", ".", "append", "(", "hist_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.history": [[377, 386], ["events.EventStorage._history.get", "KeyError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "history", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            HistoryBuffer: the scalar history for name\n        \"\"\"", "\n", "ret", "=", "self", ".", "_history", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "ret", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "\"No history metric available for {}!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.histories": [[387, 393], ["None"], "methods", ["None"], ["", "def", "histories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> HistoryBuffer]: the HistoryBuffer for all scalars\n        \"\"\"", "\n", "return", "self", ".", "_history", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.latest": [[394, 401], ["None"], "methods", ["None"], ["", "def", "latest", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[str -> (float, int)]: mapping from the name of each scalar to the most\n                recent value and the iteration number its added.\n        \"\"\"", "\n", "return", "self", ".", "_latest_scalars", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.latest_with_smoothing_hint": [[402, 418], ["events.EventStorage._latest_scalars.items", "events.EventStorage._history[].median"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median"], ["", "def", "latest_with_smoothing_hint", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Similar to :meth:`latest`, but the returned values\n        are either the un-smoothed original latest value,\n        or a median of the given window_size,\n        depend on whether the smoothing_hint is True.\n\n        This provides a default behavior that other writers can use.\n        \"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "(", "v", ",", "itr", ")", "in", "self", ".", "_latest_scalars", ".", "items", "(", ")", ":", "\n", "            ", "result", "[", "k", "]", "=", "(", "\n", "self", ".", "_history", "[", "k", "]", ".", "median", "(", "window_size", ")", "if", "self", ".", "_smoothing_hints", "[", "k", "]", "else", "v", ",", "\n", "itr", ",", "\n", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.smoothing_hints": [[419, 426], ["None"], "methods", ["None"], ["", "def", "smoothing_hints", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> bool]: the user-provided hint on whether the scalar\n                is noisy and needs smoothing.\n        \"\"\"", "\n", "return", "self", ".", "_smoothing_hints", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step": [[427, 435], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        User should either: (1) Call this function to increment storage.iter when needed. Or\n        (2) Set `storage.iter` to the correct iteration number before each iteration.\n\n        The storage will then be able to associate the new data with an iteration number.\n        \"\"\"", "\n", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter": [[445, 448], ["int"], "methods", ["None"], ["", "@", "iter", ".", "setter", "\n", "def", "iter", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "_iter", "=", "int", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iteration": [[449, 453], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iteration", "(", "self", ")", ":", "\n", "# for backward compatibility", "\n", "        ", "return", "self", ".", "_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.__enter__": [[454, 457], ["_CURRENT_STORAGE_STACK.append"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "_CURRENT_STORAGE_STACK", ".", "append", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.__exit__": [[458, 461], ["_CURRENT_STORAGE_STACK.pop"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "assert", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "==", "self", "\n", "_CURRENT_STORAGE_STACK", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.name_scope": [[462, 473], ["name.rstrip"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "name_scope", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Yields:\n            A context within which all the events added to this storage\n            will be prefixed by the name scope.\n        \"\"\"", "\n", "old_prefix", "=", "self", ".", "_current_prefix", "\n", "self", ".", "_current_prefix", "=", "name", ".", "rstrip", "(", "\"/\"", ")", "+", "\"/\"", "\n", "yield", "\n", "self", ".", "_current_prefix", "=", "old_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.clear_images": [[474, 480], ["None"], "methods", ["None"], ["", "def", "clear_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored images for visualization. This should be called\n        after images are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.clear_histograms": [[481, 487], ["None"], "methods", ["None"], ["", "def", "clear_histograms", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored histograms for visualization.\n        This should be called after histograms are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage": [[26, 36], ["len"], "function", ["None"], ["def", "get_event_storage", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The :class:`EventStorage` object that's currently being used.\n        Throws an error if no :class:`EventStorage` is currently enabled.\n    \"\"\"", "\n", "assert", "len", "(", "\n", "_CURRENT_STORAGE_STACK", "\n", ")", ",", "\"get_event_storage() has to be called inside a 'with EventStorage(...)' context!\"", "\n", "return", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.get_world_size": [[21, 27], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["def", "get_world_size", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.get_rank": [[29, 35], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "def", "get_rank", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.get_local_rank": [[37, 48], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "def", "get_local_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The rank of the current process within the local (per-machine) process group.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "assert", "_LOCAL_PROCESS_GROUP", "is", "not", "None", "\n", "return", "dist", ".", "get_rank", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.get_local_size": [[50, 61], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "get_local_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The size of the per-machine process group,\n        i.e. the number of processes per machine.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.is_main_process": [[63, 65], ["comm.get_rank"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "def", "is_main_process", "(", ")", "->", "bool", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize": [[67, 80], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._get_global_gloo_group": [[82, 92], ["functools.lru_cache", "torch.get_backend", "torch.new_group"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "_get_global_gloo_group", "(", ")", ":", "\n", "    ", "\"\"\"\n    Return a process group based on gloo backend, containing all the ranks\n    The result is cached.\n    \"\"\"", "\n", "if", "dist", ".", "get_backend", "(", ")", "==", "\"nccl\"", ":", "\n", "        ", "return", "dist", ".", "new_group", "(", "backend", "=", "\"gloo\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._serialize_to_tensor": [[94, 110], ["torch.get_backend", "torch.device", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "len", "logging.getLogger", "logging.getLogger.warning", "torch.ByteTensor", "torch.ByteTensor", "comm.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "", "def", "_serialize_to_tensor", "(", "data", ",", "group", ")", ":", "\n", "    ", "backend", "=", "dist", ".", "get_backend", "(", "group", ")", "\n", "assert", "backend", "in", "[", "\"gloo\"", ",", "\"nccl\"", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", "if", "backend", "==", "\"gloo\"", "else", "\"cuda\"", ")", "\n", "\n", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "if", "len", "(", "buffer", ")", ">", "1024", "**", "3", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Rank {} trying to all-gather {:.2f} GB of data on device {}\"", ".", "format", "(", "\n", "get_rank", "(", ")", ",", "len", "(", "buffer", ")", "/", "(", "1024", "**", "3", ")", ",", "device", "\n", ")", "\n", ")", "\n", "", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._pad_to_largest_tensor": [[112, 137], ["torch.get_world_size", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.zeros", "torch.zeros", "int", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        list[int]: size of the tensor, on each rank\n        Tensor: padded tensor that has the max size\n    \"\"\"", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "(", "\n", "world_size", ">=", "1", "\n", ")", ",", "\"comm.gather/all_gather must be called from ranks within the given group!\"", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "size_list", "=", "[", "\n", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ",", "group", "=", "group", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "zeros", "(", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "size_list", ",", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.all_gather": [[139, 175], ["comm._serialize_to_tensor", "comm._pad_to_largest_tensor", "max", "torch.all_gather", "zip", "comm.get_world_size", "comm._get_global_gloo_group", "torch.get_world_size", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._serialize_to_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._pad_to_largest_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._get_global_gloo_group", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "all_gather", "(", "data", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather": [[177, 218], ["torch.get_rank", "comm._serialize_to_tensor", "comm._pad_to_largest_tensor", "comm.get_world_size", "comm._get_global_gloo_group", "torch.get_world_size", "max", "torch.gather", "zip", "torch.gather", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._serialize_to_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._pad_to_largest_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm._get_global_gloo_group", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather"], ["", "def", "gather", "(", "data", ",", "dst", "=", "0", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        dst (int): destination rank\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: on dst, a list of data gathered from each rank. Otherwise,\n            an empty list.\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "if", "rank", "==", "dst", ":", "\n", "        ", "max_size", "=", "max", "(", "size_list", ")", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "gather", "(", "tensor", ",", "tensor_list", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "            ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "", "return", "data_list", "\n", "", "else", ":", "\n", "        ", "dist", ".", "gather", "(", "tensor", ",", "[", "]", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.shared_random_seed": [[220, 232], ["numpy.random.randint", "comm.all_gather"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather"], ["", "", "def", "shared_random_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        int: a random number that is the same across all workers.\n            If workers need a shared RNG, they can use this shared seed to\n            create one.\n\n    All workers must call this function, otherwise it will deadlock.\n    \"\"\"", "\n", "ints", "=", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", "\n", "all_ints", "=", "all_gather", "(", "ints", ")", "\n", "return", "all_ints", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.reduce_dict": [[234, 264], ["comm.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.reduce", "input_dict.keys", "names.append", "torch.stack.append", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the reduced results.\n\n    Args:\n        input_dict (dict): inputs to be reduced. All the values must be scalar CUDA Tensor.\n        average (bool): whether to do average or sum\n\n    Returns:\n        a dict with the same keys as input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "values", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.__init__": [[69, 96], ["isinstance", "isinstance", "isinstance", "ValueError", "isinstance", "pycocotools.frPyObjects.astype", "pycocotools.frPyObjects", "pycocotools.decode", "numpy.asarray().reshape", "type", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["def", "__init__", "(", "self", ",", "mask_or_polygons", ",", "height", ",", "width", ")", ":", "\n", "        ", "self", ".", "_mask", "=", "self", ".", "_polygons", "=", "self", ".", "_has_holes", "=", "None", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "\n", "m", "=", "mask_or_polygons", "\n", "if", "isinstance", "(", "m", ",", "dict", ")", ":", "\n", "# RLEs", "\n", "            ", "assert", "\"counts\"", "in", "m", "and", "\"size\"", "in", "m", "\n", "if", "isinstance", "(", "m", "[", "\"counts\"", "]", ",", "list", ")", ":", "# uncompressed RLEs", "\n", "                ", "h", ",", "w", "=", "m", "[", "\"size\"", "]", "\n", "assert", "h", "==", "height", "and", "w", "==", "width", "\n", "m", "=", "mask_util", ".", "frPyObjects", "(", "m", ",", "h", ",", "w", ")", "\n", "", "self", ".", "_mask", "=", "mask_util", ".", "decode", "(", "m", ")", "[", ":", ",", ":", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "list", ")", ":", "# list[ndarray]", "\n", "            ", "self", ".", "_polygons", "=", "[", "np", ".", "asarray", "(", "x", ")", ".", "reshape", "(", "-", "1", ")", "for", "x", "in", "m", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "np", ".", "ndarray", ")", ":", "# assumed to be a binary mask", "\n", "            ", "assert", "m", ".", "shape", "[", "1", "]", "!=", "2", ",", "m", ".", "shape", "\n", "assert", "m", ".", "shape", "==", "(", "height", ",", "width", ")", ",", "m", ".", "shape", "\n", "self", ".", "_mask", "=", "m", ".", "astype", "(", "\"uint8\"", ")", "\n", "return", "\n", "\n", "", "raise", "ValueError", "(", "\"GenericMask cannot handle object {} of type '{}'\"", ".", "format", "(", "m", ",", "type", "(", "m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.mask": [[97, 102], ["visualizer.GenericMask.polygons_to_mask"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.polygons_to_mask"], ["", "@", "property", "\n", "def", "mask", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_mask", "is", "None", ":", "\n", "            ", "self", ".", "_mask", "=", "self", ".", "polygons_to_mask", "(", "self", ".", "_polygons", ")", "\n", "", "return", "self", ".", "_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.polygons": [[103, 108], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "polygons", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_polygons", "is", "None", ":", "\n", "            ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "return", "self", ".", "_polygons", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.has_holes": [[109, 117], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "has_holes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_has_holes", "is", "None", ":", "\n", "            ", "if", "self", ".", "_mask", "is", "not", "None", ":", "\n", "                ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_has_holes", "=", "False", "# if original format is polygon, does not have holes", "\n", "", "", "return", "self", ".", "_has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.mask_to_polygons": [[118, 136], ["numpy.ascontiguousarray", "cv2.findContours", "numpy.ascontiguousarray.astype", "x.flatten", "len", "hierarchy.reshape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "mask_to_polygons", "(", "self", ",", "mask", ")", ":", "\n", "# cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level", "\n", "# hierarchy. External contours (boundary) of the object are placed in hierarchy-1.", "\n", "# Internal contours (holes) are placed in hierarchy-2.", "\n", "# cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.", "\n", "        ", "mask", "=", "np", ".", "ascontiguousarray", "(", "mask", ")", "# some versions of cv2 does not support incontiguous arr", "\n", "res", "=", "cv2", ".", "findContours", "(", "mask", ".", "astype", "(", "\"uint8\"", ")", ",", "cv2", ".", "RETR_CCOMP", ",", "cv2", ".", "CHAIN_APPROX_NONE", ")", "\n", "hierarchy", "=", "res", "[", "-", "1", "]", "\n", "if", "hierarchy", "is", "None", ":", "# empty mask", "\n", "            ", "return", "[", "]", ",", "False", "\n", "", "has_holes", "=", "(", "hierarchy", ".", "reshape", "(", "-", "1", ",", "4", ")", "[", ":", ",", "3", "]", ">=", "0", ")", ".", "sum", "(", ")", ">", "0", "\n", "res", "=", "res", "[", "-", "2", "]", "\n", "res", "=", "[", "x", ".", "flatten", "(", ")", "for", "x", "in", "res", "]", "\n", "# These coordinates from OpenCV are integers in range [0, W-1 or H-1].", "\n", "# We add 0.5 to turn them into real-value coordinate space. A better solution", "\n", "# would be to first +0.5 and then dilate the returned polygon by 0.5.", "\n", "res", "=", "[", "x", "+", "0.5", "for", "x", "in", "res", "if", "len", "(", "x", ")", ">=", "6", "]", "\n", "return", "res", ",", "has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.polygons_to_mask": [[137, 141], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["", "def", "polygons_to_mask", "(", "self", ",", "polygons", ")", ":", "\n", "        ", "rle", "=", "mask_util", ".", "frPyObjects", "(", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "rle", "=", "mask_util", ".", "merge", "(", "rle", ")", "\n", "return", "mask_util", ".", "decode", "(", "rle", ")", "[", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.area": [[142, 144], ["visualizer.GenericMask.mask.sum"], "methods", ["None"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mask", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.bbox": [[145, 152], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.toBbox"], "methods", ["None"], ["", "def", "bbox", "(", "self", ")", ":", "\n", "        ", "p", "=", "mask_util", ".", "frPyObjects", "(", "self", ".", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "p", "=", "mask_util", ".", "merge", "(", "p", ")", "\n", "bbox", "=", "mask_util", ".", "toBbox", "(", "p", ")", "\n", "bbox", "[", "2", "]", "+=", "bbox", "[", "0", "]", "\n", "bbox", "[", "3", "]", "+=", "bbox", "[", "1", "]", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.__init__": [[155, 190], ["torch.unique", "areas.numpy.numpy.numpy", "numpy.argsort", "visualizer._PanopticPrediction._seg_ids.tolist", "zip", "numpy.unique", "panoptic_seg.numpy", "segments_info.append", "float", "metadata.thing_dataset_id_to_contiguous_id.values", "int", "int", "bool"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "panoptic_seg", ",", "segments_info", ",", "metadata", "=", "None", ")", ":", "\n", "        ", "if", "segments_info", "is", "None", ":", "\n", "            ", "assert", "metadata", "is", "not", "None", "\n", "# If \"segments_info\" is None, we assume \"panoptic_img\" is a", "\n", "# H*W int32 image storing the panoptic_id in the format of", "\n", "# category_id * label_divisor + instance_id. We reserve -1 for", "\n", "# VOID label.", "\n", "label_divisor", "=", "metadata", ".", "label_divisor", "\n", "segments_info", "=", "[", "]", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_seg", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "# VOID region.", "\n", "                    ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "label_divisor", "\n", "isthing", "=", "pred_class", "in", "metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "int", "(", "panoptic_label", ")", ",", "\n", "\"category_id\"", ":", "int", "(", "pred_class", ")", ",", "\n", "\"isthing\"", ":", "bool", "(", "isthing", ")", ",", "\n", "}", "\n", ")", "\n", "", "", "del", "metadata", "\n", "\n", "self", ".", "_seg", "=", "panoptic_seg", "\n", "\n", "self", ".", "_sinfo", "=", "{", "s", "[", "\"id\"", "]", ":", "s", "for", "s", "in", "segments_info", "}", "# seg id -> seg info", "\n", "segment_ids", ",", "areas", "=", "torch", ".", "unique", "(", "panoptic_seg", ",", "sorted", "=", "True", ",", "return_counts", "=", "True", ")", "\n", "areas", "=", "areas", ".", "numpy", "(", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", "\n", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", "=", "segment_ids", "[", "sorted_idxs", "]", ",", "areas", "[", "sorted_idxs", "]", "\n", "self", ".", "_seg_ids", "=", "self", ".", "_seg_ids", ".", "tolist", "(", ")", "\n", "for", "sid", ",", "area", "in", "zip", "(", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", ")", ":", "\n", "            ", "if", "sid", "in", "self", ".", "_sinfo", ":", "\n", "                ", "self", ".", "_sinfo", "[", "sid", "]", "[", "\"area\"", "]", "=", "float", "(", "area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.non_empty_mask": [[191, 206], ["len", "numpy.zeros", "len", "empty_ids.append"], "methods", ["None"], ["", "", "", "def", "non_empty_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            (H, W) array, a mask for all pixels that have a prediction\n        \"\"\"", "\n", "empty_ids", "=", "[", "]", "\n", "for", "id", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "if", "id", "not", "in", "self", ".", "_sinfo", ":", "\n", "                ", "empty_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "empty_ids", ")", "==", "0", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "self", ".", "_seg", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "", "assert", "(", "\n", "len", "(", "empty_ids", ")", "==", "1", "\n", ")", ",", "\">1 ids corresponds to no labels. This is currently not supported\"", "\n", "return", "(", "self", ".", "_seg", "!=", "empty_ids", "[", "0", "]", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.semantic_masks": [[207, 214], ["visualizer._PanopticPrediction._sinfo.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "semantic_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "# Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.", "\n", "                ", "continue", "\n", "", "yield", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.instance_masks": [[215, 223], ["visualizer._PanopticPrediction._sinfo.get", "mask.sum"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "instance_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "not", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "                ", "continue", "\n", "", "mask", "=", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "if", "mask", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "yield", "mask", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.__init__": [[249, 259], ["visualizer.VisImage._setup_figure"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage._setup_figure"], ["    ", "def", "__init__", "(", "self", ",", "img", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (ndarray): an RGB image of shape (H, W, 3).\n            scale (float): scale the input image\n        \"\"\"", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "width", ",", "self", ".", "height", "=", "img", ".", "shape", "[", "1", "]", ",", "img", ".", "shape", "[", "0", "]", "\n", "self", ".", "_setup_figure", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage._setup_figure": [[260, 286], ["matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure.get_dpi", "matplotlib.Figure.set_size_inches", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.Figure.add_axes", "mplfigure.Figure.add_axes.axis", "mplfigure.Figure.add_axes.imshow"], "methods", ["None"], ["", "def", "_setup_figure", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            Same as in :meth:`__init__()`.\n\n        Returns:\n            fig (matplotlib.pyplot.figure): top level container for all the image plot elements.\n            ax (matplotlib.pyplot.Axes): contains figure elements and sets the coordinate system.\n        \"\"\"", "\n", "fig", "=", "mplfigure", ".", "Figure", "(", "frameon", "=", "False", ")", "\n", "self", ".", "dpi", "=", "fig", ".", "get_dpi", "(", ")", "\n", "# add a small 1e-2 to avoid precision lost due to matplotlib's truncation", "\n", "# (https://github.com/matplotlib/matplotlib/issues/15363)", "\n", "fig", ".", "set_size_inches", "(", "\n", "(", "self", ".", "width", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", "(", "self", ".", "height", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", ")", "\n", "self", ".", "canvas", "=", "FigureCanvasAgg", "(", "fig", ")", "\n", "# self.canvas = mpl.backends.backend_cairo.FigureCanvasCairo(fig)", "\n", "ax", "=", "fig", ".", "add_axes", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "ax", ".", "axis", "(", "\"off\"", ")", "\n", "# Need to imshow this first so that other patches can be drawn on top", "\n", "ax", ".", "imshow", "(", "img", ",", "extent", "=", "(", "0", ",", "self", ".", "width", ",", "self", ".", "height", ",", "0", ")", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "\n", "self", ".", "fig", "=", "fig", "\n", "self", ".", "ax", "=", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save": [[287, 295], ["visualizer.VisImage.fig.savefig"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            filepath (str): a string that contains the absolute path, including the file name, where\n                the visualized image will be saved.\n        \"\"\"", "\n", "# self.fig.savefig(filepath)", "\n", "self", ".", "fig", ".", "savefig", "(", "filepath", "[", ":", "-", "4", "]", "+", "'.svg'", ",", "format", "=", "'svg'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image": [[296, 315], ["canvas.print_to_buffer", "numpy.frombuffer", "numpy.frombuffer.reshape", "numpy.split", "rgb.astype"], "methods", ["None"], ["", "def", "get_image", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            ndarray:\n                the visualized image of shape (H, W, 3) (RGB) in uint8 type.\n                The shape is scaled w.r.t the input image using the given `scale` argument.\n        \"\"\"", "\n", "canvas", "=", "self", ".", "canvas", "\n", "s", ",", "(", "width", ",", "height", ")", "=", "canvas", ".", "print_to_buffer", "(", ")", "\n", "# buf = io.BytesIO()  # works for cairo backend", "\n", "# canvas.print_rgba(buf)", "\n", "# width, height = self.width, self.height", "\n", "# s = buf.getvalue()", "\n", "\n", "buffer", "=", "np", ".", "frombuffer", "(", "s", ",", "dtype", "=", "\"uint8\"", ")", "\n", "\n", "img_rgba", "=", "buffer", ".", "reshape", "(", "height", ",", "width", ",", "4", ")", "\n", "rgb", ",", "alpha", "=", "np", ".", "split", "(", "img_rgba", ",", "[", "3", "]", ",", "axis", "=", "2", ")", "\n", "return", "rgb", ".", "astype", "(", "\"uint8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.__init__": [[339, 363], ["numpy.asarray().clip().astype", "visualizer.VisImage", "torch.device", "max", "detectron2.data.MetadataCatalog.get", "numpy.asarray().clip", "numpy.sqrt", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip"], ["def", "__init__", "(", "self", ",", "img_rgb", ",", "metadata", "=", "None", ",", "scale", "=", "1.0", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_rgb: a numpy array of shape (H, W, C), where H and W correspond to\n                the height and width of the image respectively. C is the number of\n                color channels. The image is required to be in RGB format since that\n                is a requirement of the Matplotlib library. The image is also expected\n                to be in the range [0, 255].\n            metadata (Metadata): image metadata.\n            instance_mode (ColorMode): defines one of the pre-defined style for drawing\n                instances on an image.\n        \"\"\"", "\n", "self", ".", "img", "=", "np", ".", "asarray", "(", "img_rgb", ")", ".", "clip", "(", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "if", "metadata", "is", "None", ":", "\n", "            ", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\"__nonexist__\"", ")", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "output", "=", "VisImage", "(", "self", ".", "img", ",", "scale", "=", "scale", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# too small texts are useless, therefore clamp to 9", "\n", "self", ".", "_default_font_size", "=", "max", "(", "\n", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "//", "90", ",", "10", "//", "scale", "\n", ")", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_instance_predictions": [[364, 419], ["visualizer._create_text_labels", "predictions.has", "visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.has", "predictions.has", "visualizer.Visualizer.metadata.get", "predictions.has", "numpy.asarray", "visualizer.Visualizer.metadata.get", "visualizer.Visualizer._create_grayscale_image", "visualizer.GenericMask", "visualizer.Visualizer._jitter", "predictions.has", "predictions.pred_masks.any"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._jitter", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["", "def", "draw_instance_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "boxes", "=", "predictions", ".", "pred_boxes", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "#luyao#", "\n", "# labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "#luyao#", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "np", ".", "asarray", "(", "predictions", ".", "pred_masks", ")", "\n", "masks", "=", "[", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "for", "x", "in", "masks", "]", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "# masks = None", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "classes", "\n", "]", "\n", "#luyao#", "\n", "alpha", "=", "0.8", "\n", "", "else", ":", "\n", "            ", "colors", "=", "None", "\n", "alpha", "=", "0.77", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "\n", "(", "predictions", ".", "pred_masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", "\n", "else", "None", "\n", ")", "\n", "alpha", "=", "0.3", "\n", "\n", "", "self", ".", "overlay_instances", "(", "\n", "masks", "=", "masks", ",", "\n", "boxes", "=", "boxes", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_sem_seg": [[420, 455], ["isinstance", "numpy.unique", "numpy.argsort().tolist", "filter", "sem_seg.numpy.numpy.numpy", "visualizer.Visualizer.draw_binary_mask", "numpy.argsort", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_binary_mask"], ["", "def", "draw_sem_seg", "(", "self", ",", "sem_seg", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.8", ")", ":", "\n", "        ", "\"\"\"\n        Draw semantic segmentation predictions/labels.\n\n        Args:\n            sem_seg (Tensor or ndarray): the segmentation of shape (H, W).\n                Each value is the integer label of the pixel.\n            area_threshold (int): segments with less than `area_threshold` are not drawn.\n            alpha (float): the larger it is, the more opaque the segmentations are.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "if", "isinstance", "(", "sem_seg", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sem_seg", "=", "sem_seg", ".", "numpy", "(", ")", "\n", "", "labels", ",", "areas", "=", "np", ".", "unique", "(", "sem_seg", ",", "return_counts", "=", "True", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "labels", "[", "sorted_idxs", "]", "\n", "for", "label", "in", "filter", "(", "lambda", "l", ":", "l", "<", "len", "(", "self", ".", "metadata", ".", "stuff_classes", ")", ",", "labels", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "label", "]", "]", "\n", "", "except", "(", "AttributeError", ",", "IndexError", ")", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "binary_mask", "=", "(", "sem_seg", "==", "label", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "label", "]", "\n", "self", ".", "draw_binary_mask", "(", "\n", "binary_mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_panoptic_seg_predictions": [[456, 517], ["visualizer._PanopticPrediction", "visualizer._PanopticPrediction.semantic_masks", "list", "list", "visualizer._create_text_labels", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer._create_grayscale_image", "visualizer.Visualizer.draw_binary_mask", "visualizer._PanopticPrediction.instance_masks", "len", "zip", "visualizer._PanopticPrediction.non_empty_mask", "visualizer.Visualizer._jitter"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.non_empty_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._jitter"], ["", "def", "draw_panoptic_seg_predictions", "(", "\n", "self", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.7", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Draw panoptic prediction results on an image.\n\n        Args:\n            panoptic_seg (Tensor): of shape (height, width) where the values are ids for each\n                segment.\n            segments_info (list[dict]): Describe each segment in `panoptic_seg`.\n                Each dict contains keys \"id\", \"category_id\", \"isthing\".\n            area_threshold (int): stuff segments with less than `area_threshold` are not drawn.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "pred", ".", "non_empty_mask", "(", ")", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", "\n", "self", ".", "draw_binary_mask", "(", "\n", "mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "# draw mask for all instances second", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "\n", "try", ":", "\n", "            ", "scores", "=", "[", "x", "[", "\"score\"", "]", "for", "x", "in", "sinfo", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "scores", "=", "None", "\n", "", "labels", "=", "_create_text_labels", "(", "category_ids", ",", "scores", ",", "self", ".", "metadata", ".", "thing_classes", ")", "\n", "\n", "try", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "category_ids", "\n", "]", "\n", "", "except", "AttributeError", ":", "\n", "            ", "colors", "=", "None", "\n", "", "self", ".", "overlay_instances", "(", "masks", "=", "masks", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "colors", ",", "alpha", "=", "alpha", ")", "\n", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_dataset_dict": [[518, 586], ["dic.get", "dic.get", "dic.get", "visualizer.Visualizer.metadata.get", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer.draw_sem_seg", "torch.Tensor", "visualizer.Visualizer.draw_panoptic_seg_predictions", "numpy.array().reshape", "visualizer.Visualizer.metadata.get", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "rgb2id", "len", "detectron2.structures.BoxMode.convert", "visualizer.Visualizer._jitter", "zip", "numpy.array", "len", "a.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_sem_seg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._jitter", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "draw_dataset_dict", "(", "self", ",", "dic", ")", ":", "\n", "        ", "\"\"\"\n        Draw annotations/segmentaions in Detectron2 Dataset format.\n\n        Args:\n            dic (dict): annotation/segmentation data of one image, in Detectron2 Dataset format.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "annos", "=", "dic", ".", "get", "(", "\"annotations\"", ",", "None", ")", "\n", "if", "annos", ":", "\n", "            ", "if", "\"segmentation\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "", "else", ":", "\n", "                ", "masks", "=", "None", "\n", "", "if", "\"keypoints\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "keypts", "=", "[", "x", "[", "\"keypoints\"", "]", "for", "x", "in", "annos", "]", "\n", "keypts", "=", "np", ".", "array", "(", "keypts", ")", ".", "reshape", "(", "len", "(", "annos", ")", ",", "-", "1", ",", "3", ")", "\n", "", "else", ":", "\n", "                ", "keypts", "=", "None", "\n", "\n", "", "boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "x", "[", "\"bbox\"", "]", ",", "x", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "if", "len", "(", "x", "[", "\"bbox\"", "]", ")", "==", "4", "\n", "else", "x", "[", "\"bbox\"", "]", "\n", "for", "x", "in", "annos", "\n", "]", "\n", "\n", "labels", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "colors", "=", "None", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "                ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "labels", "\n", "]", "\n", "", "names", "=", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", "\n", "if", "names", ":", "\n", "                ", "labels", "=", "[", "names", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "", "labels", "=", "[", "\n", "\"{}\"", ".", "format", "(", "i", ")", "+", "(", "\"|crowd\"", "if", "a", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "else", "\"\"", ")", "\n", "for", "i", ",", "a", "in", "zip", "(", "labels", ",", "annos", ")", "\n", "]", "\n", "self", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "boxes", "=", "boxes", ",", "masks", "=", "masks", ",", "keypoints", "=", "keypts", ",", "assigned_colors", "=", "colors", "\n", ")", "\n", "\n", "", "sem_seg", "=", "dic", ".", "get", "(", "\"sem_seg\"", ",", "None", ")", "\n", "if", "sem_seg", "is", "None", "and", "\"sem_seg_file_name\"", "in", "dic", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "dic", "[", "\"sem_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "sem_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "sem_seg", "=", "np", ".", "asarray", "(", "sem_seg", ",", "dtype", "=", "\"uint8\"", ")", "\n", "", "", "if", "sem_seg", "is", "not", "None", ":", "\n", "            ", "self", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "pan_seg", "=", "dic", ".", "get", "(", "\"pan_seg\"", ",", "None", ")", "\n", "if", "pan_seg", "is", "None", "and", "\"pan_seg_file_name\"", "in", "dic", ":", "\n", "            ", "assert", "\"segments_info\"", "in", "dic", "\n", "with", "PathManager", ".", "open", "(", "dic", "[", "\"pan_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "pan_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "pan_seg", "=", "np", ".", "asarray", "(", "pan_seg", ")", "\n", "from", "panopticapi", ".", "utils", "import", "rgb2id", "\n", "\n", "pan_seg", "=", "rgb2id", "(", "pan_seg", ")", "\n", "", "segments_info", "=", "dic", "[", "\"segments_info\"", "]", "\n", "", "if", "pan_seg", "is", "not", "None", ":", "\n", "            ", "pan_seg", "=", "torch", ".", "Tensor", "(", "pan_seg", ")", "\n", "self", ".", "draw_panoptic_seg_predictions", "(", "pan_seg", ",", "segments_info", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances": [[587, 751], ["range", "visualizer.Visualizer._convert_boxes", "len", "visualizer.Visualizer._convert_masks", "visualizer.Visualizer._convert_keypoints", "visualizer.Visualizer.overlay_rotated_instances", "numpy.prod", "numpy.argsort().tolist", "len", "len", "len", "colormap.random_color", "numpy.asarray", "visualizer.Visualizer.draw_box", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "visualizer.Visualizer.draw_and_connect_keypoints", "len", "len", "range", "numpy.argsort", "visualizer.Visualizer.draw_polygon", "numpy.sqrt", "x.area", "len", "segment.reshape", "masks[].bbox", "numpy.clip", "len", "numpy.median", "masks[].mask.nonzero"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_keypoints", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_rotated_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.random_color", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_box", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_and_connect_keypoints", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.GenericMask.bbox", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median"], ["", "def", "overlay_instances", "(", "\n", "self", ",", "\n", "*", ",", "\n", "boxes", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "masks", "=", "None", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "None", ",", "\n", "alpha", "=", "0.5", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (Boxes, RotatedBoxes or ndarray): either a :class:`Boxes`,\n                or an Nx4 numpy array of XYXY_ABS format for the N objects in a single image,\n                or a :class:`RotatedBoxes`,\n                or an Nx5 numpy array of (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image,\n            labels (list[str]): the text to be displayed for each instance.\n            masks (masks-like object): Supported types are:\n\n                * :class:`detectron2.structures.PolygonMasks`,\n                  :class:`detectron2.structures.BitMasks`.\n                * list[list[ndarray]]: contains the segmentation masks for all objects in one image.\n                  The first level of the list corresponds to individual instances. The second\n                  level to all the polygon that compose the instance, and the third level\n                  to the polygon coordinates. The third level should have the format of\n                  [x0, y0, x1, y1, ..., xn, yn] (n >= 3).\n                * list[ndarray]: each ndarray is a binary mask of shape (H, W).\n                * list[dict]: each dict is a COCO-style RLE.\n            keypoints (Keypoint or array like): an array-like object of shape (N, K, 3),\n                where the N is the number of instances and K is the number of keypoints.\n                The last dimension corresponds to (x, y, visibility or score).\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "None", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "self", ".", "_convert_boxes", "(", "boxes", ")", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "            ", "masks", "=", "self", ".", "_convert_masks", "(", "masks", ")", "\n", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "masks", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "masks", ")", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "keypoints", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "keypoints", ")", "\n", "", "keypoints", "=", "self", ".", "_convert_keypoints", "(", "keypoints", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "labels", ")", "==", "num_instances", "\n", "", "if", "assigned_colors", "is", "None", ":", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "if", "boxes", "is", "not", "None", "and", "boxes", ".", "shape", "[", "1", "]", "==", "5", ":", "\n", "            ", "return", "self", ".", "overlay_rotated_instances", "(", "\n", "boxes", "=", "boxes", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "areas", "=", "None", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "prod", "(", "boxes", "[", ":", ",", "2", ":", "]", "-", "boxes", "[", ":", ",", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "asarray", "(", "[", "x", ".", "area", "(", ")", "for", "x", "in", "masks", "]", ")", "\n", "\n", "", "if", "areas", "is", "not", "None", ":", "\n", "            ", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "if", "boxes", "is", "not", "None", "else", "None", "\n", "labels", "=", "[", "labels", "[", "k", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "masks", "=", "[", "masks", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "if", "masks", "is", "not", "None", "else", "None", "\n", "# assigned_colors = [assigned_colors[idx] for idx in sorted_idxs]", "\n", "keypoints", "=", "keypoints", "[", "sorted_idxs", "]", "if", "keypoints", "is", "not", "None", "else", "None", "\n", "#luyao#", "\n", "", "assigned_colors", "=", "[", "[", "0", ",", "113.985", ",", "118.955", "]", ",", "[", "216.75", ",", "82.875", ",", "24.99", "]", ",", "[", "236.895", ",", "176.97", ",", "31.875", "]", ",", "[", "125.97", ",", "46.92", ",", "141.78", "]", ",", "[", "118.83", ",", "171.87", ",", "47.94", "]", ",", "[", "76.755", ",", "189.975", ",", "237.915", "]", ",", "[", "161.925", ",", "19.89", ",", "46.92", "]", ",", "[", "255", ",", "140", ",", "0", "]", ",", "[", "70", ",", "130", ",", "180", "]", ",", "[", "128", ",", "128", ",", "0", "]", ",", "[", "205", ",", "92", ",", "92", "]", ",", "[", "128", ",", "0", ",", "128", "]", ",", "[", "255", ",", "182", ",", "193", "]", ",", "[", "255", ",", "255", ",", "0", "]", ",", "[", "105", ",", "105", ",", "105", "]", ",", "[", "0", ",", "255", ",", "255", "]", ",", "[", "0", ",", "255", ",", "0", "]", ",", "[", "210", ",", "180", ",", "140", "]", ",", "[", "255", ",", "0", ",", "0", "]", ",", "[", "0", ",", "139", ",", "139", "]", ",", "[", "255", ",", "0", ",", "255", "]", ",", "[", "127", ",", "255", ",", "0", "]", ",", "[", "75", ",", "0", ",", "130", "]", ",", "[", "32", ",", "178", ",", "170", "]", ",", "[", "255", ",", "215", ",", "0", "]", ",", "[", "219", ",", "112", ",", "147", "]", ",", "[", "148", ",", "0", ",", "211", "]", ",", "[", "100", ",", "149", ",", "237", "]", ",", "[", "175", ",", "238", ",", "238", "]", ",", "[", "143", ",", "188", ",", "143", "]", ",", "[", "255", ",", "255", ",", "224", "]", ",", "[", "244", ",", "164", ",", "96", "]", ",", "[", "188", ",", "143", ",", "143", "]", ",", "[", "192", ",", "192", ",", "192", "]", ",", "[", "220", ",", "20", ",", "60", "]", ",", "[", "218", ",", "112", ",", "214", "]", ",", "[", "147", ",", "112", ",", "219", "]", "]", "\n", "\n", "\n", "# assigned_colors = [[1,140/255,0],[30/255,144/255,1],[148/255,0,211/255],[0,1,1],[1,0,0],\\", "\n", "#     [30/255,143/255,1],[0.94,0.5,0.5],[1,1,0],[0.5,0.5,0],[0.823,0.412,0.117],[0.58,0,0.827],[0.5,0,0]\\", "\n", "#     ,[0.82,0.41,0.12],[0.41,0.41,0.41],[0,0.54,0.54],[0.75,0.25,0.65],[0.2,0.6,0.8],[0.74,0,0.3],[0,1.0,0.4],[1,0.5,0.5],[0.5,0.5,1]\\", "\n", "#         ,[0.6,0,1],[0.56,0.56,0.3],[0,1,0],[1.0,0.0,0.4],[0.0,1.0,0.4],[0.0,0.5,1.0],[1,215/255,0]]", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "# color = assigned_colors[i]", "\n", "# print(i)", "\n", "            ", "color_", "=", "assigned_colors", "[", "i", "%", "len", "(", "assigned_colors", ")", "]", "\n", "color", "=", "[", "x", "/", "255", "for", "x", "in", "color_", "]", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_box", "(", "boxes", "[", "i", "]", ",", "edge_color", "=", "color", ")", "\n", "#luyao", "\n", "# alpha = 0.6", "\n", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "                ", "for", "segment", "in", "masks", "[", "i", "]", ".", "polygons", ":", "\n", "                    ", "self", ".", "draw_polygon", "(", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", ",", "color", ",", "alpha", "=", "alpha", ")", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "# first get a box", "\n", "                ", "if", "boxes", "is", "not", "None", ":", "\n", "#luyao#", "\n", "                    ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "boxes", "[", "i", "]", "\n", "text_pos", "=", "(", "x0", ",", "y0", ")", "# if drawing boxes, put text on the box corner.", "\n", "horiz_align", "=", "\"left\"", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "# skip small mask without polygon", "\n", "                    ", "if", "len", "(", "masks", "[", "i", "]", ".", "polygons", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "masks", "[", "i", "]", ".", "bbox", "(", ")", "\n", "\n", "# draw text in the center (defined by median) when box is not drawn", "\n", "# median is less sensitive to outliers.", "\n", "text_pos", "=", "np", ".", "median", "(", "masks", "[", "i", "]", ".", "mask", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "horiz_align", "=", "\"center\"", "\n", "", "else", ":", "\n", "                    ", "continue", "# drawing the box confidence for keypoints isn't very useful.", "\n", "# for small objects, draw text at the side to avoid occlusion", "\n", "", "instance_area", "=", "(", "y1", "-", "y0", ")", "*", "(", "x1", "-", "x0", ")", "\n", "# print(x0,' ',x1,' ',y0,' ',y1,' ',self.output.height,' ', self.output.width)", "\n", "#luyao#", "\n", "if", "y0", "<", "5", ":", "\n", "                    ", "text_pos", "=", "(", "(", "x0", "+", "x1", ")", "//", "2", ",", "(", "y0", "+", "y1", ")", "//", "2", ")", "\n", "#luyao#", "\n", "# if (", "\n", "#     instance_area < _SMALL_OBJECT_AREA_THRESH * self.output.scale", "\n", "#     or y1 - y0 < 40 * self.output.scale", "\n", "# ):", "\n", "#     if y1 >= self.output.height - 5:", "\n", "#         text_pos = (x1, y0)", "\n", "#     else:", "\n", "#         text_pos = (x0, y1)", "\n", "\n", "", "height_ratio", "=", "(", "y1", "-", "y0", ")", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "\n", "*", "0.5", "\n", "*", "self", ".", "_default_font_size", "\n", ")", "\n", "self", ".", "draw_text", "(", "\n", "labels", "[", "i", "]", ",", "\n", "text_pos", ",", "\n", "color", "=", "lighter_color", ",", "\n", "horizontal_alignment", "=", "horiz_align", ",", "\n", "font_size", "=", "font_size", ",", "\n", ")", "\n", "\n", "# draw keypoints", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "for", "keypoints_per_instance", "in", "keypoints", ":", "\n", "                ", "self", ".", "draw_and_connect_keypoints", "(", "keypoints_per_instance", ")", "\n", "\n", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_rotated_instances": [[752, 790], ["len", "numpy.argsort().tolist", "range", "visualizer.Visualizer.draw_rotated_box_with_label", "colormap.random_color", "numpy.argsort", "range"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_rotated_box_with_label", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.random_color"], ["", "def", "overlay_rotated_instances", "(", "self", ",", "boxes", "=", "None", ",", "labels", "=", "None", ",", "assigned_colors", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (ndarray): an Nx5 numpy array of\n                (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image.\n            labels (list[str]): the text to be displayed for each instance.\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "\n", "if", "assigned_colors", "is", "None", ":", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "boxes", "[", ":", ",", "2", "]", "*", "boxes", "[", ":", ",", "3", "]", "\n", "\n", "", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "\n", "labels", "=", "[", "labels", "[", "k", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "colors", "=", "[", "assigned_colors", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "self", ".", "draw_rotated_box_with_label", "(", "\n", "boxes", "[", "i", "]", ",", "edge_color", "=", "colors", "[", "i", "]", ",", "label", "=", "labels", "[", "i", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_and_connect_keypoints": [[791, 848], ["visualizer.Visualizer.metadata.get", "enumerate", "visualizer.Visualizer.metadata.get", "visible.get", "visualizer.Visualizer.draw_circle", "visualizer.Visualizer.draw_line", "visualizer.Visualizer.draw_line", "tuple", "visualizer.Visualizer.draw_line"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_circle", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_line"], ["", "def", "draw_and_connect_keypoints", "(", "self", ",", "keypoints", ")", ":", "\n", "        ", "\"\"\"\n        Draws keypoints of an instance and follows the rules for keypoint connections\n        to draw lines between appropriate keypoints. This follows color heuristics for\n        line color.\n\n        Args:\n            keypoints (Tensor): a tensor of shape (K, 3), where K is the number of keypoints\n                and the last dimension corresponds to (x, y, probability).\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "visible", "=", "{", "}", "\n", "keypoint_names", "=", "self", ".", "metadata", ".", "get", "(", "\"keypoint_names\"", ")", "\n", "for", "idx", ",", "keypoint", "in", "enumerate", "(", "keypoints", ")", ":", "\n", "# draw keypoint", "\n", "            ", "x", ",", "y", ",", "prob", "=", "keypoint", "\n", "if", "prob", ">", "_KEYPOINT_THRESHOLD", ":", "\n", "                ", "self", ".", "draw_circle", "(", "(", "x", ",", "y", ")", ",", "color", "=", "_RED", ")", "\n", "if", "keypoint_names", ":", "\n", "                    ", "keypoint_name", "=", "keypoint_names", "[", "idx", "]", "\n", "visible", "[", "keypoint_name", "]", "=", "(", "x", ",", "y", ")", "\n", "\n", "", "", "", "if", "self", ".", "metadata", ".", "get", "(", "\"keypoint_connection_rules\"", ")", ":", "\n", "            ", "for", "kp0", ",", "kp1", ",", "color", "in", "self", ".", "metadata", ".", "keypoint_connection_rules", ":", "\n", "                ", "if", "kp0", "in", "visible", "and", "kp1", "in", "visible", ":", "\n", "                    ", "x0", ",", "y0", "=", "visible", "[", "kp0", "]", "\n", "x1", ",", "y1", "=", "visible", "[", "kp1", "]", "\n", "color", "=", "tuple", "(", "x", "/", "255.0", "for", "x", "in", "color", ")", "\n", "self", ".", "draw_line", "(", "[", "x0", ",", "x1", "]", ",", "[", "y0", ",", "y1", "]", ",", "color", "=", "color", ")", "\n", "\n", "# draw lines from nose to mid-shoulder and mid-shoulder to mid-hip", "\n", "# Note that this strategy is specific to person keypoints.", "\n", "# For other keypoints, it should just do nothing", "\n", "", "", "", "try", ":", "\n", "            ", "ls_x", ",", "ls_y", "=", "visible", "[", "\"left_shoulder\"", "]", "\n", "rs_x", ",", "rs_y", "=", "visible", "[", "\"right_shoulder\"", "]", "\n", "mid_shoulder_x", ",", "mid_shoulder_y", "=", "(", "ls_x", "+", "rs_x", ")", "/", "2", ",", "(", "ls_y", "+", "rs_y", ")", "/", "2", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "# draw line from nose to mid-shoulder", "\n", "            ", "nose_x", ",", "nose_y", "=", "visible", ".", "get", "(", "\"nose\"", ",", "(", "None", ",", "None", ")", ")", "\n", "if", "nose_x", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_line", "(", "[", "nose_x", ",", "mid_shoulder_x", "]", ",", "[", "nose_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "\n", "", "try", ":", "\n", "# draw line from mid-shoulder to mid-hip", "\n", "                ", "lh_x", ",", "lh_y", "=", "visible", "[", "\"left_hip\"", "]", "\n", "rh_x", ",", "rh_y", "=", "visible", "[", "\"right_hip\"", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "mid_hip_x", ",", "mid_hip_y", "=", "(", "lh_x", "+", "rh_x", ")", "/", "2", ",", "(", "lh_y", "+", "rh_y", ")", "/", "2", "\n", "self", ".", "draw_line", "(", "[", "mid_hip_x", ",", "mid_shoulder_x", "]", ",", "[", "mid_hip_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_text": [[853, 911], ["visualizer.Visualizer.output.ax.text"], "methods", ["None"], ["def", "draw_text", "(", "\n", "self", ",", "\n", "text", ",", "\n", "position", ",", "\n", "*", ",", "\n", "font_size", "=", "None", ",", "\n", "color", "=", "\"g\"", ",", "\n", "horizontal_alignment", "=", "\"center\"", ",", "\n", "rotation", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text (str): class label\n            position (tuple): a tuple of the x and y coordinates to place text on image.\n            font_size (int, optional): font of the text. If not provided, a font size\n                proportional to the image width is calculated and used.\n            color: color of the text. Refer to `matplotlib.colors` for full list\n                of formats that are accepted.\n            horizontal_alignment (str): see `matplotlib.text.Text`\n            rotation: rotation angle in degrees CCW\n\n        Returns:\n            output (VisImage): image object with text drawn.\n        \"\"\"", "\n", "if", "not", "font_size", ":", "\n", "            ", "font_size", "=", "self", ".", "_default_font_size", "\n", "\n", "# print(font_size, self.output.scale)", "\n", "\n", "# since the text background is dark, we don't want the text to be dark", "\n", "# color = np.maximum(list(mplc.to_rgb(color)), 0.2)", "\n", "# color[np.argmax(color)] = max(0.8, np.max(color))", "\n", "#luyao#", "\n", "", "color", "=", "'w'", "\n", "# font_size = 7.0", "\n", "x", ",", "y", "=", "position", "\n", "self", ".", "output", ".", "ax", ".", "text", "(", "\n", "x", ",", "\n", "y", ",", "\n", "text", ",", "\n", "size", "=", "font_size", "*", "self", ".", "output", ".", "scale", ",", "\n", "# family=\"sans-serif\",", "\n", "family", "=", "\"monospace\"", ",", "\n", "# family=\"serif\",", "\n", "#luyao#", "\n", "bbox", "=", "{", "\"facecolor\"", ":", "\"black\"", ",", "\"alpha\"", ":", "0.0", ",", "\"pad\"", ":", "0.0", ",", "\"edgecolor\"", ":", "\"none\"", "}", ",", "\n", "# bbox={\"facecolor\": \"black\", \"alpha\": 0.8, \"pad\": 0.7, \"edgecolor\": \"none\"},", "\n", "# verticalalignment=\"top\",", "\n", "verticalalignment", "=", "\"bottom\"", ",", "\n", "horizontalalignment", "=", "horizontal_alignment", ",", "\n", "color", "=", "color", ",", "\n", "zorder", "=", "10", ",", "\n", "\n", "rotation", "=", "rotation", ",", "\n", "#luyao", "\n", "# fontweight='light'", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_box": [[912, 950], ["visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle"], "methods", ["None"], ["", "def", "draw_box", "(", "self", ",", "box_coord", ",", "alpha", "=", "0.5", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_coord (tuple): a tuple containing x0, y0, x1, y1 coordinates, where x0 and y0\n                are the coordinates of the image's top left corner. x1 and y1 are the\n                coordinates of the image's bottom right corner.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "box_coord", "\n", "width", "=", "x1", "-", "x0", "\n", "height", "=", "y1", "-", "y0", "\n", "\n", "# linewidth = max(self._default_font_size / 16, 1)", "\n", "# linewidth = max(self._default_font_size / 4, 1)", "\n", "#luyao#", "\n", "edge_color", "=", "[", "0.196", ",", "0.80", ",", "0.196", "]", "\n", "alpha", "=", "1.0", "\n", "linewidth", "=", "0.7", "\n", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Rectangle", "(", "\n", "(", "x0", ",", "y0", ")", ",", "\n", "width", ",", "\n", "height", ",", "\n", "fill", "=", "False", ",", "\n", "edgecolor", "=", "edge_color", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "alpha", "=", "alpha", ",", "\n", "linestyle", "=", "line_style", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_rotated_box_with_label": [[951, 1005], ["math.cos", "math.sin", "range", "visualizer.Visualizer.draw_line", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "numpy.sqrt", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip"], ["", "def", "draw_rotated_box_with_label", "(", "\n", "self", ",", "rotated_box", ",", "alpha", "=", "0.5", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ",", "label", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Draw a rotated box with label on its top-left corner.\n\n        Args:\n            rotated_box (tuple): a tuple containing (cnt_x, cnt_y, w, h, angle),\n                where cnt_x and cnt_y are the center coordinates of the box.\n                w and h are the width and height of the box. angle represents how\n                many degrees the box is rotated CCW with regard to the 0-degree box.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n            label (string): label for rotated box. It will not be rendered when set to None.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "cnt_x", ",", "cnt_y", ",", "w", ",", "h", ",", "angle", "=", "rotated_box", "\n", "area", "=", "w", "*", "h", "\n", "# use thinner lines when the box is small", "\n", "linewidth", "=", "self", ".", "_default_font_size", "/", "(", "\n", "6", "if", "area", "<", "_SMALL_OBJECT_AREA_THRESH", "*", "self", ".", "output", ".", "scale", "else", "3", "\n", ")", "\n", "\n", "theta", "=", "angle", "*", "math", ".", "pi", "/", "180.0", "\n", "c", "=", "math", ".", "cos", "(", "theta", ")", "\n", "s", "=", "math", ".", "sin", "(", "theta", ")", "\n", "rect", "=", "[", "(", "-", "w", "/", "2", ",", "h", "/", "2", ")", ",", "(", "-", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "h", "/", "2", ")", "]", "\n", "# x: left->right ; y: top->down", "\n", "rotated_rect", "=", "[", "(", "s", "*", "yy", "+", "c", "*", "xx", "+", "cnt_x", ",", "c", "*", "yy", "-", "s", "*", "xx", "+", "cnt_y", ")", "for", "(", "xx", ",", "yy", ")", "in", "rect", "]", "\n", "for", "k", "in", "range", "(", "4", ")", ":", "\n", "            ", "j", "=", "(", "k", "+", "1", ")", "%", "4", "\n", "self", ".", "draw_line", "(", "\n", "[", "rotated_rect", "[", "k", "]", "[", "0", "]", ",", "rotated_rect", "[", "j", "]", "[", "0", "]", "]", ",", "\n", "[", "rotated_rect", "[", "k", "]", "[", "1", "]", ",", "rotated_rect", "[", "j", "]", "[", "1", "]", "]", ",", "\n", "color", "=", "edge_color", ",", "\n", "linestyle", "=", "\"--\"", "if", "k", "==", "1", "else", "line_style", ",", "\n", "linewidth", "=", "linewidth", ",", "\n", ")", "\n", "\n", "", "if", "label", "is", "not", "None", ":", "\n", "            ", "text_pos", "=", "rotated_rect", "[", "1", "]", "# topleft corner", "\n", "\n", "height_ratio", "=", "h", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "label_color", "=", "self", ".", "_change_color_brightness", "(", "edge_color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "*", "0.5", "*", "self", ".", "_default_font_size", "\n", ")", "\n", "self", ".", "draw_text", "(", "label", ",", "text_pos", ",", "color", "=", "label_color", ",", "font_size", "=", "font_size", ",", "rotation", "=", "angle", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_circle": [[1006, 1023], ["visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Circle", "matplotlib.patches.Circle", "matplotlib.patches.Circle"], "methods", ["None"], ["", "def", "draw_circle", "(", "self", ",", "circle_coord", ",", "color", ",", "radius", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            circle_coord (list(int) or tuple(int)): contains the x and y coordinates\n                of the center of the circle.\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            radius (int): radius of the circle.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x", ",", "y", "=", "circle_coord", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Circle", "(", "circle_coord", ",", "radius", "=", "radius", ",", "fill", "=", "True", ",", "color", "=", "color", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_line": [[1024, 1054], ["max", "visualizer.Visualizer.output.ax.add_line", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "draw_line", "(", "self", ",", "x_data", ",", "y_data", ",", "color", ",", "linestyle", "=", "\"-\"", ",", "linewidth", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x_data (list[int]): a list containing x values of all the points being drawn.\n                Length of list should match the length of y_data.\n            y_data (list[int]): a list containing y values of all the points being drawn.\n                Length of list should match the length of x_data.\n            color: color of the line. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            linestyle: style of the line. Refer to `matplotlib.lines.Line2D`\n                for a full list of formats that are accepted.\n            linewidth (float or None): width of the line. When it's None,\n                a default value will be computed and used.\n\n        Returns:\n            output (VisImage): image object with line drawn.\n        \"\"\"", "\n", "if", "linewidth", "is", "None", ":", "\n", "            ", "linewidth", "=", "self", ".", "_default_font_size", "/", "3", "\n", "", "linewidth", "=", "max", "(", "linewidth", ",", "1", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_line", "(", "\n", "mpl", ".", "lines", ".", "Line2D", "(", "\n", "x_data", ",", "\n", "y_data", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "color", "=", "color", ",", "\n", "linestyle", "=", "linestyle", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_binary_mask": [[1055, 1115], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "binary_mask.astype.astype.astype", "visualizer.GenericMask", "colormap.random_color", "numpy.zeros", "visualizer.Visualizer.output.ax.imshow", "visualizer.Visualizer._change_color_brightness", "cv2.connectedComponentsWithStats", "range", "pycocotools.area", "segment.reshape.reshape.reshape", "visualizer.Visualizer.draw_polygon", "numpy.argmax", "pycocotools.frPyObjects", "visualizer.Visualizer.draw_text", "numpy.median"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.random_color", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median"], ["", "def", "draw_binary_mask", "(", "\n", "self", ",", "binary_mask", ",", "color", "=", "None", ",", "*", ",", "edge_color", "=", "None", ",", "text", "=", "None", ",", "alpha", "=", "0.5", ",", "area_threshold", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            binary_mask (ndarray): numpy array of shape (H, W), where H is the image height and\n                W is the image width. Each value in the array is either a 0 or 1 value of uint8\n                type.\n            color: color of the mask. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted. If None, will pick a random color.\n            edge_color: color of the polygon edges. Refer to `matplotlib.colors` for a\n                full list of formats that are accepted.\n            text (str): if None, will be drawn in the object's center of mass.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            area_threshold (float): a connected component small than this will not be shown.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"", "\n", "if", "color", "is", "None", ":", "\n", "            ", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "\n", "has_valid_segment", "=", "False", "\n", "binary_mask", "=", "binary_mask", ".", "astype", "(", "\"uint8\"", ")", "# opencv needs uint8", "\n", "mask", "=", "GenericMask", "(", "binary_mask", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "\n", "shape2d", "=", "(", "binary_mask", ".", "shape", "[", "0", "]", ",", "binary_mask", ".", "shape", "[", "1", "]", ")", "\n", "\n", "if", "not", "mask", ".", "has_holes", ":", "\n", "# draw polygons for regular masks", "\n", "            ", "for", "segment", "in", "mask", ".", "polygons", ":", "\n", "                ", "area", "=", "mask_util", ".", "area", "(", "mask_util", ".", "frPyObjects", "(", "[", "segment", "]", ",", "shape2d", "[", "0", "]", ",", "shape2d", "[", "1", "]", ")", ")", "\n", "if", "area", "<", "(", "area_threshold", "or", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "has_valid_segment", "=", "True", "\n", "segment", "=", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "self", ".", "draw_polygon", "(", "segment", ",", "color", "=", "color", ",", "edge_color", "=", "edge_color", ",", "alpha", "=", "alpha", ")", "\n", "", "", "else", ":", "\n", "# TODO: Use Path/PathPatch to draw vector graphics:", "\n", "# https://stackoverflow.com/questions/8919719/how-to-plot-a-complex-polygon", "\n", "            ", "rgba", "=", "np", ".", "zeros", "(", "shape2d", "+", "(", "4", ",", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "rgba", "[", ":", ",", ":", ",", ":", "3", "]", "=", "color", "\n", "rgba", "[", ":", ",", ":", ",", "3", "]", "=", "(", "mask", ".", "mask", "==", "1", ")", ".", "astype", "(", "\"float32\"", ")", "*", "alpha", "\n", "has_valid_segment", "=", "True", "\n", "self", ".", "output", ".", "ax", ".", "imshow", "(", "rgba", ",", "extent", "=", "(", "0", ",", "self", ".", "output", ".", "width", ",", "self", ".", "output", ".", "height", ",", "0", ")", ")", "\n", "\n", "", "if", "text", "is", "not", "None", "and", "has_valid_segment", ":", "\n", "# TODO sometimes drawn on wrong objects. the heuristics here can improve.", "\n", "            ", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "_num_cc", ",", "cc_labels", ",", "stats", ",", "centroids", "=", "cv2", ".", "connectedComponentsWithStats", "(", "binary_mask", ",", "8", ")", "\n", "largest_component_id", "=", "np", ".", "argmax", "(", "stats", "[", "1", ":", ",", "-", "1", "]", ")", "+", "1", "\n", "\n", "# draw text on the largest component, as well as other very large components.", "\n", "for", "cid", "in", "range", "(", "1", ",", "_num_cc", ")", ":", "\n", "                ", "if", "cid", "==", "largest_component_id", "or", "stats", "[", "cid", ",", "-", "1", "]", ">", "_LARGE_MASK_AREA_THRESH", ":", "\n", "# median is more stable than centroid", "\n", "# center = centroids[largest_component_id]", "\n", "                    ", "center", "=", "np", ".", "median", "(", "(", "cc_labels", "==", "cid", ")", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "self", ".", "draw_text", "(", "text", ",", "center", ",", "color", "=", "lighter_color", ")", "\n", "", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_polygon": [[1116, 1150], ["matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "visualizer.Visualizer.output.ax.add_patch", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "visualizer.Visualizer._change_color_brightness", "max", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "draw_polygon", "(", "self", ",", "segment", ",", "color", ",", "edge_color", "=", "None", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            segment: numpy array of shape Nx2, containing all the points in the polygon.\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            edge_color: color of the polygon edges. Refer to `matplotlib.colors` for a\n                full list of formats that are accepted. If not provided, a darker shade\n                of the polygon color will be used instead.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n\n        Returns:\n            output (VisImage): image object with polygon drawn.\n        \"\"\"", "\n", "#luyao#", "\n", "# edge_color = []", "\n", "if", "edge_color", "is", "None", ":", "\n", "# make edge color darker than the polygon color", "\n", "            ", "if", "alpha", ">", "0.8", ":", "\n", "                ", "edge_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "-", "0.7", ")", "\n", "", "else", ":", "\n", "                ", "edge_color", "=", "color", "\n", "", "", "edge_color", "=", "mplc", ".", "to_rgb", "(", "edge_color", ")", "+", "(", "1", ",", ")", "\n", "\n", "polygon", "=", "mpl", ".", "patches", ".", "Polygon", "(", "\n", "segment", ",", "\n", "fill", "=", "True", ",", "\n", "facecolor", "=", "mplc", ".", "to_rgb", "(", "color", ")", "+", "(", "alpha", ",", ")", ",", "\n", "#luyao# qudiaomaskyanse", "\n", "# edgecolor=edge_color,", "\n", "linewidth", "=", "max", "(", "self", ".", "_default_font_size", "//", "15", "*", "self", ".", "output", ".", "scale", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "polygon", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._jitter": [[1155, 1173], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "numpy.random.rand", "numpy.clip", "tuple", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip"], ["def", "_jitter", "(", "self", ",", "color", ")", ":", "\n", "        ", "\"\"\"\n        Randomly modifies given color to produce a slightly different color than the color given.\n\n        Args:\n            color (tuple[double]): a tuple of 3 elements, containing the RGB values of the color\n                picked. The values in the list are in the [0.0, 1.0] range.\n\n        Returns:\n            jittered_color (tuple[double]): a tuple of 3 elements, containing the RGB values of the\n                color after being jittered. The values in the list are in the [0.0, 1.0] range.\n        \"\"\"", "\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "vec", "=", "np", ".", "random", ".", "rand", "(", "3", ")", "\n", "# better to do it in another color space", "\n", "vec", "=", "vec", "/", "np", ".", "linalg", ".", "norm", "(", "vec", ")", "*", "0.5", "\n", "res", "=", "np", ".", "clip", "(", "vec", "+", "color", ",", "0", ",", "1", ")", "\n", "return", "tuple", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._create_grayscale_image": [[1174, 1184], ["visualizer.Visualizer.img.astype().mean", "numpy.stack", "visualizer.Visualizer.img.astype"], "methods", ["None"], ["", "def", "_create_grayscale_image", "(", "self", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create a grayscale version of the original image.\n        The colors in masked area, if given, will be kept.\n        \"\"\"", "\n", "img_bw", "=", "self", ".", "img", ".", "astype", "(", "\"f4\"", ")", ".", "mean", "(", "axis", "=", "2", ")", "\n", "img_bw", "=", "np", ".", "stack", "(", "[", "img_bw", "]", "*", "3", ",", "axis", "=", "2", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "img_bw", "[", "mask", "]", "=", "self", ".", "img", "[", "mask", "]", "\n", "", "return", "img_bw", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._change_color_brightness": [[1185, 1209], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "colorsys.rgb_to_hls", "colorsys.hls_to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["None"], ["", "def", "_change_color_brightness", "(", "self", ",", "color", ",", "brightness_factor", ")", ":", "\n", "        ", "\"\"\"\n        Depending on the brightness_factor, gives a lighter or darker color i.e. a color with\n        less or more saturation than the original color.\n\n        Args:\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            brightness_factor (float): a value in [-1.0, 1.0] range. A lightness factor of\n                0 will correspond to no change, a factor in [-1.0, 0) range will result in\n                a darker color and a factor in (0, 1.0] range will result in a lighter color.\n\n        Returns:\n            modified_color (tuple[double]): a tuple containing the RGB values of the\n                modified color. Each value in the tuple is in the [0.0, 1.0] range.\n        \"\"\"", "\n", "assert", "brightness_factor", ">=", "-", "1.0", "and", "brightness_factor", "<=", "1.0", "\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "polygon_color", "=", "colorsys", ".", "rgb_to_hls", "(", "*", "mplc", ".", "to_rgb", "(", "color", ")", ")", "\n", "modified_lightness", "=", "polygon_color", "[", "1", "]", "+", "(", "brightness_factor", "*", "polygon_color", "[", "1", "]", ")", "\n", "modified_lightness", "=", "0.0", "if", "modified_lightness", "<", "0.0", "else", "modified_lightness", "\n", "modified_lightness", "=", "1.0", "if", "modified_lightness", ">", "1.0", "else", "modified_lightness", "\n", "modified_color", "=", "colorsys", ".", "hls_to_rgb", "(", "polygon_color", "[", "0", "]", ",", "modified_lightness", ",", "polygon_color", "[", "2", "]", ")", "\n", "return", "modified_color", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_boxes": [[1210, 1218], ["isinstance", "isinstance", "boxes.tensor.numpy", "numpy.asarray"], "methods", ["None"], ["", "def", "_convert_boxes", "(", "self", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Convert different format of boxes to an NxB array, where B = 4 or 5 is the box dimension.\n        \"\"\"", "\n", "if", "isinstance", "(", "boxes", ",", "Boxes", ")", "or", "isinstance", "(", "boxes", ",", "RotatedBoxes", ")", ":", "\n", "            ", "return", "boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "asarray", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_masks": [[1219, 1241], ["isinstance", "isinstance", "isinstance", "m.numpy.numpy.tensor.numpy", "m.numpy.numpy.numpy", "isinstance", "ret.append", "ret.append", "visualizer.GenericMask"], "methods", ["None"], ["", "", "def", "_convert_masks", "(", "self", ",", "masks_or_polygons", ")", ":", "\n", "        ", "\"\"\"\n        Convert different format of masks or polygons to a tuple of masks and polygons.\n\n        Returns:\n            list[GenericMask]:\n        \"\"\"", "\n", "\n", "m", "=", "masks_or_polygons", "\n", "if", "isinstance", "(", "m", ",", "PolygonMasks", ")", ":", "\n", "            ", "m", "=", "m", ".", "polygons", "\n", "", "if", "isinstance", "(", "m", ",", "BitMasks", ")", ":", "\n", "            ", "m", "=", "m", ".", "tensor", ".", "numpy", "(", ")", "\n", "", "if", "isinstance", "(", "m", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "m", "=", "m", ".", "numpy", "(", ")", "\n", "", "ret", "=", "[", "]", "\n", "for", "x", "in", "m", ":", "\n", "            ", "if", "isinstance", "(", "x", ",", "GenericMask", ")", ":", "\n", "                ", "ret", ".", "append", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._convert_keypoints": [[1242, 1247], ["isinstance", "numpy.asarray"], "methods", ["None"], ["", "def", "_convert_keypoints", "(", "self", ",", "keypoints", ")", ":", "\n", "        ", "if", "isinstance", "(", "keypoints", ",", "Keypoints", ")", ":", "\n", "            ", "keypoints", "=", "keypoints", ".", "tensor", "\n", "", "keypoints", "=", "np", ".", "asarray", "(", "keypoints", ")", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.get_output": [[1248, 1255], ["None"], "methods", ["None"], ["", "def", "get_output", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            output (VisImage): the image output containing the visualizations added\n            to the image.\n        \"\"\"", "\n", "return", "self", ".", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._create_text_labels": [[225, 246], ["len", "zip"], "function", ["None"], ["", "", "", "", "def", "_create_text_labels", "(", "classes", ",", "scores", ",", "class_names", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        classes (list[int] or None):\n        scores (list[float] or None):\n        class_names (list[str] or None):\n\n    Returns:\n        list[str] or None\n    \"\"\"", "\n", "labels", "=", "None", "\n", "if", "classes", "is", "not", "None", "and", "class_names", "is", "not", "None", "and", "len", "(", "class_names", ")", ">", "0", ":", "\n", "        ", "labels", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "classes", "]", "\n", "", "if", "scores", "is", "not", "None", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "\"{:.0f}%\"", ".", "format", "(", "s", "*", "100", ")", "for", "s", "in", "scores", "]", "\n", "", "else", ":", "\n", "# labels = [\"{} {:.0f}%\".format(l, s * 100) for l, s in zip(labels, scores)]", "\n", "#luyao", "\n", "            ", "labels", "=", "[", "\"{}.{:.0f}\"", ".", "format", "(", "l", ",", "s", "*", "100", ")", "for", "l", ",", "s", "in", "zip", "(", "labels", ",", "scores", ")", "]", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer._DetectedInstance.__init__": [[31, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "label", ",", "bbox", ",", "mask_rle", ",", "color", ",", "ttl", ")", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "mask_rle", "=", "mask_rle", "\n", "self", ".", "color", "=", "color", "\n", "self", ".", "ttl", "=", "ttl", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.__init__": [[40, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "metadata", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            metadata (MetadataCatalog): image metadata.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "_old_instances", "=", "[", "]", "\n", "assert", "instance_mode", "in", "[", "\n", "ColorMode", ".", "IMAGE", ",", "\n", "ColorMode", ".", "IMAGE_BW", ",", "\n", "]", ",", "\"Other mode not supported yet.\"", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_instance_predictions": [[53, 112], ["detectron2.utils.visualizer.Visualizer", "len", "predictions.has", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.pred_boxes.tensor.numpy", "predictions.has", "predictions.has", "predictions.pred_classes.numpy", "predictions.has", "video_visualizer._DetectedInstance", "video_visualizer.VideoVisualizer.metadata.get", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "range", "masks.any"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._create_grayscale_image"], ["", "def", "draw_instance_predictions", "(", "self", ",", "frame", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            frame (ndarray): an RGB image of shape (H, W, C), in the range [0, 255].\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "num_instances", "=", "len", "(", "predictions", ")", "\n", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "\n", "", "boxes", "=", "predictions", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "predictions", ".", "pred_masks", "\n", "# mask IOU is not yet enabled", "\n", "# masks_rles = mask_util.encode(np.asarray(masks.permute(1, 2, 0), order=\"F\"))", "\n", "# assert len(masks_rles) == num_instances", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "detected", "=", "[", "\n", "_DetectedInstance", "(", "classes", "[", "i", "]", ",", "boxes", "[", "i", "]", ",", "mask_rle", "=", "None", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "# any() returns uint8 tensor", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "(", "masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "if", "masks", "is", "not", "None", "else", "None", "\n", ")", "\n", "alpha", "=", "0.3", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "0.5", "\n", "\n", "", "frame_visualizer", ".", "overlay_instances", "(", "\n", "# boxes=None if masks is not None else boxes,  # boxes are a bit distracting", "\n", "boxes", "=", "boxes", ",", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_sem_seg": [[113, 124], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.draw_sem_seg"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_sem_seg"], ["", "def", "draw_sem_seg", "(", "self", ",", "frame", ",", "sem_seg", ",", "area_threshold", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sem_seg (ndarray or Tensor): semantic segmentation of shape (H, W),\n                each value is the integer label.\n            area_threshold (Optional[int]): only draw segmentations larger than the threshold\n        \"\"\"", "\n", "# don't need to do anything special", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "frame_visualizer", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "None", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions": [[125, 180], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._PanopticPrediction", "detectron2.utils.visualizer._PanopticPrediction.semantic_masks", "list", "list", "len", "pycocotools.encode", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "detectron2.utils.visualizer._PanopticPrediction.instance_masks", "len", "zip", "numpy.asarray", "len", "video_visualizer._DetectedInstance", "detectron2.utils.visualizer._PanopticPrediction.non_empty_mask", "numpy.asarray().transpose", "range", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer._PanopticPrediction.non_empty_mask"], ["", "def", "draw_panoptic_seg_predictions", "(", "\n", "self", ",", "frame", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.5", "\n", ")", ":", "\n", "        ", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "pred", ".", "non_empty_mask", "(", ")", "\n", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "frame_visualizer", ".", "draw_binary_mask", "(", "\n", "mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "# draw mask for all instances second", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "num_instances", "=", "len", "(", "masks", ")", "\n", "masks_rles", "=", "mask_util", ".", "encode", "(", "\n", "np", ".", "asarray", "(", "np", ".", "asarray", "(", "masks", ")", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "order", "=", "\"F\"", ")", "\n", ")", "\n", "assert", "len", "(", "masks_rles", ")", "==", "num_instances", "\n", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "detected", "=", "[", "\n", "_DetectedInstance", "(", "category_ids", "[", "i", "]", ",", "bbox", "=", "None", ",", "mask_rle", "=", "masks_rles", "[", "i", "]", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "labels", "=", "[", "self", ".", "metadata", ".", "thing_classes", "[", "k", "]", "for", "k", "in", "category_ids", "]", "\n", "\n", "frame_visualizer", ".", "overlay_instances", "(", "\n", "boxes", "=", "None", ",", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.video_visualizer.VideoVisualizer._assign_colors": [[181, 237], ["numpy.zeros", "enumerate", "numpy.asarray().argmax", "numpy.asarray().max", "enumerate", "pycocotools.iou", "pycocotools.iou", "len", "numpy.zeros", "enumerate", "len", "numpy.asarray", "numpy.asarray", "extra_instances.append", "colormap.random_color", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.colormap.random_color"], ["", "def", "_assign_colors", "(", "self", ",", "instances", ")", ":", "\n", "        ", "\"\"\"\n        Naive tracking heuristics to assign same color to the same instance,\n        will update the internal state of tracked instances.\n\n        Returns:\n            list[tuple[float]]: list of colors.\n        \"\"\"", "\n", "\n", "# Compute iou with either boxes or masks:", "\n", "is_crowd", "=", "np", ".", "zeros", "(", "(", "len", "(", "instances", ")", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "instances", "[", "0", "]", ".", "bbox", "is", "None", ":", "\n", "            ", "assert", "instances", "[", "0", "]", ".", "mask_rle", "is", "not", "None", "\n", "# use mask iou only when box iou is None", "\n", "# because box seems good enough", "\n", "rles_old", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "rles_new", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "rles_old", ",", "rles_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "boxes_old", "=", "[", "x", ".", "bbox", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "boxes_new", "=", "[", "x", ".", "bbox", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "boxes_old", ",", "boxes_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.6", "\n", "", "if", "len", "(", "ious", ")", "==", "0", ":", "\n", "            ", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "_old_instances", ")", ",", "len", "(", "instances", ")", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "# Only allow matching instances of the same label:", "\n", "", "for", "old_idx", ",", "old", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "for", "new_idx", ",", "new", "in", "enumerate", "(", "instances", ")", ":", "\n", "                ", "if", "old", ".", "label", "!=", "new", ".", "label", ":", "\n", "                    ", "ious", "[", "old_idx", ",", "new_idx", "]", "=", "0", "\n", "\n", "", "", "", "matched_new_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "max_iou_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "# Try to find match for each old instance:", "\n", "extra_instances", "=", "[", "]", "\n", "for", "idx", ",", "inst", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "if", "max_iou_per_old", "[", "idx", "]", ">", "threshold", ":", "\n", "                ", "newidx", "=", "matched_new_per_old", "[", "idx", "]", "\n", "if", "instances", "[", "newidx", "]", ".", "color", "is", "None", ":", "\n", "                    ", "instances", "[", "newidx", "]", ".", "color", "=", "inst", ".", "color", "\n", "continue", "\n", "# If an old instance does not match any new instances,", "\n", "# keep it for the next frame in case it is just missed by the detector", "\n", "", "", "inst", ".", "ttl", "-=", "1", "\n", "if", "inst", ".", "ttl", ">", "0", ":", "\n", "                ", "extra_instances", ".", "append", "(", "inst", ")", "\n", "\n", "# Assign random color to newly-detected instances:", "\n", "", "", "for", "inst", "in", "instances", ":", "\n", "            ", "if", "inst", ".", "color", "is", "None", ":", "\n", "                ", "inst", ".", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "", "self", ".", "_old_instances", "=", "instances", "[", ":", "]", "+", "extra_instances", "\n", "return", "[", "d", ".", "color", "for", "d", "in", "instances", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.analysis.FlopCountAnalysis.__init__": [[57, 66], ["detectron2.export.TracingAdapter", "super().__init__", "analysis.FlopCountAnalysis.set_op_handle"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model (nn.Module):\n            inputs (Any): inputs of the given model. Does not have to be tuple of tensors.\n        \"\"\"", "\n", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ",", "allow_non_tensor", "=", "True", ")", "\n", "super", "(", ")", ".", "__init__", "(", "wrapper", ",", "wrapper", ".", "flattened_inputs", ")", "\n", "self", ".", "set_op_handle", "(", "**", "{", "k", ":", "None", "for", "k", "in", "_IGNORED_OPS", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.analysis.flop_count_operators": [[68, 98], ["model.eval", "FlopCountAnalysis().by_operator", "model.train", "analysis.FlopCountAnalysis", "FlopCountAnalysis().by_operator.items"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train"], ["", "", "def", "flop_count_operators", "(", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level flops counting using jit.\n    This is a wrapper of :func:`fvcore.nn.flop_count` and adds supports for standard\n    detection models in detectron2.\n    Please use :class:`FlopCountAnalysis` for more advanced functionalities.\n\n    Note:\n        The function runs the input through the model to compute flops.\n        The flops of a detection model is often input-dependent, for example,\n        the flops of box & mask head depends on the number of proposals &\n        the number of detected objects.\n        Therefore, the flops counting using a single input may not accurately\n        reflect the computation cost of a model. It's recommended to average\n        across a number of inputs.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n        supported_ops (dict[str, Handle]): see documentation of :func:`fvcore.nn.flop_count`\n\n    Returns:\n        Counter: Gflop count per operator\n    \"\"\"", "\n", "old_train", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "ret", "=", "FlopCountAnalysis", "(", "model", ",", "inputs", ")", ".", "by_operator", "(", ")", "\n", "model", ".", "train", "(", "old_train", ")", "\n", "return", "{", "k", ":", "v", "/", "1e9", "for", "k", ",", "v", "in", "ret", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.analysis.activation_count_operators": [[100, 123], ["analysis._wrapper_count_operators"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.analysis._wrapper_count_operators"], ["", "def", "activation_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level activations counting using jit.\n    This is a wrapper of fvcore.nn.activation_count, that supports standard detection models\n    in detectron2.\n\n    Note:\n        The function runs the input through the model to compute activations.\n        The activations of a detection model is often input-dependent, for example,\n        the activations of box & mask head depends on the number of proposals &\n        the number of detected objects.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n\n    Returns:\n        Counter: activation count per operator\n    \"\"\"", "\n", "return", "_wrapper_count_operators", "(", "model", "=", "model", ",", "inputs", "=", "inputs", ",", "mode", "=", "ACTIVATIONS_MODE", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.analysis._wrapper_count_operators": [[125, 153], ["supported_ops.update", "isinstance", "detectron2.export.TracingAdapter", "detectron2.export.TracingAdapter.eval", "isinstance", "model.train", "kwargs.pop", "len", "fvcore.nn.flop_count", "fvcore.nn.activation_count", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train"], ["", "def", "_wrapper_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "mode", ":", "str", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "# ignore some ops", "\n", "    ", "supported_ops", "=", "{", "k", ":", "lambda", "*", "args", ",", "**", "kwargs", ":", "{", "}", "for", "k", "in", "_IGNORED_OPS", "}", "\n", "supported_ops", ".", "update", "(", "kwargs", ".", "pop", "(", "\"supported_ops\"", ",", "{", "}", ")", ")", "\n", "kwargs", "[", "\"supported_ops\"", "]", "=", "supported_ops", "\n", "\n", "assert", "len", "(", "inputs", ")", "==", "1", ",", "\"Please use batch size=1\"", "\n", "tensor_input", "=", "inputs", "[", "0", "]", "[", "\"image\"", "]", "\n", "inputs", "=", "[", "{", "\"image\"", ":", "tensor_input", "}", "]", "# remove other keys, in case there are any", "\n", "\n", "old_train", "=", "model", ".", "training", "\n", "if", "isinstance", "(", "model", ",", "(", "nn", ".", "parallel", ".", "distributed", ".", "DistributedDataParallel", ",", "nn", ".", "DataParallel", ")", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ")", "\n", "wrapper", ".", "eval", "(", ")", "\n", "if", "mode", "==", "FLOPS_MODE", ":", "\n", "        ", "ret", "=", "flop_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "elif", "mode", "==", "ACTIVATIONS_MODE", ":", "\n", "        ", "ret", "=", "activation_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Count for mode {} is not supported yet.\"", ".", "format", "(", "mode", ")", ")", "\n", "# compatible with change in fvcore", "\n", "", "if", "isinstance", "(", "ret", ",", "tuple", ")", ":", "\n", "        ", "ret", "=", "ret", "[", "0", "]", "\n", "", "model", ".", "train", "(", "old_train", ")", "\n", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._ColorfulFormatter.__init__": [[19, 25], ["kwargs.pop", "len", "logging.Formatter.__init__", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_root_name", "=", "kwargs", ".", "pop", "(", "\"root_name\"", ")", "+", "\".\"", "\n", "self", ".", "_abbrev_name", "=", "kwargs", ".", "pop", "(", "\"abbrev_name\"", ",", "\"\"", ")", "\n", "if", "len", "(", "self", ".", "_abbrev_name", ")", ":", "\n", "            ", "self", ".", "_abbrev_name", "=", "self", ".", "_abbrev_name", "+", "\".\"", "\n", "", "super", "(", "_ColorfulFormatter", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._ColorfulFormatter.formatMessage": [[26, 36], ["record.name.replace", "super().formatMessage", "termcolor.colored", "termcolor.colored"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._ColorfulFormatter.formatMessage"], ["", "def", "formatMessage", "(", "self", ",", "record", ")", ":", "\n", "        ", "record", ".", "name", "=", "record", ".", "name", ".", "replace", "(", "self", ".", "_root_name", ",", "self", ".", "_abbrev_name", ")", "\n", "log", "=", "super", "(", "_ColorfulFormatter", ",", "self", ")", ".", "formatMessage", "(", "record", ")", "\n", "if", "record", ".", "levelno", "==", "logging", ".", "WARNING", ":", "\n", "            ", "prefix", "=", "colored", "(", "\"WARNING\"", ",", "\"red\"", ",", "attrs", "=", "[", "\"blink\"", "]", ")", "\n", "", "elif", "record", ".", "levelno", "==", "logging", ".", "ERROR", "or", "record", ".", "levelno", "==", "logging", ".", "CRITICAL", ":", "\n", "            ", "prefix", "=", "colored", "(", "\"ERROR\"", ",", "\"red\"", ",", "attrs", "=", "[", "\"blink\"", ",", "\"underline\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "log", "\n", "", "return", "prefix", "+", "\" \"", "+", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.setup_logger": [[38, 100], ["functools.lru_cache", "logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "detectron2.utils.file_io.PathManager.mkdirs", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logger._ColorfulFormatter", "output.endswith", "output.endswith", "os.path.join", "os.path.dirname", "logger._cached_log_stream", "termcolor.colored", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._cached_log_stream"], ["", "", "@", "functools", ".", "lru_cache", "(", ")", "# so that calling setup_logger multiple times won't add many handlers", "\n", "def", "setup_logger", "(", "\n", "output", "=", "None", ",", "distributed_rank", "=", "0", ",", "*", ",", "color", "=", "True", ",", "name", "=", "\"detectron2\"", ",", "abbrev_name", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Initialize the detectron2 logger and set its verbosity level to \"DEBUG\".\n\n    Args:\n        output (str): a file name or a directory to save log. If None, will not save log file.\n            If ends with \".txt\" or \".log\", assumed to be a file name.\n            Otherwise, logs will be saved to `output/log.txt`.\n        name (str): the root module name of this logger\n        abbrev_name (str): an abbreviation of the module, to avoid long names in logs.\n            Set to \"\" to not log the root module in logs.\n            By default, will abbreviate \"detectron2\" to \"d2\" and leave other\n            modules unchanged.\n\n    Returns:\n        logging.Logger: a logger\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "propagate", "=", "False", "\n", "\n", "if", "abbrev_name", "is", "None", ":", "\n", "        ", "abbrev_name", "=", "\"d2\"", "if", "name", "==", "\"detectron2\"", "else", "name", "\n", "\n", "", "plain_formatter", "=", "logging", ".", "Formatter", "(", "\n", "\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\"", ",", "datefmt", "=", "\"%m/%d %H:%M:%S\"", "\n", ")", "\n", "# stdout logging: master only", "\n", "if", "distributed_rank", "==", "0", ":", "\n", "        ", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "if", "color", ":", "\n", "            ", "formatter", "=", "_ColorfulFormatter", "(", "\n", "colored", "(", "\"[%(asctime)s %(name)s]: \"", ",", "\"green\"", ")", "+", "\"%(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d %H:%M:%S\"", ",", "\n", "root_name", "=", "name", ",", "\n", "abbrev_name", "=", "str", "(", "abbrev_name", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "formatter", "=", "plain_formatter", "\n", "", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "# file logging: all workers", "\n", "", "if", "output", "is", "not", "None", ":", "\n", "        ", "if", "output", ".", "endswith", "(", "\".txt\"", ")", "or", "output", ".", "endswith", "(", "\".log\"", ")", ":", "\n", "            ", "filename", "=", "output", "\n", "", "else", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "output", ",", "\"log.txt\"", ")", "\n", "", "if", "distributed_rank", ">", "0", ":", "\n", "            ", "filename", "=", "filename", "+", "\".rank{}\"", ".", "format", "(", "distributed_rank", ")", "\n", "", "PathManager", ".", "mkdirs", "(", "os", ".", "path", ".", "dirname", "(", "filename", ")", ")", "\n", "\n", "fh", "=", "logging", ".", "StreamHandler", "(", "_cached_log_stream", "(", "filename", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "plain_formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._cached_log_stream": [[104, 110], ["functools.lru_cache", "detectron2.utils.file_io.PathManager.open", "atexit.register"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register"], ["", "@", "functools", ".", "lru_cache", "(", "maxsize", "=", "None", ")", "\n", "def", "_cached_log_stream", "(", "filename", ")", ":", "\n", "# use 1K buffer if writing to cloud storage", "\n", "    ", "io", "=", "PathManager", ".", "open", "(", "filename", ",", "\"a\"", ",", "buffering", "=", "1024", "if", "\"://\"", "in", "filename", "else", "-", "1", ")", "\n", "atexit", ".", "register", "(", "io", ".", "close", ")", "\n", "return", "io", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._find_caller": [[119, 134], ["sys._getframe", "os.path.join"], "function", ["None"], ["def", "_find_caller", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        str: module name of the caller\n        tuple: a hashable key to be used to identify different callers\n    \"\"\"", "\n", "frame", "=", "sys", ".", "_getframe", "(", "2", ")", "\n", "while", "frame", ":", "\n", "        ", "code", "=", "frame", ".", "f_code", "\n", "if", "os", ".", "path", ".", "join", "(", "\"utils\"", ",", "\"logger.\"", ")", "not", "in", "code", ".", "co_filename", ":", "\n", "            ", "mod_name", "=", "frame", ".", "f_globals", "[", "\"__name__\"", "]", "\n", "if", "mod_name", "==", "\"__main__\"", ":", "\n", "                ", "mod_name", "=", "\"detectron2\"", "\n", "", "return", "mod_name", ",", "(", "code", ".", "co_filename", ",", "frame", ".", "f_lineno", ",", "code", ".", "co_name", ")", "\n", "", "frame", "=", "frame", ".", "f_back", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_first_n": [[140, 173], ["isinstance", "logger._find_caller", "len", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._find_caller"], ["def", "log_first_n", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ",", "key", "=", "\"caller\"", ")", ":", "\n", "    ", "\"\"\"\n    Log only for the first n times.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n        key (str or tuple[str]): the string(s) can be one of \"caller\" or\n            \"message\", which defines how to identify duplicated logs.\n            For example, if called with `n=1, key=\"caller\"`, this function\n            will only log the first call from the same caller, regardless of\n            the message content.\n            If called with `n=1, key=\"message\"`, this function will log the\n            same content only once, even if they are called from different places.\n            If called with `n=1, key=(\"caller\", \"message\")`, this function\n            will not log only if the same caller has logged the same message before.\n    \"\"\"", "\n", "if", "isinstance", "(", "key", ",", "str", ")", ":", "\n", "        ", "key", "=", "(", "key", ",", ")", "\n", "", "assert", "len", "(", "key", ")", ">", "0", "\n", "\n", "caller_module", ",", "caller_key", "=", "_find_caller", "(", ")", "\n", "hash_key", "=", "(", ")", "\n", "if", "\"caller\"", "in", "key", ":", "\n", "        ", "hash_key", "=", "hash_key", "+", "caller_key", "\n", "", "if", "\"message\"", "in", "key", ":", "\n", "        ", "hash_key", "=", "hash_key", "+", "(", "msg", ",", ")", "\n", "\n", "", "_LOG_COUNTER", "[", "hash_key", "]", "+=", "1", "\n", "if", "_LOG_COUNTER", "[", "hash_key", "]", "<=", "n", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_every_n": [[175, 189], ["logger._find_caller", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._find_caller"], ["", "", "def", "log_every_n", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Log once per n times.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n    \"\"\"", "\n", "caller_module", ",", "key", "=", "_find_caller", "(", ")", "\n", "_LOG_COUNTER", "[", "key", "]", "+=", "1", "\n", "if", "n", "==", "1", "or", "_LOG_COUNTER", "[", "key", "]", "%", "n", "==", "1", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_every_n_seconds": [[191, 207], ["logger._find_caller", "_LOG_TIMER.get", "time.time", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._find_caller", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "log_every_n_seconds", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Log no more than once per n seconds.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n    \"\"\"", "\n", "caller_module", ",", "key", "=", "_find_caller", "(", ")", "\n", "last_logged", "=", "_LOG_TIMER", ".", "get", "(", "key", ",", "None", ")", "\n", "current_time", "=", "time", ".", "time", "(", ")", "\n", "if", "last_logged", "is", "None", "or", "current_time", "-", "last_logged", ">=", "n", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "_LOG_TIMER", "[", "key", "]", "=", "current_time", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.create_small_table": [[209, 230], ["tuple", "tabulate.tabulate", "zip", "small_dict.items"], "function", ["None"], ["", "", "def", "create_small_table", "(", "small_dict", ")", ":", "\n", "    ", "\"\"\"\n    Create a small table using the keys of small_dict as headers. This is only\n    suitable for small dictionaries.\n\n    Args:\n        small_dict (dict): a result dictionary of only a few items.\n\n    Returns:\n        str: the table as a string.\n    \"\"\"", "\n", "keys", ",", "values", "=", "tuple", "(", "zip", "(", "*", "small_dict", ".", "items", "(", ")", ")", ")", "\n", "table", "=", "tabulate", "(", "\n", "[", "values", "]", ",", "\n", "headers", "=", "keys", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "stralign", "=", "\"center\"", ",", "\n", "numalign", "=", "\"center\"", ",", "\n", ")", "\n", "return", "table", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._log_api_usage": [[232, 238], ["torch._C._log_api_usage_once"], "function", ["None"], ["", "def", "_log_api_usage", "(", "identifier", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Internal function used to log the usage of different detectron2 components\n    inside facebook's infra.\n    \"\"\"", "\n", "torch", ".", "_C", ".", "_log_api_usage_once", "(", "\"detectron2.\"", "+", "identifier", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry._convert_target_to_string": [[15, 20], ["None"], "function", ["None"], ["def", "_convert_target_to_string", "(", "t", ":", "Any", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Inverse of ``locate()``.\n    \"\"\"", "\n", "return", "f\"{t.__module__}.{t.__qualname__}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry.locate": [[22, 43], ["pydoc.locate", "get_method", "ImportError"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry.locate"], ["", "def", "locate", "(", "name", ":", "str", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Locate and return an object ``x`` using an input string ``{x.__module__}.{x.__qualname__}``,\n    such as \"module.submodule.class_name\".\n\n    Raise Exception if it cannot be found.\n    \"\"\"", "\n", "obj", "=", "pydoc", ".", "locate", "(", "name", ")", "\n", "\n", "# Some cases (e.g. torch.optim.sgd.SGD) not handled correctly", "\n", "# by pydoc.locate. Try a private function from hydra.", "\n", "# Should use _locate directly if it's public.", "\n", "if", "obj", "is", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "hydra", ".", "utils", "import", "get_method", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "raise", "ImportError", "(", "f\"Cannot dynamically locate object {name}!\"", ")", "from", "e", "\n", "", "else", ":", "\n", "            ", "obj", "=", "get_method", "(", "name", ")", "# it raises if fails", "\n", "\n", "", "", "return", "obj", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.collect_torch_env": [[17, 27], ["torch.__config__.show", "get_pretty_env_info"], "function", ["None"], ["def", "collect_torch_env", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "torch", ".", "__config__", "\n", "\n", "return", "torch", ".", "__config__", ".", "show", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "# compatible with older versions of pytorch", "\n", "        ", "from", "torch", ".", "utils", ".", "collect_env", "import", "get_pretty_env_info", "\n", "\n", "return", "get_pretty_env_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.get_env_module": [[29, 32], ["os.environ.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "get_env_module", "(", ")", ":", "\n", "    ", "var_name", "=", "\"DETECTRON2_ENV_MODULE\"", "\n", "return", "var_name", ",", "os", ".", "environ", ".", "get", "(", "var_name", ",", "\"<not set>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.detect_compute_compatibility": [[34, 53], ["os.path.join", "os.path.isfile", "subprocess.check_output", "output.decode().strip().split.decode().strip().split", "sorted", "sorted.append", "set", "output.decode().strip().split.decode().strip", "re.findall", "output.decode().strip().split.decode"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["", "def", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "so_file", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "cuobjdump", "=", "os", ".", "path", ".", "join", "(", "CUDA_HOME", ",", "\"bin\"", ",", "\"cuobjdump\"", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cuobjdump", ")", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "\n", "\"'{}' --list-elf '{}'\"", ".", "format", "(", "cuobjdump", ",", "so_file", ")", ",", "shell", "=", "True", "\n", ")", "\n", "output", "=", "output", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "arch", "=", "[", "]", "\n", "for", "line", "in", "output", ":", "\n", "                ", "line", "=", "re", ".", "findall", "(", "r\"\\.sm_([0-9]*)\\.\"", ",", "line", ")", "[", "0", "]", "\n", "arch", ".", "append", "(", "\".\"", ".", "join", "(", "line", ")", ")", "\n", "", "arch", "=", "sorted", "(", "set", "(", "arch", ")", ")", "\n", "return", "\", \"", ".", "join", "(", "arch", ")", "\n", "", "else", ":", "\n", "            ", "return", "so_file", "+", "\"; cannot find cuobjdump\"", "\n", "", "", "except", "Exception", ":", "\n", "# unhandled failure", "\n", "        ", "return", "so_file", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.collect_env_info": [[55, 189], ["torch.cuda.is_available", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "collect_env.collect_torch_env", "data.append", "data.append", "data.append", "collect_env.get_env_module", "collections.defaultdict", "range", "collections.defaultdict.items", "data.append", "data.append", "data.append", "data.append", "tabulate.tabulate", "getattr", "sys.version.replace", "data.append", "data.append", "data.append", "torch.cuda.device_count", "devices[].append", "data.append", "data.append", "data.append", "os.environ.get", "data.append", "data.append", "data.append", "_C.get_compiler_version", "_C.get_cuda_version", "getattr", "os.path.dirname", "torch.cuda.get_device_name", "str", "data.append", "collect_env.detect_compute_compatibility", "data.append", "os.path.dirname", "os.environ.get", "subprocess.check_output", "data.append", "data.append", "collect_env.detect_compute_compatibility", "str", "os.path.dirname", "importlib.util.find_spec", "data.append", "subprocess.check_output.decode().strip().split", "os.path.join", "subprocess.check_output", "importlib.util.find_spec", "torch.cuda.get_device_capability", "os.path.isdir", "str", "os.path.isdir", "str", "str", "subprocess.check_output.decode().strip().split", "collect_env.detect_compute_compatibility", "subprocess.check_output.decode().strip", "subprocess.check_output.decode().strip", "subprocess.check_output.decode", "subprocess.check_output.decode"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.collect_torch_env", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.get_env_module", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.detect_compute_compatibility", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.detect_compute_compatibility", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.detect_compute_compatibility", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["", "", "def", "collect_env_info", "(", ")", ":", "\n", "    ", "has_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "# true for both CUDA & ROCM", "\n", "torch_version", "=", "torch", ".", "__version__", "\n", "\n", "# NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional", "\n", "from", "torch", ".", "utils", ".", "cpp_extension", "import", "CUDA_HOME", ",", "ROCM_HOME", "\n", "\n", "has_rocm", "=", "False", "\n", "if", "(", "getattr", "(", "torch", ".", "version", ",", "\"hip\"", ",", "None", ")", "is", "not", "None", ")", "and", "(", "ROCM_HOME", "is", "not", "None", ")", ":", "\n", "        ", "has_rocm", "=", "True", "\n", "", "has_cuda", "=", "has_gpu", "and", "(", "not", "has_rocm", ")", "\n", "\n", "data", "=", "[", "]", "\n", "data", ".", "append", "(", "(", "\"sys.platform\"", ",", "sys", ".", "platform", ")", ")", "# check-template.yml depends on it", "\n", "data", ".", "append", "(", "(", "\"Python\"", ",", "sys", ".", "version", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"numpy\"", ",", "np", ".", "__version__", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "import", "detectron2", "# noqa", "\n", "\n", "data", ".", "append", "(", "\n", "(", "\"detectron2\"", ",", "detectron2", ".", "__version__", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "detectron2", ".", "__file__", ")", ")", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"detectron2\"", ",", "\"failed to import\"", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "import", "detectron2", ".", "_C", "as", "_C", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"detectron2._C\"", ",", "f\"not built correctly: {e}\"", ")", ")", "\n", "\n", "# print system compilers when extension fails to build", "\n", "if", "sys", ".", "platform", "!=", "\"win32\"", ":", "# don't know what to do for windows", "\n", "            ", "try", ":", "\n", "# this is how torch/utils/cpp_extensions.py choose compiler", "\n", "                ", "cxx", "=", "os", ".", "environ", ".", "get", "(", "\"CXX\"", ",", "\"c++\"", ")", "\n", "cxx", "=", "subprocess", ".", "check_output", "(", "\"'{}' --version\"", ".", "format", "(", "cxx", ")", ",", "shell", "=", "True", ")", "\n", "cxx", "=", "cxx", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "0", "]", "\n", "", "except", "subprocess", ".", "SubprocessError", ":", "\n", "                ", "cxx", "=", "\"Not found\"", "\n", "", "data", ".", "append", "(", "(", "\"Compiler ($CXX)\"", ",", "cxx", ")", ")", "\n", "\n", "if", "has_cuda", "and", "CUDA_HOME", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "nvcc", "=", "os", ".", "path", ".", "join", "(", "CUDA_HOME", ",", "\"bin\"", ",", "\"nvcc\"", ")", "\n", "nvcc", "=", "subprocess", ".", "check_output", "(", "\"'{}' -V\"", ".", "format", "(", "nvcc", ")", ",", "shell", "=", "True", ")", "\n", "nvcc", "=", "nvcc", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "-", "1", "]", "\n", "", "except", "subprocess", ".", "SubprocessError", ":", "\n", "                    ", "nvcc", "=", "\"Not found\"", "\n", "", "data", ".", "append", "(", "(", "\"CUDA compiler\"", ",", "nvcc", ")", ")", "\n", "", "", "if", "has_cuda", "and", "sys", ".", "platform", "!=", "\"win32\"", ":", "\n", "            ", "try", ":", "\n", "                ", "so_file", "=", "importlib", ".", "util", ".", "find_spec", "(", "\"detectron2._C\"", ")", ".", "origin", "\n", "", "except", "ImportError", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "data", ".", "append", "(", "\n", "(", "\"detectron2 arch flags\"", ",", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "so_file", ")", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "# print compilers that are used to build extension", "\n", "        ", "data", ".", "append", "(", "(", "\"Compiler\"", ",", "_C", ".", "get_compiler_version", "(", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"CUDA compiler\"", ",", "_C", ".", "get_cuda_version", "(", ")", ")", ")", "# cuda or hip", "\n", "if", "has_cuda", "and", "getattr", "(", "_C", ",", "\"has_cuda\"", ",", "lambda", ":", "True", ")", "(", ")", ":", "\n", "            ", "data", ".", "append", "(", "\n", "(", "\"detectron2 arch flags\"", ",", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "_C", ".", "__file__", ")", ")", "\n", ")", "\n", "\n", "", "", "data", ".", "append", "(", "get_env_module", "(", ")", ")", "\n", "data", ".", "append", "(", "(", "\"PyTorch\"", ",", "torch_version", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "torch", ".", "__file__", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"PyTorch debug build\"", ",", "torch", ".", "version", ".", "debug", ")", ")", "\n", "\n", "data", ".", "append", "(", "(", "\"GPU available\"", ",", "has_gpu", ")", ")", "\n", "if", "has_gpu", ":", "\n", "        ", "devices", "=", "defaultdict", "(", "list", ")", "\n", "for", "k", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ":", "\n", "            ", "cap", "=", "\".\"", ".", "join", "(", "(", "str", "(", "x", ")", "for", "x", "in", "torch", ".", "cuda", ".", "get_device_capability", "(", "k", ")", ")", ")", "\n", "name", "=", "torch", ".", "cuda", ".", "get_device_name", "(", "k", ")", "+", "f\" (arch={cap})\"", "\n", "devices", "[", "name", "]", ".", "append", "(", "str", "(", "k", ")", ")", "\n", "", "for", "name", ",", "devids", "in", "devices", ".", "items", "(", ")", ":", "\n", "            ", "data", ".", "append", "(", "(", "\"GPU \"", "+", "\",\"", ".", "join", "(", "devids", ")", ",", "name", ")", ")", "\n", "\n", "", "if", "has_rocm", ":", "\n", "            ", "msg", "=", "\" - invalid!\"", "if", "not", "(", "ROCM_HOME", "and", "os", ".", "path", ".", "isdir", "(", "ROCM_HOME", ")", ")", "else", "\"\"", "\n", "data", ".", "append", "(", "(", "\"ROCM_HOME\"", ",", "str", "(", "ROCM_HOME", ")", "+", "msg", ")", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "\" - invalid!\"", "if", "not", "(", "CUDA_HOME", "and", "os", ".", "path", ".", "isdir", "(", "CUDA_HOME", ")", ")", "else", "\"\"", "\n", "data", ".", "append", "(", "(", "\"CUDA_HOME\"", ",", "str", "(", "CUDA_HOME", ")", "+", "msg", ")", ")", "\n", "\n", "cuda_arch_list", "=", "os", ".", "environ", ".", "get", "(", "\"TORCH_CUDA_ARCH_LIST\"", ",", "None", ")", "\n", "if", "cuda_arch_list", ":", "\n", "                ", "data", ".", "append", "(", "(", "\"TORCH_CUDA_ARCH_LIST\"", ",", "cuda_arch_list", ")", ")", "\n", "", "", "", "data", ".", "append", "(", "(", "\"Pillow\"", ",", "PIL", ".", "__version__", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "data", ".", "append", "(", "\n", "(", "\n", "\"torchvision\"", ",", "\n", "str", "(", "torchvision", ".", "__version__", ")", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "torchvision", ".", "__file__", ")", ",", "\n", ")", "\n", ")", "\n", "if", "has_cuda", ":", "\n", "            ", "try", ":", "\n", "                ", "torchvision_C", "=", "importlib", ".", "util", ".", "find_spec", "(", "\"torchvision._C\"", ")", ".", "origin", "\n", "msg", "=", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "torchvision_C", ")", "\n", "data", ".", "append", "(", "(", "\"torchvision arch flags\"", ",", "msg", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "data", ".", "append", "(", "(", "\"torchvision._C\"", ",", "\"Not found\"", ")", ")", "\n", "", "", "", "except", "AttributeError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"torchvision\"", ",", "\"unknown\"", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "import", "fvcore", "\n", "\n", "data", ".", "append", "(", "(", "\"fvcore\"", ",", "fvcore", ".", "__version__", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "pass", "\n", "\n", "", "try", ":", "\n", "        ", "import", "iopath", "\n", "\n", "data", ".", "append", "(", "(", "\"iopath\"", ",", "iopath", ".", "__version__", ")", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "try", ":", "\n", "        ", "import", "cv2", "\n", "\n", "data", ".", "append", "(", "(", "\"cv2\"", ",", "cv2", ".", "__version__", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"cv2\"", ",", "\"Not found\"", ")", ")", "\n", "", "env_str", "=", "tabulate", "(", "data", ")", "+", "\"\\n\"", "\n", "env_str", "+=", "collect_torch_env", "(", ")", "\n", "return", "env_str", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.get_model_no_weights": [[19, 27], ["detectron2.model_zoo.get_config", "detectron2.modeling.build_model", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model"], ["def", "get_model_no_weights", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Like model_zoo.get, but do not load any weights (even pretrained)\n    \"\"\"", "\n", "cfg", "=", "model_zoo", ".", "get_config", "(", "config_path", ")", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "", "return", "build_model", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.random_boxes": [[29, 41], ["boxes.clamp_", "torch.rand"], "function", ["None"], ["", "def", "random_boxes", "(", "num_boxes", ",", "max_coord", "=", "100", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    Create a random Nx4 boxes tensor, with coordinates < max_coord.\n    \"\"\"", "\n", "boxes", "=", "torch", ".", "rand", "(", "num_boxes", ",", "4", ",", "device", "=", "device", ")", "*", "(", "max_coord", "*", "0.5", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "1.0", ")", "# tiny boxes cause numerical instability in box regression", "\n", "# Note: the implementation of this function in torchvision is:", "\n", "# boxes[:, 2:] += torch.rand(N, 2) * 100", "\n", "# but it does not guarantee non-negative widths/heights constraints:", "\n", "# boxes[:, 2] >= boxes[:, 0] and boxes[:, 3] >= boxes[:, 1]:", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.get_sample_coco_image": [[43, 63], ["detectron2.data.detection_utils.read_image", "torch.from_numpy", "detectron2.utils.file_io.PathManager.exists", "FileNotFoundError", "numpy.ascontiguousarray", "detectron2.data.DatasetCatalog.get", "torch.from_numpy.transpose"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "get_sample_coco_image", "(", "tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        tensor (bool): if True, returns 3xHxW tensor.\n            else, returns a HxWx3 numpy array.\n\n    Returns:\n        an image, in BGR color.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "file_name", "=", "DatasetCatalog", ".", "get", "(", "\"coco_2017_val_100\"", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "if", "not", "PathManager", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# for public CI to run", "\n", "        ", "file_name", "=", "\"http://images.cocodataset.org/train2017/000000000009.jpg\"", "\n", "", "ret", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "\n", "if", "tensor", ":", "\n", "        ", "ret", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "ret", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.convert_scripted_instances": [[65, 75], ["detectron2.structures.Instances", "getattr", "detectron2.structures.Instances.set"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "convert_scripted_instances", "(", "instances", ")", ":", "\n", "    ", "\"\"\"\n    Convert a scripted Instances object to a regular :class:`Instances` object\n    \"\"\"", "\n", "ret", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "for", "name", "in", "instances", ".", "_field_names", ":", "\n", "        ", "val", "=", "getattr", "(", "instances", ",", "\"_\"", "+", "name", ",", "None", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "            ", "ret", ".", "set", "(", "name", ",", "val", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.assert_instances_allclose": [[77, 122], ["sorted", "sorted", "isinstance", "testing.convert_scripted_instances", "isinstance", "testing.convert_scripted_instances", "torch.equal", "convert_scripted_instances.get_fields().keys", "convert_scripted_instances.get_fields().keys", "isinstance", "msg.rstrip", "torch.tensor", "torch.tensor", "convert_scripted_instances.get", "convert_scripted_instances.get", "torch.allclose", "isinstance", "convert_scripted_instances.get_fields", "convert_scripted_instances.get_fields", "ValueError", "torch.abs().max().cpu().item", "torch.allclose", "torch.equal", "torch.abs().max().cpu", "type", "torch.abs().max", "torch.abs"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.convert_scripted_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.convert_scripted_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "assert_instances_allclose", "(", "input", ",", "other", ",", "*", ",", "rtol", "=", "1e-5", ",", "msg", "=", "\"\"", ",", "size_as_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input, other (Instances):\n        size_as_tensor: compare image_size of the Instances as tensors (instead of tuples).\n             Useful for comparing outputs of tracing.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input", ",", "Instances", ")", ":", "\n", "        ", "input", "=", "convert_scripted_instances", "(", "input", ")", "\n", "", "if", "not", "isinstance", "(", "other", ",", "Instances", ")", ":", "\n", "        ", "other", "=", "convert_scripted_instances", "(", "other", ")", "\n", "\n", "", "if", "not", "msg", ":", "\n", "        ", "msg", "=", "\"Two Instances are different! \"", "\n", "", "else", ":", "\n", "        ", "msg", "=", "msg", ".", "rstrip", "(", ")", "+", "\" \"", "\n", "\n", "", "size_error_msg", "=", "msg", "+", "f\"image_size is {input.image_size} vs. {other.image_size}!\"", "\n", "if", "size_as_tensor", ":", "\n", "        ", "assert", "torch", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "input", ".", "image_size", ")", ",", "torch", ".", "tensor", "(", "other", ".", "image_size", ")", "\n", ")", ",", "size_error_msg", "\n", "", "else", ":", "\n", "        ", "assert", "input", ".", "image_size", "==", "other", ".", "image_size", ",", "size_error_msg", "\n", "", "fields", "=", "sorted", "(", "input", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "fields_other", "=", "sorted", "(", "other", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "assert", "fields", "==", "fields_other", ",", "msg", "+", "f\"Fields are {fields} vs {fields_other}!\"", "\n", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "val1", ",", "val2", "=", "input", ".", "get", "(", "f", ")", ",", "other", ".", "get", "(", "f", ")", "\n", "if", "isinstance", "(", "val1", ",", "Boxes", ")", ":", "\n", "# boxes in the range of O(100) and can have a larger tolerance", "\n", "            ", "assert", "torch", ".", "allclose", "(", "val1", ".", "tensor", ",", "val2", ".", "tensor", ",", "atol", "=", "100", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "elif", "isinstance", "(", "val1", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "val1", ".", "dtype", ".", "is_floating_point", ":", "\n", "                ", "mag", "=", "torch", ".", "abs", "(", "val1", ")", ".", "max", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "val1", ",", "val2", ",", "atol", "=", "mag", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "torch", ".", "equal", "(", "val1", ",", "val2", ")", ",", "msg", "+", "f\"Field {f} is different!\"", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Don't know how to compare type {type(val1)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.testing.reload_script_model": [[124, 133], ["io.BytesIO", "torch.jit.save", "io.BytesIO.seek", "torch.jit.load"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["", "", "", "def", "reload_script_model", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Save a jit module and load it back.\n    Similar to the `getExportImportCopy` function in torch/testing/\n    \"\"\"", "\n", "buffer", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "jit", ".", "save", "(", "module", ",", "buffer", ")", "\n", "buffer", ".", "seek", "(", "0", ")", "\n", "return", "torch", ".", "jit", ".", "load", "(", "buffer", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.file_io.Detectron2Handler._get_supported_prefixes": [[24, 26], ["None"], "methods", ["None"], ["def", "_get_supported_prefixes", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "PREFIX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.file_io.Detectron2Handler._get_local_path": [[27, 30], ["iopath.common.file_io.PathManager.get_local_path", "len"], "methods", ["None"], ["", "def", "_get_local_path", "(", "self", ",", "path", ",", "**", "kwargs", ")", ":", "\n", "        ", "name", "=", "path", "[", "len", "(", "self", ".", "PREFIX", ")", ":", "]", "\n", "return", "PathManager", ".", "get_local_path", "(", "self", ".", "S3_DETECTRON2_PREFIX", "+", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.file_io.Detectron2Handler._open": [[31, 33], ["iopath.common.file_io.PathManager.open", "file_io.Detectron2Handler._get_local_path"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalogHandler._get_local_path"], ["", "def", "_open", "(", "self", ",", "path", ",", "mode", "=", "\"r\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "self", ".", "_get_local_path", "(", "path", ")", ",", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.seed_all_rng": [[27, 46], ["numpy.random.seed", "torch.manual_seed", "random.seed", "str", "logging.getLogger", "logging.getLogger.info", "int.from_bytes", "os.getpid", "int", "os.urandom", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "seed_all_rng", "(", "seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Set the random seed for the RNG in torch, numpy and python.\n\n    Args:\n        seed (int): if None, will use a strong random seed.\n    \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "        ", "seed", "=", "(", "\n", "os", ".", "getpid", "(", ")", "\n", "+", "int", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%S%f\"", ")", ")", "\n", "+", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "2", ")", ",", "\"big\"", ")", "\n", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using a generated random seed {}\"", ".", "format", "(", "seed", ")", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "\"PYTHONHASHSEED\"", "]", "=", "str", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env._import_file": [[49, 56], ["importlib.util.spec_from_file_location", "importlib.util.spec_from_file_location", "importlib.util.module_from_spec", "importlib.util.module_from_spec", "importlib.util.spec_from_file_location.loader.exec_module"], "function", ["None"], ["", "def", "_import_file", "(", "module_name", ",", "file_path", ",", "make_importable", "=", "False", ")", ":", "\n", "    ", "spec", "=", "importlib", ".", "util", ".", "spec_from_file_location", "(", "module_name", ",", "file_path", ")", "\n", "module", "=", "importlib", ".", "util", ".", "module_from_spec", "(", "spec", ")", "\n", "spec", ".", "loader", ".", "exec_module", "(", "module", ")", "\n", "if", "make_importable", ":", "\n", "        ", "sys", ".", "modules", "[", "module_name", "]", "=", "module", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env._configure_libraries": [[58, 91], ["int", "os.environ.get", "tuple", "env._configure_libraries.get_version"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.None.setup.get_version"], ["", "def", "_configure_libraries", "(", ")", ":", "\n", "    ", "\"\"\"\n    Configurations for some libraries.\n    \"\"\"", "\n", "# An environment option to disable `import cv2` globally,", "\n", "# in case it leads to negative performance impact", "\n", "disable_cv2", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"DETECTRON2_DISABLE_CV2\"", ",", "False", ")", ")", "\n", "if", "disable_cv2", ":", "\n", "        ", "sys", ".", "modules", "[", "\"cv2\"", "]", "=", "None", "\n", "", "else", ":", "\n", "# Disable opencl in opencv since its interaction with cuda often has negative effects", "\n", "# This envvar is supported after OpenCV 3.4.0", "\n", "        ", "os", ".", "environ", "[", "\"OPENCV_OPENCL_RUNTIME\"", "]", "=", "\"disabled\"", "\n", "try", ":", "\n", "            ", "import", "cv2", "\n", "\n", "if", "int", "(", "cv2", ".", "__version__", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", ">=", "3", ":", "\n", "                ", "cv2", ".", "ocl", ".", "setUseOpenCL", "(", "False", ")", "\n", "", "", "except", "ModuleNotFoundError", ":", "\n", "# Other types of ImportError, if happened, should not be ignored.", "\n", "# Because a failed opencv import could mess up address space", "\n", "# https://github.com/skvark/opencv-python/issues/381", "\n", "            ", "pass", "\n", "\n", "", "", "def", "get_version", "(", "module", ",", "digit", "=", "2", ")", ":", "\n", "        ", "return", "tuple", "(", "map", "(", "int", ",", "module", ".", "__version__", ".", "split", "(", "\".\"", ")", "[", ":", "digit", "]", ")", ")", "\n", "\n", "# fmt: off", "\n", "", "assert", "get_version", "(", "torch", ")", ">=", "(", "1", ",", "4", ")", ",", "\"Requires torch>=1.4\"", "\n", "import", "fvcore", "\n", "assert", "get_version", "(", "fvcore", ",", "3", ")", ">=", "(", "0", ",", "1", ",", "2", ")", ",", "\"Requires fvcore>=0.1.2\"", "\n", "import", "yaml", "\n", "assert", "get_version", "(", "yaml", ")", ">=", "(", "5", ",", "1", ")", ",", "\"Requires pyyaml>=5.1\"", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.setup_environment": [[97, 117], ["env._configure_libraries", "os.environ.get", "env.setup_custom_environment"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env._configure_libraries", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.setup_custom_environment"], ["def", "setup_environment", "(", ")", ":", "\n", "    ", "\"\"\"Perform environment setup work. The default setup is a no-op, but this\n    function allows the user to specify a Python source file or a module in\n    the $DETECTRON2_ENV_MODULE environment variable, that performs\n    custom setup work that may be necessary to their computing environment.\n    \"\"\"", "\n", "global", "_ENV_SETUP_DONE", "\n", "if", "_ENV_SETUP_DONE", ":", "\n", "        ", "return", "\n", "", "_ENV_SETUP_DONE", "=", "True", "\n", "\n", "_configure_libraries", "(", ")", "\n", "\n", "custom_module_path", "=", "os", ".", "environ", ".", "get", "(", "\"DETECTRON2_ENV_MODULE\"", ")", "\n", "\n", "if", "custom_module_path", ":", "\n", "        ", "setup_custom_environment", "(", "custom_module_path", ")", "\n", "", "else", ":", "\n", "# The default setup is a no-op", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.setup_custom_environment": [[119, 133], ["custom_module.endswith", "importlib.import_module.setup_environment", "env._import_file", "importlib.import_module", "importlib.import_module", "hasattr", "callable"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.setup_environment", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env._import_file"], ["", "", "def", "setup_custom_environment", "(", "custom_module", ")", ":", "\n", "    ", "\"\"\"\n    Load custom environment setup by importing a Python source file or a\n    module, and run the setup function.\n    \"\"\"", "\n", "if", "custom_module", ".", "endswith", "(", "\".py\"", ")", ":", "\n", "        ", "module", "=", "_import_file", "(", "\"detectron2.utils.env.custom_module\"", ",", "custom_module", ")", "\n", "", "else", ":", "\n", "        ", "module", "=", "importlib", ".", "import_module", "(", "custom_module", ")", "\n", "", "assert", "hasattr", "(", "module", ",", "\"setup_environment\"", ")", "and", "callable", "(", "module", ".", "setup_environment", ")", ",", "(", "\n", "\"Custom environment module defined in {} does not have the \"", "\n", "\"required callable attribute 'setup_environment'.\"", "\n", ")", ".", "format", "(", "custom_module", ")", "\n", "module", ".", "setup_environment", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.fixup_module_metadata": [[135, 171], ["set", "set.add", "getattr", "namespace.keys", "id", "id", "isinstance", "objname.startswith", "env.fixup_module_metadata.fix_one"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "fixup_module_metadata", "(", "module_name", ",", "namespace", ",", "keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Fix the __qualname__ of module members to be their exported api name, so\n    when they are referenced in docs, sphinx can find them. Reference:\n    https://github.com/python-trio/trio/blob/6754c74eacfad9cc5c92d5c24727a2f3b620624e/trio/_util.py#L216-L241\n    \"\"\"", "\n", "if", "not", "DOC_BUILDING", ":", "\n", "        ", "return", "\n", "", "seen_ids", "=", "set", "(", ")", "\n", "\n", "def", "fix_one", "(", "qualname", ",", "name", ",", "obj", ")", ":", "\n", "# avoid infinite recursion (relevant when using", "\n", "# typing.Generic, for example)", "\n", "        ", "if", "id", "(", "obj", ")", "in", "seen_ids", ":", "\n", "            ", "return", "\n", "", "seen_ids", ".", "add", "(", "id", "(", "obj", ")", ")", "\n", "\n", "mod", "=", "getattr", "(", "obj", ",", "\"__module__\"", ",", "None", ")", "\n", "if", "mod", "is", "not", "None", "and", "(", "mod", ".", "startswith", "(", "module_name", ")", "or", "mod", ".", "startswith", "(", "\"fvcore.\"", ")", ")", ":", "\n", "            ", "obj", ".", "__module__", "=", "module_name", "\n", "# Modules, unlike everything else in Python, put fully-qualitied", "\n", "# names into their __name__ attribute. We check for \".\" to avoid", "\n", "# rewriting these.", "\n", "if", "hasattr", "(", "obj", ",", "\"__name__\"", ")", "and", "\".\"", "not", "in", "obj", ".", "__name__", ":", "\n", "                ", "obj", ".", "__name__", "=", "name", "\n", "obj", ".", "__qualname__", "=", "qualname", "\n", "", "if", "isinstance", "(", "obj", ",", "type", ")", ":", "\n", "                ", "for", "attr_name", ",", "attr_value", "in", "obj", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "                    ", "fix_one", "(", "objname", "+", "\".\"", "+", "attr_name", ",", "attr_name", ",", "attr_value", ")", "\n", "\n", "", "", "", "", "if", "keys", "is", "None", ":", "\n", "        ", "keys", "=", "namespace", ".", "keys", "(", ")", "\n", "", "for", "objname", "in", "keys", ":", "\n", "        ", "if", "not", "objname", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "obj", "=", "namespace", "[", "objname", "]", "\n", "fix_one", "(", "objname", ",", "objname", ",", "obj", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory._ignore_torch_cuda_oom": [[11, 24], ["str"], "function", ["None"], ["@", "contextmanager", "\n", "def", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "    ", "\"\"\"\n    A context which ignores CUDA OOM exception from pytorch.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "# NOTE: the string may change?", "\n", "        ", "if", "\"CUDA out of memory. \"", "in", "str", "(", "e", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom": [[26, 85], ["functools.wraps", "torch.cuda.empty_cache", "logging.getLogger", "logging.getLogger.info", "func", "x.to", "memory._ignore_torch_cuda_oom", "func", "memory._ignore_torch_cuda_oom", "func", "memory.retry_if_cuda_oom.maybe_to_cpu"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory._ignore_torch_cuda_oom", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory._ignore_torch_cuda_oom"], ["", "", "", "def", "retry_if_cuda_oom", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Makes a function retry itself after encountering\n    pytorch's CUDA OOM error.\n    It will first retry after calling `torch.cuda.empty_cache()`.\n\n    If that still fails, it will then retry by trying to convert inputs to CPUs.\n    In this case, it expects the function to dispatch to CPU implementation.\n    The return values may become CPU tensors as well and it's user's\n    responsibility to convert it back to CUDA tensor if needed.\n\n    Args:\n        func: a stateless callable that takes tensor-like objects as arguments\n\n    Returns:\n        a callable which retries `func` if OOM is encountered.\n\n    Examples:\n    ::\n        output = retry_if_cuda_oom(some_torch_function)(input1, input2)\n        # output may be on CPU even if inputs are on GPU\n\n    Note:\n        1. When converting inputs to CPU, it will only look at each argument and check\n           if it has `.device` and `.to` for conversion. Nested structures of tensors\n           are not supported.\n\n        2. Since the function might be called more than once, it has to be\n           stateless.\n    \"\"\"", "\n", "\n", "def", "maybe_to_cpu", "(", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "like_gpu_tensor", "=", "x", ".", "device", ".", "type", "==", "\"cuda\"", "and", "hasattr", "(", "x", ",", "\"to\"", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "like_gpu_tensor", "=", "False", "\n", "", "if", "like_gpu_tensor", ":", "\n", "            ", "return", "x", ".", "to", "(", "device", "=", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "@", "wraps", "(", "func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Clear cache and retry", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Try on CPU. This slows down the code significantly, therefore print a notice.", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Attempting to copy inputs of {} to CPU due to CUDA OOM\"", ".", "format", "(", "str", "(", "func", ")", ")", ")", "\n", "new_args", "=", "(", "maybe_to_cpu", "(", "x", ")", "for", "x", "in", "args", ")", "\n", "new_kwargs", "=", "{", "k", ":", "maybe_to_cpu", "(", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "}", "\n", "return", "func", "(", "*", "new_args", ",", "**", "new_kwargs", ")", "\n", "\n", "", "return", "wrapped", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess": [[11, 76], ["isinstance", "detectron2.structures.Instances", "detectron2.structures.Instances.has", "output_boxes.scale", "output_boxes.clip", "detectron2.structures.Instances.has", "detectron2.structures.Instances.has", "output_width.float", "output_height.float", "torch.stack", "detectron2.structures.Instances.has", "detectron2.structures.Instances.get_fields", "output_boxes.nonempty", "detectron2.utils.memory.retry_if_cuda_oom"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.scale", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom"], ["def", "detector_postprocess", "(", "\n", "results", ":", "Instances", ",", "output_height", ":", "int", ",", "output_width", ":", "int", ",", "mask_threshold", ":", "float", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Resize the output instances.\n    The input images are often resized when entering an object detector.\n    As a result, we often need the outputs of the detector in a different\n    resolution from its inputs.\n\n    This function will resize the raw outputs of an R-CNN detector\n    to produce outputs according to the desired output resolution.\n\n    Args:\n        results (Instances): the raw outputs from the detector.\n            `results.image_size` contains the input image resolution the detector sees.\n            This object might be modified in-place.\n        output_height, output_width: the desired output resolution.\n\n    Returns:\n        Instances: the resized output from the model, based on the output resolution\n    \"\"\"", "\n", "# Change to 'if is_tracing' after PT1.7", "\n", "if", "isinstance", "(", "output_height", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Converts integer tensors to float temporaries to ensure true", "\n", "# division is performed when computing scale_x and scale_y.", "\n", "        ", "output_width_tmp", "=", "output_width", ".", "float", "(", ")", "\n", "output_height_tmp", "=", "output_height", ".", "float", "(", ")", "\n", "new_size", "=", "torch", ".", "stack", "(", "[", "output_height", ",", "output_width", "]", ")", "\n", "", "else", ":", "\n", "        ", "new_size", "=", "(", "output_height", ",", "output_width", ")", "\n", "output_width_tmp", "=", "output_width", "\n", "output_height_tmp", "=", "output_height", "\n", "\n", "", "scale_x", ",", "scale_y", "=", "(", "\n", "output_width_tmp", "/", "results", ".", "image_size", "[", "1", "]", ",", "\n", "output_height_tmp", "/", "results", ".", "image_size", "[", "0", "]", ",", "\n", ")", "\n", "results", "=", "Instances", "(", "new_size", ",", "**", "results", ".", "get_fields", "(", ")", ")", "\n", "\n", "if", "results", ".", "has", "(", "\"pred_boxes\"", ")", ":", "\n", "        ", "output_boxes", "=", "results", ".", "pred_boxes", "\n", "", "elif", "results", ".", "has", "(", "\"proposal_boxes\"", ")", ":", "\n", "        ", "output_boxes", "=", "results", ".", "proposal_boxes", "\n", "", "else", ":", "\n", "        ", "output_boxes", "=", "None", "\n", "", "assert", "output_boxes", "is", "not", "None", ",", "\"Predictions must contain boxes!\"", "\n", "\n", "output_boxes", ".", "scale", "(", "scale_x", ",", "scale_y", ")", "\n", "output_boxes", ".", "clip", "(", "results", ".", "image_size", ")", "\n", "\n", "results", "=", "results", "[", "output_boxes", ".", "nonempty", "(", ")", "]", "\n", "\n", "if", "results", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "        ", "results", ".", "pred_masks", "=", "retry_if_cuda_oom", "(", "paste_masks_in_image", ")", "(", "\n", "results", ".", "pred_masks", "[", ":", ",", "0", ",", ":", ",", ":", "]", ",", "# N, 1, M, M", "\n", "results", ".", "pred_boxes", ",", "\n", "results", ".", "image_size", ",", "\n", "threshold", "=", "mask_threshold", ",", "\n", ")", "\n", "\n", "", "if", "results", ".", "has", "(", "\"pred_keypoints\"", ")", ":", "\n", "        ", "results", ".", "pred_keypoints", "[", ":", ",", ":", ",", "0", "]", "*=", "scale_x", "\n", "results", ".", "pred_keypoints", "[", ":", ",", ":", ",", "1", "]", "*=", "scale_y", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.sem_seg_postprocess": [[78, 102], ["result[].expand", "torch.nn.functional.interpolate"], "function", ["None"], ["", "def", "sem_seg_postprocess", "(", "result", ",", "img_size", ",", "output_height", ",", "output_width", ")", ":", "\n", "    ", "\"\"\"\n    Return semantic segmentation predictions in the original resolution.\n\n    The input images are often resized when entering semantic segmentor. Moreover, in same\n    cases, they also padded inside segmentor to be divisible by maximum network stride.\n    As a result, we often need the predictions of the segmentor in a different\n    resolution from its inputs.\n\n    Args:\n        result (Tensor): semantic segmentation prediction logits. A tensor of shape (C, H, W),\n            where C is the number of classes, and H, W are the height and width of the prediction.\n        img_size (tuple): image size that segmentor is taking as input.\n        output_height, output_width: the desired output resolution.\n\n    Returns:\n        semantic segmentation prediction (Tensor): A tensor of the shape\n            (C, output_height, output_width) that contains per-pixel soft predictions.\n    \"\"\"", "\n", "result", "=", "result", "[", ":", ",", ":", "img_size", "[", "0", "]", ",", ":", "img_size", "[", "1", "]", "]", ".", "expand", "(", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "result", "=", "F", ".", "interpolate", "(", "\n", "result", ",", "size", "=", "(", "output_height", ",", "output_width", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "[", "0", "]", "\n", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.matcher.Matcher.__init__": [[24, 60], ["thresholds.insert", "thresholds.append", "all", "all", "float", "len", "float", "len", "zip"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "thresholds", ":", "List", "[", "float", "]", ",", "labels", ":", "List", "[", "int", "]", ",", "allow_low_quality_matches", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            thresholds (list): a list of thresholds used to stratify predictions\n                into levels.\n            labels (list): a list of values to label predictions belonging at\n                each level. A label can be one of {-1, 0, 1} signifying\n                {ignore, negative class, positive class}, respectively.\n            allow_low_quality_matches (bool): if True, produce additional matches\n                for predictions with maximum match quality lower than high_threshold.\n                See set_low_quality_matches_ for more details.\n\n            For example,\n                thresholds = [0.3, 0.5]\n                labels = [0, -1, 1]\n                All predictions with iou < 0.3 will be marked with 0 and\n                thus will be considered as false positives while training.\n                All predictions with 0.3 <= iou < 0.5 will be marked with -1 and\n                thus will be ignored.\n                All predictions with 0.5 <= iou will be marked with 1 and\n                thus will be considered as true positives.\n        \"\"\"", "\n", "# Add -inf and +inf to first and last position in thresholds", "\n", "thresholds", "=", "thresholds", "[", ":", "]", "\n", "assert", "thresholds", "[", "0", "]", ">", "0", "\n", "thresholds", ".", "insert", "(", "0", ",", "-", "float", "(", "\"inf\"", ")", ")", "\n", "thresholds", ".", "append", "(", "float", "(", "\"inf\"", ")", ")", "\n", "# Currently torchscript does not support all + generator", "\n", "assert", "all", "(", "[", "low", "<=", "high", "for", "(", "low", ",", "high", ")", "in", "zip", "(", "thresholds", "[", ":", "-", "1", "]", ",", "thresholds", "[", "1", ":", "]", ")", "]", ")", "\n", "assert", "all", "(", "[", "l", "in", "[", "-", "1", ",", "0", ",", "1", "]", "for", "l", "in", "labels", "]", ")", "\n", "assert", "len", "(", "labels", ")", "==", "len", "(", "thresholds", ")", "-", "1", "\n", "self", ".", "thresholds", "=", "thresholds", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "allow_low_quality_matches", "=", "allow_low_quality_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.matcher.Matcher.__call__": [[61, 104], ["torch.all", "match_quality_matrix.max", "matches.new_full", "zip", "match_quality_matrix.dim", "match_quality_matrix.numel", "match_quality_matrix.new_full", "match_quality_matrix.new_full", "matches.size", "matcher.Matcher.set_low_quality_matches_", "match_quality_matrix.size", "match_quality_matrix.size"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.matcher.Matcher.set_low_quality_matches_"], ["", "def", "__call__", "(", "self", ",", "match_quality_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            match_quality_matrix (Tensor[float]): an MxN tensor, containing the\n                pairwise quality between M ground-truth elements and N predicted\n                elements. All elements must be >= 0 (due to the us of `torch.nonzero`\n                for selecting indices in :meth:`set_low_quality_matches_`).\n\n        Returns:\n            matches (Tensor[int64]): a vector of length N, where matches[i] is a matched\n                ground-truth index in [0, M)\n            match_labels (Tensor[int8]): a vector of length N, where pred_labels[i] indicates\n                whether a prediction is a true or false positive or ignored\n        \"\"\"", "\n", "assert", "match_quality_matrix", ".", "dim", "(", ")", "==", "2", "\n", "if", "match_quality_matrix", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "default_matches", "=", "match_quality_matrix", ".", "new_full", "(", "\n", "(", "match_quality_matrix", ".", "size", "(", "1", ")", ",", ")", ",", "0", ",", "dtype", "=", "torch", ".", "int64", "\n", ")", "\n", "# When no gt boxes exist, we define IOU = 0 and therefore set labels", "\n", "# to `self.labels[0]`, which usually defaults to background class 0", "\n", "# To choose to ignore instead, can make labels=[-1,0,-1,1] + set appropriate thresholds", "\n", "default_match_labels", "=", "match_quality_matrix", ".", "new_full", "(", "\n", "(", "match_quality_matrix", ".", "size", "(", "1", ")", ",", ")", ",", "self", ".", "labels", "[", "0", "]", ",", "dtype", "=", "torch", ".", "int8", "\n", ")", "\n", "return", "default_matches", ",", "default_match_labels", "\n", "\n", "", "assert", "torch", ".", "all", "(", "match_quality_matrix", ">=", "0", ")", "\n", "\n", "# match_quality_matrix is M (gt) x N (predicted)", "\n", "# Max over gt elements (dim 0) to find best gt candidate for each prediction", "\n", "matched_vals", ",", "matches", "=", "match_quality_matrix", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "match_labels", "=", "matches", ".", "new_full", "(", "matches", ".", "size", "(", ")", ",", "1", ",", "dtype", "=", "torch", ".", "int8", ")", "\n", "\n", "for", "(", "l", ",", "low", ",", "high", ")", "in", "zip", "(", "self", ".", "labels", ",", "self", ".", "thresholds", "[", ":", "-", "1", "]", ",", "self", ".", "thresholds", "[", "1", ":", "]", ")", ":", "\n", "            ", "low_high", "=", "(", "matched_vals", ">=", "low", ")", "&", "(", "matched_vals", "<", "high", ")", "\n", "match_labels", "[", "low_high", "]", "=", "l", "\n", "\n", "", "if", "self", ".", "allow_low_quality_matches", ":", "\n", "            ", "self", ".", "set_low_quality_matches_", "(", "match_labels", ",", "match_quality_matrix", ")", "\n", "\n", "", "return", "matches", ",", "match_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.matcher.Matcher.set_low_quality_matches_": [[105, 127], ["match_quality_matrix.max", "detectron2.layers.nonzero_tuple"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple"], ["", "def", "set_low_quality_matches_", "(", "self", ",", "match_labels", ",", "match_quality_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Produce additional matches for predictions that have only low-quality matches.\n        Specifically, for each ground-truth G find the set of predictions that have\n        maximum overlap with it (including ties); for each prediction in that set, if\n        it is unmatched, then match it to the ground-truth G.\n\n        This function implements the RPN assignment case (i) in Sec. 3.1.2 of\n        :paper:`Faster R-CNN`.\n        \"\"\"", "\n", "# For each gt, find the prediction with which it has highest quality", "\n", "highest_quality_foreach_gt", ",", "_", "=", "match_quality_matrix", ".", "max", "(", "dim", "=", "1", ")", "\n", "# Find the highest quality match available, even if it is low, including ties.", "\n", "# Note that the matches qualities must be positive due to the use of", "\n", "# `torch.nonzero`.", "\n", "_", ",", "pred_inds_with_highest_quality", "=", "nonzero_tuple", "(", "\n", "match_quality_matrix", "==", "highest_quality_foreach_gt", "[", ":", ",", "None", "]", "\n", ")", "\n", "# If an anchor was labeled positive only due to a low-quality match", "\n", "# with gt_A, but it has larger overlap with gt_B, it's matched index will still be gt_B.", "\n", "# This follows the implementation in Detectron, and is found to have no significant impact.", "\n", "match_labels", "[", "pred_inds_with_highest_quality", "]", "=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.BufferList.__init__": [[26, 30], ["torch.nn.Module.__init__", "enumerate", "anchor_generator.BufferList.register_buffer", "str"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "buffers", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "for", "i", ",", "buffer", "in", "enumerate", "(", "buffers", ")", ":", "\n", "            ", "self", ".", "register_buffer", "(", "str", "(", "i", ")", ",", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.BufferList.__len__": [[31, 33], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_buffers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.BufferList.__iter__": [[34, 36], ["iter", "anchor_generator.BufferList._buffers.values"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "_buffers", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.__init__": [[92, 121], ["torch.nn.Module.__init__", "len", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator.DefaultAnchorGenerator._calculate_anchors"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", ",", "sizes", ",", "aspect_ratios", ",", "strides", ",", "offset", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        This interface is experimental.\n\n        Args:\n            sizes (list[list[float]] or list[float]):\n                If ``sizes`` is list[list[float]], ``sizes[i]`` is the list of anchor sizes\n                (i.e. sqrt of anchor area) to use for the i-th feature map.\n                If ``sizes`` is list[float], ``sizes`` is used for all feature maps.\n                Anchor sizes are given in absolute lengths in units of\n                the input image; they do not dynamically scale if the input image size changes.\n            aspect_ratios (list[list[float]] or list[float]): list of aspect ratios\n                (i.e. height / width) to use for anchors. Same \"broadcast\" rule for `sizes` applies.\n            strides (list[int]): stride of each input feature.\n            offset (float): Relative offset between the center of the first anchor and the top-left\n                corner of the image. Value has to be in [0, 1).\n                Recommend to use 0.5, which means half stride.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "num_features", "=", "len", "(", "self", ".", "strides", ")", "\n", "sizes", "=", "_broadcast_params", "(", "sizes", ",", "self", ".", "num_features", ",", "\"sizes\"", ")", "\n", "aspect_ratios", "=", "_broadcast_params", "(", "aspect_ratios", ",", "self", ".", "num_features", ",", "\"aspect_ratios\"", ")", "\n", "self", ".", "cell_anchors", "=", "self", ".", "_calculate_anchors", "(", "sizes", ",", "aspect_ratios", ")", "\n", "\n", "self", ".", "offset", "=", "offset", "\n", "assert", "0.0", "<=", "self", ".", "offset", "<", "1.0", ",", "self", ".", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.from_config": [[122, 129], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "List", "[", "ShapeSpec", "]", ")", ":", "\n", "        ", "return", "{", "\n", "\"sizes\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", ",", "\n", "\"aspect_ratios\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "ASPECT_RATIOS", ",", "\n", "\"strides\"", ":", "[", "x", ".", "stride", "for", "x", "in", "input_shape", "]", ",", "\n", "\"offset\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "OFFSET", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator._calculate_anchors": [[131, 136], ["anchor_generator.BufferList", "anchor_generator.DefaultAnchorGenerator.generate_cell_anchors().float", "zip", "anchor_generator.DefaultAnchorGenerator.generate_cell_anchors"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], ["", "def", "_calculate_anchors", "(", "self", ",", "sizes", ",", "aspect_ratios", ")", ":", "\n", "        ", "cell_anchors", "=", "[", "\n", "self", ".", "generate_cell_anchors", "(", "s", ",", "a", ")", ".", "float", "(", ")", "for", "s", ",", "a", "in", "zip", "(", "sizes", ",", "aspect_ratios", ")", "\n", "]", "\n", "return", "BufferList", "(", "cell_anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.num_cell_anchors": [[137, 144], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "num_cell_anchors", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Alias of `num_anchors`.\n        \"\"\"", "\n", "return", "self", ".", "num_anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.num_anchors": [[145, 159], ["len"], "methods", ["None"], ["", "@", "property", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "num_anchors", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[int]: Each int is the number of anchors at every pixel\n                location, on that feature map.\n                For example, if at every pixel we use anchors of 3 aspect\n                ratios and 5 sizes, the number of anchors is 15.\n                (See also ANCHOR_GENERATOR.SIZES and ANCHOR_GENERATOR.ASPECT_RATIOS in config)\n\n                In standard RPN models, `num_anchors` on every feature map is the same.\n        \"\"\"", "\n", "return", "[", "len", "(", "cell_anchors", ")", "for", "cell_anchors", "in", "self", ".", "cell_anchors", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator._grid_anchors": [[160, 175], ["zip", "anchor_generator._create_grid_offsets", "torch.stack", "anchors.append", "anchor_generator.DefaultAnchorGenerator.cell_anchors.named_buffers", "torch.stack.view", "base_anchors.view"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._create_grid_offsets"], ["", "def", "_grid_anchors", "(", "self", ",", "grid_sizes", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[Tensor]: #featuremap tensors, each is (#locations x #cell_anchors) x 4\n        \"\"\"", "\n", "anchors", "=", "[", "]", "\n", "# buffers() not supported by torchscript. use named_buffers() instead", "\n", "buffers", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "x", "[", "1", "]", "for", "x", "in", "self", ".", "cell_anchors", ".", "named_buffers", "(", ")", "]", "\n", "for", "size", ",", "stride", ",", "base_anchors", "in", "zip", "(", "grid_sizes", ",", "self", ".", "strides", ",", "buffers", ")", ":", "\n", "            ", "shift_x", ",", "shift_y", "=", "_create_grid_offsets", "(", "size", ",", "stride", ",", "self", ".", "offset", ",", "base_anchors", ".", "device", ")", "\n", "shifts", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ",", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "\n", "\n", "anchors", ".", "append", "(", "(", "shifts", ".", "view", "(", "-", "1", ",", "1", ",", "4", ")", "+", "base_anchors", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "\n", "", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.generate_cell_anchors": [[176, 212], ["torch.tensor", "math.sqrt", "anchors.append"], "methods", ["None"], ["", "def", "generate_cell_anchors", "(", "self", ",", "sizes", "=", "(", "32", ",", "64", ",", "128", ",", "256", ",", "512", ")", ",", "aspect_ratios", "=", "(", "0.5", ",", "1", ",", "2", ")", ")", ":", "\n", "        ", "\"\"\"\n        Generate a tensor storing canonical anchor boxes, which are all anchor\n        boxes of different sizes and aspect_ratios centered at (0, 0).\n        We can later build the set of anchors for a full feature map by\n        shifting and tiling these tensors (see `meth:_grid_anchors`).\n\n        Args:\n            sizes (tuple[float]):\n            aspect_ratios (tuple[float]]):\n\n        Returns:\n            Tensor of shape (len(sizes) * len(aspect_ratios), 4) storing anchor boxes\n                in XYXY format.\n        \"\"\"", "\n", "\n", "# This is different from the anchor generator defined in the original Faster R-CNN", "\n", "# code or Detectron. They yield the same AP, however the old version defines cell", "\n", "# anchors in a less natural way with a shift relative to the feature grid and", "\n", "# quantization that results in slightly different sizes for different aspect ratios.", "\n", "# See also https://github.com/facebookresearch/Detectron/issues/227", "\n", "\n", "anchors", "=", "[", "]", "\n", "for", "size", "in", "sizes", ":", "\n", "            ", "area", "=", "size", "**", "2.0", "\n", "for", "aspect_ratio", "in", "aspect_ratios", ":", "\n", "# s * s = w * h", "\n", "# a = h / w", "\n", "# ... some algebra ...", "\n", "# w = sqrt(s * s / a)", "\n", "# h = a * w", "\n", "                ", "w", "=", "math", ".", "sqrt", "(", "area", "/", "aspect_ratio", ")", "\n", "h", "=", "aspect_ratio", "*", "w", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "-", "w", "/", "2.0", ",", "-", "h", "/", "2.0", ",", "w", "/", "2.0", ",", "h", "/", "2.0", "\n", "anchors", ".", "append", "(", "[", "x0", ",", "y0", ",", "x1", ",", "y1", "]", ")", "\n", "", "", "return", "torch", ".", "tensor", "(", "anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.DefaultAnchorGenerator.forward": [[213, 227], ["anchor_generator.DefaultAnchorGenerator._grid_anchors", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors"], ["", "def", "forward", "(", "self", ",", "features", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features (list[Tensor]): list of backbone feature maps on which to generate anchors.\n\n        Returns:\n            list[Boxes]: a list of Boxes containing all the anchors for each feature map\n                (i.e. the cell anchors repeated over all locations in the feature map).\n                The number of anchors of each feature map is Hi x Wi x num_cell_anchors,\n                where Hi, Wi are resolution of the feature map divided by anchor stride.\n        \"\"\"", "\n", "grid_sizes", "=", "[", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "for", "feature_map", "in", "features", "]", "\n", "anchors_over_all_feature_maps", "=", "self", ".", "_grid_anchors", "(", "grid_sizes", ")", "\n", "return", "[", "Boxes", "(", "x", ")", "for", "x", "in", "anchors_over_all_feature_maps", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.__init__": [[241, 273], ["torch.nn.Module.__init__", "len", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator.RotatedAnchorGenerator._calculate_anchors"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", ",", "sizes", ",", "aspect_ratios", ",", "strides", ",", "angles", ",", "offset", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        This interface is experimental.\n\n        Args:\n            sizes (list[list[float]] or list[float]):\n                If sizes is list[list[float]], sizes[i] is the list of anchor sizes\n                (i.e. sqrt of anchor area) to use for the i-th feature map.\n                If sizes is list[float], the sizes are used for all feature maps.\n                Anchor sizes are given in absolute lengths in units of\n                the input image; they do not dynamically scale if the input image size changes.\n            aspect_ratios (list[list[float]] or list[float]): list of aspect ratios\n                (i.e. height / width) to use for anchors. Same \"broadcast\" rule for `sizes` applies.\n            strides (list[int]): stride of each input feature.\n            angles (list[list[float]] or list[float]): list of angles (in degrees CCW)\n                to use for anchors. Same \"broadcast\" rule for `sizes` applies.\n            offset (float): Relative offset between the center of the first anchor and the top-left\n                corner of the image. Value has to be in [0, 1).\n                Recommend to use 0.5, which means half stride.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "num_features", "=", "len", "(", "self", ".", "strides", ")", "\n", "sizes", "=", "_broadcast_params", "(", "sizes", ",", "self", ".", "num_features", ",", "\"sizes\"", ")", "\n", "aspect_ratios", "=", "_broadcast_params", "(", "aspect_ratios", ",", "self", ".", "num_features", ",", "\"aspect_ratios\"", ")", "\n", "angles", "=", "_broadcast_params", "(", "angles", ",", "self", ".", "num_features", ",", "\"angles\"", ")", "\n", "self", ".", "cell_anchors", "=", "self", ".", "_calculate_anchors", "(", "sizes", ",", "aspect_ratios", ",", "angles", ")", "\n", "\n", "self", ".", "offset", "=", "offset", "\n", "assert", "0.0", "<=", "self", ".", "offset", "<", "1.0", ",", "self", ".", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.from_config": [[274, 282], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "List", "[", "ShapeSpec", "]", ")", ":", "\n", "        ", "return", "{", "\n", "\"sizes\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", ",", "\n", "\"aspect_ratios\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "ASPECT_RATIOS", ",", "\n", "\"strides\"", ":", "[", "x", ".", "stride", "for", "x", "in", "input_shape", "]", ",", "\n", "\"offset\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "OFFSET", ",", "\n", "\"angles\"", ":", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "ANGLES", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors": [[284, 290], ["anchor_generator.BufferList", "anchor_generator.RotatedAnchorGenerator.generate_cell_anchors().float", "zip", "anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], ["", "def", "_calculate_anchors", "(", "self", ",", "sizes", ",", "aspect_ratios", ",", "angles", ")", ":", "\n", "        ", "cell_anchors", "=", "[", "\n", "self", ".", "generate_cell_anchors", "(", "size", ",", "aspect_ratio", ",", "angle", ")", ".", "float", "(", ")", "\n", "for", "size", ",", "aspect_ratio", ",", "angle", "in", "zip", "(", "sizes", ",", "aspect_ratios", ",", "angles", ")", "\n", "]", "\n", "return", "BufferList", "(", "cell_anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.num_cell_anchors": [[291, 297], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_cell_anchors", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Alias of `num_anchors`.\n        \"\"\"", "\n", "return", "self", ".", "num_anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.num_anchors": [[298, 312], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_anchors", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[int]: Each int is the number of anchors at every pixel\n                location, on that feature map.\n                For example, if at every pixel we use anchors of 3 aspect\n                ratios, 2 sizes and 5 angles, the number of anchors is 30.\n                (See also ANCHOR_GENERATOR.SIZES, ANCHOR_GENERATOR.ASPECT_RATIOS\n                and ANCHOR_GENERATOR.ANGLES in config)\n\n                In standard RRPN models, `num_anchors` on every feature map is the same.\n        \"\"\"", "\n", "return", "[", "len", "(", "cell_anchors", ")", "for", "cell_anchors", "in", "self", ".", "cell_anchors", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors": [[313, 323], ["zip", "anchor_generator._create_grid_offsets", "torch.zeros_like", "torch.stack", "anchors.append", "torch.stack.view", "base_anchors.view"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._create_grid_offsets"], ["", "def", "_grid_anchors", "(", "self", ",", "grid_sizes", ")", ":", "\n", "        ", "anchors", "=", "[", "]", "\n", "for", "size", ",", "stride", ",", "base_anchors", "in", "zip", "(", "grid_sizes", ",", "self", ".", "strides", ",", "self", ".", "cell_anchors", ")", ":", "\n", "            ", "shift_x", ",", "shift_y", "=", "_create_grid_offsets", "(", "size", ",", "stride", ",", "self", ".", "offset", ",", "base_anchors", ".", "device", ")", "\n", "zeros", "=", "torch", ".", "zeros_like", "(", "shift_x", ")", "\n", "shifts", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ",", "zeros", ",", "zeros", ",", "zeros", ")", ",", "dim", "=", "1", ")", "\n", "\n", "anchors", ".", "append", "(", "(", "shifts", ".", "view", "(", "-", "1", ",", "1", ",", "5", ")", "+", "base_anchors", ".", "view", "(", "1", ",", "-", "1", ",", "5", ")", ")", ".", "reshape", "(", "-", "1", ",", "5", ")", ")", "\n", "\n", "", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors": [[324, 359], ["torch.tensor", "math.sqrt", "anchors.extend"], "methods", ["None"], ["", "def", "generate_cell_anchors", "(", "\n", "self", ",", "\n", "sizes", "=", "(", "32", ",", "64", ",", "128", ",", "256", ",", "512", ")", ",", "\n", "aspect_ratios", "=", "(", "0.5", ",", "1", ",", "2", ")", ",", "\n", "angles", "=", "(", "-", "90", ",", "-", "60", ",", "-", "30", ",", "0", ",", "30", ",", "60", ",", "90", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Generate a tensor storing canonical anchor boxes, which are all anchor\n        boxes of different sizes, aspect_ratios, angles centered at (0, 0).\n        We can later build the set of anchors for a full feature map by\n        shifting and tiling these tensors (see `meth:_grid_anchors`).\n\n        Args:\n            sizes (tuple[float]):\n            aspect_ratios (tuple[float]]):\n            angles (tuple[float]]):\n\n        Returns:\n            Tensor of shape (len(sizes) * len(aspect_ratios) * len(angles), 5)\n                storing anchor boxes in (x_ctr, y_ctr, w, h, angle) format.\n        \"\"\"", "\n", "anchors", "=", "[", "]", "\n", "for", "size", "in", "sizes", ":", "\n", "            ", "area", "=", "size", "**", "2.0", "\n", "for", "aspect_ratio", "in", "aspect_ratios", ":", "\n", "# s * s = w * h", "\n", "# a = h / w", "\n", "# ... some algebra ...", "\n", "# w = sqrt(s * s / a)", "\n", "# h = a * w", "\n", "                ", "w", "=", "math", ".", "sqrt", "(", "area", "/", "aspect_ratio", ")", "\n", "h", "=", "aspect_ratio", "*", "w", "\n", "anchors", ".", "extend", "(", "[", "0", ",", "0", ",", "w", ",", "h", ",", "a", "]", "for", "a", "in", "angles", ")", "\n", "\n", "", "", "return", "torch", ".", "tensor", "(", "anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator.forward": [[360, 374], ["anchor_generator.RotatedAnchorGenerator._grid_anchors", "detectron2.structures.RotatedBoxes"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors"], ["", "def", "forward", "(", "self", ",", "features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features (list[Tensor]): list of backbone feature maps on which to generate anchors.\n\n        Returns:\n            list[RotatedBoxes]: a list of Boxes containing all the anchors for each feature map\n                (i.e. the cell anchors repeated over all locations in the feature map).\n                The number of anchors of each feature map is Hi x Wi x num_cell_anchors,\n                where Hi, Wi are resolution of the feature map divided by anchor stride.\n        \"\"\"", "\n", "grid_sizes", "=", "[", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "for", "feature_map", "in", "features", "]", "\n", "anchors_over_all_feature_maps", "=", "self", ".", "_grid_anchors", "(", "grid_sizes", ")", "\n", "return", "[", "RotatedBoxes", "(", "x", ")", "for", "x", "in", "anchors_over_all_feature_maps", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._create_grid_offsets": [[38, 51], ["torch.arange", "torch.arange", "torch.meshgrid", "shift_x.reshape.reshape", "shift_y.reshape.reshape"], "function", ["None"], ["", "", "def", "_create_grid_offsets", "(", "size", ":", "List", "[", "int", "]", ",", "stride", ":", "int", ",", "offset", ":", "float", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "    ", "grid_height", ",", "grid_width", "=", "size", "\n", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "offset", "*", "stride", ",", "grid_width", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "offset", "*", "stride", ",", "grid_height", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "return", "shift_x", ",", "shift_y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator._broadcast_params": [[53, 78], ["isinstance", "len", "isinstance", "len", "len", "list", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "_broadcast_params", "(", "params", ",", "num_features", ",", "name", ")", ":", "\n", "    ", "\"\"\"\n    If one size (or aspect ratio) is specified and there are multiple feature\n    maps, we \"broadcast\" anchors of that single size (or aspect ratio)\n    over all feature maps.\n\n    If params is list[float], or list[list[float]] with len(params) == 1, repeat\n    it num_features time.\n\n    Returns:\n        list[list[float]]: param for each feature\n    \"\"\"", "\n", "assert", "isinstance", "(", "\n", "params", ",", "collections", ".", "abc", ".", "Sequence", "\n", ")", ",", "f\"{name} in anchor generator has to be a list! Got {params}.\"", "\n", "assert", "len", "(", "params", ")", ",", "f\"{name} in anchor generator cannot be empty!\"", "\n", "if", "not", "isinstance", "(", "params", "[", "0", "]", ",", "collections", ".", "abc", ".", "Sequence", ")", ":", "# params is list[float]", "\n", "        ", "return", "[", "params", "]", "*", "num_features", "\n", "", "if", "len", "(", "params", ")", "==", "1", ":", "\n", "        ", "return", "list", "(", "params", ")", "*", "num_features", "\n", "", "assert", "len", "(", "params", ")", "==", "num_features", ",", "(", "\n", "f\"Got {name} of length {len(params)} in anchor generator, \"", "\n", "f\"but the number of input features is {num_features}!\"", "\n", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.build_anchor_generator": [[376, 382], ["ANCHOR_GENERATOR_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "build_anchor_generator", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Built an anchor generator from `cfg.MODEL.ANCHOR_GENERATOR.NAME`.\n    \"\"\"", "\n", "anchor_generator", "=", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "NAME", "\n", "return", "ANCHOR_GENERATOR_REGISTRY", ".", "get", "(", "anchor_generator", ")", "(", "cfg", ",", "input_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetBackbone.__init__": [[44, 104], ["backbone.Backbone.__init__", "isinstance", "isinstance", "logger.info", "mmdet_wrapper.MMDetBackbone.backbone.init_weights", "mmdet_wrapper.MMDetBackbone.backbone.train", "build_backbone", "build_neck", "logger.info", "isinstance", "mmdet_wrapper.MMDetBackbone.neck.train", "mmdet_wrapper._to_container", "mmdet_wrapper._to_container", "mmdet_wrapper.MMDetBackbone.neck.init_weights", "m.init_weights", "range", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.init_weights", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._to_container", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._to_container", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.init_weights", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "backbone", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", "]", ",", "\n", "neck", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", ",", "None", "]", "=", "None", ",", "\n", "*", ",", "\n", "pretrained_backbone", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "output_shapes", ":", "List", "[", "ShapeSpec", "]", ",", "\n", "output_names", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: either a backbone module or a mmdet config dict that defines a\n                backbone. The backbone takes a 4D image tensor and returns a\n                sequence of tensors.\n            neck: either a backbone module or a mmdet config dict that defines a\n                neck. The neck takes outputs of backbone and returns a\n                sequence of tensors. If None, no neck is used.\n            pretrained_backbone: defines the backbone weights that can be loaded by\n                mmdet, such as \"torchvision://resnet50\".\n            output_shapes: shape for every output of the backbone (or neck, if given).\n                stride and channels are often needed.\n            output_names: names for every output of the backbone (or neck, if given).\n                By default, will use \"out0\", \"out1\", ...\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "backbone", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_backbone", "\n", "\n", "backbone", "=", "build_backbone", "(", "_to_container", "(", "backbone", ")", ")", "\n", "", "self", ".", "backbone", "=", "backbone", "\n", "\n", "if", "isinstance", "(", "neck", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_neck", "\n", "\n", "neck", "=", "build_neck", "(", "_to_container", "(", "neck", ")", ")", "\n", "", "self", ".", "neck", "=", "neck", "\n", "\n", "# It's confusing that backbone weights are given as a separate argument,", "\n", "# but \"neck\" weights, if any, are part of neck itself. This is the interface", "\n", "# of mmdet so we follow it. Reference:", "\n", "# https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py", "\n", "logger", ".", "info", "(", "f\"Initializing mmdet backbone weights: {pretrained_backbone} ...\"", ")", "\n", "self", ".", "backbone", ".", "init_weights", "(", "pretrained_backbone", ")", "\n", "# train() in mmdet modules is non-trivial, and has to be explicitly", "\n", "# called. Reference:", "\n", "# https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/backbones/resnet.py", "\n", "self", ".", "backbone", ".", "train", "(", ")", "\n", "if", "self", ".", "neck", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Initializing mmdet neck weights ...\"", ")", "\n", "if", "isinstance", "(", "self", ".", "neck", ",", "nn", ".", "Sequential", ")", ":", "\n", "                ", "for", "m", "in", "self", ".", "neck", ":", "\n", "                    ", "m", ".", "init_weights", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "neck", ".", "init_weights", "(", ")", "\n", "", "self", ".", "neck", ".", "train", "(", ")", "\n", "\n", "", "self", ".", "_output_shapes", "=", "output_shapes", "\n", "if", "not", "output_names", ":", "\n", "            ", "output_names", "=", "[", "f\"out{i}\"", "for", "i", "in", "range", "(", "len", "(", "output_shapes", ")", ")", "]", "\n", "", "self", ".", "_output_names", "=", "output_names", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetBackbone.forward": [[105, 118], ["mmdet_wrapper.MMDetBackbone.backbone", "isinstance", "mmdet_wrapper.MMDetBackbone.neck", "len", "len", "ValueError", "zip", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Dict", "[", "str", ",", "Tensor", "]", ":", "\n", "        ", "outs", "=", "self", ".", "backbone", "(", "x", ")", "\n", "if", "self", ".", "neck", "is", "not", "None", ":", "\n", "            ", "outs", "=", "self", ".", "neck", "(", "outs", ")", "\n", "", "assert", "isinstance", "(", "\n", "outs", ",", "(", "list", ",", "tuple", ")", "\n", ")", ",", "\"mmdet backbone should return a list/tuple of tensors!\"", "\n", "if", "len", "(", "outs", ")", "!=", "len", "(", "self", ".", "_output_shapes", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Length of output_shapes does not match outputs from the mmdet backbone: \"", "\n", "f\"{len(outs)} != {len(self._output_shapes)}\"", "\n", ")", "\n", "", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_output_names", ",", "outs", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetBackbone.output_shape": [[119, 121], ["zip"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", "->", "Dict", "[", "str", ",", "ShapeSpec", "]", ":", "\n", "        ", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_output_names", ",", "self", ".", "_output_shapes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetDetector.__init__": [[130, 160], ["torch.nn.Module.__init__", "isinstance", "mmdet_wrapper.MMDetDetector.register_buffer", "mmdet_wrapper.MMDetDetector.register_buffer", "build_detector", "torch.tensor().view", "torch.tensor().view", "mmdet_wrapper._to_container", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._to_container"], ["def", "__init__", "(", "\n", "self", ",", "\n", "detector", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", "]", ",", "\n", "*", ",", "\n", "# Default is 32 regardless of model:", "\n", "# https://github.com/open-mmlab/mmdetection/tree/master/configs/_base_/datasets", "\n", "size_divisibility", "=", "32", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            detector: a mmdet detector, or a mmdet config dict that defines a detector.\n            size_divisibility: pad input images to multiple of this number\n            pixel_mean: per-channel mean to normalize input image\n            pixel_std: per-channel stddev to normalize input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "detector", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_detector", "\n", "\n", "detector", "=", "build_detector", "(", "_to_container", "(", "detector", ")", ")", "\n", "", "self", ".", "detector", "=", "detector", "\n", "self", ".", "size_divisibility", "=", "size_divisibility", "\n", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "assert", "(", "\n", "self", ".", "pixel_mean", ".", "shape", "==", "self", ".", "pixel_std", ".", "shape", "\n", ")", ",", "f\"{self.pixel_mean} and {self.pixel_std} have different shapes!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetDetector.forward": [[161, 219], ["x[].to", "detectron2.structures.ImageList.from_tensors", "len", "ValueError", "list", "metas.append", "gt_instances[].has", "mmdet_wrapper.MMDetDetector.detector.forward_train", "mmdet_wrapper._parse_losses", "mmdet_wrapper.MMDetDetector.detector.simple_test", "numpy.sqrt", "output_shapes.append", "output_shapes.append", "x[].to", "isinstance", "mmdet_wrapper.MMDetDetector.forward.convert_mask"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._parse_losses", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "size_divisibility", "=", "self", ".", "size_divisibility", ")", ".", "tensor", "\n", "metas", "=", "[", "]", "\n", "rescale", "=", "{", "\"height\"", "in", "x", "for", "x", "in", "batched_inputs", "}", "\n", "if", "len", "(", "rescale", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Some inputs have original height/width, but some don't!\"", ")", "\n", "", "rescale", "=", "list", "(", "rescale", ")", "[", "0", "]", "\n", "output_shapes", "=", "[", "]", "\n", "for", "input", "in", "batched_inputs", ":", "\n", "            ", "meta", "=", "{", "}", "\n", "c", ",", "h", ",", "w", "=", "input", "[", "\"image\"", "]", ".", "shape", "\n", "meta", "[", "\"img_shape\"", "]", "=", "meta", "[", "\"ori_shape\"", "]", "=", "(", "h", ",", "w", ",", "c", ")", "\n", "if", "rescale", ":", "\n", "                ", "scale_factor", "=", "np", ".", "sqrt", "(", "h", "*", "w", "/", "(", "input", "[", "\"height\"", "]", "*", "input", "[", "\"width\"", "]", ")", ")", "\n", "ori_shape", "=", "(", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "output_shapes", ".", "append", "(", "ori_shape", ")", "\n", "meta", "[", "\"ori_shape\"", "]", "=", "ori_shape", "+", "(", "c", ",", ")", "\n", "", "else", ":", "\n", "                ", "scale_factor", "=", "1.0", "\n", "output_shapes", ".", "append", "(", "(", "h", ",", "w", ")", ")", "\n", "", "meta", "[", "\"scale_factor\"", "]", "=", "scale_factor", "\n", "meta", "[", "\"flip\"", "]", "=", "False", "\n", "padh", ",", "padw", "=", "images", ".", "shape", "[", "-", "2", ":", "]", "\n", "meta", "[", "\"pad_shape\"", "]", "=", "(", "padh", ",", "padw", ",", "c", ")", "\n", "metas", ".", "append", "(", "meta", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "if", "gt_instances", "[", "0", "]", ".", "has", "(", "\"gt_masks\"", ")", ":", "\n", "                ", "from", "mmdet", ".", "core", "import", "PolygonMasks", "as", "mm_PolygonMasks", ",", "BitmapMasks", "as", "mm_BitMasks", "\n", "\n", "def", "convert_mask", "(", "m", ",", "shape", ")", ":", "\n", "# mmdet mask format", "\n", "                    ", "if", "isinstance", "(", "m", ",", "BitMasks", ")", ":", "\n", "                        ", "return", "mm_BitMasks", "(", "m", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "return", "mm_PolygonMasks", "(", "m", ".", "polygons", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "\n", "", "", "gt_masks", "=", "[", "convert_mask", "(", "x", ".", "gt_masks", ",", "x", ".", "image_size", ")", "for", "x", "in", "gt_instances", "]", "\n", "", "else", ":", "\n", "                ", "gt_masks", "=", "None", "\n", "", "losses_and_metrics", "=", "self", ".", "detector", ".", "forward_train", "(", "\n", "images", ",", "\n", "metas", ",", "\n", "[", "x", ".", "gt_boxes", ".", "tensor", "for", "x", "in", "gt_instances", "]", ",", "\n", "[", "x", ".", "gt_classes", "for", "x", "in", "gt_instances", "]", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", ")", "\n", "return", "_parse_losses", "(", "losses_and_metrics", ")", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "detector", ".", "simple_test", "(", "images", ",", "metas", ",", "rescale", "=", "rescale", ")", "\n", "results", "=", "[", "\n", "{", "\"instances\"", ":", "_convert_mmdet_result", "(", "r", ",", "shape", ")", "}", "\n", "for", "r", ",", "shape", "in", "zip", "(", "results", ",", "output_shapes", ")", "\n", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper.MMDetDetector.device": [[220, 223], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._to_container": [[22, 32], ["isinstance", "ConfigDict", "omegaconf.OmegaConf.to_container"], "function", ["None"], ["def", "_to_container", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    mmdet will assert the type of dict/list.\n    So convert omegaconf objects to dict/list.\n    \"\"\"", "\n", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "", "from", "mmcv", ".", "utils", "import", "ConfigDict", "\n", "\n", "return", "ConfigDict", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._convert_mmdet_result": [[227, 252], ["isinstance", "torch.from_numpy", "torch.cat", "detectron2.structures.Instances", "detectron2.structures.Boxes", "isinstance", "numpy.vstack", "torch.full", "list", "torch.stack", "enumerate", "len", "itertools.chain", "isinstance", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "_convert_mmdet_result", "(", "result", ",", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "Instances", ":", "\n", "    ", "if", "isinstance", "(", "result", ",", "tuple", ")", ":", "\n", "        ", "bbox_result", ",", "segm_result", "=", "result", "\n", "if", "isinstance", "(", "segm_result", ",", "tuple", ")", ":", "\n", "            ", "segm_result", "=", "segm_result", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "bbox_result", ",", "segm_result", "=", "result", ",", "None", "\n", "\n", "", "bboxes", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "bbox_result", ")", ")", "# Nx5", "\n", "bboxes", ",", "scores", "=", "bboxes", "[", ":", ",", ":", "4", "]", ",", "bboxes", "[", ":", ",", "-", "1", "]", "\n", "labels", "=", "[", "\n", "torch", ".", "full", "(", "(", "bbox", ".", "shape", "[", "0", "]", ",", ")", ",", "i", ",", "dtype", "=", "torch", ".", "int32", ")", "for", "i", ",", "bbox", "in", "enumerate", "(", "bbox_result", ")", "\n", "]", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ")", "\n", "inst", "=", "Instances", "(", "shape", ")", "\n", "inst", ".", "pred_boxes", "=", "Boxes", "(", "bboxes", ")", "\n", "inst", ".", "scores", "=", "scores", "\n", "inst", ".", "pred_classes", "=", "labels", "\n", "\n", "if", "segm_result", "is", "not", "None", "and", "len", "(", "labels", ")", ">", "0", ":", "\n", "        ", "segm_result", "=", "list", "(", "itertools", ".", "chain", "(", "*", "segm_result", ")", ")", "\n", "segm_result", "=", "[", "torch", ".", "from_numpy", "(", "x", ")", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", "else", "x", "for", "x", "in", "segm_result", "]", "\n", "segm_result", "=", "torch", ".", "stack", "(", "segm_result", ",", "dim", "=", "0", ")", "\n", "inst", ".", "pred_masks", "=", "segm_result", "\n", "", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.mmdet_wrapper._parse_losses": [[255, 271], ["collections.OrderedDict", "losses.items", "isinstance", "loss_value.mean", "isinstance", "detectron2.utils.events.get_event_storage", "collections.OrderedDict.pop().cpu().item", "detectron2.utils.events.get_event_storage.put_scalar", "sum", "TypeError", "collections.OrderedDict.pop().cpu", "_loss.mean", "collections.OrderedDict.pop"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar"], ["", "def", "_parse_losses", "(", "losses", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "Tensor", "]", ":", "\n", "    ", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "            ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f\"{loss_name} is not a tensor or list of tensors\"", ")", "\n", "\n", "", "if", "\"loss\"", "not", "in", "loss_name", ":", "\n", "# put metrics to storage; don't return them", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "value", "=", "log_vars", ".", "pop", "(", "loss_name", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "storage", ".", "put_scalar", "(", "loss_name", ",", "value", ")", "\n", "", "", "return", "log_vars", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.DatasetMapperTTA.__init__": [[38, 49], ["None"], "methods", ["None"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "min_sizes", ":", "List", "[", "int", "]", ",", "max_size", ":", "int", ",", "flip", ":", "bool", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            min_sizes: list of short-edge size to resize the image to\n            max_size: maximum height or width of resized images\n            flip: whether to apply flipping augmentation\n        \"\"\"", "\n", "self", ".", "min_sizes", "=", "min_sizes", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "flip", "=", "flip", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.DatasetMapperTTA.from_config": [[50, 56], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "{", "\n", "\"min_sizes\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "MIN_SIZES", ",", "\n", "\"max_size\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "MAX_SIZE", ",", "\n", "\"flip\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "FLIP", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.DatasetMapperTTA.__call__": [[58, 99], ["dataset_dict[].permute().numpy", "detectron2.data.transforms.ResizeTransform", "fvcore.transforms.NoOpTransform", "detectron2.data.transforms.ResizeShortestEdge", "aug_candidates.append", "detectron2.data.transforms.apply_augmentations", "torch.from_numpy", "copy.deepcopy", "ret.append", "dataset_dict[].permute", "detectron2.data.transforms.RandomFlip", "aug_candidates.append", "numpy.copy", "numpy.ascontiguousarray", "new_image.transpose"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.apply_augmentations"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dict: a dict in standard model input format. See tutorials for details.\n\n        Returns:\n            list[dict]:\n                a list of dicts, which contain augmented version of the input image.\n                The total number of dicts is ``len(min_sizes) * (2 if flip else 1)``.\n                Each dict has field \"transforms\" which is a TransformList,\n                containing the transforms that are used to generate this image.\n        \"\"\"", "\n", "numpy_image", "=", "dataset_dict", "[", "\"image\"", "]", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "shape", "=", "numpy_image", ".", "shape", "\n", "orig_shape", "=", "(", "dataset_dict", "[", "\"height\"", "]", ",", "dataset_dict", "[", "\"width\"", "]", ")", "\n", "if", "shape", "[", ":", "2", "]", "!=", "orig_shape", ":", "\n", "# It transforms the \"original\" image in the dataset to the input image", "\n", "            ", "pre_tfm", "=", "ResizeTransform", "(", "orig_shape", "[", "0", "]", ",", "orig_shape", "[", "1", "]", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "pre_tfm", "=", "NoOpTransform", "(", ")", "\n", "\n", "# Create all combinations of augmentations to use", "\n", "", "aug_candidates", "=", "[", "]", "# each element is a list[Augmentation]", "\n", "for", "min_size", "in", "self", ".", "min_sizes", ":", "\n", "            ", "resize", "=", "ResizeShortestEdge", "(", "min_size", ",", "self", ".", "max_size", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", "]", ")", "# resize only", "\n", "if", "self", ".", "flip", ":", "\n", "                ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "flip", "]", ")", "# resize + flip", "\n", "\n", "# Apply all the augmentations", "\n", "", "", "ret", "=", "[", "]", "\n", "for", "aug", "in", "aug_candidates", ":", "\n", "            ", "new_image", ",", "tfms", "=", "apply_augmentations", "(", "aug", ",", "np", ".", "copy", "(", "numpy_image", ")", ")", "\n", "torch_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "new_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "\n", "dic", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "\n", "dic", "[", "\"transforms\"", "]", "=", "pre_tfm", "+", "tfms", "\n", "dic", "[", "\"image\"", "]", "=", "torch_image", "\n", "ret", ".", "append", "(", "dic", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA.__init__": [[107, 135], ["torch.nn.Module.__init__", "isinstance", "isinstance", "cfg.clone", "type", "test_time_augmentation.DatasetMapperTTA"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["def", "__init__", "(", "self", ",", "cfg", ",", "model", ",", "tta_mapper", "=", "None", ",", "batch_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            model (GeneralizedRCNN): a GeneralizedRCNN to apply TTA on.\n            tta_mapper (callable): takes a dataset dict and returns a list of\n                augmented versions of the dataset dict. Defaults to\n                `DatasetMapperTTA(cfg)`.\n            batch_size (int): batch the augmented images into this batch size for inference.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "assert", "isinstance", "(", "\n", "model", ",", "GeneralizedRCNN", "\n", ")", ",", "\"TTA is only supported on GeneralizedRCNN. Got a model of type {}\"", ".", "format", "(", "type", "(", "model", ")", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "not", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\"TTA for keypoint is not supported yet\"", "\n", "assert", "(", "\n", "not", "self", ".", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", ")", ",", "\"TTA for pre-computed proposals is not supported yet\"", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "if", "tta_mapper", "is", "None", ":", "\n", "            ", "tta_mapper", "=", "DatasetMapperTTA", "(", "cfg", ")", "\n", "", "self", ".", "tta_mapper", "=", "tta_mapper", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads": [[136, 161], ["len", "old.keys", "old.keys", "getattr", "old.keys", "setattr", "setattr"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "_turn_off_roi_heads", "(", "self", ",", "attrs", ")", ":", "\n", "        ", "\"\"\"\n        Open a context where some heads in `model.roi_heads` are temporarily turned off.\n        Args:\n            attr (list[str]): the attribute in `model.roi_heads` which can be used\n                to turn off a specific head, e.g., \"mask_on\", \"keypoint_on\".\n        \"\"\"", "\n", "roi_heads", "=", "self", ".", "model", ".", "roi_heads", "\n", "old", "=", "{", "}", "\n", "for", "attr", "in", "attrs", ":", "\n", "            ", "try", ":", "\n", "                ", "old", "[", "attr", "]", "=", "getattr", "(", "roi_heads", ",", "attr", ")", "\n", "", "except", "AttributeError", ":", "\n", "# The head may not be implemented in certain ROIHeads", "\n", "                ", "pass", "\n", "\n", "", "", "if", "len", "(", "old", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "            ", "yield", "\n", "", "else", ":", "\n", "            ", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "False", ")", "\n", "", "yield", "\n", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "old", "[", "attr", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference": [[162, 187], ["zip", "itertools.count", "inputs.append", "instances.append", "len", "outputs.extend", "len", "test_time_augmentation.GeneralizedRCNNWithTTA.model.inference", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference"], ["", "", "", "def", "_batch_inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Execute inference on a list of inputs,\n        using batch size = self.batch_size, instead of the length of the list.\n\n        Inputs & outputs have the same format as :meth:`GeneralizedRCNN.inference`\n        \"\"\"", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "detected_instances", "=", "[", "None", "]", "*", "len", "(", "batched_inputs", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "input", ",", "instance", "in", "zip", "(", "count", "(", ")", ",", "batched_inputs", ",", "detected_instances", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "input", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "if", "len", "(", "inputs", ")", "==", "self", ".", "batch_size", "or", "idx", "==", "len", "(", "batched_inputs", ")", "-", "1", ":", "\n", "                ", "outputs", ".", "extend", "(", "\n", "self", ".", "model", ".", "inference", "(", "\n", "inputs", ",", "\n", "instances", "if", "instances", "[", "0", "]", "is", "not", "None", "else", "None", ",", "\n", "do_postprocess", "=", "False", ",", "\n", ")", "\n", ")", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA.__call__": [[188, 205], ["copy.copy", "test_time_augmentation.GeneralizedRCNNWithTTA._inference_one_image", "detectron2.data.detection_utils.read_image", "torch.from_numpy", "test_time_augmentation.GeneralizedRCNNWithTTA.__call__._maybe_read_image"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._inference_one_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image"], ["", "def", "__call__", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Same input/output format as :meth:`GeneralizedRCNN.forward`\n        \"\"\"", "\n", "\n", "def", "_maybe_read_image", "(", "dataset_dict", ")", ":", "\n", "            ", "ret", "=", "copy", ".", "copy", "(", "dataset_dict", ")", "\n", "if", "\"image\"", "not", "in", "ret", ":", "\n", "                ", "image", "=", "read_image", "(", "ret", ".", "pop", "(", "\"file_name\"", ")", ",", "self", ".", "model", ".", "input_format", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "# CHW", "\n", "ret", "[", "\"image\"", "]", "=", "image", "\n", "", "if", "\"height\"", "not", "in", "ret", "and", "\"width\"", "not", "in", "ret", ":", "\n", "                ", "ret", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "ret", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "2", "]", "\n", "", "return", "ret", "\n", "\n", "", "return", "[", "self", ".", "_inference_one_image", "(", "_maybe_read_image", "(", "x", ")", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._inference_one_image": [[206, 238], ["test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs", "test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections", "test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads", "test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_boxes", "test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes", "test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks", "postprocessing.detector_postprocess"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess"], ["", "def", "_inference_one_image", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (dict): one dataset dict with \"image\" field being a CHW tensor\n\n        Returns:\n            dict: one output dict\n        \"\"\"", "\n", "orig_shape", "=", "(", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "augmented_inputs", ",", "tfms", "=", "self", ".", "_get_augmented_inputs", "(", "input", ")", "\n", "# Detect boxes from all augmented versions", "\n", "with", "self", ".", "_turn_off_roi_heads", "(", "[", "\"mask_on\"", ",", "\"keypoint_on\"", "]", ")", ":", "\n", "# temporarily disable roi heads", "\n", "            ", "all_boxes", ",", "all_scores", ",", "all_classes", "=", "self", ".", "_get_augmented_boxes", "(", "augmented_inputs", ",", "tfms", ")", "\n", "# merge all detected boxes to obtain final predictions for boxes", "\n", "", "merged_instances", "=", "self", ".", "_merge_detections", "(", "all_boxes", ",", "all_scores", ",", "all_classes", ",", "orig_shape", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "# Use the detected boxes to obtain masks", "\n", "            ", "augmented_instances", "=", "self", ".", "_rescale_detected_boxes", "(", "\n", "augmented_inputs", ",", "merged_instances", ",", "tfms", "\n", ")", "\n", "# run forward on the detected boxes", "\n", "outputs", "=", "self", ".", "_batch_inference", "(", "augmented_inputs", ",", "augmented_instances", ")", "\n", "# Delete now useless variables to avoid being out of memory", "\n", "del", "augmented_inputs", ",", "augmented_instances", "\n", "# average the predictions", "\n", "merged_instances", ".", "pred_masks", "=", "self", ".", "_reduce_pred_masks", "(", "outputs", ",", "tfms", ")", "\n", "merged_instances", "=", "detector_postprocess", "(", "merged_instances", ",", "*", "orig_shape", ")", "\n", "return", "{", "\"instances\"", ":", "merged_instances", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"instances\"", ":", "merged_instances", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs": [[239, 243], ["test_time_augmentation.GeneralizedRCNNWithTTA.tta_mapper", "x.pop"], "methods", ["None"], ["", "", "def", "_get_augmented_inputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "augmented_inputs", "=", "self", ".", "tta_mapper", "(", "input", ")", "\n", "tfms", "=", "[", "x", ".", "pop", "(", "\"transforms\"", ")", "for", "x", "in", "augmented_inputs", "]", "\n", "return", "augmented_inputs", ",", "tfms", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_boxes": [[244, 261], ["test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "zip", "torch.cat", "tfm.inverse().apply_box", "torch.cat.append", "all_scores.extend", "all_classes.extend", "pred_boxes.cpu().numpy", "torch.from_numpy().to", "tfm.inverse", "pred_boxes.cpu", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.inverse"], ["", "def", "_get_augmented_boxes", "(", "self", ",", "augmented_inputs", ",", "tfms", ")", ":", "\n", "# 1: forward with all augmented images", "\n", "        ", "outputs", "=", "self", ".", "_batch_inference", "(", "augmented_inputs", ")", "\n", "# 2: union the results", "\n", "all_boxes", "=", "[", "]", "\n", "all_scores", "=", "[", "]", "\n", "all_classes", "=", "[", "]", "\n", "for", "output", ",", "tfm", "in", "zip", "(", "outputs", ",", "tfms", ")", ":", "\n", "# Need to inverse the transforms on boxes, to obtain results on original image", "\n", "            ", "pred_boxes", "=", "output", ".", "pred_boxes", ".", "tensor", "\n", "original_pred_boxes", "=", "tfm", ".", "inverse", "(", ")", ".", "apply_box", "(", "pred_boxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "all_boxes", ".", "append", "(", "torch", ".", "from_numpy", "(", "original_pred_boxes", ")", ".", "to", "(", "pred_boxes", ".", "device", ")", ")", "\n", "\n", "all_scores", ".", "extend", "(", "output", ".", "scores", ")", "\n", "all_classes", ".", "extend", "(", "output", ".", "pred_classes", ")", "\n", "", "all_boxes", "=", "torch", ".", "cat", "(", "all_boxes", ",", "dim", "=", "0", ")", "\n", "return", "all_boxes", ",", "all_scores", ",", "all_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections": [[262, 281], ["len", "torch.zeros", "zip", "roi_heads.fast_rcnn.fast_rcnn_inference_single_image", "itertools.count"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference_single_image"], ["", "def", "_merge_detections", "(", "self", ",", "all_boxes", ",", "all_scores", ",", "all_classes", ",", "shape_hw", ")", ":", "\n", "# select from the union of all results", "\n", "        ", "num_boxes", "=", "len", "(", "all_boxes", ")", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "\n", "# +1 because fast_rcnn_inference expects background scores as well", "\n", "all_scores_2d", "=", "torch", ".", "zeros", "(", "num_boxes", ",", "num_classes", "+", "1", ",", "device", "=", "all_boxes", ".", "device", ")", "\n", "for", "idx", ",", "cls", ",", "score", "in", "zip", "(", "count", "(", ")", ",", "all_classes", ",", "all_scores", ")", ":", "\n", "            ", "all_scores_2d", "[", "idx", ",", "cls", "]", "=", "score", "\n", "\n", "", "merged_instances", ",", "_", "=", "fast_rcnn_inference_single_image", "(", "\n", "all_boxes", ",", "\n", "all_scores_2d", ",", "\n", "shape_hw", ",", "\n", "1e-8", ",", "\n", "self", ".", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NMS_THRESH_TEST", ",", "\n", "self", ".", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", ",", "\n", ")", "\n", "\n", "return", "merged_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes": [[282, 297], ["zip", "merged_instances.pred_boxes.tensor.cpu().numpy", "torch.from_numpy", "detectron2.structures.Instances", "augmented_instances.append", "tfm.apply_box", "merged_instances.pred_boxes.tensor.cpu", "detectron2.structures.Boxes"], "methods", ["None"], ["", "def", "_rescale_detected_boxes", "(", "self", ",", "augmented_inputs", ",", "merged_instances", ",", "tfms", ")", ":", "\n", "        ", "augmented_instances", "=", "[", "]", "\n", "for", "input", ",", "tfm", "in", "zip", "(", "augmented_inputs", ",", "tfms", ")", ":", "\n", "# Transform the target box to the augmented image's coordinate space", "\n", "            ", "pred_boxes", "=", "merged_instances", ".", "pred_boxes", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_boxes", "=", "torch", ".", "from_numpy", "(", "tfm", ".", "apply_box", "(", "pred_boxes", ")", ")", "\n", "\n", "aug_instances", "=", "Instances", "(", "\n", "image_size", "=", "input", "[", "\"image\"", "]", ".", "shape", "[", "1", ":", "3", "]", ",", "\n", "pred_boxes", "=", "Boxes", "(", "pred_boxes", ")", ",", "\n", "pred_classes", "=", "merged_instances", ".", "pred_classes", ",", "\n", "scores", "=", "merged_instances", ".", "scores", ",", "\n", ")", "\n", "augmented_instances", ".", "append", "(", "aug_instances", ")", "\n", "", "return", "augmented_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks": [[298, 308], ["zip", "torch.stack", "torch.mean", "any", "output.pred_masks.flip", "isinstance"], "methods", ["None"], ["", "def", "_reduce_pred_masks", "(", "self", ",", "outputs", ",", "tfms", ")", ":", "\n", "# Should apply inverse transforms on masks.", "\n", "# We assume only resize & flip are used. pred_masks is a scale-invariant", "\n", "# representation, so we handle flip specially", "\n", "        ", "for", "output", ",", "tfm", "in", "zip", "(", "outputs", ",", "tfms", ")", ":", "\n", "            ", "if", "any", "(", "isinstance", "(", "t", ",", "HFlipTransform", ")", "for", "t", "in", "tfm", ".", "transforms", ")", ":", "\n", "                ", "output", ".", "pred_masks", "=", "output", ".", "pred_masks", ".", "flip", "(", "dims", "=", "[", "3", "]", ")", "\n", "", "", "all_pred_masks", "=", "torch", ".", "stack", "(", "[", "o", ".", "pred_masks", "for", "o", "in", "outputs", "]", ",", "dim", "=", "0", ")", "\n", "avg_pred_masks", "=", "torch", ".", "mean", "(", "all_pred_masks", ",", "dim", "=", "0", ")", "\n", "return", "avg_pred_masks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.ROIPooler.__init__": [[104, 189], ["torch.nn.Module.__init__", "isinstance", "int", "int", "len", "isinstance", "isinstance", "torch.nn.ModuleList", "math.log2", "math.log2", "math.isclose", "math.isclose", "len", "torch.nn.ModuleList", "int", "int", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "ValueError", "torchvision.ops.RoIPool", "detectron2.layers.ROIAlignRotated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "output_size", ",", "\n", "scales", ",", "\n", "sampling_ratio", ",", "\n", "pooler_type", ",", "\n", "canonical_box_size", "=", "224", ",", "\n", "canonical_level", "=", "4", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (int, tuple[int] or list[int]): output size of the pooled region,\n                e.g., 14 x 14. If tuple or list is given, the length must be 2.\n            scales (list[float]): The scale for each low-level pooling op relative to\n                the input image. For a feature map with stride s relative to the input\n                image, scale is defined as 1/s. The stride must be power of 2.\n                When there are multiple scales, they must form a pyramid, i.e. they must be\n                a monotically decreasing geometric sequence with a factor of 1/2.\n            sampling_ratio (int): The `sampling_ratio` parameter for the ROIAlign op.\n            pooler_type (string): Name of the type of pooling operation that should be applied.\n                For instance, \"ROIPool\" or \"ROIAlignV2\".\n            canonical_box_size (int): A canonical box size in pixels (sqrt(box area)). The default\n                is heuristically defined as 224 pixels in the FPN paper (based on ImageNet\n                pre-training).\n            canonical_level (int): The feature map level index from which a canonically-sized box\n                should be placed. The default is defined as level 4 (stride=16) in the FPN paper,\n                i.e., a box of size 224x224 will be placed on the feature with stride=16.\n                The box placement for all boxes will be determined from their sizes w.r.t\n                canonical_box_size. For example, a box whose area is 4x that of a canonical box\n                should be used to pool features from feature level ``canonical_level+1``.\n\n                Note that the actual input feature maps given to this module may not have\n                sufficiently many levels for the input boxes. If the boxes are too large or too\n                small for the input feature maps, the closest level will be used.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "output_size", ",", "int", ")", ":", "\n", "            ", "output_size", "=", "(", "output_size", ",", "output_size", ")", "\n", "", "assert", "len", "(", "output_size", ")", "==", "2", "\n", "assert", "isinstance", "(", "output_size", "[", "0", "]", ",", "int", ")", "and", "isinstance", "(", "output_size", "[", "1", "]", ",", "int", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "\n", "if", "pooler_type", "==", "\"ROIAlign\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlign", "(", "\n", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ",", "aligned", "=", "False", "\n", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIAlignV2\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlign", "(", "\n", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ",", "aligned", "=", "True", "\n", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIPool\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "RoIPool", "(", "output_size", ",", "spatial_scale", "=", "scale", ")", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIAlignRotated\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlignRotated", "(", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown pooler type: {}\"", ".", "format", "(", "pooler_type", ")", ")", "\n", "\n", "# Map scale (defined as 1 / stride) to its feature map level under the", "\n", "# assumption that stride is a power of 2.", "\n", "", "min_level", "=", "-", "(", "math", ".", "log2", "(", "scales", "[", "0", "]", ")", ")", "\n", "max_level", "=", "-", "(", "math", ".", "log2", "(", "scales", "[", "-", "1", "]", ")", ")", "\n", "assert", "math", ".", "isclose", "(", "min_level", ",", "int", "(", "min_level", ")", ")", "and", "math", ".", "isclose", "(", "\n", "max_level", ",", "int", "(", "max_level", ")", "\n", ")", ",", "\"Featuremap stride is not power of 2!\"", "\n", "self", ".", "min_level", "=", "int", "(", "min_level", ")", "\n", "self", ".", "max_level", "=", "int", "(", "max_level", ")", "\n", "assert", "(", "\n", "len", "(", "scales", ")", "==", "self", ".", "max_level", "-", "self", ".", "min_level", "+", "1", "\n", ")", ",", "\"[ROIPooler] Sizes of input featuremaps do not form a pyramid!\"", "\n", "assert", "0", "<=", "self", ".", "min_level", "and", "self", ".", "min_level", "<=", "self", ".", "max_level", "\n", "self", ".", "canonical_level", "=", "canonical_level", "\n", "assert", "canonical_box_size", ">", "0", "\n", "self", ".", "canonical_box_size", "=", "canonical_box_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.ROIPooler.forward": [[190, 251], ["len", "poolers.convert_boxes_to_pooler_format", "poolers.assign_boxes_to_levels", "convert_boxes_to_pooler_format.size", "torch.zeros", "enumerate", "isinstance", "isinstance", "len", "len", "len", "x[].size", "x[].size", "len", "len", "torch.zeros", "torch.zeros.index_put_", "detectron2.layers.nonzero_tuple", "pooler"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.convert_boxes_to_pooler_format", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.assign_boxes_to_levels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple"], ["", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "box_lists", ":", "List", "[", "Boxes", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (list[Tensor]): A list of feature maps of NCHW shape, with scales matching those\n                used to construct this module.\n            box_lists (list[Boxes] | list[RotatedBoxes]):\n                A list of N Boxes or N RotatedBoxes, where N is the number of images in the batch.\n                The box coordinates are defined on the original image and\n                will be scaled by the `scales` argument of :class:`ROIPooler`.\n\n        Returns:\n            Tensor:\n                A tensor of shape (M, C, output_size, output_size) where M is the total number of\n                boxes aggregated over all N batch images and C is the number of channels in `x`.\n        \"\"\"", "\n", "num_level_assignments", "=", "len", "(", "self", ".", "level_poolers", ")", "\n", "\n", "assert", "isinstance", "(", "x", ",", "list", ")", "and", "isinstance", "(", "\n", "box_lists", ",", "list", "\n", ")", ",", "\"Arguments to pooler must be lists\"", "\n", "assert", "(", "\n", "len", "(", "x", ")", "==", "num_level_assignments", "\n", ")", ",", "\"unequal value, num_level_assignments={}, but x is list of {} Tensors\"", ".", "format", "(", "\n", "num_level_assignments", ",", "len", "(", "x", ")", "\n", ")", "\n", "\n", "assert", "len", "(", "box_lists", ")", "==", "x", "[", "0", "]", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"unequal value, x[0] batch dim 0 is {}, but box_list has length {}\"", ".", "format", "(", "\n", "x", "[", "0", "]", ".", "size", "(", "0", ")", ",", "len", "(", "box_lists", ")", "\n", ")", "\n", "if", "len", "(", "box_lists", ")", "==", "0", ":", "\n", "            ", "return", "torch", ".", "zeros", "(", "\n", "(", "0", ",", "x", "[", "0", "]", ".", "shape", "[", "1", "]", ")", "+", "self", ".", "output_size", ",", "device", "=", "x", "[", "0", "]", ".", "device", ",", "dtype", "=", "x", "[", "0", "]", ".", "dtype", "\n", ")", "\n", "\n", "", "pooler_fmt_boxes", "=", "convert_boxes_to_pooler_format", "(", "box_lists", ")", "\n", "\n", "if", "num_level_assignments", "==", "1", ":", "\n", "            ", "return", "self", ".", "level_poolers", "[", "0", "]", "(", "x", "[", "0", "]", ",", "pooler_fmt_boxes", ")", "\n", "\n", "", "level_assignments", "=", "assign_boxes_to_levels", "(", "\n", "box_lists", ",", "self", ".", "min_level", ",", "self", ".", "max_level", ",", "self", ".", "canonical_box_size", ",", "self", ".", "canonical_level", "\n", ")", "\n", "\n", "num_boxes", "=", "pooler_fmt_boxes", ".", "size", "(", "0", ")", "\n", "num_channels", "=", "x", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "output_size", "=", "self", ".", "output_size", "[", "0", "]", "\n", "\n", "dtype", ",", "device", "=", "x", "[", "0", "]", ".", "dtype", ",", "x", "[", "0", "]", ".", "device", "\n", "output", "=", "torch", ".", "zeros", "(", "\n", "(", "num_boxes", ",", "num_channels", ",", "output_size", ",", "output_size", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", "\n", ")", "\n", "\n", "for", "level", ",", "pooler", "in", "enumerate", "(", "self", ".", "level_poolers", ")", ":", "\n", "            ", "inds", "=", "nonzero_tuple", "(", "level_assignments", "==", "level", ")", "[", "0", "]", "\n", "pooler_fmt_boxes_level", "=", "pooler_fmt_boxes", "[", "inds", "]", "\n", "# Use index_put_ instead of advance indexing, to avoid pytorch/issues/49852", "\n", "output", ".", "index_put_", "(", "(", "inds", ",", ")", ",", "pooler", "(", "x", "[", "level", "]", ",", "pooler_fmt_boxes_level", ")", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.assign_boxes_to_levels": [[22, 59], ["torch.sqrt", "torch.floor", "torch.clamp", "detectron2.layers.cat", "torch.clamp.to", "torch.log2", "boxes.area"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area"], ["def", "assign_boxes_to_levels", "(", "\n", "box_lists", ":", "List", "[", "Boxes", "]", ",", "\n", "min_level", ":", "int", ",", "\n", "max_level", ":", "int", ",", "\n", "canonical_box_size", ":", "int", ",", "\n", "canonical_level", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Map each box in `box_lists` to a feature map level index and return the assignment\n    vector.\n\n    Args:\n        box_lists (list[Boxes] | list[RotatedBoxes]): A list of N Boxes or N RotatedBoxes,\n            where N is the number of images in the batch.\n        min_level (int): Smallest feature map level index. The input is considered index 0,\n            the output of stage 1 is index 1, and so.\n        max_level (int): Largest feature map level index.\n        canonical_box_size (int): A canonical box size in pixels (sqrt(box area)).\n        canonical_level (int): The feature map level index on which a canonically-sized box\n            should be placed.\n\n    Returns:\n        A tensor of length M, where M is the total number of boxes aggregated over all\n            N batch images. The memory layout corresponds to the concatenation of boxes\n            from all images. Each element is the feature map index, as an offset from\n            `self.min_level`, for the corresponding box (so value i means the box is at\n            `self.min_level + i`).\n    \"\"\"", "\n", "box_sizes", "=", "torch", ".", "sqrt", "(", "cat", "(", "[", "boxes", ".", "area", "(", ")", "for", "boxes", "in", "box_lists", "]", ")", ")", "\n", "# Eqn.(1) in FPN paper", "\n", "level_assignments", "=", "torch", ".", "floor", "(", "\n", "canonical_level", "+", "torch", ".", "log2", "(", "box_sizes", "/", "canonical_box_size", "+", "1e-8", ")", "\n", ")", "\n", "# clamp level to (min, max), in case the box size is too large or too small", "\n", "# for the available feature maps", "\n", "level_assignments", "=", "torch", ".", "clamp", "(", "level_assignments", ",", "min", "=", "min_level", ",", "max", "=", "max_level", ")", "\n", "return", "level_assignments", ".", "to", "(", "torch", ".", "int64", ")", "-", "min_level", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers._fmt_box_list": [[61, 66], ["torch.full_like", "detectron2.layers.cat"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "_fmt_box_list", "(", "box_tensor", ",", "batch_index", ":", "int", ")", ":", "\n", "    ", "repeated_index", "=", "torch", ".", "full_like", "(", "\n", "box_tensor", "[", ":", ",", ":", "1", "]", ",", "batch_index", ",", "dtype", "=", "box_tensor", ".", "dtype", ",", "device", "=", "box_tensor", ".", "device", "\n", ")", "\n", "return", "cat", "(", "(", "repeated_index", ",", "box_tensor", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.convert_boxes_to_pooler_format": [[68, 96], ["detectron2.layers.cat", "poolers._fmt_box_list", "enumerate"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers._fmt_box_list"], ["", "def", "convert_boxes_to_pooler_format", "(", "box_lists", ":", "List", "[", "Boxes", "]", ")", ":", "\n", "    ", "\"\"\"\n    Convert all boxes in `box_lists` to the low-level format used by ROI pooling ops\n    (see description under Returns).\n\n    Args:\n        box_lists (list[Boxes] | list[RotatedBoxes]):\n            A list of N Boxes or N RotatedBoxes, where N is the number of images in the batch.\n\n    Returns:\n        When input is list[Boxes]:\n            A tensor of shape (M, 5), where M is the total number of boxes aggregated over all\n            N batch images.\n            The 5 columns are (batch index, x0, y0, x1, y1), where batch index\n            is the index in [0, N) identifying which batch image the box with corners at\n            (x0, y0, x1, y1) comes from.\n        When input is list[RotatedBoxes]:\n            A tensor of shape (M, 6), where M is the total number of boxes aggregated over all\n            N batch images.\n            The 6 columns are (batch index, x_ctr, y_ctr, width, height, angle_degrees),\n            where batch index is the index in [0, N) identifying which batch image the\n            rotated box (x_ctr, y_ctr, width, height, angle_degrees) comes from.\n    \"\"\"", "\n", "pooler_fmt_boxes", "=", "cat", "(", "\n", "[", "_fmt_box_list", "(", "box_list", ".", "tensor", ",", "i", ")", "for", "i", ",", "box_list", "in", "enumerate", "(", "box_lists", ")", "]", ",", "dim", "=", "0", "\n", ")", "\n", "\n", "return", "pooler_fmt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransform.__init__": [[27, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "weights", ":", "Tuple", "[", "float", ",", "float", ",", "float", ",", "float", "]", ",", "scale_clamp", ":", "float", "=", "_DEFAULT_SCALE_CLAMP", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            weights (4-element tuple): Scaling factors that are applied to the\n                (dx, dy, dw, dh) deltas. In Fast R-CNN, these were originally set\n                such that the deltas have unit variance; now they are treated as\n                hyperparameters of the system.\n            scale_clamp (float): When predicting deltas, the predicted box scaling\n                factors (dw and dh) are clamped such that they are <= scale_clamp.\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "scale_clamp", "=", "scale_clamp", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransform.get_deltas": [[42, 76], ["isinstance", "type", "isinstance", "type", "torch.stack", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "get_deltas", "(", "self", ",", "src_boxes", ",", "target_boxes", ")", ":", "\n", "        ", "\"\"\"\n        Get box regression transformation deltas (dx, dy, dw, dh) that can be used\n        to transform the `src_boxes` into the `target_boxes`. That is, the relation\n        ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless\n        any delta is too large and is clamped).\n\n        Args:\n            src_boxes (Tensor): source boxes, e.g., object proposals\n            target_boxes (Tensor): target of the transformation, e.g., ground-truth\n                boxes.\n        \"\"\"", "\n", "assert", "isinstance", "(", "src_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "src_boxes", ")", "\n", "assert", "isinstance", "(", "target_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "target_boxes", ")", "\n", "\n", "src_widths", "=", "src_boxes", "[", ":", ",", "2", "]", "-", "src_boxes", "[", ":", ",", "0", "]", "\n", "src_heights", "=", "src_boxes", "[", ":", ",", "3", "]", "-", "src_boxes", "[", ":", ",", "1", "]", "\n", "src_ctr_x", "=", "src_boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "src_widths", "\n", "src_ctr_y", "=", "src_boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "src_heights", "\n", "\n", "target_widths", "=", "target_boxes", "[", ":", ",", "2", "]", "-", "target_boxes", "[", ":", ",", "0", "]", "\n", "target_heights", "=", "target_boxes", "[", ":", ",", "3", "]", "-", "target_boxes", "[", ":", ",", "1", "]", "\n", "target_ctr_x", "=", "target_boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "target_widths", "\n", "target_ctr_y", "=", "target_boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "target_heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "dx", "=", "wx", "*", "(", "target_ctr_x", "-", "src_ctr_x", ")", "/", "src_widths", "\n", "dy", "=", "wy", "*", "(", "target_ctr_y", "-", "src_ctr_y", ")", "/", "src_heights", "\n", "dw", "=", "ww", "*", "torch", ".", "log", "(", "target_widths", "/", "src_widths", ")", "\n", "dh", "=", "wh", "*", "torch", ".", "log", "(", "target_heights", "/", "src_heights", ")", "\n", "\n", "deltas", "=", "torch", ".", "stack", "(", "(", "dx", ",", "dy", ",", "dw", ",", "dh", ")", ",", "dim", "=", "1", ")", "\n", "assert", "(", "src_widths", ">", "0", ")", ".", "all", "(", ")", ".", "item", "(", ")", ",", "\"Input boxes to Box2BoxTransform are not valid!\"", "\n", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransform.apply_deltas": [[77, 116], ["deltas.float.float.float", "boxes.to.to.to", "torch.clamp", "torch.clamp", "torch.stack", "torch.stack.reshape", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "apply_deltas", "(", "self", ",", "deltas", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"", "\n", "deltas", "=", "deltas", ".", "float", "(", ")", "# ensure fp32 for decoding precision", "\n", "boxes", "=", "boxes", ".", "to", "(", "deltas", ".", "dtype", ")", "\n", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "widths", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "dx", "=", "deltas", "[", ":", ",", "0", ":", ":", "4", "]", "/", "wx", "\n", "dy", "=", "deltas", "[", ":", ",", "1", ":", ":", "4", "]", "/", "wy", "\n", "dw", "=", "deltas", "[", ":", ",", "2", ":", ":", "4", "]", "/", "ww", "\n", "dh", "=", "deltas", "[", ":", ",", "3", ":", ":", "4", "]", "/", "wh", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "\n", "pred_ctr_x", "=", "dx", "*", "widths", "[", ":", ",", "None", "]", "+", "ctr_x", "[", ":", ",", "None", "]", "\n", "pred_ctr_y", "=", "dy", "*", "heights", "[", ":", ",", "None", "]", "+", "ctr_y", "[", ":", ",", "None", "]", "\n", "pred_w", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "[", ":", ",", "None", "]", "\n", "pred_h", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "[", ":", ",", "None", "]", "\n", "\n", "x1", "=", "pred_ctr_x", "-", "0.5", "*", "pred_w", "\n", "y1", "=", "pred_ctr_y", "-", "0.5", "*", "pred_h", "\n", "x2", "=", "pred_ctr_x", "+", "0.5", "*", "pred_w", "\n", "y2", "=", "pred_ctr_y", "+", "0.5", "*", "pred_h", "\n", "pred_boxes", "=", "torch", ".", "stack", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "pred_boxes", ".", "reshape", "(", "deltas", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.__init__": [[128, 143], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "weights", ":", "Tuple", "[", "float", ",", "float", ",", "float", ",", "float", ",", "float", "]", ",", "\n", "scale_clamp", ":", "float", "=", "_DEFAULT_SCALE_CLAMP", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            weights (5-element tuple): Scaling factors that are applied to the\n                (dx, dy, dw, dh, da) deltas. These are treated as\n                hyperparameters of the system.\n            scale_clamp (float): When predicting deltas, the predicted box scaling\n                factors (dw and dh) are clamped such that they are <= scale_clamp.\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "scale_clamp", "=", "scale_clamp", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.get_deltas": [[144, 181], ["isinstance", "type", "isinstance", "type", "torch.unbind", "torch.unbind", "torch.stack", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "get_deltas", "(", "self", ",", "src_boxes", ",", "target_boxes", ")", ":", "\n", "        ", "\"\"\"\n        Get box regression transformation deltas (dx, dy, dw, dh, da) that can be used\n        to transform the `src_boxes` into the `target_boxes`. That is, the relation\n        ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless\n        any delta is too large and is clamped).\n\n        Args:\n            src_boxes (Tensor): Nx5 source boxes, e.g., object proposals\n            target_boxes (Tensor): Nx5 target of the transformation, e.g., ground-truth\n                boxes.\n        \"\"\"", "\n", "assert", "isinstance", "(", "src_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "src_boxes", ")", "\n", "assert", "isinstance", "(", "target_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "target_boxes", ")", "\n", "\n", "src_ctr_x", ",", "src_ctr_y", ",", "src_widths", ",", "src_heights", ",", "src_angles", "=", "torch", ".", "unbind", "(", "src_boxes", ",", "dim", "=", "1", ")", "\n", "\n", "target_ctr_x", ",", "target_ctr_y", ",", "target_widths", ",", "target_heights", ",", "target_angles", "=", "torch", ".", "unbind", "(", "\n", "target_boxes", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", ",", "wa", "=", "self", ".", "weights", "\n", "dx", "=", "wx", "*", "(", "target_ctr_x", "-", "src_ctr_x", ")", "/", "src_widths", "\n", "dy", "=", "wy", "*", "(", "target_ctr_y", "-", "src_ctr_y", ")", "/", "src_heights", "\n", "dw", "=", "ww", "*", "torch", ".", "log", "(", "target_widths", "/", "src_widths", ")", "\n", "dh", "=", "wh", "*", "torch", ".", "log", "(", "target_heights", "/", "src_heights", ")", "\n", "# Angles of deltas are in radians while angles of boxes are in degrees.", "\n", "# the conversion to radians serve as a way to normalize the values", "\n", "da", "=", "target_angles", "-", "src_angles", "\n", "da", "=", "(", "da", "+", "180.0", ")", "%", "360.0", "-", "180.0", "# make it in [-180, 180)", "\n", "da", "*=", "wa", "*", "math", ".", "pi", "/", "180.0", "\n", "\n", "deltas", "=", "torch", ".", "stack", "(", "(", "dx", ",", "dy", ",", "dw", ",", "dh", ",", "da", ")", ",", "dim", "=", "1", ")", "\n", "assert", "(", "\n", "(", "src_widths", ">", "0", ")", ".", "all", "(", ")", ".", "item", "(", ")", "\n", ")", ",", "\"Input boxes to Box2BoxTransformRotated are not valid!\"", "\n", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.apply_deltas": [[182, 227], ["boxes.to().unsqueeze.to().unsqueeze.to().unsqueeze", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.exp", "torch.exp", "boxes.to().unsqueeze.to().unsqueeze.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "apply_deltas", "(", "self", ",", "deltas", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh, da) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*5).\n                deltas[i] represents box transformation for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 5)\n        \"\"\"", "\n", "assert", "deltas", ".", "shape", "[", "1", "]", "%", "5", "==", "0", "and", "boxes", ".", "shape", "[", "1", "]", "==", "5", "\n", "\n", "boxes", "=", "boxes", ".", "to", "(", "deltas", ".", "dtype", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "\n", "angles", "=", "boxes", "[", ":", ",", "4", "]", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", ",", "wa", "=", "self", ".", "weights", "\n", "\n", "dx", "=", "deltas", "[", ":", ",", "0", ":", ":", "5", "]", "/", "wx", "\n", "dy", "=", "deltas", "[", ":", ",", "1", ":", ":", "5", "]", "/", "wy", "\n", "dw", "=", "deltas", "[", ":", ",", "2", ":", ":", "5", "]", "/", "ww", "\n", "dh", "=", "deltas", "[", ":", ",", "3", ":", ":", "5", "]", "/", "wh", "\n", "da", "=", "deltas", "[", ":", ",", "4", ":", ":", "5", "]", "/", "wa", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "\n", "pred_boxes", "=", "torch", ".", "zeros_like", "(", "deltas", ")", "\n", "pred_boxes", "[", ":", ",", "0", ":", ":", "5", "]", "=", "dx", "*", "widths", "+", "ctr_x", "# x_ctr", "\n", "pred_boxes", "[", ":", ",", "1", ":", ":", "5", "]", "=", "dy", "*", "heights", "+", "ctr_y", "# y_ctr", "\n", "pred_boxes", "[", ":", ",", "2", ":", ":", "5", "]", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "# width", "\n", "pred_boxes", "[", ":", ",", "3", ":", ":", "5", "]", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "# height", "\n", "\n", "# Following original RRPN implementation,", "\n", "# angles of deltas are in radians while angles of boxes are in degrees.", "\n", "pred_angle", "=", "da", "*", "180.0", "/", "math", ".", "pi", "+", "angles", "\n", "pred_angle", "=", "(", "pred_angle", "+", "180.0", ")", "%", "360.0", "-", "180.0", "# make it in [-180, 180)", "\n", "\n", "pred_boxes", "[", ":", ",", "4", ":", ":", "5", "]", "=", "pred_angle", "\n", "\n", "return", "pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression._dense_box_regression_loss": [[229, 271], ["type().cat", "torch.stack", "fvcore.nn.smooth_l1_loss", "box2box_transform.get_deltas", "fvcore.nn.giou_loss", "ValueError", "type", "detectron2.layers.cat", "box2box_transform.apply_deltas", "detectron2.layers.cat", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "", "def", "_dense_box_regression_loss", "(", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "box2box_transform", ":", "Box2BoxTransform", ",", "\n", "pred_anchor_deltas", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "gt_boxes", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "fg_mask", ":", "torch", ".", "Tensor", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Compute loss for dense multi-level box regression.\n    Loss is accumulated over ``fg_mask``.\n\n    Args:\n        anchors: #lvl anchor boxes, each is (HixWixA, 4)\n        pred_anchor_deltas: #lvl predictions, each is (N, HixWixA, 4)\n        gt_boxes: N ground truth boxes, each has shape (R, 4) (R = sum(Hi * Wi * A))\n        fg_mask: the foreground boolean mask of shape (N, R) to compute loss on\n        box_reg_loss_type (str): Loss type to use. Supported losses: \"smooth_l1\", \"giou\".\n        smooth_l1_beta (float): beta parameter for the smooth L1 regression loss. Default to\n            use L1 loss. Only used when `box_reg_loss_type` is \"smooth_l1\"\n    \"\"\"", "\n", "anchors", "=", "type", "(", "anchors", "[", "0", "]", ")", ".", "cat", "(", "anchors", ")", ".", "tensor", "# (R, 4)", "\n", "if", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "        ", "gt_anchor_deltas", "=", "[", "box2box_transform", ".", "get_deltas", "(", "anchors", ",", "k", ")", "for", "k", "in", "gt_boxes", "]", "\n", "gt_anchor_deltas", "=", "torch", ".", "stack", "(", "gt_anchor_deltas", ")", "# (N, R, 4)", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "cat", "(", "pred_anchor_deltas", ",", "dim", "=", "1", ")", "[", "fg_mask", "]", ",", "\n", "gt_anchor_deltas", "[", "fg_mask", "]", ",", "\n", "beta", "=", "smooth_l1_beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "elif", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "        ", "pred_boxes", "=", "[", "\n", "box2box_transform", ".", "apply_deltas", "(", "k", ",", "anchors", ")", "for", "k", "in", "cat", "(", "pred_anchor_deltas", ",", "dim", "=", "1", ")", "\n", "]", "\n", "loss_box_reg", "=", "giou_loss", "(", "\n", "torch", ".", "stack", "(", "pred_boxes", ")", "[", "fg_mask", "]", ",", "torch", ".", "stack", "(", "gt_boxes", ")", "[", "fg_mask", "]", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid dense box regression loss type '{box_reg_loss_type}'\"", ")", "\n", "", "return", "loss_box_reg", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.sampling.subsample_labels": [[9, 55], ["int", "min", "min", "detectron2.layers.nonzero_tuple", "detectron2.layers.nonzero_tuple", "positive.numel", "negative.numel", "torch.randperm", "torch.randperm", "positive.numel", "negative.numel"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple"], ["def", "subsample_labels", "(", "\n", "labels", ":", "torch", ".", "Tensor", ",", "num_samples", ":", "int", ",", "positive_fraction", ":", "float", ",", "bg_label", ":", "int", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Return `num_samples` (or fewer, if not enough found)\n    random samples from `labels` which is a mixture of positives & negatives.\n    It will try to return as many positives as possible without\n    exceeding `positive_fraction * num_samples`, and then try to\n    fill the remaining slots with negatives.\n\n    Args:\n        labels (Tensor): (N, ) label vector with values:\n            * -1: ignore\n            * bg_label: background (\"negative\") class\n            * otherwise: one or more foreground (\"positive\") classes\n        num_samples (int): The total number of labels with value >= 0 to return.\n            Values that are not sampled will be filled with -1 (ignore).\n        positive_fraction (float): The number of subsampled labels with values > 0\n            is `min(num_positives, int(positive_fraction * num_samples))`. The number\n            of negatives sampled is `min(num_negatives, num_samples - num_positives_sampled)`.\n            In order words, if there are not enough positives, the sample is filled with\n            negatives. If there are also not enough negatives, then as many elements are\n            sampled as is possible.\n        bg_label (int): label index of background (\"negative\") class.\n\n    Returns:\n        pos_idx, neg_idx (Tensor):\n            1D vector of indices. The total length of both is `num_samples` or fewer.\n    \"\"\"", "\n", "positive", "=", "nonzero_tuple", "(", "(", "labels", "!=", "-", "1", ")", "&", "(", "labels", "!=", "bg_label", ")", ")", "[", "0", "]", "\n", "negative", "=", "nonzero_tuple", "(", "labels", "==", "bg_label", ")", "[", "0", "]", "\n", "\n", "num_pos", "=", "int", "(", "num_samples", "*", "positive_fraction", ")", "\n", "# protect against not enough positive examples", "\n", "num_pos", "=", "min", "(", "positive", ".", "numel", "(", ")", ",", "num_pos", ")", "\n", "num_neg", "=", "num_samples", "-", "num_pos", "\n", "# protect against not enough negative examples", "\n", "num_neg", "=", "min", "(", "negative", ".", "numel", "(", ")", ",", "num_neg", ")", "\n", "\n", "# randomly select positive and negative examples", "\n", "perm1", "=", "torch", ".", "randperm", "(", "positive", ".", "numel", "(", ")", ",", "device", "=", "positive", ".", "device", ")", "[", ":", "num_pos", "]", "\n", "perm2", "=", "torch", ".", "randperm", "(", "negative", ".", "numel", "(", ")", ",", "device", "=", "negative", ".", "device", ")", "[", ":", "num_neg", "]", "\n", "\n", "pos_idx", "=", "positive", "[", "perm1", "]", "\n", "neg_idx", "=", "negative", "[", "perm2", "]", "\n", "return", "pos_idx", ",", "neg_idx", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.__init__": [[32, 69], ["torch.nn.Module.__init__", "rcnn.GeneralizedRCNN.register_buffer", "rcnn.GeneralizedRCNN.register_buffer", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "proposal_generator", ":", "nn", ".", "Module", ",", "\n", "roi_heads", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", "input_format", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "vis_period", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            proposal_generator: a module that generates proposals using backbone features\n            roi_heads: a ROI head that performs per-region computation\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n            input_format: describe the meaning of channels of input. Needed by visualization\n            vis_period: the period to run visualization. Set to 0 to disable.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "proposal_generator", "=", "proposal_generator", "\n", "self", ".", "roi_heads", "=", "roi_heads", "\n", "\n", "self", ".", "input_format", "=", "input_format", "\n", "self", ".", "vis_period", "=", "vis_period", "\n", "if", "vis_period", ">", "0", ":", "\n", "            ", "assert", "input_format", "is", "not", "None", ",", "\"input_format is required for visualization!\"", "\n", "\n", "", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "assert", "(", "\n", "self", ".", "pixel_mean", ".", "shape", "==", "self", ".", "pixel_std", ".", "shape", "\n", ")", ",", "f\"{self.pixel_mean} and {self.pixel_std} have different shapes!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.from_config": [[70, 81], ["backbone.build_backbone.build_backbone", "proposal_generator.build_proposal_generator", "roi_heads.build_roi_heads", "backbone.build_backbone.build_backbone.output_shape", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.build.build_proposal_generator", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.build_roi_heads", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"proposal_generator\"", ":", "build_proposal_generator", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"roi_heads\"", ":", "build_roi_heads", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"input_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"vis_period\"", ":", "cfg", ".", "VIS_PERIOD", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.device": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.visualize_training": [[87, 121], ["detectron2.utils.events.get_event_storage", "zip", "detectron2.data.detection_utils.convert_image_to_rgb", "Visualizer", "v_gt.overlay_instances.overlay_instances.overlay_instances", "v_gt.overlay_instances.overlay_instances.get_image", "min", "Visualizer", "v_pred.overlay_instances.overlay_instances.overlay_instances", "v_pred.overlay_instances.overlay_instances.get_image", "numpy.concatenate", "vis_img.transpose.transpose.transpose", "detectron2.utils.events.get_event_storage.put_image", "detectron2.data.detection_utils.convert_image_to_rgb.permute", "len", "prop.proposal_boxes[].tensor.cpu().numpy", "prop.proposal_boxes[].tensor.cpu"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.convert_image_to_rgb", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_image"], ["", "def", "visualize_training", "(", "self", ",", "batched_inputs", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        A function used to visualize images and proposals. It shows ground truth\n        bounding boxes on the original image and up to 20 top-scoring predicted\n        object proposals on the original image. Users can implement different\n        visualization functions for different models.\n\n        Args:\n            batched_inputs (list): a list that contains input to the model.\n            proposals (list): a list that contains predicted proposals. Both\n                batched_inputs and proposals should have the same length.\n        \"\"\"", "\n", "from", "detectron2", ".", "utils", ".", "visualizer", "import", "Visualizer", "\n", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "max_vis_prop", "=", "20", "\n", "\n", "for", "input", ",", "prop", "in", "zip", "(", "batched_inputs", ",", "proposals", ")", ":", "\n", "            ", "img", "=", "input", "[", "\"image\"", "]", "\n", "img", "=", "convert_image_to_rgb", "(", "img", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "self", ".", "input_format", ")", "\n", "v_gt", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_gt", "=", "v_gt", ".", "overlay_instances", "(", "boxes", "=", "input", "[", "\"instances\"", "]", ".", "gt_boxes", ")", "\n", "anno_img", "=", "v_gt", ".", "get_image", "(", ")", "\n", "box_size", "=", "min", "(", "len", "(", "prop", ".", "proposal_boxes", ")", ",", "max_vis_prop", ")", "\n", "v_pred", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_pred", "=", "v_pred", ".", "overlay_instances", "(", "\n", "boxes", "=", "prop", ".", "proposal_boxes", "[", "0", ":", "box_size", "]", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "prop_img", "=", "v_pred", ".", "get_image", "(", ")", "\n", "vis_img", "=", "np", ".", "concatenate", "(", "(", "anno_img", ",", "prop_img", ")", ",", "axis", "=", "1", ")", "\n", "vis_img", "=", "vis_img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "vis_name", "=", "\"Left: GT bounding boxes;  Right: Predicted proposals\"", "\n", "storage", ".", "put_image", "(", "vis_name", ",", "vis_img", ")", "\n", "break", "# only visualize one image in a batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.forward": [[122, 173], ["rcnn.GeneralizedRCNN.preprocess_image", "rcnn.GeneralizedRCNN.backbone", "rcnn.GeneralizedRCNN.roi_heads", "losses.update", "losses.update", "rcnn.GeneralizedRCNN.inference", "rcnn.GeneralizedRCNN.proposal_generator", "detectron2.utils.events.get_event_storage", "x[].to", "x[].to", "rcnn.GeneralizedRCNN.visualize_training"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.visualize_training"], ["", "", "def", "forward", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n\n                * image: Tensor, image in (C, H, W) format.\n                * instances (optional): groundtruth :class:`Instances`\n                * proposals (optional): :class:`Instances`, precomputed proposals.\n\n                Other information that's included in the original dicts, such as:\n\n                * \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n\n        Returns:\n            list[dict]:\n                Each dict is the output for one input image.\n                The dict contains one key \"instances\" whose value is a :class:`Instances`.\n                The :class:`Instances` object has the following keys:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "            ", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "", "else", ":", "\n", "            ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "proposal_losses", "=", "{", "}", "\n", "\n", "", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "gt_instances", ")", "\n", "if", "self", ".", "vis_period", ">", "0", ":", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "if", "storage", ".", "iter", "%", "self", ".", "vis_period", "==", "0", ":", "\n", "                ", "self", ".", "visualize_training", "(", "batched_inputs", ",", "proposals", ")", "\n", "\n", "", "", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.inference": [[174, 219], ["rcnn.GeneralizedRCNN.preprocess_image", "rcnn.GeneralizedRCNN.backbone", "rcnn.GeneralizedRCNN.roi_heads", "rcnn.GeneralizedRCNN.roi_heads.forward_with_given_boxes", "rcnn.GeneralizedRCNN._postprocess", "rcnn.GeneralizedRCNN.proposal_generator", "x.to", "torch.jit.is_scripting", "x[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN._postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "inference", "(", "\n", "self", ",", "\n", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "detected_instances", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", "do_postprocess", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, same as in :meth:`forward`.\n            Otherwise, a list[Instances] containing raw network outputs.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "                ", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "results", ",", "_", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "detected_instances", "=", "[", "x", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "detected_instances", "]", "\n", "results", "=", "self", ".", "roi_heads", ".", "forward_with_given_boxes", "(", "features", ",", "detected_instances", ")", "\n", "\n", "", "if", "do_postprocess", ":", "\n", "            ", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ",", "\"Scripting is not supported for postprocess.\"", "\n", "return", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", "\n", "", "else", ":", "\n", "            ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN.preprocess_image": [[220, 228], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN._postprocess": [[229, 244], ["zip", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess"], ["", "@", "staticmethod", "\n", "def", "_postprocess", "(", "instances", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Rescale the output instances to the target size.\n        \"\"\"", "\n", "# note: private function; subject to changes", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "instances", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.ProposalNetwork.__init__": [[252, 273], ["torch.nn.Module.__init__", "rcnn.ProposalNetwork.register_buffer", "rcnn.ProposalNetwork.register_buffer", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "proposal_generator", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            proposal_generator: a module that generates proposals using backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "proposal_generator", "=", "proposal_generator", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.ProposalNetwork.from_config": [[274, 282], ["backbone.build_backbone.build_backbone", "proposal_generator.build_proposal_generator", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.build.build_proposal_generator", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"proposal_generator\"", ":", "build_proposal_generator", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.ProposalNetwork.device": [[284, 287], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.ProposalNetwork.forward": [[288, 328], ["detectron2.structures.ImageList.from_tensors", "rcnn.ProposalNetwork.backbone", "rcnn.ProposalNetwork.proposal_generator", "zip", "x[].to", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append", "x[].to", "detectron2.utils.logger.log_first_n", "x[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_first_n", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            Same as in :class:`GeneralizedRCNN.forward`\n\n        Returns:\n            list[dict]:\n                Each dict is the output for one input image.\n                The dict contains one key \"proposals\" whose value is a\n                :class:`Instances` with keys \"proposal_boxes\" and \"objectness_logits\".\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "elif", "\"targets\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "log_first_n", "(", "\n", "logging", ".", "WARN", ",", "\"'targets' in the model inputs is now renamed to 'instances'!\"", ",", "n", "=", "10", "\n", ")", "\n", "gt_instances", "=", "[", "x", "[", "\"targets\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "# In training, the proposals are not useful at all but we generate them anyway.", "\n", "# This makes RPN-only models about 5% slower.", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "proposal_losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "proposals", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"proposals\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.__init__": [[48, 156], ["torch.nn.Module.__init__", "retinanet.RetinaNet.register_buffer", "retinanet.RetinaNet.register_buffer", "len", "len", "logger.warning", "torch.tensor().view", "torch.tensor().view", "retinanet.RetinaNet.backbone.output_shape", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "head", ":", "nn", ".", "Module", ",", "\n", "head_in_features", ",", "\n", "anchor_generator", ",", "\n", "box2box_transform", ",", "\n", "anchor_matcher", ",", "\n", "num_classes", ",", "\n", "focal_loss_alpha", "=", "0.25", ",", "\n", "focal_loss_gamma", "=", "2.0", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", "test_score_thresh", "=", "0.05", ",", "\n", "test_topk_candidates", "=", "1000", ",", "\n", "test_nms_thresh", "=", "0.5", ",", "\n", "max_detections_per_image", "=", "100", ",", "\n", "pixel_mean", ",", "\n", "pixel_std", ",", "\n", "vis_period", "=", "0", ",", "\n", "input_format", "=", "\"BGR\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            head (nn.Module): a module that predicts logits and regression deltas\n                for each level from a list of per-level features\n            head_in_features (Tuple[str]): Names of the input feature maps to be used in head\n            anchor_generator (nn.Module): a module that creates anchors from a\n                list of features. Usually an instance of :class:`AnchorGenerator`\n            box2box_transform (Box2BoxTransform): defines the transform from anchors boxes to\n                instance boxes\n            anchor_matcher (Matcher): label the anchors by matching them with ground truth.\n            num_classes (int): number of classes. Used to label background proposals.\n\n            # Loss parameters:\n            focal_loss_alpha (float): focal_loss_alpha\n            focal_loss_gamma (float): focal_loss_gamma\n            smooth_l1_beta (float): smooth_l1_beta\n            box_reg_loss_type (str): Options are \"smooth_l1\", \"giou\"\n\n            # Inference parameters:\n            test_score_thresh (float): Inference cls score threshold, only anchors with\n                score > INFERENCE_TH are considered for inference (to improve speed)\n            test_topk_candidates (int): Select topk candidates before NMS\n            test_nms_thresh (float): Overlap threshold used for non-maximum suppression\n                (suppress boxes with IoU >= this threshold)\n            max_detections_per_image (int):\n                Maximum number of detections to return per image during inference\n                (100 is based on the limit established for the COCO dataset).\n\n            # Input parameters\n            pixel_mean (Tuple[float]):\n                Values to be used for image normalization (BGR order).\n                To train on images of different number of channels, set different mean & std.\n                Default values are the mean pixel value from ImageNet: [103.53, 116.28, 123.675]\n            pixel_std (Tuple[float]):\n                When using pre-trained models in Detectron1 or any MSRA models,\n                std has been absorbed into its conv1 weights, so the std needs to be set 1.\n                Otherwise, you can use [57.375, 57.120, 58.395] (ImageNet std)\n            vis_period (int):\n                The period (in terms of steps) for minibatch visualization at train time.\n                Set to 0 to disable.\n            input_format (str): Whether the model needs RGB, YUV, HSV etc.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "head_in_features", "=", "head_in_features", "\n", "if", "len", "(", "self", ".", "backbone", ".", "output_shape", "(", ")", ")", "!=", "len", "(", "self", ".", "head_in_features", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"[RetinaNet] Backbone produces unused features.\"", ")", "\n", "\n", "# Anchors", "\n", "", "self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "anchor_matcher", "=", "anchor_matcher", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "# Loss parameters:", "\n", "self", ".", "focal_loss_alpha", "=", "focal_loss_alpha", "\n", "self", ".", "focal_loss_gamma", "=", "focal_loss_gamma", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "# Inference parameters:", "\n", "self", ".", "test_score_thresh", "=", "test_score_thresh", "\n", "self", ".", "test_topk_candidates", "=", "test_topk_candidates", "\n", "self", ".", "test_nms_thresh", "=", "test_nms_thresh", "\n", "self", ".", "max_detections_per_image", "=", "max_detections_per_image", "\n", "# Vis parameters", "\n", "self", ".", "vis_period", "=", "vis_period", "\n", "self", ".", "input_format", "=", "input_format", "\n", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n", "\"\"\"\n        In Detectron1, loss is normalized by number of foreground samples in the batch.\n        When batch size is 1 per GPU, #foreground has a large variance and\n        using it lead to lower performance. Here we maintain an EMA of #foreground to\n        stabilize the normalizer.\n        \"\"\"", "\n", "self", ".", "loss_normalizer", "=", "100", "# initialize with any reasonable #fg that's not too small", "\n", "self", ".", "loss_normalizer_momentum", "=", "0.9", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.from_config": [[157, 191], ["backbone.build_backbone.build_backbone", "backbone.build_backbone.build_backbone.output_shape", "retinanet.RetinaNetHead", "anchor_generator.build_anchor_generator.build_anchor_generator", "box_regression.Box2BoxTransform", "matcher.Matcher"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.build_anchor_generator"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "backbone_shape", "=", "backbone", ".", "output_shape", "(", ")", "\n", "feature_shapes", "=", "[", "backbone_shape", "[", "f", "]", "for", "f", "in", "cfg", ".", "MODEL", ".", "RETINANET", ".", "IN_FEATURES", "]", "\n", "head", "=", "RetinaNetHead", "(", "cfg", ",", "feature_shapes", ")", "\n", "anchor_generator", "=", "build_anchor_generator", "(", "cfg", ",", "feature_shapes", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"head\"", ":", "head", ",", "\n", "\"anchor_generator\"", ":", "anchor_generator", ",", "\n", "\"box2box_transform\"", ":", "Box2BoxTransform", "(", "weights", "=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_WEIGHTS", ")", ",", "\n", "\"anchor_matcher\"", ":", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "IOU_THRESHOLDS", ",", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "IOU_LABELS", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", ",", "\n", "\"head_in_features\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "IN_FEATURES", ",", "\n", "# Loss parameters:", "\n", "\"focal_loss_alpha\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "FOCAL_LOSS_ALPHA", ",", "\n", "\"focal_loss_gamma\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "FOCAL_LOSS_GAMMA", ",", "\n", "\"smooth_l1_beta\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "SMOOTH_L1_LOSS_BETA", ",", "\n", "\"box_reg_loss_type\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_LOSS_TYPE", ",", "\n", "# Inference parameters:", "\n", "\"test_score_thresh\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "SCORE_THRESH_TEST", ",", "\n", "\"test_topk_candidates\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "TOPK_CANDIDATES_TEST", ",", "\n", "\"test_nms_thresh\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NMS_THRESH_TEST", ",", "\n", "\"max_detections_per_image\"", ":", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", ",", "\n", "# Vis parameters", "\n", "\"vis_period\"", ":", "cfg", ".", "VIS_PERIOD", ",", "\n", "\"input_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.device": [[193, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.visualize_training": [[197, 231], ["detectron2.utils.events.get_event_storage", "detectron2.data.detection_utils.convert_image_to_rgb", "Visualizer", "v_gt.overlay_instances.overlay_instances.overlay_instances", "v_gt.overlay_instances.overlay_instances.get_image", "postprocessing.detector_postprocess", "postprocessing.detector_postprocess.pred_boxes.tensor.detach().cpu().numpy", "Visualizer", "v_pred.overlay_instances.overlay_instances.overlay_instances", "v_pred.overlay_instances.overlay_instances.get_image", "numpy.vstack", "vis_img.transpose.transpose.transpose", "detectron2.utils.events.get_event_storage.put_image", "len", "len", "detectron2.data.detection_utils.convert_image_to_rgb.permute", "postprocessing.detector_postprocess.pred_boxes.tensor.detach().cpu", "postprocessing.detector_postprocess.pred_boxes.tensor.detach"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.convert_image_to_rgb", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_image"], ["", "def", "visualize_training", "(", "self", ",", "batched_inputs", ",", "results", ")", ":", "\n", "        ", "\"\"\"\n        A function used to visualize ground truth images and final network predictions.\n        It shows ground truth bounding boxes on the original image and up to 20\n        predicted object bounding boxes on the original image.\n\n        Args:\n            batched_inputs (list): a list that contains input to the model.\n            results (List[Instances]): a list of #images elements.\n        \"\"\"", "\n", "from", "detectron2", ".", "utils", ".", "visualizer", "import", "Visualizer", "\n", "\n", "assert", "len", "(", "batched_inputs", ")", "==", "len", "(", "\n", "results", "\n", ")", ",", "\"Cannot visualize inputs and results of different sizes\"", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "max_boxes", "=", "20", "\n", "\n", "image_index", "=", "0", "# only visualize a single image", "\n", "img", "=", "batched_inputs", "[", "image_index", "]", "[", "\"image\"", "]", "\n", "img", "=", "convert_image_to_rgb", "(", "img", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "self", ".", "input_format", ")", "\n", "v_gt", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_gt", "=", "v_gt", ".", "overlay_instances", "(", "boxes", "=", "batched_inputs", "[", "image_index", "]", "[", "\"instances\"", "]", ".", "gt_boxes", ")", "\n", "anno_img", "=", "v_gt", ".", "get_image", "(", ")", "\n", "processed_results", "=", "detector_postprocess", "(", "results", "[", "image_index", "]", ",", "img", ".", "shape", "[", "0", "]", ",", "img", ".", "shape", "[", "1", "]", ")", "\n", "predicted_boxes", "=", "processed_results", ".", "pred_boxes", ".", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "v_pred", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_pred", "=", "v_pred", ".", "overlay_instances", "(", "boxes", "=", "predicted_boxes", "[", "0", ":", "max_boxes", "]", ")", "\n", "prop_img", "=", "v_pred", ".", "get_image", "(", ")", "\n", "vis_img", "=", "np", ".", "vstack", "(", "(", "anno_img", ",", "prop_img", ")", ")", "\n", "vis_img", "=", "vis_img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "vis_name", "=", "f\"Top: GT bounding boxes; Bottom: {max_boxes} Highest Scoring Results\"", "\n", "storage", ".", "put_image", "(", "vis_name", ",", "vis_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.forward": [[232, 291], ["retinanet.RetinaNet.preprocess_image", "retinanet.RetinaNet.backbone", "retinanet.RetinaNet.anchor_generator", "retinanet.RetinaNet.head", "retinanet.permute_to_N_HWA_K", "retinanet.permute_to_N_HWA_K", "retinanet.RetinaNet.label_anchors", "retinanet.RetinaNet.losses", "retinanet.RetinaNet.inference", "torch.jit.is_scripting", "zip", "torch.jit.is_scripting", "x[].to", "detectron2.utils.events.get_event_storage", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append", "retinanet.RetinaNet.inference", "retinanet.RetinaNet.visualize_training"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.label_anchors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.visualize_training"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n\n                * image: Tensor, image in (C, H, W) format.\n                * instances: Instances\n\n                Other information that's included in the original dicts, such as:\n\n                * \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n        Returns:\n            In training, dict[str, Tensor]: mapping from a named loss to a tensor storing the\n            loss. Used during training only. In inference, the standard output format, described\n            in :doc:`/tutorials/models`.\n        \"\"\"", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "head_in_features", "]", "\n", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "features", ")", "\n", "pred_logits", ",", "pred_anchor_deltas", "=", "self", ".", "head", "(", "features", ")", "\n", "# Transpose the Hi*Wi*A dimension to the middle:", "\n", "pred_logits", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "self", ".", "num_classes", ")", "for", "x", "in", "pred_logits", "]", "\n", "pred_anchor_deltas", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "4", ")", "for", "x", "in", "pred_anchor_deltas", "]", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ",", "\"Not supported\"", "\n", "assert", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ",", "\"Instance annotations are missing in training!\"", "\n", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "gt_labels", ",", "gt_boxes", "=", "self", ".", "label_anchors", "(", "anchors", ",", "gt_instances", ")", "\n", "losses", "=", "self", ".", "losses", "(", "anchors", ",", "pred_logits", ",", "gt_labels", ",", "pred_anchor_deltas", ",", "gt_boxes", ")", "\n", "\n", "if", "self", ".", "vis_period", ">", "0", ":", "\n", "                ", "storage", "=", "get_event_storage", "(", ")", "\n", "if", "storage", ".", "iter", "%", "self", ".", "vis_period", "==", "0", ":", "\n", "                    ", "results", "=", "self", ".", "inference", "(", "\n", "anchors", ",", "pred_logits", ",", "pred_anchor_deltas", ",", "images", ".", "image_sizes", "\n", ")", "\n", "self", ".", "visualize_training", "(", "batched_inputs", ",", "results", ")", "\n", "\n", "", "", "return", "losses", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "inference", "(", "anchors", ",", "pred_logits", ",", "pred_anchor_deltas", ",", "images", ".", "image_sizes", ")", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "return", "results", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.losses": [[292, 345], ["len", "torch.stack", "pos_mask.sum().item", "detectron2.utils.events.get_event_storage().put_scalar", "fvcore.nn.sigmoid_focal_loss_jit", "box_regression._dense_box_regression_loss", "torch.nn.functional.one_hot", "gt_labels_target.to", "pos_mask.sum", "detectron2.utils.events.get_event_storage", "max", "detectron2.layers.cat"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression._dense_box_regression_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "", "def", "losses", "(", "self", ",", "anchors", ",", "pred_logits", ",", "gt_labels", ",", "pred_anchor_deltas", ",", "gt_boxes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[Boxes]): a list of #feature level Boxes\n            gt_labels, gt_boxes: see output of :meth:`RetinaNet.label_anchors`.\n                Their shapes are (N, R) and (N, R, 4), respectively, where R is\n                the total number of anchors across levels, i.e. sum(Hi x Wi x Ai)\n            pred_logits, pred_anchor_deltas: both are list[Tensor]. Each element in the\n                list corresponds to one level and has shape (N, Hi * Wi * Ai, K or 4).\n                Where K is the number of classes used in `pred_logits`.\n\n        Returns:\n            dict[str, Tensor]:\n                mapping from a named loss to a scalar tensor\n                storing the loss. Used during training only. The dict keys are:\n                \"loss_cls\" and \"loss_box_reg\"\n        \"\"\"", "\n", "num_images", "=", "len", "(", "gt_labels", ")", "\n", "gt_labels", "=", "torch", ".", "stack", "(", "gt_labels", ")", "# (N, R)", "\n", "\n", "valid_mask", "=", "gt_labels", ">=", "0", "\n", "pos_mask", "=", "(", "gt_labels", ">=", "0", ")", "&", "(", "gt_labels", "!=", "self", ".", "num_classes", ")", "\n", "num_pos_anchors", "=", "pos_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "get_event_storage", "(", ")", ".", "put_scalar", "(", "\"num_pos_anchors\"", ",", "num_pos_anchors", "/", "num_images", ")", "\n", "self", ".", "loss_normalizer", "=", "self", ".", "loss_normalizer_momentum", "*", "self", ".", "loss_normalizer", "+", "(", "\n", "1", "-", "self", ".", "loss_normalizer_momentum", "\n", ")", "*", "max", "(", "num_pos_anchors", ",", "1", ")", "\n", "\n", "# classification and regression loss", "\n", "gt_labels_target", "=", "F", ".", "one_hot", "(", "gt_labels", "[", "valid_mask", "]", ",", "num_classes", "=", "self", ".", "num_classes", "+", "1", ")", "[", "\n", ":", ",", ":", "-", "1", "\n", "]", "# no loss for the last (background) class", "\n", "loss_cls", "=", "sigmoid_focal_loss_jit", "(", "\n", "cat", "(", "pred_logits", ",", "dim", "=", "1", ")", "[", "valid_mask", "]", ",", "\n", "gt_labels_target", ".", "to", "(", "pred_logits", "[", "0", "]", ".", "dtype", ")", ",", "\n", "alpha", "=", "self", ".", "focal_loss_alpha", ",", "\n", "gamma", "=", "self", ".", "focal_loss_gamma", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "\n", "loss_box_reg", "=", "_dense_box_regression_loss", "(", "\n", "anchors", ",", "\n", "self", ".", "box2box_transform", ",", "\n", "pred_anchor_deltas", ",", "\n", "gt_boxes", ",", "\n", "pos_mask", ",", "\n", "box_reg_loss_type", "=", "self", ".", "box_reg_loss_type", ",", "\n", "smooth_l1_beta", "=", "self", ".", "smooth_l1_beta", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "\"loss_cls\"", ":", "loss_cls", "/", "self", ".", "loss_normalizer", ",", "\n", "\"loss_box_reg\"", ":", "loss_box_reg", "/", "self", ".", "loss_normalizer", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.label_anchors": [[347, 391], ["torch.no_grad", "detectron2.structures.Boxes.cat", "detectron2.structures.pairwise_iou", "retinanet.RetinaNet.anchor_matcher", "gt_labels.append", "matched_gt_boxes.append", "len", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_anchors", "(", "self", ",", "anchors", ",", "gt_instances", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[Boxes]): A list of #feature level Boxes.\n                The Boxes contains anchors of this image on the specific feature level.\n            gt_instances (list[Instances]): a list of N `Instances`s. The i-th\n                `Instances` contains the ground-truth per-instance annotations\n                for the i-th input image.\n\n        Returns:\n            list[Tensor]: List of #img tensors. i-th element is a vector of labels whose length is\n            the total number of anchors across all feature maps (sum(Hi * Wi * A)).\n            Label values are in {-1, 0, ..., K}, with -1 means ignore, and K means background.\n\n            list[Tensor]: i-th element is a Rx4 tensor, where R is the total number of anchors\n            across feature maps. The values are the matched gt boxes for each anchor.\n            Values are undefined for those anchors not labeled as foreground.\n        \"\"\"", "\n", "anchors", "=", "Boxes", ".", "cat", "(", "anchors", ")", "# Rx4", "\n", "\n", "gt_labels", "=", "[", "]", "\n", "matched_gt_boxes", "=", "[", "]", "\n", "for", "gt_per_image", "in", "gt_instances", ":", "\n", "            ", "match_quality_matrix", "=", "pairwise_iou", "(", "gt_per_image", ".", "gt_boxes", ",", "anchors", ")", "\n", "matched_idxs", ",", "anchor_labels", "=", "self", ".", "anchor_matcher", "(", "match_quality_matrix", ")", "\n", "del", "match_quality_matrix", "\n", "\n", "if", "len", "(", "gt_per_image", ")", ">", "0", ":", "\n", "                ", "matched_gt_boxes_i", "=", "gt_per_image", ".", "gt_boxes", ".", "tensor", "[", "matched_idxs", "]", "\n", "\n", "gt_labels_i", "=", "gt_per_image", ".", "gt_classes", "[", "matched_idxs", "]", "\n", "# Anchors with label 0 are treated as background.", "\n", "gt_labels_i", "[", "anchor_labels", "==", "0", "]", "=", "self", ".", "num_classes", "\n", "# Anchors with label -1 are ignored.", "\n", "gt_labels_i", "[", "anchor_labels", "==", "-", "1", "]", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "matched_gt_boxes_i", "=", "torch", ".", "zeros_like", "(", "anchors", ".", "tensor", ")", "\n", "gt_labels_i", "=", "torch", ".", "zeros_like", "(", "matched_idxs", ")", "+", "self", ".", "num_classes", "\n", "\n", "", "gt_labels", ".", "append", "(", "gt_labels_i", ")", "\n", "matched_gt_boxes", ".", "append", "(", "matched_gt_boxes_i", ")", "\n", "\n", "", "return", "gt_labels", ",", "matched_gt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.inference": [[392, 419], ["enumerate", "retinanet.RetinaNet.inference_single_image", "results.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.inference_single_image"], ["", "def", "inference", "(", "\n", "self", ",", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "pred_logits", ":", "List", "[", "Tensor", "]", ",", "\n", "pred_anchor_deltas", ":", "List", "[", "Tensor", "]", ",", "\n", "image_sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[Boxes]): A list of #feature level Boxes.\n                The Boxes contain anchors of this image on the specific feature level.\n            pred_logits, pred_anchor_deltas: list[Tensor], one per level. Each\n                has shape (N, Hi * Wi * Ai, K or 4)\n            image_sizes (List[(h, w)]): the input image sizes\n\n        Returns:\n            results (List[Instances]): a list of #images elements.\n        \"\"\"", "\n", "results", ":", "List", "[", "Instances", "]", "=", "[", "]", "\n", "for", "img_idx", ",", "image_size", "in", "enumerate", "(", "image_sizes", ")", ":", "\n", "            ", "pred_logits_per_image", "=", "[", "x", "[", "img_idx", "]", "for", "x", "in", "pred_logits", "]", "\n", "deltas_per_image", "=", "[", "x", "[", "img_idx", "]", "for", "x", "in", "pred_anchor_deltas", "]", "\n", "results_per_image", "=", "self", ".", "inference_single_image", "(", "\n", "anchors", ",", "pred_logits_per_image", ",", "deltas_per_image", ",", "image_size", "\n", ")", "\n", "results", ".", "append", "(", "results_per_image", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.inference_single_image": [[420, 487], ["zip", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "box_cls_i.flatten().sigmoid_", "min", "box_cls_i.flatten().sigmoid_.sort", "retinanet.RetinaNet.box2box_transform.apply_deltas", "boxes_all.append", "scores_all.append", "class_idxs_all.append", "detectron2.layers.cat", "detectron2.layers.nonzero_tuple", "topk_idxs.size", "box_cls_i.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "inference_single_image", "(", "\n", "self", ",", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "box_cls", ":", "List", "[", "Tensor", "]", ",", "\n", "box_delta", ":", "List", "[", "Tensor", "]", ",", "\n", "image_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Single-image inference. Return bounding-box detection results by thresholding\n        on scores and applying non-maximum suppression (NMS).\n\n        Arguments:\n            anchors (list[Boxes]): list of #feature levels. Each entry contains\n                a Boxes object, which contains all the anchors in that feature level.\n            box_cls (list[Tensor]): list of #feature levels. Each entry contains\n                tensor of size (H x W x A, K)\n            box_delta (list[Tensor]): Same shape as 'box_cls' except that K becomes 4.\n            image_size (tuple(H, W)): a tuple of the image height and width.\n\n        Returns:\n            Same as `inference`, but for only one image.\n        \"\"\"", "\n", "boxes_all", "=", "[", "]", "\n", "scores_all", "=", "[", "]", "\n", "class_idxs_all", "=", "[", "]", "\n", "\n", "# Iterate over every feature level", "\n", "for", "box_cls_i", ",", "box_reg_i", ",", "anchors_i", "in", "zip", "(", "box_cls", ",", "box_delta", ",", "anchors", ")", ":", "\n", "# (HxWxAxK,)", "\n", "            ", "predicted_prob", "=", "box_cls_i", ".", "flatten", "(", ")", ".", "sigmoid_", "(", ")", "\n", "\n", "# Apply two filtering below to make NMS faster.", "\n", "# 1. Keep boxes with confidence score higher than threshold", "\n", "keep_idxs", "=", "predicted_prob", ">", "self", ".", "test_score_thresh", "\n", "predicted_prob", "=", "predicted_prob", "[", "keep_idxs", "]", "\n", "topk_idxs", "=", "nonzero_tuple", "(", "keep_idxs", ")", "[", "0", "]", "\n", "\n", "# 2. Keep top k top scoring boxes only", "\n", "num_topk", "=", "min", "(", "self", ".", "test_topk_candidates", ",", "topk_idxs", ".", "size", "(", "0", ")", ")", "\n", "# torch.sort is actually faster than .topk (at least on GPUs)", "\n", "predicted_prob", ",", "idxs", "=", "predicted_prob", ".", "sort", "(", "descending", "=", "True", ")", "\n", "predicted_prob", "=", "predicted_prob", "[", ":", "num_topk", "]", "\n", "topk_idxs", "=", "topk_idxs", "[", "idxs", "[", ":", "num_topk", "]", "]", "\n", "\n", "anchor_idxs", "=", "topk_idxs", "//", "self", ".", "num_classes", "\n", "classes_idxs", "=", "topk_idxs", "%", "self", ".", "num_classes", "\n", "\n", "box_reg_i", "=", "box_reg_i", "[", "anchor_idxs", "]", "\n", "anchors_i", "=", "anchors_i", "[", "anchor_idxs", "]", "\n", "# predict boxes", "\n", "predicted_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "box_reg_i", ",", "anchors_i", ".", "tensor", ")", "\n", "\n", "boxes_all", ".", "append", "(", "predicted_boxes", ")", "\n", "scores_all", ".", "append", "(", "predicted_prob", ")", "\n", "class_idxs_all", ".", "append", "(", "classes_idxs", ")", "\n", "\n", "", "boxes_all", ",", "scores_all", ",", "class_idxs_all", "=", "[", "\n", "cat", "(", "x", ")", "for", "x", "in", "[", "boxes_all", ",", "scores_all", ",", "class_idxs_all", "]", "\n", "]", "\n", "keep", "=", "batched_nms", "(", "boxes_all", ",", "scores_all", ",", "class_idxs_all", ",", "self", ".", "test_nms_thresh", ")", "\n", "keep", "=", "keep", "[", ":", "self", ".", "max_detections_per_image", "]", "\n", "\n", "result", "=", "Instances", "(", "image_size", ")", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "boxes_all", "[", "keep", "]", ")", "\n", "result", ".", "scores", "=", "scores_all", "[", "keep", "]", "\n", "result", ".", "pred_classes", "=", "class_idxs_all", "[", "keep", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNet.preprocess_image": [[488, 496], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNetHead.__init__": [[504, 570], ["torch.nn.Module.__init__", "zip", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "logger.warning", "cls_subnet.append", "cls_subnet.append", "bbox_subnet.append", "bbox_subnet.append", "modules.modules", "math.log", "list", "torch.nn.Conv2d", "cls_subnet.append", "torch.nn.ReLU", "torch.nn.Conv2d", "bbox_subnet.append", "torch.nn.ReLU", "isinstance", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "torch.nn.init.normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "input_shape", ":", "List", "[", "ShapeSpec", "]", ",", "\n", "num_classes", ",", "\n", "num_anchors", ",", "\n", "conv_dims", ":", "List", "[", "int", "]", ",", "\n", "norm", "=", "\"\"", ",", "\n", "prior_prob", "=", "0.01", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (List[ShapeSpec]): input shape\n            num_classes (int): number of classes. Used to label background proposals.\n            num_anchors (int): number of generated anchors\n            conv_dims (List[int]): dimensions for each convolution layer\n            norm (str or callable):\n                    Normalization for conv layers except for the two output layers.\n                    See :func:`detectron2.layers.get_norm` for supported types.\n            prior_prob (float): Prior weight for computing bias\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "norm", "==", "\"BN\"", "or", "norm", "==", "\"SyncBN\"", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Shared norm does not work well for BN, SyncBN, expect poor results\"", ")", "\n", "\n", "", "cls_subnet", "=", "[", "]", "\n", "bbox_subnet", "=", "[", "]", "\n", "for", "in_channels", ",", "out_channels", "in", "zip", "(", "\n", "[", "input_shape", "[", "0", "]", ".", "channels", "]", "+", "list", "(", "conv_dims", ")", ",", "conv_dims", "\n", ")", ":", "\n", "            ", "cls_subnet", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "if", "norm", ":", "\n", "                ", "cls_subnet", ".", "append", "(", "get_norm", "(", "norm", ",", "out_channels", ")", ")", "\n", "", "cls_subnet", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "bbox_subnet", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "if", "norm", ":", "\n", "                ", "bbox_subnet", ".", "append", "(", "get_norm", "(", "norm", ",", "out_channels", ")", ")", "\n", "", "bbox_subnet", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "cls_subnet", "=", "nn", ".", "Sequential", "(", "*", "cls_subnet", ")", "\n", "self", ".", "bbox_subnet", "=", "nn", ".", "Sequential", "(", "*", "bbox_subnet", ")", "\n", "self", ".", "cls_score", "=", "nn", ".", "Conv2d", "(", "\n", "conv_dims", "[", "-", "1", "]", ",", "num_anchors", "*", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "conv_dims", "[", "-", "1", "]", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "\n", "# Initialization", "\n", "for", "modules", "in", "[", "self", ".", "cls_subnet", ",", "self", ".", "bbox_subnet", ",", "self", ".", "cls_score", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "for", "layer", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "layer", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", ",", "0", ")", "\n", "\n", "# Use prior in model initialization to improve stability", "\n", "", "", "", "bias_value", "=", "-", "(", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_score", ".", "bias", ",", "bias_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNetHead.from_config": [[571, 586], ["anchor_generator.build_anchor_generator", "len", "set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "List", "[", "ShapeSpec", "]", ")", ":", "\n", "        ", "num_anchors", "=", "build_anchor_generator", "(", "cfg", ",", "input_shape", ")", ".", "num_cell_anchors", "\n", "assert", "(", "\n", "len", "(", "set", "(", "num_anchors", ")", ")", "==", "1", "\n", ")", ",", "\"Using different number of anchors between levels is not currently supported!\"", "\n", "num_anchors", "=", "num_anchors", "[", "0", "]", "\n", "\n", "return", "{", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", ",", "\n", "\"conv_dims\"", ":", "[", "input_shape", "[", "0", "]", ".", "channels", "]", "*", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CONVS", ",", "\n", "\"prior_prob\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "PRIOR_PROB", ",", "\n", "\"norm\"", ":", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NORM", ",", "\n", "\"num_anchors\"", ":", "num_anchors", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.RetinaNetHead.forward": [[588, 610], ["logits.append", "bbox_reg.append", "retinanet.RetinaNetHead.cls_score", "retinanet.RetinaNetHead.bbox_pred", "retinanet.RetinaNetHead.cls_subnet", "retinanet.RetinaNetHead.bbox_subnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "List", "[", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): FPN feature map tensors in high to low resolution.\n                Each tensor in the list correspond to different feature levels.\n\n        Returns:\n            logits (list[Tensor]): #lvl tensors, each has shape (N, AxK, Hi, Wi).\n                The tensor predicts the classification probability\n                at each spatial position for each of the A anchors and K object\n                classes.\n            bbox_reg (list[Tensor]): #lvl tensors, each has shape (N, Ax4, Hi, Wi).\n                The tensor predicts 4-vector (dx,dy,dw,dh) box\n                regression values for every anchor. These values are the\n                relative offset between the anchor and the ground truth box.\n        \"\"\"", "\n", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "for", "feature", "in", "features", ":", "\n", "            ", "logits", ".", "append", "(", "self", ".", "cls_score", "(", "self", ".", "cls_subnet", "(", "feature", ")", ")", ")", "\n", "bbox_reg", ".", "append", "(", "self", ".", "bbox_pred", "(", "self", ".", "bbox_subnet", "(", "feature", ")", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.permute_to_N_HWA_K": [[30, 40], ["tensor.reshape.view", "tensor.reshape.permute", "tensor.reshape.reshape", "tensor.reshape.dim"], "function", ["None"], ["def", "permute_to_N_HWA_K", "(", "tensor", ",", "K", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Transpose/reshape a tensor from (N, (Ai x K), H, W) to (N, (HxWxAi), K)\n    \"\"\"", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "4", ",", "tensor", ".", "shape", "\n", "N", ",", "_", ",", "H", ",", "W", "=", "tensor", ".", "shape", "\n", "tensor", "=", "tensor", ".", "view", "(", "N", ",", "-", "1", ",", "K", ",", "H", ",", "W", ")", "\n", "tensor", "=", "tensor", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "2", ")", "\n", "tensor", "=", "tensor", ".", "reshape", "(", "N", ",", "-", "1", ",", "K", ")", "# Size=(N,HWA,K)", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.build.build_model": [[16, 26], ["model.to", "detectron2.utils.logger._log_api_usage", "META_ARCH_REGISTRY.get", "torch.device"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._log_api_usage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "build_model", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.\n    Note that it does not load any weights from ``cfg``.\n    \"\"\"", "\n", "meta_arch", "=", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "\n", "model", "=", "META_ARCH_REGISTRY", ".", "get", "(", "meta_arch", ")", "(", "cfg", ")", "\n", "model", ".", "to", "(", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", ")", "\n", "_log_api_usage", "(", "\"modeling.meta_arch.\"", "+", "meta_arch", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.PanopticFPN.__init__": [[26, 55], ["rcnn.GeneralizedRCNN.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "sem_seg_head", ":", "nn", ".", "Module", ",", "\n", "combine_overlap_thresh", ":", "float", "=", "0.5", ",", "\n", "combine_stuff_area_thresh", ":", "float", "=", "4096", ",", "\n", "combine_instances_score_thresh", ":", "float", "=", "0.5", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            sem_seg_head: a module for the semantic segmentation head.\n            combine_overlap_thresh: combine masks into one instances if\n                they have enough overlap\n            combine_stuff_area_thresh: ignore stuff areas smaller than this threshold\n            combine_instances_score_thresh: ignore instances whose score is\n                smaller than this threshold\n\n        Other arguments are the same as :class:`GeneralizedRCNN`.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n", "# options when combining instance & semantic outputs", "\n", "self", ".", "combine_overlap_thresh", "=", "combine_overlap_thresh", "\n", "self", ".", "combine_stuff_area_thresh", "=", "combine_stuff_area_thresh", "\n", "self", ".", "combine_instances_score_thresh", "=", "combine_instances_score_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.PanopticFPN.from_config": [[56, 89], ["super().from_config", "super().from_config.update", "semantic_seg.build_sem_seg_head", "logging.getLogger", "ret[].output_shape", "logging.getLogger.warning", "logging.getLogger.warning", "panoptic_fpn.PanopticFPN.from_config.update_weight"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.build_sem_seg_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ")", "\n", "ret", ".", "update", "(", "\n", "{", "\n", "\"combine_overlap_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "OVERLAP_THRESH", ",", "\n", "\"combine_stuff_area_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "STUFF_AREA_LIMIT", ",", "\n", "\"combine_instances_score_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "INSTANCES_CONFIDENCE_THRESH", ",", "# noqa", "\n", "}", "\n", ")", "\n", "ret", "[", "\"sem_seg_head\"", "]", "=", "build_sem_seg_head", "(", "cfg", ",", "ret", "[", "\"backbone\"", "]", ".", "output_shape", "(", ")", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "not", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "ENABLED", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"PANOPTIC_FPN.COMBINED.ENABLED is no longer used. \"", "\n", "\" model.inference(do_postprocess=) should be used to toggle postprocessing.\"", "\n", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "INSTANCE_LOSS_WEIGHT", "!=", "1.0", ":", "\n", "            ", "w", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "INSTANCE_LOSS_WEIGHT", "\n", "logger", ".", "warning", "(", "\n", "\"PANOPTIC_FPN.INSTANCE_LOSS_WEIGHT should be replaced by weights on each ROI head.\"", "\n", ")", "\n", "\n", "def", "update_weight", "(", "x", ")", ":", "\n", "                ", "if", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "                    ", "return", "{", "k", ":", "v", "*", "w", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "                    ", "return", "x", "*", "w", "\n", "\n", "", "", "roi_heads", "=", "ret", "[", "\"roi_heads\"", "]", "\n", "roi_heads", ".", "box_predictor", ".", "loss_weight", "=", "update_weight", "(", "roi_heads", ".", "box_predictor", ".", "loss_weight", ")", "\n", "roi_heads", ".", "mask_head", ".", "loss_weight", "=", "update_weight", "(", "roi_heads", ".", "mask_head", ".", "loss_weight", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.PanopticFPN.forward": [[90, 136], ["panoptic_fpn.PanopticFPN.preprocess_image", "panoptic_fpn.PanopticFPN.backbone", "panoptic_fpn.PanopticFPN.sem_seg_head", "panoptic_fpn.PanopticFPN.proposal_generator", "panoptic_fpn.PanopticFPN.roi_heads", "losses.update", "losses.update", "panoptic_fpn.PanopticFPN.inference", "x[].to", "detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                * \"image\": Tensor, image in (C, H, W) format.\n                * \"instances\": Instances\n                * \"sem_seg\": semantic segmentation ground truth.\n                * Other information that's included in the original dicts, such as:\n                  \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n\n        Returns:\n            list[dict]:\n                each dict has the results for one image. The dict contains the following keys:\n\n                * \"instances\": see :meth:`GeneralizedRCNN.forward` for its format.\n                * \"sem_seg\": see :meth:`SemanticSegmentor.forward` for its format.\n                * \"panoptic_seg\": See the return value of\n                  :func:`combine_semantic_and_instance_outputs` for its format.\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "assert", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", "\n", "gt_sem_seg", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "gt_sem_seg", "=", "ImageList", ".", "from_tensors", "(", "\n", "gt_sem_seg", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "sem_seg_results", ",", "sem_seg_losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "gt_sem_seg", ")", "\n", "\n", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "detector_results", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "features", ",", "proposals", ",", "gt_instances", "\n", ")", "\n", "\n", "losses", "=", "sem_seg_losses", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.PanopticFPN.inference": [[137, 181], ["panoptic_fpn.PanopticFPN.preprocess_image", "panoptic_fpn.PanopticFPN.backbone", "panoptic_fpn.PanopticFPN.sem_seg_head", "panoptic_fpn.PanopticFPN.proposal_generator", "panoptic_fpn.PanopticFPN.roi_heads", "zip", "input_per_image.get", "input_per_image.get", "postprocessing.sem_seg_postprocess", "postprocessing.detector_postprocess", "processed_results.append", "panoptic_fpn.combine_semantic_and_instance_outputs", "postprocessing.sem_seg_postprocess.argmax"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs"], ["", "def", "inference", "(", "\n", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "do_postprocess", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, see docs in :meth:`forward`.\n            Otherwise, returns a (list[Instances], list[Tensor]) that contains\n            the raw detector outputs, and raw semantic segmentation outputs.\n        \"\"\"", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "sem_seg_results", ",", "sem_seg_losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "None", ")", "\n", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "detector_results", ",", "_", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "\n", "if", "do_postprocess", ":", "\n", "            ", "processed_results", "=", "[", "]", "\n", "for", "sem_seg_result", ",", "detector_result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "sem_seg_results", ",", "detector_results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "sem_seg_r", "=", "sem_seg_postprocess", "(", "sem_seg_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "detector_r", "=", "detector_postprocess", "(", "detector_result", ",", "height", ",", "width", ")", "\n", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "sem_seg_r", ",", "\"instances\"", ":", "detector_r", "}", ")", "\n", "\n", "panoptic_r", "=", "combine_semantic_and_instance_outputs", "(", "\n", "detector_r", ",", "\n", "sem_seg_r", ".", "argmax", "(", "dim", "=", "0", ")", ",", "\n", "self", ".", "combine_overlap_thresh", ",", "\n", "self", ".", "combine_stuff_area_thresh", ",", "\n", "self", ".", "combine_instances_score_thresh", ",", "\n", ")", "\n", "processed_results", "[", "-", "1", "]", "[", "\"panoptic_seg\"", "]", "=", "panoptic_r", "\n", "", "return", "processed_results", "\n", "", "else", ":", "\n", "            ", "return", "detector_results", ",", "sem_seg_results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs": [[183, 269], ["torch.zeros_like", "torch.argsort", "instance_results.pred_masks.to", "torch.unique().cpu().tolist", "instance_results.scores[].item", "mask.sum().item", "intersect.sum().item", "segments_info.append", "mask.sum().item", "segments_info.append", "torch.unique().cpu", "mask.sum", "intersect.sum", "instance_results.pred_classes[].item", "inst_id.item", "mask.sum", "torch.unique"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "", "", "def", "combine_semantic_and_instance_outputs", "(", "\n", "instance_results", ",", "\n", "semantic_results", ",", "\n", "overlap_threshold", ",", "\n", "stuff_area_thresh", ",", "\n", "instances_score_thresh", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Implement a simple combining logic following\n    \"combine_semantic_and_instance_predictions.py\" in panopticapi\n    to produce panoptic segmentation outputs.\n\n    Args:\n        instance_results: output of :func:`detector_postprocess`.\n        semantic_results: an (H, W) tensor, each element is the contiguous semantic\n            category id\n\n    Returns:\n        panoptic_seg (Tensor): of shape (height, width) where the values are ids for each segment.\n        segments_info (list[dict]): Describe each segment in `panoptic_seg`.\n            Each dict contains keys \"id\", \"category_id\", \"isthing\".\n    \"\"\"", "\n", "panoptic_seg", "=", "torch", ".", "zeros_like", "(", "semantic_results", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "# sort instance outputs by scores", "\n", "sorted_inds", "=", "torch", ".", "argsort", "(", "-", "instance_results", ".", "scores", ")", "\n", "\n", "current_segment_id", "=", "0", "\n", "segments_info", "=", "[", "]", "\n", "\n", "instance_masks", "=", "instance_results", ".", "pred_masks", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "panoptic_seg", ".", "device", ")", "\n", "\n", "# Add instances one-by-one, check for overlaps with existing ones", "\n", "for", "inst_id", "in", "sorted_inds", ":", "\n", "        ", "score", "=", "instance_results", ".", "scores", "[", "inst_id", "]", ".", "item", "(", ")", "\n", "if", "score", "<", "instances_score_thresh", ":", "\n", "            ", "break", "\n", "", "mask", "=", "instance_masks", "[", "inst_id", "]", "# H,W", "\n", "mask_area", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "mask_area", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "intersect", "=", "(", "mask", ">", "0", ")", "&", "(", "panoptic_seg", ">", "0", ")", "\n", "intersect_area", "=", "intersect", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "intersect_area", "*", "1.0", "/", "mask_area", ">", "overlap_threshold", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "intersect_area", ">", "0", ":", "\n", "            ", "mask", "=", "mask", "&", "(", "panoptic_seg", "==", "0", ")", "\n", "\n", "", "current_segment_id", "+=", "1", "\n", "panoptic_seg", "[", "mask", "]", "=", "current_segment_id", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "current_segment_id", ",", "\n", "\"isthing\"", ":", "True", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"category_id\"", ":", "instance_results", ".", "pred_classes", "[", "inst_id", "]", ".", "item", "(", ")", ",", "\n", "\"instance_id\"", ":", "inst_id", ".", "item", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# Add semantic results to remaining empty areas", "\n", "", "semantic_labels", "=", "torch", ".", "unique", "(", "semantic_results", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "semantic_label", "in", "semantic_labels", ":", "\n", "        ", "if", "semantic_label", "==", "0", ":", "# 0 is a special \"thing\" class", "\n", "            ", "continue", "\n", "", "mask", "=", "(", "semantic_results", "==", "semantic_label", ")", "&", "(", "panoptic_seg", "==", "0", ")", "\n", "mask_area", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "mask_area", "<", "stuff_area_thresh", ":", "\n", "            ", "continue", "\n", "\n", "", "current_segment_id", "+=", "1", "\n", "panoptic_seg", "[", "mask", "]", "=", "current_segment_id", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "current_segment_id", ",", "\n", "\"isthing\"", ":", "False", ",", "\n", "\"category_id\"", ":", "semantic_label", ",", "\n", "\"area\"", ":", "mask_area", ",", "\n", "}", "\n", ")", "\n", "\n", "", "return", "panoptic_seg", ",", "segments_info", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemanticSegmentor.__init__": [[34, 55], ["torch.nn.Module.__init__", "semantic_seg.SemanticSegmentor.register_buffer", "semantic_seg.SemanticSegmentor.register_buffer", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "sem_seg_head", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            sem_seg_head: a module that predicts semantic segmentation from backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemanticSegmentor.from_config": [[56, 65], ["backbone.build_backbone.build_backbone", "semantic_seg.build_sem_seg_head", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.build_sem_seg_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "sem_seg_head", "=", "build_sem_seg_head", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"sem_seg_head\"", ":", "sem_seg_head", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemanticSegmentor.device": [[67, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemanticSegmentor.forward": [[71, 120], ["detectron2.structures.ImageList.from_tensors", "semantic_seg.SemanticSegmentor.backbone", "semantic_seg.SemanticSegmentor.sem_seg_head", "zip", "x[].to", "input_per_image.get", "input_per_image.get", "postprocessing.sem_seg_postprocess", "processed_results.append", "x[].to", "detectron2.structures.ImageList.from_tensors"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                   * \"image\": Tensor, image in (C, H, W) format.\n                   * \"sem_seg\": semantic segmentation ground truth\n                   * Other information that's included in the original dicts, such as:\n                     \"height\", \"width\" (int): the output resolution of the model (may be different\n                     from input resolution), used in inference.\n\n\n        Returns:\n            list[dict]:\n              Each dict is the output for one input image.\n              The dict contains one key \"sem_seg\" whose value is a\n              Tensor that represents the\n              per-pixel segmentation prediced by the head.\n              The prediction has shape KxHxW that represents the logits of\n              each class for each pixel.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "targets", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "targets", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "", "results", ",", "losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "targets", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ")", "\n", "r", "=", "sem_seg_postprocess", "(", "result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemSegFPNHead.__init__": [[140, 202], ["torch.nn.Module.__init__", "sorted", "zip", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "sorted.items", "max", "range", "semantic_seg.SemSegFPNHead.scale_heads.append", "semantic_seg.SemSegFPNHead.add_module", "int", "detectron2.layers.get_norm", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "head_ops.append", "torch.nn.Sequential", "head_ops.append", "numpy.log2", "numpy.log2", "torch.nn.Upsample"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "\n", "*", ",", "\n", "num_classes", ":", "int", ",", "\n", "conv_dims", ":", "int", ",", "\n", "common_stride", ":", "int", ",", "\n", "loss_weight", ":", "float", "=", "1.0", ",", "\n", "norm", ":", "Optional", "[", "Union", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "ignore_value", ":", "int", "=", "-", "1", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape: shapes (channels and stride) of the input features\n            num_classes: number of classes to predict\n            conv_dims: number of output channels for the intermediate conv layers.\n            common_stride: the common stride that all features will be upscaled to\n            loss_weight: loss weight\n            norm (str or callable): normalization for all conv layers\n            ignore_value: category id to be ignored during training.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "input_shape", "=", "sorted", "(", "input_shape", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ".", "stride", ")", "\n", "self", ".", "in_features", "=", "[", "k", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_strides", "=", "[", "v", ".", "stride", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_channels", "=", "[", "v", ".", "channels", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "\n", "self", ".", "ignore_value", "=", "ignore_value", "\n", "self", ".", "common_stride", "=", "common_stride", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n", "self", ".", "scale_heads", "=", "[", "]", "\n", "for", "in_feature", ",", "stride", ",", "channels", "in", "zip", "(", "\n", "self", ".", "in_features", ",", "feature_strides", ",", "feature_channels", "\n", ")", ":", "\n", "            ", "head_ops", "=", "[", "]", "\n", "head_length", "=", "max", "(", "1", ",", "int", "(", "np", ".", "log2", "(", "stride", ")", "-", "np", ".", "log2", "(", "self", ".", "common_stride", ")", ")", ")", "\n", "for", "k", "in", "range", "(", "head_length", ")", ":", "\n", "                ", "norm_module", "=", "get_norm", "(", "norm", ",", "conv_dims", ")", "\n", "conv", "=", "Conv2d", "(", "\n", "channels", "if", "k", "==", "0", "else", "conv_dims", ",", "\n", "conv_dims", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "norm", ",", "\n", "norm", "=", "norm_module", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "conv", ")", "\n", "head_ops", ".", "append", "(", "conv", ")", "\n", "if", "stride", "!=", "self", ".", "common_stride", ":", "\n", "                    ", "head_ops", ".", "append", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", ")", "\n", "", "", "self", ".", "scale_heads", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "head_ops", ")", ")", "\n", "self", ".", "add_module", "(", "in_feature", ",", "self", ".", "scale_heads", "[", "-", "1", "]", ")", "\n", "", "self", ".", "predictor", "=", "Conv2d", "(", "conv_dims", ",", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "predictor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemSegFPNHead.from_config": [[203, 215], ["input_shape.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "return", "{", "\n", "\"input_shape\"", ":", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "if", "k", "in", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IN_FEATURES", "\n", "}", ",", "\n", "\"ignore_value\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IGNORE_VALUE", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NUM_CLASSES", ",", "\n", "\"conv_dims\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "CONVS_DIM", ",", "\n", "\"common_stride\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "COMMON_STRIDE", ",", "\n", "\"norm\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NORM", ",", "\n", "\"loss_weight\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "LOSS_WEIGHT", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemSegFPNHead.forward": [[217, 231], ["semantic_seg.SemSegFPNHead.layers", "torch.nn.functional.interpolate", "semantic_seg.SemSegFPNHead.losses"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.layers", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses"], ["", "def", "forward", "(", "self", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            In training, returns (None, dict of losses)\n            In inference, returns (CxHxW logits, {})\n        \"\"\"", "\n", "x", "=", "self", ".", "layers", "(", "features", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "None", ",", "self", ".", "losses", "(", "x", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "x", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemSegFPNHead.layers": [[232, 240], ["enumerate", "semantic_seg.SemSegFPNHead.predictor"], "methods", ["None"], ["", "", "def", "layers", "(", "self", ",", "features", ")", ":", "\n", "        ", "for", "i", ",", "f", "in", "enumerate", "(", "self", ".", "in_features", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "+", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "", "x", "=", "self", ".", "predictor", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.SemSegFPNHead.losses": [[241, 251], ["torch.nn.functional.interpolate.float", "torch.nn.functional.interpolate", "torch.nn.functional.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "targets", ")", ":", "\n", "        ", "predictions", "=", "predictions", ".", "float", "(", ")", "# https://github.com/pytorch/pytorch/issues/48163", "\n", "predictions", "=", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "predictions", ",", "targets", ",", "reduction", "=", "\"mean\"", ",", "ignore_index", "=", "self", ".", "ignore_value", "\n", ")", "\n", "losses", "=", "{", "\"loss_sem_seg\"", ":", "loss", "*", "self", ".", "loss_weight", "}", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.semantic_seg.build_sem_seg_head": [[122, 128], ["SEM_SEG_HEADS_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "build_sem_seg_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a semantic segmentation head from `cfg.MODEL.SEM_SEG_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NAME", "\n", "return", "SEM_SEG_HEADS_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils._is_tracing": [[14, 20], ["torch.jit.is_scripting", "torch.jit.is_tracing"], "function", ["None"], ["def", "_is_tracing", "(", ")", ":", "\n", "    ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# https://github.com/pytorch/pytorch/issues/47379", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "TORCH_VERSION", ">=", "(", "1", ",", "7", ")", "and", "torch", ".", "jit", ".", "is_tracing", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.find_top_rpn_proposals": [[22, 131], ["len", "torch.arange", "enumerate", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "enumerate", "zip", "isinstance", "logits_i.sort", "logits_i.narrow", "idx.narrow", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.structures.Boxes", "detectron2.structures.Boxes.clip", "detectron2.structures.Boxes.nonempty", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "results.append", "torch.clamp", "min", "torch.full", "torch.isfinite().all", "torch.isfinite", "valid_mask.all", "proposal_utils._is_tracing", "FloatingPointError", "detectron2.layers.batched_nms.sum().item", "len", "torch.isfinite", "detectron2.layers.batched_nms.sum"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils._is_tracing"], ["", "", "def", "find_top_rpn_proposals", "(", "\n", "proposals", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "pred_objectness_logits", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "image_sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "pre_nms_topk", ":", "int", ",", "\n", "post_nms_topk", ":", "int", ",", "\n", "min_box_size", ":", "float", ",", "\n", "training", ":", "bool", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    For each feature map, select the `pre_nms_topk` highest scoring proposals,\n    apply NMS, clip proposals, and remove small boxes. Return the `post_nms_topk`\n    highest scoring proposals among all the feature maps for each image.\n\n    Args:\n        proposals (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A, 4).\n            All proposal predictions on the feature maps.\n        pred_objectness_logits (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A).\n        image_sizes (list[tuple]): sizes (h, w) for each image\n        nms_thresh (float): IoU threshold to use for NMS\n        pre_nms_topk (int): number of top k scoring proposals to keep before applying NMS.\n            When RPN is run on multiple feature maps (as in FPN) this number is per\n            feature map.\n        post_nms_topk (int): number of top k scoring proposals to keep after applying NMS.\n            When RPN is run on multiple feature maps (as in FPN) this number is total,\n            over all feature maps.\n        min_box_size (float): minimum proposal box side length in pixels (absolute units\n            wrt input images).\n        training (bool): True if proposals are to be used in training, otherwise False.\n            This arg exists only to support a legacy bug; look for the \"NB: Legacy bug ...\"\n            comment.\n\n    Returns:\n        list[Instances]: list of N Instances. The i-th Instances\n            stores post_nms_topk object proposals for image i, sorted by their\n            objectness score in descending order.\n    \"\"\"", "\n", "num_images", "=", "len", "(", "image_sizes", ")", "\n", "device", "=", "proposals", "[", "0", "]", ".", "device", "\n", "\n", "# 1. Select top-k anchor for every level and every image", "\n", "topk_scores", "=", "[", "]", "# #lvl Tensor, each of shape N x topk", "\n", "topk_proposals", "=", "[", "]", "\n", "level_ids", "=", "[", "]", "# #lvl Tensor, each of shape (topk,)", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "num_images", ",", "device", "=", "device", ")", "\n", "for", "level_id", ",", "(", "proposals_i", ",", "logits_i", ")", "in", "enumerate", "(", "zip", "(", "proposals", ",", "pred_objectness_logits", ")", ")", ":", "\n", "        ", "Hi_Wi_A", "=", "logits_i", ".", "shape", "[", "1", "]", "\n", "if", "isinstance", "(", "Hi_Wi_A", ",", "torch", ".", "Tensor", ")", ":", "# it's a tensor in tracing", "\n", "            ", "num_proposals_i", "=", "torch", ".", "clamp", "(", "Hi_Wi_A", ",", "max", "=", "pre_nms_topk", ")", "\n", "", "else", ":", "\n", "            ", "num_proposals_i", "=", "min", "(", "Hi_Wi_A", ",", "pre_nms_topk", ")", "\n", "\n", "# sort is faster than topk: https://github.com/pytorch/pytorch/issues/22812", "\n", "# topk_scores_i, topk_idx = logits_i.topk(num_proposals_i, dim=1)", "\n", "", "logits_i", ",", "idx", "=", "logits_i", ".", "sort", "(", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "topk_scores_i", "=", "logits_i", ".", "narrow", "(", "1", ",", "0", ",", "num_proposals_i", ")", "\n", "topk_idx", "=", "idx", ".", "narrow", "(", "1", ",", "0", ",", "num_proposals_i", ")", "\n", "\n", "# each is N x topk", "\n", "topk_proposals_i", "=", "proposals_i", "[", "batch_idx", "[", ":", ",", "None", "]", ",", "topk_idx", "]", "# N x topk x 4", "\n", "\n", "topk_proposals", ".", "append", "(", "topk_proposals_i", ")", "\n", "topk_scores", ".", "append", "(", "topk_scores_i", ")", "\n", "level_ids", ".", "append", "(", "torch", ".", "full", "(", "(", "num_proposals_i", ",", ")", ",", "level_id", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", ")", "\n", "\n", "# 2. Concat all levels together", "\n", "", "topk_scores", "=", "cat", "(", "topk_scores", ",", "dim", "=", "1", ")", "\n", "topk_proposals", "=", "cat", "(", "topk_proposals", ",", "dim", "=", "1", ")", "\n", "level_ids", "=", "cat", "(", "level_ids", ",", "dim", "=", "0", ")", "\n", "\n", "# 3. For each image, run a per-level NMS, and choose topk results.", "\n", "results", ":", "List", "[", "Instances", "]", "=", "[", "]", "\n", "for", "n", ",", "image_size", "in", "enumerate", "(", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "Boxes", "(", "topk_proposals", "[", "n", "]", ")", "\n", "scores_per_img", "=", "topk_scores", "[", "n", "]", "\n", "lvl", "=", "level_ids", "\n", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ".", "tensor", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores_per_img", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "            ", "if", "training", ":", "\n", "                ", "raise", "FloatingPointError", "(", "\n", "\"Predicted boxes or scores contain Inf/NaN. Training has diverged.\"", "\n", ")", "\n", "", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores_per_img", "=", "scores_per_img", "[", "valid_mask", "]", "\n", "lvl", "=", "lvl", "[", "valid_mask", "]", "\n", "", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "# filter empty boxes", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "if", "_is_tracing", "(", ")", "or", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "len", "(", "boxes", ")", ":", "\n", "            ", "boxes", ",", "scores_per_img", ",", "lvl", "=", "boxes", "[", "keep", "]", ",", "scores_per_img", "[", "keep", "]", ",", "lvl", "[", "keep", "]", "\n", "\n", "", "keep", "=", "batched_nms", "(", "boxes", ".", "tensor", ",", "scores_per_img", ",", "lvl", ",", "nms_thresh", ")", "\n", "# In Detectron1, there was different behavior during training vs. testing.", "\n", "# (https://github.com/facebookresearch/Detectron/issues/459)", "\n", "# During training, topk is over the proposals from *all* images in the training batch.", "\n", "# During testing, it is over the proposals for each image separately.", "\n", "# As a result, the training behavior becomes batch-dependent,", "\n", "# and the configuration \"POST_NMS_TOPK_TRAIN\" end up relying on the batch size.", "\n", "# This bug is addressed in Detectron2 to make the behavior independent of batch size.", "\n", "keep", "=", "keep", "[", ":", "post_nms_topk", "]", "# keep is already sorted", "\n", "\n", "res", "=", "Instances", "(", "image_size", ")", "\n", "res", ".", "proposal_boxes", "=", "boxes", "[", "keep", "]", "\n", "res", ".", "objectness_logits", "=", "scores_per_img", "[", "keep", "]", "\n", "results", ".", "append", "(", "res", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.add_ground_truth_to_proposals": [[133, 156], ["len", "len", "len", "proposal_utils.add_ground_truth_to_proposals_single_image", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.add_ground_truth_to_proposals_single_image"], ["", "def", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", ":", "\n", "    ", "\"\"\"\n    Call `add_ground_truth_to_proposals_single_image` for all images.\n\n    Args:\n        gt_boxes(list[Boxes]): list of N elements. Element i is a Boxes\n            representing the gound-truth for image i.\n        proposals (list[Instances]): list of N elements. Element i is a Instances\n            representing the proposals for image i.\n\n    Returns:\n        list[Instances]: list of N Instances. Each is the proposals for the image,\n            with field \"proposal_boxes\" and \"objectness_logits\".\n    \"\"\"", "\n", "assert", "gt_boxes", "is", "not", "None", "\n", "\n", "assert", "len", "(", "proposals", ")", "==", "len", "(", "gt_boxes", ")", "\n", "if", "len", "(", "proposals", ")", "==", "0", ":", "\n", "        ", "return", "proposals", "\n", "\n", "", "return", "[", "\n", "add_ground_truth_to_proposals_single_image", "(", "gt_boxes_i", ",", "proposals_i", ")", "\n", "for", "gt_boxes_i", ",", "proposals_i", "in", "zip", "(", "gt_boxes", ",", "proposals", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.add_ground_truth_to_proposals_single_image": [[159, 183], ["math.log", "detectron2.structures.Instances", "detectron2.structures.Instances.cat", "torch.ones", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "add_ground_truth_to_proposals_single_image", "(", "gt_boxes", ",", "proposals", ")", ":", "\n", "    ", "\"\"\"\n    Augment `proposals` with ground-truth boxes from `gt_boxes`.\n\n    Args:\n        Same as `add_ground_truth_to_proposals`, but with gt_boxes and proposals\n        per image.\n\n    Returns:\n        Same as `add_ground_truth_to_proposals`, but for only one image.\n    \"\"\"", "\n", "device", "=", "proposals", ".", "objectness_logits", ".", "device", "\n", "# Assign all ground-truth boxes an objectness logit corresponding to", "\n", "# P(object) = sigmoid(logit) =~ 1.", "\n", "gt_logit_value", "=", "math", ".", "log", "(", "(", "1.0", "-", "1e-10", ")", "/", "(", "1", "-", "(", "1.0", "-", "1e-10", ")", ")", ")", "\n", "gt_logits", "=", "gt_logit_value", "*", "torch", ".", "ones", "(", "len", "(", "gt_boxes", ")", ",", "device", "=", "device", ")", "\n", "\n", "# Concatenating gt_boxes with proposals requires them to have the same fields", "\n", "gt_proposal", "=", "Instances", "(", "proposals", ".", "image_size", ")", "\n", "gt_proposal", ".", "proposal_boxes", "=", "gt_boxes", "\n", "gt_proposal", ".", "objectness_logits", "=", "gt_logits", "\n", "new_proposals", "=", "Instances", ".", "cat", "(", "[", "proposals", ",", "gt_proposal", "]", ")", "\n", "\n", "return", "new_proposals", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead.__init__": [[75, 125], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "rpn.StandardRPNHead.modules", "len", "rpn.StandardRPNHead._get_rpn_conv", "torch.nn.Sequential", "torch.nn.Sequential", "enumerate", "isinstance", "rpn.StandardRPNHead._get_rpn_conv", "rpn.StandardRPNHead.conv.add_module", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead._get_rpn_conv", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead._get_rpn_conv"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "*", ",", "in_channels", ":", "int", ",", "num_anchors", ":", "int", ",", "box_dim", ":", "int", "=", "4", ",", "conv_dims", ":", "List", "[", "int", "]", "=", "(", "-", "1", ",", ")", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            in_channels (int): number of input feature channels. When using multiple\n                input features, they must have the same number of channels.\n            num_anchors (int): number of anchors to predict for *each spatial position*\n                on the feature map. The total number of anchors for each\n                feature map will be `num_anchors * H * W`.\n            box_dim (int): dimension of a box, which is also the number of box regression\n                predictions to make for each anchor. An axis aligned box has\n                box_dim=4, while a rotated box has box_dim=5.\n            conv_dims (list[int]): a list of integers representing the output channels\n                of N conv layers. Set it to -1 to use the same number of output channels\n                as input channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "cur_channels", "=", "in_channels", "\n", "# Keeping the old variable names and structure for backwards compatiblity.", "\n", "# Otherwise the old checkpoints will fail to load.", "\n", "if", "len", "(", "conv_dims", ")", "==", "1", ":", "\n", "            ", "out_channels", "=", "cur_channels", "if", "conv_dims", "[", "0", "]", "==", "-", "1", "else", "conv_dims", "[", "0", "]", "\n", "# 3x3 conv for the hidden representation", "\n", "self", ".", "conv", "=", "self", ".", "_get_rpn_conv", "(", "cur_channels", ",", "out_channels", ")", "\n", "cur_channels", "=", "out_channels", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "k", ",", "conv_dim", "in", "enumerate", "(", "conv_dims", ")", ":", "\n", "                ", "out_channels", "=", "cur_channels", "if", "conv_dim", "==", "-", "1", "else", "conv_dim", "\n", "if", "out_channels", "<=", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f\"Conv output channels should be greater than 0. Got {out_channels}\"", "\n", ")", "\n", "", "conv", "=", "self", ".", "_get_rpn_conv", "(", "cur_channels", ",", "out_channels", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "f\"conv{k}\"", ",", "conv", ")", "\n", "cur_channels", "=", "out_channels", "\n", "# 1x1 conv for predicting objectness logits", "\n", "", "", "self", ".", "objectness_logits", "=", "nn", ".", "Conv2d", "(", "cur_channels", ",", "num_anchors", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "# 1x1 conv for predicting box2box transform deltas", "\n", "self", ".", "anchor_deltas", "=", "nn", ".", "Conv2d", "(", "cur_channels", ",", "num_anchors", "*", "box_dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "# Keeping the order of weights initialization same for backwards compatiblility.", "\n", "for", "layer", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead._get_rpn_conv": [[126, 134], ["detectron2.layers.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["None"], ["", "", "", "def", "_get_rpn_conv", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "return", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead.from_config": [[136, 156], ["anchor_generator.build_anchor_generator.build_anchor_generator", "len", "len", "set", "set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# Standard RPN is shared across levels:", "\n", "        ", "in_channels", "=", "[", "s", ".", "channels", "for", "s", "in", "input_shape", "]", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "\"Each level must have the same channel!\"", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "# RPNHead should take the same input as anchor generator", "\n", "# NOTE: it assumes that creating an anchor generator does not have unwanted side effect.", "\n", "anchor_generator", "=", "build_anchor_generator", "(", "cfg", ",", "input_shape", ")", "\n", "num_anchors", "=", "anchor_generator", ".", "num_anchors", "\n", "box_dim", "=", "anchor_generator", ".", "box_dim", "\n", "assert", "(", "\n", "len", "(", "set", "(", "num_anchors", ")", ")", "==", "1", "\n", ")", ",", "\"Each level must have the same number of anchors per spatial position\"", "\n", "return", "{", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"num_anchors\"", ":", "num_anchors", "[", "0", "]", ",", "\n", "\"box_dim\"", ":", "box_dim", ",", "\n", "\"conv_dims\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "CONV_DIMS", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.StandardRPNHead.forward": [[158, 178], ["rpn.StandardRPNHead.conv", "pred_objectness_logits.append", "pred_anchor_deltas.append", "rpn.StandardRPNHead.objectness_logits", "rpn.StandardRPNHead.anchor_deltas"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features (list[Tensor]): list of feature maps\n\n        Returns:\n            list[Tensor]: A list of L elements.\n                Element i is a tensor of shape (N, A, Hi, Wi) representing\n                the predicted objectness logits for all anchors. A is the number of cell anchors.\n            list[Tensor]: A list of L elements. Element i is a tensor of shape\n                (N, A*box_dim, Hi, Wi) representing the predicted \"deltas\" used to transform anchors\n                to proposals.\n        \"\"\"", "\n", "pred_objectness_logits", "=", "[", "]", "\n", "pred_anchor_deltas", "=", "[", "]", "\n", "for", "x", "in", "features", ":", "\n", "            ", "t", "=", "self", ".", "conv", "(", "x", ")", "\n", "pred_objectness_logits", ".", "append", "(", "self", ".", "objectness_logits", "(", "t", ")", ")", "\n", "pred_anchor_deltas", ".", "append", "(", "self", ".", "anchor_deltas", "(", "t", ")", ")", "\n", "", "return", "pred_objectness_logits", ",", "pred_anchor_deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.__init__": [[186, 257], ["torch.nn.Module.__init__", "float", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "in_features", ":", "List", "[", "str", "]", ",", "\n", "head", ":", "nn", ".", "Module", ",", "\n", "anchor_generator", ":", "nn", ".", "Module", ",", "\n", "anchor_matcher", ":", "Matcher", ",", "\n", "box2box_transform", ":", "Box2BoxTransform", ",", "\n", "batch_size_per_image", ":", "int", ",", "\n", "positive_fraction", ":", "float", ",", "\n", "pre_nms_topk", ":", "Tuple", "[", "float", ",", "float", "]", ",", "\n", "post_nms_topk", ":", "Tuple", "[", "float", ",", "float", "]", ",", "\n", "nms_thresh", ":", "float", "=", "0.7", ",", "\n", "min_box_size", ":", "float", "=", "0.0", ",", "\n", "anchor_boundary_thresh", ":", "float", "=", "-", "1.0", ",", "\n", "loss_weight", ":", "Union", "[", "float", ",", "Dict", "[", "str", ",", "float", "]", "]", "=", "1.0", ",", "\n", "box_reg_loss_type", ":", "str", "=", "\"smooth_l1\"", ",", "\n", "smooth_l1_beta", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            in_features (list[str]): list of names of input features to use\n            head (nn.Module): a module that predicts logits and regression deltas\n                for each level from a list of per-level features\n            anchor_generator (nn.Module): a module that creates anchors from a\n                list of features. Usually an instance of :class:`AnchorGenerator`\n            anchor_matcher (Matcher): label the anchors by matching them with ground truth.\n            box2box_transform (Box2BoxTransform): defines the transform from anchors boxes to\n                instance boxes\n            batch_size_per_image (int): number of anchors per image to sample for training\n            positive_fraction (float): fraction of foreground anchors to sample for training\n            pre_nms_topk (tuple[float]): (train, test) that represents the\n                number of top k proposals to select before NMS, in\n                training and testing.\n            post_nms_topk (tuple[float]): (train, test) that represents the\n                number of top k proposals to select after NMS, in\n                training and testing.\n            nms_thresh (float): NMS threshold used to de-duplicate the predicted proposals\n            min_box_size (float): remove proposal boxes with any side smaller than this threshold,\n                in the unit of input image pixels\n            anchor_boundary_thresh (float): legacy option\n            loss_weight (float|dict): weights to use for losses. Can be single float for weighting\n                all rpn losses together, or a dict of individual weightings. Valid dict keys are:\n                    \"loss_rpn_cls\" - applied to classification loss\n                    \"loss_rpn_loc\" - applied to box regression loss\n            box_reg_loss_type (str): Loss type to use. Supported losses: \"smooth_l1\", \"giou\".\n            smooth_l1_beta (float): beta parameter for the smooth L1 regression loss. Default to\n                use L1 loss. Only used when `box_reg_loss_type` is \"smooth_l1\"\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "rpn_head", "=", "head", "\n", "self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "anchor_matcher", "=", "anchor_matcher", "\n", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "batch_size_per_image", "=", "batch_size_per_image", "\n", "self", ".", "positive_fraction", "=", "positive_fraction", "\n", "# Map from self.training state to train/test settings", "\n", "self", ".", "pre_nms_topk", "=", "{", "True", ":", "pre_nms_topk", "[", "0", "]", ",", "False", ":", "pre_nms_topk", "[", "1", "]", "}", "\n", "self", ".", "post_nms_topk", "=", "{", "True", ":", "post_nms_topk", "[", "0", "]", ",", "False", ":", "post_nms_topk", "[", "1", "]", "}", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_box_size", "=", "float", "(", "min_box_size", ")", "\n", "self", ".", "anchor_boundary_thresh", "=", "anchor_boundary_thresh", "\n", "if", "isinstance", "(", "loss_weight", ",", "float", ")", ":", "\n", "            ", "loss_weight", "=", "{", "\"loss_rpn_cls\"", ":", "loss_weight", ",", "\"loss_rpn_loc\"", ":", "loss_weight", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.from_config": [[258, 286], ["anchor_generator.build_anchor_generator", "matcher.Matcher", "rpn.build_rpn_head", "box_regression.Box2BoxTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.build_rpn_head"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "IN_FEATURES", "\n", "ret", "=", "{", "\n", "\"in_features\"", ":", "in_features", ",", "\n", "\"min_box_size\"", ":", "cfg", ".", "MODEL", ".", "PROPOSAL_GENERATOR", ".", "MIN_SIZE", ",", "\n", "\"nms_thresh\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", ",", "\n", "\"batch_size_per_image\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "\n", "\"positive_fraction\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", ",", "\n", "\"loss_weight\"", ":", "{", "\n", "\"loss_rpn_cls\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "LOSS_WEIGHT", ",", "\n", "\"loss_rpn_loc\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_LOSS_WEIGHT", "*", "cfg", ".", "MODEL", ".", "RPN", ".", "LOSS_WEIGHT", ",", "\n", "}", ",", "\n", "\"anchor_boundary_thresh\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "BOUNDARY_THRESH", ",", "\n", "\"box2box_transform\"", ":", "Box2BoxTransform", "(", "weights", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_WEIGHTS", ")", ",", "\n", "\"box_reg_loss_type\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_LOSS_TYPE", ",", "\n", "\"smooth_l1_beta\"", ":", "cfg", ".", "MODEL", ".", "RPN", ".", "SMOOTH_L1_BETA", ",", "\n", "}", "\n", "\n", "ret", "[", "\"pre_nms_topk\"", "]", "=", "(", "cfg", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOPK_TRAIN", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOPK_TEST", ")", "\n", "ret", "[", "\"post_nms_topk\"", "]", "=", "(", "cfg", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOPK_TRAIN", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOPK_TEST", ")", "\n", "\n", "ret", "[", "\"anchor_generator\"", "]", "=", "build_anchor_generator", "(", "cfg", ",", "[", "input_shape", "[", "f", "]", "for", "f", "in", "in_features", "]", ")", "\n", "ret", "[", "\"anchor_matcher\"", "]", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "IOU_THRESHOLDS", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "IOU_LABELS", ",", "allow_low_quality_matches", "=", "True", "\n", ")", "\n", "ret", "[", "\"head\"", "]", "=", "build_rpn_head", "(", "cfg", ",", "[", "input_shape", "[", "f", "]", "for", "f", "in", "in_features", "]", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._subsample_labels": [[287, 304], ["sampling.subsample_labels", "label.fill_", "label.scatter_", "label.scatter_"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.sampling.subsample_labels"], ["", "def", "_subsample_labels", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        Randomly sample a subset of positive and negative examples, and overwrite\n        the label vector to the ignore value (-1) for all elements that are not\n        included in the sample.\n\n        Args:\n            labels (Tensor): a vector of -1, 0, 1. Will be modified in-place and returned.\n        \"\"\"", "\n", "pos_idx", ",", "neg_idx", "=", "subsample_labels", "(", "\n", "label", ",", "self", ".", "batch_size_per_image", ",", "self", ".", "positive_fraction", ",", "0", "\n", ")", "\n", "# Fill with the ignore label (-1), then set positive and negative labels", "\n", "label", ".", "fill_", "(", "-", "1", ")", "\n", "label", ".", "scatter_", "(", "0", ",", "pos_idx", ",", "1", ")", "\n", "label", ".", "scatter_", "(", "0", ",", "neg_idx", ",", "0", ")", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.label_and_sample_anchors": [[305, 364], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "detectron2.structures.Boxes.cat", "zip", "rpn.RPN.to", "rpn.RPN._subsample_labels", "gt_labels.append", "matched_gt_boxes.append", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.structures.Boxes.cat.inside_box", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._subsample_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.inside_box"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_anchors", "(", "\n", "self", ",", "anchors", ":", "List", "[", "Boxes", "]", ",", "gt_instances", ":", "List", "[", "Instances", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "List", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[Boxes]): anchors for each feature map.\n            gt_instances: the ground-truth instances for each image.\n\n        Returns:\n            list[Tensor]:\n                List of #img tensors. i-th element is a vector of labels whose length is\n                the total number of anchors across all feature maps R = sum(Hi * Wi * A).\n                Label values are in {-1, 0, 1}, with meanings: -1 = ignore; 0 = negative\n                class; 1 = positive class.\n            list[Tensor]:\n                i-th element is a Rx4 tensor. The values are the matched gt boxes for each\n                anchor. Values are undefined for those anchors not labeled as 1.\n        \"\"\"", "\n", "anchors", "=", "Boxes", ".", "cat", "(", "anchors", ")", "\n", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "gt_instances", "]", "\n", "image_sizes", "=", "[", "x", ".", "image_size", "for", "x", "in", "gt_instances", "]", "\n", "del", "gt_instances", "\n", "\n", "gt_labels", "=", "[", "]", "\n", "matched_gt_boxes", "=", "[", "]", "\n", "for", "image_size_i", ",", "gt_boxes_i", "in", "zip", "(", "image_sizes", ",", "gt_boxes", ")", ":", "\n", "            ", "\"\"\"\n            image_size_i: (h, w) for the i-th image\n            gt_boxes_i: ground-truth boxes for i-th image\n            \"\"\"", "\n", "\n", "match_quality_matrix", "=", "retry_if_cuda_oom", "(", "pairwise_iou", ")", "(", "gt_boxes_i", ",", "anchors", ")", "\n", "matched_idxs", ",", "gt_labels_i", "=", "retry_if_cuda_oom", "(", "self", ".", "anchor_matcher", ")", "(", "match_quality_matrix", ")", "\n", "# Matching is memory-expensive and may result in CPU tensors. But the result is small", "\n", "gt_labels_i", "=", "gt_labels_i", ".", "to", "(", "device", "=", "gt_boxes_i", ".", "device", ")", "\n", "del", "match_quality_matrix", "\n", "\n", "if", "self", ".", "anchor_boundary_thresh", ">=", "0", ":", "\n", "# Discard anchors that go out of the boundaries of the image", "\n", "# NOTE: This is legacy functionality that is turned off by default in Detectron2", "\n", "                ", "anchors_inside_image", "=", "anchors", ".", "inside_box", "(", "image_size_i", ",", "self", ".", "anchor_boundary_thresh", ")", "\n", "gt_labels_i", "[", "~", "anchors_inside_image", "]", "=", "-", "1", "\n", "\n", "# A vector of labels (-1, 0, 1) for each anchor", "\n", "", "gt_labels_i", "=", "self", ".", "_subsample_labels", "(", "gt_labels_i", ")", "\n", "\n", "if", "len", "(", "gt_boxes_i", ")", "==", "0", ":", "\n", "# These values won't be used anyway since the anchor is labeled as background", "\n", "                ", "matched_gt_boxes_i", "=", "torch", ".", "zeros_like", "(", "anchors", ".", "tensor", ")", "\n", "", "else", ":", "\n", "# TODO wasted indexing computation for ignored boxes", "\n", "                ", "matched_gt_boxes_i", "=", "gt_boxes_i", "[", "matched_idxs", "]", ".", "tensor", "\n", "\n", "", "gt_labels", ".", "append", "(", "gt_labels_i", ")", "# N,AHW", "\n", "matched_gt_boxes", ".", "append", "(", "matched_gt_boxes_i", ")", "\n", "", "return", "gt_labels", ",", "matched_gt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.losses": [[365, 430], ["len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pos_mask.sum().item", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "box_regression._dense_box_regression_loss", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "gt_labels[].to", "pos_mask.sum", "detectron2.layers.cat", "rpn.RPN.loss_weight.get", "losses.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression._dense_box_regression_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "losses", "(", "\n", "self", ",", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "pred_objectness_logits", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "gt_labels", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "pred_anchor_deltas", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "gt_boxes", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Return the losses from a set of RPN predictions and their associated ground-truth.\n\n        Args:\n            anchors (list[Boxes or RotatedBoxes]): anchors for each feature map, each\n                has shape (Hi*Wi*A, B), where B is box dimension (4 or 5).\n            pred_objectness_logits (list[Tensor]): A list of L elements.\n                Element i is a tensor of shape (N, Hi*Wi*A) representing\n                the predicted objectness logits for all anchors.\n            gt_labels (list[Tensor]): Output of :meth:`label_and_sample_anchors`.\n            pred_anchor_deltas (list[Tensor]): A list of L elements. Element i is a tensor of shape\n                (N, Hi*Wi*A, 4 or 5) representing the predicted \"deltas\" used to transform anchors\n                to proposals.\n            gt_boxes (list[Tensor]): Output of :meth:`label_and_sample_anchors`.\n\n        Returns:\n            dict[loss name -> loss value]: A dict mapping from loss name to loss value.\n                Loss names are: `loss_rpn_cls` for objectness classification and\n                `loss_rpn_loc` for proposal localization.\n        \"\"\"", "\n", "num_images", "=", "len", "(", "gt_labels", ")", "\n", "gt_labels", "=", "torch", ".", "stack", "(", "gt_labels", ")", "# (N, sum(Hi*Wi*Ai))", "\n", "\n", "# Log the number of positive/negative anchors per-image that's used in training", "\n", "pos_mask", "=", "gt_labels", "==", "1", "\n", "num_pos_anchors", "=", "pos_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_neg_anchors", "=", "(", "gt_labels", "==", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"rpn/num_pos_anchors\"", ",", "num_pos_anchors", "/", "num_images", ")", "\n", "storage", ".", "put_scalar", "(", "\"rpn/num_neg_anchors\"", ",", "num_neg_anchors", "/", "num_images", ")", "\n", "\n", "localization_loss", "=", "_dense_box_regression_loss", "(", "\n", "anchors", ",", "\n", "self", ".", "box2box_transform", ",", "\n", "pred_anchor_deltas", ",", "\n", "gt_boxes", ",", "\n", "pos_mask", ",", "\n", "box_reg_loss_type", "=", "self", ".", "box_reg_loss_type", ",", "\n", "smooth_l1_beta", "=", "self", ".", "smooth_l1_beta", ",", "\n", ")", "\n", "\n", "valid_mask", "=", "gt_labels", ">=", "0", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "cat", "(", "pred_objectness_logits", ",", "dim", "=", "1", ")", "[", "valid_mask", "]", ",", "\n", "gt_labels", "[", "valid_mask", "]", ".", "to", "(", "torch", ".", "float32", ")", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "normalizer", "=", "self", ".", "batch_size_per_image", "*", "num_images", "\n", "losses", "=", "{", "\n", "\"loss_rpn_cls\"", ":", "objectness_loss", "/", "normalizer", ",", "\n", "# The original Faster R-CNN paper uses a slightly different normalizer", "\n", "# for loc loss. But it doesn't matter in practice", "\n", "\"loss_rpn_loc\"", ":", "localization_loss", "/", "normalizer", ",", "\n", "}", "\n", "losses", "=", "{", "k", ":", "v", "*", "self", ".", "loss_weight", ".", "get", "(", "k", ",", "1.0", ")", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", "}", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.forward": [[431, 481], ["rpn.RPN.anchor_generator", "rpn.RPN.rpn_head", "rpn.RPN.predict_proposals", "score.permute().flatten", "x.view().permute().flatten", "rpn.RPN.label_and_sample_anchors", "rpn.RPN.losses", "score.permute", "x.view().permute", "x.view"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.predict_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.label_and_sample_anchors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "gt_instances", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            images (ImageList): input images of length `N`\n            features (dict[str, Tensor]): input data as a mapping from feature\n                map name to tensor. Axis 0 represents the number of images `N` in\n                the input data; axes 1-3 are channels, height, and width, which may\n                vary between feature maps (e.g., if a feature pyramid is used).\n            gt_instances (list[Instances], optional): a length `N` list of `Instances`s.\n                Each `Instances` stores ground-truth instances for the corresponding image.\n\n        Returns:\n            proposals: list[Instances]: contains fields \"proposal_boxes\", \"objectness_logits\"\n            loss: dict[Tensor] or None\n        \"\"\"", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "features", ")", "\n", "\n", "pred_objectness_logits", ",", "pred_anchor_deltas", "=", "self", ".", "rpn_head", "(", "features", ")", "\n", "# Transpose the Hi*Wi*A dimension to the middle:", "\n", "pred_objectness_logits", "=", "[", "\n", "# (N, A, Hi, Wi) -> (N, Hi, Wi, A) -> (N, Hi*Wi*A)", "\n", "score", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ")", "\n", "for", "score", "in", "pred_objectness_logits", "\n", "]", "\n", "pred_anchor_deltas", "=", "[", "\n", "# (N, A*B, Hi, Wi) -> (N, A, B, Hi, Wi) -> (N, Hi, Wi, A, B) -> (N, Hi*Wi*A, B)", "\n", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "self", ".", "anchor_generator", ".", "box_dim", ",", "x", ".", "shape", "[", "-", "2", "]", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "2", ")", "\n", ".", "flatten", "(", "1", ",", "-", "2", ")", "\n", "for", "x", "in", "pred_anchor_deltas", "\n", "]", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "assert", "gt_instances", "is", "not", "None", ",", "\"RPN requires gt_instances in training!\"", "\n", "gt_labels", ",", "gt_boxes", "=", "self", ".", "label_and_sample_anchors", "(", "anchors", ",", "gt_instances", ")", "\n", "losses", "=", "self", ".", "losses", "(", "\n", "anchors", ",", "pred_objectness_logits", ",", "gt_labels", ",", "pred_anchor_deltas", ",", "gt_boxes", "\n", ")", "\n", "", "else", ":", "\n", "            ", "losses", "=", "{", "}", "\n", "", "proposals", "=", "self", ".", "predict_proposals", "(", "\n", "anchors", ",", "pred_objectness_logits", ",", "pred_anchor_deltas", ",", "images", ".", "image_sizes", "\n", ")", "\n", "return", "proposals", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN.predict_proposals": [[482, 512], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "rpn.RPN._decode_proposals", "proposal_utils.find_top_rpn_proposals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._decode_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.find_top_rpn_proposals"], ["", "def", "predict_proposals", "(", "\n", "self", ",", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "pred_objectness_logits", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "pred_anchor_deltas", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "image_sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Decode all the predicted box regression deltas to proposals. Find the top proposals\n        by applying NMS and removing boxes that are too small.\n\n        Returns:\n            proposals (list[Instances]): list of N Instances. The i-th Instances\n                stores post_nms_topk object proposals for image i, sorted by their\n                objectness score in descending order.\n        \"\"\"", "\n", "# The proposals are treated as fixed for joint training with roi heads.", "\n", "# This approach ignores the derivative w.r.t. the proposal boxes\u2019 coordinates that", "\n", "# are also network responses.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_proposals", "=", "self", ".", "_decode_proposals", "(", "anchors", ",", "pred_anchor_deltas", ")", "\n", "return", "find_top_rpn_proposals", "(", "\n", "pred_proposals", ",", "\n", "pred_objectness_logits", ",", "\n", "image_sizes", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "self", ".", "pre_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "min_box_size", ",", "\n", "self", ".", "training", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._decode_proposals": [[514, 534], ["zip", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.size", "pred_anchor_deltas_i.reshape.reshape.reshape", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape", "rpn.RPN.box2box_transform.apply_deltas", "proposals.append", "rpn.RPN.view", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "", "def", "_decode_proposals", "(", "self", ",", "anchors", ":", "List", "[", "Boxes", "]", ",", "pred_anchor_deltas", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Transform anchors into proposals by applying the predicted anchor deltas.\n\n        Returns:\n            proposals (list[Tensor]): A list of L tensors. Tensor i has shape\n                (N, Hi*Wi*A, B)\n        \"\"\"", "\n", "N", "=", "pred_anchor_deltas", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "proposals", "=", "[", "]", "\n", "# For each feature map", "\n", "for", "anchors_i", ",", "pred_anchor_deltas_i", "in", "zip", "(", "anchors", ",", "pred_anchor_deltas", ")", ":", "\n", "            ", "B", "=", "anchors_i", ".", "tensor", ".", "size", "(", "1", ")", "\n", "pred_anchor_deltas_i", "=", "pred_anchor_deltas_i", ".", "reshape", "(", "-", "1", ",", "B", ")", "\n", "# Expand anchors to shape (N*Hi*Wi*A, B)", "\n", "anchors_i", "=", "anchors_i", ".", "tensor", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "N", ",", "-", "1", ",", "-", "1", ")", ".", "reshape", "(", "-", "1", ",", "B", ")", "\n", "proposals_i", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "pred_anchor_deltas_i", ",", "anchors_i", ")", "\n", "# Append feature map proposals with shape (N, Hi*Wi*A, B)", "\n", "proposals", ".", "append", "(", "proposals_i", ".", "view", "(", "N", ",", "-", "1", ",", "B", ")", ")", "\n", "", "return", "proposals", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.build_rpn_head": [[58, 64], ["RPN_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "build_rpn_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build an RPN head defined by `cfg.MODEL.RPN.HEAD_NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "HEAD_NAME", "\n", "return", "RPN_HEAD_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.__init__": [[130, 136], ["rpn.RPN.__init__", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "anchor_boundary_thresh", ">=", "0", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"anchor_boundary_thresh is a legacy option not implemented for RRPN.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.from_config": [[138, 143], ["super().from_config", "box_regression.Box2BoxTransformRotated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", "[", "\"box2box_transform\"", "]", "=", "Box2BoxTransformRotated", "(", "weights", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_WEIGHTS", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.label_and_sample_anchors": [[144, 190], ["torch.no_grad", "detectron2.structures.RotatedBoxes.cat", "rrpn.RRPN.to", "rrpn.RRPN._subsample_labels", "gt_labels.append", "matched_gt_boxes.append", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.utils.memory.retry_if_cuda_oom", "len", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._subsample_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.memory.retry_if_cuda_oom"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_anchors", "(", "self", ",", "anchors", ":", "List", "[", "RotatedBoxes", "]", ",", "gt_instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[RotatedBoxes]): anchors for each feature map.\n            gt_instances: the ground-truth instances for each image.\n\n        Returns:\n            list[Tensor]:\n                List of #img tensors. i-th element is a vector of labels whose length is\n                the total number of anchors across feature maps. Label values are in {-1, 0, 1},\n                with meanings: -1 = ignore; 0 = negative class; 1 = positive class.\n            list[Tensor]:\n                i-th element is a Nx5 tensor, where N is the total number of anchors across\n                feature maps.  The values are the matched gt boxes for each anchor.\n                Values are undefined for those anchors not labeled as 1.\n        \"\"\"", "\n", "anchors", "=", "RotatedBoxes", ".", "cat", "(", "anchors", ")", "\n", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "gt_instances", "]", "\n", "del", "gt_instances", "\n", "\n", "gt_labels", "=", "[", "]", "\n", "matched_gt_boxes", "=", "[", "]", "\n", "for", "gt_boxes_i", "in", "gt_boxes", ":", "\n", "            ", "\"\"\"\n            gt_boxes_i: ground-truth boxes for i-th image\n            \"\"\"", "\n", "match_quality_matrix", "=", "retry_if_cuda_oom", "(", "pairwise_iou_rotated", ")", "(", "gt_boxes_i", ",", "anchors", ")", "\n", "matched_idxs", ",", "gt_labels_i", "=", "retry_if_cuda_oom", "(", "self", ".", "anchor_matcher", ")", "(", "match_quality_matrix", ")", "\n", "# Matching is memory-expensive and may result in CPU tensors. But the result is small", "\n", "gt_labels_i", "=", "gt_labels_i", ".", "to", "(", "device", "=", "gt_boxes_i", ".", "device", ")", "\n", "\n", "# A vector of labels (-1, 0, 1) for each anchor", "\n", "gt_labels_i", "=", "self", ".", "_subsample_labels", "(", "gt_labels_i", ")", "\n", "\n", "if", "len", "(", "gt_boxes_i", ")", "==", "0", ":", "\n", "# These values won't be used anyway since the anchor is labeled as background", "\n", "                ", "matched_gt_boxes_i", "=", "torch", ".", "zeros_like", "(", "anchors", ".", "tensor", ")", "\n", "", "else", ":", "\n", "# TODO wasted indexing computation for ignored boxes", "\n", "                ", "matched_gt_boxes_i", "=", "gt_boxes_i", "[", "matched_idxs", "]", ".", "tensor", "\n", "\n", "", "gt_labels", ".", "append", "(", "gt_labels_i", ")", "# N,AHW", "\n", "matched_gt_boxes", ".", "append", "(", "matched_gt_boxes_i", ")", "\n", "", "return", "gt_labels", ",", "matched_gt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.RRPN.predict_proposals": [[191, 203], ["torch.no_grad", "rrpn.RRPN._decode_proposals", "rrpn.find_top_rrpn_proposals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rpn.RPN._decode_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.find_top_rrpn_proposals"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict_proposals", "(", "self", ",", "anchors", ",", "pred_objectness_logits", ",", "pred_anchor_deltas", ",", "image_sizes", ")", ":", "\n", "        ", "pred_proposals", "=", "self", ".", "_decode_proposals", "(", "anchors", ",", "pred_anchor_deltas", ")", "\n", "return", "find_top_rrpn_proposals", "(", "\n", "pred_proposals", ",", "\n", "pred_objectness_logits", ",", "\n", "image_sizes", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "self", ".", "pre_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "min_box_size", ",", "\n", "self", ".", "training", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.rrpn.find_top_rrpn_proposals": [[19, 122], ["len", "torch.arange", "zip", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "enumerate", "itertools.count", "min", "logits_i.sort", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes.clip", "detectron2.structures.RotatedBoxes.nonempty", "detectron2.layers.batched_nms_rotated", "detectron2.structures.Instances", "results.append", "torch.full", "torch.isfinite().all", "torch.isfinite", "valid_mask.all", "detectron2.layers.batched_nms_rotated.sum().item", "len", "torch.isfinite", "detectron2.layers.batched_nms_rotated.sum"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms_rotated"], ["def", "find_top_rrpn_proposals", "(", "\n", "proposals", ",", "\n", "pred_objectness_logits", ",", "\n", "image_sizes", ",", "\n", "nms_thresh", ",", "\n", "pre_nms_topk", ",", "\n", "post_nms_topk", ",", "\n", "min_box_size", ",", "\n", "training", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    For each feature map, select the `pre_nms_topk` highest scoring proposals,\n    apply NMS, clip proposals, and remove small boxes. Return the `post_nms_topk`\n    highest scoring proposals among all the feature maps if `training` is True,\n    otherwise, returns the highest `post_nms_topk` scoring proposals for each\n    feature map.\n\n    Args:\n        proposals (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A, 5).\n            All proposal predictions on the feature maps.\n        pred_objectness_logits (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A).\n        image_sizes (list[tuple]): sizes (h, w) for each image\n        nms_thresh (float): IoU threshold to use for NMS\n        pre_nms_topk (int): number of top k scoring proposals to keep before applying NMS.\n            When RRPN is run on multiple feature maps (as in FPN) this number is per\n            feature map.\n        post_nms_topk (int): number of top k scoring proposals to keep after applying NMS.\n            When RRPN is run on multiple feature maps (as in FPN) this number is total,\n            over all feature maps.\n        min_box_size(float): minimum proposal box side length in pixels (absolute units wrt\n            input images).\n        training (bool): True if proposals are to be used in training, otherwise False.\n            This arg exists only to support a legacy bug; look for the \"NB: Legacy bug ...\"\n            comment.\n\n    Returns:\n        proposals (list[Instances]): list of N Instances. The i-th Instances\n            stores post_nms_topk object proposals for image i.\n    \"\"\"", "\n", "num_images", "=", "len", "(", "image_sizes", ")", "\n", "device", "=", "proposals", "[", "0", "]", ".", "device", "\n", "\n", "# 1. Select top-k anchor for every level and every image", "\n", "topk_scores", "=", "[", "]", "# #lvl Tensor, each of shape N x topk", "\n", "topk_proposals", "=", "[", "]", "\n", "level_ids", "=", "[", "]", "# #lvl Tensor, each of shape (topk,)", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "num_images", ",", "device", "=", "device", ")", "\n", "for", "level_id", ",", "proposals_i", ",", "logits_i", "in", "zip", "(", "\n", "itertools", ".", "count", "(", ")", ",", "proposals", ",", "pred_objectness_logits", "\n", ")", ":", "\n", "        ", "Hi_Wi_A", "=", "logits_i", ".", "shape", "[", "1", "]", "\n", "num_proposals_i", "=", "min", "(", "pre_nms_topk", ",", "Hi_Wi_A", ")", "\n", "\n", "# sort is faster than topk (https://github.com/pytorch/pytorch/issues/22812)", "\n", "# topk_scores_i, topk_idx = logits_i.topk(num_proposals_i, dim=1)", "\n", "logits_i", ",", "idx", "=", "logits_i", ".", "sort", "(", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "topk_scores_i", "=", "logits_i", "[", "batch_idx", ",", ":", "num_proposals_i", "]", "\n", "topk_idx", "=", "idx", "[", "batch_idx", ",", ":", "num_proposals_i", "]", "\n", "\n", "# each is N x topk", "\n", "topk_proposals_i", "=", "proposals_i", "[", "batch_idx", "[", ":", ",", "None", "]", ",", "topk_idx", "]", "# N x topk x 5", "\n", "\n", "topk_proposals", ".", "append", "(", "topk_proposals_i", ")", "\n", "topk_scores", ".", "append", "(", "topk_scores_i", ")", "\n", "level_ids", ".", "append", "(", "torch", ".", "full", "(", "(", "num_proposals_i", ",", ")", ",", "level_id", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", ")", "\n", "\n", "# 2. Concat all levels together", "\n", "", "topk_scores", "=", "cat", "(", "topk_scores", ",", "dim", "=", "1", ")", "\n", "topk_proposals", "=", "cat", "(", "topk_proposals", ",", "dim", "=", "1", ")", "\n", "level_ids", "=", "cat", "(", "level_ids", ",", "dim", "=", "0", ")", "\n", "\n", "# 3. For each image, run a per-level NMS, and choose topk results.", "\n", "results", "=", "[", "]", "\n", "for", "n", ",", "image_size", "in", "enumerate", "(", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "RotatedBoxes", "(", "topk_proposals", "[", "n", "]", ")", "\n", "scores_per_img", "=", "topk_scores", "[", "n", "]", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ".", "tensor", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores_per_img", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "            ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores_per_img", "=", "scores_per_img", "[", "valid_mask", "]", "\n", "", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "# filter empty boxes", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "lvl", "=", "level_ids", "\n", "if", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "len", "(", "boxes", ")", ":", "\n", "            ", "boxes", ",", "scores_per_img", ",", "lvl", "=", "(", "boxes", "[", "keep", "]", ",", "scores_per_img", "[", "keep", "]", ",", "level_ids", "[", "keep", "]", ")", "\n", "\n", "", "keep", "=", "batched_nms_rotated", "(", "boxes", ".", "tensor", ",", "scores_per_img", ",", "lvl", ",", "nms_thresh", ")", "\n", "# In Detectron1, there was different behavior during training vs. testing.", "\n", "# (https://github.com/facebookresearch/Detectron/issues/459)", "\n", "# During training, topk is over the proposals from *all* images in the training batch.", "\n", "# During testing, it is over the proposals for each image separately.", "\n", "# As a result, the training behavior becomes batch-dependent,", "\n", "# and the configuration \"POST_NMS_TOPK_TRAIN\" end up relying on the batch size.", "\n", "# This bug is addressed in Detectron2 to make the behavior independent of batch size.", "\n", "keep", "=", "keep", "[", ":", "post_nms_topk", "]", "\n", "\n", "res", "=", "Instances", "(", "image_size", ")", "\n", "res", ".", "proposal_boxes", "=", "boxes", "[", "keep", "]", "\n", "res", ".", "objectness_logits", "=", "scores_per_img", "[", "keep", "]", "\n", "results", ".", "append", "(", "res", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.build.build_proposal_generator": [[15, 25], ["PROPOSAL_GENERATOR_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["\n", "def", "build_model", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.\n    Note that it does not load any weights from ``cfg``.\n    \"\"\"", "\n", "meta_arch", "=", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "\n", "model", "=", "META_ARCH_REGISTRY", ".", "get", "(", "meta_arch", ")", "(", "cfg", ")", "\n", "model", ".", "to", "(", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", ")", "\n", "_log_api_usage", "(", "\"modeling.meta_arch.\"", "+", "meta_arch", ")", "\n", "return", "model", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.BaseMaskRCNNHead.__init__": [[160, 172], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", ",", "loss_weight", ":", "float", "=", "1.0", ",", "vis_period", ":", "int", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            loss_weight (float): multiplier of the loss\n            vis_period (int): visualization period\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vis_period", "=", "vis_period", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.BaseMaskRCNNHead.from_config": [[173, 176], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "return", "{", "\"vis_period\"", ":", "cfg", ".", "VIS_PERIOD", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.BaseMaskRCNNHead.forward": [[177, 197], ["mask_head.BaseMaskRCNNHead.layers", "mask_head.mask_rcnn_inference", "mask_head.mask_rcnn_loss"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.layers", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.mask_rcnn_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.mask_rcnn_loss"], ["", "def", "forward", "(", "self", ",", "x", ",", "instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: input region feature(s) provided by :class:`ROIHeads`.\n            instances (list[Instances]): contains the boxes & labels corresponding\n                to the input features.\n                Exact format is up to its caller to decide.\n                Typically, this is the foreground instances in training, with\n                \"proposal_boxes\" field and other gt annotations.\n                In inference, it contains boxes that are already predicted.\n\n        Returns:\n            A dict of losses in training. The predicted \"instances\" in inference.\n        \"\"\"", "\n", "x", "=", "self", ".", "layers", "(", "x", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "{", "\"loss_mask\"", ":", "mask_rcnn_loss", "(", "x", ",", "instances", ",", "self", ".", "vis_period", ")", "*", "self", ".", "loss_weight", "}", "\n", "", "else", ":", "\n", "            ", "mask_rcnn_inference", "(", "x", ",", "instances", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.BaseMaskRCNNHead.layers": [[198, 203], ["None"], "methods", ["None"], ["", "", "def", "layers", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Neural network layers that makes predictions from input features.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.MaskRCNNConvUpsampleHead.__init__": [[215, 264], ["super().__init__", "enumerate", "detectron2.layers.ConvTranspose2d", "mask_head.MaskRCNNConvUpsampleHead.add_module", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "len", "detectron2.layers.Conv2d", "mask_head.MaskRCNNConvUpsampleHead.add_module", "mask_head.MaskRCNNConvUpsampleHead.conv_norm_relus.append", "torch.nn.ReLU", "fvcore.c2_msra_fill", "torch.nn.init.constant_", "detectron2.layers.get_norm", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "input_shape", ":", "ShapeSpec", ",", "*", ",", "num_classes", ",", "conv_dims", ",", "conv_norm", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature\n            num_classes (int): the number of foreground classes (i.e. background is not\n                included). 1 if using class agnostic prediction.\n            conv_dims (list[int]): a list of N>0 integers representing the output dimensions\n                of N-1 conv layers and the last upsample layer.\n            conv_norm (str or callable): normalization for the conv layers.\n                See :func:`detectron2.layers.get_norm` for supported types.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "assert", "len", "(", "conv_dims", ")", ">=", "1", ",", "\"conv_dims have to be non-empty!\"", "\n", "\n", "self", ".", "conv_norm_relus", "=", "[", "]", "\n", "\n", "cur_channels", "=", "input_shape", ".", "channels", "\n", "for", "k", ",", "conv_dim", "in", "enumerate", "(", "conv_dims", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "conv", "=", "Conv2d", "(", "\n", "cur_channels", ",", "\n", "conv_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "conv_norm", ",", "\n", "norm", "=", "get_norm", "(", "conv_norm", ",", "conv_dim", ")", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "self", ".", "add_module", "(", "\"mask_fcn{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "conv", ")", "\n", "self", ".", "conv_norm_relus", ".", "append", "(", "conv", ")", "\n", "cur_channels", "=", "conv_dim", "\n", "\n", "", "self", ".", "deconv", "=", "ConvTranspose2d", "(", "\n", "cur_channels", ",", "conv_dims", "[", "-", "1", "]", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", "\n", ")", "\n", "self", ".", "add_module", "(", "\"deconv_relu\"", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "cur_channels", "=", "conv_dims", "[", "-", "1", "]", "\n", "\n", "self", ".", "predictor", "=", "Conv2d", "(", "cur_channels", ",", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "for", "layer", "in", "self", ".", "conv_norm_relus", "+", "[", "self", ".", "deconv", "]", ":", "\n", "            ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "# use normal distribution initialization for mask prediction layer", "\n", "", "nn", ".", "init", ".", "normal_", "(", "self", ".", "predictor", ".", "weight", ",", "std", "=", "0.001", ")", "\n", "if", "self", ".", "predictor", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "predictor", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.MaskRCNNConvUpsampleHead.from_config": [[265, 280], ["super().from_config", "super().from_config.update"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "conv_dim", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CONV_DIM", "\n", "num_conv", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NUM_CONV", "\n", "ret", ".", "update", "(", "\n", "conv_dims", "=", "[", "conv_dim", "]", "*", "(", "num_conv", "+", "1", ")", ",", "# +1 for ConvTranspose", "\n", "conv_norm", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NORM", ",", "\n", "input_shape", "=", "input_shape", ",", "\n", ")", "\n", "if", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CLS_AGNOSTIC_MASK", ":", "\n", "            ", "ret", "[", "\"num_classes\"", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "ret", "[", "\"num_classes\"", "]", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.MaskRCNNConvUpsampleHead.layers": [[281, 285], ["layer"], "methods", ["None"], ["", "def", "layers", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.mask_rcnn_loss": [[31, 112], ["pred_mask_logits.size", "pred_mask_logits.size", "detectron2.layers.cat", "gt_masks.to.to", "gt_masks_bool.sum().item", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "torch.nn.functional.binary_cross_entropy_with_logits", "pred_mask_logits.size", "pred_mask_logits.size", "pred_mask_logits.size", "instances_per_image.gt_masks.crop_and_resize().to", "gt_masks.to.append", "len", "torch.arange", "detectron2.layers.cat", "max", "max", "pred_mask_logits.sigmoid", "torch.cat", "enumerate", "len", "instances_per_image.gt_classes.to", "detectron2.layers.cat.append", "pred_mask_logits.sum", "mask_incorrect.sum().item", "max", "gt_masks_bool.sum", "torch.stack", "detectron2.utils.events.get_event_storage.put_image", "instances_per_image.gt_masks.crop_and_resize", "mask_incorrect.numel", "gt_masks_bool.numel", "mask_incorrect.sum"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize"], ["@", "torch", ".", "jit", ".", "unused", "\n", "def", "mask_rcnn_loss", "(", "pred_mask_logits", ":", "torch", ".", "Tensor", ",", "instances", ":", "List", "[", "Instances", "]", ",", "vis_period", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Compute the mask prediction loss defined in the Mask R-CNN paper.\n\n    Args:\n        pred_mask_logits (Tensor): A tensor of shape (B, C, Hmask, Wmask) or (B, 1, Hmask, Wmask)\n            for class-specific or class-agnostic, where B is the total number of predicted masks\n            in all images, C is the number of foreground classes, and Hmask, Wmask are the height\n            and width of the mask predictions. The values are logits.\n        instances (list[Instances]): A list of N Instances, where N is the number of images\n            in the batch. These instances are in 1:1\n            correspondence with the pred_mask_logits. The ground-truth labels (class, box, mask,\n            ...) associated with each instance are stored in fields.\n        vis_period (int): the period (in steps) to dump visualization.\n\n    Returns:\n        mask_loss (Tensor): A scalar tensor containing the loss.\n    \"\"\"", "\n", "cls_agnostic_mask", "=", "pred_mask_logits", ".", "size", "(", "1", ")", "==", "1", "\n", "total_num_masks", "=", "pred_mask_logits", ".", "size", "(", "0", ")", "\n", "mask_side_len", "=", "pred_mask_logits", ".", "size", "(", "2", ")", "\n", "assert", "pred_mask_logits", ".", "size", "(", "2", ")", "==", "pred_mask_logits", ".", "size", "(", "3", ")", ",", "\"Mask prediction must be square!\"", "\n", "\n", "gt_classes", "=", "[", "]", "\n", "gt_masks", "=", "[", "]", "\n", "for", "instances_per_image", "in", "instances", ":", "\n", "        ", "if", "len", "(", "instances_per_image", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "not", "cls_agnostic_mask", ":", "\n", "            ", "gt_classes_per_image", "=", "instances_per_image", ".", "gt_classes", ".", "to", "(", "dtype", "=", "torch", ".", "int64", ")", "\n", "gt_classes", ".", "append", "(", "gt_classes_per_image", ")", "\n", "\n", "", "gt_masks_per_image", "=", "instances_per_image", ".", "gt_masks", ".", "crop_and_resize", "(", "\n", "instances_per_image", ".", "proposal_boxes", ".", "tensor", ",", "mask_side_len", "\n", ")", ".", "to", "(", "device", "=", "pred_mask_logits", ".", "device", ")", "\n", "# A tensor of shape (N, M, M), N=#instances in the image; M=mask_side_len", "\n", "gt_masks", ".", "append", "(", "gt_masks_per_image", ")", "\n", "\n", "", "if", "len", "(", "gt_masks", ")", "==", "0", ":", "\n", "        ", "return", "pred_mask_logits", ".", "sum", "(", ")", "*", "0", "\n", "\n", "", "gt_masks", "=", "cat", "(", "gt_masks", ",", "dim", "=", "0", ")", "\n", "\n", "if", "cls_agnostic_mask", ":", "\n", "        ", "pred_mask_logits", "=", "pred_mask_logits", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "indices", "=", "torch", ".", "arange", "(", "total_num_masks", ")", "\n", "gt_classes", "=", "cat", "(", "gt_classes", ",", "dim", "=", "0", ")", "\n", "pred_mask_logits", "=", "pred_mask_logits", "[", "indices", ",", "gt_classes", "]", "\n", "\n", "", "if", "gt_masks", ".", "dtype", "==", "torch", ".", "bool", ":", "\n", "        ", "gt_masks_bool", "=", "gt_masks", "\n", "", "else", ":", "\n", "# Here we allow gt_masks to be float as well (depend on the implementation of rasterize())", "\n", "        ", "gt_masks_bool", "=", "gt_masks", ">", "0.5", "\n", "", "gt_masks", "=", "gt_masks", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Log the training accuracy (using gt classes and 0.5 threshold)", "\n", "mask_incorrect", "=", "(", "pred_mask_logits", ">", "0.0", ")", "!=", "gt_masks_bool", "\n", "mask_accuracy", "=", "1", "-", "(", "mask_incorrect", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "max", "(", "mask_incorrect", ".", "numel", "(", ")", ",", "1.0", ")", ")", "\n", "num_positive", "=", "gt_masks_bool", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "false_positive", "=", "(", "mask_incorrect", "&", "~", "gt_masks_bool", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "max", "(", "\n", "gt_masks_bool", ".", "numel", "(", ")", "-", "num_positive", ",", "1.0", "\n", ")", "\n", "false_negative", "=", "(", "mask_incorrect", "&", "gt_masks_bool", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "max", "(", "num_positive", ",", "1.0", ")", "\n", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"mask_rcnn/accuracy\"", ",", "mask_accuracy", ")", "\n", "storage", ".", "put_scalar", "(", "\"mask_rcnn/false_positive\"", ",", "false_positive", ")", "\n", "storage", ".", "put_scalar", "(", "\"mask_rcnn/false_negative\"", ",", "false_negative", ")", "\n", "if", "vis_period", ">", "0", "and", "storage", ".", "iter", "%", "vis_period", "==", "0", ":", "\n", "        ", "pred_masks", "=", "pred_mask_logits", ".", "sigmoid", "(", ")", "\n", "vis_masks", "=", "torch", ".", "cat", "(", "[", "pred_masks", ",", "gt_masks", "]", ",", "axis", "=", "2", ")", "\n", "name", "=", "\"Left: mask prediction;   Right: mask GT\"", "\n", "for", "idx", ",", "vis_mask", "in", "enumerate", "(", "vis_masks", ")", ":", "\n", "            ", "vis_mask", "=", "torch", ".", "stack", "(", "[", "vis_mask", "]", "*", "3", ",", "axis", "=", "0", ")", "\n", "storage", ".", "put_image", "(", "name", "+", "f\" ({idx})\"", ",", "vis_mask", ")", "\n", "\n", "", "", "mask_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "pred_mask_logits", ",", "gt_masks", ",", "reduction", "=", "\"mean\"", ")", "\n", "return", "mask_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.mask_rcnn_inference": [[114, 153], ["[].sigmoid.split", "zip", "pred_mask_logits.size", "pred_mask_logits.sigmoid", "detectron2.layers.cat", "torch.arange", "[].sigmoid", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "mask_rcnn_inference", "(", "pred_mask_logits", ":", "torch", ".", "Tensor", ",", "pred_instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "    ", "\"\"\"\n    Convert pred_mask_logits to estimated foreground probability masks while also\n    extracting only the masks for the predicted classes in pred_instances. For each\n    predicted box, the mask of the same class is attached to the instance by adding a\n    new \"pred_masks\" field to pred_instances.\n\n    Args:\n        pred_mask_logits (Tensor): A tensor of shape (B, C, Hmask, Wmask) or (B, 1, Hmask, Wmask)\n            for class-specific or class-agnostic, where B is the total number of predicted masks\n            in all images, C is the number of foreground classes, and Hmask, Wmask are the height\n            and width of the mask predictions. The values are logits.\n        pred_instances (list[Instances]): A list of N Instances, where N is the number of images\n            in the batch. Each Instances must have field \"pred_classes\".\n\n    Returns:\n        None. pred_instances will contain an extra \"pred_masks\" field storing a mask of size (Hmask,\n            Wmask) for predicted class. Note that the masks are returned as a soft (non-quantized)\n            masks the resolution predicted by the network; post-processing steps, such as resizing\n            the predicted masks to the original image resolution and/or binarizing them, is left\n            to the caller.\n    \"\"\"", "\n", "cls_agnostic_mask", "=", "pred_mask_logits", ".", "size", "(", "1", ")", "==", "1", "\n", "\n", "if", "cls_agnostic_mask", ":", "\n", "        ", "mask_probs_pred", "=", "pred_mask_logits", ".", "sigmoid", "(", ")", "\n", "", "else", ":", "\n", "# Select masks corresponding to the predicted classes", "\n", "        ", "num_masks", "=", "pred_mask_logits", ".", "shape", "[", "0", "]", "\n", "class_pred", "=", "cat", "(", "[", "i", ".", "pred_classes", "for", "i", "in", "pred_instances", "]", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "num_masks", ",", "device", "=", "class_pred", ".", "device", ")", "\n", "mask_probs_pred", "=", "pred_mask_logits", "[", "indices", ",", "class_pred", "]", "[", ":", ",", "None", "]", ".", "sigmoid", "(", ")", "\n", "# mask_probs_pred.shape: (B, 1, Hmask, Wmask)", "\n", "\n", "", "num_boxes_per_image", "=", "[", "len", "(", "i", ")", "for", "i", "in", "pred_instances", "]", "\n", "mask_probs_pred", "=", "mask_probs_pred", ".", "split", "(", "num_boxes_per_image", ",", "dim", "=", "0", ")", "\n", "\n", "for", "prob", ",", "instances", "in", "zip", "(", "mask_probs_pred", ",", "pred_instances", ")", ":", "\n", "        ", "instances", ".", "pred_masks", "=", "prob", "# (1, Hmask, Wmask)", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.build_mask_head": [[287, 293], ["ROI_MASK_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "build_mask_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a mask head defined by `cfg.MODEL.ROI_MASK_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NAME", "\n", "return", "ROI_MASK_HEAD_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.__init__": [[180, 245], ["len", "len", "type", "type.cat", "proposals[].has", "detectron2.structures.Boxes", "len", "detectron2.layers.cat", "type.cat", "torch.zeros", "p.has"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["def", "__init__", "(", "\n", "self", ",", "\n", "box2box_transform", ",", "\n", "pred_class_logits", ",", "\n", "pred_proposal_deltas", ",", "\n", "proposals", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box2box_transform (Box2BoxTransform/Box2BoxTransformRotated):\n                box2box transform instance for proposal-to-detection transformations.\n            pred_class_logits (Tensor): A tensor of shape (R, K + 1) storing the predicted class\n                logits for all R predicted object instances.\n                Each row corresponds to a predicted object instance.\n            pred_proposal_deltas (Tensor): A tensor of shape (R, K * B) or (R, B) for\n                class-specific or class-agnostic regression. It stores the predicted deltas that\n                transform proposals into final box detections.\n                B is the box dimension (4 or 5).\n                When B is 4, each row is [dx, dy, dw, dh (, ....)].\n                When B is 5, each row is [dx, dy, dw, dh, da (, ....)].\n            proposals (list[Instances]): A list of N Instances, where Instances i stores the\n                proposals for image i, in the field \"proposal_boxes\".\n                When training, each Instances must have ground-truth labels\n                stored in the field \"gt_classes\" and \"gt_boxes\".\n                The total number of all instances must be equal to R.\n            smooth_l1_beta (float): The transition point between L1 and L2 loss in\n                the smooth L1 loss function. When set to 0, the loss becomes L1. When\n                set to +inf, the loss becomes constant 0.\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\"\n        \"\"\"", "\n", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "num_preds_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "self", ".", "pred_class_logits", "=", "pred_class_logits", "\n", "self", ".", "pred_proposal_deltas", "=", "pred_proposal_deltas", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "\n", "self", ".", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "if", "len", "(", "proposals", ")", ":", "\n", "            ", "box_type", "=", "type", "(", "proposals", "[", "0", "]", ".", "proposal_boxes", ")", "\n", "# cat(..., dim=0) concatenates over all images in the batch", "\n", "self", ".", "proposals", "=", "box_type", ".", "cat", "(", "[", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "]", ")", "\n", "assert", "(", "\n", "not", "self", ".", "proposals", ".", "tensor", ".", "requires_grad", "\n", ")", ",", "\"Proposals should not require gradients!\"", "\n", "\n", "# \"gt_classes\" exists if and only if training. But other gt fields may", "\n", "# not necessarily exist in training for images that have no groundtruth.", "\n", "if", "proposals", "[", "0", "]", ".", "has", "(", "\"gt_classes\"", ")", ":", "\n", "                ", "self", ".", "gt_classes", "=", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# If \"gt_boxes\" does not exist, the proposals must be all negative and", "\n", "# should not be included in regression loss computation.", "\n", "# Here we just use proposal_boxes as an arbitrary placeholder because its", "\n", "# value won't be used in self.box_reg_loss().", "\n", "gt_boxes", "=", "[", "\n", "p", ".", "gt_boxes", "if", "p", ".", "has", "(", "\"gt_boxes\"", ")", "else", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "\n", "]", "\n", "self", ".", "gt_boxes", "=", "box_type", ".", "cat", "(", "gt_boxes", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "proposals", "=", "Boxes", "(", "torch", ".", "zeros", "(", "0", ",", "4", ",", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", ")", ")", "\n", "", "self", ".", "_no_instances", "=", "len", "(", "self", ".", "proposals", ")", "==", "0", "# no instances found", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss": [[246, 252], ["fast_rcnn._log_classification_stats", "detectron2.layers.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn._log_classification_stats", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy"], ["", "def", "softmax_cross_entropy_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "_log_classification_stats", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ")", "\n", "return", "cross_entropy", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ",", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.box_reg_loss": [[253, 308], ["fast_rcnn.FastRCNNOutputs.proposals.tensor.size", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.size", "detectron2.layers.nonzero_tuple", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.get_deltas", "fvcore.nn.smooth_l1_loss", "fast_rcnn.FastRCNNOutputs.gt_classes.numel", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.sum", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fvcore.nn.giou_loss", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "def", "box_reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "if", "self", ".", "_no_instances", ":", "\n", "            ", "return", "0.0", "*", "self", ".", "pred_proposal_deltas", ".", "sum", "(", ")", "\n", "\n", "", "box_dim", "=", "self", ".", "proposals", ".", "tensor", ".", "size", "(", "1", ")", "# 4 or 5", "\n", "cls_agnostic_bbox_reg", "=", "self", ".", "pred_proposal_deltas", ".", "size", "(", "1", ")", "==", "box_dim", "\n", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", "\n", "\n", "bg_class_ind", "=", "self", ".", "pred_class_logits", ".", "shape", "[", "1", "]", "-", "1", "\n", "# Box delta loss is only computed between the prediction for the gt class k", "\n", "# (if 0 <= k < bg_class_ind) and the target; there is no loss defined on predictions", "\n", "# for non-gt classes and background.", "\n", "# Empty fg_inds should produce a valid loss of zero because reduction=sum.", "\n", "fg_inds", "=", "nonzero_tuple", "(", "(", "self", ".", "gt_classes", ">=", "0", ")", "&", "(", "self", ".", "gt_classes", "<", "bg_class_ind", ")", ")", "[", "0", "]", "\n", "\n", "if", "cls_agnostic_bbox_reg", ":", "\n", "# pred_proposal_deltas only corresponds to foreground class for agnostic", "\n", "            ", "gt_class_cols", "=", "torch", ".", "arange", "(", "box_dim", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "# pred_proposal_deltas for class k are located in columns [b * k : b * k + b],", "\n", "# where b is the dimension of box representation (4 or 5)", "\n", "# Note that compared to Detectron1,", "\n", "# we do not perform bounding box regression for background classes.", "\n", "            ", "gt_class_cols", "=", "box_dim", "*", "self", ".", "gt_classes", "[", "fg_inds", ",", "None", "]", "+", "torch", ".", "arange", "(", "\n", "box_dim", ",", "device", "=", "device", "\n", ")", "\n", "\n", "", "if", "self", ".", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "            ", "gt_proposal_deltas", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "self", ".", "proposals", ".", "tensor", ",", "self", ".", "gt_boxes", ".", "tensor", "\n", ")", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "gt_proposal_deltas", "[", "fg_inds", "]", ",", "\n", "self", ".", "smooth_l1_beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "elif", "self", ".", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "            ", "fg_pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "self", ".", "proposals", ".", "tensor", "[", "fg_inds", "]", ",", "\n", ")", "\n", "loss_box_reg", "=", "giou_loss", "(", "\n", "fg_pred_boxes", ",", "\n", "self", ".", "gt_boxes", ".", "tensor", "[", "fg_inds", "]", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid bbox reg loss type '{self.box_reg_loss_type}'\"", ")", "\n", "\n", "", "loss_box_reg", "=", "loss_box_reg", "/", "self", ".", "gt_classes", ".", "numel", "(", ")", "\n", "return", "loss_box_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.losses": [[309, 314], ["fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "fast_rcnn.FastRCNNOutputs.box_reg_loss"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss"], ["", "def", "losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "return", "{", "\"loss_cls\"", ":", "self", ".", "softmax_cross_entropy_loss", "(", ")", ",", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.predict_boxes": [[315, 321], ["fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputs.split"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "def", "predict_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "pred", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "self", ".", "pred_proposal_deltas", ",", "self", ".", "proposals", ".", "tensor", ")", "\n", "return", "pred", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputs.predict_probs": [[322, 328], ["torch.nn.functional.softmax", "torch.nn.functional.softmax.split"], "methods", ["None"], ["", "def", "predict_probs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "probs", "=", "F", ".", "softmax", "(", "self", ".", "pred_class_logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "probs", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.__init__": [[338, 397], ["torch.nn.Module.__init__", "isinstance", "torch.nn.Linear", "len", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "detectron2.layers.ShapeSpec", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "ShapeSpec", ",", "\n", "*", ",", "\n", "box2box_transform", ",", "\n", "num_classes", ":", "int", ",", "\n", "test_score_thresh", ":", "float", "=", "0.0", ",", "\n", "test_nms_thresh", ":", "float", "=", "0.5", ",", "\n", "test_topk_per_image", ":", "int", "=", "100", ",", "\n", "cls_agnostic_bbox_reg", ":", "bool", "=", "False", ",", "\n", "smooth_l1_beta", ":", "float", "=", "0.0", ",", "\n", "box_reg_loss_type", ":", "str", "=", "\"smooth_l1\"", ",", "\n", "loss_weight", ":", "Union", "[", "float", ",", "Dict", "[", "str", ",", "float", "]", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature to this module\n            box2box_transform (Box2BoxTransform or Box2BoxTransformRotated):\n            num_classes (int): number of foreground classes\n            test_score_thresh (float): threshold to filter predictions results.\n            test_nms_thresh (float): NMS threshold for prediction results.\n            test_topk_per_image (int): number of top predictions to produce per image.\n            cls_agnostic_bbox_reg (bool): whether to use class agnostic for bbox regression\n            smooth_l1_beta (float): transition point from L1 to L2 loss. Only used if\n                `box_reg_loss_type` is \"smooth_l1\"\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\"\n            loss_weight (float|dict): weights to use for losses. Can be single float for weighting\n                all losses, or a dict of individual weightings. Valid dict keys are:\n                    * \"loss_cls\": applied to classification loss\n                    * \"loss_box_reg\": applied to box regression loss\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "input_shape", ",", "int", ")", ":", "# some backward compatibility", "\n", "            ", "input_shape", "=", "ShapeSpec", "(", "channels", "=", "input_shape", ")", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "input_size", "=", "input_shape", ".", "channels", "*", "(", "input_shape", ".", "width", "or", "1", ")", "*", "(", "input_shape", ".", "height", "or", "1", ")", "\n", "# prediction layer for num_classes foreground classes and one background class (hence + 1)", "\n", "self", ".", "cls_score", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_classes", "+", "1", ")", "\n", "num_bbox_reg_classes", "=", "1", "if", "cls_agnostic_bbox_reg", "else", "num_classes", "\n", "box_dim", "=", "len", "(", "box2box_transform", ".", "weights", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_bbox_reg_classes", "*", "box_dim", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "cls_score", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "bbox_pred", ".", "weight", ",", "std", "=", "0.001", ")", "\n", "for", "l", "in", "[", "self", ".", "cls_score", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "test_score_thresh", "=", "test_score_thresh", "\n", "self", ".", "test_nms_thresh", "=", "test_nms_thresh", "\n", "self", ".", "test_topk_per_image", "=", "test_topk_per_image", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "if", "isinstance", "(", "loss_weight", ",", "float", ")", ":", "\n", "            ", "loss_weight", "=", "{", "\"loss_cls\"", ":", "loss_weight", ",", "\"loss_box_reg\"", ":", "loss_weight", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.from_config": [[398, 412], ["detectron2.modeling.box_regression.Box2BoxTransform"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "return", "{", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"box2box_transform\"", ":", "Box2BoxTransform", "(", "weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_WEIGHTS", ")", ",", "\n", "# fmt: off", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", ",", "\n", "\"cls_agnostic_bbox_reg\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CLS_AGNOSTIC_BBOX_REG", ",", "\n", "\"smooth_l1_beta\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "SMOOTH_L1_BETA", ",", "\n", "\"test_score_thresh\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "SCORE_THRESH_TEST", ",", "\n", "\"test_nms_thresh\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NMS_THRESH_TEST", ",", "\n", "\"test_topk_per_image\"", ":", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", ",", "\n", "\"box_reg_loss_type\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_LOSS_TYPE", ",", "\n", "\"loss_weight\"", ":", "{", "\"loss_box_reg\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_LOSS_WEIGHT", "}", ",", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.forward": [[415, 433], ["fast_rcnn.FastRCNNOutputLayers.cls_score", "fast_rcnn.FastRCNNOutputLayers.bbox_pred", "torch.flatten.dim", "torch.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: per-region features of shape (N, ...) for N bounding boxes to predict.\n\n        Returns:\n            (Tensor, Tensor):\n            First tensor: shape (N,K+1), scores for each of the N box. Each row contains the\n            scores for K object categories and 1 background class.\n\n            Second tensor: bounding box regression deltas for each box. Shape is shape (N,Kx4),\n            or (N,4) for class-agnostic regression.\n        \"\"\"", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "\n", "", "scores", "=", "self", ".", "cls_score", "(", "x", ")", "\n", "proposal_deltas", "=", "self", ".", "bbox_pred", "(", "x", ")", "\n", "return", "scores", ",", "proposal_deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses": [[434, 475], ["fast_rcnn._log_classification_stats", "len", "len", "detectron2.layers.cat", "torch.empty", "detectron2.layers.cat", "detectron2.layers.cat", "torch.empty", "detectron2.layers.cross_entropy", "fast_rcnn.FastRCNNOutputLayers.box_reg_loss", "fast_rcnn.FastRCNNOutputLayers.loss_weight.get", "losses.items", "p.has"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn._log_classification_stats", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were used\n                to compute predictions. The fields ``proposal_boxes``, ``gt_boxes``,\n                ``gt_classes`` are expected.\n\n        Returns:\n            Dict[str, Tensor]: dict of losses\n        \"\"\"", "\n", "scores", ",", "proposal_deltas", "=", "predictions", "\n", "\n", "# parse classification outputs", "\n", "gt_classes", "=", "(", "\n", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "if", "len", "(", "proposals", ")", "else", "torch", ".", "empty", "(", "0", ")", "\n", ")", "\n", "_log_classification_stats", "(", "scores", ",", "gt_classes", ")", "\n", "\n", "# parse box regression outputs", "\n", "if", "len", "(", "proposals", ")", ":", "\n", "            ", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "# Nx4", "\n", "assert", "not", "proposal_boxes", ".", "requires_grad", ",", "\"Proposals should not require gradients!\"", "\n", "# If \"gt_boxes\" does not exist, the proposals must be all negative and", "\n", "# should not be included in regression loss computation.", "\n", "# Here we just use proposal_boxes as an arbitrary placeholder because its", "\n", "# value won't be used in self.box_reg_loss().", "\n", "gt_boxes", "=", "cat", "(", "\n", "[", "(", "p", ".", "gt_boxes", "if", "p", ".", "has", "(", "\"gt_boxes\"", ")", "else", "p", ".", "proposal_boxes", ")", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "proposal_boxes", "=", "gt_boxes", "=", "torch", ".", "empty", "(", "(", "0", ",", "4", ")", ",", "device", "=", "proposal_deltas", ".", "device", ")", "\n", "\n", "", "losses", "=", "{", "\n", "\"loss_cls\"", ":", "cross_entropy", "(", "scores", ",", "gt_classes", ",", "reduction", "=", "\"mean\"", ")", ",", "\n", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", "\n", "proposal_boxes", ",", "gt_boxes", ",", "proposal_deltas", ",", "gt_classes", "\n", ")", ",", "\n", "}", "\n", "return", "{", "k", ":", "v", "*", "self", ".", "loss_weight", ".", "get", "(", "k", ",", "1.0", ")", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss": [[476, 520], ["detectron2.layers.nonzero_tuple", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.get_deltas", "fvcore.nn.smooth_l1_loss", "max", "pred_deltas.view", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fvcore.nn.giou_loss", "ValueError", "gt_classes.numel"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "def", "box_reg_loss", "(", "self", ",", "proposal_boxes", ",", "gt_boxes", ",", "pred_deltas", ",", "gt_classes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            All boxes are tensors with the same shape Rx(4 or 5).\n            gt_classes is a long tensor of shape R, the gt class label of each proposal.\n            R shall be the number of proposals.\n        \"\"\"", "\n", "box_dim", "=", "proposal_boxes", ".", "shape", "[", "1", "]", "# 4 or 5", "\n", "# Regression loss is only computed for foreground proposals (those matched to a GT)", "\n", "fg_inds", "=", "nonzero_tuple", "(", "(", "gt_classes", ">=", "0", ")", "&", "(", "gt_classes", "<", "self", ".", "num_classes", ")", ")", "[", "0", "]", "\n", "if", "pred_deltas", ".", "shape", "[", "1", "]", "==", "box_dim", ":", "# cls-agnostic regression", "\n", "            ", "fg_pred_deltas", "=", "pred_deltas", "[", "fg_inds", "]", "\n", "", "else", ":", "\n", "            ", "fg_pred_deltas", "=", "pred_deltas", ".", "view", "(", "-", "1", ",", "self", ".", "num_classes", ",", "box_dim", ")", "[", "\n", "fg_inds", ",", "gt_classes", "[", "fg_inds", "]", "\n", "]", "\n", "\n", "", "if", "self", ".", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "            ", "gt_pred_deltas", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "proposal_boxes", "[", "fg_inds", "]", ",", "\n", "gt_boxes", "[", "fg_inds", "]", ",", "\n", ")", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "fg_pred_deltas", ",", "gt_pred_deltas", ",", "self", ".", "smooth_l1_beta", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "", "elif", "self", ".", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "            ", "fg_pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "fg_pred_deltas", ",", "proposal_boxes", "[", "fg_inds", "]", "\n", ")", "\n", "loss_box_reg", "=", "giou_loss", "(", "fg_pred_boxes", ",", "gt_boxes", "[", "fg_inds", "]", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid bbox reg loss type '{self.box_reg_loss_type}'\"", ")", "\n", "# The reg loss is normalized using the total number of regions (R), not the number", "\n", "# of foreground regions even though the box regression loss is only defined on", "\n", "# foreground regions. Why? Because doing so gives equal training influence to", "\n", "# each foreground example. To see how, consider two different minibatches:", "\n", "#  (1) Contains a single foreground region", "\n", "#  (2) Contains 100 foreground regions", "\n", "# If we normalize by the number of foreground regions, the single example in", "\n", "# minibatch (1) will be given 100 times as much influence as each foreground", "\n", "# example in minibatch (2). Normalizing by the total number of regions, R,", "\n", "# means that the single example in minibatch (1) and each of the 100 examples", "\n", "# in minibatch (2) are given equal influence.", "\n", "", "return", "loss_box_reg", "/", "max", "(", "gt_classes", ".", "numel", "(", ")", ",", "1.0", ")", "# return 0 if empty", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.inference": [[521, 542], ["fast_rcnn.FastRCNNOutputLayers.predict_boxes", "fast_rcnn.FastRCNNOutputLayers.predict_probs", "fast_rcnn.fast_rcnn_inference"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference"], ["", "def", "inference", "(", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Instances]: same as `fast_rcnn_inference`.\n            list[Tensor]: same as `fast_rcnn_inference`.\n        \"\"\"", "\n", "boxes", "=", "self", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "scores", "=", "self", ".", "predict_probs", "(", "predictions", ",", "proposals", ")", "\n", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "return", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "self", ".", "test_score_thresh", ",", "\n", "self", ".", "test_nms_thresh", ",", "\n", "self", ".", "test_topk_per_image", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes_for_gt_classes": [[544, 578], ["detectron2.layers.cat", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputLayers.split", "len", "torch.cat", "gt_classes.clamp_.clamp_.clamp_", "len", "fast_rcnn.FastRCNNOutputLayers.view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "predict_boxes_for_gt_classes", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were used\n                to compute predictions. The fields ``proposal_boxes``, ``gt_classes`` are expected.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted boxes for GT classes in case of\n                class-specific box head. Element i of the list has shape (Ri, B), where Ri is\n                the number of proposals for image i and B is the box dimension (4 or 5)\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "scores", ",", "proposal_deltas", "=", "predictions", "\n", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "N", ",", "B", "=", "proposal_boxes", ".", "shape", "\n", "predict_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "proposal_deltas", ",", "proposal_boxes", "\n", ")", "# Nx(KxB)", "\n", "\n", "K", "=", "predict_boxes", ".", "shape", "[", "1", "]", "//", "B", "\n", "if", "K", ">", "1", ":", "\n", "            ", "gt_classes", "=", "torch", ".", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "# Some proposals are ignored or have a background class. Their gt_classes", "\n", "# cannot be used as index.", "\n", "gt_classes", "=", "gt_classes", ".", "clamp_", "(", "0", ",", "K", "-", "1", ")", "\n", "\n", "predict_boxes", "=", "predict_boxes", ".", "view", "(", "N", ",", "K", ",", "B", ")", "[", "\n", "torch", ".", "arange", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "predict_boxes", ".", "device", ")", ",", "gt_classes", "\n", "]", "\n", "", "num_prop_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "return", "predict_boxes", ".", "split", "(", "num_prop_per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes": [[579, 604], ["detectron2.layers.cat", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputLayers.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "def", "predict_boxes", "(", "\n", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted class-specific or class-agnostic boxes\n                for each image. Element i has shape (Ri, K * B) or (Ri, B), where Ri is\n                the number of proposals for image i and B is the box dimension (4 or 5)\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "_", ",", "proposal_deltas", "=", "predictions", "\n", "num_prop_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "predict_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "proposal_deltas", ",", "\n", "proposal_boxes", ",", "\n", ")", "# Nx(KxB)", "\n", "return", "predict_boxes", ".", "split", "(", "num_prop_per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs": [[605, 623], ["torch.nn.functional.softmax", "torch.nn.functional.softmax.split", "len"], "methods", ["None"], ["", "def", "predict_probs", "(", "\n", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted class probabilities for each image.\n                Element i has shape (Ri, K + 1), where Ri is the number of proposals for image i.\n        \"\"\"", "\n", "scores", ",", "_", "=", "predictions", "\n", "num_inst_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "probs", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "return", "probs", ".", "split", "(", "num_inst_per_image", ",", "dim", "=", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference": [[46, 86], ["fast_rcnn.fast_rcnn_inference_single_image", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference_single_image"], ["def", "fast_rcnn_inference", "(", "\n", "boxes", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "scores", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "image_shapes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "score_thresh", ":", "float", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "topk_per_image", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 4) if doing\n            class-specific regression, or (Ri, 4) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputLayers.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputLayers.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn._log_classification_stats": [[88, 116], ["gt_classes.numel", "pred_logits.argmax", "fg_inds.nonzero().numel", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "fg_inds.nonzero"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar"], ["", "def", "_log_classification_stats", "(", "pred_logits", ",", "gt_classes", ",", "prefix", "=", "\"fast_rcnn\"", ")", ":", "\n", "    ", "\"\"\"\n    Log the classification metrics to EventStorage.\n\n    Args:\n        pred_logits: Rx(K+1) logits. The last column is for background class.\n        gt_classes: R labels\n    \"\"\"", "\n", "num_instances", "=", "gt_classes", ".", "numel", "(", ")", "\n", "if", "num_instances", "==", "0", ":", "\n", "        ", "return", "\n", "", "pred_classes", "=", "pred_logits", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "bg_class_ind", "=", "pred_logits", ".", "shape", "[", "1", "]", "-", "1", "\n", "\n", "fg_inds", "=", "(", "gt_classes", ">=", "0", ")", "&", "(", "gt_classes", "<", "bg_class_ind", ")", "\n", "num_fg", "=", "fg_inds", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "fg_gt_classes", "=", "gt_classes", "[", "fg_inds", "]", "\n", "fg_pred_classes", "=", "pred_classes", "[", "fg_inds", "]", "\n", "\n", "num_false_negative", "=", "(", "fg_pred_classes", "==", "bg_class_ind", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "num_accurate", "=", "(", "pred_classes", "==", "gt_classes", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "fg_num_accurate", "=", "(", "fg_pred_classes", "==", "fg_gt_classes", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "f\"{prefix}/cls_accuracy\"", ",", "num_accurate", "/", "num_instances", ")", "\n", "if", "num_fg", ">", "0", ":", "\n", "        ", "storage", ".", "put_scalar", "(", "f\"{prefix}/fg_cls_accuracy\"", ",", "fg_num_accurate", "/", "num_fg", ")", "\n", "storage", ".", "put_scalar", "(", "f\"{prefix}/false_negative\"", ",", "num_false_negative", "/", "num_fg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference_single_image": [[118, 172], ["detectron2.structures.Boxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms"], ["", "", "def", "fast_rcnn_inference_single_image", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "score_thresh", ":", "float", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "topk_per_image", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return bounding-box detection results by thresholding\n    on scores and applying non-maximum suppression (NMS).\n\n    Args:\n        Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "4", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "Boxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "4", ")", "# R x C x 4", "\n", "\n", "# 1. Filter results based on detection scores. It can make NMS more efficient", "\n", "#    by filtering out low-confidence detections.", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "\n", "# 2. Apply NMS for each class independently.", "\n", "keep", "=", "batched_nms", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.RotatedFastRCNNOutputLayers.from_config": [[139, 146], ["super().from_config", "box_regression.Box2BoxTransformRotated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config"], ["@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "args", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "args", "[", "\"box2box_transform\"", "]", "=", "Box2BoxTransformRotated", "(", "\n", "weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_WEIGHTS", "\n", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.RotatedFastRCNNOutputLayers.inference": [[147, 164], ["rotated_fast_rcnn.RotatedFastRCNNOutputLayers.predict_boxes", "rotated_fast_rcnn.RotatedFastRCNNOutputLayers.predict_probs", "rotated_fast_rcnn.fast_rcnn_inference_rotated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_rotated"], ["", "def", "inference", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[Instances]: same as `fast_rcnn_inference_rotated`.\n            list[Tensor]: same as `fast_rcnn_inference_rotated`.\n        \"\"\"", "\n", "boxes", "=", "self", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "scores", "=", "self", ".", "predict_probs", "(", "predictions", ",", "proposals", ")", "\n", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "return", "fast_rcnn_inference_rotated", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "self", ".", "test_score_thresh", ",", "\n", "self", ".", "test_nms_thresh", ",", "\n", "self", ".", "test_topk_per_image", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.RROIHeads.__init__": [[174, 184], ["roi_heads.StandardROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "assert", "(", "\n", "not", "self", ".", "mask_on", "and", "not", "self", ".", "keypoint_on", "\n", ")", ",", "\"Mask/Keypoints not supported in Rotated ROIHeads.\"", "\n", "assert", "not", "self", ".", "train_on_pred_boxes", ",", "\"train_on_pred_boxes not implemented for RROIHeads!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.RROIHeads._init_box_head": [[185, 214], ["tuple", "poolers.ROIPooler", "box_head.build_box_head.build_box_head", "rotated_fast_rcnn.RotatedFastRCNNOutputLayers", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.build_box_head"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "assert", "pooler_type", "in", "[", "\"ROIAlignRotated\"", "]", ",", "pooler_type", "\n", "# assume all channel counts are equal", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "box_head", "=", "build_box_head", "(", "\n", "cfg", ",", "ShapeSpec", "(", "channels", "=", "in_channels", ",", "height", "=", "pooler_resolution", ",", "width", "=", "pooler_resolution", ")", "\n", ")", "\n", "# This line is the only difference v.s. StandardROIHeads", "\n", "box_predictor", "=", "RotatedFastRCNNOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_head\"", ":", "box_head", ",", "\n", "\"box_predictor\"", ":", "box_predictor", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.RROIHeads.label_and_sample_proposals": [[216, 272], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou_rotated", "rotated_fast_rcnn.RROIHeads.proposal_matcher", "rotated_fast_rcnn.RROIHeads._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "gt_classes.numel"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.rotated_boxes.pairwise_iou_rotated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads._sample_proposals"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Prepare some proposals to be used to train the RROI heads.\n        It performs box matching between `proposals` and `targets`, and assigns\n        training labels to the proposals.\n        It returns `self.batch_size_per_image` random samples from proposals and groundtruth boxes,\n        with a fraction of positives that is no larger than `self.positive_sample_fraction.\n\n        Args:\n            See :meth:`StandardROIHeads.forward`\n\n        Returns:\n            list[Instances]: length `N` list of `Instances`s containing the proposals\n                sampled for training. Each `Instances` has the following fields:\n                - proposal_boxes: the rotated proposal boxes\n                - gt_boxes: the ground-truth rotated boxes that the proposal is assigned to\n                  (this is only meaningful if the proposal has a label > 0; if label = 0\n                   then the ground-truth box is random)\n                - gt_classes: the ground-truth classification lable for each proposal\n        \"\"\"", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "targets", "]", "\n", "if", "self", ".", "proposal_append_gt", ":", "\n", "            ", "proposals", "=", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", "\n", "\n", "", "proposals_with_gt", "=", "[", "]", "\n", "\n", "num_fg_samples", "=", "[", "]", "\n", "num_bg_samples", "=", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "has_gt", "=", "len", "(", "targets_per_image", ")", ">", "0", "\n", "match_quality_matrix", "=", "pairwise_iou_rotated", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "matched_idxs", ",", "matched_labels", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "sampled_idxs", ",", "gt_classes", "=", "self", ".", "_sample_proposals", "(", "\n", "matched_idxs", ",", "matched_labels", ",", "targets_per_image", ".", "gt_classes", "\n", ")", "\n", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "\n", "if", "has_gt", ":", "\n", "                ", "sampled_targets", "=", "matched_idxs", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_boxes", "=", "targets_per_image", ".", "gt_boxes", "[", "sampled_targets", "]", "\n", "\n", "", "num_bg_samples", ".", "append", "(", "(", "gt_classes", "==", "self", ".", "num_classes", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_fg_samples", ".", "append", "(", "gt_classes", ".", "numel", "(", ")", "-", "num_bg_samples", "[", "-", "1", "]", ")", "\n", "proposals_with_gt", ".", "append", "(", "proposals_per_image", ")", "\n", "\n", "# Log the number of fg/bg samples that are selected for training ROI heads", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_fg_samples\"", ",", "np", ".", "mean", "(", "num_fg_samples", ")", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_bg_samples\"", ",", "np", ".", "mean", "(", "num_bg_samples", ")", ")", "\n", "\n", "return", "proposals_with_gt", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_rotated": [[46, 81], ["rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated"], ["def", "fast_rcnn_inference_rotated", "(", "\n", "boxes", ",", "scores", ",", "image_shapes", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image_rotated` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 5) if doing\n            class-specific regression, or (Ri, 5) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputs.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputs.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image_rotated", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated": [[83, 132], ["detectron2.structures.RotatedBoxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms_rotated", "detectron2.structures.Instances", "detectron2.structures.RotatedBoxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms_rotated"], ["", "def", "fast_rcnn_inference_single_image_rotated", "(", "\n", "boxes", ",", "scores", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return rotated bounding-box detection results by thresholding\n    on scores and applying rotated non-maximum suppression (Rotated NMS).\n\n    Args:\n        Same as `fast_rcnn_inference_rotated`, but with rotated boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference_rotated`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "B", "=", "5", "# box dimension", "\n", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "B", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "RotatedBoxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "B", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "B", ")", "# R x C x B", "\n", "# Filter results based on detection scores", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "\n", "# Apply per-class Rotated NMS", "\n", "keep", "=", "batched_nms_rotated", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "RotatedBoxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.__init__": [[138, 165], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "num_classes", ",", "\n", "batch_size_per_image", ",", "\n", "positive_fraction", ",", "\n", "proposal_matcher", ",", "\n", "proposal_append_gt", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            num_classes (int): number of foreground classes (i.e. background is not included)\n            batch_size_per_image (int): number of proposals to sample for training\n            positive_fraction (float): fraction of positive (foreground) proposals\n                to sample for training.\n            proposal_matcher (Matcher): matcher that matches proposals and ground truth\n            proposal_append_gt (bool): whether to include ground truth as proposals as well\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_size_per_image", "=", "batch_size_per_image", "\n", "self", ".", "positive_fraction", "=", "positive_fraction", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "proposal_append_gt", "=", "proposal_append_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.from_config": [[166, 178], ["matcher.Matcher"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "{", "\n", "\"batch_size_per_image\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "BATCH_SIZE_PER_IMAGE", ",", "\n", "\"positive_fraction\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "POSITIVE_FRACTION", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", ",", "\n", "\"proposal_append_gt\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "PROPOSAL_APPEND_GT", ",", "\n", "# Matcher to assign box proposals to gt boxes", "\n", "\"proposal_matcher\"", ":", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IOU_THRESHOLDS", ",", "\n", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IOU_LABELS", ",", "\n", "allow_low_quality_matches", "=", "False", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads._sample_proposals": [[181, 218], ["sampling.subsample_labels", "torch.cat", "gt_classes.numel", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.sampling.subsample_labels", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "_sample_proposals", "(", "\n", "self", ",", "matched_idxs", ":", "torch", ".", "Tensor", ",", "matched_labels", ":", "torch", ".", "Tensor", ",", "gt_classes", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Based on the matching between N proposals and M groundtruth,\n        sample the proposals and set their classification labels.\n\n        Args:\n            matched_idxs (Tensor): a vector of length N, each is the best-matched\n                gt index in [0, M) for each proposal.\n            matched_labels (Tensor): a vector of length N, the matcher's label\n                (one of cfg.MODEL.ROI_HEADS.IOU_LABELS) for each proposal.\n            gt_classes (Tensor): a vector of length M.\n\n        Returns:\n            Tensor: a vector of indices of sampled proposals. Each is in [0, N).\n            Tensor: a vector of the same length, the classification label for\n                each sampled proposal. Each sample is labeled as either a category in\n                [0, num_classes) or the background (num_classes).\n        \"\"\"", "\n", "has_gt", "=", "gt_classes", ".", "numel", "(", ")", ">", "0", "\n", "# Get the corresponding GT for each proposal", "\n", "if", "has_gt", ":", "\n", "            ", "gt_classes", "=", "gt_classes", "[", "matched_idxs", "]", "\n", "# Label unmatched proposals (0 label from matcher) as background (label=num_classes)", "\n", "gt_classes", "[", "matched_labels", "==", "0", "]", "=", "self", ".", "num_classes", "\n", "# Label ignore proposals (-1 label)", "\n", "gt_classes", "[", "matched_labels", "==", "-", "1", "]", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "gt_classes", "=", "torch", ".", "zeros_like", "(", "matched_idxs", ")", "+", "self", ".", "num_classes", "\n", "\n", "", "sampled_fg_idxs", ",", "sampled_bg_idxs", "=", "subsample_labels", "(", "\n", "gt_classes", ",", "self", ".", "batch_size_per_image", ",", "self", ".", "positive_fraction", ",", "self", ".", "num_classes", "\n", ")", "\n", "\n", "sampled_idxs", "=", "torch", ".", "cat", "(", "[", "sampled_fg_idxs", ",", "sampled_bg_idxs", "]", ",", "dim", "=", "0", ")", "\n", "return", "sampled_idxs", ",", "gt_classes", "[", "sampled_idxs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals": [[219, 304], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou", "roi_heads.ROIHeads.proposal_matcher", "roi_heads.ROIHeads._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "targets_per_image.get_fields().items", "gt_classes.numel", "targets_per_image.get_fields", "trg_name.startswith", "proposals_per_image.set", "proposals_per_image.has"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads._sample_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_proposals", "(", "\n", "self", ",", "proposals", ":", "List", "[", "Instances", "]", ",", "targets", ":", "List", "[", "Instances", "]", "\n", ")", "->", "List", "[", "Instances", "]", ":", "\n", "        ", "\"\"\"\n        Prepare some proposals to be used to train the ROI heads.\n        It performs box matching between `proposals` and `targets`, and assigns\n        training labels to the proposals.\n        It returns ``self.batch_size_per_image`` random samples from proposals and groundtruth\n        boxes, with a fraction of positives that is no larger than\n        ``self.positive_fraction``.\n\n        Args:\n            See :meth:`ROIHeads.forward`\n\n        Returns:\n            list[Instances]:\n                length `N` list of `Instances`s containing the proposals\n                sampled for training. Each `Instances` has the following fields:\n\n                - proposal_boxes: the proposal boxes\n                - gt_boxes: the ground-truth box that the proposal is assigned to\n                  (this is only meaningful if the proposal has a label > 0; if label = 0\n                  then the ground-truth box is random)\n\n                Other fields such as \"gt_classes\", \"gt_masks\", that's included in `targets`.\n        \"\"\"", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "targets", "]", "\n", "# Augment proposals with ground-truth boxes.", "\n", "# In the case of learned proposals (e.g., RPN), when training starts", "\n", "# the proposals will be low quality due to random initialization.", "\n", "# It's possible that none of these initial", "\n", "# proposals have high enough overlap with the gt objects to be used", "\n", "# as positive examples for the second stage components (box head,", "\n", "# cls head, mask head). Adding the gt boxes to the set of proposals", "\n", "# ensures that the second stage components will have some positive", "\n", "# examples from the start of training. For RPN, this augmentation improves", "\n", "# convergence and empirically improves box AP on COCO by about 0.5", "\n", "# points (under one tested configuration).", "\n", "if", "self", ".", "proposal_append_gt", ":", "\n", "            ", "proposals", "=", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", "\n", "\n", "", "proposals_with_gt", "=", "[", "]", "\n", "\n", "num_fg_samples", "=", "[", "]", "\n", "num_bg_samples", "=", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "has_gt", "=", "len", "(", "targets_per_image", ")", ">", "0", "\n", "match_quality_matrix", "=", "pairwise_iou", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "matched_idxs", ",", "matched_labels", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "sampled_idxs", ",", "gt_classes", "=", "self", ".", "_sample_proposals", "(", "\n", "matched_idxs", ",", "matched_labels", ",", "targets_per_image", ".", "gt_classes", "\n", ")", "\n", "\n", "# Set target attributes of the sampled proposals:", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "\n", "if", "has_gt", ":", "\n", "                ", "sampled_targets", "=", "matched_idxs", "[", "sampled_idxs", "]", "\n", "# We index all the attributes of targets that start with \"gt_\"", "\n", "# and have not been added to proposals yet (=\"gt_classes\").", "\n", "# NOTE: here the indexing waste some compute, because heads", "\n", "# like masks, keypoints, etc, will filter the proposals again,", "\n", "# (by foreground/background, or number of keypoints in the image, etc)", "\n", "# so we essentially index the data twice.", "\n", "for", "(", "trg_name", ",", "trg_value", ")", "in", "targets_per_image", ".", "get_fields", "(", ")", ".", "items", "(", ")", ":", "\n", "                    ", "if", "trg_name", ".", "startswith", "(", "\"gt_\"", ")", "and", "not", "proposals_per_image", ".", "has", "(", "trg_name", ")", ":", "\n", "                        ", "proposals_per_image", ".", "set", "(", "trg_name", ",", "trg_value", "[", "sampled_targets", "]", ")", "\n", "# If no GT is given in the image, we don't know what a dummy gt value can be.", "\n", "# Therefore the returned proposals won't have any gt_* fields, except for a", "\n", "# gt_classes full of background label.", "\n", "\n", "", "", "", "num_bg_samples", ".", "append", "(", "(", "gt_classes", "==", "self", ".", "num_classes", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_fg_samples", ".", "append", "(", "gt_classes", ".", "numel", "(", ")", "-", "num_bg_samples", "[", "-", "1", "]", ")", "\n", "proposals_with_gt", ".", "append", "(", "proposals_per_image", ")", "\n", "\n", "# Log the number of fg/bg samples that are selected for training ROI heads", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_fg_samples\"", ",", "np", ".", "mean", "(", "num_fg_samples", ")", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_bg_samples\"", ",", "np", ".", "mean", "(", "num_bg_samples", ")", ")", "\n", "\n", "return", "proposals_with_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.forward": [[305, 340], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "targets", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Instances", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Args:\n            images (ImageList):\n            features (dict[str,Tensor]): input data as a mapping from feature\n                map name to tensor. Axis 0 represents the number of images `N` in\n                the input data; axes 1-3 are channels, height, and width, which may\n                vary between feature maps (e.g., if a feature pyramid is used).\n            proposals (list[Instances]): length `N` list of `Instances`. The i-th\n                `Instances` contains object proposals for the i-th input image,\n                with fields \"proposal_boxes\" and \"objectness_logits\".\n            targets (list[Instances], optional): length `N` list of `Instances`. The i-th\n                `Instances` contains the ground-truth per-instance annotations\n                for the i-th input image.  Specify `targets` during training only.\n                It may have the following fields:\n\n                - gt_boxes: the bounding box of each instance.\n                - gt_classes: the label for each instance with a category ranging in [0, #class].\n                - gt_masks: PolygonMasks or BitMasks, the ground-truth masks of each instance.\n                - gt_keypoints: NxKx3, the groud-truth keypoints for each instance.\n\n        Returns:\n            list[Instances]: length `N` list of `Instances` containing the\n            detected instances. Returned during inference only; may be [] during training.\n\n            dict[str->Tensor]:\n            mapping from a named loss to a tensor storing the loss. Used during training only.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads.__init__": [[351, 386], ["roi_heads.ROIHeads.__init__", "isinstance", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "in_features", ":", "List", "[", "str", "]", ",", "\n", "pooler", ":", "ROIPooler", ",", "\n", "res5", ":", "nn", ".", "Module", ",", "\n", "box_predictor", ":", "nn", ".", "Module", ",", "\n", "mask_head", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            in_features (list[str]): list of backbone feature map names to use for\n                feature extraction\n            pooler (ROIPooler): pooler to extra region features from backbone\n            res5 (nn.Sequential): a CNN to compute per-region features, to be used by\n                ``box_predictor`` and ``mask_head``. Typically this is a \"res5\"\n                block from a ResNet.\n            box_predictor (nn.Module): make box predictions from the feature.\n                Should have the same interface as :class:`FastRCNNOutputLayers`.\n            mask_head (nn.Module): transform features to make mask predictions\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "pooler", "=", "pooler", "\n", "if", "isinstance", "(", "res5", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "res5", "=", "nn", ".", "Sequential", "(", "*", "res5", ")", "\n", "", "self", ".", "res5", "=", "res5", "\n", "self", ".", "box_predictor", "=", "box_predictor", "\n", "self", ".", "mask_on", "=", "mask_head", "is", "not", "None", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "self", ".", "mask_head", "=", "mask_head", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads.from_config": [[387, 428], ["roi_heads.ROIHeads.from_config", "poolers.ROIPooler", "cls._build_res5_block", "fast_rcnn.FastRCNNOutputLayers", "len", "inspect.ismethod", "logger.warning", "classmethod", "detectron2.layers.ShapeSpec", "mask_head.build_mask_head", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads._build_res5_block", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.build_mask_head"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ")", "\n", "in_features", "=", "ret", "[", "\"in_features\"", "]", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "pooler_scales", "=", "(", "1.0", "/", "input_shape", "[", "in_features", "[", "0", "]", "]", ".", "stride", ",", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "mask_on", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "# fmt: on", "\n", "assert", "not", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "assert", "len", "(", "in_features", ")", "==", "1", "\n", "\n", "ret", "[", "\"pooler\"", "]", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "\n", "# Compatbility with old moco code. Might be useful.", "\n", "# See notes in StandardROIHeads.from_config", "\n", "if", "not", "inspect", ".", "ismethod", "(", "cls", ".", "_build_res5_block", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"The behavior of _build_res5_block may change. \"", "\n", "\"Please do not depend on private methods.\"", "\n", ")", "\n", "cls", ".", "_build_res5_block", "=", "classmethod", "(", "cls", ".", "_build_res5_block", ")", "\n", "\n", "", "ret", "[", "\"res5\"", "]", ",", "out_channels", "=", "cls", ".", "_build_res5_block", "(", "cfg", ")", "\n", "ret", "[", "\"box_predictor\"", "]", "=", "FastRCNNOutputLayers", "(", "\n", "cfg", ",", "ShapeSpec", "(", "channels", "=", "out_channels", ",", "height", "=", "1", ",", "width", "=", "1", ")", "\n", ")", "\n", "\n", "if", "mask_on", ":", "\n", "            ", "ret", "[", "\"mask_head\"", "]", "=", "build_mask_head", "(", "\n", "cfg", ",", "\n", "ShapeSpec", "(", "channels", "=", "out_channels", ",", "width", "=", "pooler_resolution", ",", "height", "=", "pooler_resolution", ")", ",", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads._build_res5_block": [[429, 455], ["backbone.resnet.ResNet.make_stage", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.make_stage"], ["", "@", "classmethod", "\n", "def", "_build_res5_block", "(", "cls", ",", "cfg", ")", ":", "\n", "# fmt: off", "\n", "        ", "stage_channel_factor", "=", "2", "**", "3", "# res5 is 8x res2", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "bottleneck_channels", "=", "num_groups", "*", "width_per_group", "*", "stage_channel_factor", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "*", "stage_channel_factor", "\n", "stride_in_1x1", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "assert", "not", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_ON_PER_STAGE", "[", "-", "1", "]", ",", "\"Deformable conv is not yet supported in res5 head.\"", "\n", "# fmt: on", "\n", "\n", "blocks", "=", "ResNet", ".", "make_stage", "(", "\n", "BottleneckBlock", ",", "\n", "3", ",", "\n", "stride_per_block", "=", "[", "2", ",", "1", ",", "1", "]", ",", "\n", "in_channels", "=", "out_channels", "//", "2", ",", "\n", "bottleneck_channels", "=", "bottleneck_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_groups", "=", "num_groups", ",", "\n", "norm", "=", "norm", ",", "\n", "stride_in_1x1", "=", "stride_in_1x1", ",", "\n", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", ",", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform": [[456, 459], ["roi_heads.Res5ROIHeads.pooler", "roi_heads.Res5ROIHeads.res5"], "methods", ["None"], ["", "def", "_shared_roi_transform", "(", "self", ",", "features", ",", "boxes", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "features", ",", "boxes", ")", "\n", "return", "self", ".", "res5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads.forward": [[460, 496], ["roi_heads.Res5ROIHeads._shared_roi_transform", "roi_heads.Res5ROIHeads.box_predictor", "roi_heads.Res5ROIHeads.label_and_sample_proposals", "roi_heads.Res5ROIHeads.mean", "roi_heads.Res5ROIHeads.box_predictor.losses", "roi_heads.Res5ROIHeads.box_predictor.inference", "roi_heads.Res5ROIHeads.forward_with_given_boxes", "roi_heads.select_foreground_proposals", "roi_heads.Res5ROIHeads.update", "roi_heads.Res5ROIHeads.mask_head", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_foreground_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :meth:`ROIHeads.forward`.\n        \"\"\"", "\n", "del", "images", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "assert", "targets", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "proposals", ",", "targets", ")", "\n", "", "del", "targets", "\n", "\n", "proposal_boxes", "=", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", "\n", "box_features", "=", "self", ".", "_shared_roi_transform", "(", "\n", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", ",", "proposal_boxes", "\n", ")", "\n", "predictions", "=", "self", ".", "box_predictor", "(", "box_features", ".", "mean", "(", "dim", "=", "[", "2", ",", "3", "]", ")", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "del", "features", "\n", "losses", "=", "self", ".", "box_predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "if", "self", ".", "mask_on", ":", "\n", "                ", "proposals", ",", "fg_selection_masks", "=", "select_foreground_proposals", "(", "\n", "proposals", ",", "self", ".", "num_classes", "\n", ")", "\n", "# Since the ROI feature transform is shared between boxes and masks,", "\n", "# we don't need to recompute features. The mask loss is only defined", "\n", "# on foreground proposals, so we need to select out the foreground", "\n", "# features.", "\n", "mask_features", "=", "box_features", "[", "torch", ".", "cat", "(", "fg_selection_masks", ",", "dim", "=", "0", ")", "]", "\n", "del", "box_features", "\n", "losses", ".", "update", "(", "self", ".", "mask_head", "(", "mask_features", ",", "proposals", ")", ")", "\n", "", "return", "[", "]", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", ",", "_", "=", "self", ".", "box_predictor", ".", "inference", "(", "predictions", ",", "proposals", ")", "\n", "pred_instances", "=", "self", ".", "forward_with_given_boxes", "(", "features", ",", "pred_instances", ")", "\n", "return", "pred_instances", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads.forward_with_given_boxes": [[497, 520], ["instances[].has", "instances[].has", "roi_heads.Res5ROIHeads._shared_roi_transform", "roi_heads.Res5ROIHeads.mask_head"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform"], ["", "", "def", "forward_with_given_boxes", "(", "self", ",", "features", ",", "instances", ")", ":", "\n", "        ", "\"\"\"\n        Use the given boxes in `instances` to produce other (non-box) per-ROI outputs.\n\n        Args:\n            features: same as in `forward()`\n            instances (list[Instances]): instances to predict other outputs. Expect the keys\n                \"pred_boxes\" and \"pred_classes\" to exist.\n\n        Returns:\n            instances (Instances):\n                the same `Instances` object, with extra\n                fields such as `pred_masks` or `pred_keypoints`.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "assert", "instances", "[", "0", "]", ".", "has", "(", "\"pred_boxes\"", ")", "and", "instances", "[", "0", "]", ".", "has", "(", "\"pred_classes\"", ")", "\n", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "x", "=", "self", ".", "_shared_roi_transform", "(", "features", ",", "[", "x", ".", "pred_boxes", "for", "x", "in", "instances", "]", ")", "\n", "return", "self", ".", "mask_head", "(", "x", ",", "instances", ")", "\n", "", "else", ":", "\n", "            ", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.__init__": [[535, 592], ["roi_heads.ROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "box_in_features", ":", "List", "[", "str", "]", ",", "\n", "box_pooler", ":", "ROIPooler", ",", "\n", "box_head", ":", "nn", ".", "Module", ",", "\n", "box_predictor", ":", "nn", ".", "Module", ",", "\n", "mask_in_features", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "mask_pooler", ":", "Optional", "[", "ROIPooler", "]", "=", "None", ",", "\n", "mask_head", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "keypoint_in_features", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "keypoint_pooler", ":", "Optional", "[", "ROIPooler", "]", "=", "None", ",", "\n", "keypoint_head", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "train_on_pred_boxes", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            box_in_features (list[str]): list of feature names to use for the box head.\n            box_pooler (ROIPooler): pooler to extra region features for box head\n            box_head (nn.Module): transform features to make box predictions\n            box_predictor (nn.Module): make box predictions from the feature.\n                Should have the same interface as :class:`FastRCNNOutputLayers`.\n            mask_in_features (list[str]): list of feature names to use for the mask\n                pooler or mask head. None if not using mask head.\n            mask_pooler (ROIPooler): pooler to extract region features from image features.\n                The mask head will then take region features to make predictions.\n                If None, the mask head will directly take the dict of image features\n                defined by `mask_in_features`\n            mask_head (nn.Module): transform features to make mask predictions\n            keypoint_in_features, keypoint_pooler, keypoint_head: similar to ``mask_*``.\n            train_on_pred_boxes (bool): whether to use proposal boxes or\n                predicted boxes from the box head to train other heads.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# keep self.in_features for backward compatibility", "\n", "self", ".", "in_features", "=", "self", ".", "box_in_features", "=", "box_in_features", "\n", "self", ".", "box_pooler", "=", "box_pooler", "\n", "self", ".", "box_head", "=", "box_head", "\n", "self", ".", "box_predictor", "=", "box_predictor", "\n", "\n", "self", ".", "mask_on", "=", "mask_in_features", "is", "not", "None", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "self", ".", "mask_in_features", "=", "mask_in_features", "\n", "self", ".", "mask_pooler", "=", "mask_pooler", "\n", "self", ".", "mask_head", "=", "mask_head", "\n", "\n", "", "self", ".", "keypoint_on", "=", "keypoint_in_features", "is", "not", "None", "\n", "if", "self", ".", "keypoint_on", ":", "\n", "            ", "self", ".", "keypoint_in_features", "=", "keypoint_in_features", "\n", "self", ".", "keypoint_pooler", "=", "keypoint_pooler", "\n", "self", ".", "keypoint_head", "=", "keypoint_head", "\n", "\n", "", "self", ".", "train_on_pred_boxes", "=", "train_on_pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.from_config": [[593, 609], ["roi_heads.ROIHeads.from_config", "inspect.ismethod", "inspect.ismethod", "inspect.ismethod", "super().from_config.update", "super().from_config.update", "super().from_config.update", "cls._init_box_head", "cls._init_mask_head", "cls._init_keypoint_head"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._init_box_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._init_mask_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._init_keypoint_head"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ")", "\n", "ret", "[", "\"train_on_pred_boxes\"", "]", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "TRAIN_ON_PRED_BOXES", "\n", "# Subclasses that have not been updated to use from_config style construction", "\n", "# may have overridden _init_*_head methods. In this case, those overridden methods", "\n", "# will not be classmethods and we need to avoid trying to call them here.", "\n", "# We test for this with ismethod which only returns True for bound methods of cls.", "\n", "# Such subclasses will need to handle calling their overridden _init_*_head methods.", "\n", "if", "inspect", ".", "ismethod", "(", "cls", ".", "_init_box_head", ")", ":", "\n", "            ", "ret", ".", "update", "(", "cls", ".", "_init_box_head", "(", "cfg", ",", "input_shape", ")", ")", "\n", "", "if", "inspect", ".", "ismethod", "(", "cls", ".", "_init_mask_head", ")", ":", "\n", "            ", "ret", ".", "update", "(", "cls", ".", "_init_mask_head", "(", "cfg", ",", "input_shape", ")", ")", "\n", "", "if", "inspect", ".", "ismethod", "(", "cls", ".", "_init_keypoint_head", ")", ":", "\n", "            ", "ret", ".", "update", "(", "cls", ".", "_init_keypoint_head", "(", "cfg", ",", "input_shape", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._init_box_head": [[610, 645], ["tuple", "poolers.ROIPooler", "box_head.build_box_head.build_box_head", "fast_rcnn.FastRCNNOutputLayers", "len", "detectron2.layers.ShapeSpec", "set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.build_box_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "\n", "# If StandardROIHeads is applied on multiple feature maps (as in FPN),", "\n", "# then we share the same predictors and therefore the channel counts must be the same", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "# Here we split \"box head\" and \"box predictor\", which is mainly due to historical reasons.", "\n", "# They are used together so the \"box predictor\" layers should be part of the \"box head\".", "\n", "# New subclasses of ROIHeads do not need \"box predictor\"s.", "\n", "box_head", "=", "build_box_head", "(", "\n", "cfg", ",", "ShapeSpec", "(", "channels", "=", "in_channels", ",", "height", "=", "pooler_resolution", ",", "width", "=", "pooler_resolution", ")", "\n", ")", "\n", "box_predictor", "=", "FastRCNNOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_head\"", ":", "box_head", ",", "\n", "\"box_predictor\"", ":", "box_predictor", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._init_mask_head": [[647, 680], ["tuple", "mask_head.build_mask_head", "poolers.ROIPooler", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.build_mask_head"], ["", "@", "classmethod", "\n", "def", "_init_mask_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "if", "not", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "            ", "return", "{", "}", "\n", "# fmt: off", "\n", "", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "[", "0", "]", "\n", "\n", "ret", "=", "{", "\"mask_in_features\"", ":", "in_features", "}", "\n", "ret", "[", "\"mask_pooler\"", "]", "=", "(", "\n", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "if", "pooler_type", "\n", "else", "None", "\n", ")", "\n", "if", "pooler_type", ":", "\n", "            ", "shape", "=", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "width", "=", "pooler_resolution", ",", "height", "=", "pooler_resolution", "\n", ")", "\n", "", "else", ":", "\n", "            ", "shape", "=", "{", "f", ":", "input_shape", "[", "f", "]", "for", "f", "in", "in_features", "}", "\n", "", "ret", "[", "\"mask_head\"", "]", "=", "build_mask_head", "(", "cfg", ",", "shape", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._init_keypoint_head": [[681, 714], ["tuple", "keypoint_head.build_keypoint_head", "poolers.ROIPooler", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.build_keypoint_head"], ["", "@", "classmethod", "\n", "def", "_init_keypoint_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "if", "not", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "return", "{", "}", "\n", "# fmt: off", "\n", "", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "# noqa", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "[", "0", "]", "\n", "\n", "ret", "=", "{", "\"keypoint_in_features\"", ":", "in_features", "}", "\n", "ret", "[", "\"keypoint_pooler\"", "]", "=", "(", "\n", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "if", "pooler_type", "\n", "else", "None", "\n", ")", "\n", "if", "pooler_type", ":", "\n", "            ", "shape", "=", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "width", "=", "pooler_resolution", ",", "height", "=", "pooler_resolution", "\n", ")", "\n", "", "else", ":", "\n", "            ", "shape", "=", "{", "f", ":", "input_shape", "[", "f", "]", "for", "f", "in", "in_features", "}", "\n", "", "ret", "[", "\"keypoint_head\"", "]", "=", "build_keypoint_head", "(", "cfg", ",", "shape", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward": [[715, 745], ["roi_heads.StandardROIHeads.label_and_sample_proposals", "roi_heads.StandardROIHeads._forward_box", "roi_heads.StandardROIHeads.update", "roi_heads.StandardROIHeads.update", "roi_heads.StandardROIHeads._forward_box", "roi_heads.StandardROIHeads.forward_with_given_boxes", "roi_heads.StandardROIHeads._forward_mask", "roi_heads.StandardROIHeads._forward_keypoint"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_keypoint"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "targets", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Instances", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        See :class:`ROIHeads.forward`.\n        \"\"\"", "\n", "del", "images", "\n", "if", "self", ".", "training", ":", "\n", "            ", "assert", "targets", ",", "\"'targets' argument is required during training\"", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "proposals", ",", "targets", ")", "\n", "", "del", "targets", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "losses", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ")", "\n", "# Usually the original proposals used by the box head are used by the mask, keypoint", "\n", "# heads. But when `self.train_on_pred_boxes is True`, proposals will contain boxes", "\n", "# predicted by the box head.", "\n", "losses", ".", "update", "(", "self", ".", "_forward_mask", "(", "features", ",", "proposals", ")", ")", "\n", "losses", ".", "update", "(", "self", ".", "_forward_keypoint", "(", "features", ",", "proposals", ")", ")", "\n", "return", "proposals", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ")", "\n", "# During inference cascaded prediction is used: the mask and keypoints heads are only", "\n", "# applied to the top scoring box detections.", "\n", "pred_instances", "=", "self", ".", "forward_with_given_boxes", "(", "features", ",", "pred_instances", ")", "\n", "return", "pred_instances", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes": [[746, 772], ["roi_heads.StandardROIHeads._forward_mask", "roi_heads.StandardROIHeads._forward_keypoint", "instances[].has", "instances[].has"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_keypoint", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["", "", "def", "forward_with_given_boxes", "(", "\n", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "instances", ":", "List", "[", "Instances", "]", "\n", ")", "->", "List", "[", "Instances", "]", ":", "\n", "        ", "\"\"\"\n        Use the given boxes in `instances` to produce other (non-box) per-ROI outputs.\n\n        This is useful for downstream tasks where a box is known, but need to obtain\n        other attributes (outputs of other heads).\n        Test-time augmentation also uses this.\n\n        Args:\n            features: same as in `forward()`\n            instances (list[Instances]): instances to predict other outputs. Expect the keys\n                \"pred_boxes\" and \"pred_classes\" to exist.\n\n        Returns:\n            list[Instances]:\n                the same `Instances` objects, with extra\n                fields such as `pred_masks` or `pred_keypoints`.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "assert", "instances", "[", "0", "]", ".", "has", "(", "\"pred_boxes\"", ")", "and", "instances", "[", "0", "]", ".", "has", "(", "\"pred_classes\"", ")", "\n", "\n", "instances", "=", "self", ".", "_forward_mask", "(", "features", ",", "instances", ")", "\n", "instances", "=", "self", ".", "_forward_keypoint", "(", "features", ",", "instances", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_box": [[773, 810], ["roi_heads.StandardROIHeads.box_pooler", "roi_heads.StandardROIHeads.box_head", "roi_heads.StandardROIHeads.box_predictor", "roi_heads.StandardROIHeads.box_predictor.losses", "roi_heads.StandardROIHeads.box_predictor.inference", "torch.no_grad", "roi_heads.StandardROIHeads.box_predictor.predict_boxes_for_gt_classes", "zip", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes_for_gt_classes"], ["", "def", "_forward_box", "(", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Forward logic of the box prediction branch. If `self.train_on_pred_boxes is True`,\n            the function puts predicted boxes in the `proposal_boxes` field of `proposals` argument.\n\n        Args:\n            features (dict[str, Tensor]): mapping from feature map names to tensor.\n                Same as in :meth:`ROIHeads.forward`.\n            proposals (list[Instances]): the per-image object proposals with\n                their matching ground truth.\n                Each has fields \"proposal_boxes\", and \"objectness_logits\",\n                \"gt_classes\", \"gt_boxes\".\n\n        Returns:\n            In training, a dict of losses.\n            In inference, a list of `Instances`, the predicted instances.\n        \"\"\"", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "box_in_features", "]", "\n", "box_features", "=", "self", ".", "box_pooler", "(", "features", ",", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", ")", "\n", "box_features", "=", "self", ".", "box_head", "(", "box_features", ")", "\n", "predictions", "=", "self", ".", "box_predictor", "(", "box_features", ")", "\n", "del", "box_features", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "losses", "=", "self", ".", "box_predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "# proposals is modified in-place below, so losses must be computed first.", "\n", "if", "self", ".", "train_on_pred_boxes", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pred_boxes", "=", "self", ".", "box_predictor", ".", "predict_boxes_for_gt_classes", "(", "\n", "predictions", ",", "proposals", "\n", ")", "\n", "for", "proposals_per_image", ",", "pred_boxes_per_image", "in", "zip", "(", "proposals", ",", "pred_boxes", ")", ":", "\n", "                        ", "proposals_per_image", ".", "proposal_boxes", "=", "Boxes", "(", "pred_boxes_per_image", ")", "\n", "", "", "", "return", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", ",", "_", "=", "self", ".", "box_predictor", ".", "inference", "(", "predictions", ",", "proposals", ")", "\n", "return", "pred_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_mask": [[811, 840], ["roi_heads.StandardROIHeads.mask_head", "roi_heads.select_foreground_proposals", "roi_heads.StandardROIHeads.mask_pooler"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_foreground_proposals"], ["", "", "def", "_forward_mask", "(", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Forward logic of the mask prediction branch.\n\n        Args:\n            features (dict[str, Tensor]): mapping from feature map names to tensor.\n                Same as in :meth:`ROIHeads.forward`.\n            instances (list[Instances]): the per-image instances to train/predict masks.\n                In training, they can be the proposals.\n                In inference, they can be the boxes predicted by R-CNN box head.\n\n        Returns:\n            In training, a dict of losses.\n            In inference, update `instances` with new fields \"pred_masks\" and return it.\n        \"\"\"", "\n", "if", "not", "self", ".", "mask_on", ":", "\n", "            ", "return", "{", "}", "if", "self", ".", "training", "else", "instances", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "# head is only trained on positive proposals.", "\n", "            ", "instances", ",", "_", "=", "select_foreground_proposals", "(", "instances", ",", "self", ".", "num_classes", ")", "\n", "\n", "", "if", "self", ".", "mask_pooler", "is", "not", "None", ":", "\n", "            ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "mask_in_features", "]", "\n", "boxes", "=", "[", "x", ".", "proposal_boxes", "if", "self", ".", "training", "else", "x", ".", "pred_boxes", "for", "x", "in", "instances", "]", "\n", "features", "=", "self", ".", "mask_pooler", "(", "features", ",", "boxes", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "{", "f", ":", "features", "[", "f", "]", "for", "f", "in", "self", ".", "mask_in_features", "}", "\n", "", "return", "self", ".", "mask_head", "(", "features", ",", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_keypoint": [[841, 871], ["roi_heads.StandardROIHeads.keypoint_head", "roi_heads.select_foreground_proposals", "roi_heads.select_proposals_with_visible_keypoints", "roi_heads.StandardROIHeads.keypoint_pooler"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_foreground_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_proposals_with_visible_keypoints"], ["", "def", "_forward_keypoint", "(", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Forward logic of the keypoint prediction branch.\n\n        Args:\n            features (dict[str, Tensor]): mapping from feature map names to tensor.\n                Same as in :meth:`ROIHeads.forward`.\n            instances (list[Instances]): the per-image instances to train/predict keypoints.\n                In training, they can be the proposals.\n                In inference, they can be the boxes predicted by R-CNN box head.\n\n        Returns:\n            In training, a dict of losses.\n            In inference, update `instances` with new fields \"pred_keypoints\" and return it.\n        \"\"\"", "\n", "if", "not", "self", ".", "keypoint_on", ":", "\n", "            ", "return", "{", "}", "if", "self", ".", "training", "else", "instances", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "# head is only trained on positive proposals with >=1 visible keypoints.", "\n", "            ", "instances", ",", "_", "=", "select_foreground_proposals", "(", "instances", ",", "self", ".", "num_classes", ")", "\n", "instances", "=", "select_proposals_with_visible_keypoints", "(", "instances", ")", "\n", "\n", "", "if", "self", ".", "keypoint_pooler", "is", "not", "None", ":", "\n", "            ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "keypoint_in_features", "]", "\n", "boxes", "=", "[", "x", ".", "proposal_boxes", "if", "self", ".", "training", "else", "x", ".", "pred_boxes", "for", "x", "in", "instances", "]", "\n", "features", "=", "self", ".", "keypoint_pooler", "(", "features", ",", "boxes", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "{", "f", ":", "features", "[", "f", "]", "for", "f", "in", "self", ".", "keypoint_in_features", "}", "\n", "", "return", "self", ".", "keypoint_head", "(", "features", ",", "instances", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.build_roi_heads": [[38, 44], ["ROI_HEADS_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "build_roi_heads", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build ROIHeads defined by `cfg.MODEL.ROI_HEADS.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NAME", "\n", "return", "ROI_HEADS_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_foreground_proposals": [[46, 76], ["isinstance", "isinstance", "proposals[].has", "fg_selection_mask.nonzero().squeeze", "fg_proposals.append", "fg_selection_masks.append", "fg_selection_mask.nonzero"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has"], ["", "def", "select_foreground_proposals", "(", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "bg_label", ":", "int", "\n", ")", "->", "Tuple", "[", "List", "[", "Instances", "]", ",", "List", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "    ", "\"\"\"\n    Given a list of N Instances (for N images), each containing a `gt_classes` field,\n    return a list of Instances that contain only instances with `gt_classes != -1 &&\n    gt_classes != bg_label`.\n\n    Args:\n        proposals (list[Instances]): A list of N Instances, where N is the number of\n            images in the batch.\n        bg_label: label index of background class.\n\n    Returns:\n        list[Instances]: N Instances, each contains only the selected foreground instances.\n        list[Tensor]: N boolean vector, correspond to the selection mask of\n            each Instances object. True for selected instances.\n    \"\"\"", "\n", "assert", "isinstance", "(", "proposals", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "proposals", "[", "0", "]", ",", "Instances", ")", "\n", "assert", "proposals", "[", "0", "]", ".", "has", "(", "\"gt_classes\"", ")", "\n", "fg_proposals", "=", "[", "]", "\n", "fg_selection_masks", "=", "[", "]", "\n", "for", "proposals_per_image", "in", "proposals", ":", "\n", "        ", "gt_classes", "=", "proposals_per_image", ".", "gt_classes", "\n", "fg_selection_mask", "=", "(", "gt_classes", "!=", "-", "1", ")", "&", "(", "gt_classes", "!=", "bg_label", ")", "\n", "fg_idxs", "=", "fg_selection_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "fg_proposals", ".", "append", "(", "proposals_per_image", "[", "fg_idxs", "]", ")", "\n", "fg_selection_masks", ".", "append", "(", "fg_selection_mask", ")", "\n", "", "return", "fg_proposals", ",", "fg_selection_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.select_proposals_with_visible_keypoints": [[78, 121], ["detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "proposals_per_image.proposal_boxes.tensor.unsqueeze", "all_num_fg.append", "ret.append", "numpy.mean", "len", "ret.append", "detectron2.layers.nonzero_tuple", "selection_idxs.numel"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple"], ["", "def", "select_proposals_with_visible_keypoints", "(", "proposals", ":", "List", "[", "Instances", "]", ")", "->", "List", "[", "Instances", "]", ":", "\n", "    ", "\"\"\"\n    Args:\n        proposals (list[Instances]): a list of N Instances, where N is the\n            number of images.\n\n    Returns:\n        proposals: only contains proposals with at least one visible keypoint.\n\n    Note that this is still slightly different from Detectron.\n    In Detectron, proposals for training keypoint head are re-sampled from\n    all the proposals with IOU>threshold & >=1 visible keypoint.\n\n    Here, the proposals are first sampled from all proposals with\n    IOU>threshold, then proposals with no visible keypoint are filtered out.\n    This strategy seems to make no difference on Detectron and is easier to implement.\n    \"\"\"", "\n", "ret", "=", "[", "]", "\n", "all_num_fg", "=", "[", "]", "\n", "for", "proposals_per_image", "in", "proposals", ":", "\n", "# If empty/unannotated image (hard negatives), skip filtering for train", "\n", "        ", "if", "len", "(", "proposals_per_image", ")", "==", "0", ":", "\n", "            ", "ret", ".", "append", "(", "proposals_per_image", ")", "\n", "continue", "\n", "", "gt_keypoints", "=", "proposals_per_image", ".", "gt_keypoints", ".", "tensor", "\n", "# #fg x K x 3", "\n", "vis_mask", "=", "gt_keypoints", "[", ":", ",", ":", ",", "2", "]", ">=", "1", "\n", "xs", ",", "ys", "=", "gt_keypoints", "[", ":", ",", ":", ",", "0", "]", ",", "gt_keypoints", "[", ":", ",", ":", ",", "1", "]", "\n", "proposal_boxes", "=", "proposals_per_image", ".", "proposal_boxes", ".", "tensor", ".", "unsqueeze", "(", "dim", "=", "1", ")", "# #fg x 1 x 4", "\n", "kp_in_box", "=", "(", "\n", "(", "xs", ">=", "proposal_boxes", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "&", "(", "xs", "<=", "proposal_boxes", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "&", "(", "ys", ">=", "proposal_boxes", "[", ":", ",", ":", ",", "1", "]", ")", "\n", "&", "(", "ys", "<=", "proposal_boxes", "[", ":", ",", ":", ",", "3", "]", ")", "\n", ")", "\n", "selection", "=", "(", "kp_in_box", "&", "vis_mask", ")", ".", "any", "(", "dim", "=", "1", ")", "\n", "selection_idxs", "=", "nonzero_tuple", "(", "selection", ")", "[", "0", "]", "\n", "all_num_fg", ".", "append", "(", "selection_idxs", ".", "numel", "(", ")", ")", "\n", "ret", ".", "append", "(", "proposals_per_image", "[", "selection_idxs", "]", ")", "\n", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"keypoint_head/num_fg_samples\"", ",", "np", ".", "mean", "(", "all_num_fg", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.BaseKeypointRCNNHead.__init__": [[141, 159], ["torch.nn.Module.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", ",", "num_keypoints", ",", "loss_weight", "=", "1.0", ",", "loss_normalizer", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            num_keypoints (int): number of keypoints to predict\n            loss_weight (float): weight to multiple on the keypoint loss\n            loss_normalizer (float or str):\n                If float, divide the loss by `loss_normalizer * #images`.\n                If 'visible', the loss is normalized by the total number of\n                visible keypoints across images.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_keypoints", "=", "num_keypoints", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "assert", "loss_normalizer", "==", "\"visible\"", "or", "isinstance", "(", "loss_normalizer", ",", "float", ")", ",", "loss_normalizer", "\n", "self", ".", "loss_normalizer", "=", "loss_normalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.BaseKeypointRCNNHead.from_config": [[160, 178], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "{", "\n", "\"loss_weight\"", ":", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "LOSS_WEIGHT", ",", "\n", "\"num_keypoints\"", ":", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NUM_KEYPOINTS", ",", "\n", "}", "\n", "normalize_by_visible", "=", "(", "\n", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS", "\n", ")", "# noqa", "\n", "if", "not", "normalize_by_visible", ":", "\n", "            ", "batch_size_per_image", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "BATCH_SIZE_PER_IMAGE", "\n", "positive_sample_fraction", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "POSITIVE_FRACTION", "\n", "ret", "[", "\"loss_normalizer\"", "]", "=", "(", "\n", "ret", "[", "\"num_keypoints\"", "]", "*", "batch_size_per_image", "*", "positive_sample_fraction", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ret", "[", "\"loss_normalizer\"", "]", "=", "\"visible\"", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.BaseKeypointRCNNHead.forward": [[179, 206], ["keypoint_head.BaseKeypointRCNNHead.layers", "len", "keypoint_head.keypoint_rcnn_inference", "keypoint_head.keypoint_rcnn_loss"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.layers", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.keypoint_rcnn_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.keypoint_rcnn_loss"], ["", "def", "forward", "(", "self", ",", "x", ",", "instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: input 4D region feature(s) provided by :class:`ROIHeads`.\n            instances (list[Instances]): contains the boxes & labels corresponding\n                to the input features.\n                Exact format is up to its caller to decide.\n                Typically, this is the foreground instances in training, with\n                \"proposal_boxes\" field and other gt annotations.\n                In inference, it contains boxes that are already predicted.\n\n        Returns:\n            A dict of losses if in training. The predicted \"instances\" if in inference.\n        \"\"\"", "\n", "x", "=", "self", ".", "layers", "(", "x", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "num_images", "=", "len", "(", "instances", ")", "\n", "normalizer", "=", "(", "\n", "None", "if", "self", ".", "loss_normalizer", "==", "\"visible\"", "else", "num_images", "*", "self", ".", "loss_normalizer", "\n", ")", "\n", "return", "{", "\n", "\"loss_keypoint\"", ":", "keypoint_rcnn_loss", "(", "x", ",", "instances", ",", "normalizer", "=", "normalizer", ")", "\n", "*", "self", ".", "loss_weight", "\n", "}", "\n", "", "else", ":", "\n", "            ", "keypoint_rcnn_inference", "(", "x", ",", "instances", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.BaseKeypointRCNNHead.layers": [[207, 212], ["None"], "methods", ["None"], ["", "", "def", "layers", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Neural network layers that makes predictions from regional input features.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.__init__": [[225, 260], ["super().__init__", "enumerate", "detectron2.layers.ConvTranspose2d", "keypoint_head.KRCNNConvDeconvUpsampleHead.named_parameters", "detectron2.layers.Conv2d", "keypoint_head.KRCNNConvDeconvUpsampleHead.add_module", "keypoint_head.KRCNNConvDeconvUpsampleHead.add_module", "torch.nn.ReLU", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "input_shape", ",", "*", ",", "num_keypoints", ",", "conv_dims", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature\n            conv_dims: an iterable of output channel counts for each conv in the head\n                         e.g. (512, 512, 512) for three convs outputting 512 channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "num_keypoints", "=", "num_keypoints", ",", "**", "kwargs", ")", "\n", "\n", "# default up_scale to 2.0 (this can be made an option)", "\n", "up_scale", "=", "2.0", "\n", "in_channels", "=", "input_shape", ".", "channels", "\n", "\n", "for", "idx", ",", "layer_channels", "in", "enumerate", "(", "conv_dims", ",", "1", ")", ":", "\n", "            ", "module", "=", "Conv2d", "(", "in_channels", ",", "layer_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "add_module", "(", "\"conv_fcn{}\"", ".", "format", "(", "idx", ")", ",", "module", ")", "\n", "self", ".", "add_module", "(", "\"conv_fcn_relu{}\"", ".", "format", "(", "idx", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "in_channels", "=", "layer_channels", "\n", "\n", "", "deconv_kernel", "=", "4", "\n", "self", ".", "score_lowres", "=", "ConvTranspose2d", "(", "\n", "in_channels", ",", "num_keypoints", ",", "deconv_kernel", ",", "stride", "=", "2", ",", "padding", "=", "deconv_kernel", "//", "2", "-", "1", "\n", ")", "\n", "self", ".", "up_scale", "=", "up_scale", "\n", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"bias\"", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "param", ",", "0", ")", "\n", "", "elif", "\"weight\"", "in", "name", ":", "\n", "# Caffe2 implementation uses MSRAFill, which in fact", "\n", "# corresponds to kaiming_normal_ in PyTorch", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "param", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.from_config": [[261, 267], ["super().from_config"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config"], ["", "", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", "[", "\"input_shape\"", "]", "=", "input_shape", "\n", "ret", "[", "\"conv_dims\"", "]", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "CONV_DIMS", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.layers": [[268, 273], ["detectron2.layers.interpolate", "layer"], "methods", ["None"], ["", "def", "layers", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "x", "=", "interpolate", "(", "x", ",", "scale_factor", "=", "self", ".", "up_scale", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.build_keypoint_head": [[32, 38], ["ROI_KEYPOINT_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "build_keypoint_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a keypoint head from `cfg.MODEL.ROI_KEYPOINT_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NAME", "\n", "return", "ROI_KEYPOINT_HEAD_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.keypoint_rcnn_loss": [[40, 97], ["len", "pred_keypoint_logits.view.view", "torch.nn.functional.cross_entropy", "keypoints.to_heatmap", "heatmaps.append", "torch.nonzero().squeeze.append", "detectron2.layers.cat", "detectron2.layers.cat().to", "torch.nonzero().squeeze", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "torch.nonzero().squeeze.numel", "len", "heatmaps_per_image.view", "valid_per_image.view", "len", "torch.nonzero().squeeze.numel", "pred_keypoint_logits.view.sum", "detectron2.layers.cat", "torch.nonzero"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.to_heatmap", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "keypoint_rcnn_loss", "(", "pred_keypoint_logits", ",", "instances", ",", "normalizer", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        pred_keypoint_logits (Tensor): A tensor of shape (N, K, S, S) where N is the total number\n            of instances in the batch, K is the number of keypoints, and S is the side length\n            of the keypoint heatmap. The values are spatial logits.\n        instances (list[Instances]): A list of M Instances, where M is the batch size.\n            These instances are predictions from the model\n            that are in 1:1 correspondence with pred_keypoint_logits.\n            Each Instances should contain a `gt_keypoints` field containing a `structures.Keypoint`\n            instance.\n        normalizer (float): Normalize the loss by this amount.\n            If not specified, we normalize by the number of visible keypoints in the minibatch.\n\n    Returns a scalar tensor containing the loss.\n    \"\"\"", "\n", "heatmaps", "=", "[", "]", "\n", "valid", "=", "[", "]", "\n", "\n", "keypoint_side_len", "=", "pred_keypoint_logits", ".", "shape", "[", "2", "]", "\n", "for", "instances_per_image", "in", "instances", ":", "\n", "        ", "if", "len", "(", "instances_per_image", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "keypoints", "=", "instances_per_image", ".", "gt_keypoints", "\n", "heatmaps_per_image", ",", "valid_per_image", "=", "keypoints", ".", "to_heatmap", "(", "\n", "instances_per_image", ".", "proposal_boxes", ".", "tensor", ",", "keypoint_side_len", "\n", ")", "\n", "heatmaps", ".", "append", "(", "heatmaps_per_image", ".", "view", "(", "-", "1", ")", ")", "\n", "valid", ".", "append", "(", "valid_per_image", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "len", "(", "heatmaps", ")", ":", "\n", "        ", "keypoint_targets", "=", "cat", "(", "heatmaps", ",", "dim", "=", "0", ")", "\n", "valid", "=", "cat", "(", "valid", ",", "dim", "=", "0", ")", ".", "to", "(", "dtype", "=", "torch", ".", "uint8", ")", "\n", "valid", "=", "torch", ".", "nonzero", "(", "valid", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# torch.mean (in binary_cross_entropy_with_logits) doesn't", "\n", "# accept empty tensors, so handle it separately", "\n", "", "if", "len", "(", "heatmaps", ")", "==", "0", "or", "valid", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "global", "_TOTAL_SKIPPED", "\n", "_TOTAL_SKIPPED", "+=", "1", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"kpts_num_skipped_batches\"", ",", "_TOTAL_SKIPPED", ",", "smoothing_hint", "=", "False", ")", "\n", "return", "pred_keypoint_logits", ".", "sum", "(", ")", "*", "0", "\n", "\n", "", "N", ",", "K", ",", "H", ",", "W", "=", "pred_keypoint_logits", ".", "shape", "\n", "pred_keypoint_logits", "=", "pred_keypoint_logits", ".", "view", "(", "N", "*", "K", ",", "H", "*", "W", ")", "\n", "\n", "keypoint_loss", "=", "F", ".", "cross_entropy", "(", "\n", "pred_keypoint_logits", "[", "valid", "]", ",", "keypoint_targets", "[", "valid", "]", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "\n", "# If a normalizer isn't specified, normalize by the number of visible keypoints in the minibatch", "\n", "if", "normalizer", "is", "None", ":", "\n", "        ", "normalizer", "=", "valid", ".", "numel", "(", ")", "\n", "", "keypoint_loss", "/=", "normalizer", "\n", "\n", "return", "keypoint_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.keypoint_rcnn_inference": [[99, 133], ["detectron2.layers.cat", "pred_keypoint_logits.detach.detach", "detectron2.structures.heatmaps_to_keypoints", "keypoint_results[].split", "pred_keypoint_logits.detach.split", "zip", "detectron2.layers.cat.detach", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.heatmaps_to_keypoints"], ["", "def", "keypoint_rcnn_inference", "(", "pred_keypoint_logits", ":", "torch", ".", "Tensor", ",", "pred_instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "    ", "\"\"\"\n    Post process each predicted keypoint heatmap in `pred_keypoint_logits` into (x, y, score)\n        and add it to the `pred_instances` as a `pred_keypoints` field.\n\n    Args:\n        pred_keypoint_logits (Tensor): A tensor of shape (R, K, S, S) where R is the total number\n           of instances in the batch, K is the number of keypoints, and S is the side length of\n           the keypoint heatmap. The values are spatial logits.\n        pred_instances (list[Instances]): A list of N Instances, where N is the number of images.\n\n    Returns:\n        None. Each element in pred_instances will contain extra \"pred_keypoints\" and\n            \"pred_keypoint_heatmaps\" fields. \"pred_keypoints\" is a tensor of shape\n            (#instance, K, 3) where the last dimension corresponds to (x, y, score).\n            The scores are larger than 0. \"pred_keypoint_heatmaps\" contains the raw\n            keypoint logits as passed to this function.\n    \"\"\"", "\n", "# flatten all bboxes from all images together (list[Boxes] -> Rx4 tensor)", "\n", "bboxes_flat", "=", "cat", "(", "[", "b", ".", "pred_boxes", ".", "tensor", "for", "b", "in", "pred_instances", "]", ",", "dim", "=", "0", ")", "\n", "\n", "pred_keypoint_logits", "=", "pred_keypoint_logits", ".", "detach", "(", ")", "\n", "keypoint_results", "=", "heatmaps_to_keypoints", "(", "pred_keypoint_logits", ",", "bboxes_flat", ".", "detach", "(", ")", ")", "\n", "num_instances_per_image", "=", "[", "len", "(", "i", ")", "for", "i", "in", "pred_instances", "]", "\n", "keypoint_results", "=", "keypoint_results", "[", ":", ",", ":", ",", "[", "0", ",", "1", ",", "3", "]", "]", ".", "split", "(", "num_instances_per_image", ",", "dim", "=", "0", ")", "\n", "heatmap_results", "=", "pred_keypoint_logits", ".", "split", "(", "num_instances_per_image", ",", "dim", "=", "0", ")", "\n", "\n", "for", "keypoint_results_per_image", ",", "heatmap_results_per_image", ",", "instances_per_image", "in", "zip", "(", "\n", "keypoint_results", ",", "heatmap_results", ",", "pred_instances", "\n", ")", ":", "\n", "# keypoint_results_per_image is (num instances)x(num keypoints)x(x, y, score)", "\n", "# heatmap_results_per_image is (num instances)x(num keypoints)x(side)x(side)", "\n", "        ", "instances_per_image", ".", "pred_keypoints", "=", "keypoint_results_per_image", "\n", "instances_per_image", ".", "pred_keypoint_heatmaps", "=", "heatmap_results_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.FastRCNNConvFCHead.__init__": [[32, 80], ["torch.nn.Sequential.__init__", "enumerate", "enumerate", "detectron2.layers.Conv2d", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.conv_norm_relus.append", "torch.nn.Linear", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.fcs.append", "fvcore.c2_msra_fill", "fvcore.c2_xavier_fill", "len", "len", "box_head.FastRCNNConvFCHead.add_module", "int", "torch.nn.ReLU", "detectron2.layers.get_norm", "torch.nn.ReLU", "torch.nn.Flatten", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "input_shape", ":", "ShapeSpec", ",", "*", ",", "conv_dims", ":", "List", "[", "int", "]", ",", "fc_dims", ":", "List", "[", "int", "]", ",", "conv_norm", "=", "\"\"", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature.\n            conv_dims (list[int]): the output dimensions of the conv layers\n            fc_dims (list[int]): the output dimensions of the fc layers\n            conv_norm (str or callable): normalization for the conv layers.\n                See :func:`detectron2.layers.get_norm` for supported types.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "conv_dims", ")", "+", "len", "(", "fc_dims", ")", ">", "0", "\n", "\n", "self", ".", "_output_size", "=", "(", "input_shape", ".", "channels", ",", "input_shape", ".", "height", ",", "input_shape", ".", "width", ")", "\n", "\n", "self", ".", "conv_norm_relus", "=", "[", "]", "\n", "for", "k", ",", "conv_dim", "in", "enumerate", "(", "conv_dims", ")", ":", "\n", "            ", "conv", "=", "Conv2d", "(", "\n", "self", ".", "_output_size", "[", "0", "]", ",", "\n", "conv_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "conv_norm", ",", "\n", "norm", "=", "get_norm", "(", "conv_norm", ",", "conv_dim", ")", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "self", ".", "add_module", "(", "\"conv{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "conv", ")", "\n", "self", ".", "conv_norm_relus", ".", "append", "(", "conv", ")", "\n", "self", ".", "_output_size", "=", "(", "conv_dim", ",", "self", ".", "_output_size", "[", "1", "]", ",", "self", ".", "_output_size", "[", "2", "]", ")", "\n", "\n", "", "self", ".", "fcs", "=", "[", "]", "\n", "for", "k", ",", "fc_dim", "in", "enumerate", "(", "fc_dims", ")", ":", "\n", "            ", "if", "k", "==", "0", ":", "\n", "                ", "self", ".", "add_module", "(", "\"flatten\"", ",", "nn", ".", "Flatten", "(", ")", ")", "\n", "", "fc", "=", "nn", ".", "Linear", "(", "int", "(", "np", ".", "prod", "(", "self", ".", "_output_size", ")", ")", ",", "fc_dim", ")", "\n", "self", ".", "add_module", "(", "\"fc{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "fc", ")", "\n", "self", ".", "add_module", "(", "\"fc_relu{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "fcs", ".", "append", "(", "fc", ")", "\n", "self", ".", "_output_size", "=", "fc_dim", "\n", "\n", "", "for", "layer", "in", "self", ".", "conv_norm_relus", ":", "\n", "            ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "", "for", "layer", "in", "self", ".", "fcs", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.FastRCNNConvFCHead.from_config": [[81, 92], ["None"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "num_conv", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CONV", "\n", "conv_dim", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CONV_DIM", "\n", "num_fc", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_FC", "\n", "fc_dim", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "FC_DIM", "\n", "return", "{", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"conv_dims\"", ":", "[", "conv_dim", "]", "*", "num_conv", ",", "\n", "\"fc_dims\"", ":", "[", "fc_dim", "]", "*", "num_fc", ",", "\n", "\"conv_norm\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NORM", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.FastRCNNConvFCHead.forward": [[94, 98], ["layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.FastRCNNConvFCHead.output_shape": [[99, 111], ["isinstance", "detectron2.layers.ShapeSpec", "detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "@", "property", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            ShapeSpec: the output feature shape\n        \"\"\"", "\n", "o", "=", "self", ".", "_output_size", "\n", "if", "isinstance", "(", "o", ",", "int", ")", ":", "\n", "            ", "return", "ShapeSpec", "(", "channels", "=", "o", ")", "\n", "", "else", ":", "\n", "            ", "return", "ShapeSpec", "(", "channels", "=", "o", "[", "0", "]", ",", "height", "=", "o", "[", "1", "]", ",", "width", "=", "o", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.build_box_head": [[113, 119], ["ROI_BOX_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "", "def", "build_box_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a box head defined by `cfg.MODEL.ROI_BOX_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NAME", "\n", "return", "ROI_BOX_HEAD_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn._ScaleGradient.forward": [[21, 25], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "scale", ")", ":", "\n", "        ", "ctx", ".", "scale", "=", "scale", "\n", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn._ScaleGradient.backward": [[26, 29], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "grad_output", "*", "ctx", ".", "scale", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads.__init__": [[37, 79], ["len", "torch.nn.ModuleList", "torch.nn.ModuleList", "roi_heads.StandardROIHeads.__init__", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "box_in_features", ":", "List", "[", "str", "]", ",", "\n", "box_pooler", ":", "ROIPooler", ",", "\n", "box_heads", ":", "List", "[", "nn", ".", "Module", "]", ",", "\n", "box_predictors", ":", "List", "[", "nn", ".", "Module", "]", ",", "\n", "proposal_matchers", ":", "List", "[", "Matcher", "]", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            box_pooler (ROIPooler): pooler that extracts region features from given boxes\n            box_heads (list[nn.Module]): box head for each cascade stage\n            box_predictors (list[nn.Module]): box predictor for each cascade stage\n            proposal_matchers (list[Matcher]): matcher with different IoU thresholds to\n                match boxes with ground truth for each stage. The first matcher matches\n                RPN proposals with ground truth, the other matchers use boxes predicted\n                by the previous stage as proposals and match them with ground truth.\n        \"\"\"", "\n", "assert", "\"proposal_matcher\"", "not", "in", "kwargs", ",", "(", "\n", "\"CascadeROIHeads takes 'proposal_matchers=' for each stage instead \"", "\n", "\"of one 'proposal_matcher='.\"", "\n", ")", "\n", "# The first matcher matches RPN proposals with ground truth, done in the base class", "\n", "kwargs", "[", "\"proposal_matcher\"", "]", "=", "proposal_matchers", "[", "0", "]", "\n", "num_stages", "=", "self", ".", "num_cascade_stages", "=", "len", "(", "box_heads", ")", "\n", "box_heads", "=", "nn", ".", "ModuleList", "(", "box_heads", ")", "\n", "box_predictors", "=", "nn", ".", "ModuleList", "(", "box_predictors", ")", "\n", "assert", "len", "(", "box_predictors", ")", "==", "num_stages", ",", "f\"{len(box_predictors)} != {num_stages}!\"", "\n", "assert", "len", "(", "proposal_matchers", ")", "==", "num_stages", ",", "f\"{len(proposal_matchers)} != {num_stages}!\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "box_in_features", "=", "box_in_features", ",", "\n", "box_pooler", "=", "box_pooler", ",", "\n", "box_head", "=", "box_heads", ",", "\n", "box_predictor", "=", "box_predictors", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "self", ".", "proposal_matchers", "=", "proposal_matchers", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads.from_config": [[80, 85], ["super().from_config", "super().from_config.pop"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", ".", "pop", "(", "\"proposal_matcher\"", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._init_box_head": [[86, 135], ["tuple", "poolers.ROIPooler", "detectron2.layers.ShapeSpec", "zip", "len", "len", "len", "box_head.build_box_head.build_box_head", "box_heads.append", "box_predictors.append", "proposal_matchers.append", "set", "fast_rcnn.FastRCNNOutputLayers", "matcher.Matcher", "box_regression.Box2BoxTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.box_head.build_box_head", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "cascade_bbox_reg_weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "BBOX_REG_WEIGHTS", "\n", "cascade_ious", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "IOUS", "\n", "assert", "len", "(", "cascade_bbox_reg_weights", ")", "==", "len", "(", "cascade_ious", ")", "\n", "assert", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CLS_AGNOSTIC_BBOX_REG", ",", "\"CascadeROIHeads only support class-agnostic regression now!\"", "\n", "assert", "cascade_ious", "[", "0", "]", "==", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IOU_THRESHOLDS", "[", "0", "]", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "pooled_shape", "=", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "width", "=", "pooler_resolution", ",", "height", "=", "pooler_resolution", "\n", ")", "\n", "\n", "box_heads", ",", "box_predictors", ",", "proposal_matchers", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "match_iou", ",", "bbox_reg_weights", "in", "zip", "(", "cascade_ious", ",", "cascade_bbox_reg_weights", ")", ":", "\n", "            ", "box_head", "=", "build_box_head", "(", "cfg", ",", "pooled_shape", ")", "\n", "box_heads", ".", "append", "(", "box_head", ")", "\n", "box_predictors", ".", "append", "(", "\n", "FastRCNNOutputLayers", "(", "\n", "cfg", ",", "\n", "box_head", ".", "output_shape", ",", "\n", "box2box_transform", "=", "Box2BoxTransform", "(", "weights", "=", "bbox_reg_weights", ")", ",", "\n", ")", "\n", ")", "\n", "proposal_matchers", ".", "append", "(", "Matcher", "(", "[", "match_iou", "]", ",", "[", "0", ",", "1", "]", ",", "allow_low_quality_matches", "=", "False", ")", ")", "\n", "", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_heads\"", ":", "box_heads", ",", "\n", "\"box_predictors\"", ":", "box_predictors", ",", "\n", "\"proposal_matchers\"", ":", "proposal_matchers", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads.forward": [[137, 152], ["cascade_rcnn.CascadeROIHeads.label_and_sample_proposals", "cascade_rcnn.CascadeROIHeads._forward_box", "cascade_rcnn.CascadeROIHeads.update", "cascade_rcnn.CascadeROIHeads.update", "cascade_rcnn.CascadeROIHeads._forward_box", "cascade_rcnn.CascadeROIHeads.forward_with_given_boxes", "cascade_rcnn.CascadeROIHeads._forward_mask", "cascade_rcnn.CascadeROIHeads._forward_keypoint"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.roi_heads.StandardROIHeads._forward_keypoint"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "del", "images", "\n", "if", "self", ".", "training", ":", "\n", "            ", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "proposals", ",", "targets", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "# Need targets to box head", "\n", "            ", "losses", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ",", "targets", ")", "\n", "losses", ".", "update", "(", "self", ".", "_forward_mask", "(", "features", ",", "proposals", ")", ")", "\n", "losses", ".", "update", "(", "self", ".", "_forward_keypoint", "(", "features", ",", "proposals", ")", ")", "\n", "return", "proposals", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ")", "\n", "pred_instances", "=", "self", ".", "forward_with_given_boxes", "(", "features", ",", "pred_instances", ")", "\n", "return", "pred_instances", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box": [[153, 207], ["range", "cascade_rcnn.CascadeROIHeads._run_stage", "cascade_rcnn.CascadeROIHeads.box_predictor[].predict_boxes", "head_outputs.append", "detectron2.utils.events.get_event_storage", "enumerate", "predictor.predict_boxes", "fast_rcnn.fast_rcnn_inference", "cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes", "losses.update", "h[].predict_probs", "cascade_rcnn.CascadeROIHeads._match_and_label_boxes", "detectron2.utils.events.get_event_storage.name_scope", "predictor.losses", "sum", "zip", "list", "predictor.losses.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._run_stage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.fast_rcnn_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._match_and_label_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.name_scope", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "_forward_box", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features, targets: the same as in\n                Same as in :meth:`ROIHeads.forward`.\n            proposals (list[Instances]): the per-image object proposals with\n                their matching ground truth.\n                Each has fields \"proposal_boxes\", and \"objectness_logits\",\n                \"gt_classes\", \"gt_boxes\".\n        \"\"\"", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "box_in_features", "]", "\n", "head_outputs", "=", "[", "]", "# (predictor, predictions, proposals)", "\n", "prev_pred_boxes", "=", "None", "\n", "image_sizes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "num_cascade_stages", ")", ":", "\n", "            ", "if", "k", ">", "0", ":", "\n", "# The output boxes of the previous stage are used to create the input", "\n", "# proposals of the next stage.", "\n", "                ", "proposals", "=", "self", ".", "_create_proposals_from_boxes", "(", "prev_pred_boxes", ",", "image_sizes", ")", "\n", "if", "self", ".", "training", ":", "\n", "                    ", "proposals", "=", "self", ".", "_match_and_label_boxes", "(", "proposals", ",", "k", ",", "targets", ")", "\n", "", "", "predictions", "=", "self", ".", "_run_stage", "(", "features", ",", "proposals", ",", "k", ")", "\n", "prev_pred_boxes", "=", "self", ".", "box_predictor", "[", "k", "]", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "head_outputs", ".", "append", "(", "(", "self", ".", "box_predictor", "[", "k", "]", ",", "predictions", ",", "proposals", ")", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "losses", "=", "{", "}", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "for", "stage", ",", "(", "predictor", ",", "predictions", ",", "proposals", ")", "in", "enumerate", "(", "head_outputs", ")", ":", "\n", "                ", "with", "storage", ".", "name_scope", "(", "\"stage{}\"", ".", "format", "(", "stage", ")", ")", ":", "\n", "                    ", "stage_losses", "=", "predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "", "losses", ".", "update", "(", "{", "k", "+", "\"_stage{}\"", ".", "format", "(", "stage", ")", ":", "v", "for", "k", ",", "v", "in", "stage_losses", ".", "items", "(", ")", "}", ")", "\n", "", "return", "losses", "\n", "", "else", ":", "\n", "# Each is a list[Tensor] of length #image. Each tensor is Ri x (K+1)", "\n", "            ", "scores_per_stage", "=", "[", "h", "[", "0", "]", ".", "predict_probs", "(", "h", "[", "1", "]", ",", "h", "[", "2", "]", ")", "for", "h", "in", "head_outputs", "]", "\n", "\n", "# Average the scores across heads", "\n", "scores", "=", "[", "\n", "sum", "(", "list", "(", "scores_per_image", ")", ")", "*", "(", "1.0", "/", "self", ".", "num_cascade_stages", ")", "\n", "for", "scores_per_image", "in", "zip", "(", "*", "scores_per_stage", ")", "\n", "]", "\n", "# Use the boxes of the last head", "\n", "predictor", ",", "predictions", ",", "proposals", "=", "head_outputs", "[", "-", "1", "]", "\n", "boxes", "=", "predictor", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "pred_instances", ",", "_", "=", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_sizes", ",", "\n", "predictor", ".", "test_score_thresh", ",", "\n", "predictor", ".", "test_nms_thresh", ",", "\n", "predictor", ".", "test_topk_per_image", ",", "\n", ")", "\n", "return", "pred_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._match_and_label_boxes": [[208, 257], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.structures.pairwise_iou", "num_fg_samples.append", "num_bg_samples.append", "len", "detectron2.structures.Boxes", "sum", "len", "sum", "len", "torch.zeros_like", "targets_per_image.gt_boxes.tensor.new_zeros", "proposal_labels.numel", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_match_and_label_boxes", "(", "self", ",", "proposals", ",", "stage", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Match proposals with groundtruth using the matcher at the given stage.\n        Label the proposals as foreground or background based on the match.\n\n        Args:\n            proposals (list[Instances]): One Instances for each image, with\n                the field \"proposal_boxes\".\n            stage (int): the current stage\n            targets (list[Instances]): the ground truth instances\n\n        Returns:\n            list[Instances]: the same proposals, but with fields \"gt_classes\" and \"gt_boxes\"\n        \"\"\"", "\n", "num_fg_samples", ",", "num_bg_samples", "=", "[", "]", ",", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "match_quality_matrix", "=", "pairwise_iou", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "# proposal_labels are 0 or 1", "\n", "matched_idxs", ",", "proposal_labels", "=", "self", ".", "proposal_matchers", "[", "stage", "]", "(", "match_quality_matrix", ")", "\n", "if", "len", "(", "targets_per_image", ")", ">", "0", ":", "\n", "                ", "gt_classes", "=", "targets_per_image", ".", "gt_classes", "[", "matched_idxs", "]", "\n", "# Label unmatched proposals (0 label from matcher) as background (label=num_classes)", "\n", "gt_classes", "[", "proposal_labels", "==", "0", "]", "=", "self", ".", "num_classes", "\n", "gt_boxes", "=", "targets_per_image", ".", "gt_boxes", "[", "matched_idxs", "]", "\n", "", "else", ":", "\n", "                ", "gt_classes", "=", "torch", ".", "zeros_like", "(", "matched_idxs", ")", "+", "self", ".", "num_classes", "\n", "gt_boxes", "=", "Boxes", "(", "\n", "targets_per_image", ".", "gt_boxes", ".", "tensor", ".", "new_zeros", "(", "(", "len", "(", "proposals_per_image", ")", ",", "4", ")", ")", "\n", ")", "\n", "", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "proposals_per_image", ".", "gt_boxes", "=", "gt_boxes", "\n", "\n", "num_fg_samples", ".", "append", "(", "(", "proposal_labels", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_bg_samples", ".", "append", "(", "proposal_labels", ".", "numel", "(", ")", "-", "num_fg_samples", "[", "-", "1", "]", ")", "\n", "\n", "# Log the number of fg/bg samples in each stage", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"stage{}/roi_head/num_fg_samples\"", ".", "format", "(", "stage", ")", ",", "\n", "sum", "(", "num_fg_samples", ")", "/", "len", "(", "num_fg_samples", ")", ",", "\n", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"stage{}/roi_head/num_bg_samples\"", ".", "format", "(", "stage", ")", ",", "\n", "sum", "(", "num_bg_samples", ")", "/", "len", "(", "num_bg_samples", ")", ",", "\n", ")", "\n", "return", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._run_stage": [[258, 276], ["cascade_rcnn.CascadeROIHeads.box_pooler", "_ScaleGradient.apply"], "methods", ["None"], ["", "def", "_run_stage", "(", "self", ",", "features", ",", "proposals", ",", "stage", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features (list[Tensor]): #lvl input features to ROIHeads\n            proposals (list[Instances]): #image Instances, with the field \"proposal_boxes\"\n            stage (int): the current stage\n\n        Returns:\n            Same output as `FastRCNNOutputLayers.forward()`.\n        \"\"\"", "\n", "box_features", "=", "self", ".", "box_pooler", "(", "features", ",", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", ")", "\n", "# The original implementation averages the losses among heads,", "\n", "# but scale up the parameter gradients of the heads.", "\n", "# This is equivalent to adding the losses among heads,", "\n", "# but scale down the gradients on features.", "\n", "box_features", "=", "_ScaleGradient", ".", "apply", "(", "box_features", ",", "1.0", "/", "self", ".", "num_cascade_stages", ")", "\n", "box_features", "=", "self", ".", "box_head", "[", "stage", "]", "(", "box_features", ")", "\n", "return", "self", ".", "box_predictor", "[", "stage", "]", "(", "box_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes": [[277, 299], ["zip", "detectron2.structures.Boxes", "boxes_per_image.clip", "detectron2.structures.Instances", "proposals.append", "b.detach", "boxes_per_image.nonempty"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty"], ["", "def", "_create_proposals_from_boxes", "(", "self", ",", "boxes", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (list[Tensor]): per-image predicted boxes, each of shape Ri x 4\n            image_sizes (list[tuple]): list of image shapes in (h, w)\n\n        Returns:\n            list[Instances]: per-image proposals with the given boxes.\n        \"\"\"", "\n", "# Just like RPN, the proposals should not have gradients", "\n", "boxes", "=", "[", "Boxes", "(", "b", ".", "detach", "(", ")", ")", "for", "b", "in", "boxes", "]", "\n", "proposals", "=", "[", "]", "\n", "for", "boxes_per_image", ",", "image_size", "in", "zip", "(", "boxes", ",", "image_sizes", ")", ":", "\n", "            ", "boxes_per_image", ".", "clip", "(", "image_size", ")", "\n", "if", "self", ".", "training", ":", "\n", "# do not filter empty boxes at inference time,", "\n", "# because the scores from each stage need to be aligned and added later", "\n", "                ", "boxes_per_image", "=", "boxes_per_image", "[", "boxes_per_image", ".", "nonempty", "(", ")", "]", "\n", "", "prop", "=", "Instances", "(", "image_size", ")", "\n", "prop", ".", "proposal_boxes", "=", "boxes_per_image", "\n", "proposals", ".", "append", "(", "prop", ")", "\n", "", "return", "proposals", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone": [[20, 34], ["isinstance", "detectron2.layers.ShapeSpec", "BACKBONE_REGISTRY.get", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["\n", "meta_arch", "=", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "\n", "model", "=", "META_ARCH_REGISTRY", ".", "get", "(", "meta_arch", ")", "(", "cfg", ")", "\n", "model", ".", "to", "(", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", ")", "\n", "_log_api_usage", "(", "\"modeling.meta_arch.\"", "+", "meta_arch", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.FPN.__init__": [[25, 108], ["backbone.Backbone.__init__", "isinstance", "bottom_up.output_shape", "fpn._assert_strides_are_log2_contiguous", "enumerate", "tuple", "list", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "int", "fpn.FPN.add_module", "fpn.FPN.add_module", "lateral_convs.append", "output_convs.append", "range", "fpn.FPN._out_feature_strides.keys", "math.log2", "int", "math.log2"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn._assert_strides_are_log2_contiguous", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "bottom_up", ",", "in_features", ",", "out_channels", ",", "norm", "=", "\"\"", ",", "top_block", "=", "None", ",", "fuse_type", "=", "\"sum\"", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bottom_up (Backbone): module representing the bottom up subnetwork.\n                Must be a subclass of :class:`Backbone`. The multi-scale feature\n                maps generated by the bottom up network, and listed in `in_features`,\n                are used to generate FPN levels.\n            in_features (list[str]): names of the input feature maps coming\n                from the backbone to which FPN is attached. For example, if the\n                backbone produces [\"res2\", \"res3\", \"res4\"], any *contiguous* sublist\n                of these may be used; order must be from high to low resolution.\n            out_channels (int): number of channels in the output feature maps.\n            norm (str): the normalization to use.\n            top_block (nn.Module or None): if provided, an extra operation will\n                be performed on the output of the last (smallest resolution)\n                FPN output, and the result will extend the result list. The top_block\n                further downsamples the feature map. It must have an attribute\n                \"num_levels\", meaning the number of extra FPN levels added by\n                this block, and \"in_feature\", which is a string representing\n                its input feature (e.g., p5).\n            fuse_type (str): types for fusing the top down features and the lateral\n                ones. It can be \"sum\" (default), which sums up element-wise; or \"avg\",\n                which takes the element-wise mean of the two.\n        \"\"\"", "\n", "super", "(", "FPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "bottom_up", ",", "Backbone", ")", "\n", "assert", "in_features", ",", "in_features", "\n", "\n", "# Feature map strides and channels from the bottom up network (e.g. ResNet)", "\n", "input_shapes", "=", "bottom_up", ".", "output_shape", "(", ")", "\n", "strides", "=", "[", "input_shapes", "[", "f", "]", ".", "stride", "for", "f", "in", "in_features", "]", "\n", "in_channels_per_feature", "=", "[", "input_shapes", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "\n", "_assert_strides_are_log2_contiguous", "(", "strides", ")", "\n", "lateral_convs", "=", "[", "]", "\n", "output_convs", "=", "[", "]", "\n", "\n", "use_bias", "=", "norm", "==", "\"\"", "\n", "for", "idx", ",", "in_channels", "in", "enumerate", "(", "in_channels_per_feature", ")", ":", "\n", "            ", "lateral_norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", "\n", "output_norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", "\n", "\n", "lateral_conv", "=", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "use_bias", ",", "norm", "=", "lateral_norm", "\n", ")", "\n", "output_conv", "=", "Conv2d", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "output_norm", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "lateral_conv", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "output_conv", ")", "\n", "stage", "=", "int", "(", "math", ".", "log2", "(", "strides", "[", "idx", "]", ")", ")", "\n", "self", ".", "add_module", "(", "\"fpn_lateral{}\"", ".", "format", "(", "stage", ")", ",", "lateral_conv", ")", "\n", "self", ".", "add_module", "(", "\"fpn_output{}\"", ".", "format", "(", "stage", ")", ",", "output_conv", ")", "\n", "\n", "lateral_convs", ".", "append", "(", "lateral_conv", ")", "\n", "output_convs", ".", "append", "(", "output_conv", ")", "\n", "# Place convs into top-down order (from low to high resolution)", "\n", "# to make the top-down computation in forward clearer.", "\n", "", "self", ".", "lateral_convs", "=", "lateral_convs", "[", ":", ":", "-", "1", "]", "\n", "self", ".", "output_convs", "=", "output_convs", "[", ":", ":", "-", "1", "]", "\n", "self", ".", "top_block", "=", "top_block", "\n", "self", ".", "in_features", "=", "tuple", "(", "in_features", ")", "\n", "self", ".", "bottom_up", "=", "bottom_up", "\n", "# Return feature names are \"p<stage>\", like [\"p2\", \"p3\", ..., \"p6\"]", "\n", "self", ".", "_out_feature_strides", "=", "{", "\"p{}\"", ".", "format", "(", "int", "(", "math", ".", "log2", "(", "s", ")", ")", ")", ":", "s", "for", "s", "in", "strides", "}", "\n", "# top block output feature maps.", "\n", "if", "self", ".", "top_block", "is", "not", "None", ":", "\n", "            ", "for", "s", "in", "range", "(", "stage", ",", "stage", "+", "self", ".", "top_block", ".", "num_levels", ")", ":", "\n", "                ", "self", ".", "_out_feature_strides", "[", "\"p{}\"", ".", "format", "(", "s", "+", "1", ")", "]", "=", "2", "**", "(", "s", "+", "1", ")", "\n", "\n", "", "", "self", ".", "_out_features", "=", "list", "(", "self", ".", "_out_feature_strides", ".", "keys", "(", ")", ")", "\n", "self", ".", "_out_feature_channels", "=", "{", "k", ":", "out_channels", "for", "k", "in", "self", ".", "_out_features", "}", "\n", "self", ".", "_size_divisibility", "=", "strides", "[", "-", "1", "]", "\n", "assert", "fuse_type", "in", "{", "\"avg\"", ",", "\"sum\"", "}", "\n", "self", ".", "_fuse_type", "=", "fuse_type", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.FPN.size_divisibility": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size_divisibility", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size_divisibility", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.FPN.forward": [[113, 155], ["fpn.FPN.bottom_up", "results.append", "enumerate", "zip", "results.extend", "len", "len", "torch.interpolate", "torch.interpolate", "lateral_conv", "results.insert", "fpn.FPN.top_block", "zip", "output_conv", "fpn.FPN._out_features.index"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (dict[str->Tensor]): mapping feature map name (e.g., \"res5\") to\n                feature map tensor for each feature level in high to low resolution order.\n\n        Returns:\n            dict[str->Tensor]:\n                mapping from feature map name to FPN feature map tensor\n                in high to low resolution order. Returned feature names follow the FPN\n                paper convention: \"p<stage>\", where stage has stride = 2 ** stage e.g.,\n                [\"p2\", \"p3\", ..., \"p6\"].\n        \"\"\"", "\n", "bottom_up_features", "=", "self", ".", "bottom_up", "(", "x", ")", "\n", "results", "=", "[", "]", "\n", "prev_features", "=", "self", ".", "lateral_convs", "[", "0", "]", "(", "bottom_up_features", "[", "self", ".", "in_features", "[", "-", "1", "]", "]", ")", "\n", "results", ".", "append", "(", "self", ".", "output_convs", "[", "0", "]", "(", "prev_features", ")", ")", "\n", "\n", "# Reverse feature maps into top-down order (from low to high resolution)", "\n", "for", "idx", ",", "(", "lateral_conv", ",", "output_conv", ")", "in", "enumerate", "(", "\n", "zip", "(", "self", ".", "lateral_convs", ",", "self", ".", "output_convs", ")", "\n", ")", ":", "\n", "# Slicing of ModuleList is not supported https://github.com/pytorch/pytorch/issues/47336", "\n", "# Therefore we loop over all modules but skip the first one", "\n", "            ", "if", "idx", ">", "0", ":", "\n", "                ", "features", "=", "self", ".", "in_features", "[", "-", "idx", "-", "1", "]", "\n", "features", "=", "bottom_up_features", "[", "features", "]", "\n", "top_down_features", "=", "F", ".", "interpolate", "(", "prev_features", ",", "scale_factor", "=", "2.0", ",", "mode", "=", "\"nearest\"", ")", "\n", "lateral_features", "=", "lateral_conv", "(", "features", ")", "\n", "prev_features", "=", "lateral_features", "+", "top_down_features", "\n", "if", "self", ".", "_fuse_type", "==", "\"avg\"", ":", "\n", "                    ", "prev_features", "/=", "2", "\n", "", "results", ".", "insert", "(", "0", ",", "output_conv", "(", "prev_features", ")", ")", "\n", "\n", "", "", "if", "self", ".", "top_block", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "top_block", ".", "in_feature", "in", "bottom_up_features", ":", "\n", "                ", "top_block_in_feature", "=", "bottom_up_features", "[", "self", ".", "top_block", ".", "in_feature", "]", "\n", "", "else", ":", "\n", "                ", "top_block_in_feature", "=", "results", "[", "self", ".", "_out_features", ".", "index", "(", "self", ".", "top_block", ".", "in_feature", ")", "]", "\n", "", "results", ".", "extend", "(", "self", ".", "top_block", "(", "top_block_in_feature", ")", ")", "\n", "", "assert", "len", "(", "self", ".", "_out_features", ")", "==", "len", "(", "results", ")", "\n", "return", "{", "f", ":", "res", "for", "f", ",", "res", "in", "zip", "(", "self", ".", "_out_features", ",", "results", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.FPN.output_shape": [[156, 162], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "_out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.LastLevelMaxPool.__init__": [[181, 185], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_levels", "=", "1", "\n", "self", ".", "in_feature", "=", "\"p5\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.LastLevelMaxPool.forward": [[186, 188], ["torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "[", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.LastLevelP6P7.__init__": [[196, 204], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "fvcore.c2_xavier_fill"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "in_feature", "=", "\"res5\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_levels", "=", "2", "\n", "self", ".", "in_feature", "=", "in_feature", "\n", "self", ".", "p6", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "p7", "=", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "for", "module", "in", "[", "self", ".", "p6", ",", "self", ".", "p7", "]", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.LastLevelP6P7.forward": [[205, 209], ["fpn.LastLevelP6P7.p6", "fpn.LastLevelP6P7.p7", "torch.relu", "torch.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "c5", ")", ":", "\n", "        ", "p6", "=", "self", ".", "p6", "(", "c5", ")", "\n", "p7", "=", "self", ".", "p7", "(", "F", ".", "relu", "(", "p6", ")", ")", "\n", "return", "[", "p6", ",", "p7", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn._assert_strides_are_log2_contiguous": [[165, 172], ["enumerate"], "function", ["None"], ["", "", "def", "_assert_strides_are_log2_contiguous", "(", "strides", ")", ":", "\n", "    ", "\"\"\"\n    Assert that each stride is 2x times its preceding stride, i.e. \"contiguous in log2\".\n    \"\"\"", "\n", "for", "i", ",", "stride", "in", "enumerate", "(", "strides", "[", "1", ":", "]", ",", "1", ")", ":", "\n", "        ", "assert", "stride", "==", "2", "*", "strides", "[", "i", "-", "1", "]", ",", "\"Strides {} {} are not log2 contiguous\"", ".", "format", "(", "\n", "stride", ",", "strides", "[", "i", "-", "1", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.build_resnet_fpn_backbone": [[211, 232], ["build.BACKBONE_REGISTRY.register", "resnet.build_resnet_backbone", "fpn.FPN", "fpn.LastLevelMaxPool"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.build_resnet_backbone"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_resnet_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_resnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "LastLevelMaxPool", "(", ")", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.fpn.build_retinanet_resnet_fpn_backbone": [[234, 256], ["build.BACKBONE_REGISTRY.register", "resnet.build_resnet_backbone", "fpn.FPN", "resnet.build_resnet_backbone.output_shape", "fpn.LastLevelP6P7"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.build_resnet_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_retinanet_resnet_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_resnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "in_channels_p6p7", "=", "bottom_up", ".", "output_shape", "(", ")", "[", "\"res5\"", "]", ".", "channels", "\n", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "LastLevelP6P7", "(", "in_channels_p6p7", ",", "out_channels", ")", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BasicBlock.__init__": [[38, 84], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "*", ",", "stride", "=", "1", ",", "norm", "=", "\"BN\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            in_channels (int): Number of input channels.\n            out_channels (int): Number of output channels.\n            stride (int): Stride for the first conv.\n            norm (str or callable): normalization for all conv layers.\n                See :func:`layers.get_norm` for supported format.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "stride", ")", "\n", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "shortcut", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "None", "\n", "\n", "", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv2", "=", "Conv2d", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "\n", "for", "layer", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "shortcut", "]", ":", "\n", "            ", "if", "layer", "is", "not", "None", ":", "# shortcut can be None", "\n", "                ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BasicBlock.forward": [[85, 98], ["resnet.BasicBlock.conv1", "torch.relu_", "torch.relu_", "resnet.BasicBlock.conv2", "torch.relu_", "torch.relu_", "resnet.BasicBlock.shortcut"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "shortcut", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BottleneckBlock.__init__": [[107, 181], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "*", ",", "\n", "bottleneck_channels", ",", "\n", "stride", "=", "1", ",", "\n", "num_groups", "=", "1", ",", "\n", "norm", "=", "\"BN\"", ",", "\n", "stride_in_1x1", "=", "False", ",", "\n", "dilation", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bottleneck_channels (int): number of output channels for the 3x3\n                \"bottleneck\" conv layers.\n            num_groups (int): number of groups for the 3x3 conv layer.\n            norm (str or callable): normalization for all conv layers.\n                See :func:`layers.get_norm` for supported format.\n            stride_in_1x1 (bool): when stride>1, whether to put stride in the\n                first 1x1 convolution or the bottleneck 3x3 convolution.\n            dilation (int): the dilation rate of the 3x3 conv layer.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "stride", ")", "\n", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "shortcut", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "None", "\n", "\n", "# The original MSRA ResNet models have stride in the first 1x1 conv", "\n", "# The subsequent fb.torch.resnet and Caffe2 ResNe[X]t implementations have", "\n", "# stride in the 3x3 conv", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride_1x1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv2", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "1", "*", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv3", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "\n", "for", "layer", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "conv3", ",", "self", ".", "shortcut", "]", ":", "\n", "            ", "if", "layer", "is", "not", "None", ":", "# shortcut can be None", "\n", "                ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BottleneckBlock.forward": [[194, 211], ["resnet.BottleneckBlock.conv1", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.conv2", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.conv3", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.shortcut"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "shortcut", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.DeformBottleneckBlock.__init__": [[219, 302], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "deform_conv_op", "detectron2.layers.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "*", ",", "\n", "bottleneck_channels", ",", "\n", "stride", "=", "1", ",", "\n", "num_groups", "=", "1", ",", "\n", "norm", "=", "\"BN\"", ",", "\n", "stride_in_1x1", "=", "False", ",", "\n", "dilation", "=", "1", ",", "\n", "deform_modulated", "=", "False", ",", "\n", "deform_num_groups", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "stride", ")", "\n", "self", ".", "deform_modulated", "=", "deform_modulated", "\n", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "shortcut", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "None", "\n", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride_1x1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "if", "deform_modulated", ":", "\n", "            ", "deform_conv_op", "=", "ModulatedDeformConv", "\n", "# offset channels are 2 or 3 (if with modulated) * kernel_size * kernel_size", "\n", "offset_channels", "=", "27", "\n", "", "else", ":", "\n", "            ", "deform_conv_op", "=", "DeformConv", "\n", "offset_channels", "=", "18", "\n", "\n", "", "self", ".", "conv2_offset", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "offset_channels", "*", "deform_num_groups", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "1", "*", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "deform_conv_op", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "1", "*", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", ",", "\n", "deformable_groups", "=", "deform_num_groups", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv3", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "\n", "for", "layer", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "conv3", ",", "self", ".", "shortcut", "]", ":", "\n", "            ", "if", "layer", "is", "not", "None", ":", "# shortcut can be None", "\n", "                ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "\n", "", "", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv2_offset", ".", "weight", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv2_offset", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.DeformBottleneckBlock.forward": [[303, 328], ["resnet.DeformBottleneckBlock.conv1", "torch.relu_", "torch.relu_", "torch.relu_", "torch.relu_", "resnet.DeformBottleneckBlock.conv3", "torch.relu_", "torch.relu_", "resnet.DeformBottleneckBlock.conv2_offset", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mask.sigmoid.sigmoid.sigmoid", "resnet.DeformBottleneckBlock.conv2", "resnet.DeformBottleneckBlock.conv2_offset", "resnet.DeformBottleneckBlock.conv2", "resnet.DeformBottleneckBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "if", "self", ".", "deform_modulated", ":", "\n", "            ", "offset_mask", "=", "self", ".", "conv2_offset", "(", "out", ")", "\n", "offset_x", ",", "offset_y", ",", "mask", "=", "torch", ".", "chunk", "(", "offset_mask", ",", "3", ",", "dim", "=", "1", ")", "\n", "offset", "=", "torch", ".", "cat", "(", "(", "offset_x", ",", "offset_y", ")", ",", "dim", "=", "1", ")", "\n", "mask", "=", "mask", ".", "sigmoid", "(", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "offset", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "offset", "=", "self", ".", "conv2_offset", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "offset", ")", "\n", "", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "shortcut", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BasicStem.__init__": [[335, 353], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "self", ",", "in_channels", "=", "3", ",", "out_channels", "=", "64", ",", "norm", "=", "\"BN\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            norm (str or callable): norm after the first conv layer.\n                See :func:`layers.get_norm` for supported format.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "4", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "3", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "conv1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.BasicStem.forward": [[354, 359], ["resnet.BasicStem.conv1", "torch.relu_", "torch.relu_", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu_", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.__init__": [[366, 433], ["backbone.Backbone.__init__", "enumerate", "tuple", "len", "resnet.ResNet.freeze", "max", "len", "torch.nn.Sequential", "torch.nn.Sequential", "resnet.ResNet.add_module", "resnet.ResNet.stage_names.append", "resnet.ResNet.stages.append", "int", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.normal_", "len", "isinstance", "str", "resnet.ResNet.named_children", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["def", "__init__", "(", "self", ",", "stem", ",", "stages", ",", "num_classes", "=", "None", ",", "out_features", "=", "None", ",", "freeze_at", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            stem (nn.Module): a stem module\n            stages (list[list[CNNBlockBase]]): several (typically 4) stages,\n                each contains multiple :class:`CNNBlockBase`.\n            num_classes (None or int): if None, will not perform classification.\n                Otherwise, will create a linear layer.\n            out_features (list[str]): name of the layers whose outputs should\n                be returned in forward. Can be anything in \"stem\", \"linear\", or \"res2\" ...\n                If None, will return the output of the last layer.\n            freeze_at (int): The number of stages at the beginning to freeze.\n                see :meth:`freeze` for detailed explanation.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stem", "=", "stem", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "current_stride", "=", "self", ".", "stem", ".", "stride", "\n", "self", ".", "_out_feature_strides", "=", "{", "\"stem\"", ":", "current_stride", "}", "\n", "self", ".", "_out_feature_channels", "=", "{", "\"stem\"", ":", "self", ".", "stem", ".", "out_channels", "}", "\n", "\n", "self", ".", "stage_names", ",", "self", ".", "stages", "=", "[", "]", ",", "[", "]", "\n", "\n", "if", "out_features", "is", "not", "None", ":", "\n", "# Avoid keeping unused layers in this module. They consume extra memory", "\n", "# and may cause allreduce to fail", "\n", "            ", "num_stages", "=", "max", "(", "\n", "[", "{", "\"res2\"", ":", "1", ",", "\"res3\"", ":", "2", ",", "\"res4\"", ":", "3", ",", "\"res5\"", ":", "4", "}", ".", "get", "(", "f", ",", "0", ")", "for", "f", "in", "out_features", "]", "\n", ")", "\n", "stages", "=", "stages", "[", ":", "num_stages", "]", "\n", "", "for", "i", ",", "blocks", "in", "enumerate", "(", "stages", ")", ":", "\n", "            ", "assert", "len", "(", "blocks", ")", ">", "0", ",", "len", "(", "blocks", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "                ", "assert", "isinstance", "(", "block", ",", "CNNBlockBase", ")", ",", "block", "\n", "\n", "", "name", "=", "\"res\"", "+", "str", "(", "i", "+", "2", ")", "\n", "stage", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "self", ".", "add_module", "(", "name", ",", "stage", ")", "\n", "self", ".", "stage_names", ".", "append", "(", "name", ")", "\n", "self", ".", "stages", ".", "append", "(", "stage", ")", "\n", "\n", "self", ".", "_out_feature_strides", "[", "name", "]", "=", "current_stride", "=", "int", "(", "\n", "current_stride", "*", "np", ".", "prod", "(", "[", "k", ".", "stride", "for", "k", "in", "blocks", "]", ")", "\n", ")", "\n", "self", ".", "_out_feature_channels", "[", "name", "]", "=", "curr_channels", "=", "blocks", "[", "-", "1", "]", ".", "out_channels", "\n", "", "self", ".", "stage_names", "=", "tuple", "(", "self", ".", "stage_names", ")", "# Make it static for scripting", "\n", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "curr_channels", ",", "num_classes", ")", "\n", "\n", "# Sec 5.1 in \"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\":", "\n", "# \"The 1000-way fully-connected layer is initialized by", "\n", "# drawing weights from a zero-mean Gaussian with standard deviation of 0.01.\"", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "name", "=", "\"linear\"", "\n", "\n", "", "if", "out_features", "is", "None", ":", "\n", "            ", "out_features", "=", "[", "name", "]", "\n", "", "self", ".", "_out_features", "=", "out_features", "\n", "assert", "len", "(", "self", ".", "_out_features", ")", "\n", "children", "=", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "named_children", "(", ")", "]", "\n", "for", "out_feature", "in", "self", ".", "_out_features", ":", "\n", "            ", "assert", "out_feature", "in", "children", ",", "\"Available children: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "children", ")", ")", "\n", "", "self", ".", "freeze", "(", "freeze_at", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.forward": [[434, 458], ["resnet.ResNet.stem", "zip", "resnet.ResNet.dim", "stage", "resnet.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "resnet.ResNet.linear"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: Tensor of shape (N,C,H,W). H, W must be a multiple of ``self.size_divisibility``.\n\n        Returns:\n            dict[str->Tensor]: names and the corresponding features\n        \"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "4", ",", "f\"ResNet takes an input of shape (N, C, H, W). Got {x.shape} instead!\"", "\n", "outputs", "=", "{", "}", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "\"stem\"", "in", "self", ".", "_out_features", ":", "\n", "            ", "outputs", "[", "\"stem\"", "]", "=", "x", "\n", "", "for", "name", ",", "stage", "in", "zip", "(", "self", ".", "stage_names", ",", "self", ".", "stages", ")", ":", "\n", "            ", "x", "=", "stage", "(", "x", ")", "\n", "if", "name", "in", "self", ".", "_out_features", ":", "\n", "                ", "outputs", "[", "name", "]", "=", "x", "\n", "", "", "if", "self", ".", "num_classes", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "if", "\"linear\"", "in", "self", ".", "_out_features", ":", "\n", "                ", "outputs", "[", "\"linear\"", "]", "=", "x", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.output_shape": [[459, 465], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "_out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.freeze": [[467, 490], ["enumerate", "resnet.ResNet.stem.freeze", "stage.children", "block.freeze"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze"], ["", "def", "freeze", "(", "self", ",", "freeze_at", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Freeze the first several stages of the ResNet. Commonly used in\n        fine-tuning.\n\n        Layers that produce the same feature map spatial size are defined as one\n        \"stage\" by :paper:`FPN`.\n\n        Args:\n            freeze_at (int): number of stages to freeze.\n                `1` means freezing the stem. `2` means freezing the stem and\n                one residual stage, etc.\n\n        Returns:\n            nn.Module: this ResNet itself\n        \"\"\"", "\n", "if", "freeze_at", ">=", "1", ":", "\n", "            ", "self", ".", "stem", ".", "freeze", "(", ")", "\n", "", "for", "idx", ",", "stage", "in", "enumerate", "(", "self", ".", "stages", ",", "start", "=", "2", ")", ":", "\n", "            ", "if", "freeze_at", ">=", "idx", ":", "\n", "                ", "for", "block", "in", "stage", ".", "children", "(", ")", ":", "\n", "                    ", "block", ".", "freeze", "(", ")", "\n", "", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.make_stage": [[491, 545], ["range", "kwargs.items", "blocks.append", "k.endswith", "block_class", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_stage", "(", "block_class", ",", "num_blocks", ",", "*", ",", "in_channels", ",", "out_channels", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Create a list of blocks of the same type that forms one ResNet stage.\n\n        Args:\n            block_class (type): a subclass of CNNBlockBase that's used to create all blocks in this\n                stage. A module of this type must not change spatial resolution of inputs unless its\n                stride != 1.\n            num_blocks (int): number of blocks in this stage\n            in_channels (int): input channels of the entire stage.\n            out_channels (int): output channels of **every block** in the stage.\n            kwargs: other arguments passed to the constructor of\n                `block_class`. If the argument name is \"xx_per_block\", the\n                argument is a list of values to be passed to each block in the\n                stage. Otherwise, the same argument is passed to every block\n                in the stage.\n\n        Returns:\n            list[CNNBlockBase]: a list of block module.\n\n        Examples:\n        ::\n            stage = ResNet.make_stage(\n                BottleneckBlock, 3, in_channels=16, out_channels=64,\n                bottleneck_channels=16, num_groups=1,\n                stride_per_block=[2, 1, 1],\n                dilations_per_block=[1, 1, 2]\n            )\n\n        Usually, layers that produce the same feature map spatial size are defined as one\n        \"stage\" (in :paper:`FPN`). Under such definition, ``stride_per_block[1:]`` should\n        all be 1.\n        \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "curr_kwargs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", ".", "endswith", "(", "\"_per_block\"", ")", ":", "\n", "                    ", "assert", "len", "(", "v", ")", "==", "num_blocks", ",", "(", "\n", "f\"Argument '{k}' of make_stage should have the \"", "\n", "f\"same length as num_blocks={num_blocks}.\"", "\n", ")", "\n", "newk", "=", "k", "[", ":", "-", "len", "(", "\"_per_block\"", ")", "]", "\n", "assert", "newk", "not", "in", "kwargs", ",", "f\"Cannot call make_stage with both {k} and {newk}!\"", "\n", "curr_kwargs", "[", "newk", "]", "=", "v", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "curr_kwargs", "[", "k", "]", "=", "v", "\n", "\n", "", "", "blocks", ".", "append", "(", "\n", "block_class", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "**", "curr_kwargs", ")", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.ResNet.make_default_stages": [[546, 597], ["zip", "ret.append", "resnet.ResNet.make_stage"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.make_stage"], ["", "@", "staticmethod", "\n", "def", "make_default_stages", "(", "depth", ",", "block_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Created list of ResNet stages from pre-defined depth (one of 18, 34, 50, 101, 152).\n        If it doesn't create the ResNet variant you need, please use :meth:`make_stage`\n        instead for fine-grained customization.\n\n        Args:\n            depth (int): depth of ResNet\n            block_class (type): the CNN block class. Has to accept\n                `bottleneck_channels` argument for depth > 50.\n                By default it is BasicBlock or BottleneckBlock, based on the\n                depth.\n            kwargs:\n                other arguments to pass to `make_stage`. Should not contain\n                stride and channels, as they are predefined for each depth.\n\n        Returns:\n            list[list[CNNBlockBase]]: modules in all stages; see arguments of\n                :class:`ResNet.__init__`.\n        \"\"\"", "\n", "num_blocks_per_stage", "=", "{", "\n", "18", ":", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "34", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "50", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "101", ":", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "152", ":", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "\n", "}", "[", "depth", "]", "\n", "if", "block_class", "is", "None", ":", "\n", "            ", "block_class", "=", "BasicBlock", "if", "depth", "<", "50", "else", "BottleneckBlock", "\n", "", "if", "depth", "<", "50", ":", "\n", "            ", "in_channels", "=", "[", "64", ",", "64", ",", "128", ",", "256", "]", "\n", "out_channels", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "", "else", ":", "\n", "            ", "in_channels", "=", "[", "64", ",", "256", ",", "512", ",", "1024", "]", "\n", "out_channels", "=", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", "\n", "", "ret", "=", "[", "]", "\n", "for", "(", "n", ",", "s", ",", "i", ",", "o", ")", "in", "zip", "(", "num_blocks_per_stage", ",", "[", "1", ",", "2", ",", "2", ",", "2", "]", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "            ", "if", "depth", ">=", "50", ":", "\n", "                ", "kwargs", "[", "\"bottleneck_channels\"", "]", "=", "o", "//", "4", "\n", "", "ret", ".", "append", "(", "\n", "ResNet", ".", "make_stage", "(", "\n", "block_class", "=", "block_class", ",", "\n", "num_blocks", "=", "n", ",", "\n", "stride_per_block", "=", "[", "s", "]", "+", "[", "1", "]", "*", "(", "n", "-", "1", ")", ",", "\n", "in_channels", "=", "i", ",", "\n", "out_channels", "=", "o", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.make_stage": [[605, 610], ["resnet.ResNet.make_stage"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.make_stage"], ["def", "make_stage", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Deprecated alias for backward compatibiltiy.\n    \"\"\"", "\n", "return", "ResNet", ".", "make_stage", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.build_resnet_backbone": [[612, 694], ["build.BACKBONE_REGISTRY.register", "resnet.BasicStem", "enumerate", "resnet.ResNet", "range", "resnet.ResNet.make_stage", "stages.append", "any"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.resnet.make_stage"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_resnet_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a ResNet instance from config.\n\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    \"\"\"", "\n", "# need registration of new blocks/stems?", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "stem", "=", "BasicStem", "(", "\n", "in_channels", "=", "input_shape", ".", "channels", ",", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", ",", "\n", "norm", "=", "norm", ",", "\n", ")", "\n", "\n", "# fmt: off", "\n", "freeze_at", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "\n", "out_features", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "OUT_FEATURES", "\n", "depth", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEPTH", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "in_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "stride_in_1x1", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", "\n", "res5_dilation", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "\n", "deform_on_per_stage", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_ON_PER_STAGE", "\n", "deform_modulated", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_MODULATED", "\n", "deform_num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_NUM_GROUPS", "\n", "# fmt: on", "\n", "assert", "res5_dilation", "in", "{", "1", ",", "2", "}", ",", "\"res5_dilation cannot be {}.\"", ".", "format", "(", "res5_dilation", ")", "\n", "\n", "num_blocks_per_stage", "=", "{", "\n", "18", ":", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "34", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "50", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "101", ":", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "152", ":", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "\n", "}", "[", "depth", "]", "\n", "\n", "if", "depth", "in", "[", "18", ",", "34", "]", ":", "\n", "        ", "assert", "out_channels", "==", "64", ",", "\"Must set MODEL.RESNETS.RES2_OUT_CHANNELS = 64 for R18/R34\"", "\n", "assert", "not", "any", "(", "\n", "deform_on_per_stage", "\n", ")", ",", "\"MODEL.RESNETS.DEFORM_ON_PER_STAGE unsupported for R18/R34\"", "\n", "assert", "res5_dilation", "==", "1", ",", "\"Must set MODEL.RESNETS.RES5_DILATION = 1 for R18/R34\"", "\n", "assert", "num_groups", "==", "1", ",", "\"Must set MODEL.RESNETS.NUM_GROUPS = 1 for R18/R34\"", "\n", "\n", "", "stages", "=", "[", "]", "\n", "\n", "for", "idx", ",", "stage_idx", "in", "enumerate", "(", "range", "(", "2", ",", "6", ")", ")", ":", "\n", "# res5_dilation is used this way as a convention in R-FCN & Deformable Conv paper", "\n", "        ", "dilation", "=", "res5_dilation", "if", "stage_idx", "==", "5", "else", "1", "\n", "first_stride", "=", "1", "if", "idx", "==", "0", "or", "(", "stage_idx", "==", "5", "and", "dilation", "==", "2", ")", "else", "2", "\n", "stage_kargs", "=", "{", "\n", "\"num_blocks\"", ":", "num_blocks_per_stage", "[", "idx", "]", ",", "\n", "\"stride_per_block\"", ":", "[", "first_stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks_per_stage", "[", "idx", "]", "-", "1", ")", ",", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"out_channels\"", ":", "out_channels", ",", "\n", "\"norm\"", ":", "norm", ",", "\n", "}", "\n", "# Use BasicBlock for R18 and R34.", "\n", "if", "depth", "in", "[", "18", ",", "34", "]", ":", "\n", "            ", "stage_kargs", "[", "\"block_class\"", "]", "=", "BasicBlock", "\n", "", "else", ":", "\n", "            ", "stage_kargs", "[", "\"bottleneck_channels\"", "]", "=", "bottleneck_channels", "\n", "stage_kargs", "[", "\"stride_in_1x1\"", "]", "=", "stride_in_1x1", "\n", "stage_kargs", "[", "\"dilation\"", "]", "=", "dilation", "\n", "stage_kargs", "[", "\"num_groups\"", "]", "=", "num_groups", "\n", "if", "deform_on_per_stage", "[", "idx", "]", ":", "\n", "                ", "stage_kargs", "[", "\"block_class\"", "]", "=", "DeformBottleneckBlock", "\n", "stage_kargs", "[", "\"deform_modulated\"", "]", "=", "deform_modulated", "\n", "stage_kargs", "[", "\"deform_num_groups\"", "]", "=", "deform_num_groups", "\n", "", "else", ":", "\n", "                ", "stage_kargs", "[", "\"block_class\"", "]", "=", "BottleneckBlock", "\n", "", "", "blocks", "=", "ResNet", ".", "make_stage", "(", "**", "stage_kargs", ")", "\n", "in_channels", "=", "out_channels", "\n", "out_channels", "*=", "2", "\n", "bottleneck_channels", "*=", "2", "\n", "stages", ".", "append", "(", "blocks", ")", "\n", "", "return", "ResNet", "(", "stem", ",", "stages", ",", "out_features", "=", "out_features", ",", "freeze_at", "=", "freeze_at", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.backbone.Backbone.__init__": [[15, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The `__init__` method of any subclass can specify its own set of arguments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.backbone.Backbone.forward": [[21, 30], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Subclasses must override this method, but adhere to the same return type.\n\n        Returns:\n            dict[str->Tensor]: mapping from feature name (e.g., \"res2\") to tensor\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.backbone.Backbone.size_divisibility": [[31, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size_divisibility", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Some backbones require the input height and width to be divisible by a\n        specific integer. This is typically true for encoder / decoder type networks\n        with lateral connection (e.g., FPN) for which feature maps need to match\n        dimension in the \"bottom up\" and \"top down\" paths. Set to 0 if no specific\n        input size divisibility is required.\n        \"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.backbone.Backbone.output_shape": [[42, 53], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[str->ShapeSpec]\n        \"\"\"", "\n", "# this is a backward-compatible default", "\n", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "_out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.__init__": [[20, 222], ["torch.as_tensor", "tensor.reshape().to.reshape().to.size", "isinstance", "torch.device", "tensor.reshape().to.reshape().to.numel", "tensor.reshape().to.reshape().to.reshape().to", "tensor.reshape().to.reshape().to.dim", "tensor.reshape().to.reshape().to.size", "tensor.reshape().to.reshape().to.reshape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor[float]): a Nx5 matrix.  Each row is\n                (x_center, y_center, width, height, angle),\n                in which angle is represented in degrees.\n                While there's no strict range restriction for it,\n                the recommended principal range is between [-180, 180) degrees.\n\n        Assume we have a horizontal box B = (x_center, y_center, width, height),\n        where width is along the x-axis and height is along the y-axis.\n        The rotated box B_rot (x_center, y_center, width, height, angle)\n        can be seen as:\n\n        1. When angle == 0:\n           B_rot == B\n        2. When angle > 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CCW;\n        3. When angle < 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CW.\n\n        Mathematically, since the right-handed coordinate system for image space\n        is (y, x), where y is top->down and x is left->right, the 4 vertices of the\n        rotated rectangle :math:`(yr_i, xr_i)` (i = 1, 2, 3, 4) can be obtained from\n        the vertices of the horizontal rectangle :math:`(y_i, x_i)` (i = 1, 2, 3, 4)\n        in the following way (:math:`\\\\theta = angle*\\\\pi/180` is the angle in radians,\n        :math:`(y_c, x_c)` is the center of the rectangle):\n\n        .. math::\n\n            yr_i = \\\\cos(\\\\theta) (y_i - y_c) - \\\\sin(\\\\theta) (x_i - x_c) + y_c,\n\n            xr_i = \\\\sin(\\\\theta) (y_i - y_c) + \\\\cos(\\\\theta) (x_i - x_c) + x_c,\n\n        which is the standard rigid-body rotation transformation.\n\n        Intuitively, the angle is\n        (1) the rotation angle from y-axis in image space\n        to the height vector (top->down in the box's local coordinate system)\n        of the box in CCW, and\n        (2) the rotation angle from x-axis in image space\n        to the width vector (left->right in the box's local coordinate system)\n        of the box in CCW.\n\n        More intuitively, consider the following horizontal box ABCD represented\n        in (x1, y1, x2, y2): (3, 2, 7, 4),\n        covering the [3, 7] x [2, 4] region of the continuous coordinate system\n        which looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  |   |\n            |  D---C\n            |\n            v y\n\n        Note that each capital letter represents one 0-dimensional geometric point\n        instead of a 'square pixel' here.\n\n        In the example above, using (x, y) to represent a point we have:\n\n        .. math::\n\n            O = (0, 0), A = (3, 2), B = (7, 2), C = (7, 4), D = (3, 4)\n\n        We name vector AB = vector DC as the width vector in box's local coordinate system, and\n        vector AD = vector BC as the height vector in box's local coordinate system. Initially,\n        when angle = 0 degree, they're aligned with the positive directions of x-axis and y-axis\n        in the image space, respectively.\n\n        For better illustration, we denote the center of the box as E,\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  | E |\n            |  D---C\n            |\n            v y\n\n        where the center E = ((3+7)/2, (2+4)/2) = (5, 3).\n\n        Also,\n\n        .. math::\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Therefore, the corresponding representation for the same shape in rotated box in\n        (x_center, y_center, width, height, angle) format is:\n\n        (5, 3, 4, 2, 0),\n\n        Now, let's consider (5, 3, 4, 2, 90), which is rotated by 90 degrees\n        CCW (counter-clockwise) by definition. It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   B-C\n            |   | |\n            |   |E|\n            |   | |\n            |   A-D\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CCW with regard to E:\n        A = (4, 5), B = (4, 1), C = (6, 1), D = (6, 5)\n\n        Here, 90 degrees can be seen as the CCW angle to rotate from y-axis to\n        vector AD or vector BC (the top->down height vector in box's local coordinate system),\n        or the CCW angle to rotate from x-axis to vector AB or vector DC (the left->right\n        width vector in box's local coordinate system).\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        Next, how about (5, 3, 4, 2, -90), which is rotated by 90 degrees CW (clockwise)\n        by definition? It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   D-A\n            |   | |\n            |   |E|\n            |   | |\n            |   C-B\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CW with regard to E:\n        A = (6, 1), B = (6, 5), C = (4, 5), D = (4, 1)\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        This covers exactly the same region as (5, 3, 4, 2, 90) does, and their IoU\n        will be 1. However, these two will generate different RoI Pooling results and\n        should not be treated as an identical box.\n\n        On the other hand, it's easy to see that (X, Y, W, H, A) is identical to\n        (X, Y, W, H, A+360N), for any integer N. For example (5, 3, 4, 2, 270) would be\n        identical to (5, 3, 4, 2, -90), because rotating the shape 270 degrees CCW is\n        equivalent to rotating the same shape 90 degrees CW.\n\n        We could rotate further to get (5, 3, 4, 2, 180), or (5, 3, 4, 2, -180):\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  C---D\n            |  | E |\n            |  B---A\n            |\n            v y\n\n        .. math::\n\n            A = (7, 4), B = (3, 4), C = (3, 2), D = (7, 2),\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Finally, this is a very inaccurate (heavily quantized) illustration of\n        how (5, 3, 4, 2, 60) looks like in case anyone wonders:\n\n        .. code:: none\n\n            O--------> x\n            |     B\\\n            |    /  C\n            |   /E /\n            |  A  /\n            |   `D\n            v y\n\n        It's still a rectangle with center of (5, 3), width of 4 and height of 2,\n        but its angle (and thus orientation) is somewhere between\n        (5, 3, 4, 2, 0) and (5, 3, 4, 2, 90).\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "tensor", ".", "numel", "(", ")", "==", "0", ":", "\n", "# Use reshape, so we don't end up creating a new tensor that does not depend on", "\n", "# the inputs (and consequently confuses jit)", "\n", "            ", "tensor", "=", "tensor", ".", "reshape", "(", "(", "0", ",", "5", ")", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "==", "5", ",", "tensor", ".", "size", "(", ")", "\n", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.clone": [[223, 231], ["rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes.tensor.clone"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["", "def", "clone", "(", "self", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Clone the RotatedBoxes.\n\n        Returns:\n            RotatedBoxes\n        \"\"\"", "\n", "return", "RotatedBoxes", "(", "self", ".", "tensor", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.to": [[232, 236], ["rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes.tensor.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "@", "_maybe_jit_unused", "\n", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "# Boxes are assumed float32 and does not support to(dtype)", "\n", "        ", "return", "RotatedBoxes", "(", "self", ".", "tensor", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.area": [[237, 247], ["None"], "methods", ["None"], ["", "def", "area", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the area of all the boxes.\n\n        Returns:\n            torch.Tensor: a vector with areas of each box.\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "area", "=", "box", "[", ":", ",", "2", "]", "*", "box", "[", ":", ",", "3", "]", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.normalize_angles": [[248, 253], ["None"], "methods", ["None"], ["", "def", "normalize_angles", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Restrict angles to the range of [-180, 180) degrees\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "4", "]", "=", "(", "self", ".", "tensor", "[", ":", ",", "4", "]", "+", "180.0", ")", "%", "360.0", "-", "180.0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.clip": [[254, 303], ["rotated_boxes.RotatedBoxes.normalize_angles", "x1.clamp_", "y1.clamp_", "x2.clamp_", "y2.clamp_", "torch.min", "torch.min", "torch.where", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.normalize_angles"], ["", "def", "clip", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "clip_angle_threshold", ":", "float", "=", "1.0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clip (in place) the boxes by limiting x coordinates to the range [0, width]\n        and y coordinates to the range [0, height].\n\n        For RRPN:\n        Only clip boxes that are almost horizontal with a tolerance of\n        clip_angle_threshold to maintain backward compatibility.\n\n        Rotated boxes beyond this threshold are not clipped for two reasons:\n\n        1. There are potentially multiple ways to clip a rotated box to make it\n           fit within the image.\n        2. It's tricky to make the entire rectangular box fit within the image\n           and still be able to not leave out pixels of interest.\n\n        Therefore we rely on ops like RoIAlignRotated to safely handle this.\n\n        Args:\n            box_size (height, width): The clipping box's size.\n            clip_angle_threshold:\n                Iff. abs(normalized(angle)) <= clip_angle_threshold (in degrees),\n                we do the clipping as horizontal boxes.\n        \"\"\"", "\n", "h", ",", "w", "=", "box_size", "\n", "\n", "# normalize angles to be within (-180, 180] degrees", "\n", "self", ".", "normalize_angles", "(", ")", "\n", "\n", "idx", "=", "torch", ".", "where", "(", "torch", ".", "abs", "(", "self", ".", "tensor", "[", ":", ",", "4", "]", ")", "<=", "clip_angle_threshold", ")", "[", "0", "]", "\n", "\n", "# convert to (x1, y1, x2, y2)", "\n", "x1", "=", "self", ".", "tensor", "[", "idx", ",", "0", "]", "-", "self", ".", "tensor", "[", "idx", ",", "2", "]", "/", "2.0", "\n", "y1", "=", "self", ".", "tensor", "[", "idx", ",", "1", "]", "-", "self", ".", "tensor", "[", "idx", ",", "3", "]", "/", "2.0", "\n", "x2", "=", "self", ".", "tensor", "[", "idx", ",", "0", "]", "+", "self", ".", "tensor", "[", "idx", ",", "2", "]", "/", "2.0", "\n", "y2", "=", "self", ".", "tensor", "[", "idx", ",", "1", "]", "+", "self", ".", "tensor", "[", "idx", ",", "3", "]", "/", "2.0", "\n", "\n", "# clip", "\n", "x1", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y1", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "x2", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y2", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "\n", "# convert back to (xc, yc, w, h)", "\n", "self", ".", "tensor", "[", "idx", ",", "0", "]", "=", "(", "x1", "+", "x2", ")", "/", "2.0", "\n", "self", ".", "tensor", "[", "idx", ",", "1", "]", "=", "(", "y1", "+", "y2", ")", "/", "2.0", "\n", "# make sure widths and heights do not increase due to numerical errors", "\n", "self", ".", "tensor", "[", "idx", ",", "2", "]", "=", "torch", ".", "min", "(", "self", ".", "tensor", "[", "idx", ",", "2", "]", ",", "x2", "-", "x1", ")", "\n", "self", ".", "tensor", "[", "idx", ",", "3", "]", "=", "torch", ".", "min", "(", "self", ".", "tensor", "[", "idx", ",", "3", "]", ",", "y2", "-", "y1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.nonempty": [[304, 318], ["None"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ",", "threshold", ":", "float", "=", "0.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find boxes that are non-empty.\n        A box is considered empty, if either of its side is no larger than threshold.\n\n        Returns:\n            Tensor: a binary vector which represents\n            whether each box is empty (False) or non-empty (True).\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "widths", "=", "box", "[", ":", ",", "2", "]", "\n", "heights", "=", "box", "[", ":", ",", "3", "]", "\n", "keep", "=", "(", "widths", ">", "threshold", ")", "&", "(", "heights", ">", "threshold", ")", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.__getitem__": [[319, 341], ["isinstance", "rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes", "b.dim", "rotated_boxes.RotatedBoxes.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            RotatedBoxes: Create a new :class:`RotatedBoxes` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_boxes = boxes[3]`: return a `RotatedBoxes` which contains only one box.\n        2. `new_boxes = boxes[2:10]`: return a slice of boxes.\n        3. `new_boxes = boxes[vector]`, where vector is a torch.ByteTensor\n           with `length = len(boxes)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned RotatedBoxes might share storage with this RotatedBoxes,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "RotatedBoxes", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "b", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "b", ".", "dim", "(", ")", "==", "2", ",", "\"Indexing on RotatedBoxes with {} failed to return a matrix!\"", ".", "format", "(", "\n", "item", "\n", ")", "\n", "return", "RotatedBoxes", "(", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.__len__": [[342, 344], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.__repr__": [[345, 347], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "\"RotatedBoxes(\"", "+", "str", "(", "self", ".", "tensor", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.inside_box": [[348, 384], ["torch.abs", "torch.abs", "torch.cos", "torch.sin"], "methods", ["None"], ["", "def", "inside_box", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "boundary_threshold", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_size (height, width): Size of the reference box covering\n                [0, width] x [0, height]\n            boundary_threshold (int): Boxes that extend beyond the reference box\n                boundary by more than boundary_threshold are considered \"outside\".\n\n        For RRPN, it might not be necessary to call this function since it's common\n        for rotated box to extend to outside of the image boundaries\n        (the clip function only clips the near-horizontal boxes)\n\n        Returns:\n            a binary vector, indicating whether each box is inside the reference box.\n        \"\"\"", "\n", "height", ",", "width", "=", "box_size", "\n", "\n", "cnt_x", "=", "self", ".", "tensor", "[", "...", ",", "0", "]", "\n", "cnt_y", "=", "self", ".", "tensor", "[", "...", ",", "1", "]", "\n", "half_w", "=", "self", ".", "tensor", "[", "...", ",", "2", "]", "/", "2.0", "\n", "half_h", "=", "self", ".", "tensor", "[", "...", ",", "3", "]", "/", "2.0", "\n", "a", "=", "self", ".", "tensor", "[", "...", ",", "4", "]", "\n", "c", "=", "torch", ".", "abs", "(", "torch", ".", "cos", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "s", "=", "torch", ".", "abs", "(", "torch", ".", "sin", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "# This basically computes the horizontal bounding rectangle of the rotated box", "\n", "max_rect_dx", "=", "c", "*", "half_w", "+", "s", "*", "half_h", "\n", "max_rect_dy", "=", "c", "*", "half_h", "+", "s", "*", "half_w", "\n", "\n", "inds_inside", "=", "(", "\n", "(", "cnt_x", "-", "max_rect_dx", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "cnt_y", "-", "max_rect_dy", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "cnt_x", "+", "max_rect_dx", "<", "width", "+", "boundary_threshold", ")", "\n", "&", "(", "cnt_y", "+", "max_rect_dy", "<", "height", "+", "boundary_threshold", ")", "\n", ")", "\n", "\n", "return", "inds_inside", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.get_centers": [[385, 391], ["None"], "methods", ["None"], ["", "def", "get_centers", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns:\n            The box centers in a Nx2 array of (x, y).\n        \"\"\"", "\n", "return", "self", ".", "tensor", "[", ":", ",", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.scale": [[392, 456], ["torch.cos", "torch.sin", "torch.sqrt", "torch.sqrt", "torch.atan2"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "scale_x", ":", "float", ",", "scale_y", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Scale the rotated box with horizontal and vertical scaling factors\n        Note: when scale_factor_x != scale_factor_y,\n        the rotated box does not preserve the rectangular shape when the angle\n        is not a multiple of 90 degrees under resize transformation.\n        Instead, the shape is a parallelogram (that has skew)\n        Here we make an approximation by fitting a rotated rectangle to the parallelogram.\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "0", "]", "*=", "scale_x", "\n", "self", ".", "tensor", "[", ":", ",", "1", "]", "*=", "scale_y", "\n", "theta", "=", "self", ".", "tensor", "[", ":", ",", "4", "]", "*", "math", ".", "pi", "/", "180.0", "\n", "c", "=", "torch", ".", "cos", "(", "theta", ")", "\n", "s", "=", "torch", ".", "sin", "(", "theta", ")", "\n", "\n", "# In image space, y is top->down and x is left->right", "\n", "# Consider the local coordintate system for the rotated box,", "\n", "# where the box center is located at (0, 0), and the four vertices ABCD are", "\n", "# A(-w / 2, -h / 2), B(w / 2, -h / 2), C(w / 2, h / 2), D(-w / 2, h / 2)", "\n", "# the midpoint of the left edge AD of the rotated box E is:", "\n", "# E = (A+D)/2 = (-w / 2, 0)", "\n", "# the midpoint of the top edge AB of the rotated box F is:", "\n", "# F(0, -h / 2)", "\n", "# To get the old coordinates in the global system, apply the rotation transformation", "\n", "# (Note: the right-handed coordinate system for image space is yOx):", "\n", "# (old_x, old_y) = (s * y + c * x, c * y - s * x)", "\n", "# E(old) = (s * 0 + c * (-w/2), c * 0 - s * (-w/2)) = (-c * w / 2, s * w / 2)", "\n", "# F(old) = (s * (-h / 2) + c * 0, c * (-h / 2) - s * 0) = (-s * h / 2, -c * h / 2)", "\n", "# After applying the scaling factor (sfx, sfy):", "\n", "# E(new) = (-sfx * c * w / 2, sfy * s * w / 2)", "\n", "# F(new) = (-sfx * s * h / 2, -sfy * c * h / 2)", "\n", "# The new width after scaling tranformation becomes:", "\n", "\n", "# w(new) = |E(new) - O| * 2", "\n", "#        = sqrt[(sfx * c * w / 2)^2 + (sfy * s * w / 2)^2] * 2", "\n", "#        = sqrt[(sfx * c)^2 + (sfy * s)^2] * w", "\n", "# i.e., scale_factor_w = sqrt[(sfx * c)^2 + (sfy * s)^2]", "\n", "#", "\n", "# For example,", "\n", "# when angle = 0 or 180, |c| = 1, s = 0, scale_factor_w == scale_factor_x;", "\n", "# when |angle| = 90, c = 0, |s| = 1, scale_factor_w == scale_factor_y", "\n", "self", ".", "tensor", "[", ":", ",", "2", "]", "*=", "torch", ".", "sqrt", "(", "(", "scale_x", "*", "c", ")", "**", "2", "+", "(", "scale_y", "*", "s", ")", "**", "2", ")", "\n", "\n", "# h(new) = |F(new) - O| * 2", "\n", "#        = sqrt[(sfx * s * h / 2)^2 + (sfy * c * h / 2)^2] * 2", "\n", "#        = sqrt[(sfx * s)^2 + (sfy * c)^2] * h", "\n", "# i.e., scale_factor_h = sqrt[(sfx * s)^2 + (sfy * c)^2]", "\n", "#", "\n", "# For example,", "\n", "# when angle = 0 or 180, |c| = 1, s = 0, scale_factor_h == scale_factor_y;", "\n", "# when |angle| = 90, c = 0, |s| = 1, scale_factor_h == scale_factor_x", "\n", "self", ".", "tensor", "[", ":", ",", "3", "]", "*=", "torch", ".", "sqrt", "(", "(", "scale_x", "*", "s", ")", "**", "2", "+", "(", "scale_y", "*", "c", ")", "**", "2", ")", "\n", "\n", "# The angle is the rotation angle from y-axis in image space to the height", "\n", "# vector (top->down in the box's local coordinate system) of the box in CCW.", "\n", "#", "\n", "# angle(new) = angle_yOx(O - F(new))", "\n", "#            = angle_yOx( (sfx * s * h / 2, sfy * c * h / 2) )", "\n", "#            = atan2(sfx * s * h / 2, sfy * c * h / 2)", "\n", "#            = atan2(sfx * s, sfy * c)", "\n", "#", "\n", "# For example,", "\n", "# when sfx == sfy, angle(new) == atan2(s, c) == angle(old)", "\n", "self", ".", "tensor", "[", ":", ",", "4", "]", "=", "torch", ".", "atan2", "(", "scale_x", "*", "s", ",", "scale_y", "*", "c", ")", "*", "180", "/", "math", ".", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.cat": [[457, 477], ["isinstance", "all", "cls", "len", "cls", "torch.cat", "torch.empty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "@", "classmethod", "\n", "@", "_maybe_jit_unused", "\n", "def", "cat", "(", "cls", ",", "boxes_list", ":", "List", "[", "\"RotatedBoxes\"", "]", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of RotatedBoxes into a single RotatedBoxes\n\n        Arguments:\n            boxes_list (list[RotatedBoxes])\n\n        Returns:\n            RotatedBoxes: the concatenated RotatedBoxes\n        \"\"\"", "\n", "assert", "isinstance", "(", "boxes_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "boxes_list", ")", "==", "0", ":", "\n", "            ", "return", "cls", "(", "torch", ".", "empty", "(", "0", ")", ")", "\n", "", "assert", "all", "(", "[", "isinstance", "(", "box", ",", "RotatedBoxes", ")", "for", "box", "in", "boxes_list", "]", ")", "\n", "\n", "# use torch.cat (v.s. layers.cat) so the returned boxes never share storage with input", "\n", "cat_boxes", "=", "cls", "(", "torch", ".", "cat", "(", "[", "b", ".", "tensor", "for", "b", "in", "boxes_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.device": [[478, 481], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.RotatedBoxes.__iter__": [[482, 488], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Yield a box as a Tensor of shape (5,) at a time.\n        \"\"\"", "\n", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.rotated_boxes.pairwise_iou": [[490, 506], ["detectron2.layers.rotated_boxes.pairwise_iou_rotated"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.rotated_boxes.pairwise_iou_rotated"], ["", "", "def", "pairwise_iou", "(", "boxes1", ":", "RotatedBoxes", ",", "boxes2", ":", "RotatedBoxes", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Given two lists of rotated boxes of size N and M,\n    compute the IoU (intersection over union)\n    between **all** N x M pairs of boxes.\n    The box order must be (x_center, y_center, width, height, angle).\n\n    Args:\n        boxes1, boxes2 (RotatedBoxes):\n            two `RotatedBoxes`. Contains N & M rotated boxes, respectively.\n\n    Returns:\n        Tensor: IoU, sized [N,M].\n    \"\"\"", "\n", "\n", "return", "pairwise_iou_rotated", "(", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.__init__": [[36, 45], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ",", "image_sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            tensor (Tensor): of shape (N, H, W) or (N, C_1, ..., C_K, H, W) where K >= 1\n            image_sizes (list[tuple[int, int]]): Each tuple is (h, w). It can\n                be smaller than (H, W) due to padding.\n        \"\"\"", "\n", "self", ".", "tensor", "=", "tensor", "\n", "self", ".", "image_sizes", "=", "image_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.__getitem__": [[49, 61], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Access the individual image in its original size.\n\n        Args:\n            idx: int or slice\n\n        Returns:\n            Tensor: an image of shape (H, W) or (C_1, ..., C_K, H, W) where K >= 1\n        \"\"\"", "\n", "size", "=", "self", ".", "image_sizes", "[", "idx", "]", "\n", "return", "self", ".", "tensor", "[", "idx", ",", "...", ",", ":", "size", "[", "0", "]", ",", ":", "size", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.to": [[62, 66], ["image_list.ImageList.tensor.to", "image_list.ImageList"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"ImageList\"", ":", "\n", "        ", "cast_tensor", "=", "self", ".", "tensor", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "ImageList", "(", "cast_tensor", ",", "self", ".", "image_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.device": [[67, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors": [[71, 125], ["isinstance", "torch.jit.is_scripting", "image_list.ImageList", "len", "isinstance", "type", "image_list._as_tensor", "torch.stack().max", "max_size.to().tolist", "len", "torch.nn.functional.pad().unsqueeze_", "tensors[].new_full", "zip", "tensors[].new_full.contiguous", "torch.jit.is_tracing", "list", "pad_img[].copy_", "torch.stack", "max_size.to", "torch.nn.functional.pad", "list", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list._as_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "@", "staticmethod", "\n", "def", "from_tensors", "(", "\n", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "size_divisibility", ":", "int", "=", "0", ",", "pad_value", ":", "float", "=", "0.0", "\n", ")", "->", "\"ImageList\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensors: a tuple or list of `torch.Tensor`, each of shape (Hi, Wi) or\n                (C_1, ..., C_K, Hi, Wi) where K >= 1. The Tensors will be padded\n                to the same shape with `pad_value`.\n            size_divisibility (int): If `size_divisibility > 0`, add padding to ensure\n                the common height and width is divisible by `size_divisibility`.\n                This depends on the model and many models need a divisibility of 32.\n            pad_value (float): value to pad\n\n        Returns:\n            an `ImageList`.\n        \"\"\"", "\n", "assert", "len", "(", "tensors", ")", ">", "0", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "tuple", ",", "list", ")", ")", "\n", "for", "t", "in", "tensors", ":", "\n", "            ", "assert", "isinstance", "(", "t", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "t", ")", "\n", "assert", "t", ".", "shape", "[", ":", "-", "2", "]", "==", "tensors", "[", "0", "]", ".", "shape", "[", ":", "-", "2", "]", ",", "t", ".", "shape", "\n", "\n", "", "image_sizes", "=", "[", "(", "im", ".", "shape", "[", "-", "2", "]", ",", "im", ".", "shape", "[", "-", "1", "]", ")", "for", "im", "in", "tensors", "]", "\n", "image_sizes_tensor", "=", "[", "_as_tensor", "(", "x", ")", "for", "x", "in", "image_sizes", "]", "\n", "max_size", "=", "torch", ".", "stack", "(", "image_sizes_tensor", ")", ".", "max", "(", "0", ")", ".", "values", "\n", "\n", "if", "size_divisibility", ">", "1", ":", "\n", "            ", "stride", "=", "size_divisibility", "\n", "# the last two dims are H,W, both subject to divisibility requirement", "\n", "max_size", "=", "(", "max_size", "+", "(", "stride", "-", "1", ")", ")", "//", "stride", "*", "stride", "\n", "\n", "# handle weirdness of scripting and tracing ...", "\n", "", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "max_size", ":", "List", "[", "int", "]", "=", "max_size", ".", "to", "(", "dtype", "=", "torch", ".", "long", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "# https://github.com/pytorch/pytorch/issues/42448", "\n", "            ", "if", "TORCH_VERSION", ">=", "(", "1", ",", "7", ")", "and", "torch", ".", "jit", ".", "is_tracing", "(", ")", ":", "\n", "                ", "image_sizes", "=", "image_sizes_tensor", "\n", "\n", "", "", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "# This seems slightly (2%) faster.", "\n", "# TODO: check whether it's faster for multiple images as well", "\n", "            ", "image_size", "=", "image_sizes", "[", "0", "]", "\n", "padding_size", "=", "[", "0", ",", "max_size", "[", "-", "1", "]", "-", "image_size", "[", "1", "]", ",", "0", ",", "max_size", "[", "-", "2", "]", "-", "image_size", "[", "0", "]", "]", "\n", "batched_imgs", "=", "F", ".", "pad", "(", "tensors", "[", "0", "]", ",", "padding_size", ",", "value", "=", "pad_value", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "", "else", ":", "\n", "# max_size can be a tensor in tracing mode, therefore convert to list", "\n", "            ", "batch_shape", "=", "[", "len", "(", "tensors", ")", "]", "+", "list", "(", "tensors", "[", "0", "]", ".", "shape", "[", ":", "-", "2", "]", ")", "+", "list", "(", "max_size", ")", "\n", "batched_imgs", "=", "tensors", "[", "0", "]", ".", "new_full", "(", "batch_shape", ",", "pad_value", ")", "\n", "for", "img", ",", "pad_img", "in", "zip", "(", "tensors", ",", "batched_imgs", ")", ":", "\n", "                ", "pad_img", "[", "...", ",", ":", "img", ".", "shape", "[", "-", "2", "]", ",", ":", "img", ".", "shape", "[", "-", "1", "]", "]", ".", "copy_", "(", "img", ")", "\n", "\n", "", "", "return", "ImageList", "(", "batched_imgs", ".", "contiguous", "(", ")", ",", "image_sizes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list._as_tensor": [[11, 22], ["torch.jit.is_scripting", "torch.as_tensor", "torch.as_tensor", "isinstance", "all", "torch.stack", "isinstance"], "function", ["None"], ["def", "_as_tensor", "(", "x", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    An equivalent of `torch.as_tensor`, but works under tracing if input\n    is a list of tensor. `torch.as_tensor` will record a constant in tracing,\n    but this function will use `torch.stack` instead.\n    \"\"\"", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "return", "torch", ".", "as_tensor", "(", "x", ")", "\n", "", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "[", "isinstance", "(", "t", ",", "torch", ".", "Tensor", ")", "for", "t", "in", "x", "]", ")", ":", "\n", "        ", "return", "torch", ".", "stack", "(", "x", ")", "\n", "", "return", "torch", ".", "as_tensor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__init__": [[38, 48], ["kwargs.items", "instances.Instances.set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["def", "__init__", "(", "self", ",", "image_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "**", "kwargs", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_size (height, width): the spatial size of the image.\n            kwargs: fields to add to this `Instances`.\n        \"\"\"", "\n", "self", ".", "_image_size", "=", "image_size", "\n", "self", ".", "_fields", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "set", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.image_size": [[49, 56], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "image_size", "(", "self", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple: height, width\n        \"\"\"", "\n", "return", "self", ".", "_image_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__setattr__": [[57, 62], ["name.startswith", "super().__setattr__", "instances.Instances.set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.__setattr__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "__setattr__", "(", "self", ",", "name", ":", "str", ",", "val", ":", "Any", ")", "->", "None", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "set", "(", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__getattr__": [[63, 67], ["AttributeError"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "if", "name", "==", "\"_fields\"", "or", "name", "not", "in", "self", ".", "_fields", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Cannot find field '{}' in the given Instances!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.set": [[68, 80], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "name", ":", "str", ",", "value", ":", "Any", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set the field named `name` to `value`.\n        The length of `value` must be the number of instances,\n        and must agree with other existing fields in this object.\n        \"\"\"", "\n", "data_len", "=", "len", "(", "value", ")", "\n", "if", "len", "(", "self", ".", "_fields", ")", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "self", ")", "==", "data_len", "\n", ")", ",", "\"Adding a field of length {} to a Instances of length {}\"", ".", "format", "(", "data_len", ",", "len", "(", "self", ")", ")", "\n", "", "self", ".", "_fields", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.has": [[81, 87], ["None"], "methods", ["None"], ["", "def", "has", "(", "self", ",", "name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns:\n            bool: whether the field called `name` exists.\n        \"\"\"", "\n", "return", "name", "in", "self", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.remove": [[88, 93], ["None"], "methods", ["None"], ["", "def", "remove", "(", "self", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Remove the field called `name`.\n        \"\"\"", "\n", "del", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.get": [[94, 99], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Returns the field called `name`.\n        \"\"\"", "\n", "return", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.get_fields": [[100, 108], ["None"], "methods", ["None"], ["", "def", "get_fields", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: a dict which maps names (str) to data of the fields\n\n        Modifying the returned dict will modify this instance.\n        \"\"\"", "\n", "return", "self", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.to": [[110, 121], ["instances.Instances", "instances.Instances._fields.items", "hasattr", "instances.Instances.set", "v.to.to.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Instances: all fields are called with a `to(device)`, if the field has this method.\n        \"\"\"", "\n", "ret", "=", "Instances", "(", "self", ".", "_image_size", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "v", ",", "\"to\"", ")", ":", "\n", "                ", "v", "=", "v", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "ret", ".", "set", "(", "k", ",", "v", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__getitem__": [[122, 141], ["instances.Instances", "instances.Instances._fields.items", "type", "instances.Instances.set", "IndexError", "slice", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            item: an index-like object and will be used to index all the fields.\n\n        Returns:\n            If `item` is a string, return the data in the corresponding field.\n            Otherwise, returns an `Instances` where all fields are indexed by `item`.\n        \"\"\"", "\n", "if", "type", "(", "item", ")", "==", "int", ":", "\n", "            ", "if", "item", ">=", "len", "(", "self", ")", "or", "item", "<", "-", "len", "(", "self", ")", ":", "\n", "                ", "raise", "IndexError", "(", "\"Instances index out of range!\"", ")", "\n", "", "else", ":", "\n", "                ", "item", "=", "slice", "(", "item", ",", "None", ",", "len", "(", "self", ")", ")", "\n", "\n", "", "", "ret", "=", "Instances", "(", "self", ".", "_image_size", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ":", "\n", "            ", "ret", ".", "set", "(", "k", ",", "v", "[", "item", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__len__": [[142, 147], ["instances.Instances._fields.values", "NotImplementedError", "v.__len__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.MaskLoader.MaskLoader.__len__"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "for", "v", "in", "self", ".", "_fields", ".", "values", "(", ")", ":", "\n", "# use __len__ because len() has to be int and is not friendly to tracing", "\n", "            ", "return", "v", ".", "__len__", "(", ")", "\n", "", "raise", "NotImplementedError", "(", "\"Empty Instances does not support __len__!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__iter__": [[148, 150], ["NotImplementedError"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"`Instances` object is not iterable!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.cat": [[151, 182], ["all", "instances.Instances", "instance_lists[]._fields.keys", "len", "len", "isinstance", "instances.Instances.set", "isinstance", "i.get", "torch.cat", "isinstance", "list", "hasattr", "itertools.chain", "type", "type().cat", "ValueError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "instance_lists", ":", "List", "[", "\"Instances\"", "]", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            instance_lists (list[Instances])\n\n        Returns:\n            Instances\n        \"\"\"", "\n", "assert", "all", "(", "isinstance", "(", "i", ",", "Instances", ")", "for", "i", "in", "instance_lists", ")", "\n", "assert", "len", "(", "instance_lists", ")", ">", "0", "\n", "if", "len", "(", "instance_lists", ")", "==", "1", ":", "\n", "            ", "return", "instance_lists", "[", "0", "]", "\n", "\n", "", "image_size", "=", "instance_lists", "[", "0", "]", ".", "image_size", "\n", "for", "i", "in", "instance_lists", "[", "1", ":", "]", ":", "\n", "            ", "assert", "i", ".", "image_size", "==", "image_size", "\n", "", "ret", "=", "Instances", "(", "image_size", ")", "\n", "for", "k", "in", "instance_lists", "[", "0", "]", ".", "_fields", ".", "keys", "(", ")", ":", "\n", "            ", "values", "=", "[", "i", ".", "get", "(", "k", ")", "for", "i", "in", "instance_lists", "]", "\n", "v0", "=", "values", "[", "0", "]", "\n", "if", "isinstance", "(", "v0", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "values", "=", "torch", ".", "cat", "(", "values", ",", "dim", "=", "0", ")", "\n", "", "elif", "isinstance", "(", "v0", ",", "list", ")", ":", "\n", "                ", "values", "=", "list", "(", "itertools", ".", "chain", "(", "*", "values", ")", ")", "\n", "", "elif", "hasattr", "(", "type", "(", "v0", ")", ",", "\"cat\"", ")", ":", "\n", "                ", "values", "=", "type", "(", "v0", ")", ".", "cat", "(", "values", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported type {} for concatenation\"", ".", "format", "(", "type", "(", "v0", ")", ")", ")", "\n", "", "ret", ".", "set", "(", "k", ",", "values", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.instances.Instances.__str__": [[183, 190], ["len", "instances.Instances._fields.items"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={}, \"", ".", "format", "(", "len", "(", "self", ")", ")", "\n", "s", "+=", "\"image_height={}, \"", ".", "format", "(", "self", ".", "_image_size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "_image_size", "[", "1", "]", ")", "\n", "s", "+=", "\"fields=[{}])\"", ".", "format", "(", "\", \"", ".", "join", "(", "(", "f\"{k}: {v}\"", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ")", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.__init__": [[32, 43], ["torch.as_tensor", "isinstance", "torch.device", "torch.as_tensor.dim"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "__init__", "(", "self", ",", "keypoints", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", ",", "List", "[", "List", "[", "float", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            keypoints: A Tensor, numpy array, or list of the x, y, and visibility of each keypoint.\n                The shape should be (N, K, 3) where N is the number of\n                instances, and K is the number of keypoints per instance.\n        \"\"\"", "\n", "device", "=", "keypoints", ".", "device", "if", "isinstance", "(", "keypoints", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "keypoints", "=", "torch", ".", "as_tensor", "(", "keypoints", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "assert", "keypoints", ".", "dim", "(", ")", "==", "3", "and", "keypoints", ".", "shape", "[", "2", "]", "==", "3", ",", "keypoints", ".", "shape", "\n", "self", ".", "tensor", "=", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.__len__": [[44, 46], ["keypoints.Keypoints.tensor.size"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.to": [[47, 49], ["type", "keypoints.Keypoints.tensor.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"Keypoints\"", ":", "\n", "        ", "return", "type", "(", "self", ")", "(", "self", ".", "tensor", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.device": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.to_heatmap": [[54, 70], ["keypoints._keypoints_to_heatmap"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints._keypoints_to_heatmap"], ["", "def", "to_heatmap", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "heatmap_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Convert keypoint annotations to a heatmap of one-hot labels for training,\n        as described in :paper:`Mask R-CNN`.\n\n        Arguments:\n            boxes: Nx4 tensor, the boxes to draw the keypoints to\n\n        Returns:\n            heatmaps:\n                A tensor of shape (N, K), each element is integer spatial label\n                in the range [0, heatmap_size**2 - 1] for each keypoint in the input.\n            valid:\n                A tensor of shape (N, K) containing whether each keypoint is in the roi or not.\n        \"\"\"", "\n", "return", "_keypoints_to_heatmap", "(", "self", ".", "tensor", ",", "boxes", ",", "heatmap_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.__getitem__": [[71, 88], ["isinstance", "keypoints.Keypoints", "keypoints.Keypoints"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"Keypoints\"", ":", "\n", "        ", "\"\"\"\n        Create a new `Keypoints` by indexing on this `Keypoints`.\n\n        The following usage are allowed:\n\n        1. `new_kpts = kpts[3]`: return a `Keypoints` which contains only one instance.\n        2. `new_kpts = kpts[2:10]`: return a slice of key points.\n        3. `new_kpts = kpts[vector]`, where vector is a torch.ByteTensor\n           with `length = len(kpts)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned Keypoints might share storage with this Keypoints,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "Keypoints", "(", "[", "self", ".", "tensor", "[", "item", "]", "]", ")", "\n", "", "return", "Keypoints", "(", "self", ".", "tensor", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.Keypoints.__repr__": [[89, 93], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "tensor", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints._keypoints_to_heatmap": [[96, 153], ["x.floor().long.floor().long", "y.floor().long.floor().long", "rois.numel", "rois.new().long", "rois.new().long", "x.floor().long.floor", "y.floor().long.floor", "rois.new", "rois.new"], "function", ["None"], ["", "", "def", "_keypoints_to_heatmap", "(", "\n", "keypoints", ":", "torch", ".", "Tensor", ",", "rois", ":", "torch", ".", "Tensor", ",", "heatmap_size", ":", "int", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Encode keypoint locations into a target heatmap for use in SoftmaxWithLoss across space.\n\n    Maps keypoints from the half-open interval [x1, x2) on continuous image coordinates to the\n    closed interval [0, heatmap_size - 1] on discrete image coordinates. We use the\n    continuous-discrete conversion from Heckbert 1990 (\"What is the coordinate of a pixel?\"):\n    d = floor(c) and c = d + 0.5, where d is a discrete coordinate and c is a continuous coordinate.\n\n    Arguments:\n        keypoints: tensor of keypoint locations in of shape (N, K, 3).\n        rois: Nx4 tensor of rois in xyxy format\n        heatmap_size: integer side length of square heatmap.\n\n    Returns:\n        heatmaps: A tensor of shape (N, K) containing an integer spatial label\n            in the range [0, heatmap_size**2 - 1] for each keypoint in the input.\n        valid: A tensor of shape (N, K) containing whether each keypoint is in\n            the roi or not.\n    \"\"\"", "\n", "\n", "if", "rois", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "rois", ".", "new", "(", ")", ".", "long", "(", ")", ",", "rois", ".", "new", "(", ")", ".", "long", "(", ")", "\n", "", "offset_x", "=", "rois", "[", ":", ",", "0", "]", "\n", "offset_y", "=", "rois", "[", ":", ",", "1", "]", "\n", "scale_x", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "2", "]", "-", "rois", "[", ":", ",", "0", "]", ")", "\n", "scale_y", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "3", "]", "-", "rois", "[", ":", ",", "1", "]", ")", "\n", "\n", "offset_x", "=", "offset_x", "[", ":", ",", "None", "]", "\n", "offset_y", "=", "offset_y", "[", ":", ",", "None", "]", "\n", "scale_x", "=", "scale_x", "[", ":", ",", "None", "]", "\n", "scale_y", "=", "scale_y", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "keypoints", "[", "...", ",", "0", "]", "\n", "y", "=", "keypoints", "[", "...", ",", "1", "]", "\n", "\n", "x_boundary_inds", "=", "x", "==", "rois", "[", ":", ",", "2", "]", "[", ":", ",", "None", "]", "\n", "y_boundary_inds", "=", "y", "==", "rois", "[", ":", ",", "3", "]", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "(", "x", "-", "offset_x", ")", "*", "scale_x", "\n", "x", "=", "x", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "y", "=", "(", "y", "-", "offset_y", ")", "*", "scale_y", "\n", "y", "=", "y", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "\n", "x", "[", "x_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "y", "[", "y_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "\n", "valid_loc", "=", "(", "x", ">=", "0", ")", "&", "(", "y", ">=", "0", ")", "&", "(", "x", "<", "heatmap_size", ")", "&", "(", "y", "<", "heatmap_size", ")", "\n", "vis", "=", "keypoints", "[", "...", ",", "2", "]", ">", "0", "\n", "valid", "=", "(", "valid_loc", "&", "vis", ")", ".", "long", "(", ")", "\n", "\n", "lin_ind", "=", "y", "*", "heatmap_size", "+", "x", "\n", "heatmaps", "=", "lin_ind", "*", "valid", "\n", "\n", "return", "heatmaps", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.keypoints.heatmaps_to_keypoints": [[155, 231], ["maps.detach.detach", "rois.detach.detach", "widths.ceil", "heights.ceil", "maps.detach.new_zeros", "torch.arange", "range", "torch.nn.functional.interpolate().squeeze", "F.interpolate().squeeze.view().max", "max_score.view.view", "F.interpolate().squeeze.view().argmax", "int", "int", "tmp_pool_resolution.sum", "torch.nn.functional.interpolate", "F.interpolate().squeeze.view", "F.interpolate().squeeze.view", "x_int.float", "y_int.float", "roi_map_scores.view().max", "roi_map_scores.view"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "@", "script_if_tracing", "\n", "def", "heatmaps_to_keypoints", "(", "maps", ":", "torch", ".", "Tensor", ",", "rois", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Extract predicted keypoint locations from heatmaps.\n\n    Args:\n        maps (Tensor): (#ROIs, #keypoints, POOL_H, POOL_W). The predicted heatmap of logits for\n            each ROI and each keypoint.\n        rois (Tensor): (#ROIs, 4). The box of each ROI.\n\n    Returns:\n        Tensor of shape (#ROIs, #keypoints, 4) with the last dimension corresponding to\n        (x, y, logit, score) for each keypoint.\n\n    When converting discrete pixel indices in an NxN image to a continuous keypoint coordinate,\n    we maintain consistency with :meth:`Keypoints.to_heatmap` by using the conversion from\n    Heckbert 1990: c = d + 0.5, where d is a discrete coordinate and c is a continuous coordinate.\n    \"\"\"", "\n", "# The decorator use of torch.no_grad() was not supported by torchscript.", "\n", "# https://github.com/pytorch/pytorch/issues/44768", "\n", "maps", "=", "maps", ".", "detach", "(", ")", "\n", "rois", "=", "rois", ".", "detach", "(", ")", "\n", "\n", "offset_x", "=", "rois", "[", ":", ",", "0", "]", "\n", "offset_y", "=", "rois", "[", ":", ",", "1", "]", "\n", "\n", "widths", "=", "(", "rois", "[", ":", ",", "2", "]", "-", "rois", "[", ":", ",", "0", "]", ")", ".", "clamp", "(", "min", "=", "1", ")", "\n", "heights", "=", "(", "rois", "[", ":", ",", "3", "]", "-", "rois", "[", ":", ",", "1", "]", ")", ".", "clamp", "(", "min", "=", "1", ")", "\n", "widths_ceil", "=", "widths", ".", "ceil", "(", ")", "\n", "heights_ceil", "=", "heights", ".", "ceil", "(", ")", "\n", "\n", "num_rois", ",", "num_keypoints", "=", "maps", ".", "shape", "[", ":", "2", "]", "\n", "xy_preds", "=", "maps", ".", "new_zeros", "(", "rois", ".", "shape", "[", "0", "]", ",", "num_keypoints", ",", "4", ")", "\n", "\n", "width_corrections", "=", "widths", "/", "widths_ceil", "\n", "height_corrections", "=", "heights", "/", "heights_ceil", "\n", "\n", "keypoints_idx", "=", "torch", ".", "arange", "(", "num_keypoints", ",", "device", "=", "maps", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_rois", ")", ":", "\n", "        ", "outsize", "=", "(", "int", "(", "heights_ceil", "[", "i", "]", ")", ",", "int", "(", "widths_ceil", "[", "i", "]", ")", ")", "\n", "roi_map", "=", "F", ".", "interpolate", "(", "\n", "maps", "[", "[", "i", "]", "]", ",", "size", "=", "outsize", ",", "mode", "=", "\"bicubic\"", ",", "align_corners", "=", "False", "\n", ")", ".", "squeeze", "(", "\n", "0", "\n", ")", "# #keypoints x H x W", "\n", "\n", "# softmax over the spatial region", "\n", "max_score", ",", "_", "=", "roi_map", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "max", "(", "1", ")", "\n", "max_score", "=", "max_score", ".", "view", "(", "num_keypoints", ",", "1", ",", "1", ")", "\n", "tmp_full_resolution", "=", "(", "roi_map", "-", "max_score", ")", ".", "exp_", "(", ")", "\n", "tmp_pool_resolution", "=", "(", "maps", "[", "i", "]", "-", "max_score", ")", ".", "exp_", "(", ")", "\n", "# Produce scores over the region H x W, but normalize with POOL_H x POOL_W,", "\n", "# so that the scores of objects of different absolute sizes will be more comparable", "\n", "roi_map_scores", "=", "tmp_full_resolution", "/", "tmp_pool_resolution", ".", "sum", "(", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "w", "=", "roi_map", ".", "shape", "[", "2", "]", "\n", "pos", "=", "roi_map", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "argmax", "(", "1", ")", "\n", "\n", "x_int", "=", "pos", "%", "w", "\n", "y_int", "=", "(", "pos", "-", "x_int", ")", "//", "w", "\n", "\n", "assert", "(", "\n", "roi_map_scores", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "==", "roi_map_scores", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "max", "(", "1", ")", "[", "0", "]", "\n", ")", ".", "all", "(", ")", "\n", "\n", "x", "=", "(", "x_int", ".", "float", "(", ")", "+", "0.5", ")", "*", "width_corrections", "[", "i", "]", "\n", "y", "=", "(", "y_int", ".", "float", "(", ")", "+", "0.5", ")", "*", "height_corrections", "[", "i", "]", "\n", "\n", "xy_preds", "[", "i", ",", ":", ",", "0", "]", "=", "x", "+", "offset_x", "[", "i", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "1", "]", "=", "y", "+", "offset_y", "[", "i", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "2", "]", "=", "roi_map", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "3", "]", "=", "roi_map_scores", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "\n", "", "return", "xy_preds", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.__init__": [[93, 103], ["torch.as_tensor", "torch.as_tensor.size", "isinstance", "torch.device", "torch.as_tensor.dim"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "__init__", "(", "self", ",", "tensor", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor: bool Tensor of N,H,W, representing N instances in the image.\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "3", ",", "tensor", ".", "size", "(", ")", "\n", "self", ".", "image_size", "=", "tensor", ".", "shape", "[", "1", ":", "]", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.to": [[104, 106], ["masks.BitMasks", "masks.BitMasks.tensor.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "return", "BitMasks", "(", "self", ".", "tensor", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.device": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.__getitem__": [[111, 133], ["isinstance", "masks.BitMasks", "masks.BitMasks", "m.dim", "masks.BitMasks.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            BitMasks: Create a new :class:`BitMasks` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_masks = masks[3]`: return a `BitMasks` which contains only one mask.\n        2. `new_masks = masks[2:10]`: return a slice of masks.\n        3. `new_masks = masks[vector]`, where vector is a torch.BoolTensor\n           with `length = len(masks)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned object might share storage with this object,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "BitMasks", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "m", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "m", ".", "dim", "(", ")", "==", "3", ",", "\"Indexing on BitMasks with {} returns a tensor with shape {}!\"", ".", "format", "(", "\n", "item", ",", "m", ".", "shape", "\n", ")", "\n", "return", "BitMasks", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.__iter__": [[134, 136], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.__repr__": [[137, 141], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "tensor", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.__len__": [[142, 144], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.nonempty": [[145, 154], ["masks.BitMasks.tensor.flatten().any", "masks.BitMasks.tensor.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "nonempty", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find masks that are non-empty.\n\n        Returns:\n            Tensor: a BoolTensor which represents\n                whether each mask is empty (False) or non-empty (True).\n        \"\"\"", "\n", "return", "self", ".", "tensor", ".", "flatten", "(", "1", ")", ".", "any", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.from_polygon_masks": [[155, 168], ["isinstance", "masks.BitMasks", "masks.polygons_to_bitmask", "torch.stack", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygons_to_bitmask"], ["", "@", "staticmethod", "\n", "def", "from_polygon_masks", "(", "\n", "polygon_masks", ":", "Union", "[", "\"PolygonMasks\"", ",", "List", "[", "List", "[", "np", ".", "ndarray", "]", "]", "]", ",", "height", ":", "int", ",", "width", ":", "int", "\n", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            polygon_masks (list[list[ndarray]] or PolygonMasks)\n            height, width (int)\n        \"\"\"", "\n", "if", "isinstance", "(", "polygon_masks", ",", "PolygonMasks", ")", ":", "\n", "            ", "polygon_masks", "=", "polygon_masks", ".", "polygons", "\n", "", "masks", "=", "[", "polygons_to_bitmask", "(", "p", ",", "height", ",", "width", ")", "for", "p", "in", "polygon_masks", "]", "\n", "return", "BitMasks", "(", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "x", ")", "for", "x", "in", "masks", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.crop_and_resize": [[169, 201], ["torch.cat", "masks.BitMasks.tensor.to", "rois.to.to.to", "detectron2.layers.roi_align.ROIAlign().forward().squeeze", "len", "len", "len", "len", "torch.arange().to", "detectron2.layers.roi_align.ROIAlign().forward", "torch.arange", "len", "detectron2.layers.roi_align.ROIAlign"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Decoder.forward"], ["", "def", "crop_and_resize", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "mask_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Crop each bitmask by the given box, and resize results to (mask_size, mask_size).\n        This can be used to prepare training targets for Mask R-CNN.\n        It has less reconstruction error compared to rasterization with polygons.\n        However we observe no difference in accuracy,\n        but BitMasks requires more memory to store all the masks.\n\n        Args:\n            boxes (Tensor): Nx4 tensor storing the boxes for each mask\n            mask_size (int): the size of the rasterized mask.\n\n        Returns:\n            Tensor:\n                A bool tensor of shape (N, mask_size, mask_size), where\n                N is the number of predicted boxes for this image.\n        \"\"\"", "\n", "assert", "len", "(", "boxes", ")", "==", "len", "(", "self", ")", ",", "\"{} != {}\"", ".", "format", "(", "len", "(", "boxes", ")", ",", "len", "(", "self", ")", ")", "\n", "device", "=", "self", ".", "tensor", ".", "device", "\n", "\n", "batch_inds", "=", "torch", ".", "arange", "(", "len", "(", "boxes", ")", ",", "device", "=", "device", ")", ".", "to", "(", "dtype", "=", "boxes", ".", "dtype", ")", "[", ":", ",", "None", "]", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "batch_inds", ",", "boxes", "]", ",", "dim", "=", "1", ")", "# Nx5", "\n", "\n", "bit_masks", "=", "self", ".", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "rois", "=", "rois", ".", "to", "(", "device", "=", "device", ")", "\n", "output", "=", "(", "\n", "ROIAlign", "(", "(", "mask_size", ",", "mask_size", ")", ",", "1.0", ",", "0", ",", "aligned", "=", "True", ")", "\n", ".", "forward", "(", "bit_masks", "[", ":", ",", "None", ",", ":", ",", ":", "]", ",", "rois", ")", "\n", ".", "squeeze", "(", "1", ")", "\n", ")", "\n", "output", "=", "output", ">=", "0.5", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.get_bounding_boxes": [[202, 219], ["torch.zeros", "torch.any", "torch.any", "range", "torch.zeros.Boxes", "torch.where", "torch.where", "torch.as_tensor", "len", "len"], "methods", ["None"], ["", "def", "get_bounding_boxes", "(", "self", ")", "->", "Boxes", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Boxes: tight bounding boxes around bitmasks.\n            If a mask is empty, it's bounding box will be all zero.\n        \"\"\"", "\n", "boxes", "=", "torch", ".", "zeros", "(", "self", ".", "tensor", ".", "shape", "[", "0", "]", ",", "4", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "x_any", "=", "torch", ".", "any", "(", "self", ".", "tensor", ",", "dim", "=", "1", ")", "\n", "y_any", "=", "torch", ".", "any", "(", "self", ".", "tensor", ",", "dim", "=", "2", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "tensor", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "x", "=", "torch", ".", "where", "(", "x_any", "[", "idx", ",", ":", "]", ")", "[", "0", "]", "\n", "y", "=", "torch", ".", "where", "(", "y_any", "[", "idx", ",", ":", "]", ")", "[", "0", "]", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "len", "(", "y", ")", ">", "0", ":", "\n", "                ", "boxes", "[", "idx", ",", ":", "]", "=", "torch", ".", "as_tensor", "(", "\n", "[", "x", "[", "0", "]", ",", "y", "[", "0", "]", ",", "x", "[", "-", "1", "]", "+", "1", ",", "y", "[", "-", "1", "]", "+", "1", "]", ",", "dtype", "=", "torch", ".", "float32", "\n", ")", "\n", "", "", "return", "Boxes", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.BitMasks.cat": [[220, 237], ["isinstance", "all", "len", "type", "torch.cat", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "bitmasks_list", ":", "List", "[", "\"BitMasks\"", "]", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of BitMasks into a single BitMasks\n\n        Arguments:\n            bitmasks_list (list[BitMasks])\n\n        Returns:\n            BitMasks: the concatenated BitMasks\n        \"\"\"", "\n", "assert", "isinstance", "(", "bitmasks_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "bitmasks_list", ")", ">", "0", "\n", "assert", "all", "(", "isinstance", "(", "bitmask", ",", "BitMasks", ")", "for", "bitmask", "in", "bitmasks_list", ")", "\n", "\n", "cat_bitmasks", "=", "type", "(", "bitmasks_list", "[", "0", "]", ")", "(", "torch", ".", "cat", "(", "[", "bm", ".", "tensor", "for", "bm", "in", "bitmasks_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_bitmasks", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.__init__": [[247, 289], ["isinstance", "ValueError", "isinstance", "numpy.asarray().astype", "masks.PolygonMasks.__init__.process_polygons"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "polygons", ":", "List", "[", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            polygons (list[list[np.ndarray]]): The first\n                level of the list correspond to individual instances,\n                the second level to all the polygons that compose the\n                instance, and the third level to the polygon coordinates.\n                The third level array should have the format of\n                [x0, y0, x1, y1, ..., xn, yn] (n >= 3).\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "polygons", ",", "list", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot create PolygonMasks: Expect a list of list of polygons per image. \"", "\n", "\"Got '{}' instead.\"", ".", "format", "(", "type", "(", "polygons", ")", ")", "\n", ")", "\n", "\n", "", "def", "_make_array", "(", "t", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "# Use float64 for higher precision, because why not?", "\n", "# Always put polygons on CPU (self.to is a no-op) since they", "\n", "# are supposed to be small tensors.", "\n", "# May need to change this assumption if GPU placement becomes useful", "\n", "            ", "if", "isinstance", "(", "t", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "t", "=", "t", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "np", ".", "asarray", "(", "t", ")", ".", "astype", "(", "\"float64\"", ")", "\n", "\n", "", "def", "process_polygons", "(", "\n", "polygons_per_instance", ":", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", "]", "\n", ")", "->", "List", "[", "np", ".", "ndarray", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "polygons_per_instance", ",", "list", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot create polygons: Expect a list of polygons per instance. \"", "\n", "\"Got '{}' instead.\"", ".", "format", "(", "type", "(", "polygons_per_instance", ")", ")", "\n", ")", "\n", "# transform each polygon to a numpy array", "\n", "", "polygons_per_instance", "=", "[", "_make_array", "(", "p", ")", "for", "p", "in", "polygons_per_instance", "]", "\n", "for", "polygon", "in", "polygons_per_instance", ":", "\n", "                ", "if", "len", "(", "polygon", ")", "%", "2", "!=", "0", "or", "len", "(", "polygon", ")", "<", "6", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Cannot create a polygon from {len(polygon)} coordinates.\"", ")", "\n", "", "", "return", "polygons_per_instance", "\n", "\n", "", "self", ".", "polygons", ":", "List", "[", "List", "[", "np", ".", "ndarray", "]", "]", "=", "[", "\n", "process_polygons", "(", "polygons_per_instance", ")", "for", "polygons_per_instance", "in", "polygons", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.to": [[291, 293], ["None"], "methods", ["None"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.device": [[294, 297], ["torch.device"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.get_bounding_boxes": [[298, 314], ["torch.zeros", "enumerate", "torch.zeros.Boxes", "len", "torch.as_tensor", "torch.zeros", "torch.from_numpy().view().to", "torch.min", "torch.max", "float", "float", "torch.from_numpy().view", "torch.min", "torch.max", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "get_bounding_boxes", "(", "self", ")", "->", "Boxes", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Boxes: tight bounding boxes around polygon masks.\n        \"\"\"", "\n", "boxes", "=", "torch", ".", "zeros", "(", "len", "(", "self", ".", "polygons", ")", ",", "4", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "idx", ",", "polygons_per_instance", "in", "enumerate", "(", "self", ".", "polygons", ")", ":", "\n", "            ", "minxy", "=", "torch", ".", "as_tensor", "(", "[", "float", "(", "\"inf\"", ")", ",", "float", "(", "\"inf\"", ")", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "maxxy", "=", "torch", ".", "zeros", "(", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "polygon", "in", "polygons_per_instance", ":", "\n", "                ", "coords", "=", "torch", ".", "from_numpy", "(", "polygon", ")", ".", "view", "(", "-", "1", ",", "2", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "minxy", "=", "torch", ".", "min", "(", "minxy", ",", "torch", ".", "min", "(", "coords", ",", "dim", "=", "0", ")", ".", "values", ")", "\n", "maxxy", "=", "torch", ".", "max", "(", "maxxy", ",", "torch", ".", "max", "(", "coords", ",", "dim", "=", "0", ")", ".", "values", ")", "\n", "", "boxes", "[", "idx", ",", ":", "2", "]", "=", "minxy", "\n", "boxes", "[", "idx", ",", "2", ":", "]", "=", "maxxy", "\n", "", "return", "Boxes", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.nonempty": [[315, 325], ["torch.from_numpy", "numpy.asarray", "len"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find masks that are non-empty.\n\n        Returns:\n            Tensor:\n                a BoolTensor which represents whether each mask is empty (False) or not (True).\n        \"\"\"", "\n", "keep", "=", "[", "1", "if", "len", "(", "polygon", ")", ">", "0", "else", "0", "for", "polygon", "in", "self", ".", "polygons", "]", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "keep", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.__getitem__": [[326, 355], ["isinstance", "masks.PolygonMasks", "isinstance", "isinstance", "isinstance", "torch.nonzero().squeeze().cpu().numpy().tolist", "item.cpu().numpy().tolist.cpu().numpy().tolist.dim", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "ValueError", "torch.nonzero().squeeze().cpu().numpy", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "torch.nonzero().squeeze().cpu", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu", "torch.nonzero().squeeze", "torch.nonzero"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "List", "[", "int", "]", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "\"\"\"\n        Support indexing over the instances and return a `PolygonMasks` object.\n        `item` can be:\n\n        1. An integer. It will return an object with only one instance.\n        2. A slice. It will return an object with the selected instances.\n        3. A list[int]. It will return an object with the selected instances,\n           correpsonding to the indices in the list.\n        4. A vector mask of type BoolTensor, whose length is num_instances.\n           It will return an object with the instances whose mask is nonzero.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "item", "]", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "slice", ")", ":", "\n", "            ", "selected_polygons", "=", "self", ".", "polygons", "[", "item", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "list", ")", ":", "\n", "            ", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "i", "]", "for", "i", "in", "item", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Polygons is a list, so we have to move the indices back to CPU.", "\n", "            ", "if", "item", ".", "dtype", "==", "torch", ".", "bool", ":", "\n", "                ", "assert", "item", ".", "dim", "(", ")", "==", "1", ",", "item", ".", "shape", "\n", "item", "=", "torch", ".", "nonzero", "(", "item", ",", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "elif", "item", ".", "dtype", "in", "[", "torch", ".", "int32", ",", "torch", ".", "int64", "]", ":", "\n", "                ", "item", "=", "item", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported tensor dtype={} for indexing!\"", ".", "format", "(", "item", ".", "dtype", ")", ")", "\n", "", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "i", "]", "for", "i", "in", "item", "]", "\n", "", "return", "PolygonMasks", "(", "selected_polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.__iter__": [[356, 363], ["iter"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "List", "[", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Yields:\n            list[ndarray]: the polygons for one instance.\n            Each Tensor is a float64 vector representing a polygon.\n        \"\"\"", "\n", "return", "iter", "(", "self", ".", "polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.__repr__": [[364, 368], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "polygons", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.__len__": [[369, 371], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize": [[372, 403], ["boxes.to.to.to", "torch.stack().to", "len", "len", "len", "len", "torch.device", "masks.rasterize_polygons_within_box", "len", "torch.empty", "box.numpy", "zip", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.rasterize_polygons_within_box"], ["", "def", "crop_and_resize", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "mask_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Crop each mask by the given box, and resize results to (mask_size, mask_size).\n        This can be used to prepare training targets for Mask R-CNN.\n\n        Args:\n            boxes (Tensor): Nx4 tensor storing the boxes for each mask\n            mask_size (int): the size of the rasterized mask.\n\n        Returns:\n            Tensor: A bool tensor of shape (N, mask_size, mask_size), where\n            N is the number of predicted boxes for this image.\n        \"\"\"", "\n", "assert", "len", "(", "boxes", ")", "==", "len", "(", "self", ")", ",", "\"{} != {}\"", ".", "format", "(", "len", "(", "boxes", ")", ",", "len", "(", "self", ")", ")", "\n", "\n", "device", "=", "boxes", ".", "device", "\n", "# Put boxes on the CPU, as the polygon representation is not efficient GPU-wise", "\n", "# (several small tensors for representing a single instance mask)", "\n", "boxes", "=", "boxes", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "results", "=", "[", "\n", "rasterize_polygons_within_box", "(", "poly", ",", "box", ".", "numpy", "(", ")", ",", "mask_size", ")", "\n", "for", "poly", ",", "box", "in", "zip", "(", "self", ".", "polygons", ",", "boxes", ")", "\n", "]", "\n", "\"\"\"\n        poly: list[list[float]], the polygons for one instance\n        box: a tensor of shape (4,)\n        \"\"\"", "\n", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "return", "torch", ".", "empty", "(", "0", ",", "mask_size", ",", "mask_size", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "", "return", "torch", ".", "stack", "(", "results", ",", "dim", "=", "0", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.area": [[404, 422], ["torch.tensor", "area.append", "masks.polygon_area"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygon_area"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Computes area of the mask.\n        Only works with Polygons, using the shoelace formula:\n        https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates\n\n        Returns:\n            Tensor: a vector, area for each instance\n        \"\"\"", "\n", "\n", "area", "=", "[", "]", "\n", "for", "polygons_per_instance", "in", "self", ".", "polygons", ":", "\n", "            ", "area_per_instance", "=", "0", "\n", "for", "p", "in", "polygons_per_instance", ":", "\n", "                ", "area_per_instance", "+=", "polygon_area", "(", "p", "[", "0", ":", ":", "2", "]", ",", "p", "[", "1", ":", ":", "2", "]", ")", "\n", "", "area", ".", "append", "(", "area_per_instance", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.cat": [[423, 442], ["isinstance", "all", "len", "type", "list", "isinstance", "itertools.chain.from_iterable"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "polymasks_list", ":", "List", "[", "\"PolygonMasks\"", "]", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of PolygonMasks into a single PolygonMasks\n\n        Arguments:\n            polymasks_list (list[PolygonMasks])\n\n        Returns:\n            PolygonMasks: the concatenated PolygonMasks\n        \"\"\"", "\n", "assert", "isinstance", "(", "polymasks_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "polymasks_list", ")", ">", "0", "\n", "assert", "all", "(", "isinstance", "(", "polymask", ",", "PolygonMasks", ")", "for", "polymask", "in", "polymasks_list", ")", "\n", "\n", "cat_polymasks", "=", "type", "(", "polymasks_list", "[", "0", "]", ")", "(", "\n", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "pm", ".", "polygons", "for", "pm", "in", "polymasks_list", ")", ")", "\n", ")", "\n", "return", "cat_polymasks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygon_area": [[14, 18], ["numpy.abs", "numpy.dot", "numpy.dot", "numpy.roll", "numpy.roll"], "function", ["None"], ["def", "polygon_area", "(", "x", ",", "y", ")", ":", "\n", "# Using the shoelace formula", "\n", "# https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates", "\n", "    ", "return", "0.5", "*", "np", ".", "abs", "(", "np", ".", "dot", "(", "x", ",", "np", ".", "roll", "(", "y", ",", "1", ")", ")", "-", "np", ".", "dot", "(", "y", ",", "np", ".", "roll", "(", "x", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygons_to_bitmask": [[20, 33], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode().astype", "len", "pycocotools.decode"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["", "def", "polygons_to_bitmask", "(", "polygons", ":", "List", "[", "np", ".", "ndarray", "]", ",", "height", ":", "int", ",", "width", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Args:\n        polygons (list[ndarray]): each array has shape (Nx2,)\n        height, width (int)\n\n    Returns:\n        ndarray: a bool mask of shape (height, width)\n    \"\"\"", "\n", "assert", "len", "(", "polygons", ")", ">", "0", ",", "\"COCOAPI does not support empty polygons\"", "\n", "rles", "=", "mask_util", ".", "frPyObjects", "(", "polygons", ",", "height", ",", "width", ")", "\n", "rle", "=", "mask_util", ".", "merge", "(", "rles", ")", "\n", "return", "mask_util", ".", "decode", "(", "rle", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.rasterize_polygons_within_box": [[35, 82], ["copy.deepcopy", "masks.polygons_to_bitmask", "torch.from_numpy", "max", "max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygons_to_bitmask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "rasterize_polygons_within_box", "(", "\n", "polygons", ":", "List", "[", "np", ".", "ndarray", "]", ",", "box", ":", "np", ".", "ndarray", ",", "mask_size", ":", "int", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Rasterize the polygons into a mask image and\n    crop the mask content in the given box.\n    The cropped mask is resized to (mask_size, mask_size).\n\n    This function is used when generating training targets for mask head in Mask R-CNN.\n    Given original ground-truth masks for an image, new ground-truth mask\n    training targets in the size of `mask_size x mask_size`\n    must be provided for each predicted box. This function will be called to\n    produce such targets.\n\n    Args:\n        polygons (list[ndarray[float]]): a list of polygons, which represents an instance.\n        box: 4-element numpy array\n        mask_size (int):\n\n    Returns:\n        Tensor: BoolTensor of shape (mask_size, mask_size)\n    \"\"\"", "\n", "# 1. Shift the polygons w.r.t the boxes", "\n", "w", ",", "h", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", ",", "box", "[", "3", "]", "-", "box", "[", "1", "]", "\n", "\n", "polygons", "=", "copy", ".", "deepcopy", "(", "polygons", ")", "\n", "for", "p", "in", "polygons", ":", "\n", "        ", "p", "[", "0", ":", ":", "2", "]", "=", "p", "[", "0", ":", ":", "2", "]", "-", "box", "[", "0", "]", "\n", "p", "[", "1", ":", ":", "2", "]", "=", "p", "[", "1", ":", ":", "2", "]", "-", "box", "[", "1", "]", "\n", "\n", "# 2. Rescale the polygons to the new box size", "\n", "# max() to avoid division by small number", "\n", "", "ratio_h", "=", "mask_size", "/", "max", "(", "h", ",", "0.1", ")", "\n", "ratio_w", "=", "mask_size", "/", "max", "(", "w", ",", "0.1", ")", "\n", "\n", "if", "ratio_h", "==", "ratio_w", ":", "\n", "        ", "for", "p", "in", "polygons", ":", "\n", "            ", "p", "*=", "ratio_h", "\n", "", "", "else", ":", "\n", "        ", "for", "p", "in", "polygons", ":", "\n", "            ", "p", "[", "0", ":", ":", "2", "]", "*=", "ratio_w", "\n", "p", "[", "1", ":", ":", "2", "]", "*=", "ratio_h", "\n", "\n", "# 3. Rasterize the polygons with coco api", "\n", "", "", "mask", "=", "polygons_to_bitmask", "(", "polygons", ",", "mask_size", ",", "mask_size", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert": [[53, 138], ["type", "isinstance", "isinstance", "torch.cat().to.double", "torch.abs", "torch.abs", "arr[].to", "type.", "torch.cat().to.numpy", "torch.tensor", "torch.from_numpy().clone", "box.clone", "torch.cos", "torch.sin", "torch.cat().to.double", "torch.zeros", "torch.cat().to", "torch.cat().to.flatten().tolist", "len", "len", "torch.from_numpy", "torch.cat", "NotImplementedError", "torch.cat().to.flatten", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["@", "staticmethod", "\n", "def", "convert", "(", "box", ":", "_RawBoxType", ",", "from_mode", ":", "\"BoxMode\"", ",", "to_mode", ":", "\"BoxMode\"", ")", "->", "_RawBoxType", ":", "\n", "        ", "\"\"\"\n        Args:\n            box: can be a k-tuple, k-list or an Nxk array/tensor, where k = 4 or 5\n            from_mode, to_mode (BoxMode)\n\n        Returns:\n            The converted box of the same type.\n        \"\"\"", "\n", "if", "from_mode", "==", "to_mode", ":", "\n", "            ", "return", "box", "\n", "\n", "", "original_type", "=", "type", "(", "box", ")", "\n", "is_numpy", "=", "isinstance", "(", "box", ",", "np", ".", "ndarray", ")", "\n", "single_box", "=", "isinstance", "(", "box", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "single_box", ":", "\n", "            ", "assert", "len", "(", "box", ")", "==", "4", "or", "len", "(", "box", ")", "==", "5", ",", "(", "\n", "\"BoxMode.convert takes either a k-tuple/list or an Nxk array/tensor,\"", "\n", "\" where k == 4 or 5\"", "\n", ")", "\n", "arr", "=", "torch", ".", "tensor", "(", "box", ")", "[", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "# avoid modifying the input box", "\n", "            ", "if", "is_numpy", ":", "\n", "                ", "arr", "=", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "box", ")", ")", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                ", "arr", "=", "box", ".", "clone", "(", ")", "\n", "\n", "", "", "assert", "to_mode", "not", "in", "[", "BoxMode", ".", "XYXY_REL", ",", "BoxMode", ".", "XYWH_REL", "]", "and", "from_mode", "not", "in", "[", "\n", "BoxMode", ".", "XYXY_REL", ",", "\n", "BoxMode", ".", "XYWH_REL", ",", "\n", "]", ",", "\"Relative mode not yet supported!\"", "\n", "\n", "if", "from_mode", "==", "BoxMode", ".", "XYWHA_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYXY_ABS", ":", "\n", "            ", "assert", "(", "\n", "arr", ".", "shape", "[", "-", "1", "]", "==", "5", "\n", ")", ",", "\"The last dimension of input shape must be 5 for XYWHA format\"", "\n", "original_dtype", "=", "arr", ".", "dtype", "\n", "arr", "=", "arr", ".", "double", "(", ")", "\n", "\n", "w", "=", "arr", "[", ":", ",", "2", "]", "\n", "h", "=", "arr", "[", ":", ",", "3", "]", "\n", "a", "=", "arr", "[", ":", ",", "4", "]", "\n", "c", "=", "torch", ".", "abs", "(", "torch", ".", "cos", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "s", "=", "torch", ".", "abs", "(", "torch", ".", "sin", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "# This basically computes the horizontal bounding rectangle of the rotated box", "\n", "new_w", "=", "c", "*", "w", "+", "s", "*", "h", "\n", "new_h", "=", "c", "*", "h", "+", "s", "*", "w", "\n", "\n", "# convert center to top-left corner", "\n", "arr", "[", ":", ",", "0", "]", "-=", "new_w", "/", "2.0", "\n", "arr", "[", ":", ",", "1", "]", "-=", "new_h", "/", "2.0", "\n", "# bottom-right corner", "\n", "arr", "[", ":", ",", "2", "]", "=", "arr", "[", ":", ",", "0", "]", "+", "new_w", "\n", "arr", "[", ":", ",", "3", "]", "=", "arr", "[", ":", ",", "1", "]", "+", "new_h", "\n", "\n", "arr", "=", "arr", "[", ":", ",", ":", "4", "]", ".", "to", "(", "dtype", "=", "original_dtype", ")", "\n", "", "elif", "from_mode", "==", "BoxMode", ".", "XYWH_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYWHA_ABS", ":", "\n", "            ", "original_dtype", "=", "arr", ".", "dtype", "\n", "arr", "=", "arr", ".", "double", "(", ")", "\n", "arr", "[", ":", ",", "0", "]", "+=", "arr", "[", ":", ",", "2", "]", "/", "2.0", "\n", "arr", "[", ":", ",", "1", "]", "+=", "arr", "[", ":", ",", "3", "]", "/", "2.0", "\n", "angles", "=", "torch", ".", "zeros", "(", "(", "arr", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "arr", ".", "dtype", ")", "\n", "arr", "=", "torch", ".", "cat", "(", "(", "arr", ",", "angles", ")", ",", "axis", "=", "1", ")", ".", "to", "(", "dtype", "=", "original_dtype", ")", "\n", "", "else", ":", "\n", "            ", "if", "to_mode", "==", "BoxMode", ".", "XYXY_ABS", "and", "from_mode", "==", "BoxMode", ".", "XYWH_ABS", ":", "\n", "                ", "arr", "[", ":", ",", "2", "]", "+=", "arr", "[", ":", ",", "0", "]", "\n", "arr", "[", ":", ",", "3", "]", "+=", "arr", "[", ":", ",", "1", "]", "\n", "", "elif", "from_mode", "==", "BoxMode", ".", "XYXY_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYWH_ABS", ":", "\n", "                ", "arr", "[", ":", ",", "2", "]", "-=", "arr", "[", ":", ",", "0", "]", "\n", "arr", "[", ":", ",", "3", "]", "-=", "arr", "[", ":", ",", "1", "]", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Conversion from BoxMode {} to {} is not supported yet\"", ".", "format", "(", "\n", "from_mode", ",", "to_mode", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "single_box", ":", "\n", "            ", "return", "original_type", "(", "arr", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "if", "is_numpy", ":", "\n", "            ", "return", "arr", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.__init__": [[152, 166], ["torch.as_tensor", "tensor.reshape().to.reshape().to.size", "isinstance", "torch.device", "tensor.reshape().to.reshape().to.numel", "tensor.reshape().to.reshape().to.reshape().to", "tensor.reshape().to.reshape().to.dim", "tensor.reshape().to.reshape().to.size", "tensor.reshape().to.reshape().to.reshape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor[float]): a Nx4 matrix.  Each row is (x1, y1, x2, y2).\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "tensor", ".", "numel", "(", ")", "==", "0", ":", "\n", "# Use reshape, so we don't end up creating a new tensor that does not depend on", "\n", "# the inputs (and consequently confuses jit)", "\n", "            ", "tensor", "=", "tensor", ".", "reshape", "(", "(", "-", "1", ",", "4", ")", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "==", "4", ",", "tensor", ".", "size", "(", ")", "\n", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone": [[167, 175], ["boxes.Boxes", "boxes.Boxes.tensor.clone"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["", "def", "clone", "(", "self", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Clone the Boxes.\n\n        Returns:\n            Boxes\n        \"\"\"", "\n", "return", "Boxes", "(", "self", ".", "tensor", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.to": [[176, 180], ["boxes.Boxes", "boxes.Boxes.tensor.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "@", "_maybe_jit_unused", "\n", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "# Boxes are assumed float32 and does not support to(dtype)", "\n", "        ", "return", "Boxes", "(", "self", ".", "tensor", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area": [[181, 191], ["None"], "methods", ["None"], ["", "def", "area", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the area of all the boxes.\n\n        Returns:\n            torch.Tensor: a vector with areas of each box.\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "area", "=", "(", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", ")", "*", "(", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", ")", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip": [[192, 207], ["torch.isfinite().all", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "torch.stack", "torch.isfinite"], "methods", ["None"], ["", "def", "clip", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clip (in place) the boxes by limiting x coordinates to the range [0, width]\n        and y coordinates to the range [0, height].\n\n        Args:\n            box_size (height, width): The clipping box's size.\n        \"\"\"", "\n", "assert", "torch", ".", "isfinite", "(", "self", ".", "tensor", ")", ".", "all", "(", ")", ",", "\"Box tensor contains infinite or NaN!\"", "\n", "h", ",", "w", "=", "box_size", "\n", "x1", "=", "self", ".", "tensor", "[", ":", ",", "0", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y1", "=", "self", ".", "tensor", "[", ":", ",", "1", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "x2", "=", "self", ".", "tensor", "[", ":", ",", "2", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y2", "=", "self", ".", "tensor", "[", ":", ",", "3", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "self", ".", "tensor", "=", "torch", ".", "stack", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty": [[208, 223], ["None"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ",", "threshold", ":", "float", "=", "0.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find boxes that are non-empty.\n        A box is considered empty, if either of its side is no larger than threshold.\n\n        Returns:\n            Tensor:\n                a binary vector which represents whether each box is empty\n                (False) or non-empty (True).\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "widths", "=", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", "\n", "heights", "=", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", "\n", "keep", "=", "(", "widths", ">", "threshold", ")", "&", "(", "heights", ">", "threshold", ")", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.__getitem__": [[224, 247], ["isinstance", "boxes.Boxes", "boxes.Boxes", "b.dim", "boxes.Boxes.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            item: int, slice, or a BoolTensor\n\n        Returns:\n            Boxes: Create a new :class:`Boxes` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_boxes = boxes[3]`: return a `Boxes` which contains only one box.\n        2. `new_boxes = boxes[2:10]`: return a slice of boxes.\n        3. `new_boxes = boxes[vector]`, where vector is a torch.BoolTensor\n           with `length = len(boxes)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned Boxes might share storage with this Boxes,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "Boxes", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "b", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "b", ".", "dim", "(", ")", "==", "2", ",", "\"Indexing on Boxes with {} failed to return a matrix!\"", ".", "format", "(", "item", ")", "\n", "return", "Boxes", "(", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.__len__": [[248, 250], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.__repr__": [[251, 253], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "\"Boxes(\"", "+", "str", "(", "self", ".", "tensor", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.inside_box": [[254, 272], ["None"], "methods", ["None"], ["", "def", "inside_box", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "boundary_threshold", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_size (height, width): Size of the reference box.\n            boundary_threshold (int): Boxes that extend beyond the reference box\n                boundary by more than boundary_threshold are considered \"outside\".\n\n        Returns:\n            a binary vector, indicating whether each box is inside the reference box.\n        \"\"\"", "\n", "height", ",", "width", "=", "box_size", "\n", "inds_inside", "=", "(", "\n", "(", "self", ".", "tensor", "[", "...", ",", "0", "]", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "1", "]", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "2", "]", "<", "width", "+", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "3", "]", "<", "height", "+", "boundary_threshold", ")", "\n", ")", "\n", "return", "inds_inside", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.get_centers": [[273, 279], ["None"], "methods", ["None"], ["", "def", "get_centers", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns:\n            The box centers in a Nx2 array of (x, y).\n        \"\"\"", "\n", "return", "(", "self", ".", "tensor", "[", ":", ",", ":", "2", "]", "+", "self", ".", "tensor", "[", ":", ",", "2", ":", "]", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.scale": [[280, 286], ["None"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "scale_x", ":", "float", ",", "scale_y", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Scale the box with horizontal and vertical scaling factors\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "self", ".", "tensor", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.cat": [[287, 307], ["isinstance", "all", "cls", "len", "cls", "torch.cat", "torch.empty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "@", "classmethod", "\n", "@", "_maybe_jit_unused", "\n", "def", "cat", "(", "cls", ",", "boxes_list", ":", "List", "[", "\"Boxes\"", "]", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of Boxes into a single Boxes\n\n        Arguments:\n            boxes_list (list[Boxes])\n\n        Returns:\n            Boxes: the concatenated Boxes\n        \"\"\"", "\n", "assert", "isinstance", "(", "boxes_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "boxes_list", ")", "==", "0", ":", "\n", "            ", "return", "cls", "(", "torch", ".", "empty", "(", "0", ")", ")", "\n", "", "assert", "all", "(", "[", "isinstance", "(", "box", ",", "Boxes", ")", "for", "box", "in", "boxes_list", "]", ")", "\n", "\n", "# use torch.cat (v.s. layers.cat) so the returned boxes never share storage with input", "\n", "cat_boxes", "=", "cls", "(", "torch", ".", "cat", "(", "[", "b", ".", "tensor", "for", "b", "in", "boxes_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device": [[308, 311], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.__iter__": [[314, 320], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Yield a box as a Tensor of shape (4,) at a time.\n        \"\"\"", "\n", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_intersection": [[322, 342], ["width_height.clamp_", "width_height.prod", "torch.min", "torch.max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "", "def", "pairwise_intersection", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given two lists of boxes of size N and M,\n    compute the intersection area between __all__ N x M pairs of boxes.\n    The box order must be (xmin, ymin, xmax, ymax)\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: intersection, sized [N,M].\n    \"\"\"", "\n", "boxes1", ",", "boxes2", "=", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", "\n", "width_height", "=", "torch", ".", "min", "(", "boxes1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "boxes2", "[", ":", ",", "2", ":", "]", ")", "-", "torch", ".", "max", "(", "\n", "boxes1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "boxes2", "[", ":", ",", ":", "2", "]", "\n", ")", "# [N,M,2]", "\n", "\n", "width_height", ".", "clamp_", "(", "min", "=", "0", ")", "# [N,M,2]", "\n", "intersection", "=", "width_height", ".", "prod", "(", "dim", "=", "2", ")", "# [N,M]", "\n", "return", "intersection", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou": [[346, 369], ["boxes1.area", "boxes2.area", "boxes.pairwise_intersection", "torch.where", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_intersection"], ["", "def", "pairwise_iou", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given two lists of boxes of size N and M, compute the IoU\n    (intersection over union) between **all** N x M pairs of boxes.\n    The box order must be (xmin, ymin, xmax, ymax).\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: IoU, sized [N,M].\n    \"\"\"", "\n", "area1", "=", "boxes1", ".", "area", "(", ")", "# [N]", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [M]", "\n", "inter", "=", "pairwise_intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "\n", "# handle empty boxes", "\n", "iou", "=", "torch", ".", "where", "(", "\n", "inter", ">", "0", ",", "\n", "inter", "/", "(", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", ")", ",", "\n", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "inter", ".", "dtype", ",", "device", "=", "inter", ".", "device", ")", ",", "\n", ")", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_ioa": [[371, 389], ["boxes2.area", "boxes.pairwise_intersection", "torch.where", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_intersection"], ["", "def", "pairwise_ioa", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to :func:`pariwise_iou` but compute the IoA (intersection over boxes2 area).\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: IoA, sized [N,M].\n    \"\"\"", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [M]", "\n", "inter", "=", "pairwise_intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "\n", "# handle empty boxes", "\n", "ioa", "=", "torch", ".", "where", "(", "\n", "inter", ">", "0", ",", "inter", "/", "area2", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "inter", ".", "dtype", ",", "device", "=", "inter", ".", "device", ")", "\n", ")", "\n", "return", "ioa", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.matched_boxlist_iou": [[391, 417], ["boxes1.area", "boxes2.area", "torch.max", "torch.min", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "matched_boxlist_iou", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Compute pairwise intersection over union (IOU) of two sets of matched\n    boxes. The box order must be (xmin, ymin, xmax, ymax).\n    Similar to boxlist_iou, but computes only diagonal elements of the matrix\n\n    Args:\n        boxes1: (Boxes) bounding boxes, sized [N,4].\n        boxes2: (Boxes) bounding boxes, sized [N,4].\n    Returns:\n        Tensor: iou, sized [N].\n    \"\"\"", "\n", "assert", "len", "(", "boxes1", ")", "==", "len", "(", "\n", "boxes2", "\n", ")", ",", "\"boxlists should have the same\"", "\"number of entries, got {}, {}\"", ".", "format", "(", "\n", "len", "(", "boxes1", ")", ",", "len", "(", "boxes2", ")", "\n", ")", "\n", "area1", "=", "boxes1", ".", "area", "(", ")", "# [N]", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [N]", "\n", "box1", ",", "box2", "=", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", "\n", "lt", "=", "torch", ".", "max", "(", "box1", "[", ":", ",", ":", "2", "]", ",", "box2", "[", ":", ",", ":", "2", "]", ")", "# [N,2]", "\n", "rb", "=", "torch", ".", "min", "(", "box1", "[", ":", ",", "2", ":", "]", ",", "box2", "[", ":", ",", "2", ":", "]", ")", "# [N,2]", "\n", "wh", "=", "(", "rb", "-", "lt", ")", ".", "clamp", "(", "min", "=", "0", ")", "# [N,2]", "\n", "inter", "=", "wh", "[", ":", ",", "0", "]", "*", "wh", "[", ":", ",", "1", "]", "# [N]", "\n", "iou", "=", "inter", "/", "(", "area1", "+", "area2", "-", "inter", ")", "# [N]", "\n", "return", "iou", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode._open_cfg": [[24, 27], ["detectron2.utils.file_io.PathManager.open"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.merge_from_file": [[29, 71], ["detectron2.utils.file_io.PathManager.isfile", "config.CfgNode.load_yaml_with_base", "logging.getLogger", "config.CfgNode.get", "type", "guess_version", "config.CfgNode.merge_from_other_cfg", "logging.getLogger.warning", "downgrade_config", "downgrade_config.merge_from_other_cfg", "upgrade_config", "config.CfgNode.clear", "config.CfgNode.update"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.guess_version", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.downgrade_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.upgrade_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n", "\n", "if", "loaded_ver", "==", "self", ".", "VERSION", ":", "\n", "            ", "self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "", "else", ":", "\n", "# compat.py needs to import CfgNode", "\n", "            ", "from", ".", "compat", "import", "upgrade_config", ",", "downgrade_config", "\n", "\n", "logger", ".", "warning", "(", "\n", "\"Loading an old v{} config file '{}' by automatically upgrading to v{}. \"", "\n", "\"See docs/CHANGELOG.md for instructions to update your files.\"", ".", "format", "(", "\n", "loaded_ver", ",", "cfg_filename", ",", "self", ".", "VERSION", "\n", ")", "\n", ")", "\n", "# To convert, first obtain a full config at an old version", "\n", "old_self", "=", "downgrade_config", "(", "self", ",", "to_version", "=", "loaded_ver", ")", "\n", "old_self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "new_config", "=", "upgrade_config", "(", "old_self", ")", "\n", "self", ".", "clear", "(", ")", "\n", "self", ".", "update", "(", "new_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump": [[72, 79], ["super().dump"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump"], ["", "", "def", "dump", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            str: a yaml string representation of the config\n        \"\"\"", "\n", "# to make it show up in docs", "\n", "return", "super", "(", ")", ".", "dump", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.get_cfg": [[84, 94], ["_C.clone"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["def", "get_cfg", "(", ")", "->", "CfgNode", ":", "\n", "    ", "\"\"\"\n    Get a copy of the default config.\n\n    Returns:\n        a detectron2 CfgNode instance.\n    \"\"\"", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "return", "_C", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.set_global_cfg": [[96, 113], ["global_cfg.clear", "global_cfg.update"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "set_global_cfg", "(", "cfg", ":", "CfgNode", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Let the global config point to the given cfg.\n\n    Assume that the given \"cfg\" has the key \"KEY\", after calling\n    `set_global_cfg(cfg)`, the key can be accessed by:\n    ::\n        from detectron2.config import global_cfg\n        print(global_cfg.KEY)\n\n    By using a hacky global config, you can access these configs anywhere,\n    without having to pass the config object or the values deep into the code.\n    This is a hacky feature introduced for quick prototyping / research exploration.\n    \"\"\"", "\n", "global", "global_cfg", "\n", "global_cfg", ".", "clear", "(", ")", "\n", "global_cfg", ".", "update", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.configurable": [[115, 200], ["functools.wraps", "inspect.isfunction", "inspect.isfunction", "config._called_with_cfg", "functools.wraps", "inspect.ismethod", "TypeError", "config._get_args_from_config", "init_func", "init_func", "config._called_with_cfg", "type", "AttributeError", "config._get_args_from_config", "orig_func", "orig_func"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._called_with_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._get_args_from_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._called_with_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._get_args_from_config"], ["", "def", "configurable", "(", "init_func", "=", "None", ",", "*", ",", "from_config", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Decorate a function or a class's __init__ method so that it can be called\n    with a :class:`CfgNode` object using a :func:`from_config` function that translates\n    :class:`CfgNode` to arguments.\n\n    Examples:\n    ::\n        # Usage 1: Decorator on __init__:\n        class A:\n            @configurable\n            def __init__(self, a, b=2, c=3):\n                pass\n\n            @classmethod\n            def from_config(cls, cfg):   # 'cfg' must be the first argument\n                # Returns kwargs to be passed to __init__\n                return {\"a\": cfg.A, \"b\": cfg.B}\n\n        a1 = A(a=1, b=2)  # regular construction\n        a2 = A(cfg)       # construct with a cfg\n        a3 = A(cfg, b=3, c=4)  # construct with extra overwrite\n\n        # Usage 2: Decorator on any function. Needs an extra from_config argument:\n        @configurable(from_config=lambda cfg: {\"a: cfg.A, \"b\": cfg.B})\n        def a_func(a, b=2, c=3):\n            pass\n\n        a1 = a_func(a=1, b=2)  # regular call\n        a2 = a_func(cfg)       # call with a cfg\n        a3 = a_func(cfg, b=3, c=4)  # call with extra overwrite\n\n    Args:\n        init_func (callable): a class's ``__init__`` method in usage 1. The\n            class must have a ``from_config`` classmethod which takes `cfg` as\n            the first argument.\n        from_config (callable): the from_config function in usage 2. It must take `cfg`\n            as its first argument.\n    \"\"\"", "\n", "\n", "if", "init_func", "is", "not", "None", ":", "\n", "        ", "assert", "(", "\n", "inspect", ".", "isfunction", "(", "init_func", ")", "\n", "and", "from_config", "is", "None", "\n", "and", "init_func", ".", "__name__", "==", "\"__init__\"", "\n", ")", ",", "\"Incorrect use of @configurable. Check API documentation for examples.\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "init_func", ")", "\n", "def", "wrapped", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "from_config_func", "=", "type", "(", "self", ")", ".", "from_config", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "                ", "raise", "AttributeError", "(", "\n", "\"Class with @configurable must have a 'from_config' classmethod.\"", "\n", ")", "from", "e", "\n", "", "if", "not", "inspect", ".", "ismethod", "(", "from_config_func", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"Class with @configurable must have a 'from_config' classmethod.\"", ")", "\n", "\n", "", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "explicit_args", "=", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "init_func", "(", "self", ",", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                ", "init_func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "else", ":", "\n", "        ", "if", "from_config", "is", "None", ":", "\n", "            ", "return", "configurable", "# @configurable() is made equivalent to @configurable", "\n", "", "assert", "inspect", ".", "isfunction", "(", "\n", "from_config", "\n", ")", ",", "\"from_config argument of configurable must be a function!\"", "\n", "\n", "def", "wrapper", "(", "orig_func", ")", ":", "\n", "            ", "@", "functools", ".", "wraps", "(", "orig_func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                    ", "explicit_args", "=", "_get_args_from_config", "(", "from_config", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "orig_func", "(", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                    ", "return", "orig_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._get_args_from_config": [[202, 233], ["inspect.signature", "any", "inspect.isfunction", "TypeError", "from_config_func", "set", "list", "from_config_func", "from_config_func.update", "list", "inspect.signature.parameters.keys", "kwargs.keys", "inspect.signature.parameters.keys", "inspect.signature.parameters.values", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Use `from_config` to obtain explicit arguments.\n\n    Returns:\n        dict: arguments to be used for cls.__init__\n    \"\"\"", "\n", "signature", "=", "inspect", ".", "signature", "(", "from_config_func", ")", "\n", "if", "list", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"cfg\"", ":", "\n", "        ", "if", "inspect", ".", "isfunction", "(", "from_config_func", ")", ":", "\n", "            ", "name", "=", "from_config_func", ".", "__name__", "\n", "", "else", ":", "\n", "            ", "name", "=", "f\"{from_config_func.__self__}.from_config\"", "\n", "", "raise", "TypeError", "(", "f\"{name} must take 'cfg' as the first argument!\"", ")", "\n", "", "support_var_arg", "=", "any", "(", "\n", "param", ".", "kind", "in", "[", "param", ".", "VAR_POSITIONAL", ",", "param", ".", "VAR_KEYWORD", "]", "\n", "for", "param", "in", "signature", ".", "parameters", ".", "values", "(", ")", "\n", ")", "\n", "if", "support_var_arg", ":", "# forward all arguments to from_config, if from_config accepts them", "\n", "        ", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# forward supported arguments to from_config", "\n", "        ", "supported_arg_names", "=", "set", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "\n", "extra_kwargs", "=", "{", "}", "\n", "for", "name", "in", "list", "(", "kwargs", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "name", "not", "in", "supported_arg_names", ":", "\n", "                ", "extra_kwargs", "[", "name", "]", "=", "kwargs", ".", "pop", "(", "name", ")", "\n", "", "", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# forward the other arguments to __init__", "\n", "ret", ".", "update", "(", "extra_kwargs", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config._called_with_cfg": [[235, 250], ["isinstance", "len", "isinstance", "kwargs.pop"], "function", ["None"], ["", "def", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        bool: whether the arguments contain CfgNode and should be considered\n            forwarded to from_config.\n    \"\"\"", "\n", "from", "omegaconf", "import", "DictConfig", "\n", "\n", "if", "len", "(", "args", ")", "and", "isinstance", "(", "args", "[", "0", "]", ",", "(", "_CfgNode", ",", "DictConfig", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "if", "isinstance", "(", "kwargs", ".", "pop", "(", "\"cfg\"", ",", "None", ")", ",", "(", "_CfgNode", ",", "DictConfig", ")", ")", ":", "\n", "        ", "return", "True", "\n", "# `from_config`'s first argument is forced to be \"cfg\".", "\n", "# So the above check covers all cases.", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.LazyCall.__init__": [[101, 107], ["TypeError", "callable", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "target", ")", ":", "\n", "        ", "if", "not", "(", "callable", "(", "target", ")", "or", "isinstance", "(", "target", ",", "(", "str", ",", "abc", ".", "Mapping", ")", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"target of LazyCall must be a callable or defines a callable! Got {target}\"", "\n", ")", "\n", "", "self", ".", "_target", "=", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.LazyCall.__call__": [[108, 111], ["omegaconf.DictConfig"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", "[", "\"_target_\"", "]", "=", "self", ".", "_target", "\n", "return", "DictConfig", "(", "content", "=", "kwargs", ",", "flags", "=", "{", "\"allow_objects\"", ":", "True", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.dump_dataclass": [[13, 35], ["dataclasses.fields", "dataclasses.is_dataclass", "detectron2.utils.registry._convert_target_to_string", "getattr", "dataclasses.is_dataclass", "isinstance", "isinstance", "type", "instantiate.dump_dataclass", "dataclasses.is_dataclass", "instantiate.dump_dataclass"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry._convert_target_to_string", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.dump_dataclass", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.dump_dataclass"], ["def", "dump_dataclass", "(", "obj", ":", "Any", ")", ":", "\n", "    ", "\"\"\"\n    Dump a dataclass recursively into a dict that can be later instantiated.\n\n    Args:\n        obj: a dataclass object\n\n    Returns:\n        dict\n    \"\"\"", "\n", "assert", "dataclasses", ".", "is_dataclass", "(", "obj", ")", "and", "not", "isinstance", "(", "\n", "obj", ",", "type", "\n", ")", ",", "\"dump_dataclass() requires an instance of a dataclass.\"", "\n", "ret", "=", "{", "\"_target_\"", ":", "_convert_target_to_string", "(", "type", "(", "obj", ")", ")", "}", "\n", "for", "f", "in", "dataclasses", ".", "fields", "(", "obj", ")", ":", "\n", "        ", "v", "=", "getattr", "(", "obj", ",", "f", ".", "name", ")", "\n", "if", "dataclasses", ".", "is_dataclass", "(", "v", ")", ":", "\n", "            ", "v", "=", "dump_dataclass", "(", "v", ")", "\n", "", "if", "isinstance", "(", "v", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "v", "=", "[", "dump_dataclass", "(", "x", ")", "if", "dataclasses", ".", "is_dataclass", "(", "x", ")", "else", "x", "for", "x", "in", "v", "]", "\n", "", "ret", "[", "f", ".", "name", "]", "=", "v", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.instantiate": [[37, 84], ["isinstance", "isinstance", "ListConfig", "isinstance", "cfg.pop", "instantiate.instantiate", "isinstance", "callable", "instantiate.instantiate", "instantiate.instantiate", "instantiate.instantiate", "detectron2.utils.registry.locate", "detectron2.utils.registry.locate.", "cfg.items", "logging.getLogger", "logging.getLogger.error", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.instantiate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.instantiate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.instantiate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.instantiate.instantiate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry.locate"], ["", "def", "instantiate", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Recursively instantiate objects defined in dictionaries by\n    \"_target_\" and arguments.\n\n    Args:\n        cfg: a dict-like object with \"_target_\" that defines the caller, and\n            other keys that define the arguments\n\n    Returns:\n        object instantiated by cfg\n    \"\"\"", "\n", "from", "omegaconf", "import", "ListConfig", "\n", "\n", "if", "isinstance", "(", "cfg", ",", "ListConfig", ")", ":", "\n", "        ", "lst", "=", "[", "instantiate", "(", "x", ")", "for", "x", "in", "cfg", "]", "\n", "return", "ListConfig", "(", "lst", ",", "flags", "=", "{", "\"allow_objects\"", ":", "True", "}", ")", "\n", "", "if", "isinstance", "(", "cfg", ",", "list", ")", ":", "\n", "# Specialize for list, because many classes take", "\n", "# list[objects] as arguments, such as ResNet, DatasetMapper", "\n", "        ", "return", "[", "instantiate", "(", "x", ")", "for", "x", "in", "cfg", "]", "\n", "\n", "", "if", "isinstance", "(", "cfg", ",", "abc", ".", "Mapping", ")", "and", "\"_target_\"", "in", "cfg", ":", "\n", "# conceptually equivalent to hydra.utils.instantiate(cfg) with _convert_=all,", "\n", "# but faster: https://github.com/facebookresearch/hydra/issues/1200", "\n", "        ", "cfg", "=", "{", "k", ":", "instantiate", "(", "v", ")", "for", "k", ",", "v", "in", "cfg", ".", "items", "(", ")", "}", "\n", "cls", "=", "cfg", ".", "pop", "(", "\"_target_\"", ")", "\n", "cls", "=", "instantiate", "(", "cls", ")", "\n", "\n", "if", "isinstance", "(", "cls", ",", "str", ")", ":", "\n", "            ", "cls_name", "=", "cls", "\n", "cls", "=", "locate", "(", "cls_name", ")", "\n", "assert", "cls", "is", "not", "None", ",", "cls_name", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "cls_name", "=", "cls", ".", "__module__", "+", "\".\"", "+", "cls", ".", "__qualname__", "\n", "", "except", "AttributeError", ":", "\n", "# target could be anything, so the above could fail", "\n", "                ", "cls_name", "=", "str", "(", "cls", ")", "\n", "", "", "assert", "callable", "(", "cls", ")", ",", "f\"_target_ {cls} does not define a callable object\"", "\n", "try", ":", "\n", "            ", "return", "cls", "(", "**", "cfg", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "f\"Error when instantiating {cls_name}!\"", ")", "\n", "raise", "\n", "", "", "return", "cfg", "# return as-is if don't know what to do", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._RenameConverter.upgrade": [[153, 157], ["compat._rename"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename"], ["@", "classmethod", "\n", "def", "upgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "for", "old", ",", "new", "in", "cls", ".", "RENAME", ":", "\n", "            ", "_rename", "(", "cfg", ",", "old", ",", "new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._RenameConverter.downgrade": [[158, 162], ["compat._rename"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename"], ["", "", "@", "classmethod", "\n", "def", "downgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "for", "old", ",", "new", "in", "cls", ".", "RENAME", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "_rename", "(", "cfg", ",", "new", ",", "old", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.upgrade": [[203, 220], ["compat._RenameConverter.upgrade", "compat._rename", "compat._rename", "compat._rename", "compat._rename"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.upgrade", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename"], ["@", "classmethod", "\n", "def", "upgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "upgrade", "(", "cfg", ")", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "==", "\"RetinaNet\"", ":", "\n", "            ", "_rename", "(", "\n", "cfg", ",", "\"MODEL.RETINANET.ANCHOR_ASPECT_RATIOS\"", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", "\n", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.RETINANET.ANCHOR_SIZES\"", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ")", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RPN\"", "]", "[", "\"ANCHOR_SIZES\"", "]", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RPN\"", "]", "[", "\"ANCHOR_ASPECT_RATIOS\"", "]", "\n", "", "else", ":", "\n", "            ", "_rename", "(", "cfg", ",", "\"MODEL.RPN.ANCHOR_ASPECT_RATIOS\"", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.RPN.ANCHOR_SIZES\"", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ")", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_SIZES\"", "]", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_ASPECT_RATIOS\"", "]", "\n", "", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_STRIDES\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.downgrade": [[221, 230], ["compat._RenameConverter.downgrade", "compat._rename", "compat._rename"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.downgrade", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename"], ["", "@", "classmethod", "\n", "def", "downgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "downgrade", "(", "cfg", ")", "\n", "\n", "_rename", "(", "cfg", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", ",", "\"MODEL.RPN.ANCHOR_ASPECT_RATIOS\"", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ",", "\"MODEL.RPN.ANCHOR_SIZES\"", ")", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_ASPECT_RATIOS", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_ASPECT_RATIOS", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_SIZES", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_SIZES", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_STRIDES", "=", "[", "]", "# this is not used anywhere in any version", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.upgrade_config": [[33, 53], ["cfg.clone.clone", "range", "converter.upgrade", "globals", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.upgrade"], ["def", "upgrade_config", "(", "cfg", ":", "CN", ",", "to_version", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "CN", ":", "\n", "    ", "\"\"\"\n    Upgrade a config from its current version to a newer version.\n\n    Args:\n        cfg (CfgNode):\n        to_version (int): defaults to the latest version.\n    \"\"\"", "\n", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "if", "to_version", "is", "None", ":", "\n", "        ", "to_version", "=", "_C", ".", "VERSION", "\n", "\n", "", "assert", "cfg", ".", "VERSION", "<=", "to_version", ",", "\"Cannot upgrade from v{} to v{}!\"", ".", "format", "(", "\n", "cfg", ".", "VERSION", ",", "to_version", "\n", ")", "\n", "for", "k", "in", "range", "(", "cfg", ".", "VERSION", ",", "to_version", ")", ":", "\n", "        ", "converter", "=", "globals", "(", ")", "[", "\"ConverterV\"", "+", "str", "(", "k", "+", "1", ")", "]", "\n", "converter", ".", "upgrade", "(", "cfg", ")", "\n", "cfg", ".", "VERSION", "=", "k", "+", "1", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.downgrade_config": [[55, 80], ["cfg.clone.clone", "range", "converter.downgrade", "globals", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.ConverterV2.downgrade"], ["", "def", "downgrade_config", "(", "cfg", ":", "CN", ",", "to_version", ":", "int", ")", "->", "CN", ":", "\n", "    ", "\"\"\"\n    Downgrade a config from its current version to an older version.\n\n    Args:\n        cfg (CfgNode):\n        to_version (int):\n\n    Note:\n        A general downgrade of arbitrary configs is not always possible due to the\n        different functionalities in different versions.\n        The purpose of downgrade is only to recover the defaults in old versions,\n        allowing it to load an old partial yaml config.\n        Therefore, the implementation only needs to fill in the default values\n        in the old version when a general downgrade is not possible.\n    \"\"\"", "\n", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "cfg", ".", "VERSION", ">=", "to_version", ",", "\"Cannot downgrade from v{} to v{}!\"", ".", "format", "(", "\n", "cfg", ".", "VERSION", ",", "to_version", "\n", ")", "\n", "for", "k", "in", "range", "(", "cfg", ".", "VERSION", ",", "to_version", ",", "-", "1", ")", ":", "\n", "        ", "converter", "=", "globals", "(", ")", "[", "\"ConverterV\"", "+", "str", "(", "k", ")", "]", "\n", "converter", ".", "downgrade", "(", "cfg", ")", "\n", "cfg", ".", "VERSION", "=", "k", "-", "1", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat.guess_version": [[82, 114], ["logging.getLogger", "name.split", "compat.guess_version._has"], "function", ["None"], ["", "def", "guess_version", "(", "cfg", ":", "CN", ",", "filename", ":", "str", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Guess the version of a partial config where the VERSION field is not specified.\n    Returns the version, or the latest if cannot make a guess.\n\n    This makes it easier for users to migrate.\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "def", "_has", "(", "name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "n", "in", "name", ".", "split", "(", "\".\"", ")", ":", "\n", "            ", "if", "n", "not", "in", "cur", ":", "\n", "                ", "return", "False", "\n", "", "cur", "=", "cur", "[", "n", "]", "\n", "", "return", "True", "\n", "\n", "# Most users' partial configs have \"MODEL.WEIGHT\", so guess on it", "\n", "", "ret", "=", "None", "\n", "if", "_has", "(", "\"MODEL.WEIGHT\"", ")", "or", "_has", "(", "\"TEST.AUG_ON\"", ")", ":", "\n", "        ", "ret", "=", "1", "\n", "\n", "", "if", "ret", "is", "not", "None", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Config '{}' has no VERSION. Assuming it to be v{}.\"", ".", "format", "(", "filename", ",", "ret", ")", ")", "\n", "", "else", ":", "\n", "        ", "ret", "=", "_C", ".", "VERSION", "\n", "logger", ".", "warning", "(", "\n", "\"Config '{}' has no VERSION. Assuming it to be compatible with latest v{}.\"", ".", "format", "(", "\n", "filename", ",", "ret", "\n", ")", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.compat._rename": [[116, 144], ["old.split", "new.split", "compat._rename._set"], "function", ["None"], ["", "def", "_rename", "(", "cfg", ":", "CN", ",", "old", ":", "str", ",", "new", ":", "str", ")", "->", "None", ":", "\n", "    ", "old_keys", "=", "old", ".", "split", "(", "\".\"", ")", "\n", "new_keys", "=", "new", ".", "split", "(", "\".\"", ")", "\n", "\n", "def", "_set", "(", "key_seq", ":", "List", "[", "str", "]", ",", "val", ":", "str", ")", "->", "None", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", "[", ":", "-", "1", "]", ":", "\n", "            ", "if", "k", "not", "in", "cur", ":", "\n", "                ", "cur", "[", "k", "]", "=", "CN", "(", ")", "\n", "", "cur", "=", "cur", "[", "k", "]", "\n", "", "cur", "[", "key_seq", "[", "-", "1", "]", "]", "=", "val", "\n", "\n", "", "def", "_get", "(", "key_seq", ":", "List", "[", "str", "]", ")", "->", "CN", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", ":", "\n", "            ", "cur", "=", "cur", "[", "k", "]", "\n", "", "return", "cur", "\n", "\n", "", "def", "_del", "(", "key_seq", ":", "List", "[", "str", "]", ")", "->", "None", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", "[", ":", "-", "1", "]", ":", "\n", "            ", "cur", "=", "cur", "[", "k", "]", "\n", "", "del", "cur", "[", "key_seq", "[", "-", "1", "]", "]", "\n", "if", "len", "(", "cur", ")", "==", "0", "and", "len", "(", "key_seq", ")", ">", "1", ":", "\n", "            ", "_del", "(", "key_seq", "[", ":", "-", "1", "]", ")", "\n", "\n", "", "", "_set", "(", "new_keys", ",", "_get", "(", "old_keys", ")", ")", "\n", "_del", "(", "old_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers._NewEmptyTensorOp.forward": [[37, 41], ["x.new_empty"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers._NewEmptyTensorOp.backward": [[42, 46], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.Conv2d.__init__": [[53, 69], ["kwargs.pop", "kwargs.pop", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Extra keyword arguments supported in addition to those in `torch.nn.Conv2d`:\n\n        Args:\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n\n        It assumes that norm layer is used before activation.\n        \"\"\"", "\n", "norm", "=", "kwargs", ".", "pop", "(", "\"norm\"", ",", "None", ")", "\n", "activation", "=", "kwargs", ".", "pop", "(", "\"activation\"", ",", "None", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.Conv2d.forward": [[70, 92], ["torch.nn.functional.conv2d", "torch.jit.is_scripting", "wrappers.Conv2d.norm", "wrappers.Conv2d.activation", "wrappers.Conv2d.numel", "isinstance"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# torchscript does not support SyncBatchNorm yet", "\n", "# https://github.com/pytorch/pytorch/issues/40507", "\n", "# and we skip these codes in torchscript since:", "\n", "# 1. currently we only support torchscript in evaluation mode", "\n", "# 2. features needed by exporting module to torchscript are added in PyTorch 1.6 or", "\n", "# later version, `Conv2d` in these PyTorch versions has already supported empty inputs.", "\n", "        ", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "if", "x", ".", "numel", "(", ")", "==", "0", "and", "self", ".", "training", ":", "\n", "# https://github.com/pytorch/pytorch/issues/12013", "\n", "                ", "assert", "not", "isinstance", "(", "\n", "self", ".", "norm", ",", "torch", ".", "nn", ".", "SyncBatchNorm", "\n", ")", ",", "\"SyncBatchNorm does not support empty inputs!\"", "\n", "\n", "", "", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat": [[16, 24], ["isinstance", "torch.cat", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["def", "cat", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "dim", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy": [[26, 34], ["torch.nn.functional.cross_entropy", "target.numel", "input.sum"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cross_entropy"], ["", "def", "cross_entropy", "(", "input", ",", "target", ",", "*", ",", "reduction", "=", "\"mean\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Same as `torch.nn.functional.cross_entropy`, but returns 0 (instead of nan)\n    for empty inputs.\n    \"\"\"", "\n", "if", "target", ".", "numel", "(", ")", "==", "0", "and", "reduction", "==", "\"mean\"", ":", "\n", "        ", "return", "input", ".", "sum", "(", ")", "*", "0.0", "# connect the gradient", "\n", "", "return", "F", ".", "cross_entropy", "(", "input", ",", "target", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.nonzero_tuple": [[100, 111], ["torch.jit.is_scripting", "x.nonzero().unbind", "x.nonzero", "x.dim", "x.unsqueeze().nonzero().unbind", "x.nonzero", "x.unsqueeze().nonzero", "x.unsqueeze"], "function", ["None"], ["def", "nonzero_tuple", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    A 'as_tuple=True' version of torch.nonzero to support torchscript.\n    because of https://github.com/pytorch/pytorch/issues/38718\n    \"\"\"", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "return", "x", ".", "unsqueeze", "(", "0", ")", ".", "nonzero", "(", ")", ".", "unbind", "(", "1", ")", "\n", "", "return", "x", ".", "nonzero", "(", ")", ".", "unbind", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms": [[19, 40], ["scores.new_zeros", "torch.jit.annotate", "scores.new_zeros.nonzero().view", "len", "torchvision.ops.boxes.batched_nms", "scores.size", "torch.unique().cpu().tolist", "torchvision.ops.nms", "torchvision.ops.boxes.float", "scores.new_zeros.nonzero", "scores[].argsort", "torch.unique().cpu", "torch.unique"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms"], ["", "def", "batched_nms", "(", "\n", "boxes", ":", "torch", ".", "Tensor", ",", "scores", ":", "torch", ".", "Tensor", ",", "idxs", ":", "torch", ".", "Tensor", ",", "iou_threshold", ":", "float", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Same as torchvision.ops.boxes.batched_nms, but safer.\n    \"\"\"", "\n", "assert", "boxes", ".", "shape", "[", "-", "1", "]", "==", "4", "\n", "# TODO may need better strategy.", "\n", "# Investigate after having a fully-cuda NMS op.", "\n", "if", "len", "(", "boxes", ")", "<", "40000", ":", "\n", "# fp16 does not have enough range for batched NMS", "\n", "        ", "return", "box_ops", ".", "batched_nms", "(", "boxes", ".", "float", "(", ")", ",", "scores", ",", "idxs", ",", "iou_threshold", ")", "\n", "\n", "", "result_mask", "=", "scores", ".", "new_zeros", "(", "scores", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "for", "id", "in", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "torch", ".", "unique", "(", "idxs", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "mask", "=", "(", "idxs", "==", "id", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "keep", "=", "nms", "(", "boxes", "[", "mask", "]", ",", "scores", "[", "mask", "]", ",", "iou_threshold", ")", "\n", "result_mask", "[", "mask", "[", "keep", "]", "]", "=", "True", "\n", "", "keep", "=", "result_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "keep", "=", "keep", "[", "scores", "[", "keep", "]", ".", "argsort", "(", "descending", "=", "True", ")", "]", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.nms_rotated": [[44, 106], ["nms_rotated_func"], "function", ["None"], ["", "def", "nms_rotated", "(", "boxes", ",", "scores", ",", "iou_threshold", ")", ":", "\n", "    ", "\"\"\"\n    Performs non-maximum suppression (NMS) on the rotated boxes according\n    to their intersection-over-union (IoU).\n\n    Rotated NMS iteratively removes lower scoring rotated boxes which have an\n    IoU greater than iou_threshold with another (higher scoring) rotated box.\n\n    Note that RotatedBox (5, 3, 4, 2, -90) covers exactly the same region as\n    RotatedBox (5, 3, 4, 2, 90) does, and their IoU will be 1. However, they\n    can be representing completely different objects in certain tasks, e.g., OCR.\n\n    As for the question of whether rotated-NMS should treat them as faraway boxes\n    even though their IOU is 1, it depends on the application and/or ground truth annotation.\n\n    As an extreme example, consider a single character v and the square box around it.\n\n    If the angle is 0 degree, the object (text) would be read as 'v';\n\n    If the angle is 90 degrees, the object (text) would become '>';\n\n    If the angle is 180 degrees, the object (text) would become '^';\n\n    If the angle is 270/-90 degrees, the object (text) would become '<'\n\n    All of these cases have IoU of 1 to each other, and rotated NMS that only\n    uses IoU as criterion would only keep one of them with the highest score -\n    which, practically, still makes sense in most cases because typically\n    only one of theses orientations is the correct one. Also, it does not matter\n    as much if the box is only used to classify the object (instead of transcribing\n    them with a sequential OCR recognition model) later.\n\n    On the other hand, when we use IoU to filter proposals that are close to the\n    ground truth during training, we should definitely take the angle into account if\n    we know the ground truth is labeled with the strictly correct orientation (as in,\n    upside-down words are annotated with -180 degrees even though they can be covered\n    with a 0/90/-90 degree box, etc.)\n\n    The way the original dataset is annotated also matters. For example, if the dataset\n    is a 4-point polygon dataset that does not enforce ordering of vertices/orientation,\n    we can estimate a minimum rotated bounding box to this polygon, but there's no way\n    we can tell the correct angle with 100% confidence (as shown above, there could be 4 different\n    rotated boxes, with angles differed by 90 degrees to each other, covering the exactly\n    same region). In that case we have to just use IoU to determine the box\n    proximity (as many detection benchmarks (even for text) do) unless there're other\n    assumptions we can make (like width is always larger than height, or the object is not\n    rotated by more than 90 degrees CCW/CW, etc.)\n\n    In summary, not considering angles in rotated NMS seems to be a good option for now,\n    but we should be aware of its implications.\n\n    Args:\n        boxes (Tensor[N, 5]): Rotated boxes to perform NMS on. They are expected to be in\n           (x_center, y_center, width, height, angle_degrees) format.\n        scores (Tensor[N]): Scores for each one of the rotated boxes\n        iou_threshold (float): Discards all overlapping rotated boxes with IoU < iou_threshold\n\n    Returns:\n        keep (Tensor): int64 tensor with the indices of the elements that have been kept\n        by Rotated NMS, sorted in decreasing order of scores\n    \"\"\"", "\n", "return", "nms_rotated_func", "(", "boxes", ",", "scores", ",", "iou_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.batched_nms_rotated": [[110, 159], ["boxes.float.float", "boxes.float.clone", "nms.nms_rotated", "boxes.float.numel", "torch.empty", "idxs.to", "torch.max", "torch.min", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.nms.nms_rotated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "batched_nms_rotated", "(", "boxes", ",", "scores", ",", "idxs", ",", "iou_threshold", ")", ":", "\n", "    ", "\"\"\"\n    Performs non-maximum suppression in a batched fashion.\n\n    Each index value correspond to a category, and NMS\n    will not be applied between elements of different categories.\n\n    Args:\n        boxes (Tensor[N, 5]):\n           boxes where NMS will be performed. They\n           are expected to be in (x_ctr, y_ctr, width, height, angle_degrees) format\n        scores (Tensor[N]):\n           scores for each one of the boxes\n        idxs (Tensor[N]):\n           indices of the categories for each one of the boxes.\n        iou_threshold (float):\n           discards all overlapping boxes\n           with IoU < iou_threshold\n\n    Returns:\n        Tensor:\n            int64 tensor with the indices of the elements that have been kept\n            by NMS, sorted in decreasing order of scores\n    \"\"\"", "\n", "assert", "boxes", ".", "shape", "[", "-", "1", "]", "==", "5", "\n", "\n", "if", "boxes", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "empty", "(", "(", "0", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "boxes", ".", "device", ")", "\n", "", "boxes", "=", "boxes", ".", "float", "(", ")", "# fp16 does not have enough range for batched NMS", "\n", "# Strategy: in order to perform NMS independently per class,", "\n", "# we add an offset to all the boxes. The offset is dependent", "\n", "# only on the class idx, and is large enough so that boxes", "\n", "# from different classes do not overlap", "\n", "\n", "# Note that batched_nms in torchvision/ops/boxes.py only uses max_coordinate,", "\n", "# which won't handle negative coordinates correctly.", "\n", "# Here by using min_coordinate we can make sure the negative coordinates are", "\n", "# correctly handled.", "\n", "max_coordinate", "=", "(", "\n", "torch", ".", "max", "(", "boxes", "[", ":", ",", "0", "]", ",", "boxes", "[", ":", ",", "1", "]", ")", "+", "torch", ".", "max", "(", "boxes", "[", ":", ",", "2", "]", ",", "boxes", "[", ":", ",", "3", "]", ")", "/", "2", "\n", ")", ".", "max", "(", ")", "\n", "min_coordinate", "=", "(", "\n", "torch", ".", "min", "(", "boxes", "[", ":", ",", "0", "]", ",", "boxes", "[", ":", ",", "1", "]", ")", "-", "torch", ".", "max", "(", "boxes", "[", ":", ",", "2", "]", ",", "boxes", "[", ":", ",", "3", "]", ")", "/", "2", "\n", ")", ".", "min", "(", ")", "\n", "offsets", "=", "idxs", ".", "to", "(", "boxes", ")", "*", "(", "max_coordinate", "-", "min_coordinate", "+", "1", ")", "\n", "boxes_for_nms", "=", "boxes", ".", "clone", "(", ")", "# avoid modifying the original values in boxes", "\n", "boxes_for_nms", "[", ":", ",", ":", "2", "]", "+=", "offsets", "[", ":", ",", "None", "]", "\n", "keep", "=", "nms_rotated", "(", "boxes_for_nms", ",", "scores", ",", "iou_threshold", ")", "\n", "return", "keep", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.aspp.ASPP.__init__": [[19, 128], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "aspp.ASPP.convs.append", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "aspp.ASPP.convs.append", "wrappers.Conv2d", "fvcore.c2_xavier_fill", "len", "len", "wrappers.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "aspp.ASPP.convs.append", "aspp.ASPP.convs.append", "fvcore.c2_xavier_fill", "torch.nn.AdaptiveAvgPool2d", "wrappers.Conv2d", "torch.nn.AvgPool2d", "wrappers.Conv2d", "batch_norm.get_norm", "copy.deepcopy", "batch_norm.get_norm", "copy.deepcopy", "blocks.DepthwiseSeparableConv2d", "wrappers.Conv2d", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "batch_norm.get_norm", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "dilations", ",", "\n", "*", ",", "\n", "norm", ",", "\n", "activation", ",", "\n", "pool_kernel_size", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "use_depthwise_separable_conv", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            in_channels (int): number of input channels for ASPP.\n            out_channels (int): number of output channels.\n            dilations (list): a list of 3 dilations in ASPP.\n            norm (str or callable): normalization for all conv layers.\n                See :func:`layers.get_norm` for supported format. norm is\n                applied to all conv layers except the conv following\n                global average pooling.\n            activation (callable): activation function.\n            pool_kernel_size (tuple, list): the average pooling size (kh, kw)\n                for image pooling layer in ASPP. If set to None, it always\n                performs global average pooling. If not None, it must be\n                divisible by the shape of inputs in forward(). It is recommended\n                to use a fixed input feature size in training, and set this\n                option to match this size, so that it performs global average\n                pooling in training, and the size of the pooling window stays\n                consistent in inference.\n            dropout (float): apply dropout on the output of ASPP. It is used in\n                the official DeepLab implementation with a rate of 0.1:\n                https://github.com/tensorflow/models/blob/21b73d22f3ed05b650e85ac50849408dd36de32e/research/deeplab/model.py#L532  # noqa\n            use_depthwise_separable_conv (bool): use DepthwiseSeparableConv2d\n                for 3x3 convs in ASPP, proposed in :paper:`DeepLabV3+`.\n        \"\"\"", "\n", "super", "(", "ASPP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "dilations", ")", "==", "3", ",", "\"ASPP expects 3 dilations, got {}\"", ".", "format", "(", "len", "(", "dilations", ")", ")", "\n", "self", ".", "pool_kernel_size", "=", "pool_kernel_size", "\n", "self", ".", "dropout", "=", "dropout", "\n", "use_bias", "=", "norm", "==", "\"\"", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# conv 1x1", "\n", "self", ".", "convs", ".", "append", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "convs", "[", "-", "1", "]", ")", "\n", "# atrous convs", "\n", "for", "dilation", "in", "dilations", ":", "\n", "            ", "if", "use_depthwise_separable_conv", ":", "\n", "                ", "self", ".", "convs", ".", "append", "(", "\n", "DepthwiseSeparableConv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm1", "=", "norm", ",", "\n", "activation1", "=", "deepcopy", "(", "activation", ")", ",", "\n", "norm2", "=", "norm", ",", "\n", "activation2", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "convs", ".", "append", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "convs", "[", "-", "1", "]", ")", "\n", "# image pooling", "\n", "# We do not add BatchNorm because the spatial resolution is 1x1,", "\n", "# the original TF implementation has BatchNorm.", "\n", "", "", "if", "pool_kernel_size", "is", "None", ":", "\n", "            ", "image_pooling", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", ",", "\n", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "True", ",", "activation", "=", "deepcopy", "(", "activation", ")", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "image_pooling", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "pool_kernel_size", ",", "stride", "=", "1", ")", ",", "\n", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "True", ",", "activation", "=", "deepcopy", "(", "activation", ")", ")", ",", "\n", ")", "\n", "", "weight_init", ".", "c2_xavier_fill", "(", "image_pooling", "[", "1", "]", ")", "\n", "self", ".", "convs", ".", "append", "(", "image_pooling", ")", "\n", "\n", "self", ".", "project", "=", "Conv2d", "(", "\n", "5", "*", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "project", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.aspp.ASPP.forward": [[129, 145], ["torch.nn.functional.interpolate", "torch.cat", "aspp.ASPP.project", "aspp.ASPP.append", "torch.nn.functional.dropout", "ValueError", "conv"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "if", "self", ".", "pool_kernel_size", "is", "not", "None", ":", "\n", "            ", "if", "size", "[", "0", "]", "%", "self", ".", "pool_kernel_size", "[", "0", "]", "or", "size", "[", "1", "]", "%", "self", ".", "pool_kernel_size", "[", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"`pool_kernel_size` must be divisible by the shape of inputs. \"", "\n", "\"Input size: {} `pool_kernel_size`: {}\"", ".", "format", "(", "size", ",", "self", ".", "pool_kernel_size", ")", "\n", ")", "\n", "", "", "res", "=", "[", "]", "\n", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "res", ".", "append", "(", "conv", "(", "x", ")", ")", "\n", "", "res", "[", "-", "1", "]", "=", "F", ".", "interpolate", "(", "res", "[", "-", "1", "]", ",", "size", "=", "size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "res", "=", "torch", ".", "cat", "(", "res", ",", "dim", "=", "1", ")", "\n", "res", "=", "self", ".", "project", "(", "res", ")", "\n", "res", "=", "F", ".", "dropout", "(", "res", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "if", "self", ".", "dropout", ">", "0", "else", "res", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.rotated_boxes.pairwise_iou_rotated": [[7, 23], ["detectron2._C.box_iou_rotated"], "function", ["None"], ["\n", "from", ".", "boxes", "import", "Boxes", ",", "_maybe_jit_unused", "\n", "\n", "\n", "class", "RotatedBoxes", "(", "Boxes", ")", ":", "\n", "    ", "\"\"\"\n    This structure stores a list of rotated boxes as a Nx5 torch.Tensor.\n    It supports some common methods about boxes\n    (`area`, `clip`, `nonempty`, etc),\n    and also behaves like a Tensor\n    (support indexing, `to(device)`, `.device`, and iteration over all boxes)\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv.forward": [[17, 81], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "ctx.save_for_backward", "input.new_empty", "ValueError", "deform_conv._DeformConv._output_size", "input.new_empty", "input.new_empty", "torchvision.ops.deform_conv2d", "deform_conv._DeformConv._cal_im2col_step", "detectron2._C.deform_conv_forward", "input.dim", "NotImplementedError", "weight.size", "weight.size", "input.dim"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv._output_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv._cal_im2col_step"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "weight", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "im2col_step", "=", "64", ",", "\n", ")", ":", "\n", "        ", "if", "input", "is", "not", "None", "and", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected 4D tensor as input, got {}D tensor instead.\"", ".", "format", "(", "input", ".", "dim", "(", ")", ")", "\n", ")", "\n", "", "ctx", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "ctx", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "ctx", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "im2col_step", "=", "im2col_step", "\n", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "weight", ")", "\n", "\n", "output", "=", "input", ".", "new_empty", "(", "\n", "_DeformConv", ".", "_output_size", "(", "input", ",", "weight", ",", "ctx", ".", "padding", ",", "ctx", ".", "dilation", ",", "ctx", ".", "stride", ")", "\n", ")", "\n", "\n", "ctx", ".", "bufs_", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "# columns, ones", "\n", "\n", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "if", "deformable_groups", "!=", "1", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Deformable Conv with deformable_groups != 1 is not supported on CPUs!\"", "\n", ")", "\n", "", "return", "deform_conv2d", "(", "\n", "input", ",", "offset", ",", "weight", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "_DeformConv", ".", "_cal_im2col_step", "(", "input", ".", "shape", "[", "0", "]", ",", "ctx", ".", "im2col_step", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "cur_im2col_step", ")", "==", "0", ",", "\"im2col step must divide batchsize\"", "\n", "\n", "_C", ".", "deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "offset", ",", "\n", "output", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv.backward": [[82, 143], ["NotImplementedError", "deform_conv._DeformConv._cal_im2col_step", "torch.zeros_like", "torch.zeros_like", "detectron2._C.deform_conv_backward_input", "torch.zeros_like", "detectron2._C.deform_conv_backward_filter", "weight.size", "weight.size", "weight.size", "weight.size"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv._cal_im2col_step"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "offset", ",", "weight", "=", "ctx", ".", "saved_tensors", "\n", "\n", "grad_input", "=", "grad_offset", "=", "grad_weight", "=", "None", "\n", "\n", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "_DeformConv", ".", "_cal_im2col_step", "(", "input", ".", "shape", "[", "0", "]", ",", "ctx", ".", "im2col_step", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "cur_im2col_step", ")", "==", "0", ",", "\"im2col step must divide batchsize\"", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", "or", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "                ", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "_C", ".", "deform_conv_backward_input", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "                ", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "_C", ".", "deform_conv_backward_filter", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "1", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "\n", "", "", "return", "grad_input", ",", "grad_offset", ",", "grad_weight", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv._output_size": [[144, 161], ["weight.size", "range", "input.size", "input.size", "all", "ValueError", "input.dim", "map", "weight.size", "map"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_output_size", "(", "input", ",", "weight", ",", "padding", ",", "dilation", ",", "stride", ")", ":", "\n", "        ", "channels", "=", "weight", ".", "size", "(", "0", ")", "\n", "output_size", "=", "(", "input", ".", "size", "(", "0", ")", ",", "channels", ")", "\n", "for", "d", "in", "range", "(", "input", ".", "dim", "(", ")", "-", "2", ")", ":", "\n", "            ", "in_size", "=", "input", ".", "size", "(", "d", "+", "2", ")", "\n", "pad", "=", "padding", "[", "d", "]", "\n", "kernel", "=", "dilation", "[", "d", "]", "*", "(", "weight", ".", "size", "(", "d", "+", "2", ")", "-", "1", ")", "+", "1", "\n", "stride_", "=", "stride", "[", "d", "]", "\n", "output_size", "+=", "(", "(", "in_size", "+", "(", "2", "*", "pad", ")", "-", "kernel", ")", "//", "stride_", "+", "1", ",", ")", "\n", "", "if", "not", "all", "(", "map", "(", "lambda", "s", ":", "s", ">", "0", ",", "output_size", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"convolution input is too small (output would be {})\"", ".", "format", "(", "\n", "\"x\"", ".", "join", "(", "map", "(", "str", ",", "output_size", ")", ")", "\n", ")", "\n", ")", "\n", "", "return", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._DeformConv._cal_im2col_step": [[162, 184], ["functools.lru_cache", "range", "min", "int", "math.sqrt"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "lru_cache", "(", "maxsize", "=", "128", ")", "\n", "def", "_cal_im2col_step", "(", "input_size", ",", "default_size", ")", ":", "\n", "        ", "\"\"\"\n        Calculate proper im2col step size, which should be divisible by input_size and not larger\n        than prefer_size. Meanwhile the step size should be as large as possible to be more\n        efficient. So we choose the largest one among all divisors of input_size which are smaller\n        than prefer_size.\n        :param input_size: input batch size .\n        :param default_size: default preferred im2col step size.\n        :return: the largest proper step size.\n        \"\"\"", "\n", "if", "input_size", "<=", "default_size", ":", "\n", "            ", "return", "input_size", "\n", "", "best_step", "=", "1", "\n", "for", "step", "in", "range", "(", "2", ",", "min", "(", "int", "(", "math", ".", "sqrt", "(", "input_size", ")", ")", "+", "1", ",", "default_size", ")", ")", ":", "\n", "            ", "if", "input_size", "%", "step", "==", "0", ":", "\n", "                ", "if", "input_size", "//", "step", "<=", "default_size", ":", "\n", "                    ", "return", "input_size", "//", "step", "\n", "", "best_step", "=", "step", "\n", "\n", "", "", "return", "best_step", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._ModulatedDeformConv.forward": [[187, 242], ["input.new_empty", "detectron2._C.modulated_deform_conv_forward", "input.new_empty", "NotImplementedError", "ctx.save_for_backward", "deform_conv._ModulatedDeformConv._infer_shape", "input.new_empty", "input.new_empty"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._ModulatedDeformConv._infer_shape"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "weight", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", ")", ":", "\n", "        ", "ctx", ".", "stride", "=", "stride", "\n", "ctx", ".", "padding", "=", "padding", "\n", "ctx", ".", "dilation", "=", "dilation", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "with_bias", "=", "bias", "is", "not", "None", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "bias", "=", "input", ".", "new_empty", "(", "1", ")", "# fake tensor", "\n", "", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "if", "(", "\n", "weight", ".", "requires_grad", "\n", "or", "mask", ".", "requires_grad", "\n", "or", "offset", ".", "requires_grad", "\n", "or", "input", ".", "requires_grad", "\n", ")", ":", "\n", "            ", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", ")", "\n", "", "output", "=", "input", ".", "new_empty", "(", "_ModulatedDeformConv", ".", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ")", "\n", "ctx", ".", "_bufs", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "\n", "_C", ".", "modulated_deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "output", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", ",", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._ModulatedDeformConv.backward": [[243, 294], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "detectron2._C.modulated_deform_conv_backward", "NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", "=", "ctx", ".", "saved_tensors", "\n", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "grad_mask", "=", "torch", ".", "zeros_like", "(", "mask", ")", "\n", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "grad_bias", "=", "torch", ".", "zeros_like", "(", "bias", ")", "\n", "_C", ".", "modulated_deform_conv_backward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "grad_input", ",", "\n", "grad_weight", ",", "\n", "grad_bias", ",", "\n", "grad_offset", ",", "\n", "grad_mask", ",", "\n", "grad_output", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", ",", "\n", ")", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "grad_bias", "=", "None", "\n", "\n", "", "return", "(", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "grad_mask", ",", "\n", "grad_weight", ",", "\n", "grad_bias", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv._ModulatedDeformConv._infer_shape": [[296, 309], ["input.size", "weight.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ":", "\n", "        ", "n", "=", "input", ".", "size", "(", "0", ")", "\n", "channels_out", "=", "weight", ".", "size", "(", "0", ")", "\n", "height", ",", "width", "=", "input", ".", "shape", "[", "2", ":", "4", "]", "\n", "kernel_h", ",", "kernel_w", "=", "weight", ".", "shape", "[", "2", ":", "4", "]", "\n", "height_out", "=", "(", "\n", "height", "+", "2", "*", "ctx", ".", "padding", "-", "(", "ctx", ".", "dilation", "*", "(", "kernel_h", "-", "1", ")", "+", "1", ")", "\n", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "width_out", "=", "(", "\n", "width", "+", "2", "*", "ctx", ".", "padding", "-", "(", "ctx", ".", "dilation", "*", "(", "kernel_w", "-", "1", ")", "+", "1", ")", "\n", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "return", "n", ",", "channels_out", ",", "height_out", ",", "width_out", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.DeformConv.__init__": [[316, 367], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.Parameter", "torch.nn.init.kaiming_uniform_", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Deformable convolution from :paper:`deformconv`.\n\n        Arguments are similar to :class:`Conv2D`. Extra arguments:\n\n        Args:\n            deformable_groups (int): number of groups used in deformable convolution.\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n        \"\"\"", "\n", "super", "(", "DeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "bias", "\n", "assert", "in_channels", "%", "groups", "==", "0", ",", "\"in_channels {} cannot be divisible by groups {}\"", ".", "format", "(", "\n", "in_channels", ",", "groups", "\n", ")", "\n", "assert", "(", "\n", "out_channels", "%", "groups", "==", "0", "\n", ")", ",", "\"out_channels {} cannot be divisible by groups {}\"", ".", "format", "(", "out_channels", ",", "groups", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "self", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "self", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "self", ".", "groups", ",", "*", "self", ".", "kernel_size", ")", "\n", ")", "\n", "self", ".", "bias", "=", "None", "\n", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.DeformConv.forward": [[368, 398], ["deform_conv", "deform_conv.DeformConv.numel", "wrappers._NewEmptyTensorOp.apply", "deform_conv.DeformConv.norm", "deform_conv.DeformConv.activation", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "offset", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", "==", "0", ":", "\n", "# When input is empty, we want to return a empty tensor with \"correct\" shape,", "\n", "# So that the following operations will not panic", "\n", "# if they check for the shape of the tensor.", "\n", "# This computes the height and width of the output tensor", "\n", "            ", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n", "", "x", "=", "deform_conv", "(", "\n", "x", ",", "\n", "offset", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", ",", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.DeformConv.extra_repr": [[399, 410], ["str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "\"in_channels=\"", "+", "str", "(", "self", ".", "in_channels", ")", "\n", "tmpstr", "+=", "\", out_channels=\"", "+", "str", "(", "self", ".", "out_channels", ")", "\n", "tmpstr", "+=", "\", kernel_size=\"", "+", "str", "(", "self", ".", "kernel_size", ")", "\n", "tmpstr", "+=", "\", stride=\"", "+", "str", "(", "self", ".", "stride", ")", "\n", "tmpstr", "+=", "\", padding=\"", "+", "str", "(", "self", ".", "padding", ")", "\n", "tmpstr", "+=", "\", dilation=\"", "+", "str", "(", "self", ".", "dilation", ")", "\n", "tmpstr", "+=", "\", groups=\"", "+", "str", "(", "self", ".", "groups", ")", "\n", "tmpstr", "+=", "\", deformable_groups=\"", "+", "str", "(", "self", ".", "deformable_groups", ")", "\n", "tmpstr", "+=", "\", bias=False\"", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.ModulatedDeformConv.__init__": [[413, 461], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.Parameter", "torch.nn.init.kaiming_uniform_", "torch.Tensor", "torch.nn.Parameter", "torch.nn.init.constant_", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "norm", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Modulated deformable convolution from :paper:`deformconv2`.\n\n        Arguments are similar to :class:`Conv2D`. Extra arguments:\n\n        Args:\n            deformable_groups (int): number of groups used in deformable convolution.\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n        \"\"\"", "\n", "super", "(", "ModulatedDeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "self", ".", "with_bias", "=", "bias", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "self", ".", "kernel_size", ")", "\n", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.ModulatedDeformConv.forward": [[462, 490], ["modulated_deform_conv", "deform_conv.ModulatedDeformConv.numel", "wrappers._NewEmptyTensorOp.apply", "deform_conv.ModulatedDeformConv.norm", "deform_conv.ModulatedDeformConv.activation", "zip"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "offset", ",", "mask", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n", "", "x", "=", "modulated_deform_conv", "(", "\n", "x", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", ",", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.deform_conv.ModulatedDeformConv.extra_repr": [[491, 502], ["str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "\"in_channels=\"", "+", "str", "(", "self", ".", "in_channels", ")", "\n", "tmpstr", "+=", "\", out_channels=\"", "+", "str", "(", "self", ".", "out_channels", ")", "\n", "tmpstr", "+=", "\", kernel_size=\"", "+", "str", "(", "self", ".", "kernel_size", ")", "\n", "tmpstr", "+=", "\", stride=\"", "+", "str", "(", "self", ".", "stride", ")", "\n", "tmpstr", "+=", "\", padding=\"", "+", "str", "(", "self", ".", "padding", ")", "\n", "tmpstr", "+=", "\", dilation=\"", "+", "str", "(", "self", ".", "dilation", ")", "\n", "tmpstr", "+=", "\", groups=\"", "+", "str", "(", "self", ".", "groups", ")", "\n", "tmpstr", "+=", "\", deformable_groups=\"", "+", "str", "(", "self", ".", "deformable_groups", ")", "\n", "tmpstr", "+=", "\", bias=\"", "+", "str", "(", "self", ".", "with_bias", ")", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.__init__": [[29, 42], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "stride", ")", ":", "\n", "        ", "\"\"\"\n        The `__init__` method of any subclass should also contain these arguments.\n\n        Args:\n            in_channels (int):\n            out_channels (int):\n            stride (int):\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze": [[43, 56], ["blocks.CNNBlockBase.parameters", "batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm"], ["", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Make this block not trainable.\n        This method sets all parameters to `requires_grad=False`,\n        and convert all BatchNorm layers to FrozenBatchNorm\n\n        Returns:\n            the block itself\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "FrozenBatchNorm2d", ".", "convert_frozen_batchnorm", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.DepthwiseSeparableConv2d.__init__": [[66, 109], ["torch.nn.Module.__init__", "wrappers.Conv2d", "wrappers.Conv2d", "fvcore.c2_msra_fill", "fvcore.c2_msra_fill", "batch_norm.get_norm", "batch_norm.get_norm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "*", ",", "\n", "norm1", "=", "None", ",", "\n", "activation1", "=", "None", ",", "\n", "norm2", "=", "None", ",", "\n", "activation2", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            norm1, norm2 (str or callable): normalization for the two conv layers.\n            activation1, activation2 (callable(Tensor) -> Tensor): activation\n                function for the two conv layers.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depthwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "in_channels", ",", "\n", "bias", "=", "not", "norm1", ",", "\n", "norm", "=", "get_norm", "(", "norm1", ",", "in_channels", ")", ",", "\n", "activation", "=", "activation1", ",", "\n", ")", "\n", "self", ".", "pointwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "not", "norm2", ",", "\n", "norm", "=", "get_norm", "(", "norm2", ",", "out_channels", ")", ",", "\n", "activation", "=", "activation2", ",", "\n", ")", "\n", "\n", "# default initialization", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "depthwise", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "pointwise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.DepthwiseSeparableConv2d.forward": [[110, 112], ["blocks.DepthwiseSeparableConv2d.pointwise", "blocks.DepthwiseSeparableConv2d.depthwise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "pointwise", "(", "self", ".", "depthwise", "(", "x", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops._do_paste_mask": [[19, 72], ["torch.split", "img_x[].expand", "img_y[].expand", "torch.stack", "torch.nn.functional.grid_sample", "torch.clamp().to", "torch.clamp().to", "torch.clamp().to", "torch.arange", "torch.arange", "img_y.size", "img_x.size", "img_y.size", "img_x.size", "torch.jit.is_scripting", "torch.stack.to", "torch.jit.is_scripting", "masks.float.float", "torch.jit.is_scripting", "torch.clamp", "torch.clamp", "torch.clamp", "slice", "slice", "boxes[].max().ceil", "boxes[].max().ceil", "boxes.min().values.floor", "boxes[].max", "boxes[].max", "boxes.min"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["def", "_do_paste_mask", "(", "masks", ",", "boxes", ",", "img_h", ":", "int", ",", "img_w", ":", "int", ",", "skip_empty", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        masks: N, 1, H, W\n        boxes: N, 4\n        img_h, img_w (int):\n        skip_empty (bool): only paste masks within the region that\n            tightly bound all boxes, and returns the results this region only.\n            An important optimization for CPU.\n\n    Returns:\n        if skip_empty == False, a mask of shape (N, img_h, img_w)\n        if skip_empty == True, a mask of shape (N, h', w'), and the slice\n            object for the corresponding region.\n    \"\"\"", "\n", "# On GPU, paste all masks together (up to chunk size)", "\n", "# by using the entire image to sample the masks", "\n", "# Compared to pasting them one by one,", "\n", "# this has more operations but is faster on COCO-scale dataset.", "\n", "device", "=", "masks", ".", "device", "\n", "\n", "if", "skip_empty", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "x0_int", ",", "y0_int", "=", "torch", ".", "clamp", "(", "boxes", ".", "min", "(", "dim", "=", "0", ")", ".", "values", ".", "floor", "(", ")", "[", ":", "2", "]", "-", "1", ",", "min", "=", "0", ")", ".", "to", "(", "\n", "dtype", "=", "torch", ".", "int32", "\n", ")", "\n", "x1_int", "=", "torch", ".", "clamp", "(", "boxes", "[", ":", ",", "2", "]", ".", "max", "(", ")", ".", "ceil", "(", ")", "+", "1", ",", "max", "=", "img_w", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "\n", "y1_int", "=", "torch", ".", "clamp", "(", "boxes", "[", ":", ",", "3", "]", ".", "max", "(", ")", ".", "ceil", "(", ")", "+", "1", ",", "max", "=", "img_h", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "x0_int", ",", "y0_int", "=", "0", ",", "0", "\n", "x1_int", ",", "y1_int", "=", "img_w", ",", "img_h", "\n", "", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "torch", ".", "split", "(", "boxes", ",", "1", ",", "dim", "=", "1", ")", "# each is Nx1", "\n", "\n", "N", "=", "masks", ".", "shape", "[", "0", "]", "\n", "\n", "img_y", "=", "torch", ".", "arange", "(", "y0_int", ",", "y1_int", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "+", "0.5", "\n", "img_x", "=", "torch", ".", "arange", "(", "x0_int", ",", "x1_int", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "+", "0.5", "\n", "img_y", "=", "(", "img_y", "-", "y0", ")", "/", "(", "y1", "-", "y0", ")", "*", "2", "-", "1", "\n", "img_x", "=", "(", "img_x", "-", "x0", ")", "/", "(", "x1", "-", "x0", ")", "*", "2", "-", "1", "\n", "# img_x, img_y have shapes (N, w), (N, h)", "\n", "\n", "gx", "=", "img_x", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "N", ",", "img_y", ".", "size", "(", "1", ")", ",", "img_x", ".", "size", "(", "1", ")", ")", "\n", "gy", "=", "img_y", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "N", ",", "img_y", ".", "size", "(", "1", ")", ",", "img_x", ".", "size", "(", "1", ")", ")", "\n", "grid", "=", "torch", ".", "stack", "(", "[", "gx", ",", "gy", "]", ",", "dim", "=", "3", ")", "\n", "\n", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "if", "not", "masks", ".", "dtype", ".", "is_floating_point", ":", "\n", "            ", "masks", "=", "masks", ".", "float", "(", ")", "\n", "", "", "img_masks", "=", "F", ".", "grid_sample", "(", "masks", ",", "grid", ".", "to", "(", "masks", ".", "dtype", ")", ",", "align_corners", "=", "False", ")", "\n", "\n", "if", "skip_empty", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "return", "img_masks", "[", ":", ",", "0", "]", ",", "(", "slice", "(", "y0_int", ",", "y1_int", ")", ",", "slice", "(", "x0_int", ",", "x1_int", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "img_masks", "[", ":", ",", "0", "]", ",", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops.paste_masks_in_image": [[74, 148], ["len", "torch.chunk", "torch.zeros", "masks.new_empty", "isinstance", "len", "torch.jit.is_scripting", "int", "torch.arange", "mask_ops._do_paste_mask", "torch.jit.is_scripting", "numpy.ceil", "int", "int"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops._do_paste_mask"], ["", "", "def", "paste_masks_in_image", "(", "\n", "masks", ":", "torch", ".", "Tensor", ",", "boxes", ":", "Boxes", ",", "image_shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "threshold", ":", "float", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Paste a set of masks that are of a fixed resolution (e.g., 28 x 28) into an image.\n    The location, height, and width for pasting each mask is determined by their\n    corresponding bounding boxes in boxes.\n\n    Note:\n        This is a complicated but more accurate implementation. In actual deployment, it is\n        often enough to use a faster but less accurate implementation.\n        See :func:`paste_mask_in_image_old` in this file for an alternative implementation.\n\n    Args:\n        masks (tensor): Tensor of shape (Bimg, Hmask, Wmask), where Bimg is the number of\n            detected object instances in the image and Hmask, Wmask are the mask width and mask\n            height of the predicted mask (e.g., Hmask = Wmask = 28). Values are in [0, 1].\n        boxes (Boxes or Tensor): A Boxes of length Bimg or Tensor of shape (Bimg, 4).\n            boxes[i] and masks[i] correspond to the same object instance.\n        image_shape (tuple): height, width\n        threshold (float): A threshold in [0, 1] for converting the (soft) masks to\n            binary masks.\n\n    Returns:\n        img_masks (Tensor): A tensor of shape (Bimg, Himage, Wimage), where Bimg is the\n        number of detected object instances and Himage, Wimage are the image width\n        and height. img_masks[i] is a binary mask for object instance i.\n    \"\"\"", "\n", "\n", "assert", "masks", ".", "shape", "[", "-", "1", "]", "==", "masks", ".", "shape", "[", "-", "2", "]", ",", "\"Only square mask predictions are supported\"", "\n", "N", "=", "len", "(", "masks", ")", "\n", "if", "N", "==", "0", ":", "\n", "        ", "return", "masks", ".", "new_empty", "(", "(", "0", ",", ")", "+", "image_shape", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "", "if", "not", "isinstance", "(", "boxes", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "boxes", "=", "boxes", ".", "tensor", "\n", "", "device", "=", "boxes", ".", "device", "\n", "assert", "len", "(", "boxes", ")", "==", "N", ",", "boxes", ".", "shape", "\n", "\n", "img_h", ",", "img_w", "=", "image_shape", "\n", "\n", "# The actual implementation split the input into chunks,", "\n", "# and paste them chunk by chunk.", "\n", "if", "device", ".", "type", "==", "\"cpu\"", "or", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# CPU is most efficient when they are pasted one by one with skip_empty=True", "\n", "# so that it performs minimal number of operations.", "\n", "        ", "num_chunks", "=", "N", "\n", "", "else", ":", "\n", "# GPU benefits from parallelism for larger chunks, but may have memory issue", "\n", "# int(img_h) because shape may be tensors in tracing", "\n", "        ", "num_chunks", "=", "int", "(", "np", ".", "ceil", "(", "N", "*", "int", "(", "img_h", ")", "*", "int", "(", "img_w", ")", "*", "BYTES_PER_FLOAT", "/", "GPU_MEM_LIMIT", ")", ")", "\n", "assert", "(", "\n", "num_chunks", "<=", "N", "\n", ")", ",", "\"Default GPU_MEM_LIMIT in mask_ops.py is too small; try increasing it\"", "\n", "", "chunks", "=", "torch", ".", "chunk", "(", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", ",", "num_chunks", ")", "\n", "\n", "img_masks", "=", "torch", ".", "zeros", "(", "\n", "N", ",", "img_h", ",", "img_w", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "bool", "if", "threshold", ">=", "0", "else", "torch", ".", "uint8", "\n", ")", "\n", "for", "inds", "in", "chunks", ":", "\n", "        ", "masks_chunk", ",", "spatial_inds", "=", "_do_paste_mask", "(", "\n", "masks", "[", "inds", ",", "None", ",", ":", ",", ":", "]", ",", "boxes", "[", "inds", "]", ",", "img_h", ",", "img_w", ",", "skip_empty", "=", "device", ".", "type", "==", "\"cpu\"", "\n", ")", "\n", "\n", "if", "threshold", ">=", "0", ":", "\n", "            ", "masks_chunk", "=", "(", "masks_chunk", ">=", "threshold", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", "\n", "", "else", ":", "\n", "# for visualization and debugging", "\n", "            ", "masks_chunk", "=", "(", "masks_chunk", "*", "255", ")", ".", "to", "(", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "# Scripting does not use the optimized codepath", "\n", "            ", "img_masks", "[", "inds", "]", "=", "masks_chunk", "\n", "", "else", ":", "\n", "            ", "img_masks", "[", "(", "inds", ",", ")", "+", "spatial_inds", "]", "=", "masks_chunk", "\n", "", "", "return", "img_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops.paste_mask_in_image_old": [[155, 208], ["box.to.to", "PIL.Image.fromarray", "torch.from_numpy().to.resize", "numpy.array", "torch.zeros", "max", "min", "max", "min", "torch.from_numpy().to.cpu().numpy", "numpy.array", "torch.from_numpy", "torch.from_numpy().to", "torch.from_numpy().to.cpu", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "paste_mask_in_image_old", "(", "mask", ",", "box", ",", "img_h", ",", "img_w", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"\n    Paste a single mask in an image.\n    This is a per-box implementation of :func:`paste_masks_in_image`.\n    This function has larger quantization error due to incorrect pixel\n    modeling and is not used any more.\n\n    Args:\n        mask (Tensor): A tensor of shape (Hmask, Wmask) storing the mask of a single\n            object instance. Values are in [0, 1].\n        box (Tensor): A tensor of shape (4, ) storing the x0, y0, x1, y1 box corners\n            of the object instance.\n        img_h, img_w (int): Image height and width.\n        threshold (float): Mask binarization threshold in [0, 1].\n\n    Returns:\n        im_mask (Tensor):\n            The resized and binarized object mask pasted into the original\n            image plane (a tensor of shape (img_h, img_w)).\n    \"\"\"", "\n", "# Conversion from continuous box coordinates to discrete pixel coordinates", "\n", "# via truncation (cast to int32). This determines which pixels to paste the", "\n", "# mask onto.", "\n", "box", "=", "box", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "# Continuous to discrete coordinate conversion", "\n", "# An example (1D) box with continuous coordinates (x0=0.7, x1=4.3) will map to", "\n", "# a discrete coordinates (x0=0, x1=4). Note that box is mapped to 5 = x1 - x0 + 1", "\n", "# pixels (not x1 - x0 pixels).", "\n", "samples_w", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1", "# Number of pixel samples, *not* geometric width", "\n", "samples_h", "=", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1", "# Number of pixel samples, *not* geometric height", "\n", "\n", "# Resample the mask from it's original grid to the new samples_w x samples_h grid", "\n", "mask", "=", "Image", ".", "fromarray", "(", "mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "mask", "=", "mask", ".", "resize", "(", "(", "samples_w", ",", "samples_h", ")", ",", "resample", "=", "Image", ".", "BILINEAR", ")", "\n", "mask", "=", "np", ".", "array", "(", "mask", ",", "copy", "=", "False", ")", "\n", "\n", "if", "threshold", ">=", "0", ":", "\n", "        ", "mask", "=", "np", ".", "array", "(", "mask", ">", "threshold", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "", "else", ":", "\n", "# for visualization and debugging, we also", "\n", "# allow it to return an unmodified mask", "\n", "        ", "mask", "=", "torch", ".", "from_numpy", "(", "mask", "*", "255", ")", ".", "to", "(", "torch", ".", "uint8", ")", "\n", "\n", "", "im_mask", "=", "torch", ".", "zeros", "(", "(", "img_h", ",", "img_w", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "x_0", "=", "max", "(", "box", "[", "0", "]", ",", "0", ")", "\n", "x_1", "=", "min", "(", "box", "[", "2", "]", "+", "1", ",", "img_w", ")", "\n", "y_0", "=", "max", "(", "box", "[", "1", "]", ",", "0", ")", "\n", "y_1", "=", "min", "(", "box", "[", "3", "]", "+", "1", ",", "img_h", ")", "\n", "\n", "im_mask", "[", "y_0", ":", "y_1", ",", "x_0", ":", "x_1", "]", "=", "mask", "[", "\n", "(", "y_0", "-", "box", "[", "1", "]", ")", ":", "(", "y_1", "-", "box", "[", "1", "]", ")", ",", "(", "x_0", "-", "box", "[", "0", "]", ")", ":", "(", "x_1", "-", "box", "[", "0", "]", ")", "\n", "]", "\n", "return", "im_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops.pad_masks": [[219, 235], ["masks.new_zeros", "float"], "function", ["None"], ["", "def", "pad_masks", "(", "masks", ",", "padding", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        masks (tensor): A tensor of shape (B, M, M) representing B masks.\n        padding (int): Number of cells to pad on all sides.\n\n    Returns:\n        The padded masks and the scale factor of the padding size / original size.\n    \"\"\"", "\n", "B", "=", "masks", ".", "shape", "[", "0", "]", "\n", "M", "=", "masks", ".", "shape", "[", "-", "1", "]", "\n", "pad2", "=", "2", "*", "padding", "\n", "scale", "=", "float", "(", "M", "+", "pad2", ")", "/", "M", "\n", "padded_masks", "=", "masks", ".", "new_zeros", "(", "(", "B", ",", "M", "+", "pad2", ",", "M", "+", "pad2", ")", ")", "\n", "padded_masks", "[", ":", ",", "padding", ":", "-", "padding", ",", "padding", ":", "-", "padding", "]", "=", "masks", "\n", "return", "padded_masks", ",", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.mask_ops.scale_boxes": [[237, 261], ["torch.zeros_like"], "function", ["None"], ["", "def", "scale_boxes", "(", "boxes", ",", "scale", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        boxes (tensor): A tensor of shape (B, 4) representing B boxes with 4\n            coords representing the corners x0, y0, x1, y1,\n        scale (float): The box scaling factor.\n\n    Returns:\n        Scaled boxes.\n    \"\"\"", "\n", "w_half", "=", "(", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", ")", "*", "0.5", "\n", "h_half", "=", "(", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", ")", "*", "0.5", "\n", "x_c", "=", "(", "boxes", "[", ":", ",", "2", "]", "+", "boxes", "[", ":", ",", "0", "]", ")", "*", "0.5", "\n", "y_c", "=", "(", "boxes", "[", ":", ",", "3", "]", "+", "boxes", "[", ":", ",", "1", "]", ")", "*", "0.5", "\n", "\n", "w_half", "*=", "scale", "\n", "h_half", "*=", "scale", "\n", "\n", "scaled_boxes", "=", "torch", ".", "zeros_like", "(", "boxes", ")", "\n", "scaled_boxes", "[", ":", ",", "0", "]", "=", "x_c", "-", "w_half", "\n", "scaled_boxes", "[", ":", ",", "2", "]", "=", "x_c", "+", "w_half", "\n", "scaled_boxes", "[", ":", ",", "1", "]", "=", "y_c", "-", "h_half", "\n", "scaled_boxes", "[", ":", ",", "3", "]", "=", "y_c", "+", "h_half", "\n", "return", "scaled_boxes", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.__init__": [[36, 44], ["torch.nn.Module.__init__", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "register_buffer", "(", "\"weight\"", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"running_mean\"", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"running_var\"", ",", "torch", ".", "ones", "(", "num_features", ")", "-", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.forward": [[45, 66], ["scale.reshape.reshape.reshape", "bias.reshape.reshape.reshape", "torch.nn.functional.batch_norm", "torch.nn.functional.batch_norm", "bias.reshape.reshape.to", "scale.reshape.reshape.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "requires_grad", ":", "\n", "# When gradients are needed, F.batch_norm will use extra memory", "\n", "# because its backward op computes gradients for weight/bias as well.", "\n", "            ", "scale", "=", "self", ".", "weight", "*", "(", "self", ".", "running_var", "+", "self", ".", "eps", ")", ".", "rsqrt", "(", ")", "\n", "bias", "=", "self", ".", "bias", "-", "self", ".", "running_mean", "*", "scale", "\n", "scale", "=", "scale", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "bias", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "out_dtype", "=", "x", ".", "dtype", "# may be half", "\n", "return", "x", "*", "scale", ".", "to", "(", "out_dtype", ")", "+", "bias", ".", "to", "(", "out_dtype", ")", "\n", "", "else", ":", "\n", "# When gradients are not needed, F.batch_norm is a single fused op", "\n", "# and provide more optimization opportunities.", "\n", "            ", "return", "F", ".", "batch_norm", "(", "\n", "x", ",", "\n", "self", ".", "running_mean", ",", "\n", "self", ".", "running_var", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "training", "=", "False", ",", "\n", "eps", "=", "self", ".", "eps", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d._load_from_state_dict": [[68, 92], ["local_metadata.get", "super()._load_from_state_dict", "logging.getLogger", "logging.getLogger.info", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "prefix.rstrip"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d._load_from_state_dict"], ["", "", "def", "_load_from_state_dict", "(", "\n", "self", ",", "state_dict", ",", "prefix", ",", "local_metadata", ",", "strict", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", ":", "\n", "        ", "version", "=", "local_metadata", ".", "get", "(", "\"version\"", ",", "None", ")", "\n", "\n", "if", "version", "is", "None", "or", "version", "<", "2", ":", "\n", "# No running_mean/var in early versions", "\n", "# This will silent the warnings", "\n", "            ", "if", "prefix", "+", "\"running_mean\"", "not", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "prefix", "+", "\"running_mean\"", "]", "=", "torch", ".", "zeros_like", "(", "self", ".", "running_mean", ")", "\n", "", "if", "prefix", "+", "\"running_var\"", "not", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "prefix", "+", "\"running_var\"", "]", "=", "torch", ".", "ones_like", "(", "self", ".", "running_var", ")", "\n", "\n", "# NOTE: if a checkpoint is trained with BatchNorm and loaded (together with", "\n", "# version number) to FrozenBatchNorm, running_var will be wrong. One solution", "\n", "# is to remove the version number from the checkpoint.", "\n", "", "", "if", "version", "is", "not", "None", "and", "version", "<", "3", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"FrozenBatchNorm {} is upgraded to version 3.\"", ".", "format", "(", "prefix", ".", "rstrip", "(", "\".\"", ")", ")", ")", "\n", "# In version < 3, running_var are used without +eps.", "\n", "state_dict", "[", "prefix", "+", "\"running_var\"", "]", "-=", "self", ".", "eps", "\n", "\n", "", "super", "(", ")", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "strict", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.__repr__": [[94, 96], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"FrozenBatchNorm2d(num_features={}, eps={})\"", ".", "format", "(", "self", ".", "num_features", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm": [[97, 129], ["isinstance", "cls", "module.named_children", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "cls.convert_frozen_batchnorm", "cls.add_module", "module.weight.data.clone", "module.bias.data.clone"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["", "@", "classmethod", "\n", "def", "convert_frozen_batchnorm", "(", "cls", ",", "module", ")", ":", "\n", "        ", "\"\"\"\n        Convert all BatchNorm/SyncBatchNorm in module into FrozenBatchNorm.\n\n        Args:\n            module (torch.nn.Module):\n\n        Returns:\n            If module is BatchNorm/SyncBatchNorm, returns a new module.\n            Otherwise, in-place convert module and return it.\n\n        Similar to convert_sync_batchnorm in\n        https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py\n        \"\"\"", "\n", "bn_module", "=", "nn", ".", "modules", ".", "batchnorm", "\n", "bn_module", "=", "(", "bn_module", ".", "BatchNorm2d", ",", "bn_module", ".", "SyncBatchNorm", ")", "\n", "res", "=", "module", "\n", "if", "isinstance", "(", "module", ",", "bn_module", ")", ":", "\n", "            ", "res", "=", "cls", "(", "module", ".", "num_features", ")", "\n", "if", "module", ".", "affine", ":", "\n", "                ", "res", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "res", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "res", ".", "running_mean", ".", "data", "=", "module", ".", "running_mean", ".", "data", "\n", "res", ".", "running_var", ".", "data", "=", "module", ".", "running_var", ".", "data", "\n", "res", ".", "eps", "=", "module", ".", "eps", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "                ", "new_child", "=", "cls", ".", "convert_frozen_batchnorm", "(", "child", ")", "\n", "if", "new_child", "is", "not", "child", ":", "\n", "                    ", "res", ".", "add_module", "(", "name", ",", "new_child", ")", "\n", "", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.NaiveSyncBatchNorm.__init__": [[187, 191], ["wrappers.BatchNorm2d.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "stats_mode", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "stats_mode", "in", "[", "\"\"", ",", "\"N\"", "]", "\n", "self", ".", "_stats_mode", "=", "stats_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.NaiveSyncBatchNorm.forward": [[192, 232], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "scale.reshape.reshape.reshape", "bias.reshape.reshape.reshape", "super().forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "fvcore.nn.distributed.differentiable_all_reduce", "vec[].detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.split", "torch.split", "torch.split", "torch.split", "detectron2.utils.comm.get_world_size", "fvcore.nn.distributed.differentiable_all_reduce", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max.clamp", "torch.max.clamp", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.mean.detach", "torch.mean.detach", "var.detach", "torch.get_world_size", "torch.get_world_size", "input.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Decoder.forward", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "comm", ".", "get_world_size", "(", ")", "==", "1", "or", "not", "self", ".", "training", ":", "\n", "            ", "return", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "\n", "", "B", ",", "C", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "mean", "=", "torch", ".", "mean", "(", "input", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", "\n", "meansqr", "=", "torch", ".", "mean", "(", "input", "*", "input", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", "\n", "\n", "if", "self", ".", "_stats_mode", "==", "\"\"", ":", "\n", "            ", "assert", "B", ">", "0", ",", "'SyncBatchNorm(stats_mode=\"\") does not support zero batch size.'", "\n", "vec", "=", "torch", ".", "cat", "(", "[", "mean", ",", "meansqr", "]", ",", "dim", "=", "0", ")", "\n", "vec", "=", "differentiable_all_reduce", "(", "vec", ")", "*", "(", "1.0", "/", "dist", ".", "get_world_size", "(", ")", ")", "\n", "mean", ",", "meansqr", "=", "torch", ".", "split", "(", "vec", ",", "C", ")", "\n", "momentum", "=", "self", ".", "momentum", "\n", "", "else", ":", "\n", "            ", "if", "B", "==", "0", ":", "\n", "                ", "vec", "=", "torch", ".", "zeros", "(", "[", "2", "*", "C", "+", "1", "]", ",", "device", "=", "mean", ".", "device", ",", "dtype", "=", "mean", ".", "dtype", ")", "\n", "vec", "=", "vec", "+", "input", ".", "sum", "(", ")", "# make sure there is gradient w.r.t input", "\n", "", "else", ":", "\n", "                ", "vec", "=", "torch", ".", "cat", "(", "\n", "[", "mean", ",", "meansqr", ",", "torch", ".", "ones", "(", "[", "1", "]", ",", "device", "=", "mean", ".", "device", ",", "dtype", "=", "mean", ".", "dtype", ")", "]", ",", "dim", "=", "0", "\n", ")", "\n", "", "vec", "=", "differentiable_all_reduce", "(", "vec", "*", "B", ")", "\n", "\n", "total_batch", "=", "vec", "[", "-", "1", "]", ".", "detach", "(", ")", "\n", "momentum", "=", "total_batch", ".", "clamp", "(", "max", "=", "1", ")", "*", "self", ".", "momentum", "# no update if total_batch is 0", "\n", "total_batch", "=", "torch", ".", "max", "(", "total_batch", ",", "torch", ".", "ones_like", "(", "total_batch", ")", ")", "# avoid div-by-zero", "\n", "mean", ",", "meansqr", ",", "_", "=", "torch", ".", "split", "(", "vec", "/", "total_batch", ",", "C", ")", "\n", "\n", "", "var", "=", "meansqr", "-", "mean", "*", "mean", "\n", "invstd", "=", "torch", ".", "rsqrt", "(", "var", "+", "self", ".", "eps", ")", "\n", "scale", "=", "self", ".", "weight", "*", "invstd", "\n", "bias", "=", "self", ".", "bias", "-", "mean", "*", "scale", "\n", "scale", "=", "scale", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "bias", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "self", ".", "running_mean", "+=", "momentum", "*", "(", "mean", ".", "detach", "(", ")", "-", "self", ".", "running_mean", ")", "\n", "self", ".", "running_var", "+=", "momentum", "*", "(", "var", ".", "detach", "(", ")", "-", "self", ".", "running_var", ")", "\n", "return", "input", "*", "scale", "+", "bias", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.batch_norm.get_norm": [[131, 157], ["isinstance", "norm", "len", "torch.nn.GroupNorm"], "function", ["None"], ["", "", "def", "get_norm", "(", "norm", ",", "out_channels", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        norm (str or callable): either one of BN, SyncBN, FrozenBN, GN;\n            or a callable that takes a channel number and returns\n            the normalization layer as a nn.Module.\n\n    Returns:\n        nn.Module or None: the normalization layer\n    \"\"\"", "\n", "if", "norm", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "norm", ",", "str", ")", ":", "\n", "        ", "if", "len", "(", "norm", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "norm", "=", "{", "\n", "\"BN\"", ":", "BatchNorm2d", ",", "\n", "# Fixed in https://github.com/pytorch/pytorch/pull/36382", "\n", "\"SyncBN\"", ":", "NaiveSyncBatchNorm", "if", "env", ".", "TORCH_VERSION", "<=", "(", "1", ",", "5", ")", "else", "nn", ".", "SyncBatchNorm", ",", "\n", "\"FrozenBN\"", ":", "FrozenBatchNorm2d", ",", "\n", "\"GN\"", ":", "lambda", "channels", ":", "nn", ".", "GroupNorm", "(", "32", ",", "channels", ")", ",", "\n", "# for debugging:", "\n", "\"nnSyncBN\"", ":", "nn", ".", "SyncBatchNorm", ",", "\n", "\"naiveSyncBN\"", ":", "NaiveSyncBatchNorm", ",", "\n", "}", "[", "norm", "]", "\n", "", "return", "norm", "(", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align.ROIAlign.__init__": [[8, 48], ["torch.nn.Module.__init__", "tuple", "int", "__version__.split"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ",", "aligned", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (tuple): h, w\n            spatial_scale (float): scale the input boxes by this number\n            sampling_ratio (int): number of inputs samples to take for each output\n                sample. 0 to take samples densely.\n            aligned (bool): if False, use the legacy implementation in\n                Detectron. If True, align the results more perfectly.\n\n        Note:\n            The meaning of aligned=True:\n\n            Given a continuous coordinate c, its two neighboring pixel indices (in our\n            pixel model) are computed by floor(c - 0.5) and ceil(c - 0.5). For example,\n            c=1.3 has pixel neighbors with discrete indices [0] and [1] (which are sampled\n            from the underlying signal at continuous coordinates 0.5 and 1.5). But the original\n            roi_align (aligned=False) does not subtract the 0.5 when computing neighboring\n            pixel indices and therefore it uses pixels with a slightly incorrect alignment\n            (relative to our pixel model) when performing bilinear interpolation.\n\n            With `aligned=True`,\n            we first appropriately scale the ROI and then shift it by -0.5\n            prior to calling roi_align. This produces the correct neighbors; see\n            detectron2/tests/test_roi_align.py for verification.\n\n            The difference does not make a difference to the model's performance if\n            ROIAlign is used together with conv layers.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n", "self", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "self", ".", "aligned", "=", "aligned", "\n", "\n", "from", "torchvision", "import", "__version__", "\n", "\n", "version", "=", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "__version__", ".", "split", "(", "\".\"", ")", "[", ":", "2", "]", ")", "\n", "# https://github.com/pytorch/vision/pull/2438", "\n", "assert", "version", ">=", "(", "0", ",", "7", ")", ",", "\"Require torchvision >= 0.7\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align.ROIAlign.forward": [[49, 63], ["torchvision.ops.roi_align", "rois.to", "rois.dim", "rois.size"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "input", ",", "rois", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: NCHW images\n            rois: Bx5 boxes. First column is the index into N. The other 4 columns are xyxy.\n        \"\"\"", "\n", "assert", "rois", ".", "dim", "(", ")", "==", "2", "and", "rois", ".", "size", "(", "1", ")", "==", "5", "\n", "return", "roi_align", "(", "\n", "input", ",", "\n", "rois", ".", "to", "(", "dtype", "=", "input", ".", "dtype", ")", ",", "\n", "self", ".", "output_size", ",", "\n", "self", ".", "spatial_scale", ",", "\n", "self", ".", "sampling_ratio", ",", "\n", "self", ".", "aligned", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align.ROIAlign.__repr__": [[65, 73], ["str", "str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"output_size=\"", "+", "str", "(", "self", ".", "output_size", ")", "\n", "tmpstr", "+=", "\", spatial_scale=\"", "+", "str", "(", "self", ".", "spatial_scale", ")", "\n", "tmpstr", "+=", "\", sampling_ratio=\"", "+", "str", "(", "self", ".", "sampling_ratio", ")", "\n", "tmpstr", "+=", "\", aligned=\"", "+", "str", "(", "self", ".", "aligned", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.shape_spec.ShapeSpec.__new__": [[19, 21], ["super().__new__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.shape_spec.ShapeSpec.__new__"], ["def", "__new__", "(", "cls", ",", "channels", "=", "None", ",", "height", "=", "None", ",", "width", "=", "None", ",", "stride", "=", "None", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__new__", "(", "cls", ",", "channels", ",", "height", ",", "width", ",", "stride", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated._ROIAlignRotated.forward": [[12, 23], ["ctx.save_for_backward", "torch.nn.modules.utils._pair", "input.size", "detectron2._C.roi_align_rotated_forward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "roi", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "roi", ")", "\n", "ctx", ".", "output_size", "=", "_pair", "(", "output_size", ")", "\n", "ctx", ".", "spatial_scale", "=", "spatial_scale", "\n", "ctx", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "ctx", ".", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "output", "=", "_C", ".", "roi_align_rotated_forward", "(", "\n", "input", ",", "roi", ",", "spatial_scale", ",", "output_size", "[", "0", "]", ",", "output_size", "[", "1", "]", ",", "sampling_ratio", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated._ROIAlignRotated.backward": [[24, 45], ["detectron2._C.roi_align_rotated_backward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "(", "rois", ",", ")", "=", "ctx", ".", "saved_tensors", "\n", "output_size", "=", "ctx", ".", "output_size", "\n", "spatial_scale", "=", "ctx", ".", "spatial_scale", "\n", "sampling_ratio", "=", "ctx", ".", "sampling_ratio", "\n", "bs", ",", "ch", ",", "h", ",", "w", "=", "ctx", ".", "input_shape", "\n", "grad_input", "=", "_C", ".", "roi_align_rotated_backward", "(", "\n", "grad_output", ",", "\n", "rois", ",", "\n", "spatial_scale", ",", "\n", "output_size", "[", "0", "]", ",", "\n", "output_size", "[", "1", "]", ",", "\n", "bs", ",", "\n", "ch", ",", "\n", "h", ",", "\n", "w", ",", "\n", "sampling_ratio", ",", "\n", ")", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated.ROIAlignRotated.__init__": [[51, 70], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (tuple): h, w\n            spatial_scale (float): scale the input boxes by this number\n            sampling_ratio (int): number of inputs samples to take for each output\n                sample. 0 to take samples densely.\n\n        Note:\n            ROIAlignRotated supports continuous coordinate by default:\n            Given a continuous coordinate c, its two neighboring pixel indices (in our\n            pixel model) are computed by floor(c - 0.5) and ceil(c - 0.5). For example,\n            c=1.3 has pixel neighbors with discrete indices [0] and [1] (which are sampled\n            from the underlying signal at continuous coordinates 0.5 and 1.5).\n        \"\"\"", "\n", "super", "(", "ROIAlignRotated", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n", "self", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated.ROIAlignRotated.forward": [[71, 86], ["roi_align_rotated().to", "input.float.float.float", "rois.float.float.float", "rois.float.float.dim", "rois.float.float.size", "roi_align_rotated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "input", ",", "rois", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: NCHW images\n            rois: Bx6 boxes. First column is the index into N.\n                The other 5 columns are (x_ctr, y_ctr, width, height, angle_degrees).\n        \"\"\"", "\n", "assert", "rois", ".", "dim", "(", ")", "==", "2", "and", "rois", ".", "size", "(", "1", ")", "==", "6", "\n", "orig_dtype", "=", "input", ".", "dtype", "\n", "if", "orig_dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "input", "=", "input", ".", "float", "(", ")", "\n", "rois", "=", "rois", ".", "float", "(", ")", "\n", "", "return", "roi_align_rotated", "(", "\n", "input", ",", "rois", ",", "self", ".", "output_size", ",", "self", ".", "spatial_scale", ",", "self", ".", "sampling_ratio", "\n", ")", ".", "to", "(", "dtype", "=", "orig_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated.ROIAlignRotated.__repr__": [[87, 94], ["str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"output_size=\"", "+", "str", "(", "self", ".", "output_size", ")", "\n", "tmpstr", "+=", "\", spatial_scale=\"", "+", "str", "(", "self", ".", "spatial_scale", ")", "\n", "tmpstr", "+=", "\", sampling_ratio=\"", "+", "str", "(", "self", ".", "sampling_ratio", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalog.get": [[57, 64], ["name.startswith", "name.startswith", "RuntimeError", "catalog.ModelCatalog._get_c2_detectron_baseline", "catalog.ModelCatalog._get_c2_imagenet_pretrained"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalog._get_c2_detectron_baseline", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalog._get_c2_imagenet_pretrained"], ["@", "staticmethod", "\n", "def", "get", "(", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"Caffe2Detectron/COCO\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_detectron_baseline", "(", "name", ")", "\n", "", "if", "name", ".", "startswith", "(", "\"ImageNetPretrained/\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_imagenet_pretrained", "(", "name", ")", "\n", "", "raise", "RuntimeError", "(", "\"model not present in the catalog: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalog._get_c2_imagenet_pretrained": [[65, 72], ["len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_c2_imagenet_pretrained", "(", "name", ")", ":", "\n", "        ", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", "\n", "name", "=", "name", "[", "len", "(", "\"ImageNetPretrained/\"", ")", ":", "]", "\n", "name", "=", "ModelCatalog", ".", "C2_IMAGENET_MODELS", "[", "name", "]", "\n", "url", "=", "\"/\"", ".", "join", "(", "[", "prefix", ",", "name", "]", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalog._get_c2_detectron_baseline": [[73, 93], ["ModelCatalog.C2_DETECTRON_PATH_FORMAT.format", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_c2_detectron_baseline", "(", "name", ")", ":", "\n", "        ", "name", "=", "name", "[", "len", "(", "\"Caffe2Detectron/COCO/\"", ")", ":", "]", "\n", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_MODELS", "[", "name", "]", "\n", "if", "\"keypoint_rcnn\"", "in", "name", ":", "\n", "            ", "dataset", "=", "ModelCatalog", ".", "C2_DATASET_COCO_KEYPOINTS", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ModelCatalog", ".", "C2_DATASET_COCO", "\n", "\n", "", "if", "\"35998355/rpn_R-50-C4_1x\"", "in", "name", ":", "\n", "# this one model is somehow different from others ..", "\n", "            ", "type", "=", "\"rpn\"", "\n", "", "else", ":", "\n", "            ", "type", "=", "\"generalized_rcnn\"", "\n", "\n", "# Detectron C2 models are stored in the structure defined in `C2_DETECTRON_PATH_FORMAT`.", "\n", "", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_PATH_FORMAT", ".", "format", "(", "\n", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", ",", "url", "=", "url", ",", "type", "=", "type", ",", "dataset", "=", "dataset", "\n", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalogHandler._get_supported_prefixes": [[102, 104], ["None"], "methods", ["None"], ["def", "_get_supported_prefixes", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "PREFIX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalogHandler._get_local_path": [[105, 110], ["logging.getLogger", "catalog.ModelCatalog.get", "logging.getLogger.info", "detectron2.utils.file_io.PathManager.get_local_path", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_get_local_path", "(", "self", ",", "path", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "catalog_path", "=", "ModelCatalog", ".", "get", "(", "path", "[", "len", "(", "self", ".", "PREFIX", ")", ":", "]", ")", "\n", "logger", ".", "info", "(", "\"Catalog entry {} points to {}\"", ".", "format", "(", "path", ",", "catalog_path", ")", ")", "\n", "return", "PathManager", ".", "get_local_path", "(", "catalog_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalogHandler._open": [[111, 113], ["detectron2.utils.file_io.PathManager.open", "catalog.ModelCatalogHandler._get_local_path"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.catalog.ModelCatalogHandler._get_local_path"], ["", "def", "_open", "(", "self", ",", "path", ",", "mode", "=", "\"r\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "self", ".", "_get_local_path", "(", "path", ")", ",", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.detection_checkpoint.DetectionCheckpointer.__init__": [[17, 26], ["detectron2.is_main_process", "fvcore.common.checkpoint.Checkpointer.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "save_dir", "=", "\"\"", ",", "*", ",", "save_to_disk", "=", "None", ",", "**", "checkpointables", ")", ":", "\n", "        ", "is_main_process", "=", "comm", ".", "is_main_process", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "\n", "save_dir", ",", "\n", "save_to_disk", "=", "is_main_process", "if", "save_to_disk", "is", "None", "else", "save_to_disk", ",", "\n", "**", "checkpointables", ",", "\n", ")", "\n", "self", ".", "path_manager", "=", "PathManager", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file": [[27, 47], ["filename.endswith", "super()._load_file", "detectron2.utils.file_io.PathManager.open", "pickle.load", "detection_checkpoint.DetectionCheckpointer.logger.info", "pickle.load.items", "k.endswith"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file"], ["", "def", "_load_file", "(", "self", ",", "filename", ")", ":", "\n", "        ", "if", "filename", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "if", "\"model\"", "in", "data", "and", "\"__author__\"", "in", "data", ":", "\n", "# file is in Detectron2 model zoo format", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"Reading a file from '{}'\"", ".", "format", "(", "data", "[", "\"__author__\"", "]", ")", ")", "\n", "return", "data", "\n", "", "else", ":", "\n", "# assume file is from Caffe2 / Detectron1 model zoo", "\n", "                ", "if", "\"blobs\"", "in", "data", ":", "\n", "# Detection models have \"blobs\", but ImageNet models don't", "\n", "                    ", "data", "=", "data", "[", "\"blobs\"", "]", "\n", "", "data", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", "if", "not", "k", ".", "endswith", "(", "\"_momentum\"", ")", "}", "\n", "return", "{", "\"model\"", ":", "data", ",", "\"__author__\"", ":", "\"Caffe2\"", ",", "\"matching_heuristics\"", ":", "True", "}", "\n", "\n", "", "", "loaded", "=", "super", "(", ")", ".", "_load_file", "(", "filename", ")", "# load native pth checkpoint", "\n", "if", "\"model\"", "not", "in", "loaded", ":", "\n", "            ", "loaded", "=", "{", "\"model\"", ":", "loaded", "}", "\n", "", "return", "loaded", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.detection_checkpoint.DetectionCheckpointer._load_model": [[48, 71], ["checkpoint.get", "super()._load_model", "dict", "detection_checkpoint.DetectionCheckpointer._convert_ndarray_to_tensor", "c2_model_loading.align_and_update_state_dicts", "detection_checkpoint.DetectionCheckpointer.model.named_buffers", "detection_checkpoint.DetectionCheckpointer.model.state_dict", "super()._load_model.missing_keys.remove", "checkpoint.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.detection_checkpoint.DetectionCheckpointer._load_model", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.align_and_update_state_dicts", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_load_model", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "if", "checkpoint", ".", "get", "(", "\"matching_heuristics\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "_convert_ndarray_to_tensor", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "# convert weights by name-matching heuristics", "\n", "checkpoint", "[", "\"model\"", "]", "=", "align_and_update_state_dicts", "(", "\n", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "checkpoint", "[", "\"model\"", "]", ",", "\n", "c2_conversion", "=", "checkpoint", ".", "get", "(", "\"__author__\"", ",", "None", ")", "==", "\"Caffe2\"", ",", "\n", ")", "\n", "# for non-caffe2 models, use standard ways to load it", "\n", "", "incompatible", "=", "super", "(", ")", ".", "_load_model", "(", "checkpoint", ")", "\n", "\n", "model_buffers", "=", "dict", "(", "self", ".", "model", ".", "named_buffers", "(", "recurse", "=", "False", ")", ")", "\n", "for", "k", "in", "[", "\"pixel_mean\"", ",", "\"pixel_std\"", "]", ":", "\n", "# Ignore missing key message about pixel_mean/std.", "\n", "# Though they may be missing in old checkpoints, they will be correctly", "\n", "# initialized from config anyway.", "\n", "            ", "if", "k", "in", "model_buffers", ":", "\n", "                ", "try", ":", "\n", "                    ", "incompatible", ".", "missing_keys", ".", "remove", "(", "k", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "", "", "", "return", "incompatible", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.convert_basic_c2_names": [[10, 64], ["copy.deepcopy", "k.replace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "k.replace", "k.replace", "k.replace", "k.replace", "re.sub", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["def", "convert_basic_c2_names", "(", "original_keys", ")", ":", "\n", "    ", "\"\"\"\n    Apply some basic name conversion to names in C2 weights.\n    It only deals with typical backbone models.\n\n    Args:\n        original_keys (list[str]):\n    Returns:\n        list[str]: The same number of strings matching those in original_keys.\n    \"\"\"", "\n", "layer_keys", "=", "copy", ".", "deepcopy", "(", "original_keys", ")", "\n", "layer_keys", "=", "[", "\n", "{", "\"pred_b\"", ":", "\"linear_b\"", ",", "\"pred_w\"", ":", "\"linear_w\"", "}", ".", "get", "(", "k", ",", "k", ")", "for", "k", "in", "layer_keys", "\n", "]", "# some hard-coded mappings", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"\\\\.b$\"", ",", "\".bias\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"\\\\.w$\"", ",", "\".weight\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "# Uniform both bn and gn names to \"norm\"", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.s$\"", ",", "\"norm.weight\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.bias$\"", ",", "\"norm.bias\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.rm\"", ",", "\"norm.running_mean\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.running.mean$\"", ",", "\"norm.running_mean\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.riv$\"", ",", "\"norm.running_var\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.running.var$\"", ",", "\"norm.running_var\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.gamma$\"", ",", "\"norm.weight\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"bn\\\\.beta$\"", ",", "\"norm.bias\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"gn\\\\.s$\"", ",", "\"norm.weight\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"gn\\\\.bias$\"", ",", "\"norm.bias\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# stem", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^res\\\\.conv1\\\\.norm\\\\.\"", ",", "\"conv1.norm.\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "# to avoid mis-matching with \"conv1\" in other components (e.g. detection head)", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^conv1\\\\.\"", ",", "\"stem.conv1.\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# layer1-4 is used by torchvision, however we follow the C2 naming strategy (res2-5)", "\n", "# layer_keys = [re.sub(\"^res2.\", \"layer1.\", k) for k in layer_keys]", "\n", "# layer_keys = [re.sub(\"^res3.\", \"layer2.\", k) for k in layer_keys]", "\n", "# layer_keys = [re.sub(\"^res4.\", \"layer3.\", k) for k in layer_keys]", "\n", "# layer_keys = [re.sub(\"^res5.\", \"layer4.\", k) for k in layer_keys]", "\n", "\n", "# blocks", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch1.\"", ",", "\".shortcut.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2a.\"", ",", "\".conv1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2b.\"", ",", "\".conv2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2c.\"", ",", "\".conv3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# DensePose substitutions", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^body.conv.fcn\"", ",", "\"body_conv_fcn\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"AnnIndex.lowres\"", ",", "\"ann_index_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"Index.UV.lowres\"", ",", "\"index_uv_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"U.lowres\"", ",", "\"u_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"V.lowres\"", ",", "\"v_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "return", "layer_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.convert_c2_detectron_names": [[66, 205], ["logging.getLogger", "logging.getLogger.info", "sorted", "copy.deepcopy", "c2_model_loading.convert_basic_c2_names", "zip", "weights.keys", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "name.split", "name.startswith", "c2_model_loading.convert_c2_detectron_names.fpn_map"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.convert_basic_c2_names"], ["", "def", "convert_c2_detectron_names", "(", "weights", ")", ":", "\n", "    ", "\"\"\"\n    Map Caffe2 Detectron weight names to Detectron2 names.\n\n    Args:\n        weights (dict): name -> tensor\n\n    Returns:\n        dict: detectron2 names -> tensor\n        dict: detectron2 names -> C2 names\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Renaming Caffe2 weights ......\"", ")", "\n", "original_keys", "=", "sorted", "(", "weights", ".", "keys", "(", ")", ")", "\n", "layer_keys", "=", "copy", ".", "deepcopy", "(", "original_keys", ")", "\n", "\n", "layer_keys", "=", "convert_basic_c2_names", "(", "layer_keys", ")", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# RPN hidden representation conv", "\n", "# --------------------------------------------------------------------------", "\n", "# FPN case", "\n", "# In the C2 model, the RPN hidden layer conv is defined for FPN level 2 and then", "\n", "# shared for all other levels, hence the appearance of \"fpn2\"", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"conv.rpn.fpn2\"", ",", "\"proposal_generator.rpn_head.conv\"", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "# Non-FPN case", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.rpn\"", ",", "\"proposal_generator.rpn_head.conv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# RPN box transformation conv", "\n", "# --------------------------------------------------------------------------", "\n", "# FPN case (see note above about \"fpn2\")", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.bbox.pred.fpn2\"", ",", "\"proposal_generator.rpn_head.anchor_deltas\"", ")", "\n", "for", "k", "in", "layer_keys", "\n", "]", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.cls.logits.fpn2\"", ",", "\"proposal_generator.rpn_head.objectness_logits\"", ")", "\n", "for", "k", "in", "layer_keys", "\n", "]", "\n", "# Non-FPN case", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.bbox.pred\"", ",", "\"proposal_generator.rpn_head.anchor_deltas\"", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.cls.logits\"", ",", "\"proposal_generator.rpn_head.objectness_logits\"", ")", "\n", "for", "k", "in", "layer_keys", "\n", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# Fast R-CNN box head", "\n", "# --------------------------------------------------------------------------", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^bbox\\\\.pred\"", ",", "\"bbox_pred\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^cls\\\\.score\"", ",", "\"cls_score\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^fc6\\\\.\"", ",", "\"box_head.fc1.\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^fc7\\\\.\"", ",", "\"box_head.fc2.\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "# 4conv1fc head tensor names: head_conv1_w, head_conv1_gn_s", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^head\\\\.conv\"", ",", "\"box_head.conv\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# FPN lateral and output convolutions", "\n", "# --------------------------------------------------------------------------", "\n", "def", "fpn_map", "(", "name", ")", ":", "\n", "        ", "\"\"\"\n        Look for keys with the following patterns:\n        1) Starts with \"fpn.inner.\"\n           Example: \"fpn.inner.res2.2.sum.lateral.weight\"\n           Meaning: These are lateral pathway convolutions\n        2) Starts with \"fpn.res\"\n           Example: \"fpn.res2.2.sum.weight\"\n           Meaning: These are FPN output convolutions\n        \"\"\"", "\n", "splits", "=", "name", ".", "split", "(", "\".\"", ")", "\n", "norm", "=", "\".norm\"", "if", "\"norm\"", "in", "splits", "else", "\"\"", "\n", "if", "name", ".", "startswith", "(", "\"fpn.inner.\"", ")", ":", "\n", "# splits example: ['fpn', 'inner', 'res2', '2', 'sum', 'lateral', 'weight']", "\n", "            ", "stage", "=", "int", "(", "splits", "[", "2", "]", "[", "len", "(", "\"res\"", ")", ":", "]", ")", "\n", "return", "\"fpn_lateral{}{}.{}\"", ".", "format", "(", "stage", ",", "norm", ",", "splits", "[", "-", "1", "]", ")", "\n", "", "elif", "name", ".", "startswith", "(", "\"fpn.res\"", ")", ":", "\n", "# splits example: ['fpn', 'res2', '2', 'sum', 'weight']", "\n", "            ", "stage", "=", "int", "(", "splits", "[", "1", "]", "[", "len", "(", "\"res\"", ")", ":", "]", ")", "\n", "return", "\"fpn_output{}{}.{}\"", ".", "format", "(", "stage", ",", "norm", ",", "splits", "[", "-", "1", "]", ")", "\n", "", "return", "name", "\n", "\n", "", "layer_keys", "=", "[", "fpn_map", "(", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# Mask R-CNN mask head", "\n", "# --------------------------------------------------------------------------", "\n", "# roi_heads.StandardROIHeads case", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".[mask].fcn\"", ",", "\"mask_head.mask_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "re", ".", "sub", "(", "\"^\\\\.mask\\\\.fcn\"", ",", "\"mask_head.mask_fcn\"", ",", "k", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"mask.fcn.logits\"", ",", "\"mask_head.predictor\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "# roi_heads.Res5ROIHeads case", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv5.mask\"", ",", "\"mask_head.deconv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# Keypoint R-CNN head", "\n", "# --------------------------------------------------------------------------", "\n", "# interestingly, the keypoint head convs have blob names that are simply \"conv_fcnX\"", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.fcn\"", ",", "\"roi_heads.keypoint_head.conv_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"kps.score.lowres\"", ",", "\"roi_heads.keypoint_head.score_lowres\"", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"kps.score.\"", ",", "\"roi_heads.keypoint_head.score.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# --------------------------------------------------------------------------", "\n", "# Done with replacements", "\n", "# --------------------------------------------------------------------------", "\n", "assert", "len", "(", "set", "(", "layer_keys", ")", ")", "==", "len", "(", "layer_keys", ")", "\n", "assert", "len", "(", "original_keys", ")", "==", "len", "(", "layer_keys", ")", "\n", "\n", "new_weights", "=", "{", "}", "\n", "new_keys_to_original_keys", "=", "{", "}", "\n", "for", "orig", ",", "renamed", "in", "zip", "(", "original_keys", ",", "layer_keys", ")", ":", "\n", "        ", "new_keys_to_original_keys", "[", "renamed", "]", "=", "orig", "\n", "if", "renamed", ".", "startswith", "(", "\"bbox_pred.\"", ")", "or", "renamed", ".", "startswith", "(", "\"mask_head.predictor.\"", ")", ":", "\n", "# remove the meaningless prediction weight for background class", "\n", "            ", "new_start_idx", "=", "4", "if", "renamed", ".", "startswith", "(", "\"bbox_pred.\"", ")", "else", "1", "\n", "new_weights", "[", "renamed", "]", "=", "weights", "[", "orig", "]", "[", "new_start_idx", ":", "]", "\n", "logger", ".", "info", "(", "\n", "\"Remove prediction weight for background class in {}. The shape changes from \"", "\n", "\"{} to {}.\"", ".", "format", "(", "\n", "renamed", ",", "tuple", "(", "weights", "[", "orig", "]", ".", "shape", ")", ",", "tuple", "(", "new_weights", "[", "renamed", "]", ".", "shape", ")", "\n", ")", "\n", ")", "\n", "", "elif", "renamed", ".", "startswith", "(", "\"cls_score.\"", ")", ":", "\n", "# move weights of bg class from original index 0 to last index", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Move classification weights for background class in {} from index 0 to \"", "\n", "\"index {}.\"", ".", "format", "(", "renamed", ",", "weights", "[", "orig", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "\n", ")", "\n", "new_weights", "[", "renamed", "]", "=", "torch", ".", "cat", "(", "[", "weights", "[", "orig", "]", "[", "1", ":", "]", ",", "weights", "[", "orig", "]", "[", ":", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_weights", "[", "renamed", "]", "=", "weights", "[", "orig", "]", "\n", "\n", "", "", "return", "new_weights", ",", "new_keys_to_original_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.align_and_update_state_dicts": [[209, 335], ["sorted", "sorted", "torch.as_tensor().view", "torch.as_tensor().view.max", "logging.getLogger", "enumerate", "sorted", "c2_model_loading._longest_common_prefix", "c2_model_loading._group_keys_by_module", "set", "tabulate.tabulate", "logging.getLogger.info", "model_state_dict.keys", "c2_model_loading.convert_c2_detectron_names", "ckpt_state_dict.keys", "len", "len", "idxs.tolist", "matched_keys.values", "len", "logging.getLogger.warning", "a.endswith", "c2_model_loading.align_and_update_state_dicts.match"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._longest_common_prefix", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._group_keys_by_module", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading.convert_c2_detectron_names"], ["", "def", "align_and_update_state_dicts", "(", "model_state_dict", ",", "ckpt_state_dict", ",", "c2_conversion", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Match names between the two state-dict, and returns a new chkpt_state_dict with names\n    converted to match model_state_dict with heuristics. The returned dict can be later\n    loaded with fvcore checkpointer.\n    If `c2_conversion==True`, `ckpt_state_dict` is assumed to be a Caffe2\n    model and will be renamed at first.\n\n    Strategy: suppose that the models that we will create will have prefixes appended\n    to each of its keys, for example due to an extra level of nesting that the original\n    pre-trained weights from ImageNet won't contain. For example, model.state_dict()\n    might return backbone[0].body.res2.conv1.weight, while the pre-trained model contains\n    res2.conv1.weight. We thus want to match both parameters together.\n    For that, we look for each model weight, look among all loaded keys if there is one\n    that is a suffix of the current weight name, and use it if that's the case.\n    If multiple matches exist, take the one with longest size\n    of the corresponding name. For example, for the same model as before, the pretrained\n    weight file can contain both res2.conv1.weight, as well as conv1.weight. In this case,\n    we want to match backbone[0].body.conv1.weight to conv1.weight, and\n    backbone[0].body.res2.conv1.weight to res2.conv1.weight.\n    \"\"\"", "\n", "model_keys", "=", "sorted", "(", "model_state_dict", ".", "keys", "(", ")", ")", "\n", "if", "c2_conversion", ":", "\n", "        ", "ckpt_state_dict", ",", "original_keys", "=", "convert_c2_detectron_names", "(", "ckpt_state_dict", ")", "\n", "# original_keys: the name in the original dict (before renaming)", "\n", "", "else", ":", "\n", "        ", "original_keys", "=", "{", "x", ":", "x", "for", "x", "in", "ckpt_state_dict", ".", "keys", "(", ")", "}", "\n", "", "ckpt_keys", "=", "sorted", "(", "ckpt_state_dict", ".", "keys", "(", ")", ")", "\n", "\n", "def", "match", "(", "a", ",", "b", ")", ":", "\n", "# Matched ckpt_key should be a complete (starts with '.') suffix.", "\n", "# For example, roi_heads.mesh_head.whatever_conv1 does not match conv1,", "\n", "# but matches whatever_conv1 or mesh_head.whatever_conv1.", "\n", "        ", "return", "a", "==", "b", "or", "a", ".", "endswith", "(", "\".\"", "+", "b", ")", "\n", "\n", "# get a matrix of string matches, where each (i, j) entry correspond to the size of the", "\n", "# ckpt_key string, if it matches", "\n", "", "match_matrix", "=", "[", "len", "(", "j", ")", "if", "match", "(", "i", ",", "j", ")", "else", "0", "for", "i", "in", "model_keys", "for", "j", "in", "ckpt_keys", "]", "\n", "match_matrix", "=", "torch", ".", "as_tensor", "(", "match_matrix", ")", ".", "view", "(", "len", "(", "model_keys", ")", ",", "len", "(", "ckpt_keys", ")", ")", "\n", "# use the matched one with longest size in case of multiple matches", "\n", "max_match_size", ",", "idxs", "=", "match_matrix", ".", "max", "(", "1", ")", "\n", "# remove indices that correspond to no-match", "\n", "idxs", "[", "max_match_size", "==", "0", "]", "=", "-", "1", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "# matched_pairs (matched checkpoint key --> matched model key)", "\n", "matched_keys", "=", "{", "}", "\n", "result_state_dict", "=", "{", "}", "\n", "for", "idx_model", ",", "idx_ckpt", "in", "enumerate", "(", "idxs", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "if", "idx_ckpt", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "key_model", "=", "model_keys", "[", "idx_model", "]", "\n", "key_ckpt", "=", "ckpt_keys", "[", "idx_ckpt", "]", "\n", "value_ckpt", "=", "ckpt_state_dict", "[", "key_ckpt", "]", "\n", "shape_in_model", "=", "model_state_dict", "[", "key_model", "]", ".", "shape", "\n", "\n", "if", "shape_in_model", "!=", "value_ckpt", ".", "shape", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Shape of {} in checkpoint is {}, while shape of {} in model is {}.\"", ".", "format", "(", "\n", "key_ckpt", ",", "value_ckpt", ".", "shape", ",", "key_model", ",", "shape_in_model", "\n", ")", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"{} will not be loaded. Please double check and see if this is desired.\"", ".", "format", "(", "\n", "key_ckpt", "\n", ")", "\n", ")", "\n", "continue", "\n", "\n", "", "assert", "key_model", "not", "in", "result_state_dict", "\n", "result_state_dict", "[", "key_model", "]", "=", "value_ckpt", "\n", "if", "key_ckpt", "in", "matched_keys", ":", "# already added to matched_keys", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Ambiguity found for {} in checkpoint!\"", "\n", "\"It matches at least two keys in the model ({} and {}).\"", ".", "format", "(", "\n", "key_ckpt", ",", "key_model", ",", "matched_keys", "[", "key_ckpt", "]", "\n", ")", "\n", ")", "\n", "raise", "ValueError", "(", "\"Cannot match one checkpoint key to multiple keys in the model.\"", ")", "\n", "\n", "", "matched_keys", "[", "key_ckpt", "]", "=", "key_model", "\n", "\n", "# logging:", "\n", "", "matched_model_keys", "=", "sorted", "(", "matched_keys", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "matched_model_keys", ")", "==", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\"No weights in checkpoint matched with model.\"", ")", "\n", "return", "ckpt_state_dict", "\n", "", "common_prefix", "=", "_longest_common_prefix", "(", "matched_model_keys", ")", "\n", "rev_matched_keys", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "matched_keys", ".", "items", "(", ")", "}", "\n", "original_keys", "=", "{", "k", ":", "original_keys", "[", "rev_matched_keys", "[", "k", "]", "]", "for", "k", "in", "matched_model_keys", "}", "\n", "\n", "model_key_groups", "=", "_group_keys_by_module", "(", "matched_model_keys", ",", "original_keys", ")", "\n", "table", "=", "[", "]", "\n", "memo", "=", "set", "(", ")", "\n", "for", "key_model", "in", "matched_model_keys", ":", "\n", "        ", "if", "key_model", "in", "memo", ":", "\n", "            ", "continue", "\n", "", "if", "key_model", "in", "model_key_groups", ":", "\n", "            ", "group", "=", "model_key_groups", "[", "key_model", "]", "\n", "memo", "|=", "set", "(", "group", ")", "\n", "shapes", "=", "[", "tuple", "(", "model_state_dict", "[", "k", "]", ".", "shape", ")", "for", "k", "in", "group", "]", "\n", "table", ".", "append", "(", "\n", "(", "\n", "_longest_common_prefix", "(", "[", "k", "[", "len", "(", "common_prefix", ")", ":", "]", "for", "k", "in", "group", "]", ")", "+", "\"*\"", ",", "\n", "_group_str", "(", "[", "original_keys", "[", "k", "]", "for", "k", "in", "group", "]", ")", ",", "\n", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", ".", "replace", "(", "\" \"", ",", "\"\"", ")", "for", "x", "in", "shapes", "]", ")", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "key_checkpoint", "=", "original_keys", "[", "key_model", "]", "\n", "shape", "=", "str", "(", "tuple", "(", "model_state_dict", "[", "key_model", "]", ".", "shape", ")", ")", "\n", "table", ".", "append", "(", "(", "key_model", "[", "len", "(", "common_prefix", ")", ":", "]", ",", "key_checkpoint", ",", "shape", ")", ")", "\n", "", "", "table_str", "=", "tabulate", "(", "\n", "table", ",", "tablefmt", "=", "\"pipe\"", ",", "headers", "=", "[", "\"Names in Model\"", ",", "\"Names in Checkpoint\"", ",", "\"Shapes\"", "]", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Following weights matched with \"", "\n", "+", "(", "f\"submodule {common_prefix[:-1]}\"", "if", "common_prefix", "else", "\"model\"", ")", "\n", "+", "\":\\n\"", "\n", "+", "table_str", "\n", ")", "\n", "\n", "unmatched_ckpt_keys", "=", "[", "k", "for", "k", "in", "ckpt_keys", "if", "k", "not", "in", "set", "(", "matched_keys", ".", "keys", "(", ")", ")", "]", "\n", "for", "k", "in", "unmatched_ckpt_keys", ":", "\n", "        ", "result_state_dict", "[", "k", "]", "=", "ckpt_state_dict", "[", "k", "]", "\n", "", "return", "result_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._group_keys_by_module": [[337, 375], ["sorted", "key.rfind", "c2_model_loading._group_keys_by_module._submodule_name"], "function", ["None"], ["", "def", "_group_keys_by_module", "(", "keys", ":", "List", "[", "str", "]", ",", "original_names", ":", "Dict", "[", "str", ",", "str", "]", ")", ":", "\n", "    ", "\"\"\"\n    Params in the same submodule are grouped together.\n\n    Args:\n        keys: names of all parameters\n        original_names: mapping from parameter name to their name in the checkpoint\n\n    Returns:\n        dict[name -> all other names in the same group]\n    \"\"\"", "\n", "\n", "def", "_submodule_name", "(", "key", ")", ":", "\n", "        ", "pos", "=", "key", ".", "rfind", "(", "\".\"", ")", "\n", "if", "pos", "<", "0", ":", "\n", "            ", "return", "None", "\n", "", "prefix", "=", "key", "[", ":", "pos", "+", "1", "]", "\n", "return", "prefix", "\n", "\n", "", "all_submodules", "=", "[", "_submodule_name", "(", "k", ")", "for", "k", "in", "keys", "]", "\n", "all_submodules", "=", "[", "x", "for", "x", "in", "all_submodules", "if", "x", "]", "\n", "all_submodules", "=", "sorted", "(", "all_submodules", ",", "key", "=", "len", ")", "\n", "\n", "ret", "=", "{", "}", "\n", "for", "prefix", "in", "all_submodules", ":", "\n", "        ", "group", "=", "[", "k", "for", "k", "in", "keys", "if", "k", ".", "startswith", "(", "prefix", ")", "]", "\n", "if", "len", "(", "group", ")", "<=", "1", ":", "\n", "            ", "continue", "\n", "", "original_name_lcp", "=", "_longest_common_prefix_str", "(", "[", "original_names", "[", "k", "]", "for", "k", "in", "group", "]", ")", "\n", "if", "len", "(", "original_name_lcp", ")", "==", "0", ":", "\n", "# don't group weights if original names don't share prefix", "\n", "            ", "continue", "\n", "\n", "", "for", "k", "in", "group", ":", "\n", "            ", "if", "k", "in", "ret", ":", "\n", "                ", "continue", "\n", "", "ret", "[", "k", "]", "=", "group", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._longest_common_prefix": [[377, 386], ["n.split", "min", "max", "len", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_longest_common_prefix", "(", "names", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    [\"abc.zfg\", \"abc.zef\"] -> \"abc.\"\n    \"\"\"", "\n", "names", "=", "[", "n", ".", "split", "(", "\".\"", ")", "for", "n", "in", "names", "]", "\n", "m1", ",", "m2", "=", "min", "(", "names", ")", ",", "max", "(", "names", ")", "\n", "ret", "=", "[", "a", "for", "a", ",", "b", "in", "zip", "(", "m1", ",", "m2", ")", "if", "a", "==", "b", "]", "\n", "ret", "=", "\".\"", ".", "join", "(", "ret", ")", "+", "\".\"", "if", "len", "(", "ret", ")", "else", "\"\"", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._longest_common_prefix_str": [[388, 393], ["min", "max", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_longest_common_prefix_str", "(", "names", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "    ", "m1", ",", "m2", "=", "min", "(", "names", ")", ",", "max", "(", "names", ")", "\n", "lcp", "=", "[", "a", "for", "a", ",", "b", "in", "zip", "(", "m1", ",", "m2", ")", "if", "a", "==", "b", "]", "\n", "lcp", "=", "\"\"", ".", "join", "(", "lcp", ")", "\n", "return", "lcp", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._group_str": [[395, 408], ["c2_model_loading._longest_common_prefix_str", "ret.replace.replace", "ret.replace.replace", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.checkpoint.c2_model_loading._longest_common_prefix_str"], ["", "def", "_group_str", "(", "names", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Turn \"common1\", \"common2\", \"common3\" into \"common{1,2,3}\"\n    \"\"\"", "\n", "lcp", "=", "_longest_common_prefix_str", "(", "names", ")", "\n", "rest", "=", "[", "x", "[", "len", "(", "lcp", ")", ":", "]", "for", "x", "in", "names", "]", "\n", "rest", "=", "\"{\"", "+", "\",\"", ".", "join", "(", "rest", ")", "+", "\"}\"", "\n", "ret", "=", "lcp", "+", "rest", "\n", "\n", "# add some simplification for BN specifically", "\n", "ret", "=", "ret", ".", "replace", "(", "\"bn_{beta,running_mean,running_var,gamma}\"", ",", "\"bn_*\"", ")", "\n", "ret", "=", "ret", ".", "replace", "(", "\"bn_beta,bn_running_mean,bn_running_var,bn_gamma\"", ",", "\"bn_*\"", ")", "\n", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_checkpoint_url": [[86, 102], ["config_path.replace", "RuntimeError"], "function", ["None"], ["", "def", "get_checkpoint_url", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Returns the URL to the model trained using the given config\n\n    Args:\n        config_path (str): config file name relative to detectron2's \"configs/\"\n            directory, e.g., \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n\n    Returns:\n        str: a URL to the model\n    \"\"\"", "\n", "name", "=", "config_path", ".", "replace", "(", "\".yaml\"", ",", "\"\"", ")", "\n", "if", "config_path", "in", "_ModelZooUrls", ".", "CONFIG_PATH_TO_URL_SUFFIX", ":", "\n", "        ", "suffix", "=", "_ModelZooUrls", ".", "CONFIG_PATH_TO_URL_SUFFIX", "[", "config_path", "]", "\n", "return", "_ModelZooUrls", ".", "S3_PREFIX", "+", "name", "+", "\"/\"", "+", "suffix", "\n", "", "raise", "RuntimeError", "(", "\"{} not available in Model Zoo!\"", ".", "format", "(", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_config_file": [[104, 121], ["pkg_resources.resource_filename", "os.path.join", "os.path.exists", "RuntimeError"], "function", ["None"], ["", "def", "get_config_file", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Returns path to a builtin config file.\n\n    Args:\n        config_path (str): config file name relative to detectron2's \"configs/\"\n            directory, e.g., \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n\n    Returns:\n        str: the real path to the config file.\n    \"\"\"", "\n", "cfg_file", "=", "pkg_resources", ".", "resource_filename", "(", "\n", "\"detectron2.model_zoo\"", ",", "os", ".", "path", ".", "join", "(", "\"configs\"", ",", "config_path", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg_file", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"{} not available in Model Zoo!\"", ".", "format", "(", "config_path", ")", ")", "\n", "", "return", "cfg_file", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_config": [[123, 144], ["model_zoo.get_config_file", "detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "model_zoo.get_checkpoint_url"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_config_file", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.get_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_checkpoint_url"], ["", "def", "get_config", "(", "config_path", ",", "trained", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Returns a config object for a model in model zoo.\n\n    Args:\n        config_path (str): config file name relative to detectron2's \"configs/\"\n            directory, e.g., \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n        trained (bool): If True, will set ``MODEL.WEIGHTS`` to trained model zoo weights.\n            If False, the checkpoint specified in the config file's ``MODEL.WEIGHTS`` is used\n            instead; this will typically (though not always) initialize a subset of weights using\n            an ImageNet pre-trained model, while randomly initializing the other weights.\n\n    Returns:\n        CfgNode: a config object\n    \"\"\"", "\n", "cfg_file", "=", "get_config_file", "(", "config_path", ")", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "cfg_file", ")", "\n", "if", "trained", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "WEIGHTS", "=", "get_checkpoint_url", "(", "config_path", ")", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get": [[146, 173], ["model_zoo.get_config", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "torch.cuda.is_available", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.model_zoo.model_zoo.get_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model"], ["", "def", "get", "(", "config_path", ",", "trained", ":", "bool", "=", "False", ",", "device", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Get a model specified by relative path under Detectron2's official ``configs/`` directory.\n\n    Args:\n        config_path (str): config file name relative to detectron2's \"configs/\"\n            directory, e.g., \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n        trained (bool): see :func:`get_config`.\n        device (str or None): overwrite the device in config, if given.\n\n    Returns:\n        nn.Module: a detectron2 model. Will be in training mode.\n\n    Example:\n    ::\n        from detectron2 import model_zoo\n        model = model_zoo.get(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\", trained=True)\n    \"\"\"", "\n", "cfg", "=", "get_config", "(", "config_path", ",", "trained", ")", "\n", "if", "device", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "device", "\n", "", "elif", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "\n", "", "model", "=", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript.scripting_with_instances": [[14, 59], ["torchscript_patch.freeze_training_mode", "torchscript_patch.patch_instances", "torch.jit.script"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.freeze_training_mode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.patch_instances"], ["def", "scripting_with_instances", "(", "model", ",", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Run :func:`torch.jit.script` on a model that uses the :class:`Instances` class. Since\n    attributes of :class:`Instances` are \"dynamically\" added in eager mode\uff0cit is difficult\n    for scripting to support it out of the box. This function is made to support scripting\n    a model that uses :class:`Instances`. It does the following:\n\n    1. Create a scriptable ``new_Instances`` class which behaves similarly to ``Instances``,\n       but with all attributes been \"static\".\n       The attributes need to be statically declared in the ``fields`` argument.\n    2. Register ``new_Instances``, and force scripting compiler to\n       use it when trying to compile ``Instances``.\n\n    After this function, the process will be reverted. User should be able to script another model\n    using different fields.\n\n    Example:\n        Assume that ``Instances`` in the model consist of two attributes named\n        ``proposal_boxes`` and ``objectness_logits`` with type :class:`Boxes` and\n        :class:`Tensor` respectively during inference. You can call this function like:\n        ::\n            fields = {\"proposal_boxes\": Boxes, \"objectness_logits\": torch.Tensor}\n            torchscipt_model =  scripting_with_instances(model, fields)\n\n    Note:\n        It only support models in evaluation mode.\n\n    Args:\n        model (nn.Module): The input model to be exported by scripting.\n        fields (Dict[str, type]): Attribute names and corresponding type that\n            ``Instances`` will use in the model. Note that all attributes used in ``Instances``\n            need to be added, regardless of whether they are inputs/outputs of the model.\n            Data type not defined in detectron2 is not supported for now.\n\n    Returns:\n        torch.jit.ScriptModule: the model in torchscript format\n    \"\"\"", "\n", "assert", "TORCH_VERSION", ">=", "(", "1", ",", "8", ")", ",", "\"This feature is not available in PyTorch < 1.8\"", "\n", "assert", "(", "\n", "not", "model", ".", "training", "\n", ")", ",", "\"Currently we only support exporting models in evaluation mode to torchscript\"", "\n", "\n", "with", "freeze_training_mode", "(", "model", ")", ",", "patch_instances", "(", "fields", ")", ":", "\n", "        ", "scripted_model", "=", "torch", ".", "jit", ".", "script", "(", "model", ")", "\n", "return", "scripted_model", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript.dump_torchscript_IR": [[65, 128], ["detectron2.utils.file_io.PathManager.mkdirs", "isinstance", "detectron2.utils.file_io.PathManager.open", "torchscript.dump_torchscript_IR.dump_code"], "function", ["None"], ["def", "dump_torchscript_IR", "(", "model", ",", "dir", ")", ":", "\n", "    ", "\"\"\"\n    Dump IR of a TracedModule/ScriptModule at various levels.\n    Useful for debugging.\n\n    Args:\n        model (TracedModule or ScriptModule): traced or scripted module\n        dir (str): output directory to dump files.\n    \"\"\"", "\n", "# TODO: support ScriptFunction as well", "\n", "PathManager", ".", "mkdirs", "(", "dir", ")", "\n", "\n", "def", "_get_script_mod", "(", "mod", ")", ":", "\n", "        ", "if", "isinstance", "(", "mod", ",", "torch", ".", "jit", ".", "TracedModule", ")", ":", "\n", "            ", "return", "mod", ".", "_actual_script_module", "\n", "", "return", "mod", "\n", "\n", "# Dump pretty-printed code: https://pytorch.org/docs/stable/jit.html#inspecting-code", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_code.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\n", "        ", "def", "get_code", "(", "mod", ")", ":", "\n", "# Try a few ways to get code using private attributes.", "\n", "            ", "try", ":", "\n", "# This contains more information than just `mod.code`", "\n", "                ", "return", "_get_script_mod", "(", "mod", ")", ".", "_c", ".", "code", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "", "try", ":", "\n", "                ", "return", "mod", ".", "code", "\n", "", "except", "AttributeError", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "def", "dump_code", "(", "prefix", ",", "mod", ")", ":", "\n", "            ", "code", "=", "get_code", "(", "mod", ")", "\n", "name", "=", "prefix", "or", "\"root model\"", "\n", "if", "code", "is", "None", ":", "\n", "                ", "f", ".", "write", "(", "f\"Could not found code for {name} (type={mod.original_name})\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "f", ".", "write", "(", "f\"\\nCode for {name}, type={mod.original_name}:\\n\"", ")", "\n", "f", ".", "write", "(", "code", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"-\"", "*", "80", ")", "\n", "\n", "", "for", "name", ",", "m", "in", "mod", ".", "named_children", "(", ")", ":", "\n", "                ", "dump_code", "(", "prefix", "+", "\".\"", "+", "name", ",", "m", ")", "\n", "\n", "", "", "dump_code", "(", "\"\"", ",", "model", ")", "\n", "\n", "# Recursively dump IR of all modules", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_IR.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "try", ":", "\n", "            ", "f", ".", "write", "(", "_get_script_mod", "(", "model", ")", ".", "_c", ".", "dump_to_str", "(", "True", ",", "False", ",", "False", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n", "# Dump IR of the entire graph (all submodules inlined)", "\n", "", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_IR_inlined.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "model", ".", "inlined_graph", ")", ")", "\n", "\n", "# Dump the model structure in pytorch style", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "model", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.ScopedWS.__init__": [[130, 135], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ws_name", ",", "is_reset", ",", "is_cleanup", "=", "False", ")", ":", "\n", "        ", "self", ".", "ws_name", "=", "ws_name", "\n", "self", ".", "is_reset", "=", "is_reset", "\n", "self", ".", "is_cleanup", "=", "is_cleanup", "\n", "self", ".", "org_ws", "=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.ScopedWS.__enter__": [[136, 144], ["caffe2.python.workspace.CurrentWorkspace", "caffe2.python.workspace.SwitchWorkspace", "caffe2.python.workspace.ResetWorkspace"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "org_ws", "=", "workspace", ".", "CurrentWorkspace", "(", ")", "\n", "if", "self", ".", "ws_name", "is", "not", "None", ":", "\n", "            ", "workspace", ".", "SwitchWorkspace", "(", "self", ".", "ws_name", ",", "True", ")", "\n", "", "if", "self", ".", "is_reset", ":", "\n", "            ", "workspace", ".", "ResetWorkspace", "(", ")", "\n", "\n", "", "return", "workspace", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.ScopedWS.__exit__": [[145, 150], ["caffe2.python.workspace.ResetWorkspace", "caffe2.python.workspace.SwitchWorkspace"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "if", "self", ".", "is_cleanup", ":", "\n", "            ", "workspace", ".", "ResetWorkspace", "(", ")", "\n", "", "if", "self", ".", "ws_name", "is", "not", "None", ":", "\n", "            ", "workspace", ".", "SwitchWorkspace", "(", "self", ".", "org_ws", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.__init__": [[785, 788], ["set", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "vertices", "=", "set", "(", ")", "\n", "self", ".", "graph", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.add_edge": [[789, 793], ["shared.DiGraph.graph[].append", "shared.DiGraph.vertices.add", "shared.DiGraph.vertices.add"], "methods", ["None"], ["", "def", "add_edge", "(", "self", ",", "u", ",", "v", ")", ":", "\n", "        ", "self", ".", "graph", "[", "u", "]", ".", "append", "(", "v", ")", "\n", "self", ".", "vertices", ".", "add", "(", "u", ")", "\n", "self", ".", "vertices", ".", "add", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.get_all_paths": [[795, 814], ["shared.DiGraph.get_all_paths._get_all_paths_util"], "methods", ["None"], ["", "def", "get_all_paths", "(", "self", ",", "s", ",", "d", ")", ":", "\n", "        ", "visited", "=", "{", "k", ":", "False", "for", "k", "in", "self", ".", "vertices", "}", "\n", "path", "=", "[", "]", "\n", "all_paths", "=", "[", "]", "\n", "\n", "def", "_get_all_paths_util", "(", "graph", ",", "u", ",", "d", ",", "visited", ",", "path", ")", ":", "\n", "            ", "visited", "[", "u", "]", "=", "True", "\n", "path", ".", "append", "(", "u", ")", "\n", "if", "u", "==", "d", ":", "\n", "                ", "all_paths", ".", "append", "(", "copy", ".", "deepcopy", "(", "path", ")", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "graph", "[", "u", "]", ":", "\n", "                    ", "if", "not", "visited", "[", "i", "]", ":", "\n", "                        ", "_get_all_paths_util", "(", "graph", ",", "i", ",", "d", ",", "visited", ",", "path", ")", "\n", "", "", "", "path", ".", "pop", "(", ")", "\n", "visited", "[", "u", "]", "=", "False", "\n", "\n", "", "_get_all_paths_util", "(", "self", ".", "graph", ",", "s", ",", "d", ",", "visited", ",", "path", ")", "\n", "return", "all_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.from_ssa": [[815, 823], ["shared.DiGraph", "range", "len", "shared.DiGraph.add_edge"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.add_edge"], ["", "@", "staticmethod", "\n", "def", "from_ssa", "(", "ssa", ")", ":", "\n", "        ", "graph", "=", "DiGraph", "(", ")", "\n", "for", "op_id", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "            ", "for", "inp", "in", "ssa", "[", "op_id", "]", "[", "0", "]", ":", "\n", "                ", "for", "outp", "in", "ssa", "[", "op_id", "]", "[", "1", "]", ":", "\n", "                    ", "graph", ".", "add_edge", "(", "inp", ",", "outp", ")", "\n", "", "", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device": [[25, 42], ["torch.device", "torch.device", "torch.ops._caffe2.CopyGPUToCPU", "torch.ops._caffe2.CopyGPUToCPU", "torch.ops._caffe2.CopyCPUToGPU", "torch.ops._caffe2.CopyCPUToGPU", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "to_device", "(", "t", ",", "device_str", ")", ":", "\n", "    ", "\"\"\"\n    This function is a replacement of .to(another_device) such that it allows the\n    casting to be traced properly by explicitly calling the underlying copy ops.\n    It also avoids introducing unncessary op when casting to the same device.\n    \"\"\"", "\n", "src", "=", "t", ".", "device", "\n", "dst", "=", "torch", ".", "device", "(", "device_str", ")", "\n", "\n", "if", "src", "==", "dst", ":", "\n", "        ", "return", "t", "\n", "", "elif", "src", ".", "type", "==", "\"cuda\"", "and", "dst", ".", "type", "==", "\"cpu\"", ":", "\n", "        ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "CopyGPUToCPU", "(", "t", ")", "\n", "", "elif", "src", ".", "type", "==", "\"cpu\"", "and", "dst", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "CopyCPUToGPU", "(", "t", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Can't cast tensor from device {} to device {}\"", ".", "format", "(", "src", ",", "dst", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.BilinearInterpolation": [[48, 77], ["shared.BilinearInterpolation.upsample_filt"], "function", ["None"], ["", "", "def", "BilinearInterpolation", "(", "tensor_in", ",", "up_scale", ")", ":", "\n", "    ", "assert", "up_scale", "%", "2", "==", "0", ",", "\"Scale should be even\"", "\n", "\n", "def", "upsample_filt", "(", "size", ")", ":", "\n", "        ", "factor", "=", "(", "size", "+", "1", ")", "//", "2", "\n", "if", "size", "%", "2", "==", "1", ":", "\n", "            ", "center", "=", "factor", "-", "1", "\n", "", "else", ":", "\n", "            ", "center", "=", "factor", "-", "0.5", "\n", "\n", "", "og", "=", "np", ".", "ogrid", "[", ":", "size", ",", ":", "size", "]", "\n", "return", "(", "1", "-", "abs", "(", "og", "[", "0", "]", "-", "center", ")", "/", "factor", ")", "*", "(", "1", "-", "abs", "(", "og", "[", "1", "]", "-", "center", ")", "/", "factor", ")", "\n", "\n", "", "kernel_size", "=", "int", "(", "up_scale", ")", "*", "2", "\n", "bil_filt", "=", "upsample_filt", "(", "kernel_size", ")", "\n", "\n", "dim", "=", "int", "(", "tensor_in", ".", "shape", "[", "1", "]", ")", "\n", "kernel", "=", "np", ".", "zeros", "(", "(", "dim", ",", "dim", ",", "kernel_size", ",", "kernel_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "kernel", "[", "range", "(", "dim", ")", ",", "range", "(", "dim", ")", ",", ":", ",", ":", "]", "=", "bil_filt", "\n", "\n", "tensor_out", "=", "F", ".", "conv_transpose2d", "(", "\n", "tensor_in", ",", "\n", "weight", "=", "to_device", "(", "torch", ".", "Tensor", "(", "kernel", ")", ",", "tensor_in", ".", "device", ")", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "int", "(", "up_scale", ")", ",", "\n", "padding", "=", "int", "(", "up_scale", "/", "2", ")", ",", "\n", ")", "\n", "\n", "return", "tensor_out", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.onnx_compatibale_interpolate": [[82, 113], ["torch.nn.functional.interpolate", "logger.warning", "input.dim", "isinstance", "isinstance", "torch.ops._caffe2.ResizeNearest", "torch.ops._caffe2.ResizeNearest", "len", "logger.warning", "shared.BilinearInterpolation"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.BilinearInterpolation"], ["", "def", "onnx_compatibale_interpolate", "(", "\n", "input", ",", "size", "=", "None", ",", "scale_factor", "=", "None", ",", "mode", "=", "\"nearest\"", ",", "align_corners", "=", "None", "\n", ")", ":", "\n", "# NOTE: The input dimensions are interpreted in the form:", "\n", "# `mini-batch x channels x [optional depth] x [optional height] x width`.", "\n", "    ", "if", "size", "is", "None", "and", "scale_factor", "is", "not", "None", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "if", "isinstance", "(", "scale_factor", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "height_scale", ",", "width_scale", "=", "(", "scale_factor", ",", "scale_factor", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "scale_factor", ",", "(", "tuple", ",", "list", ")", ")", "\n", "assert", "len", "(", "scale_factor", ")", "==", "2", "\n", "height_scale", ",", "width_scale", "=", "scale_factor", "\n", "\n", "", "assert", "not", "align_corners", ",", "\"No matching C2 op for align_corners == True\"", "\n", "if", "mode", "==", "\"nearest\"", ":", "\n", "                ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "ResizeNearest", "(", "\n", "input", ",", "order", "=", "\"NCHW\"", ",", "width_scale", "=", "width_scale", ",", "height_scale", "=", "height_scale", "\n", ")", "\n", "", "elif", "mode", "==", "\"bilinear\"", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"Use F.conv_transpose2d for bilinear interpolate\"", "\n", "\" because there's no such C2 op, this may cause significant\"", "\n", "\" slowdown and the boundary pixels won't be as same as\"", "\n", "\" using F.interpolate due to padding.\"", "\n", ")", "\n", "assert", "height_scale", "==", "width_scale", "\n", "return", "BilinearInterpolation", "(", "input", ",", "up_scale", "=", "height_scale", ")", "\n", "", "", "logger", ".", "warning", "(", "\"Output size is not static, it might cause ONNX conversion issue\"", ")", "\n", "\n", "", "return", "interp", "(", "input", ",", "size", ",", "scale_factor", ",", "mode", ",", "align_corners", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.mock_torch_nn_functional_interpolate": [[115, 124], ["torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "unittest.mock.patch"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_torch_nn_functional_interpolate", "(", ")", ":", "\n", "    ", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "        ", "with", "mock", ".", "patch", "(", "\n", "\"torch.nn.functional.interpolate\"", ",", "side_effect", "=", "onnx_compatibale_interpolate", "\n", ")", ":", "\n", "            ", "yield", "\n", "", "", "else", ":", "\n", "        ", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.fetch_any_blob": [[152, 162], ["caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchInt8Blob", "logger.error"], "function", ["None"], ["", "", "", "def", "fetch_any_blob", "(", "name", ")", ":", "\n", "    ", "bb", "=", "None", "\n", "try", ":", "\n", "        ", "bb", "=", "workspace", ".", "FetchBlob", "(", "name", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "bb", "=", "workspace", ".", "FetchInt8Blob", "(", "name", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Get blob {} error: {}\"", ".", "format", "(", "name", ",", "e", ")", ")", "\n", "\n", "", "return", "bb", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg": [[167, 172], ["None"], "function", ["None"], ["", "def", "get_pb_arg", "(", "pb", ",", "arg_name", ")", ":", "\n", "    ", "for", "x", "in", "pb", ".", "arg", ":", "\n", "        ", "if", "x", ".", "name", "==", "arg_name", ":", "\n", "            ", "return", "x", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valf": [[174, 177], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_valf", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "f", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_floats": [[179, 182], ["shared.get_pb_arg", "list", "map"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_floats", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "map", "(", "float", ",", "arg", ".", "floats", ")", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_ints": [[184, 187], ["shared.get_pb_arg", "list", "map"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_ints", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "map", "(", "int", ",", "arg", ".", "ints", ")", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali": [[189, 192], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_vali", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "i", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals": [[194, 197], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_vals", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "s", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valstrings": [[199, 202], ["shared.get_pb_arg", "list"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_valstrings", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "arg", ".", "strings", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg": [[204, 219], ["shared.get_pb_arg", "caffe2.MakeArgument", "hasattr", "pb.arg.extend", "logger.warning", "setattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg"], ["", "def", "check_set_pb_arg", "(", "pb", ",", "arg_name", ",", "arg_attr", ",", "arg_value", ",", "allow_override", "=", "False", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "if", "arg", "is", "None", ":", "\n", "        ", "arg", "=", "putils", ".", "MakeArgument", "(", "arg_name", ",", "arg_value", ")", "\n", "assert", "hasattr", "(", "arg", ",", "arg_attr", ")", "\n", "pb", ".", "arg", ".", "extend", "(", "[", "arg", "]", ")", "\n", "", "if", "allow_override", "and", "getattr", "(", "arg", ",", "arg_attr", ")", "!=", "arg_value", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Override argument {}: {} -> {}\"", ".", "format", "(", "arg_name", ",", "getattr", "(", "arg", ",", "arg_attr", ")", ",", "arg_value", ")", "\n", ")", "\n", "setattr", "(", "arg", ",", "arg_attr", ",", "arg_value", ")", "\n", "", "else", ":", "\n", "        ", "assert", "arg", "is", "not", "None", "\n", "assert", "getattr", "(", "arg", ",", "arg_attr", ")", "==", "arg_value", ",", "\"Existing value {}, new value {}\"", ".", "format", "(", "\n", "getattr", "(", "arg", ",", "arg_attr", ")", ",", "arg_value", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._create_const_fill_op_from_numpy": [[222, 241], ["caffe2.python.core.CreateOperator", "type", "numpy.dtype", "numpy.dtype", "numpy.dtype", "numpy.dtype", "numpy.dtype", "args_dict.update", "args_dict.update", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "", "def", "_create_const_fill_op_from_numpy", "(", "name", ",", "tensor", ",", "device_option", "=", "None", ")", ":", "\n", "    ", "assert", "type", "(", "tensor", ")", "==", "np", ".", "ndarray", "\n", "kTypeNameMapper", "=", "{", "\n", "np", ".", "dtype", "(", "\"float32\"", ")", ":", "\"GivenTensorFill\"", ",", "\n", "np", ".", "dtype", "(", "\"int32\"", ")", ":", "\"GivenTensorIntFill\"", ",", "\n", "np", ".", "dtype", "(", "\"int64\"", ")", ":", "\"GivenTensorInt64Fill\"", ",", "\n", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\"GivenTensorStringFill\"", ",", "\n", "}", "\n", "\n", "args_dict", "=", "{", "}", "\n", "if", "tensor", ".", "dtype", "==", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\n", "        ", "args_dict", ".", "update", "(", "{", "\"values\"", ":", "[", "str", "(", "tensor", ".", "data", ")", "]", ",", "\"shape\"", ":", "[", "1", "]", "}", ")", "\n", "", "else", ":", "\n", "        ", "args_dict", ".", "update", "(", "{", "\"values\"", ":", "tensor", ",", "\"shape\"", ":", "tensor", ".", "shape", "}", ")", "\n", "\n", "", "if", "device_option", "is", "not", "None", ":", "\n", "        ", "args_dict", "[", "\"device_option\"", "]", "=", "device_option", "\n", "\n", "", "return", "core", ".", "CreateOperator", "(", "kTypeNameMapper", "[", "tensor", ".", "dtype", "]", ",", "[", "]", ",", "[", "name", "]", ",", "**", "args_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._create_const_fill_op_from_c2_int8_tensor": [[243, 262], ["caffe2.python.core.CreateOperator", "type", "numpy.dtype", "numpy.dtype", "tensor.tobytes", "numpy.dtype", "numpy.dtype", "numpy.dtype"], "function", ["None"], ["", "def", "_create_const_fill_op_from_c2_int8_tensor", "(", "name", ",", "int8_tensor", ")", ":", "\n", "    ", "assert", "type", "(", "int8_tensor", ")", "==", "workspace", ".", "Int8Tensor", "\n", "kTypeNameMapper", "=", "{", "\n", "np", ".", "dtype", "(", "\"int32\"", ")", ":", "\"Int8GivenIntTensorFill\"", ",", "\n", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\"Int8GivenTensorFill\"", ",", "\n", "}", "\n", "\n", "tensor", "=", "int8_tensor", ".", "data", "\n", "assert", "tensor", ".", "dtype", "in", "[", "np", ".", "dtype", "(", "\"uint8\"", ")", ",", "np", ".", "dtype", "(", "\"int32\"", ")", "]", "\n", "values", "=", "tensor", ".", "tobytes", "(", ")", "if", "tensor", ".", "dtype", "==", "np", ".", "dtype", "(", "\"uint8\"", ")", "else", "tensor", "\n", "\n", "return", "core", ".", "CreateOperator", "(", "\n", "kTypeNameMapper", "[", "tensor", ".", "dtype", "]", ",", "\n", "[", "]", ",", "\n", "[", "name", "]", ",", "\n", "values", "=", "values", ",", "\n", "shape", "=", "tensor", ".", "shape", ",", "\n", "Y_scale", "=", "int8_tensor", ".", "scale", ",", "\n", "Y_zero_point", "=", "int8_tensor", ".", "zero_point", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.create_const_fill_op": [[265, 288], ["type", "type", "shared._create_const_fill_op_from_numpy", "shared._create_const_fill_op_from_c2_int8_tensor"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._create_const_fill_op_from_numpy", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._create_const_fill_op_from_c2_int8_tensor"], ["", "def", "create_const_fill_op", "(", "\n", "name", ":", "str", ",", "\n", "blob", ":", "Union", "[", "np", ".", "ndarray", ",", "workspace", ".", "Int8Tensor", "]", ",", "\n", "device_option", ":", "Optional", "[", "caffe2_pb2", ".", "DeviceOption", "]", "=", "None", ",", "\n", ")", "->", "caffe2_pb2", ".", "OperatorDef", ":", "\n", "    ", "\"\"\"\n    Given a blob object, return the Caffe2 operator that creates this blob\n    as constant. Currently support NumPy tensor and Caffe2 Int8Tensor.\n    \"\"\"", "\n", "\n", "tensor_type", "=", "type", "(", "blob", ")", "\n", "assert", "tensor_type", "in", "[", "\n", "np", ".", "ndarray", ",", "\n", "workspace", ".", "Int8Tensor", ",", "\n", "]", ",", "'Error when creating const fill op for \"{}\", unsupported blob type: {}'", ".", "format", "(", "\n", "name", ",", "type", "(", "blob", ")", "\n", ")", "\n", "\n", "if", "tensor_type", "==", "np", ".", "ndarray", ":", "\n", "        ", "return", "_create_const_fill_op_from_numpy", "(", "name", ",", "blob", ",", "device_option", ")", "\n", "", "elif", "tensor_type", "==", "workspace", ".", "Int8Tensor", ":", "\n", "        ", "assert", "device_option", "is", "None", "\n", "return", "_create_const_fill_op_from_c2_int8_tensor", "(", "name", ",", "blob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.construct_init_net_from_params": [[290, 312], ["caffe2.proto.caffe2_pb2.NetDef", "params.items", "isinstance", "caffe2_pb2.NetDef.op.extend", "caffe2_pb2.NetDef.external_output.append", "logger.warning", "shared.create_const_fill_op", "type", "device_options.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.create_const_fill_op", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "construct_init_net_from_params", "(", "\n", "params", ":", "Dict", "[", "str", ",", "Any", "]", ",", "device_options", ":", "Optional", "[", "Dict", "[", "str", ",", "caffe2_pb2", ".", "DeviceOption", "]", "]", "=", "None", "\n", ")", "->", "caffe2_pb2", ".", "NetDef", ":", "\n", "    ", "\"\"\"\n    Construct the init_net from params dictionary\n    \"\"\"", "\n", "init_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "device_options", "=", "device_options", "or", "{", "}", "\n", "for", "name", ",", "blob", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "blob", ",", "str", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "(", "\n", "\"Blob {} with type {} is not supported in generating init net,\"", "\n", "\" skipped.\"", ".", "format", "(", "name", ",", "type", "(", "blob", ")", ")", "\n", ")", "\n", ")", "\n", "continue", "\n", "", "init_net", ".", "op", ".", "extend", "(", "\n", "[", "create_const_fill_op", "(", "name", ",", "blob", ",", "device_option", "=", "device_options", ".", "get", "(", "name", ",", "None", ")", ")", "]", "\n", ")", "\n", "init_net", ".", "external_output", ".", "append", "(", "name", ")", "\n", "", "return", "init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_producer_map": [[314, 325], ["range", "len", "enumerate"], "function", ["None"], ["", "def", "get_producer_map", "(", "ssa", ")", ":", "\n", "    ", "\"\"\"\n    Return dict from versioned blob to (i, j),\n        where i is index of producer op, j is the index of output of that op.\n    \"\"\"", "\n", "producer_map", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "        ", "outputs", "=", "ssa", "[", "i", "]", "[", "1", "]", "\n", "for", "j", ",", "outp", "in", "enumerate", "(", "outputs", ")", ":", "\n", "            ", "producer_map", "[", "outp", "]", "=", "(", "i", ",", "j", ")", "\n", "", "", "return", "producer_map", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_consumer_map": [[327, 338], ["collections.defaultdict", "range", "len", "enumerate", "consumer_map[].append"], "function", ["None"], ["", "def", "get_consumer_map", "(", "ssa", ")", ":", "\n", "    ", "\"\"\"\n    Return dict from versioned blob to list of (i, j),\n        where i is index of consumer op, j is the index of input of that op.\n    \"\"\"", "\n", "consumer_map", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "        ", "inputs", "=", "ssa", "[", "i", "]", "[", "0", "]", "\n", "for", "j", ",", "inp", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "consumer_map", "[", "inp", "]", ".", "append", "(", "(", "i", ",", "j", ")", ")", "\n", "", "", "return", "consumer_map", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_params_from_init_net": [[340, 367], ["caffe2.python.core.get_ssa", "shared.get_producer_map", "shared.ScopedWS", "ws.RunNetOnce", "shared.get_params_from_init_net._get_device_option"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_producer_map"], ["", "def", "get_params_from_init_net", "(", "\n", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", ")", "->", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "caffe2_pb2", ".", "DeviceOption", "]", "]", ":", "\n", "    ", "\"\"\"\n    Take the output blobs from init_net by running it.\n    Outputs:\n        params: dict from blob name to numpy array\n        device_options: dict from blob name to the device option of its creating op\n    \"\"\"", "\n", "# NOTE: this assumes that the params is determined by producer op with the", "\n", "# only exception be CopyGPUToCPU which is CUDA op but returns CPU tensor.", "\n", "def", "_get_device_option", "(", "producer_op", ")", ":", "\n", "        ", "if", "producer_op", ".", "type", "==", "\"CopyGPUToCPU\"", ":", "\n", "            ", "return", "caffe2_pb2", ".", "DeviceOption", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "producer_op", ".", "device_option", "\n", "\n", "", "", "with", "ScopedWS", "(", "\"__get_params_from_init_net__\"", ",", "is_reset", "=", "True", ",", "is_cleanup", "=", "True", ")", "as", "ws", ":", "\n", "        ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "params", "=", "{", "b", ":", "fetch_any_blob", "(", "b", ")", "for", "b", "in", "init_net", ".", "external_output", "}", "\n", "", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "producer_map", "=", "get_producer_map", "(", "ssa", ")", "\n", "device_options", "=", "{", "\n", "b", ":", "_get_device_option", "(", "init_net", ".", "op", "[", "producer_map", "[", "(", "b", ",", "versions", "[", "b", "]", ")", "]", "[", "0", "]", "]", ")", "\n", "for", "b", "in", "init_net", ".", "external_output", "\n", "}", "\n", "return", "params", ",", "device_options", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._updater_raise": [[369, 373], ["RuntimeError"], "function", ["None"], ["", "def", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "    ", "raise", "RuntimeError", "(", "\n", "\"Failed to apply updater for op {} given input_types {} and\"", "\n", "\" output_types {}\"", ".", "format", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._generic_status_identifier": [[376, 446], ["caffe2.python.core.get_ssa", "set().union", "set().union.union().union", "all", "all", "copy.deepcopy", "zip", "zip", "status_updater", "zip", "shared._generic_status_identifier._update_i"], "function", ["None"], ["", "def", "_generic_status_identifier", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "status_updater", ":", "Callable", ",", "\n", "known_status", ":", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ",", "\n", ")", "->", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Statically infer the status of each blob, the status can be such as device type\n        (CPU/GPU), layout (NCHW/NHWC), data type (float32/int8), etc. \"Blob\" here\n        is versioned blob (Tuple[str, int]) in the format compatible with ssa.\n    Inputs:\n        predict_net: the caffe2 network\n        status_updater: a callable, given an op and the status of its input/output,\n            it returns the updated status of input/output. `None` is used for\n            representing unknown status.\n        known_status: a dict containing known status, used as initialization.\n    Outputs:\n        A dict mapping from versioned blob to its status\n    \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "versioned_ext_input", "=", "[", "(", "b", ",", "0", ")", "for", "b", "in", "predict_net", ".", "external_input", "]", "\n", "versioned_ext_output", "=", "[", "(", "b", ",", "versions", "[", "b", "]", ")", "for", "b", "in", "predict_net", ".", "external_output", "]", "\n", "all_versioned_blobs", "=", "set", "(", ")", ".", "union", "(", "*", "[", "set", "(", "x", "[", "0", "]", "+", "x", "[", "1", "]", ")", "for", "x", "in", "ssa", "]", ")", "\n", "\n", "allowed_vbs", "=", "all_versioned_blobs", ".", "union", "(", "versioned_ext_input", ")", ".", "union", "(", "versioned_ext_output", ")", "\n", "assert", "all", "(", "k", "in", "allowed_vbs", "for", "k", "in", "known_status", ")", "\n", "assert", "all", "(", "v", "is", "not", "None", "for", "v", "in", "known_status", ".", "values", "(", ")", ")", "\n", "_known_status", "=", "copy", ".", "deepcopy", "(", "known_status", ")", "\n", "\n", "def", "_check_and_update", "(", "key", ",", "value", ")", ":", "\n", "        ", "assert", "value", "is", "not", "None", "\n", "if", "key", "in", "_known_status", ":", "\n", "            ", "if", "not", "_known_status", "[", "key", "]", "==", "value", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Confilict status for {}, existing status {}, new status {}\"", ".", "format", "(", "\n", "key", ",", "_known_status", "[", "key", "]", ",", "value", "\n", ")", "\n", ")", "\n", "", "", "_known_status", "[", "key", "]", "=", "value", "\n", "\n", "", "def", "_update_i", "(", "op", ",", "ssa_i", ")", ":", "\n", "        ", "versioned_inputs", "=", "ssa_i", "[", "0", "]", "\n", "versioned_outputs", "=", "ssa_i", "[", "1", "]", "\n", "\n", "inputs_status", "=", "[", "_known_status", ".", "get", "(", "b", ",", "None", ")", "for", "b", "in", "versioned_inputs", "]", "\n", "outputs_status", "=", "[", "_known_status", ".", "get", "(", "b", ",", "None", ")", "for", "b", "in", "versioned_outputs", "]", "\n", "\n", "new_inputs_status", ",", "new_outputs_status", "=", "status_updater", "(", "op", ",", "inputs_status", ",", "outputs_status", ")", "\n", "\n", "for", "versioned_blob", ",", "status", "in", "zip", "(", "\n", "versioned_inputs", "+", "versioned_outputs", ",", "new_inputs_status", "+", "new_outputs_status", "\n", ")", ":", "\n", "            ", "if", "status", "is", "not", "None", ":", "\n", "                ", "_check_and_update", "(", "versioned_blob", ",", "status", ")", "\n", "\n", "", "", "", "for", "op", ",", "ssa_i", "in", "zip", "(", "predict_net", ".", "op", ",", "ssa", ")", ":", "\n", "        ", "_update_i", "(", "op", ",", "ssa_i", ")", "\n", "", "for", "op", ",", "ssa_i", "in", "zip", "(", "reversed", "(", "predict_net", ".", "op", ")", ",", "reversed", "(", "ssa", ")", ")", ":", "\n", "        ", "_update_i", "(", "op", ",", "ssa_i", ")", "\n", "\n", "# NOTE: This strictly checks all the blob from predict_net must be assgined", "\n", "# a known status. However sometimes it's impossible (eg. having deadend op),", "\n", "# we may relax this constraint if", "\n", "", "for", "k", "in", "all_versioned_blobs", ":", "\n", "        ", "if", "k", "not", "in", "_known_status", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Can not infer the status for {}. Currently only support the case where\"", "\n", "\" a single forward and backward pass can identify status for all blobs.\"", ".", "format", "(", "k", ")", "\n", ")", "\n", "\n", "", "", "return", "_known_status", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.infer_device_type": [[448, 486], ["shared._generic_status_identifier", "shared._updater_raise", "shared._updater_raise", "len", "all", "shared._updater_raise"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._generic_status_identifier", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._updater_raise", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._updater_raise", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._updater_raise"], ["", "def", "infer_device_type", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "known_status", ":", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ",", "\n", "device_name_style", ":", "str", "=", "\"caffe2\"", ",", "\n", ")", "->", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "str", "]", ":", "\n", "    ", "\"\"\" Return the device type (\"cpu\" or \"gpu\"/\"cuda\") of each (versioned) blob \"\"\"", "\n", "\n", "assert", "device_name_style", "in", "[", "\"caffe2\"", ",", "\"pytorch\"", "]", "\n", "_CPU_STR", "=", "\"cpu\"", "\n", "_GPU_STR", "=", "\"gpu\"", "if", "device_name_style", "==", "\"caffe2\"", "else", "\"cuda\"", "\n", "\n", "def", "_copy_cpu_to_gpu_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "if", "input_types", "[", "0", "]", "==", "_GPU_STR", "or", "output_types", "[", "0", "]", "==", "_CPU_STR", ":", "\n", "            ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "return", "(", "[", "_CPU_STR", "]", ",", "[", "_GPU_STR", "]", ")", "\n", "\n", "", "def", "_copy_gpu_to_cpu_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "if", "input_types", "[", "0", "]", "==", "_CPU_STR", "or", "output_types", "[", "0", "]", "==", "_GPU_STR", ":", "\n", "            ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "return", "(", "[", "_GPU_STR", "]", ",", "[", "_CPU_STR", "]", ")", "\n", "\n", "", "def", "_other_ops_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "non_none_types", "=", "[", "x", "for", "x", "in", "input_types", "+", "output_types", "if", "x", "is", "not", "None", "]", "\n", "if", "len", "(", "non_none_types", ")", ">", "0", ":", "\n", "            ", "the_type", "=", "non_none_types", "[", "0", "]", "\n", "if", "not", "all", "(", "x", "==", "the_type", "for", "x", "in", "non_none_types", ")", ":", "\n", "                ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "", "else", ":", "\n", "            ", "the_type", "=", "None", "\n", "", "return", "(", "[", "the_type", "for", "_", "in", "op", ".", "input", "]", ",", "[", "the_type", "for", "_", "in", "op", ".", "output", "]", ")", "\n", "\n", "", "def", "_device_updater", "(", "op", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\n", "\"CopyCPUToGPU\"", ":", "_copy_cpu_to_gpu_updater", ",", "\n", "\"CopyGPUToCPU\"", ":", "_copy_gpu_to_cpu_updater", ",", "\n", "}", ".", "get", "(", "op", ".", "type", ",", "_other_ops_updater", ")", "(", "op", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "_generic_status_identifier", "(", "predict_net", ",", "_device_updater", ",", "known_status", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._modify_blob_names": [[491, 505], ["blob_list.extend", "copy.deepcopy", "shared._modify_blob_names._replace_list"], "function", ["None"], ["", "def", "_modify_blob_names", "(", "ops", ",", "blob_rename_f", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "\n", "def", "_replace_list", "(", "blob_list", ",", "replaced_list", ")", ":", "\n", "        ", "del", "blob_list", "[", ":", "]", "\n", "blob_list", ".", "extend", "(", "replaced_list", ")", "\n", "\n", "", "for", "x", "in", "ops", ":", "\n", "        ", "cur", "=", "copy", ".", "deepcopy", "(", "x", ")", "\n", "_replace_list", "(", "cur", ".", "input", ",", "list", "(", "map", "(", "blob_rename_f", ",", "cur", ".", "input", ")", ")", ")", "\n", "_replace_list", "(", "cur", ".", "output", ",", "list", "(", "map", "(", "blob_rename_f", ",", "cur", ".", "output", ")", ")", ")", "\n", "ret", ".", "append", "(", "cur", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._rename_blob": [[507, 520], ["shared._rename_blob._list_to_str"], "function", ["None"], ["", "def", "_rename_blob", "(", "name", ",", "blob_sizes", ",", "blob_ranges", ")", ":", "\n", "    ", "def", "_list_to_str", "(", "bsize", ")", ":", "\n", "        ", "ret", "=", "\", \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "bsize", "]", ")", "\n", "ret", "=", "\"[\"", "+", "ret", "+", "\"]\"", "\n", "return", "ret", "\n", "\n", "", "ret", "=", "name", "\n", "if", "blob_sizes", "is", "not", "None", "and", "name", "in", "blob_sizes", ":", "\n", "        ", "ret", "+=", "\"\\n\"", "+", "_list_to_str", "(", "blob_sizes", "[", "name", "]", ")", "\n", "", "if", "blob_ranges", "is", "not", "None", "and", "name", "in", "blob_ranges", ":", "\n", "        ", "ret", "+=", "\"\\n\"", "+", "_list_to_str", "(", "blob_ranges", "[", "name", "]", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.save_graph": [[523, 526], ["functools.partial", "shared.save_graph_base"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.save_graph_base"], ["", "def", "save_graph", "(", "net", ",", "file_name", ",", "graph_name", "=", "\"net\"", ",", "op_only", "=", "True", ",", "blob_sizes", "=", "None", ",", "blob_ranges", "=", "None", ")", ":", "\n", "    ", "blob_rename_f", "=", "functools", ".", "partial", "(", "_rename_blob", ",", "blob_sizes", "=", "blob_sizes", ",", "blob_ranges", "=", "blob_ranges", ")", "\n", "return", "save_graph_base", "(", "net", ",", "file_name", ",", "graph_name", ",", "op_only", ",", "blob_rename_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.save_graph_base": [[528, 558], ["shared._modify_blob_names", "caffe2.python.net_drawer.GetPydotGraph", "caffe2.python.net_drawer.GetPydotGraphMinimal", "os.path.dirname", "os.path.exists", "os.makedirs", "os.path.splitext", "net_drawer.GetPydotGraphMinimal.write_png", "print", "os.path.basename", "net_drawer.GetPydotGraphMinimal.write_pdf", "net_drawer.GetPydotGraphMinimal.write_svg", "print"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._modify_blob_names"], ["", "def", "save_graph_base", "(", "net", ",", "file_name", ",", "graph_name", "=", "\"net\"", ",", "op_only", "=", "True", ",", "blob_rename_func", "=", "None", ")", ":", "\n", "    ", "graph", "=", "None", "\n", "ops", "=", "net", ".", "op", "\n", "if", "blob_rename_func", "is", "not", "None", ":", "\n", "        ", "ops", "=", "_modify_blob_names", "(", "ops", ",", "blob_rename_func", ")", "\n", "", "if", "not", "op_only", ":", "\n", "        ", "graph", "=", "net_drawer", ".", "GetPydotGraph", "(", "ops", ",", "graph_name", ",", "rankdir", "=", "\"TB\"", ")", "\n", "", "else", ":", "\n", "        ", "graph", "=", "net_drawer", ".", "GetPydotGraphMinimal", "(", "\n", "ops", ",", "graph_name", ",", "rankdir", "=", "\"TB\"", ",", "minimal_dependency", "=", "True", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "par_dir", "=", "os", ".", "path", ".", "dirname", "(", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "par_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "par_dir", ")", "\n", "\n", "", "format", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "-", "1", "]", "\n", "if", "format", "==", "\".png\"", ":", "\n", "            ", "graph", ".", "write_png", "(", "file_name", ")", "\n", "", "elif", "format", "==", "\".pdf\"", ":", "\n", "            ", "graph", ".", "write_pdf", "(", "file_name", ")", "\n", "", "elif", "format", "==", "\".svg\"", ":", "\n", "            ", "graph", ".", "write_svg", "(", "file_name", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Incorrect format {}\"", ".", "format", "(", "format", ")", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Error when writing graph to image {}\"", ".", "format", "(", "e", ")", ")", "\n", "\n", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.group_norm_replace_aten_with_caffe2": [[563, 587], ["logger.info", "shared.get_pb_arg_vals", "op.arg.remove", "shared.get_pb_arg_vali", "shared.get_pb_arg_vali", "get_pb_arg_vals.decode", "shared.get_pb_arg", "op.arg.remove", "op.arg.remove", "shared.check_set_pb_arg", "shared.get_pb_arg", "shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg"], ["", "def", "group_norm_replace_aten_with_caffe2", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\"\n    For ONNX exported model, GroupNorm will be represented as ATen op,\n        this can be a drop in replacement from ATen to GroupNorm\n    \"\"\"", "\n", "count", "=", "0", "\n", "for", "op", "in", "predict_net", ".", "op", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"ATen\"", ":", "\n", "            ", "op_name", "=", "get_pb_arg_vals", "(", "op", ",", "\"operator\"", ",", "None", ")", "# return byte in py3", "\n", "if", "op_name", "and", "op_name", ".", "decode", "(", ")", "==", "\"group_norm\"", ":", "\n", "                ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"operator\"", ")", ")", "\n", "\n", "if", "get_pb_arg_vali", "(", "op", ",", "\"cudnn_enabled\"", ",", "None", ")", ":", "\n", "                    ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"cudnn_enabled\"", ")", ")", "\n", "\n", "", "num_groups", "=", "get_pb_arg_vali", "(", "op", ",", "\"num_groups\"", ",", "None", ")", "\n", "if", "num_groups", "is", "not", "None", ":", "\n", "                    ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"num_groups\"", ")", ")", "\n", "check_set_pb_arg", "(", "op", ",", "\"group\"", ",", "\"i\"", ",", "num_groups", ")", "\n", "\n", "", "op", ".", "type", "=", "\"GroupNorm\"", "\n", "count", "+=", "1", "\n", "", "", "", "if", "count", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Replaced {} ATen operator to GroupNormOp\"", ".", "format", "(", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias": [[592, 597], ["isinstance", "torch.ops._caffe2.AliasWithName", "torch.ops._caffe2.AliasWithName", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export"], "function", ["None"], ["", "", "def", "alias", "(", "x", ",", "name", ",", "is_backward", "=", "False", ")", ":", "\n", "    ", "if", "not", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "        ", "return", "x", "\n", "", "assert", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "\n", "return", "torch", ".", "ops", ".", "_caffe2", ".", "AliasWithName", "(", "x", ",", "name", ",", "is_backward", "=", "is_backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.fuse_alias_placeholder": [[599, 622], ["enumerate", "predict_net.op.extend", "get_pb_arg_vals().decode", "bool", "shared.rename_op_input", "shared.rename_op_output", "new_ops.append", "len", "len", "shared.get_pb_arg_vali", "op.arg[].s.decode", "shared.get_pb_arg_vals"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_input", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_output", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals"], ["", "def", "fuse_alias_placeholder", "(", "predict_net", ",", "init_net", ")", ":", "\n", "    ", "\"\"\" Remove AliasWithName placeholder and rename the input/output of it \"\"\"", "\n", "# First we finish all the re-naming", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"AliasWithName\"", ":", "\n", "            ", "assert", "len", "(", "op", ".", "input", ")", "==", "1", "\n", "assert", "len", "(", "op", ".", "output", ")", "==", "1", "\n", "name", "=", "get_pb_arg_vals", "(", "op", ",", "\"name\"", ",", "None", ")", ".", "decode", "(", ")", "\n", "is_backward", "=", "bool", "(", "get_pb_arg_vali", "(", "op", ",", "\"is_backward\"", ",", "0", ")", ")", "\n", "rename_op_input", "(", "predict_net", ",", "init_net", ",", "i", ",", "0", ",", "name", ",", "from_producer", "=", "is_backward", ")", "\n", "rename_op_output", "(", "predict_net", ",", "i", ",", "0", ",", "name", ")", "\n", "\n", "# Remove AliasWithName, should be very safe since it's a non-op", "\n", "", "", "new_ops", "=", "[", "]", "\n", "for", "op", "in", "predict_net", ".", "op", ":", "\n", "        ", "if", "op", ".", "type", "!=", "\"AliasWithName\"", ":", "\n", "            ", "new_ops", ".", "append", "(", "op", ")", "\n", "", "else", ":", "\n", "# safety check", "\n", "            ", "assert", "op", ".", "input", "==", "op", ".", "output", "\n", "assert", "op", ".", "input", "[", "0", "]", "==", "op", ".", "arg", "[", "0", "]", ".", "s", ".", "decode", "(", ")", "\n", "", "", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._rename_versioned_blob_in_proto": [[631, 660], ["zip", "range", "range", "start_versions.get", "range", "end_versions.get", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_rename_versioned_blob_in_proto", "(", "\n", "proto", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "old_name", ":", "str", ",", "\n", "new_name", ":", "str", ",", "\n", "version", ":", "int", ",", "\n", "ssa", ":", "List", "[", "Tuple", "[", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", "]", "]", ",", "\n", "start_versions", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "end_versions", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", ")", ":", "\n", "    ", "\"\"\" In given proto, rename all blobs with matched version \"\"\"", "\n", "# Operater list", "\n", "for", "op", ",", "i_th_ssa", "in", "zip", "(", "proto", ".", "op", ",", "ssa", ")", ":", "\n", "        ", "versioned_inputs", ",", "versioned_outputs", "=", "i_th_ssa", "\n", "for", "i", "in", "range", "(", "len", "(", "op", ".", "input", ")", ")", ":", "\n", "            ", "if", "versioned_inputs", "[", "i", "]", "==", "(", "old_name", ",", "version", ")", ":", "\n", "                ", "op", ".", "input", "[", "i", "]", "=", "new_name", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "op", ".", "output", ")", ")", ":", "\n", "            ", "if", "versioned_outputs", "[", "i", "]", "==", "(", "old_name", ",", "version", ")", ":", "\n", "                ", "op", ".", "output", "[", "i", "]", "=", "new_name", "\n", "# external_input", "\n", "", "", "", "if", "start_versions", ".", "get", "(", "old_name", ",", "0", ")", "==", "version", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "proto", ".", "external_input", ")", ")", ":", "\n", "            ", "if", "proto", ".", "external_input", "[", "i", "]", "==", "old_name", ":", "\n", "                ", "proto", ".", "external_input", "[", "i", "]", "=", "new_name", "\n", "# external_output", "\n", "", "", "", "if", "end_versions", ".", "get", "(", "old_name", ",", "0", ")", "==", "version", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "proto", ".", "external_output", ")", ")", ":", "\n", "            ", "if", "proto", ".", "external_output", "[", "i", "]", "==", "old_name", ":", "\n", "                ", "proto", ".", "external_output", "[", "i", "]", "=", "new_name", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_input": [[662, 726], ["isinstance", "isinstance", "caffe2.python.core.get_ssa", "caffe2.python.core.get_ssa", "shared._rename_versioned_blob_in_proto", "shared._rename_versioned_blob_in_proto", "copy.deepcopy", "shared.get_producer_map", "shared.rename_op_output", "shared.rename_op_input.contain_targets"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._rename_versioned_blob_in_proto", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._rename_versioned_blob_in_proto", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_producer_map", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_output"], ["", "", "", "", "def", "rename_op_input", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "op_id", ":", "int", ",", "\n", "input_id", ":", "int", ",", "\n", "new_name", ":", "str", ",", "\n", "from_producer", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Rename the op_id-th operator in predict_net, change it's input_id-th input's\n        name to the new_name. It also does automatic re-route and change\n        external_input and init_net if necessary.\n    - It requires the input is only consumed by this op.\n    - This function modifies predict_net and init_net in-place.\n    - When from_producer is enable, this also updates other operators that consumes\n        the same input. Be cautious because may trigger unintended behavior.\n    \"\"\"", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "assert", "isinstance", "(", "init_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "\n", "init_net_ssa", ",", "init_net_versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "predict_net_ssa", ",", "predict_net_versions", "=", "core", ".", "get_ssa", "(", "\n", "predict_net", ",", "copy", ".", "deepcopy", "(", "init_net_versions", ")", "\n", ")", "\n", "\n", "versioned_inputs", ",", "versioned_outputs", "=", "predict_net_ssa", "[", "op_id", "]", "\n", "old_name", ",", "version", "=", "versioned_inputs", "[", "input_id", "]", "\n", "\n", "if", "from_producer", ":", "\n", "        ", "producer_map", "=", "get_producer_map", "(", "predict_net_ssa", ")", "\n", "if", "not", "(", "old_name", ",", "version", ")", "in", "producer_map", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Can't find producer, the input {} is probably from\"", "\n", "\" init_net, this is not supported yet.\"", ".", "format", "(", "old_name", ")", "\n", ")", "\n", "", "producer", "=", "producer_map", "[", "(", "old_name", ",", "version", ")", "]", "\n", "rename_op_output", "(", "predict_net", ",", "producer", "[", "0", "]", ",", "producer", "[", "1", "]", ",", "new_name", ")", "\n", "return", "\n", "\n", "", "def", "contain_targets", "(", "op_ssa", ")", ":", "\n", "        ", "return", "(", "old_name", ",", "version", ")", "in", "op_ssa", "[", "0", "]", "\n", "\n", "", "is_consumer", "=", "[", "contain_targets", "(", "op_ssa", ")", "for", "op_ssa", "in", "predict_net_ssa", "]", "\n", "if", "sum", "(", "is_consumer", ")", ">", "1", ":", "\n", "        ", "raise", "IllegalGraphTransformError", "(", "\n", "(", "\n", "\"Input '{}' of operator(#{}) are consumed by other ops, please use\"", "\n", "+", "\" rename_op_output on the producer instead. Offending op: \\n{}\"", "\n", ")", ".", "format", "(", "old_name", ",", "op_id", ",", "predict_net", ".", "op", "[", "op_id", "]", ")", "\n", ")", "\n", "\n", "# update init_net", "\n", "", "_rename_versioned_blob_in_proto", "(", "\n", "init_net", ",", "old_name", ",", "new_name", ",", "version", ",", "init_net_ssa", ",", "{", "}", ",", "init_net_versions", "\n", ")", "\n", "# update predict_net", "\n", "_rename_versioned_blob_in_proto", "(", "\n", "predict_net", ",", "\n", "old_name", ",", "\n", "new_name", ",", "\n", "version", ",", "\n", "predict_net_ssa", ",", "\n", "init_net_versions", ",", "\n", "predict_net_versions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_output": [[729, 747], ["isinstance", "caffe2.python.core.get_ssa", "shared._rename_versioned_blob_in_proto"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._rename_versioned_blob_in_proto"], ["", "def", "rename_op_output", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "op_id", ":", "int", ",", "output_id", ":", "int", ",", "new_name", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Rename the op_id-th operator in predict_net, change it's output_id-th input's\n        name to the new_name. It also does automatic re-route and change\n        external_output and if necessary.\n    - It allows multiple consumers of its output.\n    - This function modifies predict_net in-place, doesn't need init_net.\n    \"\"\"", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "\n", "ssa", ",", "blob_versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "versioned_inputs", ",", "versioned_outputs", "=", "ssa", "[", "op_id", "]", "\n", "old_name", ",", "version", "=", "versioned_outputs", "[", "output_id", "]", "\n", "\n", "# update predict_net", "\n", "_rename_versioned_blob_in_proto", "(", "\n", "predict_net", ",", "old_name", ",", "new_name", ",", "version", ",", "ssa", ",", "{", "}", ",", "blob_versions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_sub_graph_external_input_output": [[750, 780], ["caffe2.python.core.get_ssa", "sum", "list", "range", "set", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "get_sub_graph_external_input_output", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "sub_graph_op_indices", ":", "List", "[", "int", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Return the list of external input/output of sub-graph,\n    each element is tuple of the name and corresponding version in predict_net.\n\n    external input/output is defined the same way as caffe2 NetDef.\n    \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "all_inputs", "=", "[", "]", "\n", "all_outputs", "=", "[", "]", "\n", "for", "op_id", "in", "sub_graph_op_indices", ":", "\n", "        ", "all_inputs", "+=", "[", "inp", "for", "inp", "in", "ssa", "[", "op_id", "]", "[", "0", "]", "if", "inp", "not", "in", "all_inputs", "]", "\n", "all_outputs", "+=", "list", "(", "ssa", "[", "op_id", "]", "[", "1", "]", ")", "# ssa output won't repeat", "\n", "\n", "# for versioned blobs, external inputs are just those blob in all_inputs", "\n", "# but not in all_outputs", "\n", "", "ext_inputs", "=", "[", "inp", "for", "inp", "in", "all_inputs", "if", "inp", "not", "in", "all_outputs", "]", "\n", "\n", "# external outputs are essentially outputs of this subgraph that are used", "\n", "# outside of this sub-graph (including predict_net.external_output)", "\n", "all_other_inputs", "=", "sum", "(", "\n", "(", "ssa", "[", "i", "]", "[", "0", "]", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", "if", "i", "not", "in", "sub_graph_op_indices", ")", ",", "\n", "[", "(", "outp", ",", "versions", "[", "outp", "]", ")", "for", "outp", "in", "predict_net", ".", "external_output", "]", ",", "\n", ")", "\n", "ext_outputs", "=", "[", "outp", "for", "outp", "in", "all_outputs", "if", "outp", "in", "set", "(", "all_other_inputs", ")", "]", "\n", "\n", "return", "ext_inputs", ",", "ext_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._get_dependency_chain": [[825, 853], ["shared.get_consumer_map", "shared.get_producer_map", "shared.DiGraph.from_ssa", "DiGraph.from_ssa.get_all_paths", "sorted", "min", "len", "logger.warning", "set().union", "set", "set"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_consumer_map", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_producer_map", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.from_ssa", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.DiGraph.get_all_paths", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "", "def", "_get_dependency_chain", "(", "ssa", ",", "versioned_target", ",", "versioned_source", ")", ":", "\n", "    ", "\"\"\"\n    Return the index list of relevant operator to produce target blob from source blob,\n        if there's no dependency, return empty list.\n    \"\"\"", "\n", "\n", "# finding all paths between nodes can be O(N!), thus we can only search", "\n", "# in the subgraph using the op starting from the first consumer of source blob", "\n", "# to the producer of the target blob.", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "producer_map", "=", "get_producer_map", "(", "ssa", ")", "\n", "start_op", "=", "min", "(", "x", "[", "0", "]", "for", "x", "in", "consumer_map", "[", "versioned_source", "]", ")", "-", "15", "\n", "end_op", "=", "(", "\n", "producer_map", "[", "versioned_target", "]", "[", "0", "]", "+", "15", "if", "versioned_target", "in", "producer_map", "else", "start_op", "\n", ")", "\n", "sub_graph_ssa", "=", "ssa", "[", "start_op", ":", "end_op", "+", "1", "]", "\n", "if", "len", "(", "sub_graph_ssa", ")", ">", "30", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Subgraph bebetween {} and {} is large (from op#{} to op#{}), it\"", "\n", "\" might take non-trival time to find all paths between them.\"", ".", "format", "(", "\n", "versioned_source", ",", "versioned_target", ",", "start_op", ",", "end_op", "\n", ")", "\n", ")", "\n", "\n", "", "dag", "=", "DiGraph", ".", "from_ssa", "(", "sub_graph_ssa", ")", "\n", "paths", "=", "dag", ".", "get_all_paths", "(", "versioned_source", ",", "versioned_target", ")", "# include two ends", "\n", "ops_in_paths", "=", "[", "[", "producer_map", "[", "blob", "]", "[", "0", "]", "for", "blob", "in", "path", "[", "1", ":", "]", "]", "for", "path", "in", "paths", "]", "\n", "return", "sorted", "(", "set", "(", ")", ".", "union", "(", "*", "[", "set", "(", "ops", ")", "for", "ops", "in", "ops_in_paths", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.identify_reshape_sub_graph": [[855, 880], ["caffe2.python.core.get_ssa", "enumerate", "shared._get_dependency_chain", "ret.append", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared._get_dependency_chain"], ["", "def", "identify_reshape_sub_graph", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Idenfity the reshape sub-graph in a protobuf.\n    The reshape sub-graph is defined as matching the following pattern:\n\n    (input_blob) -> Op_1 -> ... -> Op_N -> (new_shape) -\u2500\u2510\n        \u2514-------------------------------------------> Reshape -> (output_blob)\n\n    Return:\n        List of sub-graphs, each sub-graph is represented as a list of indices\n        of the relavent ops, [Op_1, Op_2, ..., Op_N, Reshape]\n    \"\"\"", "\n", "\n", "ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"Reshape\"", ":", "\n", "            ", "assert", "len", "(", "op", ".", "input", ")", "==", "2", "\n", "input_ssa", "=", "ssa", "[", "i", "]", "[", "0", "]", "\n", "data_source", "=", "input_ssa", "[", "0", "]", "\n", "shape_source", "=", "input_ssa", "[", "1", "]", "\n", "op_indices", "=", "_get_dependency_chain", "(", "ssa", ",", "shape_source", ",", "data_source", ")", "\n", "ret", ".", "append", "(", "op_indices", "+", "[", "i", "]", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.remove_reshape_for_fc": [[882, 950], ["shared.identify_reshape_sub_graph", "copy.deepcopy", "copy.deepcopy.op.extend", "caffe2.python.core.get_ssa", "all", "logger.info", "shared.rename_op_output", "shared.get_sub_graph_external_input_output", "remove_op_ids.extend", "params_to_remove.extend", "logger.info", "copy.deepcopy.external_input.remove", "shared.get_sub_graph_external_input_output", "enumerate", "range", "sub_graphs_to_remove.append", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.identify_reshape_sub_graph", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.rename_op_output", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_sub_graph_external_input_output", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_sub_graph_external_input_output"], ["", "def", "remove_reshape_for_fc", "(", "predict_net", ",", "params", ")", ":", "\n", "    ", "\"\"\"\n    In PyTorch nn.Linear has to take 2D tensor, this often leads to reshape\n        a 4D tensor to 2D by calling .view(). However this (dynamic) reshaping\n        doesn't work well with ONNX and Int8 tools, and cause using extra\n        ops (eg. ExpandDims) that might not be available on mobile.\n    Luckily Caffe2 supports 4D tensor for FC, so we can remove those reshape\n        after exporting ONNX model.\n    \"\"\"", "\n", "from", "caffe2", ".", "python", "import", "core", "\n", "\n", "# find all reshape sub-graph that can be removed, which is now all Reshape", "\n", "# sub-graph whose output is only consumed by FC.", "\n", "# TODO: to make it safer, we may need the actually value to better determine", "\n", "# if a Reshape before FC is removable.", "\n", "reshape_sub_graphs", "=", "identify_reshape_sub_graph", "(", "predict_net", ")", "\n", "sub_graphs_to_remove", "=", "[", "]", "\n", "for", "reshape_sub_graph", "in", "reshape_sub_graphs", ":", "\n", "        ", "reshape_op_id", "=", "reshape_sub_graph", "[", "-", "1", "]", "\n", "assert", "predict_net", ".", "op", "[", "reshape_op_id", "]", ".", "type", "==", "\"Reshape\"", "\n", "ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "reshape_output", "=", "ssa", "[", "reshape_op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "consumers", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", "if", "reshape_output", "in", "ssa", "[", "i", "]", "[", "0", "]", "]", "\n", "if", "all", "(", "predict_net", ".", "op", "[", "consumer", "]", ".", "type", "==", "\"FC\"", "for", "consumer", "in", "consumers", ")", ":", "\n", "# safety check if the sub-graph is isolated, for this reshape sub-graph,", "\n", "# it means it has one non-param external input and one external output.", "\n", "            ", "ext_inputs", ",", "ext_outputs", "=", "get_sub_graph_external_input_output", "(", "\n", "predict_net", ",", "reshape_sub_graph", "\n", ")", "\n", "non_params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "!=", "0", "]", "\n", "if", "len", "(", "non_params_ext_inputs", ")", "==", "1", "and", "len", "(", "ext_outputs", ")", "==", "1", ":", "\n", "                ", "sub_graphs_to_remove", ".", "append", "(", "reshape_sub_graph", ")", "\n", "\n", "# perform removing subgraph by:", "\n", "# 1: rename the Reshape's output to its input, then the graph can be", "\n", "#   seen as in-place itentify, meaning whose external input/output are the same.", "\n", "# 2: simply remove those ops.", "\n", "", "", "", "remove_op_ids", "=", "[", "]", "\n", "params_to_remove", "=", "[", "]", "\n", "for", "sub_graph", "in", "sub_graphs_to_remove", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Remove Reshape sub-graph:\\n{}\"", ".", "format", "(", "\n", "\"\"", ".", "join", "(", "[", "\"(#{:>4})\\n{}\"", ".", "format", "(", "i", ",", "predict_net", ".", "op", "[", "i", "]", ")", "for", "i", "in", "sub_graph", "]", ")", "\n", ")", "\n", ")", "\n", "reshape_op_id", "=", "sub_graph", "[", "-", "1", "]", "\n", "new_reshap_output", "=", "predict_net", ".", "op", "[", "reshape_op_id", "]", ".", "input", "[", "0", "]", "\n", "rename_op_output", "(", "predict_net", ",", "reshape_op_id", ",", "0", ",", "new_reshap_output", ")", "\n", "ext_inputs", ",", "ext_outputs", "=", "get_sub_graph_external_input_output", "(", "predict_net", ",", "sub_graph", ")", "\n", "non_params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "!=", "0", "]", "\n", "params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "==", "0", "]", "\n", "assert", "len", "(", "non_params_ext_inputs", ")", "==", "1", "and", "len", "(", "ext_outputs", ")", "==", "1", "\n", "assert", "ext_outputs", "[", "0", "]", "[", "0", "]", "==", "non_params_ext_inputs", "[", "0", "]", "[", "0", "]", "\n", "assert", "ext_outputs", "[", "0", "]", "[", "1", "]", "==", "non_params_ext_inputs", "[", "0", "]", "[", "1", "]", "+", "1", "\n", "remove_op_ids", ".", "extend", "(", "sub_graph", ")", "\n", "params_to_remove", ".", "extend", "(", "params_ext_inputs", ")", "\n", "\n", "", "predict_net", "=", "copy", ".", "deepcopy", "(", "predict_net", ")", "\n", "new_ops", "=", "[", "op", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", "if", "i", "not", "in", "remove_op_ids", "]", "\n", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "for", "versioned_params", "in", "params_to_remove", ":", "\n", "        ", "name", "=", "versioned_params", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"Remove params: {} from init_net and predict_net.external_input\"", ".", "format", "(", "name", ")", ")", "\n", "del", "params", "[", "name", "]", "\n", "predict_net", ".", "external_input", ".", "remove", "(", "name", ")", "\n", "\n", "", "return", "predict_net", ",", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.fuse_copy_between_cpu_and_gpu": [[952, 1008], ["shared.fuse_copy_between_cpu_and_gpu._fuse_once"], "function", ["None"], ["", "def", "fuse_copy_between_cpu_and_gpu", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\"\n    In-place fuse extra copy ops between cpu/gpu for the following case:\n        a -CopyAToB-> b -CopyBToA> c1 -NextOp1-> d1\n                        -CopyBToA> c2 -NextOp2-> d2\n    The fused network will look like:\n        a -NextOp1-> d1\n          -NextOp2-> d2\n    \"\"\"", "\n", "\n", "_COPY_OPS", "=", "[", "\"CopyCPUToGPU\"", ",", "\"CopyGPUToCPU\"", "]", "\n", "\n", "def", "_fuse_once", "(", "predict_net", ")", ":", "\n", "        ", "ssa", ",", "blob_versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "versioned_external_output", "=", "[", "\n", "(", "name", ",", "blob_versions", "[", "name", "]", ")", "for", "name", "in", "predict_net", ".", "external_output", "\n", "]", "\n", "\n", "for", "op_id", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "            ", "if", "op", ".", "type", "in", "_COPY_OPS", ":", "\n", "                ", "fw_copy_versioned_output", "=", "ssa", "[", "op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "consumer_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "consumer_map", "[", "fw_copy_versioned_output", "]", "]", "\n", "reverse_op_type", "=", "_COPY_OPS", "[", "1", "-", "_COPY_OPS", ".", "index", "(", "op", ".", "type", ")", "]", "\n", "\n", "is_fusable", "=", "(", "\n", "len", "(", "consumer_ids", ")", ">", "0", "\n", "and", "fw_copy_versioned_output", "not", "in", "versioned_external_output", "\n", "and", "all", "(", "\n", "predict_net", ".", "op", "[", "_op_id", "]", ".", "type", "==", "reverse_op_type", "\n", "and", "ssa", "[", "_op_id", "]", "[", "1", "]", "[", "0", "]", "not", "in", "versioned_external_output", "\n", "for", "_op_id", "in", "consumer_ids", "\n", ")", "\n", ")", "\n", "\n", "if", "is_fusable", ":", "\n", "                    ", "for", "rv_copy_op_id", "in", "consumer_ids", ":", "\n", "# making each NextOp uses \"a\" directly and removing Copy ops", "\n", "                        ", "rs_copy_versioned_output", "=", "ssa", "[", "rv_copy_op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "next_op_id", ",", "inp_id", "=", "consumer_map", "[", "rs_copy_versioned_output", "]", "[", "0", "]", "\n", "predict_net", ".", "op", "[", "next_op_id", "]", ".", "input", "[", "inp_id", "]", "=", "op", ".", "input", "[", "0", "]", "\n", "# remove CopyOps", "\n", "", "new_ops", "=", "[", "\n", "op", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", "\n", "if", "i", "!=", "op_id", "and", "i", "not", "in", "consumer_ids", "\n", "]", "\n", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "return", "True", "\n", "\n", "", "", "", "return", "False", "\n", "\n", "# _fuse_once returns False is nothing can be fused", "\n", "", "while", "_fuse_once", "(", "predict_net", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.remove_dead_end_ops": [[1010, 1035], ["caffe2.python.core.get_ssa", "shared.get_consumer_map", "set", "reversed", "net_def.op.extend", "list", "all", "enumerate", "set.add", "enumerate", "shared.remove_dead_end_ops._is_dead_end"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_consumer_map", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "remove_dead_end_ops", "(", "net_def", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\" remove ops if its output is not used or not in external_output \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "net_def", ")", "\n", "versioned_external_output", "=", "[", "(", "name", ",", "versions", "[", "name", "]", ")", "for", "name", "in", "net_def", ".", "external_output", "]", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "removed_op_ids", "=", "set", "(", ")", "\n", "\n", "def", "_is_dead_end", "(", "versioned_blob", ")", ":", "\n", "        ", "return", "not", "(", "\n", "versioned_blob", "in", "versioned_external_output", "\n", "or", "(", "\n", "len", "(", "consumer_map", "[", "versioned_blob", "]", ")", ">", "0", "\n", "and", "all", "(", "x", "[", "0", "]", "not", "in", "removed_op_ids", "for", "x", "in", "consumer_map", "[", "versioned_blob", "]", ")", "\n", ")", "\n", ")", "\n", "\n", "", "for", "i", ",", "ssa_i", "in", "reversed", "(", "list", "(", "enumerate", "(", "ssa", ")", ")", ")", ":", "\n", "        ", "versioned_outputs", "=", "ssa_i", "[", "1", "]", "\n", "if", "all", "(", "_is_dead_end", "(", "outp", ")", "for", "outp", "in", "versioned_outputs", ")", ":", "\n", "            ", "removed_op_ids", ".", "add", "(", "i", ")", "\n", "\n", "# simply removing those deadend ops should have no effect to external_output", "\n", "", "", "new_ops", "=", "[", "op", "for", "i", ",", "op", "in", "enumerate", "(", "net_def", ".", "op", ")", "if", "i", "not", "in", "removed_op_ids", "]", "\n", "del", "net_def", ".", "op", "[", ":", "]", "\n", "net_def", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.Caffe2CompatibleConverter.__init__": [[32, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "replaceCls", ")", ":", "\n", "        ", "self", ".", "replaceCls", "=", "replaceCls", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.Caffe2CompatibleConverter.create_from": [[35, 55], ["isinstance", "issubclass", "isinstance", "type"], "methods", ["None"], ["", "def", "create_from", "(", "self", ",", "module", ")", ":", "\n", "# update module's class to the new class", "\n", "        ", "assert", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "if", "issubclass", "(", "self", ".", "replaceCls", ",", "GenericMixin", ")", ":", "\n", "# replaceCls should act as mixin, create a new class on-the-fly", "\n", "            ", "new_class", "=", "type", "(", "\n", "\"{}MixedWith{}\"", ".", "format", "(", "self", ".", "replaceCls", ".", "__name__", ",", "module", ".", "__class__", ".", "__name__", ")", ",", "\n", "(", "self", ".", "replaceCls", ",", "module", ".", "__class__", ")", ",", "\n", "{", "}", ",", "# {\"new_method\": lambda self: ...},", "\n", ")", "\n", "module", ".", "__class__", "=", "new_class", "\n", "", "else", ":", "\n", "# replaceCls is complete class, this allow arbitrary class swap", "\n", "            ", "module", ".", "__class__", "=", "self", ".", "replaceCls", "\n", "\n", "# initialize Caffe2Compatible", "\n", "", "if", "isinstance", "(", "module", ",", "Caffe2Compatible", ")", ":", "\n", "            ", "module", ".", "tensor_mode", "=", "False", "\n", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.ROIHeadsPatcher.__init__": [[115, 118], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "heads", ",", "use_heatmap_max_keypoint", ")", ":", "\n", "        ", "self", ".", "heads", "=", "heads", "\n", "self", ".", "use_heatmap_max_keypoint", "=", "use_heatmap_max_keypoint", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads": [[119, 153], ["getattr", "getattr", "caffe2_patch.mock_fastrcnn_outputs_inference", "contextlib.ExitStack", "caffe2_patch.mock_keypoint_rcnn_inference", "caffe2_patch.mock_mask_rcnn_inference", "stack.enter_context", "type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_fastrcnn_outputs_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_keypoint_rcnn_inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_mask_rcnn_inference"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_roi_heads", "(", "self", ",", "tensor_mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Patching several inference functions inside ROIHeads and its subclasses\n\n        Args:\n            tensor_mode (bool): whether the inputs/outputs are caffe2's tensor\n                format or not. Default to True.\n        \"\"\"", "\n", "# NOTE: this requries the `keypoint_rcnn_inference` and `mask_rcnn_inference`", "\n", "# are called inside the same file as BaseXxxHead due to using mock.patch.", "\n", "kpt_heads_mod", "=", "keypoint_head", ".", "BaseKeypointRCNNHead", ".", "__module__", "\n", "mask_head_mod", "=", "mask_head", ".", "BaseMaskRCNNHead", ".", "__module__", "\n", "\n", "mock_ctx_managers", "=", "[", "\n", "mock_fastrcnn_outputs_inference", "(", "\n", "tensor_mode", "=", "tensor_mode", ",", "\n", "check", "=", "True", ",", "\n", "box_predictor_type", "=", "type", "(", "self", ".", "heads", ".", "box_predictor", ")", ",", "\n", ")", "\n", "]", "\n", "if", "getattr", "(", "self", ".", "heads", ",", "\"keypoint_on\"", ",", "False", ")", ":", "\n", "            ", "mock_ctx_managers", "+=", "[", "\n", "mock_keypoint_rcnn_inference", "(", "\n", "tensor_mode", ",", "kpt_heads_mod", ",", "self", ".", "use_heatmap_max_keypoint", "\n", ")", "\n", "]", "\n", "", "if", "getattr", "(", "self", ".", "heads", ",", "\"mask_on\"", ",", "False", ")", ":", "\n", "            ", "mock_ctx_managers", "+=", "[", "mock_mask_rcnn_inference", "(", "tensor_mode", ",", "mask_head_mod", ")", "]", "\n", "\n", "", "with", "contextlib", ".", "ExitStack", "(", ")", "as", "stack", ":", "# python 3.3+", "\n", "            ", "for", "mgr", "in", "mock_ctx_managers", ":", "\n", "                ", "stack", ".", "enter_context", "(", "mgr", ")", "\n", "", "yield", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch": [[57, 68], ["model.named_children", "isinstance", "caffe2_patch.patch", "updater.create_from", "detectron2.modeling.proposal_generator.rpn.RPN", "detectron2.modeling.poolers.ROIPooler"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.Caffe2CompatibleConverter.create_from"], ["", "", "def", "patch", "(", "model", ",", "target", ",", "updater", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    recursively (post-order) update all modules with the target type and its\n    subclasses, make a initialization/composition/inheritance/... via the\n    updater.create_from.\n    \"\"\"", "\n", "for", "name", ",", "module", "in", "model", ".", "named_children", "(", ")", ":", "\n", "        ", "model", ".", "_modules", "[", "name", "]", "=", "patch", "(", "module", ",", "target", ",", "updater", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "isinstance", "(", "model", ",", "target", ")", ":", "\n", "        ", "return", "updater", ".", "create_from", "(", "model", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch_generalized_rcnn": [[70, 76], ["caffe2_patch.patch", "caffe2_patch.patch", "ccc", "ccc"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch"], ["", "def", "patch_generalized_rcnn", "(", "model", ")", ":", "\n", "    ", "ccc", "=", "Caffe2CompatibleConverter", "\n", "model", "=", "patch", "(", "model", ",", "rpn", ".", "RPN", ",", "ccc", "(", "Caffe2RPN", ")", ")", "\n", "model", "=", "patch", "(", "model", ",", "poolers", ".", "ROIPooler", ",", "ccc", "(", "Caffe2ROIPooler", ")", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_fastrcnn_outputs_inference": [[78, 91], ["unittest.mock.patch.object", "c10.Caffe2FastRCNNOutputsInference"], "function", ["None"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_fastrcnn_outputs_inference", "(", "\n", "tensor_mode", ",", "check", "=", "True", ",", "box_predictor_type", "=", "FastRCNNOutputLayers", "\n", ")", ":", "\n", "    ", "with", "mock", ".", "patch", ".", "object", "(", "\n", "box_predictor_type", ",", "\n", "\"inference\"", ",", "\n", "autospec", "=", "True", ",", "\n", "side_effect", "=", "Caffe2FastRCNNOutputsInference", "(", "tensor_mode", ")", ",", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_mask_rcnn_inference": [[93, 101], ["unittest.mock.patch", "c10.Caffe2MaskRCNNInference"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_mask_rcnn_inference", "(", "tensor_mode", ",", "patched_module", ",", "check", "=", "True", ")", ":", "\n", "    ", "with", "mock", ".", "patch", "(", "\n", "\"{}.mask_rcnn_inference\"", ".", "format", "(", "patched_module", ")", ",", "side_effect", "=", "Caffe2MaskRCNNInference", "(", ")", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.mock_keypoint_rcnn_inference": [[103, 112], ["unittest.mock.patch", "c10.Caffe2KeypointRCNNInference"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_keypoint_rcnn_inference", "(", "tensor_mode", ",", "patched_module", ",", "use_heatmap_max_keypoint", ",", "check", "=", "True", ")", ":", "\n", "    ", "with", "mock", ".", "patch", "(", "\n", "\"{}.keypoint_rcnn_inference\"", ".", "format", "(", "patched_module", ")", ",", "\n", "side_effect", "=", "Caffe2KeypointRCNNInference", "(", "use_heatmap_max_keypoint", ")", ",", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.__init__": [[145, 156], ["super().__init__", "caffe2_modeling.Caffe2MetaArch.eval", "caffe2_modeling.set_caffe2_compatible_tensor_mode"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.set_caffe2_compatible_tensor_mode"], ["def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            torch_model (nn.Module): the detectron2 model (meta_arch) to be\n                converted.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_wrapped_model", "=", "torch_model", "\n", "self", ".", "eval", "(", ")", "\n", "set_caffe2_compatible_tensor_mode", "(", "self", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.get_caffe2_inputs": [[157, 179], ["caffe2_modeling.convert_batched_inputs_to_c2_format"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.convert_batched_inputs_to_c2_format"], ["", "def", "get_caffe2_inputs", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Convert pytorch-style structured inputs to caffe2-style inputs that\n        are tuples of tensors.\n\n        Args:\n            batched_inputs (list[dict]): inputs to a detectron2 model\n                in its standard format. Each dict has \"image\" (CHW tensor), and optionally\n                \"height\" and \"width\".\n\n        Returns:\n            tuple[Tensor]:\n                tuple of tensors that will be the inputs to the\n                :meth:`forward` method. For existing models, the first\n                is an NCHW tensor (padded and batched); the second is\n                a im_info Nx3 tensor, where the rows are\n                (height, width, unused legacy parameter)\n        \"\"\"", "\n", "return", "convert_batched_inputs_to_c2_format", "(", "\n", "batched_inputs", ",", "\n", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", ",", "\n", "self", ".", "_wrapped_model", ".", "device", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.encode_additional_info": [[181, 186], ["None"], "methods", ["None"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "\"\"\"\n        Save extra metadata that will be used by inference in the output protobuf.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.forward": [[187, 201], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward in caffe2-style. It has to use caffe2-compatible ops\n        and the method will be used for tracing.\n\n        Args:\n            inputs (tuple[Tensor]): inputs defined by :meth:`get_caffe2_input`.\n                They will be the inputs of the converted caffe2 graph.\n\n        Returns:\n            tuple[Tensor]: output tensors. They will be the outputs of the\n                converted caffe2 graph.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image": [[202, 218], ["shared.alias", "shared.alias", "shared.alias", "detectron2.structures.ImageList"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias"], ["", "def", "_caffe2_preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Caffe2 implementation of preprocess_image, which is called inside each MetaArch's forward.\n        It normalizes the input images, and the final caffe2 graph assumes the\n        inputs have been batched already.\n        \"\"\"", "\n", "data", ",", "im_info", "=", "inputs", "\n", "data", "=", "alias", "(", "data", ",", "\"data\"", ")", "\n", "im_info", "=", "alias", "(", "im_info", ",", "\"im_info\"", ")", "\n", "mean", ",", "std", "=", "self", ".", "_wrapped_model", ".", "pixel_mean", ",", "self", ".", "_wrapped_model", ".", "pixel_std", "\n", "normalized_data", "=", "(", "data", "-", "mean", ")", "/", "std", "\n", "normalized_data", "=", "alias", "(", "normalized_data", ",", "\"normalized_data\"", ")", "\n", "\n", "# Pack (data, im_info) into ImageList which is recognized by self.inference.", "\n", "images", "=", "ImageList", "(", "tensor", "=", "normalized_data", ",", "image_sizes", "=", "im_info", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.get_outputs_converter": [[219, 246], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "\"\"\"\n        Creates a function that converts outputs of the caffe2 model to\n        detectron2's standard format.\n        The function uses information in `predict_net` and `init_net` that are\n        available at inferene time. Therefore the function logic can be used in inference.\n\n        The returned function has the following signature:\n\n            def convert(batched_inputs, c2_inputs, c2_results) -> detectron2_outputs\n\n        Where\n\n            * batched_inputs (list[dict]): the original input format of the meta arch\n            * c2_inputs (tuple[Tensor]): the caffe2 inputs.\n            * c2_results (dict[str, Tensor]): the caffe2 output format,\n                corresponding to the outputs of the :meth:`forward` function.\n            * detectron2_outputs: the original output format of the meta arch.\n\n        This function can be used to compare the outputs of the original meta arch and\n        the converted caffe2 graph.\n\n        Returns:\n            callable: a callable of the above signature.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2GeneralizedRCNN.__init__": [[249, 256], ["isinstance", "caffe2_patch.patch_generalized_rcnn", "caffe2_modeling.Caffe2MetaArch.__init__", "caffe2_patch.ROIHeadsPatcher"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch_generalized_rcnn", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "GeneralizedRCNN", ")", "\n", "torch_model", "=", "patch_generalized_rcnn", "(", "torch_model", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n", "self", ".", "roi_heads_patcher", "=", "ROIHeadsPatcher", "(", "\n", "self", ".", "_wrapped_model", ".", "roi_heads", ",", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2GeneralizedRCNN.encode_additional_info": [[258, 265], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "str.encode", "str"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"GeneralizedRCNN\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2GeneralizedRCNN.forward": [[266, 276], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2GeneralizedRCNN._caffe2_preprocess_image", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.backbone", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.proposal_generator", "tuple", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.inference", "caffe2_modeling.Caffe2GeneralizedRCNN.roi_heads_patcher.mock_roi_heads", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.roi_heads", "detector_results[].flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "return", "self", ".", "_wrapped_model", ".", "inference", "(", "inputs", ")", "\n", "", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "proposals", ",", "_", "=", "self", ".", "_wrapped_model", ".", "proposal_generator", "(", "images", ",", "features", ")", "\n", "with", "self", ".", "roi_heads_patcher", ".", "mock_roi_heads", "(", ")", ":", "\n", "            ", "detector_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ")", "\n", "", "return", "tuple", "(", "detector_results", "[", "0", "]", ".", "flatten", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2GeneralizedRCNN.get_outputs_converter": [[277, 286], ["caffe2_modeling.assemble_rcnn_outputs_by_name", "detectron2.modeling.meta_arch.GeneralizedRCNN._postprocess", "int", "int"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.assemble_rcnn_outputs_by_name", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN._postprocess"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "results", "=", "assemble_rcnn_outputs_by_name", "(", "image_sizes", ",", "c2_results", ")", "\n", "return", "meta_arch", ".", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "image_sizes", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2PanopticFPN.__init__": [[289, 296], ["isinstance", "caffe2_patch.patch_generalized_rcnn", "caffe2_modeling.Caffe2MetaArch.__init__", "caffe2_patch.ROIHeadsPatcher"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch_generalized_rcnn", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "PanopticFPN", ")", "\n", "torch_model", "=", "patch_generalized_rcnn", "(", "torch_model", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n", "self", ".", "roi_heads_patcher", "=", "ROIHeadsPatcher", "(", "\n", "self", ".", "_wrapped_model", ".", "roi_heads", ",", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2PanopticFPN.forward": [[298, 313], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2PanopticFPN._caffe2_preprocess_image", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.backbone", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.sem_seg_head", "shared.alias", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.proposal_generator", "caffe2_modeling.Caffe2PanopticFPN.roi_heads_patcher.mock_roi_heads", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.roi_heads", "tuple", "detector_results[].flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "tensor_mode", "\n", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "sem_seg_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "sem_seg_head", "(", "features", ")", "\n", "sem_seg_results", "=", "alias", "(", "sem_seg_results", ",", "\"sem_seg\"", ")", "\n", "\n", "proposals", ",", "_", "=", "self", ".", "_wrapped_model", ".", "proposal_generator", "(", "images", ",", "features", ")", "\n", "\n", "with", "self", ".", "roi_heads_patcher", ".", "mock_roi_heads", "(", "self", ".", "tensor_mode", ")", ":", "\n", "            ", "detector_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ")", "\n", "\n", "", "return", "tuple", "(", "detector_results", "[", "0", "]", ".", "flatten", "(", ")", ")", "+", "(", "sem_seg_results", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2PanopticFPN.encode_additional_info": [[314, 340], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "str.encode", "caffe2_modeling._cast_to_f32", "caffe2_modeling._cast_to_f32", "str"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"PanopticFPN\"", ")", "\n", "\n", "# Inference parameters:", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_overlap_threshold\"", ",", "\n", "\"f\"", ",", "\n", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "combine_overlap_thresh", ")", ",", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_stuff_area_limit\"", ",", "\n", "\"i\"", ",", "\n", "self", ".", "_wrapped_model", ".", "combine_stuff_area_thresh", ",", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_instances_confidence_threshold\"", ",", "\n", "\"f\"", ",", "\n", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "combine_instances_score_thresh", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2PanopticFPN.get_outputs_converter": [[342, 381], ["shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "shared.get_pb_arg_valf", "caffe2_modeling.assemble_rcnn_outputs_by_name", "zip", "input_per_image.get", "input_per_image.get", "detectron2.modeling.postprocessing.sem_seg_postprocess", "detectron2.modeling.postprocessing.detector_postprocess", "processed_results.append", "detectron2.modeling.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs", "int", "int", "detectron2.modeling.postprocessing.sem_seg_postprocess.argmax"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.assemble_rcnn_outputs_by_name", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "combine_overlap_threshold", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"combine_overlap_threshold\"", ",", "None", ")", "\n", "combine_stuff_area_limit", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"combine_stuff_area_limit\"", ",", "None", ")", "\n", "combine_instances_confidence_threshold", "=", "get_pb_arg_valf", "(", "\n", "predict_net", ",", "\"combine_instances_confidence_threshold\"", ",", "None", "\n", ")", "\n", "\n", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "detector_results", "=", "assemble_rcnn_outputs_by_name", "(", "\n", "image_sizes", ",", "c2_results", ",", "force_mask_on", "=", "True", "\n", ")", "\n", "sem_seg_results", "=", "c2_results", "[", "\"sem_seg\"", "]", "\n", "\n", "# copied from meta_arch/panoptic_fpn.py ...", "\n", "processed_results", "=", "[", "]", "\n", "for", "sem_seg_result", ",", "detector_result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "sem_seg_results", ",", "detector_results", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "sem_seg_r", "=", "sem_seg_postprocess", "(", "sem_seg_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "detector_r", "=", "detector_postprocess", "(", "detector_result", ",", "height", ",", "width", ")", "\n", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "sem_seg_r", ",", "\"instances\"", ":", "detector_r", "}", ")", "\n", "\n", "panoptic_r", "=", "combine_semantic_and_instance_outputs", "(", "\n", "detector_r", ",", "\n", "sem_seg_r", ".", "argmax", "(", "dim", "=", "0", ")", ",", "\n", "combine_overlap_threshold", ",", "\n", "combine_stuff_area_limit", ",", "\n", "combine_instances_confidence_threshold", ",", "\n", ")", "\n", "processed_results", "[", "-", "1", "]", "[", "\"panoptic_seg\"", "]", "=", "panoptic_r", "\n", "", "return", "processed_results", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.__init__": [[384, 387], ["isinstance", "caffe2_modeling.Caffe2MetaArch.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "RetinaNet", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.forward": [[388, 409], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2RetinaNet._caffe2_preprocess_image", "caffe2_modeling.Caffe2RetinaNet._wrapped_model.backbone", "enumerate", "caffe2_modeling.Caffe2RetinaNet._wrapped_model.head", "enumerate", "tuple", "shared.alias", "return_tensors.append", "zip", "return_tensors.append", "return_tensors.append", "shared.alias", "shared.alias"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "tensor_mode", "\n", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "\n", "# explicitly return the images sizes to avoid removing \"im_info\" by ONNX", "\n", "# since it's not used in the forward path", "\n", "return_tensors", "=", "[", "images", ".", "image_sizes", "]", "\n", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "_wrapped_model", ".", "head_in_features", "]", "\n", "for", "i", ",", "feature_i", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "alias", "(", "feature_i", ",", "\"feature_{}\"", ".", "format", "(", "i", ")", ",", "is_backward", "=", "True", ")", "\n", "return_tensors", ".", "append", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "pred_logits", ",", "pred_anchor_deltas", "=", "self", ".", "_wrapped_model", ".", "head", "(", "features", ")", "\n", "for", "i", ",", "(", "box_cls_i", ",", "box_delta_i", ")", "in", "enumerate", "(", "zip", "(", "pred_logits", ",", "pred_anchor_deltas", ")", ")", ":", "\n", "            ", "return_tensors", ".", "append", "(", "alias", "(", "box_cls_i", ",", "\"box_cls_{}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "return_tensors", ".", "append", "(", "alias", "(", "box_delta_i", ",", "\"box_delta_{}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "\n", "", "return", "tuple", "(", "return_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.encode_additional_info": [[410, 442], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg", "str.encode", "caffe2_modeling._cast_to_f32", "caffe2_modeling._cast_to_f32", "str", "caffe2_modeling._cast_to_f32"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"RetinaNet\"", ")", "\n", "\n", "# Inference parameters:", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"score_threshold\"", ",", "\"f\"", ",", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "test_score_thresh", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"topk_candidates\"", ",", "\"i\"", ",", "self", ".", "_wrapped_model", ".", "test_topk_candidates", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"nms_threshold\"", ",", "\"f\"", ",", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "test_nms_thresh", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"max_detections_per_image\"", ",", "\n", "\"i\"", ",", "\n", "self", ".", "_wrapped_model", ".", "max_detections_per_image", ",", "\n", ")", "\n", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"bbox_reg_weights\"", ",", "\n", "\"floats\"", ",", "\n", "[", "_cast_to_f32", "(", "w", ")", "for", "w", "in", "self", ".", "_wrapped_model", ".", "box2box_transform", ".", "weights", "]", ",", "\n", ")", "\n", "self", ".", "_encode_anchor_generator_cfg", "(", "predict_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg": [[443, 451], ["io.BytesIO", "torch.save", "io.BytesIO.getvalue", "shared.check_set_pb_arg"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.check_set_pb_arg"], ["", "def", "_encode_anchor_generator_cfg", "(", "self", ",", "predict_net", ")", ":", "\n", "# serialize anchor_generator for future use", "\n", "        ", "serialized_anchor_generator", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "_wrapped_model", ".", "anchor_generator", ",", "serialized_anchor_generator", ")", "\n", "# Ideally we can put anchor generating inside the model, then we don't", "\n", "# need to store this information.", "\n", "bytes", "=", "serialized_anchor_generator", ".", "getvalue", "(", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"serialized_anchor_generator\"", ",", "\"s\"", ",", "bytes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.get_outputs_converter": [[452, 497], ["types.SimpleNamespace", "io.BytesIO", "torch.load", "shared.get_pb_arg_floats", "detectron2.modeling.box_regression.Box2BoxTransform", "shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "functools.partial", "functools.partial", "shared.get_pb_arg_vals", "len", "types.SimpleNamespace.anchor_generator", "types.SimpleNamespace.inference", "detectron2.modeling.meta_arch.GeneralizedRCNN._postprocess", "tuple", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "int", "int", "range", "range", "x.clone", "c2_results.keys", "x.startswith"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_floats", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.rcnn.GeneralizedRCNN._postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.hujiecpp_ISTR.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "self", "=", "types", ".", "SimpleNamespace", "(", ")", "\n", "serialized_anchor_generator", "=", "io", ".", "BytesIO", "(", "\n", "get_pb_arg_vals", "(", "predict_net", ",", "\"serialized_anchor_generator\"", ",", "None", ")", "\n", ")", "\n", "self", ".", "anchor_generator", "=", "torch", ".", "load", "(", "serialized_anchor_generator", ")", "\n", "bbox_reg_weights", "=", "get_pb_arg_floats", "(", "predict_net", ",", "\"bbox_reg_weights\"", ",", "None", ")", "\n", "self", ".", "box2box_transform", "=", "Box2BoxTransform", "(", "weights", "=", "tuple", "(", "bbox_reg_weights", ")", ")", "\n", "self", ".", "test_score_thresh", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"score_threshold\"", ",", "None", ")", "\n", "self", ".", "test_topk_candidates", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"topk_candidates\"", ",", "None", ")", "\n", "self", ".", "test_nms_thresh", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"nms_threshold\"", ",", "None", ")", "\n", "self", ".", "max_detections_per_image", "=", "get_pb_arg_vali", "(", "\n", "predict_net", ",", "\"max_detections_per_image\"", ",", "None", "\n", ")", "\n", "\n", "# hack to reuse inference code from RetinaNet", "\n", "self", ".", "inference", "=", "functools", ".", "partial", "(", "meta_arch", ".", "RetinaNet", ".", "inference", ",", "self", ")", "\n", "self", ".", "inference_single_image", "=", "functools", ".", "partial", "(", "\n", "meta_arch", ".", "RetinaNet", ".", "inference_single_image", ",", "self", "\n", ")", "\n", "\n", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "\n", "num_features", "=", "len", "(", "[", "x", "for", "x", "in", "c2_results", ".", "keys", "(", ")", "if", "x", ".", "startswith", "(", "\"box_cls_\"", ")", "]", ")", "\n", "pred_logits", "=", "[", "c2_results", "[", "\"box_cls_{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "num_features", ")", "]", "\n", "pred_anchor_deltas", "=", "[", "c2_results", "[", "\"box_delta_{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "num_features", ")", "]", "\n", "\n", "# For each feature level, feature should have the same batch size and", "\n", "# spatial dimension as the box_cls and box_delta.", "\n", "dummy_features", "=", "[", "x", ".", "clone", "(", ")", "[", ":", ",", "0", ":", "0", ",", ":", ",", ":", "]", "for", "x", "in", "pred_logits", "]", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "dummy_features", ")", "\n", "\n", "# self.num_classess can be inferred", "\n", "self", ".", "num_classes", "=", "pred_logits", "[", "0", "]", ".", "shape", "[", "1", "]", "//", "(", "pred_anchor_deltas", "[", "0", "]", ".", "shape", "[", "1", "]", "//", "4", ")", "\n", "\n", "pred_logits", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "self", ".", "num_classes", ")", "for", "x", "in", "pred_logits", "]", "\n", "pred_anchor_deltas", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "4", ")", "for", "x", "in", "pred_anchor_deltas", "]", "\n", "\n", "results", "=", "self", ".", "inference", "(", "anchors", ",", "pred_logits", ",", "pred_anchor_deltas", ",", "image_sizes", ")", "\n", "return", "meta_arch", ".", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "image_sizes", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.assemble_rcnn_outputs_by_name": [[30, 96], ["tensor_outputs.get", "class_nms.to", "tensor_outputs.get", "tensor_outputs.get", "tensor_outputs.get", "detectron2.structures.Instances", "NotImplementedError", "len", "detectron2.structures.RotatedBoxes", "detectron2.structures.Boxes", "torch.arange", "torch.zeros", "keypoints_tensor.transpose", "detectron2.modeling.roi_heads.keypoint_head.keypoint_rcnn_inference"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.keypoint_head.keypoint_rcnn_inference"], ["def", "assemble_rcnn_outputs_by_name", "(", "image_sizes", ",", "tensor_outputs", ",", "force_mask_on", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A function to assemble caffe2 model's outputs (i.e. Dict[str, Tensor])\n    to detectron2's format (i.e. list of Instances instance).\n    This only works when the model follows the Caffe2 detectron's naming convention.\n\n    Args:\n        image_sizes (List[List[int, int]]): [H, W] of every image.\n        tensor_outputs (Dict[str, Tensor]): external_output to its tensor.\n\n        force_mask_on (Bool): if true, the it make sure there'll be pred_masks even\n            if the mask is not found from tensor_outputs (usually due to model crash)\n    \"\"\"", "\n", "\n", "results", "=", "[", "Instances", "(", "image_size", ")", "for", "image_size", "in", "image_sizes", "]", "\n", "\n", "batch_splits", "=", "tensor_outputs", ".", "get", "(", "\"batch_splits\"", ",", "None", ")", "\n", "if", "batch_splits", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "assert", "len", "(", "image_sizes", ")", "==", "1", "\n", "result", "=", "results", "[", "0", "]", "\n", "\n", "bbox_nms", "=", "tensor_outputs", "[", "\"bbox_nms\"", "]", "\n", "score_nms", "=", "tensor_outputs", "[", "\"score_nms\"", "]", "\n", "class_nms", "=", "tensor_outputs", "[", "\"class_nms\"", "]", "\n", "# Detection will always success because Conv support 0-batch", "\n", "assert", "bbox_nms", "is", "not", "None", "\n", "assert", "score_nms", "is", "not", "None", "\n", "assert", "class_nms", "is", "not", "None", "\n", "if", "bbox_nms", ".", "shape", "[", "1", "]", "==", "5", ":", "\n", "        ", "result", ".", "pred_boxes", "=", "RotatedBoxes", "(", "bbox_nms", ")", "\n", "", "else", ":", "\n", "        ", "result", ".", "pred_boxes", "=", "Boxes", "(", "bbox_nms", ")", "\n", "", "result", ".", "scores", "=", "score_nms", "\n", "result", ".", "pred_classes", "=", "class_nms", ".", "to", "(", "torch", ".", "int64", ")", "\n", "\n", "mask_fcn_probs", "=", "tensor_outputs", ".", "get", "(", "\"mask_fcn_probs\"", ",", "None", ")", "\n", "if", "mask_fcn_probs", "is", "not", "None", ":", "\n", "# finish the mask pred", "\n", "        ", "mask_probs_pred", "=", "mask_fcn_probs", "\n", "num_masks", "=", "mask_probs_pred", ".", "shape", "[", "0", "]", "\n", "class_pred", "=", "result", ".", "pred_classes", "\n", "indices", "=", "torch", ".", "arange", "(", "num_masks", ",", "device", "=", "class_pred", ".", "device", ")", "\n", "mask_probs_pred", "=", "mask_probs_pred", "[", "indices", ",", "class_pred", "]", "[", ":", ",", "None", "]", "\n", "result", ".", "pred_masks", "=", "mask_probs_pred", "\n", "", "elif", "force_mask_on", ":", "\n", "# NOTE: there's no way to know the height/width of mask here, it won't be", "\n", "# used anyway when batch size is 0, so just set them to 0.", "\n", "        ", "result", ".", "pred_masks", "=", "torch", ".", "zeros", "(", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "", "keypoints_out", "=", "tensor_outputs", ".", "get", "(", "\"keypoints_out\"", ",", "None", ")", "\n", "kps_score", "=", "tensor_outputs", ".", "get", "(", "\"kps_score\"", ",", "None", ")", "\n", "if", "keypoints_out", "is", "not", "None", ":", "\n", "# keypoints_out: [N, 4, #kypoints], where 4 is in order of (x, y, score, prob)", "\n", "        ", "keypoints_tensor", "=", "keypoints_out", "\n", "# NOTE: it's possible that prob is not calculated if \"should_output_softmax\"", "\n", "# is set to False in HeatmapMaxKeypoint, so just using raw score, seems", "\n", "# it doesn't affect mAP. TODO: check more carefully.", "\n", "keypoint_xyp", "=", "keypoints_tensor", ".", "transpose", "(", "1", ",", "2", ")", "[", ":", ",", ":", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "result", ".", "pred_keypoints", "=", "keypoint_xyp", "\n", "", "elif", "kps_score", "is", "not", "None", ":", "\n", "# keypoint heatmap to sparse data structure", "\n", "        ", "pred_keypoint_logits", "=", "kps_score", "\n", "keypoint_head", ".", "keypoint_rcnn_inference", "(", "pred_keypoint_logits", ",", "[", "result", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling._cast_to_f32": [[98, 100], ["struct.unpack", "struct.pack"], "function", ["None"], ["", "def", "_cast_to_f32", "(", "f64", ")", ":", "\n", "    ", "return", "struct", ".", "unpack", "(", "\"f\"", ",", "struct", ".", "pack", "(", "\"f\"", ",", "f64", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.set_caffe2_compatible_tensor_mode": [[102, 108], ["model.apply", "isinstance"], "function", ["None"], ["", "def", "set_caffe2_compatible_tensor_mode", "(", "model", ",", "enable", "=", "True", ")", ":", "\n", "    ", "def", "_fn", "(", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "Caffe2Compatible", ")", ":", "\n", "            ", "m", ".", "tensor_mode", "=", "enable", "\n", "\n", "", "", "model", ".", "apply", "(", "_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.convert_batched_inputs_to_c2_format": [[110, 136], ["all", "all", "detectron2.structures.ImageList.from_tensors", "zip", "torch.Tensor", "input_per_image.get", "input_per_image.get", "torch.Tensor.append", "ImageList.from_tensors.tensor.to", "torch.Tensor.to", "isinstance", "x[].dim"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "convert_batched_inputs_to_c2_format", "(", "batched_inputs", ",", "size_divisibility", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    See get_caffe2_inputs() below.\n    \"\"\"", "\n", "assert", "all", "(", "isinstance", "(", "x", ",", "dict", ")", "for", "x", "in", "batched_inputs", ")", "\n", "assert", "all", "(", "x", "[", "\"image\"", "]", ".", "dim", "(", ")", "==", "3", "for", "x", "in", "batched_inputs", ")", "\n", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "size_divisibility", ")", "\n", "\n", "im_info", "=", "[", "]", "\n", "for", "input_per_image", ",", "image_size", "in", "zip", "(", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "        ", "target_height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "target_width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "# noqa", "\n", "# NOTE: The scale inside im_info is kept as convention and for providing", "\n", "# post-processing information if further processing is needed. For", "\n", "# current Caffe2 model definitions that don't include post-processing inside", "\n", "# the model, this number is not used.", "\n", "# NOTE: There can be a slight difference between width and height", "\n", "# scales, using a single number can results in numerical difference", "\n", "# compared with D2's post-processing.", "\n", "scale", "=", "target_height", "/", "image_size", "[", "0", "]", "\n", "im_info", ".", "append", "(", "[", "image_size", "[", "0", "]", ",", "image_size", "[", "1", "]", ",", "scale", "]", ")", "\n", "", "im_info", "=", "torch", ".", "Tensor", "(", "im_info", ")", "\n", "\n", "return", "images", ".", "tensor", ".", "to", "(", "device", ")", ",", "im_info", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._clear_jit_cache": [[20, 26], ["concrete_type_store.type_store.clear", "_jit_caching_layer.clear"], "function", ["None"], ["def", "_clear_jit_cache", "(", ")", ":", "\n", "    ", "from", "torch", ".", "jit", ".", "_recursive", "import", "concrete_type_store", "\n", "from", "torch", ".", "jit", ".", "_state", "import", "_jit_caching_layer", "\n", "\n", "concrete_type_store", ".", "type_store", ".", "clear", "(", ")", "# for modules", "\n", "_jit_caching_layer", ".", "clear", "(", ")", "# for free functions", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._add_instances_conversion_methods": [[28, 48], ["instances.get_fields", "newInstances", "instances.get_fields.items", "hasattr", "setattr", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields"], ["", "def", "_add_instances_conversion_methods", "(", "newInstances", ")", ":", "\n", "    ", "\"\"\"\n    Add from_instances methods to the scripted Instances class.\n    \"\"\"", "\n", "cls_name", "=", "newInstances", ".", "__name__", "\n", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "from_instances", "(", "instances", ":", "Instances", ")", ":", "\n", "        ", "\"\"\"\n        Create scripted Instances from original Instances\n        \"\"\"", "\n", "fields", "=", "instances", ".", "get_fields", "(", ")", "\n", "image_size", "=", "instances", ".", "image_size", "\n", "ret", "=", "newInstances", "(", "image_size", ")", "\n", "for", "name", ",", "val", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "assert", "hasattr", "(", "ret", ",", "f\"_{name}\"", ")", ",", "f\"No attribute named {name} in {cls_name}\"", "\n", "setattr", "(", "ret", ",", "name", ",", "deepcopy", "(", "val", ")", ")", "\n", "", "return", "ret", "\n", "\n", "", "newInstances", ".", "from_instances", "=", "from_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.patch_instances": [[50, 88], ["tempfile.TemporaryDirectory", "tempfile.NamedTemporaryFile", "torchscript_patch._clear_jit_cache", "torchscript_patch._gen_instance_module", "f.write", "f.flush", "f.close", "torchscript_patch._import", "getattr", "torch.jit.script", "torch._jit_internal._qualified_name", "torchscript_patch._add_instances_conversion_methods", "sys.modules.pop"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._clear_jit_cache", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._gen_instance_module", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._import", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._add_instances_conversion_methods"], ["", "@", "contextmanager", "\n", "def", "patch_instances", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    A contextmanager, under which the Instances class in detectron2 is replaced\n    by a statically-typed scriptable class, defined by `fields`.\n    See more in `scripting_with_instances`.\n    \"\"\"", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"detectron2\"", ")", "as", "dir", ",", "tempfile", ".", "NamedTemporaryFile", "(", "\n", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "suffix", "=", "\".py\"", ",", "dir", "=", "dir", ",", "delete", "=", "False", "\n", ")", "as", "f", ":", "\n", "        ", "try", ":", "\n", "# Objects that use Instances should not reuse previously-compiled", "\n", "# results in cache, because `Instances` could be a new class each time.", "\n", "            ", "_clear_jit_cache", "(", ")", "\n", "\n", "cls_name", ",", "s", "=", "_gen_instance_module", "(", "fields", ")", "\n", "f", ".", "write", "(", "s", ")", "\n", "f", ".", "flush", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "module", "=", "_import", "(", "f", ".", "name", ")", "\n", "new_instances", "=", "getattr", "(", "module", ",", "cls_name", ")", "\n", "_", "=", "torch", ".", "jit", ".", "script", "(", "new_instances", ")", "\n", "# let torchscript think Instances was scripted already", "\n", "Instances", ".", "__torch_script_class__", "=", "True", "\n", "# let torchscript find new_instances when looking for the jit type of Instances", "\n", "Instances", ".", "_jit_override_qualname", "=", "torch", ".", "_jit_internal", ".", "_qualified_name", "(", "new_instances", ")", "\n", "\n", "_add_instances_conversion_methods", "(", "new_instances", ")", "\n", "yield", "new_instances", "\n", "", "finally", ":", "\n", "            ", "try", ":", "\n", "                ", "del", "Instances", ".", "__torch_script_class__", "\n", "del", "Instances", ".", "_jit_override_qualname", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "", "sys", ".", "modules", ".", "pop", "(", "module", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._gen_instance_class": [[90, 259], ["tuple", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "_FieldType", "lines.append", "lines.append", "lines.append", "lines.append", "hasattr", "lines.append", "lines.append", "os.linesep.join", "isinstance", "fields.items", "torchscript_patch._gen_instance_class.indent"], "function", ["None"], ["", "", "", "def", "_gen_instance_class", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        fields (dict[name: type])\n    \"\"\"", "\n", "\n", "class", "_FieldType", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "name", ",", "type_", ")", ":", "\n", "            ", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "f\"Field name must be str, got {name}\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "type_", "=", "type_", "\n", "self", ".", "annotation", "=", "f\"{type_.__module__}.{type_.__name__}\"", "\n", "\n", "", "", "fields", "=", "[", "_FieldType", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "]", "\n", "\n", "def", "indent", "(", "level", ",", "s", ")", ":", "\n", "        ", "return", "\" \"", "*", "4", "*", "level", "+", "s", "\n", "\n", "", "lines", "=", "[", "]", "\n", "\n", "global", "_counter", "\n", "_counter", "+=", "1", "\n", "\n", "cls_name", "=", "\"ScriptedInstances{}\"", ".", "format", "(", "_counter", ")", "\n", "\n", "field_names", "=", "tuple", "(", "x", ".", "name", "for", "x", "in", "fields", ")", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\nclass {cls_name}:\n    def __init__(self, image_size: Tuple[int, int]):\n        self.image_size = image_size\n        self._field_names = {field_names}\n\"\"\"", "\n", ")", "\n", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "indent", "(", "2", ",", "f\"self._{f.name} = torch.jit.annotate(Optional[{f.annotation}], None)\"", ")", "\n", ")", "\n", "\n", "", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n    @property\n    def {f.name}(self) -> {f.annotation}:\n        # has to use a local for type refinement\n        # https://pytorch.org/docs/stable/jit_language_reference.html#optional-type-refinement\n        t = self._{f.name}\n        assert t is not None\n        return t\n\n    @{f.name}.setter\n    def {f.name}(self, value: {f.annotation}) -> None:\n        self._{f.name} = value\n\"\"\"", "\n", ")", "\n", "\n", "# support method `__len__`", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n    def __len__(self) -> int:\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            return len(t)\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        raise NotImplementedError(\"Empty Instances does not support __len__!\")\n\"\"\"", "\n", ")", "\n", "\n", "# support method `has`", "\n", "lines", ".", "append", "(", "\n", "\"\"\"\n    def has(self, name: str) -> bool:\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        if name == \"{f.name}\":\n            return self._{f.name} is not None\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return False\n\"\"\"", "\n", ")", "\n", "\n", "# support method `to`", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\n    def to(self, device: torch.device) -> \"{cls_name}\":\n        ret = {cls_name}(self.image_size)\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "if", "hasattr", "(", "f", ".", "type_", ",", "\"to\"", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret._{f.name} = t.to(device)\n\"\"\"", "\n", ")", "\n", "", "else", ":", "\n", "# For now, ignore fields that cannot be moved to devices.", "\n", "# Maybe can support other tensor-like classes (e.g. __torch_function__)", "\n", "            ", "pass", "\n", "", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\n\"\"\"", "\n", ")", "\n", "\n", "# support method `getitem`", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\n    def __getitem__(self, item) -> \"{cls_name}\":\n        ret = {cls_name}(self.image_size)\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret._{f.name} = t[item]\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\n\"\"\"", "\n", ")", "\n", "\n", "# support method `get_fields()`", "\n", "lines", ".", "append", "(", "\n", "\"\"\"\n    def get_fields(self) -> Dict[str, Tensor]:\n        ret = {}\n    \"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "if", "f", ".", "type_", "==", "Boxes", ":", "\n", "            ", "stmt", "=", "\"t.tensor\"", "\n", "", "elif", "f", ".", "type_", "==", "torch", ".", "Tensor", ":", "\n", "            ", "stmt", "=", "\"t\"", "\n", "", "else", ":", "\n", "            ", "stmt", "=", "f'assert False, \"unsupported type {str(f.type_)}\"'", "\n", "", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret[\"{f.name}\"] = {stmt}\n        \"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\"\"\"", "\n", ")", "\n", "return", "cls_name", ",", "os", ".", "linesep", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._gen_instance_module": [[261, 278], ["torchscript_patch._gen_instance_class"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._gen_instance_class"], ["", "def", "_gen_instance_module", "(", "fields", ")", ":", "\n", "# TODO: find a more automatic way to enable import of other classes", "\n", "    ", "s", "=", "\"\"\"\nfrom copy import deepcopy\nimport torch\nfrom torch import Tensor\nimport typing\nfrom typing import *\n\nimport detectron2\nfrom detectron2.structures import Boxes, Instances\n\n\"\"\"", "\n", "\n", "cls_name", ",", "cls_def", "=", "_gen_instance_class", "(", "fields", ")", "\n", "s", "+=", "cls_def", "\n", "return", "cls_name", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch._import": [[280, 283], ["detectron2.utils.env._import_file"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env._import_file"], ["", "def", "_import", "(", "path", ")", ":", "\n", "    ", "return", "_import_file", "(", "\n", "\"{}{}\"", ".", "format", "(", "sys", ".", "modules", "[", "__name__", "]", ".", "__name__", ",", "_counter", ")", ",", "path", ",", "make_importable", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.patch_builtin_len": [[286, 311], ["obj.__len__", "contextlib.ExitStack", "list", "stack.enter_context", "unittest.mock.patch"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.MaskLoader.MaskLoader.__len__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_patch.patch"], ["", "@", "contextmanager", "\n", "def", "patch_builtin_len", "(", "modules", "=", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n    Patch the builtin len() function of a few detectron2 modules\n    to use __len__ instead, because __len__ does not convert values to\n    integers and therefore is friendly to tracing.\n\n    Args:\n        modules (list[stsr]): names of extra modules to patch len(), in\n            addition to those in detectron2.\n    \"\"\"", "\n", "\n", "def", "_new_len", "(", "obj", ")", ":", "\n", "        ", "return", "obj", ".", "__len__", "(", ")", "\n", "\n", "", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "MODULES", "=", "[", "\n", "\"detectron2.modeling.roi_heads.fast_rcnn\"", ",", "\n", "\"detectron2.modeling.roi_heads.mask_head\"", ",", "\n", "\"detectron2.modeling.roi_heads.keypoint_head\"", ",", "\n", "]", "+", "list", "(", "modules", ")", "\n", "ctxs", "=", "[", "stack", ".", "enter_context", "(", "mock", ".", "patch", "(", "mod", "+", "\".len\"", ")", ")", "for", "mod", "in", "MODULES", "]", "\n", "for", "m", "in", "ctxs", ":", "\n", "            ", "m", ".", "side_effect", "=", "_new_len", "\n", "", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.patch_nonscriptable_classes": [[313, 356], ["hasattr", "copy.deepcopy", "torch.nn.ModuleList", "copy.deepcopy", "torch.nn.ModuleList", "torch.nn.ModuleList", "torchscript_patch..named_children", "copy.deepcopy", "delattr", "name.startswith", "delattr"], "function", ["None"], ["", "", "def", "patch_nonscriptable_classes", "(", ")", ":", "\n", "    ", "\"\"\"\n    Apply patches on a few nonscriptable detectron2 classes.\n    Should not have side-effects on eager usage.\n    \"\"\"", "\n", "# __prepare_scriptable__ can also be added to models for easier maintenance.", "\n", "# But it complicates the clean model code.", "\n", "\n", "from", "detectron2", ".", "modeling", ".", "backbone", "import", "ResNet", ",", "FPN", "\n", "\n", "# Due to https://github.com/pytorch/pytorch/issues/36061,", "\n", "# we change backbone to use ModuleList for scripting.", "\n", "# (note: this changes param names in state_dict)", "\n", "\n", "def", "prepare_resnet", "(", "self", ")", ":", "\n", "        ", "ret", "=", "deepcopy", "(", "self", ")", "\n", "ret", ".", "stages", "=", "nn", ".", "ModuleList", "(", "ret", ".", "stages", ")", "\n", "for", "k", "in", "self", ".", "stage_names", ":", "\n", "            ", "delattr", "(", "ret", ",", "k", ")", "\n", "", "return", "ret", "\n", "\n", "", "ResNet", ".", "__prepare_scriptable__", "=", "prepare_resnet", "\n", "\n", "def", "prepare_fpn", "(", "self", ")", ":", "\n", "        ", "ret", "=", "deepcopy", "(", "self", ")", "\n", "ret", ".", "lateral_convs", "=", "nn", ".", "ModuleList", "(", "ret", ".", "lateral_convs", ")", "\n", "ret", ".", "output_convs", "=", "nn", ".", "ModuleList", "(", "ret", ".", "output_convs", ")", "\n", "for", "name", ",", "_", "in", "self", ".", "named_children", "(", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"fpn_\"", ")", ":", "\n", "                ", "delattr", "(", "ret", ",", "name", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "FPN", ".", "__prepare_scriptable__", "=", "prepare_fpn", "\n", "\n", "# Annotate some attributes to be constants for the purpose of scripting,", "\n", "# even though they are not constants in eager mode.", "\n", "from", "detectron2", ".", "modeling", ".", "roi_heads", "import", "StandardROIHeads", "\n", "\n", "if", "hasattr", "(", "StandardROIHeads", ",", "\"__annotations__\"", ")", ":", "\n", "# copy first to avoid editing annotations of base class", "\n", "        ", "StandardROIHeads", ".", "__annotations__", "=", "deepcopy", "(", "StandardROIHeads", ".", "__annotations__", ")", "\n", "StandardROIHeads", ".", "__annotations__", "[", "\"mask_on\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "StandardROIHeads", ".", "__annotations__", "[", "\"keypoint_on\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.freeze_training_mode": [[362, 378], ["type", "model.modules", "hasattr"], "function", ["None"], ["@", "contextmanager", "\n", "def", "freeze_training_mode", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context manager that annotates the \"training\" attribute of every submodule\n    to constant, so that the training codepath in these modules can be\n    meta-compiled away. Upon exiting, the annotations are reverted.\n    \"\"\"", "\n", "classes", "=", "{", "type", "(", "x", ")", "for", "x", "in", "model", ".", "modules", "(", ")", "}", "\n", "# __constants__ is the old way to annotate constants and not compatible", "\n", "# with __annotations__ .", "\n", "classes", "=", "{", "x", "for", "x", "in", "classes", "if", "not", "hasattr", "(", "x", ",", "\"__constants__\"", ")", "}", "\n", "for", "cls", "in", "classes", ":", "\n", "        ", "cls", ".", "__annotations__", "[", "\"training\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "", "yield", "\n", "for", "cls", "in", "classes", ":", "\n", "        ", "cls", ".", "__annotations__", "[", "\"training\"", "]", "=", "bool", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export.export_onnx_model": [[33, 72], ["isinstance", "model.apply", "onnx.optimizer.get_available_passes", "all", "onnx.optimizer.optimize", "torch.no_grad", "io.BytesIO", "torch.onnx.export", "onnx.load_from_string", "f.getvalue"], "function", ["None"], ["def", "export_onnx_model", "(", "model", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Trace and export a model to onnx format.\n\n    Args:\n        model (nn.Module):\n        inputs (tuple[args]): the model will be called by `model(*inputs)`\n\n    Returns:\n        an onnx model\n    \"\"\"", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "\n", "# make sure all modules are in eval mode, onnx may change the training state", "\n", "# of the module if the states are not consistent", "\n", "def", "_check_eval", "(", "module", ")", ":", "\n", "        ", "assert", "not", "module", ".", "training", "\n", "\n", "", "model", ".", "apply", "(", "_check_eval", ")", "\n", "\n", "# Export the model to ONNX", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "with", "io", ".", "BytesIO", "(", ")", "as", "f", ":", "\n", "            ", "torch", ".", "onnx", ".", "export", "(", "\n", "model", ",", "\n", "inputs", ",", "\n", "f", ",", "\n", "operator_export_type", "=", "OperatorExportTypes", ".", "ONNX_ATEN_FALLBACK", ",", "\n", "# verbose=True,  # NOTE: uncomment this for debugging", "\n", "# export_params=True,", "\n", ")", "\n", "onnx_model", "=", "onnx", ".", "load_from_string", "(", "f", ".", "getvalue", "(", ")", ")", "\n", "\n", "# Apply ONNX's Optimization", "\n", "", "", "all_passes", "=", "onnx", ".", "optimizer", ".", "get_available_passes", "(", ")", "\n", "passes", "=", "[", "\"fuse_bn_into_conv\"", "]", "\n", "assert", "all", "(", "p", "in", "all_passes", "for", "p", "in", "passes", ")", "\n", "onnx_model", "=", "onnx", ".", "optimizer", ".", "optimize", "(", "onnx_model", ",", "passes", ")", "\n", "return", "onnx_model", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export._op_stats": [[74, 81], ["sorted", "sorted", "type_count.items", "type_count.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_op_stats", "(", "net_def", ")", ":", "\n", "    ", "type_count", "=", "{", "}", "\n", "for", "t", "in", "[", "op", ".", "type", "for", "op", "in", "net_def", ".", "op", "]", ":", "\n", "        ", "type_count", "[", "t", "]", "=", "type_count", ".", "get", "(", "t", ",", "0", ")", "+", "1", "\n", "", "type_count_list", "=", "sorted", "(", "type_count", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "0", "]", ")", "# alphabet", "\n", "type_count_list", "=", "sorted", "(", "type_count_list", ",", "key", "=", "lambda", "kv", ":", "-", "kv", "[", "1", "]", ")", "# count", "\n", "return", "\"\\n\"", ".", "join", "(", "\"{:>4}x {}\"", ".", "format", "(", "count", ",", "name", ")", "for", "name", ",", "count", "in", "type_count_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export._assign_device_option": [[83, 127], ["shared.infer_device_type", "caffe2.python.core.get_ssa", "caffe2_export._assign_device_option._assign_op_device_option"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.infer_device_type"], ["", "def", "_assign_device_option", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "tensor_inputs", ":", "List", "[", "torch", ".", "Tensor", "]", "\n", ")", ":", "\n", "    ", "\"\"\"\n    ONNX exported network doesn't have concept of device, assign necessary\n    device option for each op in order to make it runable on GPU runtime.\n    \"\"\"", "\n", "\n", "def", "_get_device_type", "(", "torch_tensor", ")", ":", "\n", "        ", "assert", "torch_tensor", ".", "device", ".", "type", "in", "[", "\"cpu\"", ",", "\"cuda\"", "]", "\n", "assert", "torch_tensor", ".", "device", ".", "index", "==", "0", "\n", "return", "torch_tensor", ".", "device", ".", "type", "\n", "\n", "", "def", "_assign_op_device_option", "(", "net_proto", ",", "net_ssa", ",", "blob_device_types", ")", ":", "\n", "        ", "for", "op", ",", "ssa_i", "in", "zip", "(", "net_proto", ".", "op", ",", "net_ssa", ")", ":", "\n", "            ", "if", "op", ".", "type", "in", "[", "\"CopyCPUToGPU\"", ",", "\"CopyGPUToCPU\"", "]", ":", "\n", "                ", "op", ".", "device_option", ".", "CopyFrom", "(", "core", ".", "DeviceOption", "(", "caffe2_pb2", ".", "CUDA", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "devices", "=", "[", "blob_device_types", "[", "b", "]", "for", "b", "in", "ssa_i", "[", "0", "]", "+", "ssa_i", "[", "1", "]", "]", "\n", "assert", "all", "(", "d", "==", "devices", "[", "0", "]", "for", "d", "in", "devices", ")", "\n", "if", "devices", "[", "0", "]", "==", "\"cuda\"", ":", "\n", "                    ", "op", ".", "device_option", ".", "CopyFrom", "(", "core", ".", "DeviceOption", "(", "caffe2_pb2", ".", "CUDA", ",", "0", ")", ")", "\n", "\n", "# update ops in predict_net", "\n", "", "", "", "", "predict_net_input_device_types", "=", "{", "\n", "(", "name", ",", "0", ")", ":", "_get_device_type", "(", "tensor", ")", "\n", "for", "name", ",", "tensor", "in", "zip", "(", "predict_net", ".", "external_input", ",", "tensor_inputs", ")", "\n", "}", "\n", "predict_net_device_types", "=", "infer_device_type", "(", "\n", "predict_net", ",", "known_status", "=", "predict_net_input_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "predict_net_ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "_assign_op_device_option", "(", "predict_net", ",", "predict_net_ssa", ",", "predict_net_device_types", ")", "\n", "\n", "# update ops in init_net", "\n", "init_net_ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "init_net_output_device_types", "=", "{", "\n", "(", "name", ",", "versions", "[", "name", "]", ")", ":", "predict_net_device_types", "[", "(", "name", ",", "0", ")", "]", "\n", "for", "name", "in", "init_net", ".", "external_output", "\n", "}", "\n", "init_net_device_types", "=", "infer_device_type", "(", "\n", "init_net", ",", "known_status", "=", "init_net_output_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "_assign_op_device_option", "(", "init_net", ",", "init_net_ssa", ",", "init_net_device_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export.export_caffe2_detection_model": [[129, 173], ["copy.deepcopy", "isinstance", "hasattr", "logger.info", "caffe2_export.export_onnx_model", "caffe2.python.onnx.backend.Caffe2Backend.onnx_graph_to_caffe2_net", "tabulate.tabulate", "logger.info", "shared.fuse_alias_placeholder", "any", "shared.get_params_from_init_net", "shared.remove_reshape_for_fc", "shared.construct_init_net_from_params", "shared.group_norm_replace_aten_with_caffe2", "copy.deepcopy.encode_additional_info", "logger.info", "logger.info", "shared.fuse_copy_between_cpu_and_gpu", "shared.remove_dead_end_ops", "caffe2_export._assign_device_option", "termcolor.colored", "caffe2_export._op_stats", "caffe2_export._op_stats", "type"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.export_onnx_model", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.fuse_alias_placeholder", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_params_from_init_net", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.remove_reshape_for_fc", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.construct_init_net_from_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.group_norm_replace_aten_with_caffe2", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.encode_additional_info", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.fuse_copy_between_cpu_and_gpu", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.remove_dead_end_ops", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export._assign_device_option", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export._op_stats", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export._op_stats"], ["", "def", "export_caffe2_detection_model", "(", "model", ":", "torch", ".", "nn", ".", "Module", ",", "tensor_inputs", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "    ", "\"\"\"\n    Export a caffe2-compatible Detectron2 model to caffe2 format via ONNX.\n\n    Arg:\n        model: a caffe2-compatible version of detectron2 model, defined in caffe2_modeling.py\n        tensor_inputs: a list of tensors that caffe2 model takes as input.\n    \"\"\"", "\n", "model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "assert", "hasattr", "(", "model", ",", "\"encode_additional_info\"", ")", "\n", "\n", "# Export via ONNX", "\n", "logger", ".", "info", "(", "\n", "\"Exporting a {} model via ONNX ...\"", ".", "format", "(", "type", "(", "model", ")", ".", "__name__", ")", "\n", "+", "\" Some warnings from ONNX are expected and are usually not to worry about.\"", "\n", ")", "\n", "onnx_model", "=", "export_onnx_model", "(", "model", ",", "(", "tensor_inputs", ",", ")", ")", "\n", "# Convert ONNX model to Caffe2 protobuf", "\n", "init_net", ",", "predict_net", "=", "Caffe2Backend", ".", "onnx_graph_to_caffe2_net", "(", "onnx_model", ")", "\n", "ops_table", "=", "[", "[", "op", ".", "type", ",", "op", ".", "input", ",", "op", ".", "output", "]", "for", "op", "in", "predict_net", ".", "op", "]", "\n", "table", "=", "tabulate", "(", "ops_table", ",", "headers", "=", "[", "\"type\"", ",", "\"input\"", ",", "\"output\"", "]", ",", "tablefmt", "=", "\"pipe\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"ONNX export Done. Exported predict_net (before optimizations):\\n\"", "+", "colored", "(", "table", ",", "\"cyan\"", ")", "\n", ")", "\n", "\n", "# Apply protobuf optimization", "\n", "fuse_alias_placeholder", "(", "predict_net", ",", "init_net", ")", "\n", "if", "any", "(", "t", ".", "device", ".", "type", "!=", "\"cpu\"", "for", "t", "in", "tensor_inputs", ")", ":", "\n", "        ", "fuse_copy_between_cpu_and_gpu", "(", "predict_net", ")", "\n", "remove_dead_end_ops", "(", "init_net", ")", "\n", "_assign_device_option", "(", "predict_net", ",", "init_net", ",", "tensor_inputs", ")", "\n", "", "params", ",", "device_options", "=", "get_params_from_init_net", "(", "init_net", ")", "\n", "predict_net", ",", "params", "=", "remove_reshape_for_fc", "(", "predict_net", ",", "params", ")", "\n", "init_net", "=", "construct_init_net_from_params", "(", "params", ",", "device_options", ")", "\n", "group_norm_replace_aten_with_caffe2", "(", "predict_net", ")", "\n", "\n", "# Record necessary information for running the pb model in Detectron2 system.", "\n", "model", ".", "encode_additional_info", "(", "predict_net", ",", "init_net", ")", "\n", "\n", "logger", ".", "info", "(", "\"Operators used in predict_net: \\n{}\"", ".", "format", "(", "_op_stats", "(", "predict_net", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Operators used in init_net: \\n{}\"", ".", "format", "(", "_op_stats", "(", "init_net", ")", ")", ")", "\n", "\n", "return", "predict_net", ",", "init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export.run_and_save_graph": [[175, 208], ["logger.info", "shared.save_graph", "logger.info", "shared.ScopedWS", "ws.RunNetOnce", "set", "zip", "logger.info", "shared.save_graph", "ws.Blobs", "ws.FeedBlob", "ws.RunNetOnce", "ws.FetchBlob", "logger.warning", "ws.Blobs", "isinstance", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.save_graph", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.save_graph"], ["", "def", "run_and_save_graph", "(", "predict_net", ",", "init_net", ",", "tensor_inputs", ",", "graph_save_path", ")", ":", "\n", "    ", "\"\"\"\n    Run the caffe2 model on given inputs, recording the shape and draw the graph.\n\n    predict_net/init_net: caffe2 model.\n    tensor_inputs: a list of tensors that caffe2 model takes as input.\n    graph_save_path: path for saving graph of exported model.\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "\"Saving graph of ONNX exported model to {} ...\"", ".", "format", "(", "graph_save_path", ")", ")", "\n", "save_graph", "(", "predict_net", ",", "graph_save_path", ",", "op_only", "=", "False", ")", "\n", "\n", "# Run the exported Caffe2 net", "\n", "logger", ".", "info", "(", "\"Running ONNX exported model ...\"", ")", "\n", "with", "ScopedWS", "(", "\"__ws_tmp__\"", ",", "True", ")", "as", "ws", ":", "\n", "        ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "initialized_blobs", "=", "set", "(", "ws", ".", "Blobs", "(", ")", ")", "\n", "uninitialized", "=", "[", "inp", "for", "inp", "in", "predict_net", ".", "external_input", "if", "inp", "not", "in", "initialized_blobs", "]", "\n", "for", "name", ",", "blob", "in", "zip", "(", "uninitialized", ",", "tensor_inputs", ")", ":", "\n", "            ", "ws", ".", "FeedBlob", "(", "name", ",", "blob", ")", "\n", "\n", "", "try", ":", "\n", "            ", "ws", ".", "RunNetOnce", "(", "predict_net", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Encountered RuntimeError: \\n{}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "\n", "", "ws_blobs", "=", "{", "b", ":", "ws", ".", "FetchBlob", "(", "b", ")", "for", "b", "in", "ws", ".", "Blobs", "(", ")", "}", "\n", "blob_sizes", "=", "{", "b", ":", "ws_blobs", "[", "b", "]", ".", "shape", "for", "b", "in", "ws_blobs", "if", "isinstance", "(", "ws_blobs", "[", "b", "]", ",", "np", ".", "ndarray", ")", "}", "\n", "\n", "logger", ".", "info", "(", "\"Saving graph with blob shapes to {} ...\"", ".", "format", "(", "graph_save_path", ")", ")", "\n", "save_graph", "(", "predict_net", ",", "graph_save_path", ",", "op_only", "=", "False", ",", "blob_sizes", "=", "blob_sizes", ")", "\n", "\n", "return", "ws_blobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2Boxes.__init__": [[29, 35], ["isinstance", "tensor.size", "tensor.dim", "tensor.size"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "assert", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "in", "[", "4", ",", "5", ",", "6", "]", ",", "tensor", ".", "size", "(", ")", "\n", "# TODO: make tensor immutable when dim is Nx5 for Boxes,", "\n", "# and Nx6 for RotatedBoxes?", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.__init__": [[48, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "im_info", ",", "indices", ",", "extra_fields", "=", "None", ")", ":", "\n", "# [N, 3] -> (H, W, Scale)", "\n", "        ", "self", ".", "im_info", "=", "im_info", "\n", "# [N,] -> indice of batch to which the instance belongs", "\n", "self", ".", "indices", "=", "indices", "\n", "# [N, ...]", "\n", "self", ".", "batch_extra_fields", "=", "extra_fields", "or", "{", "}", "\n", "\n", "self", ".", "image_size", "=", "self", ".", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields": [[58, 71], ["c10.InstancesList.batch_extra_fields.items"], "methods", ["None"], ["", "def", "get_fields", "(", "self", ")", ":", "\n", "        ", "\"\"\"like `get_fields` in the Instances object,\n        but return each field in tensor representations\"\"\"", "\n", "ret", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "# if isinstance(v, torch.Tensor):", "\n", "#     tensor_rep = v", "\n", "# elif isinstance(v, (Boxes, Keypoints)):", "\n", "#     tensor_rep = v.tensor", "\n", "# else:", "\n", "#     raise ValueError(\"Can't find tensor representation for: {}\".format())", "\n", "            ", "ret", "[", "k", "]", "=", "v", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has": [[72, 74], ["None"], "methods", ["None"], ["", "def", "has", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "batch_extra_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.set": [[75, 82], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "data_len", "=", "len", "(", "value", ")", "\n", "if", "len", "(", "self", ".", "batch_extra_fields", ")", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "self", ")", "==", "data_len", "\n", ")", ",", "\"Adding a field of length {} to a Instances of length {}\"", ".", "format", "(", "data_len", ",", "len", "(", "self", ")", ")", "\n", "", "self", ".", "batch_extra_fields", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.__setattr__": [[83, 88], ["object.__setattr__", "c10.InstancesList.set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.__setattr__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "val", ")", ":", "\n", "        ", "if", "name", "in", "[", "\"im_info\"", ",", "\"indices\"", ",", "\"batch_extra_fields\"", ",", "\"image_size\"", "]", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "set", "(", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.__getattr__": [[89, 93], ["AttributeError"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "not", "in", "self", ".", "batch_extra_fields", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Cannot find field '{}' in the given Instances!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "self", ".", "batch_extra_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.flatten": [[97, 105], ["c10.InstancesList.batch_extra_fields.items", "isinstance", "ret.append", "ret.append"], "methods", ["None"], ["", "def", "flatten", "(", "self", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "_", ",", "v", "in", "self", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "(", "Boxes", ",", "Keypoints", ")", ")", ":", "\n", "                ", "ret", ".", "append", "(", "v", ".", "tensor", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "v", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.to_d2_instances_list": [[106, 145], ["enumerate", "isinstance", "all", "detectron2.structures.Instances", "instances_list.batch_extra_fields.items", "ret.append", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "isinstance", "isinstance", "issubclass", "isinstance", "detectron2.structures.Instances.set", "isinstance", "detectron2.structures.Instances.set", "issubclass", "int", "int", "detectron2.structures.Instances.set", "detectron2.structures.Boxes", "detectron2.structures.Instances.set", "issubclass", "info[].item", "info[].item", "detectron2.structures.Keypoints", "detectron2.structures.Instances.set", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "staticmethod", "\n", "def", "to_d2_instances_list", "(", "instances_list", ")", ":", "\n", "        ", "\"\"\"\n        Convert InstancesList to List[Instances]. The input `instances_list` can\n        also be a List[Instances], in this case this method is a non-op.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "instances_list", ",", "InstancesList", ")", ":", "\n", "            ", "assert", "all", "(", "isinstance", "(", "x", ",", "Instances", ")", "for", "x", "in", "instances_list", ")", "\n", "return", "instances_list", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "i", ",", "info", "in", "enumerate", "(", "instances_list", ".", "im_info", ")", ":", "\n", "            ", "instances", "=", "Instances", "(", "torch", ".", "Size", "(", "[", "int", "(", "info", "[", "0", "]", ".", "item", "(", ")", ")", ",", "int", "(", "info", "[", "1", "]", ".", "item", "(", ")", ")", "]", ")", ")", "\n", "\n", "ids", "=", "instances_list", ".", "indices", "==", "i", "\n", "for", "k", ",", "v", "in", "instances_list", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "v", "[", "ids", "]", ")", "\n", "continue", "\n", "", "elif", "isinstance", "(", "v", ",", "Boxes", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "v", "[", "ids", ",", "-", "4", ":", "]", ")", "\n", "continue", "\n", "\n", "", "target_type", ",", "tensor_source", "=", "v", "\n", "assert", "isinstance", "(", "tensor_source", ",", "torch", ".", "Tensor", ")", "\n", "assert", "tensor_source", ".", "shape", "[", "0", "]", "==", "instances_list", ".", "indices", ".", "shape", "[", "0", "]", "\n", "tensor_source", "=", "tensor_source", "[", "ids", "]", "\n", "\n", "if", "issubclass", "(", "target_type", ",", "Boxes", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "Boxes", "(", "tensor_source", "[", ":", ",", "-", "4", ":", "]", ")", ")", "\n", "", "elif", "issubclass", "(", "target_type", ",", "Keypoints", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "Keypoints", "(", "tensor_source", ")", ")", "\n", "", "elif", "issubclass", "(", "target_type", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "tensor_source", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Can't handle targe type: {}\"", ".", "format", "(", "target_type", ")", ")", "\n", "\n", "", "", "ret", ".", "append", "(", "instances", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2Compatible._get_tensor_mode": [[152, 154], ["None"], "methods", ["None"], ["def", "_get_tensor_mode", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tensor_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2Compatible._set_tensor_mode": [[155, 157], ["None"], "methods", ["None"], ["", "def", "_set_tensor_mode", "(", "self", ",", "v", ")", ":", "\n", "        ", "self", ".", "_tensor_mode", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2RPN._generate_proposals": [[165, 247], ["isinstance", "isinstance", "zip", "c10.Caffe2RPN.c2_postprocess", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "iter", "scores.detach.detach.detach", "bbox_deltas.detach.detach.detach", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "rpn_rois_list.append", "rpn_roi_probs_list.append", "len", "list", "int", "int", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "shared.to_device", "len", "len", "shared.to_device", "math.log2", "math.log2", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2RPN.c2_postprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device"], ["    ", "def", "_generate_proposals", "(", "\n", "self", ",", "images", ",", "objectness_logits_pred", ",", "anchor_deltas_pred", ",", "gt_instances", "=", "None", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "images", ",", "ImageList", ")", "\n", "if", "self", ".", "tensor_mode", ":", "\n", "            ", "im_info", "=", "images", ".", "image_sizes", "\n", "", "else", ":", "\n", "            ", "im_info", "=", "torch", ".", "tensor", "(", "[", "[", "im_sz", "[", "0", "]", ",", "im_sz", "[", "1", "]", ",", "1.0", "]", "for", "im_sz", "in", "images", ".", "image_sizes", "]", ")", ".", "to", "(", "\n", "images", ".", "tensor", ".", "device", "\n", ")", "\n", "", "assert", "isinstance", "(", "im_info", ",", "torch", ".", "Tensor", ")", "\n", "\n", "rpn_rois_list", "=", "[", "]", "\n", "rpn_roi_probs_list", "=", "[", "]", "\n", "for", "scores", ",", "bbox_deltas", ",", "cell_anchors_tensor", ",", "feat_stride", "in", "zip", "(", "\n", "objectness_logits_pred", ",", "\n", "anchor_deltas_pred", ",", "\n", "iter", "(", "self", ".", "anchor_generator", ".", "cell_anchors", ")", ",", "\n", "self", ".", "anchor_generator", ".", "strides", ",", "\n", ")", ":", "\n", "            ", "scores", "=", "scores", ".", "detach", "(", ")", "\n", "bbox_deltas", "=", "bbox_deltas", ".", "detach", "(", ")", "\n", "\n", "rpn_rois", ",", "rpn_roi_probs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "GenerateProposals", "(", "\n", "scores", ",", "\n", "bbox_deltas", ",", "\n", "im_info", ",", "\n", "cell_anchors_tensor", ",", "\n", "spatial_scale", "=", "1.0", "/", "feat_stride", ",", "\n", "pre_nms_topN", "=", "self", ".", "pre_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "post_nms_topN", "=", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "nms_thresh", "=", "self", ".", "nms_thresh", ",", "\n", "min_size", "=", "self", ".", "min_box_size", ",", "\n", "# correct_transform_coords=True,  # deprecated argument", "\n", "angle_bound_on", "=", "True", ",", "# Default", "\n", "angle_bound_lo", "=", "-", "180", ",", "\n", "angle_bound_hi", "=", "180", ",", "\n", "clip_angle_thresh", "=", "1.0", ",", "# Default", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "rpn_rois_list", ".", "append", "(", "rpn_rois", ")", "\n", "rpn_roi_probs_list", ".", "append", "(", "rpn_roi_probs", ")", "\n", "\n", "# For FPN in D2, in RPN all proposals from different levels are concated", "\n", "# together, ranked and picked by top post_nms_topk. Then in ROIPooler", "\n", "# it calculates level_assignments and calls the RoIAlign from", "\n", "# the corresponding level.", "\n", "\n", "", "if", "len", "(", "objectness_logits_pred", ")", "==", "1", ":", "\n", "            ", "rpn_rois", "=", "rpn_rois_list", "[", "0", "]", "\n", "rpn_roi_probs", "=", "rpn_roi_probs_list", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "rpn_rois_list", ")", "==", "len", "(", "rpn_roi_probs_list", ")", "\n", "rpn_post_nms_topN", "=", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", "\n", "\n", "device", "=", "rpn_rois_list", "[", "0", "]", ".", "device", "\n", "input_list", "=", "[", "to_device", "(", "x", ",", "\"cpu\"", ")", "for", "x", "in", "(", "rpn_rois_list", "+", "rpn_roi_probs_list", ")", "]", "\n", "\n", "# TODO remove this after confirming rpn_max_level/rpn_min_level", "\n", "# is not needed in CollectRpnProposals.", "\n", "feature_strides", "=", "list", "(", "self", ".", "anchor_generator", ".", "strides", ")", "\n", "rpn_min_level", "=", "int", "(", "math", ".", "log2", "(", "feature_strides", "[", "0", "]", ")", ")", "\n", "rpn_max_level", "=", "int", "(", "math", ".", "log2", "(", "feature_strides", "[", "-", "1", "]", ")", ")", "\n", "assert", "(", "rpn_max_level", "-", "rpn_min_level", "+", "1", ")", "==", "len", "(", "\n", "rpn_rois_list", "\n", ")", ",", "\"CollectRpnProposals requires continuous levels\"", "\n", "\n", "rpn_rois", "=", "torch", ".", "ops", ".", "_caffe2", ".", "CollectRpnProposals", "(", "\n", "input_list", ",", "\n", "# NOTE: in current implementation, rpn_max_level and rpn_min_level", "\n", "# are not needed, only the subtraction of two matters and it", "\n", "# can be infer from the number of inputs. Keep them now for", "\n", "# consistency.", "\n", "rpn_max_level", "=", "2", "+", "len", "(", "rpn_rois_list", ")", "-", "1", ",", "\n", "rpn_min_level", "=", "2", ",", "\n", "rpn_post_nms_topN", "=", "rpn_post_nms_topN", ",", "\n", ")", "\n", "rpn_rois", "=", "to_device", "(", "rpn_rois", ",", "device", ")", "\n", "rpn_roi_probs", "=", "[", "]", "\n", "\n", "", "proposals", "=", "self", ".", "c2_postprocess", "(", "im_info", ",", "rpn_rois", ",", "rpn_roi_probs", ",", "self", ".", "tensor_mode", ")", "\n", "return", "proposals", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2RPN.forward": [[248, 257], ["c10.Caffe2RPN.rpn_head", "c10.Caffe2RPN._generate_proposals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2RPN._generate_proposals"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "gt_instances", "=", "None", ")", ":", "\n", "        ", "assert", "not", "self", ".", "training", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "objectness_logits_pred", ",", "anchor_deltas_pred", "=", "self", ".", "rpn_head", "(", "features", ")", "\n", "return", "self", ".", "_generate_proposals", "(", "\n", "images", ",", "\n", "objectness_logits_pred", ",", "\n", "anchor_deltas_pred", ",", "\n", "gt_instances", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2RPN.c2_postprocess": [[259, 274], ["c10.InstancesList", "c10.InstancesList.to_d2_instances_list", "c10.Caffe2Boxes"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.to_d2_instances_list"], ["", "@", "staticmethod", "\n", "def", "c2_postprocess", "(", "im_info", ",", "rpn_rois", ",", "rpn_roi_probs", ",", "tensor_mode", ")", ":", "\n", "        ", "proposals", "=", "InstancesList", "(", "\n", "im_info", "=", "im_info", ",", "\n", "indices", "=", "rpn_rois", "[", ":", ",", "0", "]", ",", "\n", "extra_fields", "=", "{", "\n", "\"proposal_boxes\"", ":", "Caffe2Boxes", "(", "rpn_rois", ")", ",", "\n", "\"objectness_logits\"", ":", "(", "torch", ".", "Tensor", ",", "rpn_roi_probs", ")", ",", "\n", "}", ",", "\n", ")", "\n", "if", "not", "tensor_mode", ":", "\n", "            ", "proposals", "=", "InstancesList", ".", "to_d2_instances_list", "(", "proposals", ")", "\n", "", "else", ":", "\n", "            ", "proposals", "=", "[", "proposals", "]", "\n", "", "return", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2ROIPooler.c2_preprocess": [[277, 287], ["all", "all", "detectron2.modeling.poolers.convert_boxes_to_pooler_format", "isinstance", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.poolers.convert_boxes_to_pooler_format"], ["    ", "@", "staticmethod", "\n", "def", "c2_preprocess", "(", "box_lists", ")", ":", "\n", "        ", "assert", "all", "(", "isinstance", "(", "x", ",", "Boxes", ")", "for", "x", "in", "box_lists", ")", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "Caffe2Boxes", ")", "for", "x", "in", "box_lists", ")", ":", "\n", "# input is pure-tensor based", "\n", "            ", "assert", "len", "(", "box_lists", ")", "==", "1", "\n", "pooler_fmt_boxes", "=", "box_lists", "[", "0", "]", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "pooler_fmt_boxes", "=", "poolers", ".", "convert_boxes_to_pooler_format", "(", "box_lists", ")", "\n", "", "return", "pooler_fmt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2ROIPooler.forward": [[288, 359], ["c10.Caffe2ROIPooler.c2_preprocess", "len", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "zip", "detectron2.layers.cat", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "isinstance", "c2_roi_align", "shared.to_device", "shared.to_device", "isinstance", "c2_roi_align", "roi_feat_fpn_list.append", "bool", "detectron2.layers.cat.numel", "rois_idx_restore_int32.numel", "float", "int", "int", "int", "float", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2ROIPooler.c2_preprocess", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device"], ["", "def", "forward", "(", "self", ",", "x", ",", "box_lists", ")", ":", "\n", "        ", "assert", "not", "self", ".", "training", "\n", "\n", "pooler_fmt_boxes", "=", "self", ".", "c2_preprocess", "(", "box_lists", ")", "\n", "num_level_assignments", "=", "len", "(", "self", ".", "level_poolers", ")", "\n", "\n", "if", "num_level_assignments", "==", "1", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "level_poolers", "[", "0", "]", ",", "ROIAlignRotated", ")", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlignRotated", "\n", "aligned", "=", "True", "\n", "", "else", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlign", "\n", "aligned", "=", "self", ".", "level_poolers", "[", "0", "]", ".", "aligned", "\n", "\n", "", "out", "=", "c2_roi_align", "(", "\n", "x", "[", "0", "]", ",", "\n", "pooler_fmt_boxes", ",", "\n", "order", "=", "\"NCHW\"", ",", "\n", "spatial_scale", "=", "float", "(", "self", ".", "level_poolers", "[", "0", "]", ".", "spatial_scale", ")", ",", "\n", "pooled_h", "=", "int", "(", "self", ".", "output_size", "[", "0", "]", ")", ",", "\n", "pooled_w", "=", "int", "(", "self", ".", "output_size", "[", "1", "]", ")", ",", "\n", "sampling_ratio", "=", "int", "(", "self", ".", "level_poolers", "[", "0", "]", ".", "sampling_ratio", ")", ",", "\n", "aligned", "=", "aligned", ",", "\n", ")", "\n", "return", "out", "\n", "\n", "", "device", "=", "pooler_fmt_boxes", ".", "device", "\n", "assert", "(", "\n", "self", ".", "max_level", "-", "self", ".", "min_level", "+", "1", "==", "4", "\n", ")", ",", "\"Currently DistributeFpnProposals only support 4 levels\"", "\n", "fpn_outputs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "DistributeFpnProposals", "(", "\n", "to_device", "(", "pooler_fmt_boxes", ",", "\"cpu\"", ")", ",", "\n", "roi_canonical_scale", "=", "self", ".", "canonical_box_size", ",", "\n", "roi_canonical_level", "=", "self", ".", "canonical_level", ",", "\n", "roi_max_level", "=", "self", ".", "max_level", ",", "\n", "roi_min_level", "=", "self", ".", "min_level", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "fpn_outputs", "=", "[", "to_device", "(", "x", ",", "device", ")", "for", "x", "in", "fpn_outputs", "]", "\n", "\n", "rois_fpn_list", "=", "fpn_outputs", "[", ":", "-", "1", "]", "\n", "rois_idx_restore_int32", "=", "fpn_outputs", "[", "-", "1", "]", "\n", "\n", "roi_feat_fpn_list", "=", "[", "]", "\n", "for", "roi_fpn", ",", "x_level", ",", "pooler", "in", "zip", "(", "rois_fpn_list", ",", "x", ",", "self", ".", "level_poolers", ")", ":", "\n", "            ", "if", "isinstance", "(", "pooler", ",", "ROIAlignRotated", ")", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlignRotated", "\n", "aligned", "=", "True", "\n", "", "else", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlign", "\n", "aligned", "=", "bool", "(", "pooler", ".", "aligned", ")", "\n", "\n", "", "roi_feat_fpn", "=", "c2_roi_align", "(", "\n", "x_level", ",", "\n", "roi_fpn", ",", "\n", "order", "=", "\"NCHW\"", ",", "\n", "spatial_scale", "=", "float", "(", "pooler", ".", "spatial_scale", ")", ",", "\n", "pooled_h", "=", "int", "(", "self", ".", "output_size", "[", "0", "]", ")", ",", "\n", "pooled_w", "=", "int", "(", "self", ".", "output_size", "[", "1", "]", ")", ",", "\n", "sampling_ratio", "=", "int", "(", "pooler", ".", "sampling_ratio", ")", ",", "\n", "aligned", "=", "aligned", ",", "\n", ")", "\n", "roi_feat_fpn_list", ".", "append", "(", "roi_feat_fpn", ")", "\n", "\n", "", "roi_feat_shuffled", "=", "cat", "(", "roi_feat_fpn_list", ",", "dim", "=", "0", ")", "\n", "assert", "roi_feat_shuffled", ".", "numel", "(", ")", ">", "0", "and", "rois_idx_restore_int32", ".", "numel", "(", ")", ">", "0", ",", "(", "\n", "\"Caffe2 export requires tracing with a model checkpoint + input that can produce valid\"", "\n", "\" detections. But no detections were obtained with the given checkpoint and input!\"", "\n", ")", "\n", "roi_feat", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BatchPermutation", "(", "roi_feat_shuffled", ",", "rois_idx_restore_int32", ")", "\n", "return", "roi_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2FastRCNNOutputsInference.__init__": [[362, 364], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tensor_mode", ")", ":", "\n", "        ", "self", ".", "tensor_mode", "=", "tensor_mode", "# whether the output is caffe2 tensor mode", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2FastRCNNOutputsInference.__call__": [[365, 493], ["type().cat", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "shared.to_device", "shared.to_device", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "detectron2.layers.cat", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "c10.InstancesList", "len", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "detectron2.layers.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "roi_class_nms.to.to.to", "c10.InstancesList.to_d2_instances_list", "shared.alias.int().tolist", "list", "type", "float", "float", "int", "torch.full", "torch.full", "torch.full", "torch.full", "shared.alias.to().split", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.full", "torch.full", "torch.full", "torch.full", "enumerate", "c10.Caffe2Boxes", "shared.alias.int", "enumerate", "shared.alias.to", "int", "len", "x.item"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.to_d2_instances_list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "__call__", "(", "self", ",", "box_predictor", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\" equivalent to FastRCNNOutputLayers.inference \"\"\"", "\n", "num_classes", "=", "box_predictor", ".", "num_classes", "\n", "score_thresh", "=", "box_predictor", ".", "test_score_thresh", "\n", "nms_thresh", "=", "box_predictor", ".", "test_nms_thresh", "\n", "topk_per_image", "=", "box_predictor", ".", "test_topk_per_image", "\n", "is_rotated", "=", "len", "(", "box_predictor", ".", "box2box_transform", ".", "weights", ")", "==", "5", "\n", "\n", "if", "is_rotated", ":", "\n", "            ", "box_dim", "=", "5", "\n", "assert", "box_predictor", ".", "box2box_transform", ".", "weights", "[", "4", "]", "==", "1", ",", "(", "\n", "\"The weights for Rotated BBoxTransform in C2 have only 4 dimensions,\"", "\n", "+", "\" thus enforcing the angle weight to be 1 for now\"", "\n", ")", "\n", "box2box_transform_weights", "=", "box_predictor", ".", "box2box_transform", ".", "weights", "[", ":", "4", "]", "\n", "", "else", ":", "\n", "            ", "box_dim", "=", "4", "\n", "box2box_transform_weights", "=", "box_predictor", ".", "box2box_transform", ".", "weights", "\n", "\n", "", "class_logits", ",", "box_regression", "=", "predictions", "\n", "if", "num_classes", "+", "1", "==", "class_logits", ".", "shape", "[", "1", "]", ":", "\n", "            ", "class_prob", "=", "F", ".", "softmax", "(", "class_logits", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "num_classes", "==", "class_logits", ".", "shape", "[", "1", "]", "\n", "class_prob", "=", "F", ".", "sigmoid", "(", "class_logits", ")", "\n", "# BoxWithNMSLimit will infer num_classes from the shape of the class_prob", "\n", "# So append a zero column as placeholder for the background class", "\n", "class_prob", "=", "torch", ".", "cat", "(", "(", "class_prob", ",", "torch", ".", "zeros", "(", "class_prob", ".", "shape", "[", "0", "]", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "assert", "box_regression", ".", "shape", "[", "1", "]", "%", "box_dim", "==", "0", "\n", "cls_agnostic_bbox_reg", "=", "box_regression", ".", "shape", "[", "1", "]", "//", "box_dim", "==", "1", "\n", "\n", "input_tensor_mode", "=", "proposals", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", ".", "shape", "[", "1", "]", "==", "box_dim", "+", "1", "\n", "\n", "rois", "=", "type", "(", "proposals", "[", "0", "]", ".", "proposal_boxes", ")", ".", "cat", "(", "[", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "]", ")", "\n", "device", ",", "dtype", "=", "rois", ".", "tensor", ".", "device", ",", "rois", ".", "tensor", ".", "dtype", "\n", "if", "input_tensor_mode", ":", "\n", "            ", "im_info", "=", "proposals", "[", "0", "]", ".", "image_size", "\n", "rois", "=", "rois", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "im_info", "=", "torch", ".", "tensor", "(", "\n", "[", "[", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ",", "1.0", "]", "for", "sz", "in", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "]", "\n", ")", "\n", "batch_ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "b", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "len", "(", "p", ")", "for", "p", "in", "proposals", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "batch_ids", ",", "rois", ".", "tensor", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "roi_pred_bbox", ",", "roi_batch_splits", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BBoxTransform", "(", "\n", "to_device", "(", "rois", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "box_regression", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "im_info", ",", "\"cpu\"", ")", ",", "\n", "weights", "=", "box2box_transform_weights", ",", "\n", "apply_scale", "=", "True", ",", "\n", "rotated", "=", "is_rotated", ",", "\n", "angle_bound_on", "=", "True", ",", "\n", "angle_bound_lo", "=", "-", "180", ",", "\n", "angle_bound_hi", "=", "180", ",", "\n", "clip_angle_thresh", "=", "1.0", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "roi_pred_bbox", "=", "to_device", "(", "roi_pred_bbox", ",", "device", ")", "\n", "roi_batch_splits", "=", "to_device", "(", "roi_batch_splits", ",", "device", ")", "\n", "\n", "nms_outputs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BoxWithNMSLimit", "(", "\n", "to_device", "(", "class_prob", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "roi_pred_bbox", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "roi_batch_splits", ",", "\"cpu\"", ")", ",", "\n", "score_thresh", "=", "float", "(", "score_thresh", ")", ",", "\n", "nms", "=", "float", "(", "nms_thresh", ")", ",", "\n", "detections_per_im", "=", "int", "(", "topk_per_image", ")", ",", "\n", "soft_nms_enabled", "=", "False", ",", "\n", "soft_nms_method", "=", "\"linear\"", ",", "\n", "soft_nms_sigma", "=", "0.5", ",", "\n", "soft_nms_min_score_thres", "=", "0.001", ",", "\n", "rotated", "=", "is_rotated", ",", "\n", "cls_agnostic_bbox_reg", "=", "cls_agnostic_bbox_reg", ",", "\n", "input_boxes_include_bg_cls", "=", "False", ",", "\n", "output_classes_include_bg_cls", "=", "False", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "roi_score_nms", "=", "to_device", "(", "nms_outputs", "[", "0", "]", ",", "device", ")", "\n", "roi_bbox_nms", "=", "to_device", "(", "nms_outputs", "[", "1", "]", ",", "device", ")", "\n", "roi_class_nms", "=", "to_device", "(", "nms_outputs", "[", "2", "]", ",", "device", ")", "\n", "roi_batch_splits_nms", "=", "to_device", "(", "nms_outputs", "[", "3", "]", ",", "device", ")", "\n", "roi_keeps_nms", "=", "to_device", "(", "nms_outputs", "[", "4", "]", ",", "device", ")", "\n", "roi_keeps_size_nms", "=", "to_device", "(", "nms_outputs", "[", "5", "]", ",", "device", ")", "\n", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "roi_class_nms", "=", "roi_class_nms", ".", "to", "(", "torch", ".", "int64", ")", "\n", "\n", "", "roi_batch_ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "b", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "int", "(", "x", ".", "item", "(", ")", ")", "for", "x", "in", "roi_batch_splits_nms", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "roi_class_nms", "=", "alias", "(", "roi_class_nms", ",", "\"class_nms\"", ")", "\n", "roi_score_nms", "=", "alias", "(", "roi_score_nms", ",", "\"score_nms\"", ")", "\n", "roi_bbox_nms", "=", "alias", "(", "roi_bbox_nms", ",", "\"bbox_nms\"", ")", "\n", "roi_batch_splits_nms", "=", "alias", "(", "roi_batch_splits_nms", ",", "\"batch_splits_nms\"", ")", "\n", "roi_keeps_nms", "=", "alias", "(", "roi_keeps_nms", ",", "\"keeps_nms\"", ")", "\n", "roi_keeps_size_nms", "=", "alias", "(", "roi_keeps_size_nms", ",", "\"keeps_size_nms\"", ")", "\n", "\n", "results", "=", "InstancesList", "(", "\n", "im_info", "=", "im_info", ",", "\n", "indices", "=", "roi_batch_ids", "[", ":", ",", "0", "]", ",", "\n", "extra_fields", "=", "{", "\n", "\"pred_boxes\"", ":", "Caffe2Boxes", "(", "roi_bbox_nms", ")", ",", "\n", "\"scores\"", ":", "roi_score_nms", ",", "\n", "\"pred_classes\"", ":", "roi_class_nms", ",", "\n", "}", ",", "\n", ")", "\n", "\n", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "results", "=", "InstancesList", ".", "to_d2_instances_list", "(", "results", ")", "\n", "batch_splits", "=", "roi_batch_splits_nms", ".", "int", "(", ")", ".", "tolist", "(", ")", "\n", "kept_indices", "=", "list", "(", "roi_keeps_nms", ".", "to", "(", "torch", ".", "int64", ")", ".", "split", "(", "batch_splits", ")", ")", "\n", "", "else", ":", "\n", "            ", "results", "=", "[", "results", "]", "\n", "kept_indices", "=", "[", "roi_keeps_nms", "]", "\n", "\n", "", "return", "results", ",", "kept_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2MaskRCNNInference.__call__": [[496, 505], ["all", "pred_mask_logits.sigmoid", "shared.alias", "detectron2.modeling.roi_heads.mask_head.mask_rcnn_inference", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.roi_heads.mask_head.mask_rcnn_inference"], ["    ", "def", "__call__", "(", "self", ",", "pred_mask_logits", ",", "pred_instances", ")", ":", "\n", "        ", "\"\"\" equivalent to mask_head.mask_rcnn_inference \"\"\"", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "InstancesList", ")", "for", "x", "in", "pred_instances", ")", ":", "\n", "            ", "assert", "len", "(", "pred_instances", ")", "==", "1", "\n", "mask_probs_pred", "=", "pred_mask_logits", ".", "sigmoid", "(", ")", "\n", "mask_probs_pred", "=", "alias", "(", "mask_probs_pred", ",", "\"mask_fcn_probs\"", ")", "\n", "pred_instances", "[", "0", "]", ".", "pred_masks", "=", "mask_probs_pred", "\n", "", "else", ":", "\n", "            ", "mask_rcnn_inference", "(", "pred_mask_logits", ",", "pred_instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2KeypointRCNNInference.__init__": [[508, 510], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "use_heatmap_max_keypoint", ")", ":", "\n", "        ", "self", ".", "use_heatmap_max_keypoint", "=", "use_heatmap_max_keypoint", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.Caffe2KeypointRCNNInference.__call__": [[511, 528], ["shared.alias", "all", "isinstance", "len", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "shared.to_device", "shared.alias", "shared.to_device"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.alias", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.to_device"], ["", "def", "__call__", "(", "self", ",", "pred_keypoint_logits", ",", "pred_instances", ")", ":", "\n", "# just return the keypoint heatmap for now,", "\n", "# there will be option to call HeatmapMaxKeypointOp", "\n", "        ", "output", "=", "alias", "(", "pred_keypoint_logits", ",", "\"kps_score\"", ")", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "InstancesList", ")", "for", "x", "in", "pred_instances", ")", ":", "\n", "            ", "assert", "len", "(", "pred_instances", ")", "==", "1", "\n", "if", "self", ".", "use_heatmap_max_keypoint", ":", "\n", "                ", "device", "=", "output", ".", "device", "\n", "output", "=", "torch", ".", "ops", ".", "_caffe2", ".", "HeatmapMaxKeypoint", "(", "\n", "to_device", "(", "output", ",", "\"cpu\"", ")", ",", "\n", "pred_instances", "[", "0", "]", ".", "pred_boxes", ".", "tensor", ",", "\n", "should_output_softmax", "=", "True", ",", "# worth make it configerable?", "\n", ")", "\n", "output", "=", "to_device", "(", "output", ",", "device", ")", "\n", "output", "=", "alias", "(", "output", ",", "\"keypoints_out\"", ")", "\n", "", "pred_instances", "[", "0", "]", ".", "pred_keypoints", "=", "output", "\n", "", "return", "pred_keypoint_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.__init__": [[68, 91], ["isinstance", "isinstance", "type", "C2MetaArch", "api.Caffe2Tracer.traceable_model.get_caffe2_inputs", "api.add_export_config", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2MetaArch.get_caffe2_inputs", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.add_export_config"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "model", ":", "nn", ".", "Module", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode): a detectron2 config, with extra export-related options\n                added by :func:`add_export_config`. It's used to construct\n                caffe2-compatible model.\n            model (nn.Module): An original pytorch model. Must be among a few official models\n                in detectron2 that can be converted to become caffe2-compatible automatically.\n                Weights have to be already loaded to this model.\n            inputs: sample inputs that the given model takes for inference.\n                Will be used to trace the model. For most models, random inputs with\n                no detected objects will not work as they lead to wrong traces.\n        \"\"\"", "\n", "assert", "isinstance", "(", "cfg", ",", "CfgNode", ")", ",", "cfg", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", ",", "type", "(", "model", ")", "\n", "\n", "if", "\"EXPORT_CAFFE2\"", "not", "in", "cfg", ":", "\n", "            ", "cfg", "=", "add_export_config", "(", "cfg", ")", "# will just the defaults", "\n", "# TODO make it support custom models, by passing in c2 model directly", "\n", "", "C2MetaArch", "=", "META_ARCH_CAFFE2_EXPORT_TYPE_MAP", "[", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "]", "\n", "self", ".", "traceable_model", "=", "C2MetaArch", "(", "cfg", ",", "copy", ".", "deepcopy", "(", "model", ")", ")", "\n", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "traceable_inputs", "=", "self", ".", "traceable_model", ".", "get_caffe2_inputs", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.export_caffe2": [[92, 107], ["export_caffe2_detection_model", "api.Caffe2Model"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export.export_caffe2_detection_model"], ["", "def", "export_caffe2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to Caffe2's protobuf format.\n        The returned object can be saved with its :meth:`.save_protobuf()` method.\n        The result can be loaded and executed using Caffe2 runtime.\n\n        Returns:\n            :class:`Caffe2Model`\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "export_caffe2_detection_model", "\n", "\n", "predict_net", ",", "init_net", "=", "export_caffe2_detection_model", "(", "\n", "self", ".", "traceable_model", ",", "self", ".", "traceable_inputs", "\n", ")", "\n", "return", "Caffe2Model", "(", "predict_net", ",", "init_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.export_onnx": [[108, 122], ["export_onnx_model_impl"], "methods", ["None"], ["", "def", "export_onnx", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to ONNX format.\n        Note that the exported model contains custom ops only available in caffe2, therefore it\n        cannot be directly executed by other runtime (such as onnxruntime or TensorRT).\n        Post-processing or transformation passes may be applied on the model to accommodate\n        different runtimes, but we currently do not provide support for them.\n\n        Returns:\n            onnx.ModelProto: an onnx model.\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "export_onnx_model", "as", "export_onnx_model_impl", "\n", "\n", "return", "export_onnx_model_impl", "(", "self", ".", "traceable_model", ",", "(", "self", ".", "traceable_inputs", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.export_torchscript": [[123, 135], ["logging.getLogger", "logging.getLogger.info", "torch.no_grad", "torch.jit.trace"], "methods", ["None"], ["", "def", "export_torchscript", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to a ``torch.jit.TracedModule`` by tracing.\n        The returned object can be saved to a file by ``.save()``.\n\n        Returns:\n            torch.jit.TracedModule: a torch TracedModule\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Tracing the model with torch.jit.trace ...\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "torch", ".", "jit", ".", "trace", "(", "self", ".", "traceable_model", ",", "(", "self", ".", "traceable_inputs", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.__init__": [[153, 159], ["torch.nn.Module.__init__", "api.Caffe2Model.eval"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eval", "(", ")", "# always in eval mode", "\n", "self", ".", "_predict_net", "=", "predict_net", "\n", "self", ".", "_init_net", "=", "init_net", "\n", "self", ".", "_predictor", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.predict_net": [[162, 168], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "predict_net", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        caffe2.core.Net: the underlying caffe2 predict net\n        \"\"\"", "\n", "return", "self", ".", "_predict_net", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.init_net": [[169, 175], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "init_net", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        caffe2.core.Net: the underlying caffe2 init net\n        \"\"\"", "\n", "return", "self", ".", "_init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.save_protobuf": [[176, 201], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.file_io.PathManager.exists", "detectron2.utils.file_io.PathManager.mkdirs", "detectron2.utils.file_io.PathManager.open", "f.write", "detectron2.utils.file_io.PathManager.open", "f.write", "detectron2.utils.file_io.PathManager.open", "f.write", "os.path.join", "api.Caffe2Model._predict_net.SerializeToString", "os.path.join", "str", "os.path.join", "api.Caffe2Model._init_net.SerializeToString"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["", "def", "save_protobuf", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the model as caffe2's protobuf format.\n        It saves the following files:\n\n            * \"model.pb\": definition of the graph. Can be visualized with\n              tools like `netron <https://github.com/lutzroeder/netron>`_.\n            * \"model_init.pb\": model parameters\n            * \"model.pbtxt\": human-readable definition of the graph. Not\n              needed for deployment.\n\n        Args:\n            output_dir (str): the output directory to save protobuf files.\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Saving model to {} ...\"", ".", "format", "(", "output_dir", ")", ")", "\n", "if", "not", "PathManager", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "output_dir", ")", "\n", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model.pb\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "self", ".", "_predict_net", ".", "SerializeToString", "(", ")", ")", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model.pbtxt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "self", ".", "_predict_net", ")", ")", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model_init.pb\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "self", ".", "_init_net", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.save_graph": [[202, 223], ["shared.save_graph", "shared.get_pb_arg_vali", "shared.get_pb_arg_vals().decode", "caffe2_modeling.convert_batched_inputs_to_c2_format", "run_and_save_graph", "x.cpu().numpy", "shared.get_pb_arg_vals", "x.cpu"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.save_graph", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.convert_batched_inputs_to_c2_format", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_export.run_and_save_graph", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals"], ["", "", "def", "save_graph", "(", "self", ",", "output_file", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Save the graph as SVG format.\n\n        Args:\n            output_file (str): a SVG file\n            inputs: optional inputs given to the model.\n                If given, the inputs will be used to run the graph to record\n                shape of every tensor. The shape information will be\n                saved together with the graph.\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "run_and_save_graph", "\n", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "save_graph", "(", "self", ".", "_predict_net", ",", "output_file", ",", "op_only", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "size_divisibility", "=", "get_pb_arg_vali", "(", "self", ".", "_predict_net", ",", "\"size_divisibility\"", ",", "0", ")", "\n", "device", "=", "get_pb_arg_vals", "(", "self", ".", "_predict_net", ",", "\"device\"", ",", "b\"cpu\"", ")", ".", "decode", "(", "\"ascii\"", ")", "\n", "inputs", "=", "convert_batched_inputs_to_c2_format", "(", "inputs", ",", "size_divisibility", ",", "device", ")", "\n", "inputs", "=", "[", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "x", "in", "inputs", "]", "\n", "run_and_save_graph", "(", "self", ".", "_predict_net", ",", "self", ".", "_init_net", ",", "inputs", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.load_protobuf": [[224, 244], ["caffe2.proto.caffe2_pb2.NetDef", "caffe2.proto.caffe2_pb2.NetDef", "api.Caffe2Model", "detectron2.utils.file_io.PathManager.open", "caffe2.proto.caffe2_pb2.NetDef.ParseFromString", "detectron2.utils.file_io.PathManager.open", "caffe2.proto.caffe2_pb2.NetDef.ParseFromString", "os.path.join", "f.read", "os.path.join", "f.read"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "load_protobuf", "(", "dir", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dir (str): a directory used to save Caffe2Model with\n                :meth:`save_protobuf`.\n                The files \"model.pb\" and \"model_init.pb\" are needed.\n\n        Returns:\n            Caffe2Model: the caffe2 model loaded from this directory.\n        \"\"\"", "\n", "predict_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model.pb\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "predict_net", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "init_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_init.pb\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "init_net", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "return", "Caffe2Model", "(", "predict_net", ",", "init_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Model.__call__": [[245, 258], ["api.Caffe2Model._predictor", "caffe2_inference.ProtobufDetectionModel"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        An interface that wraps around a Caffe2 model and mimics detectron2's models'\n        input/output format. See details about the format at :doc:`/tutorials/models`.\n        This is used to compare the outputs of caffe2 model with its original torch model.\n\n        Due to the extra conversion between Pytorch/Caffe2, this method is not meant for\n        benchmark. Because of the conversion, this method also has dependency\n        on detectron2 in order to convert to detectron2's output format.\n        \"\"\"", "\n", "if", "self", ".", "_predictor", "is", "None", ":", "\n", "            ", "self", ".", "_predictor", "=", "ProtobufDetectionModel", "(", "self", ".", "_predict_net", ",", "self", ".", "_init_net", ")", "\n", "", "return", "self", ".", "_predictor", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.add_export_config": [[25, 43], ["cfg.is_frozen", "cfg.defrost", "detectron2.config.CfgNode", "cfg.freeze"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze"], ["def", "add_export_config", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Add options needed by caffe2 export.\n\n    Args:\n        cfg (CfgNode): a detectron2 config\n\n    Returns:\n        CfgNode:\n            an updated config with new options that will be used by :class:`Caffe2Tracer`.\n    \"\"\"", "\n", "is_frozen", "=", "cfg", ".", "is_frozen", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "EXPORT_CAFFE2", "=", "CfgNode", "(", ")", "\n", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "=", "False", "\n", "if", "is_frozen", ":", "\n", "        ", "cfg", ".", "freeze", "(", ")", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.export_caffe2_model": [[260, 266], ["logging.getLogger", "logging.getLogger.warning", "api.Caffe2Tracer.export_caffe2", "api.Caffe2Tracer"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.export_caffe2"], ["", "", "def", "export_caffe2_model", "(", "cfg", ",", "model", ",", "inputs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"export_caffe2_model() is deprecated. Please use `Caffe2Tracer().export_caffe2() instead.\"", "\n", ")", "\n", "return", "Caffe2Tracer", "(", "cfg", ",", "model", ",", "inputs", ")", ".", "export_caffe2", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.export_onnx_model": [[268, 274], ["logging.getLogger", "logging.getLogger.warning", "api.Caffe2Tracer.export_onnx", "api.Caffe2Tracer"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.api.Caffe2Tracer.export_onnx"], ["", "def", "export_onnx_model", "(", "cfg", ",", "model", ",", "inputs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"export_caffe2_model() is deprecated. Please use `Caffe2Tracer().export_onnx() instead.\"", "\n", ")", "\n", "return", "Caffe2Tracer", "(", "cfg", ",", "model", ",", "inputs", ")", ".", "export_onnx", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema.flatten": [[35, 38], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema.__call__": [[39, 41], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema._concat": [[42, 51], ["isinstance", "sizes.append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_concat", "(", "values", ")", ":", "\n", "        ", "ret", "=", "(", ")", "\n", "sizes", "=", "[", "]", "\n", "for", "v", "in", "values", ":", "\n", "            ", "assert", "isinstance", "(", "v", ",", "tuple", ")", ",", "\"Flattened results must be a tuple\"", "\n", "ret", "=", "ret", "+", "v", "\n", "sizes", ".", "append", "(", "len", "(", "v", ")", ")", "\n", "", "return", "ret", ",", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema._split": [[52, 64], ["len", "range", "sum", "len", "ret.append", "len", "sum", "sum", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_split", "(", "values", ",", "sizes", ")", ":", "\n", "        ", "if", "len", "(", "sizes", ")", ":", "\n", "            ", "expected_len", "=", "sum", "(", "sizes", ")", "\n", "assert", "(", "\n", "len", "(", "values", ")", "==", "expected_len", "\n", ")", ",", "f\"Values has length {len(values)} but expect length {expected_len}.\"", "\n", "", "ret", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "sizes", ")", ")", ":", "\n", "            ", "begin", ",", "end", "=", "sum", "(", "sizes", "[", ":", "k", "]", ")", ",", "sum", "(", "sizes", "[", ":", "k", "+", "1", "]", ")", "\n", "ret", ".", "append", "(", "values", "[", "begin", ":", "end", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.ListSchema.__call__": [[71, 79], ["flatten.ListSchema._split", "list", "len", "len", "ValueError", "m", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema._split", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "values", "=", "self", ".", "_split", "(", "values", ",", "self", ".", "sizes", ")", "\n", "if", "len", "(", "values", ")", "!=", "len", "(", "self", ".", "schemas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Values has length {len(values)} but schemas \"", "f\"has length {len(self.schemas)}!\"", "\n", ")", "\n", "", "values", "=", "[", "m", "(", "v", ")", "for", "m", ",", "v", "in", "zip", "(", "self", ".", "schemas", ",", "values", ")", "]", "\n", "return", "list", "(", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.ListSchema.flatten": [[80, 85], ["cls._concat", "flatten.flatten_to_tuple", "cls"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.Schema._concat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.flatten_to_tuple"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "res", "=", "[", "flatten_to_tuple", "(", "k", ")", "for", "k", "in", "obj", "]", "\n", "values", ",", "sizes", "=", "cls", ".", "_concat", "(", "[", "k", "[", "0", "]", "for", "k", "in", "res", "]", ")", "\n", "return", "values", ",", "cls", "(", "[", "k", "[", "1", "]", "for", "k", "in", "res", "]", ",", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TupleSchema.__call__": [[89, 91], ["tuple", "flatten.ListSchema.__call__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.ISTRDatasetMapper.__call__"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "tuple", "(", "super", "(", ")", ".", "__call__", "(", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.IdentitySchema.__call__": [[95, 97], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "values", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.IdentitySchema.flatten": [[98, 101], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "return", "(", "obj", ",", ")", ",", "cls", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.DictSchema.__call__": [[107, 110], ["flatten.ListSchema.__call__", "dict", "zip"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.ISTRDatasetMapper.__call__"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "values", "=", "super", "(", ")", ".", "__call__", "(", "values", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "keys", ",", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.DictSchema.flatten": [[111, 120], ["obj.keys", "sorted", "ListSchema.flatten", "obj.keys", "cls", "isinstance", "KeyError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "for", "k", "in", "obj", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "k", ",", "str", ")", ":", "\n", "                ", "raise", "KeyError", "(", "\"Only support flattening dictionaries if keys are str.\"", ")", "\n", "", "", "keys", "=", "sorted", "(", "obj", ".", "keys", "(", ")", ")", "\n", "values", "=", "[", "obj", "[", "k", "]", "for", "k", "in", "keys", "]", "\n", "ret", ",", "schema", "=", "ListSchema", ".", "flatten", "(", "values", ")", "\n", "return", "ret", ",", "cls", "(", "schema", ".", "schemas", ",", "schema", ".", "sizes", ",", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.InstancesSchema.__call__": [[124, 128], ["flatten.DictSchema.__call__", "detectron2.structures.Instances"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.ISTRDatasetMapper.__call__"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "image_size", ",", "fields", "=", "values", "[", "-", "1", "]", ",", "values", "[", ":", "-", "1", "]", "\n", "fields", "=", "super", "(", ")", ".", "__call__", "(", "fields", ")", "\n", "return", "Instances", "(", "image_size", ",", "**", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.InstancesSchema.flatten": [[129, 136], ["flatten.DictSchema.flatten", "obj.get_fields", "isinstance", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.get_fields"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "ret", ",", "schema", "=", "super", "(", ")", ".", "flatten", "(", "obj", ".", "get_fields", "(", ")", ")", "\n", "size", "=", "obj", ".", "image_size", "\n", "if", "not", "isinstance", "(", "size", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "size", "=", "torch", ".", "tensor", "(", "size", ")", "\n", "", "return", "ret", "+", "(", "size", ",", ")", ",", "schema", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.__call__": [[147, 149], ["detectron2.utils.registry.locate"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry.locate"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "locate", "(", "self", ".", "class_name", ")", "(", "values", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten": [[150, 153], ["cls", "detectron2.utils.registry._convert_target_to_string", "type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.registry._convert_target_to_string"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "return", "(", "obj", ".", "tensor", ",", ")", ",", "cls", "(", "_convert_target_to_string", "(", "type", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TracingAdapter.__init__": [[224, 275], ["torch.nn.Module.__init__", "isinstance", "flatten.flatten_to_tuple", "all", "isinstance", "tuple", "model", "isinstance", "isinstance", "ValueError", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.flatten_to_tuple"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "inputs", ",", "\n", "inference_func", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "allow_non_tensor", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: an nn.Module\n            inputs: An input argument or a tuple of input arguments used to call model.\n                After flattening, it has to only consist of tensors.\n            inference_func: a callable that takes (model, *inputs), calls the\n                model with inputs, and return outputs. By default it\n                is ``lambda model, *inputs: model(*inputs)``. Can be override\n                if you need to call the model differently.\n            allow_non_tensor: allow inputs/outputs to contain non-tensor objects.\n                This option will filter out non-tensor objects to make the\n                model traceable, but ``inputs_schema``/``outputs_schema`` cannot be\n                used anymore because inputs/outputs cannot be rebuilt from pure tensors.\n                This is useful when you're only interested in the single trace of\n                execution (e.g. for flop count), but not interested in\n                generalizing the traced graph to new inputs.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "(", "nn", ".", "parallel", ".", "distributed", ".", "DistributedDataParallel", ",", "nn", ".", "DataParallel", ")", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "self", ".", "model", "=", "model", "\n", "if", "not", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "            ", "inputs", "=", "(", "inputs", ",", ")", "\n", "", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "allow_non_tensor", "=", "allow_non_tensor", "\n", "\n", "if", "inference_func", "is", "None", ":", "\n", "            ", "inference_func", "=", "lambda", "model", ",", "*", "inputs", ":", "model", "(", "*", "inputs", ")", "# noqa", "\n", "", "self", ".", "inference_func", "=", "inference_func", "\n", "\n", "self", ".", "flattened_inputs", ",", "self", ".", "inputs_schema", "=", "flatten_to_tuple", "(", "inputs", ")", "\n", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "for", "x", "in", "self", ".", "flattened_inputs", ")", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "allow_non_tensor", ":", "\n", "            ", "self", ".", "flattened_inputs", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "flattened_inputs", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "]", "\n", ")", "\n", "self", ".", "inputs_schema", "=", "None", "\n", "", "else", ":", "\n", "            ", "for", "input", "in", "self", ".", "flattened_inputs", ":", "\n", "                ", "if", "not", "isinstance", "(", "input", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Inputs for tracing must only contain tensors. \"", "\n", "f\"Got a {type(input)} instead.\"", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TracingAdapter.forward": [[278, 315], ["torch.no_grad", "torchscript_patch.patch_builtin_len", "flatten.TracingAdapter.inference_func", "flatten.flatten_to_tuple", "tuple", "flatten.TracingAdapter.inputs_schema", "len", "len", "ValueError", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.torchscript_patch.patch_builtin_len", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.flatten_to_tuple"], ["", "", "", "", "def", "forward", "(", "self", ",", "*", "args", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ",", "patch_builtin_len", "(", ")", ":", "\n", "            ", "if", "self", ".", "inputs_schema", "is", "not", "None", ":", "\n", "                ", "inputs_orig_format", "=", "self", ".", "inputs_schema", "(", "args", ")", "\n", "", "else", ":", "\n", "                ", "if", "args", "!=", "self", ".", "flattened_inputs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"TracingAdapter does not contain valid inputs_schema.\"", "\n", "\" So it cannot generalize to other inputs and must be\"", "\n", "\" traced with `.flattened_inputs`.\"", "\n", ")", "\n", "", "inputs_orig_format", "=", "self", ".", "inputs", "\n", "\n", "", "outputs", "=", "self", ".", "inference_func", "(", "self", ".", "model", ",", "*", "inputs_orig_format", ")", "\n", "flattened_outputs", ",", "schema", "=", "flatten_to_tuple", "(", "outputs", ")", "\n", "\n", "flattened_output_tensors", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "flattened_outputs", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "]", "\n", ")", "\n", "if", "len", "(", "flattened_output_tensors", ")", "<", "len", "(", "flattened_outputs", ")", ":", "\n", "                ", "if", "self", ".", "allow_non_tensor", ":", "\n", "                    ", "flattened_outputs", "=", "flattened_output_tensors", "\n", "self", ".", "outputs_schema", "=", "None", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Model cannot be traced because some model outputs \"", "\n", "\"cannot flatten to tensors.\"", "\n", ")", "\n", "", "", "else", ":", "# schema is valid", "\n", "                ", "if", "self", ".", "outputs_schema", "is", "None", ":", "\n", "                    ", "self", ".", "outputs_schema", "=", "schema", "\n", "", "else", ":", "\n", "                    ", "assert", "self", ".", "outputs_schema", "==", "schema", ",", "(", "\n", "\"Model should always return outputs with the same \"", "\n", "\"structure so it can be traced!\"", "\n", ")", "\n", "", "", "return", "flattened_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TracingAdapter._create_wrapper": [[316, 328], ["flatten.flatten_to_tuple", "traced_model", "flatten.TracingAdapter.outputs_schema"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.flatten_to_tuple"], ["", "", "def", "_create_wrapper", "(", "self", ",", "traced_model", ")", ":", "\n", "        ", "\"\"\"\n        Return a function that has an input/output interface the same as the\n        original model, but it calls the given traced model under the hood.\n        \"\"\"", "\n", "\n", "def", "forward", "(", "*", "args", ")", ":", "\n", "            ", "flattened_inputs", ",", "_", "=", "flatten_to_tuple", "(", "args", ")", "\n", "flattened_outputs", "=", "traced_model", "(", "*", "flattened_inputs", ")", "\n", "return", "self", ".", "outputs_schema", "(", "flattened_outputs", ")", "\n", "\n", "", "return", "forward", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.flatten_to_tuple": [[157, 183], ["F.flatten", "isinstance"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "flatten_to_tuple", "(", "obj", ")", ":", "\n", "    ", "\"\"\"\n    Flatten an object so it can be used for PyTorch tracing.\n    Also returns how to rebuild the original object from the flattened outputs.\n\n    Returns:\n        res (tuple): the flattened results that can be used as tracing outputs\n        schema: an object with a ``__call__`` method such that ``schema(res) == obj``.\n             It is a pure dataclass that can be serialized.\n    \"\"\"", "\n", "schemas", "=", "[", "\n", "(", "(", "str", ",", "bytes", ")", ",", "IdentitySchema", ")", ",", "\n", "(", "list", ",", "ListSchema", ")", ",", "\n", "(", "tuple", ",", "TupleSchema", ")", ",", "\n", "(", "collections", ".", "abc", ".", "Mapping", ",", "DictSchema", ")", ",", "\n", "(", "Instances", ",", "InstancesSchema", ")", ",", "\n", "(", "Boxes", ",", "TensorWrapSchema", ")", ",", "\n", "]", "\n", "for", "klass", ",", "schema", "in", "schemas", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "klass", ")", ":", "\n", "            ", "F", "=", "schema", "\n", "break", "\n", "", "", "else", ":", "\n", "        ", "F", "=", "IdentitySchema", "\n", "\n", "", "return", "F", ".", "flatten", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufModel.__init__": [[26, 47], ["logger.info", "super().__init__", "isinstance", "isinstance", "caffe2.python.core.Net", "logger.info", "set", "next", "shared.ScopedWS", "ws.RunNetOnce", "ws.CreateNet", "caffe2_inference.ProtobufModel.net.Proto", "ws.Blobs", "uninitialized_external_input.append", "ws.CreateBlob"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Initializing ProtobufModel for: {predict_net.name} ...\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "assert", "isinstance", "(", "init_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "# create unique temporary workspace for each instance", "\n", "self", ".", "ws_name", "=", "\"__tmp_ProtobufModel_{}__\"", ".", "format", "(", "next", "(", "self", ".", "_ids", ")", ")", "\n", "self", ".", "net", "=", "core", ".", "Net", "(", "predict_net", ")", "\n", "\n", "logger", ".", "info", "(", "\"Running init_net once to fill the parameters ...\"", ")", "\n", "with", "ScopedWS", "(", "self", ".", "ws_name", ",", "is_reset", "=", "True", ",", "is_cleanup", "=", "False", ")", "as", "ws", ":", "\n", "            ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "uninitialized_external_input", "=", "[", "]", "\n", "for", "blob", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_input", ":", "\n", "                ", "if", "blob", "not", "in", "ws", ".", "Blobs", "(", ")", ":", "\n", "                    ", "uninitialized_external_input", ".", "append", "(", "blob", ")", "\n", "ws", ".", "CreateBlob", "(", "blob", ")", "\n", "", "", "ws", ".", "CreateNet", "(", "self", ".", "net", ")", "\n", "\n", "", "self", ".", "_error_msgs", "=", "set", "(", ")", "\n", "self", ".", "_input_blobs", "=", "uninitialized_external_input", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufModel._infer_output_devices": [[48, 70], ["caffe2_inference.ProtobufModel.net.Proto", "shared.infer_device_type", "caffe2.python.core.get_ssa", "caffe2_inference.ProtobufModel._infer_output_devices._get_device_type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.infer_device_type"], ["", "def", "_infer_output_devices", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[str]: list of device for each external output\n        \"\"\"", "\n", "\n", "def", "_get_device_type", "(", "torch_tensor", ")", ":", "\n", "            ", "assert", "torch_tensor", ".", "device", ".", "type", "in", "[", "\"cpu\"", ",", "\"cuda\"", "]", "\n", "assert", "torch_tensor", ".", "device", ".", "index", "==", "0", "\n", "return", "torch_tensor", ".", "device", ".", "type", "\n", "\n", "", "predict_net", "=", "self", ".", "net", ".", "Proto", "(", ")", "\n", "input_device_types", "=", "{", "\n", "(", "name", ",", "0", ")", ":", "_get_device_type", "(", "tensor", ")", "for", "name", ",", "tensor", "in", "zip", "(", "self", ".", "_input_blobs", ",", "inputs", ")", "\n", "}", "\n", "device_type_map", "=", "infer_device_type", "(", "\n", "predict_net", ",", "known_status", "=", "input_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "versioned_outputs", "=", "[", "(", "name", ",", "versions", "[", "name", "]", ")", "for", "name", "in", "predict_net", ".", "external_output", "]", "\n", "output_devices", "=", "[", "device_type_map", "[", "outp", "]", "for", "outp", "in", "versioned_outputs", "]", "\n", "return", "output_devices", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufModel.forward": [[71, 123], ["zip", "tuple", "len", "len", "shared.ScopedWS", "zip", "any", "caffe2_inference.ProtobufModel._infer_output_devices", "outputs.append", "len", "ws.FeedBlob", "ws.RunNet", "ws.FetchBlob", "caffe2_inference.ProtobufModel.net.Proto", "ws.FeedBlob", "caffe2_inference.ProtobufModel.net.Proto", "isinstance", "RuntimeError", "torch.tensor().to", "logger.warning", "caffe2_inference.ProtobufModel.net.Proto", "caffe2_inference.ProtobufModel._error_msgs.add", "logger.warning", "caffe2_inference.ProtobufModel.net.Proto", "caffe2_inference.ProtobufModel.net.Proto", "torch.tensor", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufModel._infer_output_devices", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (tuple[torch.Tensor])\n\n        Returns:\n            tuple[torch.Tensor]\n        \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "self", ".", "_input_blobs", ")", ",", "(", "\n", "f\"Length of inputs ({len(inputs)}) \"", "\n", "f\"doesn't match the required input blobs: {self._input_blobs}\"", "\n", ")", "\n", "\n", "with", "ScopedWS", "(", "self", ".", "ws_name", ",", "is_reset", "=", "False", ",", "is_cleanup", "=", "False", ")", "as", "ws", ":", "\n", "            ", "for", "b", ",", "tensor", "in", "zip", "(", "self", ".", "_input_blobs", ",", "inputs", ")", ":", "\n", "                ", "ws", ".", "FeedBlob", "(", "b", ",", "tensor", ")", "\n", "\n", "", "try", ":", "\n", "                ", "ws", ".", "RunNet", "(", "self", ".", "net", ".", "Proto", "(", ")", ".", "name", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "not", "str", "(", "e", ")", "in", "self", ".", "_error_msgs", ":", "\n", "                    ", "self", ".", "_error_msgs", ".", "add", "(", "str", "(", "e", ")", ")", "\n", "logger", ".", "warning", "(", "\"Encountered new RuntimeError: \\n{}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "", "logger", ".", "warning", "(", "\"Catch the error and use partial results.\"", ")", "\n", "\n", "", "c2_outputs", "=", "[", "ws", ".", "FetchBlob", "(", "b", ")", "for", "b", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", "]", "\n", "# Remove outputs of current run, this is necessary in order to", "\n", "# prevent fetching the result from previous run if the model fails", "\n", "# in the middle.", "\n", "for", "b", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ":", "\n", "# Needs to create uninitialized blob to make the net runable.", "\n", "# This is \"equivalent\" to: ws.RemoveBlob(b) then ws.CreateBlob(b),", "\n", "# but there'no such API.", "\n", "                ", "ws", ".", "FeedBlob", "(", "b", ",", "f\"{b}, a C++ native class of type nullptr (uninitialized).\"", ")", "\n", "\n", "# Cast output to torch.Tensor on the desired device", "\n", "", "", "output_devices", "=", "(", "\n", "self", ".", "_infer_output_devices", "(", "inputs", ")", "\n", "if", "any", "(", "t", ".", "device", ".", "type", "!=", "\"cpu\"", "for", "t", "in", "inputs", ")", "\n", "else", "[", "\"cpu\"", "for", "_", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", "]", "\n", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "for", "name", ",", "c2_output", ",", "device", "in", "zip", "(", "\n", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ",", "c2_outputs", ",", "output_devices", "\n", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "c2_output", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Invalid output for blob {}, received: {}\"", ".", "format", "(", "name", ",", "c2_output", ")", "\n", ")", "\n", "", "outputs", ".", "append", "(", "torch", ".", "tensor", "(", "c2_output", ")", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "", "return", "tuple", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufDetectionModel.__init__": [[131, 150], ["super().__init__", "caffe2_inference.ProtobufModel", "shared.get_pb_arg_vali", "shared.get_pb_arg_vals().decode", "shared.get_pb_arg_vals", "shared.get_pb_arg_vals.get_outputs_converter", "shared.get_pb_arg_vals", "shared.get_pb_arg_vals.decode"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.Caffe2RetinaNet.get_outputs_converter", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ",", "*", ",", "convert_outputs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predict_net, init_net (core.Net): caffe2 nets\n            convert_outptus (callable): a function that converts caffe2\n                outputs to the same format of the original pytorch model.\n                By default, use the one defined in the caffe2 meta_arch.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "protobuf_model", "=", "ProtobufModel", "(", "predict_net", ",", "init_net", ")", "\n", "self", ".", "size_divisibility", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"size_divisibility\"", ",", "0", ")", "\n", "self", ".", "device", "=", "get_pb_arg_vals", "(", "predict_net", ",", "\"device\"", ",", "b\"cpu\"", ")", ".", "decode", "(", "\"ascii\"", ")", "\n", "\n", "if", "convert_outputs", "is", "None", ":", "\n", "            ", "meta_arch", "=", "get_pb_arg_vals", "(", "predict_net", ",", "\"meta_architecture\"", ",", "b\"GeneralizedRCNN\"", ")", "\n", "meta_arch", "=", "META_ARCH_CAFFE2_EXPORT_TYPE_MAP", "[", "meta_arch", ".", "decode", "(", "\"ascii\"", ")", "]", "\n", "self", ".", "_convert_outputs", "=", "meta_arch", ".", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_convert_outputs", "=", "convert_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufDetectionModel._convert_inputs": [[151, 155], ["caffe2_modeling.convert_batched_inputs_to_c2_format"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_modeling.convert_batched_inputs_to_c2_format"], ["", "", "def", "_convert_inputs", "(", "self", ",", "batched_inputs", ")", ":", "\n", "# currently all models convert inputs in the same way", "\n", "        ", "return", "convert_batched_inputs_to_c2_format", "(", "\n", "batched_inputs", ",", "self", ".", "size_divisibility", ",", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufDetectionModel.forward": [[157, 162], ["caffe2_inference.ProtobufDetectionModel._convert_inputs", "caffe2_inference.ProtobufDetectionModel.protobuf_model", "dict", "caffe2_inference.ProtobufDetectionModel._convert_outputs", "zip", "caffe2_inference.ProtobufDetectionModel.protobuf_model.net.Proto"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.caffe2_inference.ProtobufDetectionModel._convert_inputs"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "c2_inputs", "=", "self", ".", "_convert_inputs", "(", "batched_inputs", ")", "\n", "c2_results", "=", "self", ".", "protobuf_model", "(", "c2_inputs", ")", "\n", "c2_results", "=", "dict", "(", "zip", "(", "self", ".", "protobuf_model", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ",", "c2_results", ")", ")", "\n", "return", "self", ".", "_convert_outputs", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultPredictor.__init__": [[214, 230], ["cfg.clone", "detectron2.modeling.build_model", "defaults.DefaultPredictor.model.eval", "len", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.load", "detectron2.ResizeShortestEdge", "detectron2.data.MetadataCatalog.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["# Target fraction of foreground (positive) examples per RPN minibatch", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "=", "0.5", "\n", "# Options are: \"smooth_l1\", \"giou\"", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_LOSS_TYPE", "=", "\"smooth_l1\"", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_LOSS_WEIGHT", "=", "1.0", "\n", "# Weights on (dx, dy, dw, dh) for normalizing RPN anchor regression targets", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_WEIGHTS", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", "\n", "# The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "SMOOTH_L1_BETA", "=", "0.0", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "LOSS_WEIGHT", "=", "1.0", "\n", "# Number of top scoring RPN proposals to keep before applying NMS", "\n", "# When FPN is used, this is *per FPN level* (not total)", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOPK_TRAIN", "=", "12000", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOPK_TEST", "=", "6000", "\n", "# Number of top scoring RPN proposals to keep after applying NMS", "\n", "# When FPN is used, this limit is applied per level and then again to the union", "\n", "# of proposals from all levels", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultPredictor.__call__": [[231, 253], ["torch.no_grad", "defaults.DefaultPredictor.aug.get_transform().apply_image", "torch.as_tensor", "torch.as_tensor.astype().transpose", "defaults.DefaultPredictor.model", "defaults.DefaultPredictor.aug.get_transform", "torch.as_tensor.astype"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.get_transform"], ["# NOTE: When FPN is used, the meaning of this config is different from Detectron1.", "\n", "# It means per-batch topk in Detectron1, but per-image topk here.", "\n", "# See the \"find_top_rpn_proposals\" function for details.", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOPK_TRAIN", "=", "2000", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOPK_TEST", "=", "1000", "\n", "# NMS threshold used on RPN proposals", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", "=", "0.7", "\n", "# Set this to -1 to use the same number of output channels as input channels.", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "CONV_DIMS", "=", "[", "-", "1", "]", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# ROI HEADS options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "NAME", "=", "\"Res5ROIHeads\"", "\n", "# Number of foreground classes", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "=", "80", "\n", "# Names of the input feature maps to be used by ROI heads", "\n", "# Currently all heads (box, mask, ...) use the same input feature map list", "\n", "# e.g., [\"p2\", \"p3\", \"p4\", \"p5\"] is commonly used for FPN", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "=", "[", "\"res4\"", "]", "\n", "# IOU overlap ratios [IOU_THRESHOLD]", "\n", "# Overlap threshold for an RoI to be considered background (if < IOU_THRESHOLD)", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.__init__": [[298, 338], ["train_loop.TrainerBase.__init__", "logging.getLogger", "defaults.DefaultTrainer.auto_scale_workers", "defaults.DefaultTrainer.build_model", "defaults.DefaultTrainer.build_optimizer", "defaults.DefaultTrainer.build_train_loader", "defaults.DefaultTrainer.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "defaults.DefaultTrainer.register_hooks", "logging.getLogger.isEnabledFor", "detectron2.utils.logger.setup_logger", "detectron2.utils.comm.get_world_size", "detectron2.utils.comm.get_world_size", "torch.nn.parallel.DistributedDataParallel", "defaults.DefaultTrainer.build_hooks", "detectron2.utils.comm.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.auto_scale_workers", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model", "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_optimizer", "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_train_loader", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.build_lr_scheduler", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.register_hooks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.setup_logger", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_hooks", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.get_local_rank"], ["_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "=", "0", "\n", "# Type of pooling operation applied to the incoming feature map for each RoI", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "=", "\"ROIAlignV2\"", "\n", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_FC", "=", "0", "\n", "# Hidden layer dimension for FC layers in the RoI box head", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "FC_DIM", "=", "1024", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CONV", "=", "0", "\n", "# Channel dimension for Conv layers in the RoI box head", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CONV_DIM", "=", "256", "\n", "# Normalization method for the convolution layers.", "\n", "# Options: \"\" (no norm), \"GN\", \"SyncBN\".", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NORM", "=", "\"\"", "\n", "# Whether to use class agnostic for bbox regression", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CLS_AGNOSTIC_BBOX_REG", "=", "False", "\n", "# If true, RoI heads use bounding boxes predicted by the box head rather than proposal boxes.", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "TRAIN_ON_PRED_BOXES", "=", "False", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Cascaded Box Head", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", "=", "CN", "(", ")", "\n", "# The number of cascade stages is implicitly defined by the length of the following two configs.", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "BBOX_REG_WEIGHTS", "=", "(", "\n", "(", "10.0", ",", "10.0", ",", "5.0", ",", "5.0", ")", ",", "\n", "(", "20.0", ",", "20.0", ",", "10.0", ",", "10.0", ")", ",", "\n", "(", "30.0", ",", "30.0", ",", "15.0", ",", "15.0", ")", ",", "\n", ")", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "IOUS", "=", "(", "0.5", ",", "0.6", ",", "0.7", ")", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Mask Head", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NAME", "=", "\"MaskRCNNConvUpsampleHead\"", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_RESOLUTION", "=", "14", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SAMPLING_RATIO", "=", "0", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NUM_CONV", "=", "0", "# The number of convs in the mask head", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CONV_DIM", "=", "256", "\n", "# Normalization method for the convolution layers.", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.resume_or_load": [[339, 364], ["defaults.DefaultTrainer.checkpointer.resume_or_load", "isinstance", "defaults.DefaultTrainer.checkpointer.has_checkpoint", "defaults.DefaultTrainer.get", "defaults.DefaultTrainer.model._sync_params_and_buffers", "detectron2.utils.comm.all_gather"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather"], ["# Options: \"\" (no norm), \"GN\", \"SyncBN\".", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "NORM", "=", "\"\"", "\n", "# Whether to use class agnostic for mask prediction", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CLS_AGNOSTIC_MASK", "=", "False", "\n", "# Type of pooling operation applied to the incoming feature map for each RoI", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_TYPE", "=", "\"ROIAlignV2\"", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Keypoint Head", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NAME", "=", "\"KRCNNConvDeconvUpsampleHead\"", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_RESOLUTION", "=", "14", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_SAMPLING_RATIO", "=", "0", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "CONV_DIMS", "=", "tuple", "(", "512", "for", "_", "in", "range", "(", "8", ")", ")", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NUM_KEYPOINTS", "=", "17", "# 17 is the number of keypoints in COCO.", "\n", "\n", "# Images with too few (or no) keypoints are excluded from training.", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "=", "1", "\n", "# Normalize by the total number of visible keypoints in the minibatch if True.", "\n", "# Otherwise, normalize by the total number of keypoints that could ever exist", "\n", "# in the minibatch.", "\n", "# The keypoint softmax loss is only calculated on visible keypoints.", "\n", "# Since the number of visible keypoints can vary significantly between", "\n", "# minibatches, this has the effect of up-weighting the importance of", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_hooks": [[365, 412], ["defaults.DefaultTrainer.cfg.clone", "defaults.DefaultTrainer.defrost", "detectron2.utils.comm.is_main_process", "ret.append", "detectron2.utils.comm.is_main_process", "hooks.IterationTimer", "hooks.LRScheduler", "ret.append", "defaults.DefaultTrainer.test", "hooks.EvalHook", "ret.append", "hooks.PreciseBN", "hooks.PeriodicCheckpointer", "hooks.PeriodicWriter", "fvcore.nn.precise_bn.get_bn_modules", "defaults.DefaultTrainer.build_train_loader", "defaults.DefaultTrainer.build_writers"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.test", "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_train_loader", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_writers"], ["# minibatches with few visible keypoints. (Imagine the extreme case of", "\n", "# only one visible keypoint versus N: in the case of N, each one", "\n", "# contributes 1/N to the gradient compared to the single keypoint", "\n", "# determining the gradient direction). Instead, we can normalize the", "\n", "# loss by the total number of keypoints, if it were the case that all", "\n", "# keypoints were visible in a full minibatch. (Returning to the example,", "\n", "# this means that the one visible keypoint contributes as much as each", "\n", "# of the N keypoints.)", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS", "=", "True", "\n", "# Multi-task loss weight to use for keypoints", "\n", "# Recommended values:", "\n", "#   - use 1.0 if NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS is True", "\n", "#   - use 4.0 if NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS is False", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "LOSS_WEIGHT", "=", "1.0", "\n", "# Type of pooling operation applied to the incoming feature map for each RoI", "\n", "_C", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_TYPE", "=", "\"ROIAlignV2\"", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Semantic Segmentation Head", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NAME", "=", "\"SemSegFPNHead\"", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IN_FEATURES", "=", "[", "\"p2\"", ",", "\"p3\"", ",", "\"p4\"", ",", "\"p5\"", "]", "\n", "# Label in the semantic segmentation ground truth that is ignored, i.e., no loss is calculated for", "\n", "# the correposnding pixel.", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IGNORE_VALUE", "=", "255", "\n", "# Number of classes in the semantic segmentation head", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NUM_CLASSES", "=", "54", "\n", "# Number of channels in the 3x3 convs inside semantic-FPN heads.", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "CONVS_DIM", "=", "128", "\n", "# Outputs from semantic-FPN heads are up-scaled to the COMMON_STRIDE stride.", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "COMMON_STRIDE", "=", "4", "\n", "# Normalization method for the convolution layers. Options: \"\" (no norm), \"GN\".", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NORM", "=", "\"GN\"", "\n", "_C", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "LOSS_WEIGHT", "=", "1.0", "\n", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", "=", "CN", "(", ")", "\n", "# Scaling of all losses from instance detection / segmentation head.", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "INSTANCE_LOSS_WEIGHT", "=", "1.0", "\n", "\n", "# options when combining instance & semantic segmentation outputs", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", "=", "CN", "(", "{", "\"ENABLED\"", ":", "True", "}", ")", "# \"COMBINE.ENABLED\" is deprecated & not used", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "OVERLAP_THRESH", "=", "0.5", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "STUFF_AREA_LIMIT", "=", "4096", "\n", "_C", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "INSTANCES_CONFIDENCE_THRESH", "=", "0.5", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_writers": [[413, 423], ["defaults.default_writers"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.default_writers"], ["# RetinaNet Head", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "RETINANET", "=", "CN", "(", ")", "\n", "\n", "# This is the number of foreground classes.", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", "=", "80", "\n", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "IN_FEATURES", "=", "[", "\"p3\"", ",", "\"p4\"", ",", "\"p5\"", ",", "\"p6\"", ",", "\"p7\"", "]", "\n", "\n", "# Convolutions to use in the cls and bbox tower", "\n", "# NOTE: this doesn't include the last conv for logits", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.train": [[424, 438], ["super().train", "len", "detectron2.utils.comm.is_main_process", "hasattr", "detectron2.evaluation.verify_results"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.verify_results"], ["_C", ".", "MODEL", ".", "RETINANET", ".", "NUM_CONVS", "=", "4", "\n", "\n", "# IoU overlap ratio [bg, fg] for labeling anchors.", "\n", "# Anchors with < bg are labeled negative (0)", "\n", "# Anchors  with >= bg and < fg are ignored (-1)", "\n", "# Anchors with >= fg are labeled positive (1)", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "IOU_THRESHOLDS", "=", "[", "0.4", ",", "0.5", "]", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "IOU_LABELS", "=", "[", "0", ",", "-", "1", ",", "1", "]", "\n", "\n", "# Prior prob for rare case (i.e. foreground) at the beginning of training.", "\n", "# This is used to set the bias for the logits layer of the classifier subnet.", "\n", "# This improves training stability in the case of heavy class imbalance.", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "PRIOR_PROB", "=", "0.01", "\n", "\n", "# Inference cls score threshold, only anchors with score > INFERENCE_TH are", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.run_step": [[439, 442], ["defaults.DefaultTrainer._trainer.run_step"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.AMPTrainer.run_step"], ["# considered for inference (to improve speed)", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "SCORE_THRESH_TEST", "=", "0.05", "\n", "# Select topk candidates before NMS", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "TOPK_CANDIDATES_TEST", "=", "1000", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model": [[443, 456], ["detectron2.modeling.build_model", "logging.getLogger", "logging.getLogger.info"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model"], ["_C", ".", "MODEL", ".", "RETINANET", ".", "NMS_THRESH_TEST", "=", "0.5", "\n", "\n", "# Weights on (dx, dy, dw, dh) for normalizing Retinanet anchor regression targets", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_WEIGHTS", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", "\n", "\n", "# Loss parameters", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "FOCAL_LOSS_GAMMA", "=", "2.0", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "FOCAL_LOSS_ALPHA", "=", "0.25", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "SMOOTH_L1_LOSS_BETA", "=", "0.1", "\n", "# Options are: \"smooth_l1\", \"giou\"", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_LOSS_TYPE", "=", "\"smooth_l1\"", "\n", "\n", "# One of BN, SyncBN, FrozenBN, GN", "\n", "# Only supports GN until unshared norm is implemented", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_optimizer": [[457, 467], ["detectron2.solver.build_optimizer"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_optimizer"], ["_C", ".", "MODEL", ".", "RETINANET", ".", "NORM", "=", "\"\"", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# ResNe[X]t options (ResNets = {ResNet, ResNeXt}", "\n", "# Note that parts of a resnet may be used for both the backbone and the head", "\n", "# These options apply to both", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "RESNETS", "=", "CN", "(", ")", "\n", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "DEPTH", "=", "50", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_lr_scheduler": [[468, 475], ["detectron2.solver.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.build_lr_scheduler"], ["_C", ".", "MODEL", ".", "RESNETS", ".", "OUT_FEATURES", "=", "[", "\"res4\"", "]", "# res4 for C4 backbone, res2..5 for FPN backbone", "\n", "\n", "# Number of groups to use; 1 ==> ResNet; > 1 ==> ResNeXt", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "=", "1", "\n", "\n", "# Options: FrozenBN, GN, \"SyncBN\", \"BN\"", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "NORM", "=", "\"FrozenBN\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_train_loader": [[476, 486], ["detectron2.data.build_detection_train_loader"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_detection_train_loader"], ["# Baseline width of each group.", "\n", "# Scaling this parameters will scale the width of all bottleneck layers.", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "=", "64", "\n", "\n", "# Place the stride 2 conv on the 1x1 filter", "\n", "# Use True only for the original MSRA ResNet; use False for C2 and Torch models", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", "=", "True", "\n", "\n", "# Apply dilation in stage \"res5\"", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_test_loader": [[487, 497], ["detectron2.data.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_detection_test_loader"], ["# Output width of res2. Scaling this parameters will scale the width of all 1x1 convs in ResNet", "\n", "# For R18 and R34, this needs to be set to 64", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "=", "256", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "=", "64", "\n", "\n", "# Apply Deformable Convolution in stages", "\n", "# Specify if apply deform_conv on Res2, Res3, Res4, Res5", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_ON_PER_STAGE", "=", "[", "False", ",", "False", ",", "False", ",", "False", "]", "\n", "# Use True to use modulated deform_conv (DeformableV2, https://arxiv.org/abs/1811.11168);", "\n", "# Use False for DeformableV1.", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_MODULATED", "=", "False", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_evaluator": [[498, 512], ["NotImplementedError"], "methods", ["None"], ["# Number of groups in deformable conv.", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_NUM_GROUPS", "=", "1", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Solver", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "SOLVER", "=", "CN", "(", ")", "\n", "\n", "# See detectron2/solver/build.py for LR scheduler options", "\n", "_C", ".", "SOLVER", ".", "LR_SCHEDULER_NAME", "=", "\"WarmupMultiStepLR\"", "\n", "\n", "_C", ".", "SOLVER", ".", "MAX_ITER", "=", "40000", "\n", "\n", "_C", ".", "SOLVER", ".", "BASE_LR", "=", "0.001", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.test": [[514, 566], ["logging.getLogger", "isinstance", "collections.OrderedDict", "enumerate", "cls.build_test_loader", "detectron2.evaluation.inference_on_dataset", "detectron2.utils.comm.is_main_process", "len", "len", "len", "len", "len", "isinstance", "logging.getLogger.info", "detectron2.evaluation.print_csv_format", "list", "cls.build_evaluator", "collections.OrderedDict.values", "logging.getLogger.warn"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_test_loader", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.inference_on_dataset", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.print_csv_format", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_evaluator"], ["_C", ".", "SOLVER", ".", "MOMENTUM", "=", "0.9", "\n", "\n", "_C", ".", "SOLVER", ".", "NESTEROV", "=", "False", "\n", "\n", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY", "=", "0.0001", "\n", "# The weight decay that's applied to parameters of normalization layers", "\n", "# (typically the affine transformation)", "\n", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY_NORM", "=", "0.0", "\n", "\n", "_C", ".", "SOLVER", ".", "GAMMA", "=", "0.1", "\n", "# The iteration number to decrease learning rate by GAMMA.", "\n", "_C", ".", "SOLVER", ".", "STEPS", "=", "(", "30000", ",", ")", "\n", "\n", "_C", ".", "SOLVER", ".", "WARMUP_FACTOR", "=", "1.0", "/", "1000", "\n", "_C", ".", "SOLVER", ".", "WARMUP_ITERS", "=", "1000", "\n", "_C", ".", "SOLVER", ".", "WARMUP_METHOD", "=", "\"linear\"", "\n", "\n", "# Save a checkpoint after every this number of iterations", "\n", "_C", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "=", "5000", "\n", "\n", "# Number of images per batch across all machines. This is also the number", "\n", "# of training images per step (i.e. per iteration). If we use 16 GPUs", "\n", "# and IMS_PER_BATCH = 32, each GPU will see 2 images per batch.", "\n", "# May be adjusted automatically if REFERENCE_WORLD_SIZE is set.", "\n", "_C", ".", "SOLVER", ".", "IMS_PER_BATCH", "=", "16", "\n", "\n", "# The reference number of workers (GPUs) this config is meant to train with.", "\n", "# It takes no effect when set to 0.", "\n", "# With a non-zero value, it will be used by DefaultTrainer to compute a desired", "\n", "# per-worker batch size, and then scale the other related configs (total batch size,", "\n", "# learning rate, etc) to match the per-worker batch size.", "\n", "# See documentation of `DefaultTrainer.auto_scale_workers` for details:", "\n", "_C", ".", "SOLVER", ".", "REFERENCE_WORLD_SIZE", "=", "0", "\n", "\n", "# Detectron v1 (and previous detection code) used a 2x higher LR and 0 WD for", "\n", "# biases. This is not useful (at least for recent models). You should avoid", "\n", "# changing these and they exist only to reproduce Detectron v1 training if", "\n", "# desired.", "\n", "_C", ".", "SOLVER", ".", "BIAS_LR_FACTOR", "=", "1.0", "\n", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY_BIAS", "=", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY", "\n", "\n", "# Gradient clipping", "\n", "_C", ".", "SOLVER", ".", "CLIP_GRADIENTS", "=", "CN", "(", "{", "\"ENABLED\"", ":", "False", "}", ")", "\n", "# Type of gradient clipping, currently 2 values are supported:", "\n", "# - \"value\": the absolute values of elements of each gradients are clipped", "\n", "# - \"norm\": the norm of the gradient for each parameter is clipped thus", "\n", "#   affecting all elements in the parameter", "\n", "_C", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "CLIP_TYPE", "=", "\"value\"", "\n", "# Maximum absolute value used for clipping gradients", "\n", "_C", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "CLIP_VALUE", "=", "1.0", "\n", "# Floating point number p for L-p norm to be used with the \"norm\"", "\n", "# gradient clipping type; for L-inf, please specify .inf", "\n", "_C", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "NORM_TYPE", "=", "2.0", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.auto_scale_workers": [[567, 637], ["cfg.clone.clone.clone", "cfg.clone.clone.is_frozen", "cfg.clone.clone.defrost", "int", "int", "int", "tuple", "int", "int", "logging.getLogger", "logging.getLogger.info", "round", "round", "round", "round", "round", "cfg.clone.clone.freeze", "int", "round"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze"], ["\n", "# Enable automatic mixed precision for training", "\n", "# Note that this does not change model's inference behavior.", "\n", "# To use AMP in inference, run inference under autocast()", "\n", "_C", ".", "SOLVER", ".", "AMP", "=", "CN", "(", "{", "\"ENABLED\"", ":", "False", "}", ")", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Specific test options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "TEST", "=", "CN", "(", ")", "\n", "# For end-to-end tests to verify the expected accuracy.", "\n", "# Each item is [task, metric, value, tolerance]", "\n", "# e.g.: [['bbox', 'AP', 38.5, 0.2]]", "\n", "_C", ".", "TEST", ".", "EXPECTED_RESULTS", "=", "[", "]", "\n", "# The period (in terms of steps) to evaluate the model during training.", "\n", "# Set to 0 to disable.", "\n", "_C", ".", "TEST", ".", "EVAL_PERIOD", "=", "0", "\n", "# The sigmas used to calculate keypoint OKS. See http://cocodataset.org/#keypoints-eval", "\n", "# When empty, it will use the defaults in COCO.", "\n", "# Otherwise it should be a list[float] with the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.", "\n", "_C", ".", "TEST", ".", "KEYPOINT_OKS_SIGMAS", "=", "[", "]", "\n", "# Maximum number of detections to return per image during inference (100 is", "\n", "# based on the limit established for the COCO dataset).", "\n", "_C", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", "=", "100", "\n", "\n", "_C", ".", "TEST", ".", "AUG", "=", "CN", "(", "{", "\"ENABLED\"", ":", "False", "}", ")", "\n", "_C", ".", "TEST", ".", "AUG", ".", "MIN_SIZES", "=", "(", "400", ",", "500", ",", "600", ",", "700", ",", "800", ",", "900", ",", "1000", ",", "1100", ",", "1200", ")", "\n", "_C", ".", "TEST", ".", "AUG", ".", "MAX_SIZE", "=", "4000", "\n", "_C", ".", "TEST", ".", "AUG", ".", "FLIP", "=", "True", "\n", "\n", "_C", ".", "TEST", ".", "PRECISE_BN", "=", "CN", "(", "{", "\"ENABLED\"", ":", "False", "}", ")", "\n", "_C", ".", "TEST", ".", "PRECISE_BN", ".", "NUM_ITER", "=", "200", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Misc options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Directory where output files are written", "\n", "_C", ".", "OUTPUT_DIR", "=", "\"./output\"", "\n", "# Set seed to negative to fully randomize everything.", "\n", "# Set seed to positive to use a fixed seed. Note that a fixed seed increases", "\n", "# reproducibility but does not guarantee fully deterministic behavior.", "\n", "# Disabling all parallelism further increases reproducibility.", "\n", "_C", ".", "SEED", "=", "-", "1", "\n", "# Benchmark different cudnn algorithms.", "\n", "# If input images have very different sizes, this option will have large overhead", "\n", "# for about 10k iterations. It usually hurts total time, but can benefit for certain models.", "\n", "# If input images have the same or similar sizes, benchmark is often helpful.", "\n", "_C", ".", "CUDNN_BENCHMARK", "=", "False", "\n", "# The period (in terms of steps) for minibatch visualization at train time.", "\n", "# Set to 0 to disable.", "\n", "_C", ".", "VIS_PERIOD", "=", "0", "\n", "\n", "# global config is for quick hack purposes.", "\n", "# You can set them in command line or config files,", "\n", "# and access it with:", "\n", "#", "\n", "# from detectron2.config import global_cfg", "\n", "# print(global_cfg.HACK)", "\n", "#", "\n", "# Do not commit any configs into it.", "\n", "_C", ".", "GLOBAL", "=", "CN", "(", ")", "\n", "_C", ".", "GLOBAL", ".", "HACK", "=", "1.0", "\n", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.default_argument_parser": [[56, 116], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "hash", "os.getuid"], "function", ["None"], ["# Size of the smallest side of the image during testing. Set to zero to disable resize in testing.", "\n", "_C", ".", "INPUT", ".", "MIN_SIZE_TEST", "=", "800", "\n", "# Maximum size of the side of the image during testing", "\n", "_C", ".", "INPUT", ".", "MAX_SIZE_TEST", "=", "1333", "\n", "# Mode for flipping images used in data augmentation during training", "\n", "# choose one of [\"horizontal, \"vertical\", \"none\"]", "\n", "_C", ".", "INPUT", ".", "RANDOM_FLIP", "=", "\"horizontal\"", "\n", "\n", "# `True` if cropping is used for data augmentation during training", "\n", "_C", ".", "INPUT", ".", "CROP", "=", "CN", "(", "{", "\"ENABLED\"", ":", "False", "}", ")", "\n", "# Cropping type. See documentation of `detectron2.data.transforms.RandomCrop` for explanation.", "\n", "_C", ".", "INPUT", ".", "CROP", ".", "TYPE", "=", "\"relative_range\"", "\n", "# Size of crop in range (0, 1] if CROP.TYPE is \"relative\" or \"relative_range\" and in number of", "\n", "# pixels if CROP.TYPE is \"absolute\"", "\n", "_C", ".", "INPUT", ".", "CROP", ".", "SIZE", "=", "[", "0.9", ",", "0.9", "]", "\n", "\n", "\n", "# Whether the model needs RGB, YUV, HSV etc.", "\n", "# Should be one of the modes defined here, as we use PIL to read the image:", "\n", "# https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes", "\n", "# with BGR being the one exception. One can set image format to BGR, we will", "\n", "# internally use RGB for conversion and flip the channels over", "\n", "_C", ".", "INPUT", ".", "FORMAT", "=", "\"BGR\"", "\n", "# The ground truth mask format that the model will use.", "\n", "# Mask R-CNN supports either \"polygon\" or \"bitmask\" as ground truth.", "\n", "_C", ".", "INPUT", ".", "MASK_FORMAT", "=", "\"polygon\"", "# alternative: \"bitmask\"", "\n", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# Dataset", "\n", "# -----------------------------------------------------------------------------", "\n", "_C", ".", "DATASETS", "=", "CN", "(", ")", "\n", "# List of the dataset names for training. Must be registered in DatasetCatalog", "\n", "# Samples from these datasets will be merged and used as one dataset.", "\n", "_C", ".", "DATASETS", ".", "TRAIN", "=", "(", ")", "\n", "# List of the pre-computed proposal files for training, which must be consistent", "\n", "# with datasets listed in DATASETS.TRAIN.", "\n", "_C", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "=", "(", ")", "\n", "# Number of top scoring precomputed proposals to keep for training", "\n", "_C", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "=", "2000", "\n", "# List of the dataset names for testing. Must be registered in DatasetCatalog", "\n", "_C", ".", "DATASETS", ".", "TEST", "=", "(", ")", "\n", "# List of the pre-computed proposal files for test, which must be consistent", "\n", "# with datasets listed in DATASETS.TEST.", "\n", "_C", ".", "DATASETS", ".", "PROPOSAL_FILES_TEST", "=", "(", ")", "\n", "# Number of top scoring precomputed proposals to keep for test", "\n", "_C", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "=", "1000", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# DataLoader", "\n", "# -----------------------------------------------------------------------------", "\n", "_C", ".", "DATALOADER", "=", "CN", "(", ")", "\n", "# Number of data loading threads", "\n", "_C", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "4", "\n", "# If True, each batch should contain only images for which the aspect ratio", "\n", "# is compatible. This groups portrait images together, and landscape images", "\n", "# are not batched with portrait images.", "\n", "_C", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "=", "True", "\n", "# Options: TrainingSampler, RepeatFactorTrainingSampler", "\n", "_C", ".", "DATALOADER", ".", "SAMPLER_TRAIN", "=", "\"TrainingSampler\"", "\n", "# Repeat threshold for RepeatFactorTrainingSampler", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.default_setup": [[118, 165], ["detectron2.utils.comm.get_rank", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.env.seed_all_rng", "detectron2.utils.comm.is_main_process", "detectron2.utils.file_io.PathManager.mkdirs", "hasattr", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.comm.is_main_process", "os.path.join", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.comm.get_world_size", "detectron2.utils.collect_env.collect_env_info", "str", "detectron2.utils.file_io.PathManager.open", "f.write", "hasattr", "detectron2.utils.file_io.PathManager.open().read", "cfg.dump", "detectron2.utils.file_io.PathManager.open"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.setup_logger", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.setup_logger", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.seed_all_rng", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.collect_env.collect_env_info", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump"], ["# Tf True, when working on datasets that have instance annotations, the", "\n", "# training dataloader will filter out images without associated annotations", "\n", "_C", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", "=", "True", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Backbone options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "BACKBONE", "=", "CN", "(", ")", "\n", "\n", "_C", ".", "MODEL", ".", "BACKBONE", ".", "NAME", "=", "\"build_resnet_backbone\"", "\n", "# Freeze the first several stages so they are not trained.", "\n", "# There are 5 stages in ResNet. The first is a convolution, and the following", "\n", "# stages are each group of residual blocks.", "\n", "_C", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "=", "2", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# FPN options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "FPN", "=", "CN", "(", ")", "\n", "# Names of the input feature maps to be used by FPN", "\n", "# They must have contiguous power of 2 strides", "\n", "# e.g., [\"res2\", \"res3\", \"res4\", \"res5\"]", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "=", "[", "]", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "=", "256", "\n", "\n", "# Options: \"\" (no norm), \"GN\"", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "NORM", "=", "\"\"", "\n", "\n", "# Types for fusing the FPN top-down and lateral features. Can be either \"sum\" or \"avg\"", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", "=", "\"sum\"", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Proposal generator options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "PROPOSAL_GENERATOR", "=", "CN", "(", ")", "\n", "# Current proposal generators include \"RPN\", \"RRPN\" and \"PrecomputedProposals\"", "\n", "_C", ".", "MODEL", ".", "PROPOSAL_GENERATOR", ".", "NAME", "=", "\"RPN\"", "\n", "# Proposal height and width both need to be greater than MIN_SIZE", "\n", "# (a the scale used during training or inference)", "\n", "_C", ".", "MODEL", ".", "PROPOSAL_GENERATOR", ".", "MIN_SIZE", "=", "0", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Anchor generator options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ANCHOR_GENERATOR", "=", "CN", "(", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.default_writers": [[167, 185], ["detectron2.utils.events.CommonMetricPrinter", "detectron2.utils.events.JSONWriter", "detectron2.utils.events.TensorboardXWriter", "os.path.join"], "function", ["None"], ["_C", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "NAME", "=", "\"DefaultAnchorGenerator\"", "\n", "# Anchor sizes (i.e. sqrt of area) in absolute pixels w.r.t. the network input.", "\n", "# Format: list[list[float]]. SIZES[i] specifies the list of sizes to use for", "\n", "# IN_FEATURES[i]; len(SIZES) must be equal to len(IN_FEATURES) or 1.", "\n", "# When len(SIZES) == 1, SIZES[0] is used for all IN_FEATURES.", "\n", "_C", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", "=", "[", "[", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", "]", "\n", "# Anchor aspect ratios. For each area given in `SIZES`, anchors with different aspect", "\n", "# ratios are generated by an anchor generator.", "\n", "# Format: list[list[float]]. ASPECT_RATIOS[i] specifies the list of aspect ratios (H/W)", "\n", "# to use for IN_FEATURES[i]; len(ASPECT_RATIOS) == len(IN_FEATURES) must be true,", "\n", "# or len(ASPECT_RATIOS) == 1 is true and aspect ratio list ASPECT_RATIOS[0] is used", "\n", "# for all IN_FEATURES.", "\n", "_C", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "ASPECT_RATIOS", "=", "[", "[", "0.5", ",", "1.0", ",", "2.0", "]", "]", "\n", "# Anchor angles.", "\n", "# list[list[float]], the angle in degrees, for each input feature map.", "\n", "# ANGLES[i] specifies the list of angles for IN_FEATURES[i].", "\n", "_C", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "ANGLES", "=", "[", "[", "-", "90", ",", "0", ",", "90", "]", "]", "\n", "# Relative offset between the center of the first anchor and the top-left corner of the image", "\n", "# Value has to be in [0, 1). Recommend to use 0.5, which means half stride.", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.launch._find_free_port": [[15, 25], ["socket.socket", "socket.socket.bind", "socket.socket.close", "socket.socket.getsockname"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close"], ["def", "_find_free_port", "(", ")", ":", "\n", "    ", "import", "socket", "\n", "\n", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "# Binding to port 0 will cause the OS to find an available port for us", "\n", "sock", ".", "bind", "(", "(", "\"\"", ",", "0", ")", ")", "\n", "port", "=", "sock", ".", "getsockname", "(", ")", "[", "1", "]", "\n", "sock", ".", "close", "(", ")", "\n", "# NOTE: there is still a chance the port could be taken by other processes.", "\n", "return", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.launch.launch": [[27, 83], ["torch.spawn", "main_func", "launch._find_free_port", "dist_url.startswith", "logging.getLogger", "logging.getLogger.warning"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.launch._find_free_port"], ["", "def", "launch", "(", "\n", "main_func", ",", "\n", "num_gpus_per_machine", ",", "\n", "num_machines", "=", "1", ",", "\n", "machine_rank", "=", "0", ",", "\n", "dist_url", "=", "None", ",", "\n", "args", "=", "(", ")", ",", "\n", "timeout", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Launch multi-gpu or distributed training.\n    This function must be called on all machines involved in the training.\n    It will spawn child processes (defined by ``num_gpus_per_machine``) on each machine.\n\n    Args:\n        main_func: a function that will be called by `main_func(*args)`\n        num_gpus_per_machine (int): number of GPUs per machine\n        num_machines (int): the total number of machines\n        machine_rank (int): the rank of this machine\n        dist_url (str): url to connect to for distributed jobs, including protocol\n                       e.g. \"tcp://127.0.0.1:8686\".\n                       Can be set to \"auto\" to automatically select a free port on localhost\n        timeout (timedelta): timeout of the distributed workers\n        args (tuple): arguments passed to main_func\n    \"\"\"", "\n", "world_size", "=", "num_machines", "*", "num_gpus_per_machine", "\n", "if", "world_size", ">", "1", ":", "\n", "# https://github.com/pytorch/pytorch/pull/14391", "\n", "# TODO prctl in spawned processes", "\n", "\n", "        ", "if", "dist_url", "==", "\"auto\"", ":", "\n", "            ", "assert", "num_machines", "==", "1", ",", "\"dist_url=auto not supported in multi-machine jobs.\"", "\n", "port", "=", "_find_free_port", "(", ")", "\n", "dist_url", "=", "f\"tcp://127.0.0.1:{port}\"", "\n", "", "if", "num_machines", ">", "1", "and", "dist_url", ".", "startswith", "(", "\"file://\"", ")", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"file:// is not a reliable init_method in multi-machine jobs. Prefer tcp://\"", "\n", ")", "\n", "\n", "", "mp", ".", "spawn", "(", "\n", "_distributed_worker", ",", "\n", "nprocs", "=", "num_gpus_per_machine", ",", "\n", "args", "=", "(", "\n", "main_func", ",", "\n", "world_size", ",", "\n", "num_gpus_per_machine", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "args", ",", "\n", "timeout", ",", "\n", ")", ",", "\n", "daemon", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "main_func", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.launch._distributed_worker": [[85, 126], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "detectron2.utils.comm.synchronize", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "range", "main_func", "torch.init_process_group", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "list", "torch.new_group", "logging.getLogger", "logging.getLogger.error", "range"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "_distributed_worker", "(", "\n", "local_rank", ",", "\n", "main_func", ",", "\n", "world_size", ",", "\n", "num_gpus_per_machine", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "args", ",", "\n", "timeout", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"cuda is not available. Please check your installation.\"", "\n", "global_rank", "=", "machine_rank", "*", "num_gpus_per_machine", "+", "local_rank", "\n", "try", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"NCCL\"", ",", "\n", "init_method", "=", "dist_url", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "global_rank", ",", "\n", "timeout", "=", "timeout", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "\"Process group URL: {}\"", ".", "format", "(", "dist_url", ")", ")", "\n", "raise", "e", "\n", "# synchronize is needed here to prevent a possible timeout after calling init_process_group", "\n", "# See: https://github.com/facebookresearch/maskrcnn-benchmark/issues/172", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "\n", "assert", "num_gpus_per_machine", "<=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "\n", "# Setup the local process group (which contains ranks within the same machine)", "\n", "assert", "comm", ".", "_LOCAL_PROCESS_GROUP", "is", "None", "\n", "num_machines", "=", "world_size", "//", "num_gpus_per_machine", "\n", "for", "i", "in", "range", "(", "num_machines", ")", ":", "\n", "        ", "ranks_on_i", "=", "list", "(", "range", "(", "i", "*", "num_gpus_per_machine", ",", "(", "i", "+", "1", ")", "*", "num_gpus_per_machine", ")", ")", "\n", "pg", "=", "dist", ".", "new_group", "(", "ranks_on_i", ")", "\n", "if", "i", "==", "machine_rank", ":", "\n", "            ", "comm", ".", "_LOCAL_PROCESS_GROUP", "=", "pg", "\n", "\n", "", "", "main_func", "(", "*", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.CallbackHook.__init__": [[47, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", ",", "before_train", "=", "None", ",", "after_train", "=", "None", ",", "before_step", "=", "None", ",", "after_step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Each argument is a function that takes one argument: the trainer.\n        \"\"\"", "\n", "self", ".", "_before_train", "=", "before_train", "\n", "self", ".", "_before_step", "=", "before_step", "\n", "self", ".", "_after_step", "=", "after_step", "\n", "self", ".", "_after_train", "=", "after_train", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.CallbackHook.before_train": [[56, 59], ["hooks.CallbackHook._before_train"], "methods", ["None"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_before_train", ":", "\n", "            ", "self", ".", "_before_train", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.CallbackHook.after_train": [[60, 67], ["hooks.CallbackHook._after_train"], "methods", ["None"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_after_train", ":", "\n", "            ", "self", ".", "_after_train", "(", "self", ".", "trainer", ")", "\n", "# The functions may be closures that hold reference to the trainer", "\n", "# Therefore, delete them to avoid circular reference.", "\n", "", "del", "self", ".", "_before_train", ",", "self", ".", "_after_train", "\n", "del", "self", ".", "_before_step", ",", "self", ".", "_after_step", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.CallbackHook.before_step": [[68, 71], ["hooks.CallbackHook._before_step"], "methods", ["None"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_before_step", ":", "\n", "            ", "self", ".", "_before_step", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.CallbackHook.after_step": [[72, 75], ["hooks.CallbackHook._after_step"], "methods", ["None"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_after_step", ":", "\n", "            ", "self", ".", "_after_step", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.IterationTimer.__init__": [[89, 99], ["fvcore.common.timer.Timer", "time.perf_counter", "fvcore.common.timer.Timer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "warmup_iter", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            warmup_iter (int): the number of iterations at the beginning to exclude\n                from timing.\n        \"\"\"", "\n", "self", ".", "_warmup_iter", "=", "warmup_iter", "\n", "self", ".", "_step_timer", "=", "Timer", "(", ")", "\n", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", "=", "Timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.IterationTimer.before_train": [[100, 104], ["time.perf_counter", "hooks.IterationTimer._total_timer.reset", "hooks.IterationTimer._total_timer.pause"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", ".", "reset", "(", ")", "\n", "self", ".", "_total_timer", ".", "pause", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.IterationTimer.after_train": [[105, 128], ["logging.getLogger", "hooks.IterationTimer._total_timer.seconds", "logging.getLogger.info", "time.perf_counter", "logging.getLogger.info", "str", "str", "str", "datetime.timedelta", "datetime.timedelta", "datetime.timedelta", "int", "int", "int"], "methods", ["None"], ["", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_start_time", "\n", "total_time_minus_hooks", "=", "self", ".", "_total_timer", ".", "seconds", "(", ")", "\n", "hook_time", "=", "total_time", "-", "total_time_minus_hooks", "\n", "\n", "num_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "-", "self", ".", "trainer", ".", "start_iter", "-", "self", ".", "_warmup_iter", "\n", "\n", "if", "num_iter", ">", "0", "and", "total_time_minus_hooks", ">", "0", ":", "\n", "# Speed is meaningful only after warmup", "\n", "# NOTE this format is parsed by grep in some scripts", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Overall training speed: {} iterations in {} ({:.4f} s / it)\"", ".", "format", "(", "\n", "num_iter", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time_minus_hooks", ")", ")", ")", ",", "\n", "total_time_minus_hooks", "/", "num_iter", ",", "\n", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"Total training time: {} ({} on hooks)\"", ".", "format", "(", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "hook_time", ")", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.IterationTimer.before_step": [[131, 134], ["hooks.IterationTimer._step_timer.reset", "hooks.IterationTimer._total_timer.resume"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_step_timer", ".", "reset", "(", ")", "\n", "self", ".", "_total_timer", ".", "resume", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.IterationTimer.after_step": [[135, 147], ["hooks.IterationTimer._total_timer.pause", "hooks.IterationTimer._step_timer.seconds", "hooks.IterationTimer.trainer.storage.put_scalars", "time.perf_counter", "hooks.IterationTimer._total_timer.reset"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalars", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "# +1 because we're in after_step, the current step is done", "\n", "# but not yet counted", "\n", "        ", "iter_done", "=", "self", ".", "trainer", ".", "iter", "-", "self", ".", "trainer", ".", "start_iter", "+", "1", "\n", "if", "iter_done", ">=", "self", ".", "_warmup_iter", ":", "\n", "            ", "sec", "=", "self", ".", "_step_timer", ".", "seconds", "(", ")", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "time", "=", "sec", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", ".", "reset", "(", ")", "\n", "\n", "", "self", ".", "_total_timer", ".", "pause", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PeriodicWriter.__init__": [[157, 167], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "writers", ",", "period", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            writers (list[EventWriter]): a list of EventWriter objects\n            period (int):\n        \"\"\"", "\n", "self", ".", "_writers", "=", "writers", "\n", "for", "w", "in", "writers", ":", "\n", "            ", "assert", "isinstance", "(", "w", ",", "EventWriter", ")", ",", "w", "\n", "", "self", ".", "_period", "=", "period", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PeriodicWriter.after_step": [[168, 174], ["writer.write"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "trainer", ".", "iter", "+", "1", ")", "%", "self", ".", "_period", "==", "0", "or", "(", "\n", "self", ".", "trainer", ".", "iter", "==", "self", ".", "trainer", ".", "max_iter", "-", "1", "\n", ")", ":", "\n", "            ", "for", "writer", "in", "self", ".", "_writers", ":", "\n", "                ", "writer", ".", "write", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PeriodicWriter.after_train": [[175, 181], ["writer.write", "writer.close"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.TensorboardXWriter.close"], ["", "", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "for", "writer", "in", "self", ".", "_writers", ":", "\n", "# If any new data is found (e.g. produced by other after_train),", "\n", "# write them before closing", "\n", "            ", "writer", ".", "write", "(", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PeriodicCheckpointer.before_train": [[194, 196], ["None"], "methods", ["None"], ["def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "max_iter", "=", "self", ".", "trainer", ".", "max_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PeriodicCheckpointer.after_step": [[197, 200], ["hooks.PeriodicCheckpointer.step"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "# No way to use **kwargs", "\n", "        ", "self", ".", "step", "(", "self", ".", "trainer", ".", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.LRScheduler.__init__": [[208, 220], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", "=", "None", ",", "scheduler", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            optimizer (torch.optim.Optimizer):\n            scheduler (torch.optim.LRScheduler or fvcore.common.param_scheduler.ParamScheduler):\n                if a :class:`ParamScheduler` object, it defines the multiplier over the base LR\n                in the optimizer.\n\n        If any argument is not given, will try to obtain it from the trainer.\n        \"\"\"", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_scheduler", "=", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.LRScheduler.before_train": [[221, 250], ["isinstance", "max", "detectron2.solver.LRMultiplier", "collections.Counter", "enumerate", "enumerate", "len", "collections.Counter.most_common", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "self", ".", "_optimizer", "or", "self", ".", "trainer", ".", "optimizer", "\n", "self", ".", "_scheduler", "=", "self", ".", "_scheduler", "or", "self", ".", "trainer", ".", "scheduler", "\n", "if", "isinstance", "(", "self", ".", "_scheduler", ",", "ParamScheduler", ")", ":", "\n", "            ", "self", ".", "_scheduler", "=", "LRMultiplier", "(", "\n", "self", ".", "_optimizer", ",", "\n", "self", ".", "_scheduler", ",", "\n", "self", ".", "trainer", ".", "max_iter", ",", "\n", "last_iter", "=", "self", ".", "trainer", ".", "iter", "-", "1", ",", "\n", ")", "\n", "\n", "# NOTE: some heuristics on what LR to summarize", "\n", "# summarize the param group with most parameters", "\n", "", "largest_group", "=", "max", "(", "len", "(", "g", "[", "\"params\"", "]", ")", "for", "g", "in", "self", ".", "_optimizer", ".", "param_groups", ")", "\n", "\n", "if", "largest_group", "==", "1", ":", "\n", "# If all groups have one parameter,", "\n", "# then find the most common initial LR, and use it for summary", "\n", "            ", "lr_count", "=", "Counter", "(", "[", "g", "[", "\"lr\"", "]", "for", "g", "in", "self", ".", "_optimizer", ".", "param_groups", "]", ")", "\n", "lr", "=", "lr_count", ".", "most_common", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "_optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "g", "[", "\"lr\"", "]", "==", "lr", ":", "\n", "                    ", "self", ".", "_best_param_group_id", "=", "i", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "_optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "len", "(", "g", "[", "\"params\"", "]", ")", "==", "largest_group", ":", "\n", "                    ", "self", ".", "_best_param_group_id", "=", "i", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.LRScheduler.after_step": [[251, 255], ["hooks.LRScheduler.trainer.storage.put_scalar", "hooks.LRScheduler._scheduler.step"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step"], ["", "", "", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "lr", "=", "self", ".", "_optimizer", ".", "param_groups", "[", "self", ".", "_best_param_group_id", "]", "[", "\"lr\"", "]", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalar", "(", "\"lr\"", ",", "lr", ",", "smoothing_hint", "=", "False", ")", "\n", "self", ".", "_scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.AutogradProfiler.__init__": [[280, 292], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "enable_predicate", ",", "output_dir", ",", "*", ",", "use_cuda", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            enable_predicate (callable[trainer -> bool]): a function which takes a trainer,\n                and returns whether to enable the profiler.\n                It will be called once every step, and can be used to select which steps to profile.\n            output_dir (str): the output directory to dump tracing files.\n            use_cuda (bool): same as in `torch.autograd.profiler.profile`.\n        \"\"\"", "\n", "self", ".", "_enable_predicate", "=", "enable_predicate", "\n", "self", ".", "_use_cuda", "=", "use_cuda", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.AutogradProfiler.before_step": [[293, 299], ["hooks.AutogradProfiler._enable_predicate", "torch.autograd.profiler.profile", "hooks.AutogradProfiler._profiler.__enter__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.ScopedWS.__enter__"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_enable_predicate", "(", "self", ".", "trainer", ")", ":", "\n", "            ", "self", ".", "_profiler", "=", "torch", ".", "autograd", ".", "profiler", ".", "profile", "(", "use_cuda", "=", "self", ".", "_use_cuda", ")", "\n", "self", ".", "_profiler", ".", "__enter__", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_profiler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.AutogradProfiler.after_step": [[300, 319], ["hooks.AutogradProfiler._profiler.__exit__", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "hooks.AutogradProfiler._profiler.export_chrome_trace", "tempfile.TemporaryDirectory", "os.path.join", "hooks.AutogradProfiler._profiler.export_chrome_trace", "detectron2.utils.file_io.PathManager.open", "f.write", "open", "f.read"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.shared.ScopedWS.__exit__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_profiler", "is", "None", ":", "\n", "            ", "return", "\n", "", "self", ".", "_profiler", ".", "__exit__", "(", "None", ",", "None", ",", "None", ")", "\n", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "out_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "\"profiler-trace-iter{}.json\"", ".", "format", "(", "self", ".", "trainer", ".", "iter", ")", "\n", ")", "\n", "if", "\"://\"", "not", "in", "out_file", ":", "\n", "            ", "self", ".", "_profiler", ".", "export_chrome_trace", "(", "out_file", ")", "\n", "", "else", ":", "\n", "# Support non-posix filesystems", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"detectron2_profiler\"", ")", "as", "d", ":", "\n", "                ", "tmp_file", "=", "os", ".", "path", ".", "join", "(", "d", ",", "\"tmp.json\"", ")", "\n", "self", ".", "_profiler", ".", "export_chrome_trace", "(", "tmp_file", ")", "\n", "with", "open", "(", "tmp_file", ")", "as", "f", ":", "\n", "                    ", "content", "=", "f", ".", "read", "(", ")", "\n", "", "", "with", "PathManager", ".", "open", "(", "out_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook.__init__": [[328, 343], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "eval_period", ",", "eval_function", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            eval_period (int): the period to run `eval_function`. Set to 0 to\n                not evaluate periodically (but still after the last iteration).\n            eval_function (callable): a function which takes no arguments, and\n                returns a nested dict of evaluation metrics.\n\n        Note:\n            This hook must be enabled in all or none workers.\n            If you would like only certain workers to perform evaluation,\n            give other workers a no-op function (`eval_function=lambda: None`).\n        \"\"\"", "\n", "self", ".", "_period", "=", "eval_period", "\n", "self", ".", "_func", "=", "eval_function", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook._do_eval": [[344, 366], ["hooks.EvalHook._func", "detectron2.synchronize", "isinstance", "detectron2.evaluation.testing.flatten_results_dict", "detectron2.evaluation.testing.flatten_results_dict.items", "hooks.EvalHook.trainer.storage.put_scalars", "float", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.flatten_results_dict", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalars"], ["", "def", "_do_eval", "(", "self", ")", ":", "\n", "        ", "results", "=", "self", ".", "_func", "(", ")", "\n", "\n", "if", "results", ":", "\n", "            ", "assert", "isinstance", "(", "\n", "results", ",", "dict", "\n", ")", ",", "\"Eval function must return a dict. Got {} instead.\"", ".", "format", "(", "results", ")", "\n", "\n", "flattened_results", "=", "flatten_results_dict", "(", "results", ")", "\n", "for", "k", ",", "v", "in", "flattened_results", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "float", "(", "v", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"[EvalHook] eval_function should return a nested dict of float. \"", "\n", "\"Got '{}: {}' instead.\"", ".", "format", "(", "k", ",", "v", ")", "\n", ")", "from", "e", "\n", "", "", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "**", "flattened_results", ",", "smoothing_hint", "=", "False", ")", "\n", "\n", "# Evaluation may take different time among workers.", "\n", "# A barrier make them start the next iteration together.", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook.after_step": [[367, 371], ["hooks.EvalHook._do_eval"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook._do_eval"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "next_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "\n", "if", "self", ".", "_period", ">", "0", "and", "next_iter", "%", "self", ".", "_period", "==", "0", ":", "\n", "            ", "self", ".", "_do_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook.after_train": [[372, 379], ["hooks.EvalHook._do_eval"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.EvalHook._do_eval"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "# This condition is to prevent the eval from running after a failed training", "\n", "        ", "if", "self", ".", "trainer", ".", "iter", "+", "1", ">=", "self", ".", "trainer", ".", "max_iter", ":", "\n", "            ", "self", ".", "_do_eval", "(", ")", "\n", "# func is likely a closure that holds reference to the trainer", "\n", "# therefore we clean it to avoid circular reference in the end", "\n", "", "del", "self", ".", "_func", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PreciseBN.__init__": [[391, 419], ["logging.getLogger", "len", "hooks.PreciseBN._logger.info", "fvcore.nn.precise_bn.get_bn_modules"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "period", ",", "model", ",", "data_loader", ",", "num_iter", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            period (int): the period this hook is run, or 0 to not run during training.\n                The hook will always run in the end of training.\n            model (nn.Module): a module whose all BN layers in training mode will be\n                updated by precise BN.\n                Note that user is responsible for ensuring the BN layers to be\n                updated are in training mode when this hook is triggered.\n            data_loader (iterable): it will produce data to be run by `model(data)`.\n            num_iter (int): number of iterations used to compute the precise\n                statistics.\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "len", "(", "get_bn_modules", "(", "model", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "\"PreciseBN is disabled because model does not contain BN layers in training mode.\"", "\n", ")", "\n", "self", ".", "_disabled", "=", "True", "\n", "return", "\n", "\n", "", "self", ".", "_model", "=", "model", "\n", "self", ".", "_data_loader", "=", "data_loader", "\n", "self", ".", "_num_iter", "=", "num_iter", "\n", "self", ".", "_period", "=", "period", "\n", "self", ".", "_disabled", "=", "False", "\n", "\n", "self", ".", "_data_iter", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PreciseBN.after_step": [[420, 425], ["hooks.PreciseBN.update_stats"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PreciseBN.update_stats"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "next_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "\n", "is_final", "=", "next_iter", "==", "self", ".", "trainer", ".", "max_iter", "\n", "if", "is_final", "or", "(", "self", ".", "_period", ">", "0", "and", "next_iter", "%", "self", ".", "_period", "==", "0", ")", ":", "\n", "            ", "self", ".", "update_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.hooks.PreciseBN.update_stats": [[426, 451], ["iter", "itertools.count", "detectron2.utils.events.EventStorage", "hooks.PreciseBN._logger.info", "fvcore.nn.precise_bn.update_bn_stats", "hooks.PreciseBN.update_stats.data_loader"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter"], ["", "", "def", "update_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Update the model with precise statistics. Users can manually call this method.\n        \"\"\"", "\n", "if", "self", ".", "_disabled", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "_data_iter", "is", "None", ":", "\n", "            ", "self", ".", "_data_iter", "=", "iter", "(", "self", ".", "_data_loader", ")", "\n", "\n", "", "def", "data_loader", "(", ")", ":", "\n", "            ", "for", "num_iter", "in", "itertools", ".", "count", "(", "1", ")", ":", "\n", "                ", "if", "num_iter", "%", "100", "==", "0", ":", "\n", "                    ", "self", ".", "_logger", ".", "info", "(", "\n", "\"Running precise-BN ... {}/{} iterations.\"", ".", "format", "(", "num_iter", ",", "self", ".", "_num_iter", ")", "\n", ")", "\n", "# This way we can reuse the same iterator", "\n", "", "yield", "next", "(", "self", ".", "_data_iter", ")", "\n", "\n", "", "", "with", "EventStorage", "(", ")", ":", "# capture events in a new storage to discard them", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "\"Running precise-BN for {} iterations...  \"", ".", "format", "(", "self", ".", "_num_iter", ")", "\n", "+", "\"Note that this could produce different statistics every time.\"", "\n", ")", "\n", "update_bn_stats", "(", "self", ".", "_model", ",", "data_loader", "(", ")", ",", "self", ".", "_num_iter", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.HookBase.before_train": [[54, 59], ["None"], "methods", ["None"], ["def", "before_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before the first iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.HookBase.after_train": [[60, 65], ["None"], "methods", ["None"], ["", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after the last iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.HookBase.before_step": [[66, 71], ["None"], "methods", ["None"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before each iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.HookBase.after_step": [[72, 77], ["None"], "methods", ["None"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after each iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.__init__": [[98, 105], ["detectron2.utils.logger._log_api_usage"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._log_api_usage"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_hooks", ":", "List", "[", "HookBase", "]", "=", "[", "]", "\n", "self", ".", "iter", ":", "int", "\n", "self", ".", "start_iter", ":", "int", "\n", "self", ".", "max_iter", ":", "int", "\n", "self", ".", "storage", ":", "EventStorage", "\n", "_log_api_usage", "(", "\"trainer.\"", "+", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.register_hooks": [[106, 123], ["train_loop.TrainerBase._hooks.extend", "isinstance", "weakref.proxy"], "methods", ["None"], ["", "def", "register_hooks", "(", "self", ",", "hooks", ":", "List", "[", "Optional", "[", "HookBase", "]", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Register hooks to the trainer. The hooks are executed in the order\n        they are registered.\n\n        Args:\n            hooks (list[Optional[HookBase]]): list of hooks\n        \"\"\"", "\n", "hooks", "=", "[", "h", "for", "h", "in", "hooks", "if", "h", "is", "not", "None", "]", "\n", "for", "h", "in", "hooks", ":", "\n", "            ", "assert", "isinstance", "(", "h", ",", "HookBase", ")", "\n", "# To avoid circular reference, hooks and trainer cannot own each other.", "\n", "# This normally does not matter, but will cause memory leak if the", "\n", "# involved objects contain __del__:", "\n", "# See http://engineering.hearsaysocial.com/2013/06/16/circular-references-in-python/", "\n", "h", ".", "trainer", "=", "weakref", ".", "proxy", "(", "self", ")", "\n", "", "self", ".", "_hooks", ".", "extend", "(", "hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.train": [[124, 151], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "train_loop.TrainerBase.before_train", "range", "train_loop.TrainerBase.after_train", "train_loop.TrainerBase.before_step", "train_loop.TrainerBase.run_step", "train_loop.TrainerBase.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_step", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.AMPTrainer.run_step", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_step"], ["", "def", "train", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter, max_iter (int): See docs above\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "# self.iter == max_iter can be used by `after_train` to", "\n", "# tell whether the training successfully finished or failed", "\n", "# due to exceptions.", "\n", "", "self", ".", "iter", "+=", "1", "\n", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_train": [[152, 155], ["h.before_train"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_train"], ["", "", "", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "before_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_train": [[156, 160], ["h.after_train"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_train"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "storage", ".", "iter", "=", "self", ".", "iter", "\n", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_step": [[161, 168], ["h.before_step"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.before_step"], ["", "", "def", "before_step", "(", "self", ")", ":", "\n", "# Maintain the invariant that storage.iter == trainer.iter", "\n", "# for the entire execution of each step", "\n", "        ", "self", ".", "storage", ".", "iter", "=", "self", ".", "iter", "\n", "\n", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "before_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_step": [[169, 172], ["h.after_step"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.after_step"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "after_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.TrainerBase.run_step": [[173, 175], ["None"], "methods", ["None"], ["", "", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.SimpleTrainer.__init__": [[196, 218], ["train_loop.TrainerBase.__init__", "model.train", "iter"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter"], ["def", "__init__", "(", "self", ",", "model", ",", "data_loader", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: a torch Module. Takes a data from data_loader and returns a\n                dict of losses.\n            data_loader: an iterable. Contains data to be used to call model.\n            optimizer: a torch optimizer.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "\"\"\"\n        We set the model to training mode in the trainer.\n        However it's valid to train a model that's in eval mode.\n        If you want your model (or a submodule of it) to behave\n        like evaluation during training, you can overwrite its train() method.\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "_data_loader_iter", "=", "iter", "(", "data_loader", ")", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.SimpleTrainer.run_step": [[219, 252], ["time.perf_counter", "next", "train_loop.SimpleTrainer.model", "sum", "train_loop.SimpleTrainer.optimizer.zero_grad", "sum.backward", "train_loop.SimpleTrainer._write_metrics", "train_loop.SimpleTrainer.optimizer.step", "time.perf_counter", "train_loop.SimpleTrainer.values"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated._ROIAlignRotated.backward", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.SimpleTrainer._write_metrics", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step"], ["", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the standard training logic described above.\n        \"\"\"", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[SimpleTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\"\"\"\n        If you want to do something with the data, you can wrap the dataloader.\n        \"\"\"", "\n", "data", "=", "next", "(", "self", ".", "_data_loader_iter", ")", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "\"\"\"\n        If you want to do something with the losses, you can wrap the model.\n        \"\"\"", "\n", "loss_dict", "=", "self", ".", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "\"\"\"\n        If you need to accumulate gradients or do something similar, you can\n        wrap the optimizer with your custom `zero_grad()` method.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "\n", "self", ".", "_write_metrics", "(", "loss_dict", ",", "data_time", ")", "\n", "\n", "\"\"\"\n        If you need gradient clipping/scaling or other processing, you can\n        wrap the optimizer with your custom `step()` method. But it is\n        suboptimal as explained in https://arxiv.org/abs/2006.15704 Sec 3.2.4\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.SimpleTrainer._write_metrics": [[253, 294], ["detectron2.gather", "detectron2.is_main_process", "v.detach().cpu().item", "detectron2.utils.events.get_event_storage", "numpy.max", "detectron2.utils.events.get_event_storage.put_scalar", "sum", "detectron2.utils.events.get_event_storage.put_scalar", "loss_dict.items", "numpy.mean", "metrics_dict.values", "numpy.isfinite", "FloatingPointError", "len", "detectron2.utils.events.get_event_storage.put_scalars", "v.detach().cpu", "x.pop", "all_metrics_dict[].keys", "v.detach"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.get_event_storage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "\n", "self", ",", "\n", "loss_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "data_time", ":", "float", ",", "\n", "prefix", ":", "str", "=", "\"\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss_dict (dict): dict of scalar losses\n            data_time (float): time taken by the dataloader iteration\n        \"\"\"", "\n", "metrics_dict", "=", "{", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "for", "k", ",", "v", "in", "loss_dict", ".", "items", "(", ")", "}", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "\n", "# Gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "\n", "# data_time among workers can have high variance. The actual latency", "\n", "# caused by data_time is the maximum among workers.", "\n", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "# average the rest metrics", "\n", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "total_losses_reduced", "=", "sum", "(", "metrics_dict", ".", "values", "(", ")", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "total_losses_reduced", ")", ":", "\n", "                ", "raise", "FloatingPointError", "(", "\n", "f\"Loss became infinite or NaN at iteration={self.iter}!\\n\"", "\n", "f\"loss_dict = {metrics_dict}\"", "\n", ")", "\n", "\n", "", "storage", ".", "put_scalar", "(", "\"{}total_loss\"", ".", "format", "(", "prefix", ")", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.AMPTrainer.__init__": [[302, 320], ["isinstance", "train_loop.SimpleTrainer.__init__", "isinstance", "GradScaler", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "data_loader", ",", "optimizer", ",", "grad_scaler", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model, data_loader, optimizer: same as in :class:`SimpleTrainer`.\n            grad_scaler: torch GradScaler to automatically scale gradients.\n        \"\"\"", "\n", "unsupported", "=", "\"AMPTrainer does not support single-process multi-device training!\"", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "assert", "not", "(", "model", ".", "device_ids", "and", "len", "(", "model", ".", "device_ids", ")", ">", "1", ")", ",", "unsupported", "\n", "", "assert", "not", "isinstance", "(", "model", ",", "DataParallel", ")", ",", "unsupported", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "if", "grad_scaler", "is", "None", ":", "\n", "            ", "from", "torch", ".", "cuda", ".", "amp", "import", "GradScaler", "\n", "\n", "grad_scaler", "=", "GradScaler", "(", ")", "\n", "", "self", ".", "grad_scaler", "=", "grad_scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.AMPTrainer.run_step": [[321, 344], ["torch.cuda.is_available", "time.perf_counter", "next", "train_loop.AMPTrainer.optimizer.zero_grad", "train_loop.AMPTrainer.grad_scaler.scale().backward", "train_loop.AMPTrainer._write_metrics", "train_loop.AMPTrainer.grad_scaler.step", "train_loop.AMPTrainer.grad_scaler.update", "time.perf_counter", "autocast", "train_loop.AMPTrainer.model", "sum", "train_loop.AMPTrainer.values", "train_loop.AMPTrainer.grad_scaler.scale"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated._ROIAlignRotated.backward", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.train_loop.SimpleTrainer._write_metrics", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.scale"], ["", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the AMP training logic.\n        \"\"\"", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[AMPTrainer] model was changed to eval mode!\"", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"[AMPTrainer] CUDA is required for AMP training!\"", "\n", "from", "torch", ".", "cuda", ".", "amp", "import", "autocast", "\n", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "data", "=", "next", "(", "self", ".", "_data_loader_iter", ")", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "with", "autocast", "(", ")", ":", "\n", "            ", "loss_dict", "=", "self", ".", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "grad_scaler", ".", "scale", "(", "losses", ")", ".", "backward", "(", ")", "\n", "\n", "self", ".", "_write_metrics", "(", "loss_dict", ",", "data_time", ")", "\n", "\n", "self", ".", "grad_scaler", ".", "step", "(", "self", ".", "optimizer", ")", "\n", "self", ".", "grad_scaler", ".", "update", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.MapDataset.__init__": [[28, 34], ["detectron2.utils.serialize.PicklableWrapper", "random.Random", "set", "range", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["def", "__init__", "(", "self", ",", "dataset", ",", "map_func", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_map_func", "=", "PicklableWrapper", "(", "map_func", ")", "# wrap so that a lambda will work", "\n", "\n", "self", ".", "_rng", "=", "random", ".", "Random", "(", "42", ")", "\n", "self", ".", "_fallback_candidates", "=", "set", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.MapDataset.__len__": [[35, 37], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.MapDataset.__getitem__": [[38, 58], ["int", "common.MapDataset._map_func", "common.MapDataset._fallback_candidates.discard", "common.MapDataset._fallback_candidates.add", "common.MapDataset._rng.sample", "logging.getLogger", "logging.getLogger.warning"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "retry_count", "=", "0", "\n", "cur_idx", "=", "int", "(", "idx", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "data", "=", "self", ".", "_map_func", "(", "self", ".", "_dataset", "[", "cur_idx", "]", ")", "\n", "if", "data", "is", "not", "None", ":", "\n", "                ", "self", ".", "_fallback_candidates", ".", "add", "(", "cur_idx", ")", "\n", "return", "data", "\n", "\n", "# _map_func fails for this idx, use a random new index from the pool", "\n", "", "retry_count", "+=", "1", "\n", "self", ".", "_fallback_candidates", ".", "discard", "(", "cur_idx", ")", "\n", "cur_idx", "=", "self", ".", "_rng", ".", "sample", "(", "self", ".", "_fallback_candidates", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "if", "retry_count", ">=", "3", ":", "\n", "                ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Failed to apply `_map_func` for idx: {}, retry count: {}\"", ".", "format", "(", "\n", "idx", ",", "retry_count", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.DatasetFromList.__init__": [[67, 98], ["pickle.dumps", "numpy.frombuffer", "logging.getLogger", "logging.getLogger.info", "numpy.asarray", "numpy.cumsum", "numpy.concatenate", "logging.getLogger.info", "common.DatasetFromList.__init__._serialize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lst", ":", "list", ",", "copy", ":", "bool", "=", "True", ",", "serialize", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            lst (list): a list which contains elements to produce.\n            copy (bool): whether to deepcopy the element when producing it,\n                so that the result can be modified in place without affecting the\n                source in the list.\n            serialize (bool): whether to hold memory using serialized objects, when\n                enabled, data loader workers can use shared RAM from master\n                process instead of making a copy.\n        \"\"\"", "\n", "self", ".", "_lst", "=", "lst", "\n", "self", ".", "_copy", "=", "copy", "\n", "self", ".", "_serialize", "=", "serialize", "\n", "\n", "def", "_serialize", "(", "data", ")", ":", "\n", "            ", "buffer", "=", "pickle", ".", "dumps", "(", "data", ",", "protocol", "=", "-", "1", ")", "\n", "return", "np", ".", "frombuffer", "(", "buffer", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "", "if", "self", ".", "_serialize", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\n", "\"Serializing {} elements to byte tensors and concatenating them all ...\"", ".", "format", "(", "\n", "len", "(", "self", ".", "_lst", ")", "\n", ")", "\n", ")", "\n", "self", ".", "_lst", "=", "[", "_serialize", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", "\n", "self", ".", "_addr", "=", "np", ".", "asarray", "(", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "self", ".", "_addr", "=", "np", ".", "cumsum", "(", "self", ".", "_addr", ")", "\n", "self", ".", "_lst", "=", "np", ".", "concatenate", "(", "self", ".", "_lst", ")", "\n", "logger", ".", "info", "(", "\"Serialized dataset takes {:.2f} MiB\"", ".", "format", "(", "len", "(", "self", ".", "_lst", ")", "/", "1024", "**", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.DatasetFromList.__len__": [[99, 104], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "return", "len", "(", "self", ".", "_addr", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.DatasetFromList.__getitem__": [[105, 115], ["common.DatasetFromList._addr[].item", "memoryview", "pickle.loads", "common.DatasetFromList._addr[].item", "copy.deepcopy"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "start_addr", "=", "0", "if", "idx", "==", "0", "else", "self", ".", "_addr", "[", "idx", "-", "1", "]", ".", "item", "(", ")", "\n", "end_addr", "=", "self", ".", "_addr", "[", "idx", "]", ".", "item", "(", ")", "\n", "bytes", "=", "memoryview", "(", "self", ".", "_lst", "[", "start_addr", ":", "end_addr", "]", ")", "\n", "return", "pickle", ".", "loads", "(", "bytes", ")", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "            ", "return", "copy", ".", "deepcopy", "(", "self", ".", "_lst", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_lst", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.ToIterableDataset.__init__": [[123, 134], ["isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "sampler", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset (torch.utils.data.Dataset): an old-style dataset with ``__getitem__``\n            sampler (torch.utils.data.sampler.Sampler): a cheap iterable that produces indices\n                to be applied on ``dataset``.\n        \"\"\"", "\n", "assert", "not", "isinstance", "(", "dataset", ",", "data", ".", "IterableDataset", ")", ",", "dataset", "\n", "assert", "isinstance", "(", "sampler", ",", "Sampler", ")", ",", "sampler", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sampler", "=", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.ToIterableDataset.__iter__": [[135, 150], ["torch.get_worker_info", "itertools.islice"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", "or", "worker_info", ".", "num_workers", "==", "1", ":", "\n", "            ", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "                ", "yield", "self", ".", "dataset", "[", "idx", "]", "\n", "", "", "else", ":", "\n", "# With map-style dataset, `DataLoader(dataset, sampler)` runs the", "\n", "# sampler in main process only. But `DataLoader(ToIterableDataset(dataset, sampler))`", "\n", "# will run sampler in every of the N worker and only keep 1/N of the ids on each", "\n", "# worker. The assumption is that sampler is cheap to iterate and it's fine to discard", "\n", "# ids in workers.", "\n", "            ", "for", "idx", "in", "itertools", ".", "islice", "(", "\n", "self", ".", "sampler", ",", "worker_info", ".", "id", ",", "None", ",", "worker_info", ".", "num_workers", "\n", ")", ":", "\n", "                ", "yield", "self", ".", "dataset", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.AspectRatioGroupedDataset.__init__": [[165, 175], ["range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset: an iterable. Each element must be a dict with keys\n                \"width\" and \"height\", which will be used to batch data.\n            batch_size (int):\n        \"\"\"", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "# Hard-coded two aspect ratio groups: w > h and w < h.", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.common.AspectRatioGroupedDataset.__iter__": [[178, 187], ["bucket.append", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "d", "in", "self", ".", "dataset", ":", "\n", "            ", "w", ",", "h", "=", "d", "[", "\"width\"", "]", ",", "d", "[", "\"height\"", "]", "\n", "bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "bucket", "=", "self", ".", "_buckets", "[", "bucket_id", "]", "\n", "bucket", ".", "append", "(", "d", ")", "\n", "if", "len", "(", "bucket", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "bucket", "[", ":", "]", "\n", "del", "bucket", "[", ":", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.convert_PIL_to_numpy": [[59, 90], ["numpy.asarray", "np.dot.convert", "numpy.expand_dims", "numpy.dot", "numpy.array"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["def", "convert_PIL_to_numpy", "(", "image", ",", "format", ")", ":", "\n", "    ", "\"\"\"\n    Convert PIL image to numpy array of target format.\n\n    Args:\n        image (PIL.Image): a PIL image\n        format (str): the format of output image\n\n    Returns:\n        (np.ndarray): also see `read_image`\n    \"\"\"", "\n", "if", "format", "is", "not", "None", ":", "\n", "# PIL only supports RGB, so convert to RGB and flip channels over below", "\n", "        ", "conversion_format", "=", "format", "\n", "if", "format", "in", "[", "\"BGR\"", ",", "\"YUV-BT.601\"", "]", ":", "\n", "            ", "conversion_format", "=", "\"RGB\"", "\n", "", "image", "=", "image", ".", "convert", "(", "conversion_format", ")", "\n", "", "image", "=", "np", ".", "asarray", "(", "image", ")", "\n", "# PIL squeezes out the channel dimension for \"L\", so make it HWC", "\n", "if", "format", "==", "\"L\"", ":", "\n", "        ", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "-", "1", ")", "\n", "\n", "# handle formats not supported by PIL", "\n", "", "elif", "format", "==", "\"BGR\"", ":", "\n", "# flip channels if needed", "\n", "        ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "elif", "format", "==", "\"YUV-BT.601\"", ":", "\n", "        ", "image", "=", "image", "/", "255.0", "\n", "image", "=", "np", ".", "dot", "(", "image", ",", "np", ".", "array", "(", "_M_RGB2YUV", ")", ".", "T", ")", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.convert_image_to_rgb": [[92, 116], ["isinstance", "np.asarray.cpu().numpy", "numpy.dot", "np.asarray.astype", "numpy.asarray", "np.asarray.cpu", "PIL.Image.fromarray().convert", "numpy.array", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["", "def", "convert_image_to_rgb", "(", "image", ",", "format", ")", ":", "\n", "    ", "\"\"\"\n    Convert an image from given format to RGB.\n\n    Args:\n        image (np.ndarray or Tensor): an HWC image\n        format (str): the format of input image, also see `read_image`\n\n    Returns:\n        (np.ndarray): (H,W,3) RGB image in 0-255 range, can be either float or uint8\n    \"\"\"", "\n", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "image", "=", "image", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "format", "==", "\"BGR\"", ":", "\n", "        ", "image", "=", "image", "[", ":", ",", ":", ",", "[", "2", ",", "1", ",", "0", "]", "]", "\n", "", "elif", "format", "==", "\"YUV-BT.601\"", ":", "\n", "        ", "image", "=", "np", ".", "dot", "(", "image", ",", "np", ".", "array", "(", "_M_YUV2RGB", ")", ".", "T", ")", "\n", "image", "=", "image", "*", "255.0", "\n", "", "else", ":", "\n", "        ", "if", "format", "==", "\"L\"", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "", "image", "=", "image", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "image", "=", "np", ".", "asarray", "(", "Image", ".", "fromarray", "(", "image", ",", "mode", "=", "format", ")", ".", "convert", "(", "\"RGB\"", ")", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils._apply_exif_orientation": [[118, 163], ["image.getexif.get", "hasattr", "image.getexif", "image.transpose"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_apply_exif_orientation", "(", "image", ")", ":", "\n", "    ", "\"\"\"\n    Applies the exif orientation correctly.\n\n    This code exists per the bug:\n      https://github.com/python-pillow/Pillow/issues/3973\n    with the function `ImageOps.exif_transpose`. The Pillow source raises errors with\n    various methods, especially `tobytes`\n\n    Function based on:\n      https://github.com/wkentaro/labelme/blob/v4.5.4/labelme/utils/image.py#L59\n      https://github.com/python-pillow/Pillow/blob/7.1.2/src/PIL/ImageOps.py#L527\n\n    Args:\n        image (PIL.Image): a PIL image\n\n    Returns:\n        (PIL.Image): the PIL image with exif orientation applied, if applicable\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "image", ",", "\"getexif\"", ")", ":", "\n", "        ", "return", "image", "\n", "\n", "", "try", ":", "\n", "        ", "exif", "=", "image", ".", "getexif", "(", ")", "\n", "", "except", "Exception", ":", "# https://github.com/facebookresearch/detectron2/issues/1885", "\n", "        ", "exif", "=", "None", "\n", "\n", "", "if", "exif", "is", "None", ":", "\n", "        ", "return", "image", "\n", "\n", "", "orientation", "=", "exif", ".", "get", "(", "_EXIF_ORIENT", ")", "\n", "\n", "method", "=", "{", "\n", "2", ":", "Image", ".", "FLIP_LEFT_RIGHT", ",", "\n", "3", ":", "Image", ".", "ROTATE_180", ",", "\n", "4", ":", "Image", ".", "FLIP_TOP_BOTTOM", ",", "\n", "5", ":", "Image", ".", "TRANSPOSE", ",", "\n", "6", ":", "Image", ".", "ROTATE_270", ",", "\n", "7", ":", "Image", ".", "TRANSVERSE", ",", "\n", "8", ":", "Image", ".", "ROTATE_90", ",", "\n", "}", ".", "get", "(", "orientation", ")", "\n", "\n", "if", "method", "is", "not", "None", ":", "\n", "        ", "return", "image", ".", "transpose", "(", "method", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image": [[165, 185], ["detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "detection_utils._apply_exif_orientation", "detection_utils.convert_PIL_to_numpy"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils._apply_exif_orientation", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.convert_PIL_to_numpy"], ["", "def", "read_image", "(", "file_name", ",", "format", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Read an image into the given format.\n    Will apply rotation and flipping if the image has such exif information.\n\n    Args:\n        file_name (str): image file path\n        format (str): one of the supported image modes in PIL, or \"BGR\" or \"YUV-BT.601\".\n\n    Returns:\n        image (np.ndarray):\n            an HWC image in the given format, which is 0-255, uint8 for\n            supported image modes in PIL or \"BGR\"; float (0-1 for Y) for YUV-BT.601.\n    \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "file_name", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "f", ")", "\n", "\n", "# work around this bug: https://github.com/python-pillow/Pillow/issues/3973", "\n", "image", "=", "_apply_exif_orientation", "(", "image", ")", "\n", "return", "convert_PIL_to_numpy", "(", "image", ",", "format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_image_size": [[187, 211], ["detection_utils.SizeMismatchError"], "function", ["None"], ["", "", "def", "check_image_size", "(", "dataset_dict", ",", "image", ")", ":", "\n", "    ", "\"\"\"\n    Raise an error if the image does not match the size specified in the dict.\n    \"\"\"", "\n", "if", "\"width\"", "in", "dataset_dict", "or", "\"height\"", "in", "dataset_dict", ":", "\n", "        ", "image_wh", "=", "(", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "0", "]", ")", "\n", "expected_wh", "=", "(", "dataset_dict", "[", "\"width\"", "]", ",", "dataset_dict", "[", "\"height\"", "]", ")", "\n", "if", "not", "image_wh", "==", "expected_wh", ":", "\n", "            ", "raise", "SizeMismatchError", "(", "\n", "\"Mismatched image shape{}, got {}, expect {}.\"", ".", "format", "(", "\n", "\" for image \"", "+", "dataset_dict", "[", "\"file_name\"", "]", "\n", "if", "\"file_name\"", "in", "dataset_dict", "\n", "else", "\"\"", ",", "\n", "image_wh", ",", "\n", "expected_wh", ",", "\n", ")", "\n", "+", "\" Please check the width/height in your annotation.\"", "\n", ")", "\n", "\n", "# To ensure bbox always remap to original image size", "\n", "", "", "if", "\"width\"", "not", "in", "dataset_dict", ":", "\n", "        ", "dataset_dict", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "", "if", "\"height\"", "not", "in", "dataset_dict", ":", "\n", "        ", "dataset_dict", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_proposals": [[213, 254], ["transforms.apply_box", "detectron2.structures.Boxes", "torch.as_tensor", "detectron2.structures.Boxes.clip", "detectron2.structures.Boxes.nonempty", "detectron2.structures.Instances", "detectron2.structures.BoxMode.convert", "dataset_dict.pop().astype", "dataset_dict.pop", "dataset_dict.pop", "dataset_dict.pop"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["", "", "def", "transform_proposals", "(", "dataset_dict", ",", "image_shape", ",", "transforms", ",", "*", ",", "proposal_topk", ",", "min_box_size", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Apply transformations to the proposals in dataset_dict, if any.\n\n    Args:\n        dataset_dict (dict): a dict read from the dataset, possibly\n            contains fields \"proposal_boxes\", \"proposal_objectness_logits\", \"proposal_bbox_mode\"\n        image_shape (tuple): height, width\n        transforms (TransformList):\n        proposal_topk (int): only keep top-K scoring proposals\n        min_box_size (int): proposals with either side smaller than this\n            threshold are removed\n\n    The input dict is modified in-place, with abovementioned keys removed. A new\n    key \"proposals\" will be added. Its value is an `Instances`\n    object which contains the transformed proposals in its field\n    \"proposal_boxes\" and \"objectness_logits\".\n    \"\"\"", "\n", "if", "\"proposal_boxes\"", "in", "dataset_dict", ":", "\n", "# Transform proposal boxes", "\n", "        ", "boxes", "=", "transforms", ".", "apply_box", "(", "\n", "BoxMode", ".", "convert", "(", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_boxes\"", ")", ",", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_bbox_mode\"", ")", ",", "\n", "BoxMode", ".", "XYXY_ABS", ",", "\n", ")", "\n", ")", "\n", "boxes", "=", "Boxes", "(", "boxes", ")", "\n", "objectness_logits", "=", "torch", ".", "as_tensor", "(", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_objectness_logits\"", ")", ".", "astype", "(", "\"float32\"", ")", "\n", ")", "\n", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "boxes", "=", "boxes", "[", "keep", "]", "\n", "objectness_logits", "=", "objectness_logits", "[", "keep", "]", "\n", "\n", "proposals", "=", "Instances", "(", "image_shape", ")", "\n", "proposals", ".", "proposal_boxes", "=", "boxes", "[", ":", "proposal_topk", "]", "\n", "proposals", ".", "objectness_logits", "=", "objectness_logits", "[", ":", "proposal_topk", "]", "\n", "dataset_dict", "[", "\"proposals\"", "]", "=", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_instance_annotations": [[256, 318], ["isinstance", "detectron2.structures.BoxMode.convert", "[].clip", "numpy.minimum", "transforms.TransformList", "isinstance", "detection_utils.transform_keypoint_annotations", "list", "isinstance", "T.TransformList.apply_box", "numpy.asarray().reshape", "p.reshape", "pycocotools.decode", "T.TransformList.apply_segmentation", "ValueError", "numpy.array", "T.TransformList.apply_polygons", "tuple", "numpy.asarray", "type"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_keypoint_annotations", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_segmentation"], ["", "", "def", "transform_instance_annotations", "(", "\n", "annotation", ",", "transforms", ",", "image_size", ",", "*", ",", "keypoint_hflip_indices", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply transforms to box, segmentation and keypoints annotations of a single instance.\n\n    It will use `transforms.apply_box` for the box, and\n    `transforms.apply_coords` for segmentation polygons & keypoints.\n    If you need anything more specially designed for each data structure,\n    you'll need to implement your own version of this function or the transforms.\n\n    Args:\n        annotation (dict): dict of instance annotations for a single instance.\n            It will be modified in-place.\n        transforms (TransformList or list[Transform]):\n        image_size (tuple): the height, width of the transformed image\n        keypoint_hflip_indices (ndarray[int]): see `create_keypoint_hflip_indices`.\n\n    Returns:\n        dict:\n            the same input dict with fields \"bbox\", \"segmentation\", \"keypoints\"\n            transformed according to `transforms`.\n            The \"bbox_mode\" field will be set to XYXY_ABS.\n    \"\"\"", "\n", "if", "isinstance", "(", "transforms", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "transforms", "=", "T", ".", "TransformList", "(", "transforms", ")", "\n", "# bbox is 1d (per-instance bounding box)", "\n", "", "bbox", "=", "BoxMode", ".", "convert", "(", "annotation", "[", "\"bbox\"", "]", ",", "annotation", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "# clip transformed bbox to image size", "\n", "bbox", "=", "transforms", ".", "apply_box", "(", "np", ".", "array", "(", "[", "bbox", "]", ")", ")", "[", "0", "]", ".", "clip", "(", "min", "=", "0", ")", "\n", "annotation", "[", "\"bbox\"", "]", "=", "np", ".", "minimum", "(", "bbox", ",", "list", "(", "image_size", "+", "image_size", ")", "[", ":", ":", "-", "1", "]", ")", "\n", "annotation", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "\n", "if", "\"segmentation\"", "in", "annotation", ":", "\n", "# each instance contains 1 or more polygons", "\n", "        ", "segm", "=", "annotation", "[", "\"segmentation\"", "]", "\n", "if", "isinstance", "(", "segm", ",", "list", ")", ":", "\n", "# polygons", "\n", "            ", "polygons", "=", "[", "np", ".", "asarray", "(", "p", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "for", "p", "in", "segm", "]", "\n", "annotation", "[", "\"segmentation\"", "]", "=", "[", "\n", "p", ".", "reshape", "(", "-", "1", ")", "for", "p", "in", "transforms", ".", "apply_polygons", "(", "polygons", ")", "\n", "]", "\n", "", "elif", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "# RLE", "\n", "            ", "mask", "=", "mask_util", ".", "decode", "(", "segm", ")", "\n", "mask", "=", "transforms", ".", "apply_segmentation", "(", "mask", ")", "\n", "assert", "tuple", "(", "mask", ".", "shape", "[", ":", "2", "]", ")", "==", "image_size", "\n", "annotation", "[", "\"segmentation\"", "]", "=", "mask", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot transform segmentation of type '{}'!\"", "\n", "\"Supported types are: polygons as list[list[float] or ndarray],\"", "\n", "\" COCO-style RLE as a dict.\"", ".", "format", "(", "type", "(", "segm", ")", ")", "\n", ")", "\n", "\n", "", "", "if", "\"keypoints\"", "in", "annotation", ":", "\n", "        ", "keypoints", "=", "transform_keypoint_annotations", "(", "\n", "annotation", "[", "\"keypoints\"", "]", ",", "transforms", ",", "image_size", ",", "keypoint_hflip_indices", "\n", ")", "\n", "annotation", "[", "\"keypoints\"", "]", "=", "keypoints", "\n", "\n", "", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_keypoint_annotations": [[320, 360], ["numpy.asarray().reshape", "transforms.apply_coords", "inside.all.all", "numpy.asarray", "numpy.array", "numpy.array", "sum", "isinstance"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_coords"], ["", "def", "transform_keypoint_annotations", "(", "keypoints", ",", "transforms", ",", "image_size", ",", "keypoint_hflip_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Transform keypoint annotations of an image.\n    If a keypoint is transformed out of image boundary, it will be marked \"unlabeled\" (visibility=0)\n\n    Args:\n        keypoints (list[float]): Nx3 float in Detectron2's Dataset format.\n            Each point is represented by (x, y, visibility).\n        transforms (TransformList):\n        image_size (tuple): the height, width of the transformed image\n        keypoint_hflip_indices (ndarray[int]): see `create_keypoint_hflip_indices`.\n            When `transforms` includes horizontal flip, will use the index\n            mapping to flip keypoints.\n    \"\"\"", "\n", "# (N*3,) -> (N, 3)", "\n", "keypoints", "=", "np", ".", "asarray", "(", "keypoints", ",", "dtype", "=", "\"float64\"", ")", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "keypoints_xy", "=", "transforms", ".", "apply_coords", "(", "keypoints", "[", ":", ",", ":", "2", "]", ")", "\n", "\n", "# Set all out-of-boundary points to \"unlabeled\"", "\n", "inside", "=", "(", "keypoints_xy", ">=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", ")", "&", "(", "keypoints_xy", "<=", "np", ".", "array", "(", "image_size", "[", ":", ":", "-", "1", "]", ")", ")", "\n", "inside", "=", "inside", ".", "all", "(", "axis", "=", "1", ")", "\n", "keypoints", "[", ":", ",", ":", "2", "]", "=", "keypoints_xy", "\n", "keypoints", "[", ":", ",", "2", "]", "[", "~", "inside", "]", "=", "0", "\n", "\n", "# This assumes that HorizFlipTransform is the only one that does flip", "\n", "do_hflip", "=", "sum", "(", "isinstance", "(", "t", ",", "T", ".", "HFlipTransform", ")", "for", "t", "in", "transforms", ".", "transforms", ")", "%", "2", "==", "1", "\n", "\n", "# Alternative way: check if probe points was horizontally flipped.", "\n", "# probe = np.asarray([[0.0, 0.0], [image_width, 0.0]])", "\n", "# probe_aug = transforms.apply_coords(probe.copy())", "\n", "# do_hflip = np.sign(probe[1][0] - probe[0][0]) != np.sign(probe_aug[1][0] - probe_aug[0][0])  # noqa", "\n", "\n", "# If flipped, swap each keypoint with its opposite-handed equivalent", "\n", "if", "do_hflip", ":", "\n", "        ", "assert", "keypoint_hflip_indices", "is", "not", "None", "\n", "keypoints", "=", "keypoints", "[", "keypoint_hflip_indices", ",", ":", "]", "\n", "\n", "# Maintain COCO convention that if visibility == 0 (unlabeled), then x, y = 0", "\n", "", "keypoints", "[", "keypoints", "[", ":", ",", "2", "]", "==", "0", "]", "=", "0", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.annotations_to_instances": [[362, 429], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.tensor", "detectron2.structures.BoxMode.convert", "int", "len", "len", "detectron2.structures.Keypoints", "detectron2.structures.BitMasks", "obj.get", "detectron2.structures.PolygonMasks", "isinstance", "torch.stack", "ValueError", "detectron2.structures.PolygonMasks.append", "isinstance", "detectron2.structures.polygons_to_bitmask", "detectron2.structures.PolygonMasks.append", "isinstance", "torch.from_numpy", "pycocotools.decode", "detectron2.structures.PolygonMasks.append", "ValueError", "numpy.ascontiguousarray", "type"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.polygons_to_bitmask", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode"], ["", "def", "annotations_to_instances", "(", "annos", ",", "image_size", ",", "mask_format", "=", "\"polygon\"", ")", ":", "\n", "    ", "\"\"\"\n    Create an :class:`Instances` object used by the models,\n    from instance annotations in the dataset dict.\n\n    Args:\n        annos (list[dict]): a list of instance annotations in one image, each\n            element for one instance.\n        image_size (tuple): height, width\n\n    Returns:\n        Instances:\n            It will contain fields \"gt_boxes\", \"gt_classes\",\n            \"gt_masks\", \"gt_keypoints\", if they can be obtained from `annos`.\n            This is the format that builtin models expect.\n    \"\"\"", "\n", "boxes", "=", "[", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "obj", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "for", "obj", "in", "annos", "]", "\n", "target", "=", "Instances", "(", "image_size", ")", "\n", "target", ".", "gt_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "\n", "classes", "=", "[", "int", "(", "obj", "[", "\"category_id\"", "]", ")", "for", "obj", "in", "annos", "]", "\n", "classes", "=", "torch", ".", "tensor", "(", "classes", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "target", ".", "gt_classes", "=", "classes", "\n", "\n", "if", "len", "(", "annos", ")", "and", "\"segmentation\"", "in", "annos", "[", "0", "]", ":", "\n", "        ", "segms", "=", "[", "obj", "[", "\"segmentation\"", "]", "for", "obj", "in", "annos", "]", "\n", "if", "mask_format", "==", "\"polygon\"", ":", "\n", "            ", "try", ":", "\n", "                ", "masks", "=", "PolygonMasks", "(", "segms", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Failed to use mask_format=='polygon' from the given annotations!\"", "\n", ")", "from", "e", "\n", "", "", "else", ":", "\n", "            ", "assert", "mask_format", "==", "\"bitmask\"", ",", "mask_format", "\n", "masks", "=", "[", "]", "\n", "for", "segm", "in", "segms", ":", "\n", "                ", "if", "isinstance", "(", "segm", ",", "list", ")", ":", "\n", "# polygon", "\n", "                    ", "masks", ".", "append", "(", "polygons_to_bitmask", "(", "segm", ",", "*", "image_size", ")", ")", "\n", "", "elif", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "# COCO RLE", "\n", "                    ", "masks", ".", "append", "(", "mask_util", ".", "decode", "(", "segm", ")", ")", "\n", "", "elif", "isinstance", "(", "segm", ",", "np", ".", "ndarray", ")", ":", "\n", "                    ", "assert", "segm", ".", "ndim", "==", "2", ",", "\"Expect segmentation of 2 dimensions, got {}.\"", ".", "format", "(", "\n", "segm", ".", "ndim", "\n", ")", "\n", "# mask array", "\n", "masks", ".", "append", "(", "segm", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Cannot convert segmentation of type '{}' to BitMasks!\"", "\n", "\"Supported types are: polygons as list[list[float] or ndarray],\"", "\n", "\" COCO-style RLE as a dict, or a binary segmentation mask \"", "\n", "\" in a 2D numpy array of shape HxW.\"", ".", "format", "(", "type", "(", "segm", ")", ")", "\n", ")", "\n", "# torch.from_numpy does not support array with negative stride.", "\n", "", "", "masks", "=", "BitMasks", "(", "\n", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "x", ")", ")", "for", "x", "in", "masks", "]", ")", "\n", ")", "\n", "", "target", ".", "gt_masks", "=", "masks", "\n", "\n", "", "if", "len", "(", "annos", ")", "and", "\"keypoints\"", "in", "annos", "[", "0", "]", ":", "\n", "        ", "kpts", "=", "[", "obj", ".", "get", "(", "\"keypoints\"", ",", "[", "]", ")", "for", "obj", "in", "annos", "]", "\n", "target", ".", "gt_keypoints", "=", "Keypoints", "(", "kpts", ")", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.annotations_to_instances_rotated": [[431, 458], ["detectron2.structures.Instances", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes.clip", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clip"], ["", "def", "annotations_to_instances_rotated", "(", "annos", ",", "image_size", ")", ":", "\n", "    ", "\"\"\"\n    Create an :class:`Instances` object used by the models,\n    from instance annotations in the dataset dict.\n    Compared to `annotations_to_instances`, this function is for rotated boxes only\n\n    Args:\n        annos (list[dict]): a list of instance annotations in one image, each\n            element for one instance.\n        image_size (tuple): height, width\n\n    Returns:\n        Instances:\n            Containing fields \"gt_boxes\", \"gt_classes\",\n            if they can be obtained from `annos`.\n            This is the format that builtin models expect.\n    \"\"\"", "\n", "boxes", "=", "[", "obj", "[", "\"bbox\"", "]", "for", "obj", "in", "annos", "]", "\n", "target", "=", "Instances", "(", "image_size", ")", "\n", "boxes", "=", "target", ".", "gt_boxes", "=", "RotatedBoxes", "(", "boxes", ")", "\n", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "classes", "=", "[", "obj", "[", "\"category_id\"", "]", "for", "obj", "in", "annos", "]", "\n", "classes", "=", "torch", ".", "tensor", "(", "classes", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "target", ".", "gt_classes", "=", "classes", "\n", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.filter_empty_instances": [[460, 488], ["r.append", "instances.has", "r.append", "instances.gt_boxes.nonempty", "instances.gt_masks.nonempty"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.nonempty"], ["", "def", "filter_empty_instances", "(", "instances", ",", "by_box", "=", "True", ",", "by_mask", "=", "True", ",", "box_threshold", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"\n    Filter out empty instances in an `Instances` object.\n\n    Args:\n        instances (Instances):\n        by_box (bool): whether to filter out instances with empty boxes\n        by_mask (bool): whether to filter out instances with empty masks\n        box_threshold (float): minimum width and height to be considered non-empty\n\n    Returns:\n        Instances: the filtered instances.\n    \"\"\"", "\n", "assert", "by_box", "or", "by_mask", "\n", "r", "=", "[", "]", "\n", "if", "by_box", ":", "\n", "        ", "r", ".", "append", "(", "instances", ".", "gt_boxes", ".", "nonempty", "(", "threshold", "=", "box_threshold", ")", ")", "\n", "", "if", "instances", ".", "has", "(", "\"gt_masks\"", ")", "and", "by_mask", ":", "\n", "        ", "r", ".", "append", "(", "instances", ".", "gt_masks", ".", "nonempty", "(", ")", ")", "\n", "\n", "# TODO: can also filter visible keypoints", "\n", "\n", "", "if", "not", "r", ":", "\n", "        ", "return", "instances", "\n", "", "m", "=", "r", "[", "0", "]", "\n", "for", "x", "in", "r", "[", "1", ":", "]", ":", "\n", "        ", "m", "=", "m", "&", "x", "\n", "", "return", "instances", "[", "m", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.create_keypoint_hflip_indices": [[490, 510], ["detection_utils.check_metadata_consistency", "detection_utils.check_metadata_consistency", "catalog.MetadataCatalog.get", "dict", "dict.update", "numpy.asarray", "names.index", "dict.items"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "create_keypoint_hflip_indices", "(", "dataset_names", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dataset_names (list[str]): list of dataset names\n    Returns:\n        ndarray[int]: a vector of size=#keypoints, storing the\n        horizontally-flipped keypoint indices.\n    \"\"\"", "\n", "\n", "check_metadata_consistency", "(", "\"keypoint_names\"", ",", "dataset_names", ")", "\n", "check_metadata_consistency", "(", "\"keypoint_flip_map\"", ",", "dataset_names", ")", "\n", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_names", "[", "0", "]", ")", "\n", "names", "=", "meta", ".", "keypoint_names", "\n", "# TODO flip -> hflip", "\n", "flip_map", "=", "dict", "(", "meta", ".", "keypoint_flip_map", ")", "\n", "flip_map", ".", "update", "(", "{", "v", ":", "k", "for", "k", ",", "v", "in", "flip_map", ".", "items", "(", ")", "}", ")", "\n", "flipped_names", "=", "[", "i", "if", "i", "not", "in", "flip_map", "else", "flip_map", "[", "i", "]", "for", "i", "in", "names", "]", "\n", "flip_indices", "=", "[", "names", ".", "index", "(", "i", ")", "for", "i", "in", "flipped_names", "]", "\n", "return", "np", ".", "asarray", "(", "flip_indices", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.gen_crop_transform_with_instance": [[512, 540], ["numpy.asarray", "detectron2.structures.BoxMode.convert", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.random.randint", "numpy.random.randint", "transforms.CropTransform", "numpy.ceil().astype", "numpy.floor().astype", "numpy.asarray", "numpy.ceil", "numpy.floor"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["", "def", "gen_crop_transform_with_instance", "(", "crop_size", ",", "image_size", ",", "instance", ")", ":", "\n", "    ", "\"\"\"\n    Generate a CropTransform so that the cropping region contains\n    the center of the given instance.\n\n    Args:\n        crop_size (tuple): h, w in pixels\n        image_size (tuple): h, w\n        instance (dict): an annotation dict of one instance, in Detectron2's\n            dataset format.\n    \"\"\"", "\n", "crop_size", "=", "np", ".", "asarray", "(", "crop_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "instance", "[", "\"bbox\"", "]", ",", "instance", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "center_yx", "=", "(", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ")", "*", "0.5", ",", "(", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ")", "*", "0.5", "\n", "assert", "(", "\n", "image_size", "[", "0", "]", ">=", "center_yx", "[", "0", "]", "and", "image_size", "[", "1", "]", ">=", "center_yx", "[", "1", "]", "\n", ")", ",", "\"The annotation bounding box is outside of the image!\"", "\n", "assert", "(", "\n", "image_size", "[", "0", "]", ">=", "crop_size", "[", "0", "]", "and", "image_size", "[", "1", "]", ">=", "crop_size", "[", "1", "]", "\n", ")", ",", "\"Crop size is larger than image size!\"", "\n", "\n", "min_yx", "=", "np", ".", "maximum", "(", "np", ".", "floor", "(", "center_yx", ")", ".", "astype", "(", "np", ".", "int32", ")", "-", "crop_size", ",", "0", ")", "\n", "max_yx", "=", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "image_size", ",", "dtype", "=", "np", ".", "int32", ")", "-", "crop_size", ",", "0", ")", "\n", "max_yx", "=", "np", ".", "minimum", "(", "max_yx", ",", "np", ".", "ceil", "(", "center_yx", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "\n", "y0", "=", "np", ".", "random", ".", "randint", "(", "min_yx", "[", "0", "]", ",", "max_yx", "[", "0", "]", "+", "1", ")", "\n", "x0", "=", "np", ".", "random", ".", "randint", "(", "min_yx", "[", "1", "]", ",", "max_yx", "[", "1", "]", "+", "1", ")", "\n", "return", "T", ".", "CropTransform", "(", "x0", ",", "y0", ",", "crop_size", "[", "1", "]", ",", "crop_size", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_metadata_consistency": [[542, 569], ["logging.getLogger", "enumerate", "len", "getattr", "catalog.MetadataCatalog.get", "logging.getLogger.error", "logging.getLogger.error", "ValueError", "str", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "check_metadata_consistency", "(", "key", ",", "dataset_names", ")", ":", "\n", "    ", "\"\"\"\n    Check that the datasets have consistent metadata.\n\n    Args:\n        key (str): a metadata key\n        dataset_names (list[str]): a list of dataset names\n\n    Raises:\n        AttributeError: if the key does not exist in the metadata\n        ValueError: if the given datasets do not have the same metadata values defined by key\n    \"\"\"", "\n", "if", "len", "(", "dataset_names", ")", "==", "0", ":", "\n", "        ", "return", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "entries_per_dataset", "=", "[", "getattr", "(", "MetadataCatalog", ".", "get", "(", "d", ")", ",", "key", ")", "for", "d", "in", "dataset_names", "]", "\n", "for", "idx", ",", "entry", "in", "enumerate", "(", "entries_per_dataset", ")", ":", "\n", "        ", "if", "entry", "!=", "entries_per_dataset", "[", "0", "]", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Metadata '{}' for dataset '{}' is '{}'\"", ".", "format", "(", "key", ",", "dataset_names", "[", "idx", "]", ",", "str", "(", "entry", ")", ")", "\n", ")", "\n", "logger", ".", "error", "(", "\n", "\"Metadata '{}' for dataset '{}' is '{}'\"", ".", "format", "(", "\n", "key", ",", "dataset_names", "[", "0", "]", ",", "str", "(", "entries_per_dataset", "[", "0", "]", ")", "\n", ")", "\n", ")", "\n", "raise", "ValueError", "(", "\"Datasets have different metadata '{}'!\"", ".", "format", "(", "key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.build_augmentation": [[571, 596], ["transforms.ResizeShortestEdge", "augmentation.append", "transforms.RandomFlip"], "function", ["None"], ["", "", "", "def", "build_augmentation", "(", "cfg", ",", "is_train", ")", ":", "\n", "    ", "\"\"\"\n    Create a list of default :class:`Augmentation` from config.\n    Now it includes resizing and flipping.\n\n    Returns:\n        list[Augmentation]\n    \"\"\"", "\n", "if", "is_train", ":", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TRAIN", "\n", "sample_style", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN_SAMPLING", "\n", "", "else", ":", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", "sample_style", "=", "\"choice\"", "\n", "", "augmentation", "=", "[", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", "]", "\n", "if", "is_train", "and", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "!=", "\"none\"", ":", "\n", "        ", "augmentation", ".", "append", "(", "\n", "T", ".", "RandomFlip", "(", "\n", "horizontal", "=", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "==", "\"horizontal\"", ",", "\n", "vertical", "=", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "==", "\"vertical\"", ",", "\n", ")", "\n", ")", "\n", "", "return", "augmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register": [[29, 39], ["callable"], "methods", ["None"], ["\"FAIR/X-101-64x4d\"", ":", "\"ImageNetPretrained/FBResNeXt/X-101-64x4d.pkl\"", ",", "\n", "\"FAIR/X-152-32x8d-IN5k\"", ":", "\"ImageNetPretrained/25093814/X-152-32x8d-IN5k.pkl\"", ",", "\n", "}", "\n", "\n", "C2_DETECTRON_PATH_FORMAT", "=", "(", "\n", "\"{prefix}/{url}/output/train/{dataset}/{type}/model_final.pkl\"", "# noqa B950", "\n", ")", "\n", "\n", "C2_DATASET_COCO", "=", "\"coco_2014_train%3Acoco_2014_valminusminival\"", "\n", "C2_DATASET_COCO_KEYPOINTS", "=", "\"keypoints_coco_2014_train%3Akeypoints_coco_2014_valminusminival\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.get": [[40, 59], ["f", "KeyError", "catalog._DatasetCatalog.list"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["# format: {model_name} -> part of the url", "\n", "C2_DETECTRON_MODELS", "=", "{", "\n", "\"35857197/e2e_faster_rcnn_R-50-C4_1x\"", ":", "\"35857197/12_2017_baselines/e2e_faster_rcnn_R-50-C4_1x.yaml.01_33_49.iAX0mXvW\"", ",", "# noqa B950", "\n", "\"35857345/e2e_faster_rcnn_R-50-FPN_1x\"", ":", "\"35857345/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml.01_36_30.cUF7QR7I\"", ",", "# noqa B950", "\n", "\"35857890/e2e_faster_rcnn_R-101-FPN_1x\"", ":", "\"35857890/12_2017_baselines/e2e_faster_rcnn_R-101-FPN_1x.yaml.01_38_50.sNxI7sX7\"", ",", "# noqa B950", "\n", "\"36761737/e2e_faster_rcnn_X-101-32x8d-FPN_1x\"", ":", "\"36761737/12_2017_baselines/e2e_faster_rcnn_X-101-32x8d-FPN_1x.yaml.06_31_39.5MIHi1fZ\"", ",", "# noqa B950", "\n", "\"35858791/e2e_mask_rcnn_R-50-C4_1x\"", ":", "\"35858791/12_2017_baselines/e2e_mask_rcnn_R-50-C4_1x.yaml.01_45_57.ZgkA7hPB\"", ",", "# noqa B950", "\n", "\"35858933/e2e_mask_rcnn_R-50-FPN_1x\"", ":", "\"35858933/12_2017_baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC\"", ",", "# noqa B950", "\n", "\"35861795/e2e_mask_rcnn_R-101-FPN_1x\"", ":", "\"35861795/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_1x.yaml.02_31_37.KqyEK4tT\"", ",", "# noqa B950", "\n", "\"36761843/e2e_mask_rcnn_X-101-32x8d-FPN_1x\"", ":", "\"36761843/12_2017_baselines/e2e_mask_rcnn_X-101-32x8d-FPN_1x.yaml.06_35_59.RZotkLKI\"", ",", "# noqa B950", "\n", "\"48616381/e2e_mask_rcnn_R-50-FPN_2x_gn\"", ":", "\"GN/48616381/04_2018_gn_baselines/e2e_mask_rcnn_R-50-FPN_2x_gn_0416.13_23_38.bTlTI97Q\"", ",", "# noqa B950", "\n", "\"37697547/e2e_keypoint_rcnn_R-50-FPN_1x\"", ":", "\"37697547/12_2017_baselines/e2e_keypoint_rcnn_R-50-FPN_1x.yaml.08_42_54.kdzV35ao\"", ",", "# noqa B950", "\n", "\"35998355/rpn_R-50-C4_1x\"", ":", "\"35998355/12_2017_baselines/rpn_R-50-C4_1x.yaml.08_00_43.njH5oD9L\"", ",", "# noqa B950", "\n", "\"35998814/rpn_R-50-FPN_1x\"", ":", "\"35998814/12_2017_baselines/rpn_R-50-FPN_1x.yaml.08_06_03.Axg0r179\"", ",", "# noqa B950", "\n", "\"36225147/fast_R-50-FPN_1x\"", ":", "\"36225147/12_2017_baselines/fast_rcnn_R-50-FPN_1x.yaml.08_39_09.L3obSdQ2\"", ",", "# noqa B950", "\n", "}", "\n", "\n", "@", "staticmethod", "\n", "def", "get", "(", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"Caffe2Detectron/COCO\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.list": [[60, 68], ["catalog._DatasetCatalog.list"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["            ", "return", "ModelCatalog", ".", "_get_c2_detectron_baseline", "(", "name", ")", "\n", "", "if", "name", ".", "startswith", "(", "\"ImageNetPretrained/\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_imagenet_pretrained", "(", "name", ")", "\n", "", "raise", "RuntimeError", "(", "\"model not present in the catalog: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_get_c2_imagenet_pretrained", "(", "name", ")", ":", "\n", "        ", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", "\n", "name", "=", "name", "[", "len", "(", "\"ImageNetPretrained/\"", ")", ":", "]", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.remove": [[69, 74], ["catalog._DatasetCatalog.pop"], "methods", ["None"], ["name", "=", "ModelCatalog", ".", "C2_IMAGENET_MODELS", "[", "name", "]", "\n", "url", "=", "\"/\"", ".", "join", "(", "[", "prefix", ",", "name", "]", ")", "\n", "return", "url", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_get_c2_detectron_baseline", "(", "name", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.__str__": [[75, 77], ["catalog._DatasetCatalog.keys"], "methods", ["None"], ["        ", "name", "=", "name", "[", "len", "(", "\"Caffe2Detectron/COCO/\"", ")", ":", "]", "\n", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_MODELS", "[", "name", "]", "\n", "if", "\"keypoint_rcnn\"", "in", "name", ":", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.__getattr__": [[115, 133], ["detectron2.utils.logger.log_first_n", "getattr", "len", "AttributeError", "AttributeError", "str", "catalog.Metadata.__dict__.keys"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_first_n"], ["", "", "PathManager", ".", "register_handler", "(", "ModelCatalogHandler", "(", ")", ")", "\n", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.__setattr__": [[136, 154], ["detectron2.utils.logger.log_first_n", "setattr", "getattr", "types.SimpleNamespace.__setattr__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_first_n", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.__setattr__"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.as_dict": [[155, 161], ["copy.copy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set": [[162, 169], ["kwargs.items", "setattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.get": [[170, 179], ["getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get": [[194, 208], ["len", "super().get", "catalog.Metadata"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list": [[209, 217], ["catalog._MetadataCatalog.list"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.remove": [[218, 223], ["catalog._MetadataCatalog.pop"], "methods", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.__str__": [[224, 226], ["catalog._MetadataCatalog.keys"], "methods", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.filter_images_with_only_crowd_annotations": [[38, 67], ["len", "len", "logging.getLogger", "logging.getLogger.info", "build.filter_images_with_only_crowd_annotations.valid"], "function", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.filter_images_with_few_keypoints": [[69, 101], ["len", "len", "logging.getLogger", "logging.getLogger.info", "sum", "build.filter_images_with_few_keypoints.visible_keypoints_in_image"], "function", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.load_proposals_into_dataset": [[103, 155], ["logging.getLogger", "logging.getLogger.info", "set", "detectron2.utils.file_io.PathManager.open", "pickle.load", "str", "detectron2.structures.BoxMode", "pickle.load.pop", "str", "enumerate", "objectness_logits.argsort", "str", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.print_instances_class_histogram": [[157, 206], ["len", "numpy.arange", "numpy.zeros", "min", "list", "sum", "itertools.zip_longest.extend", "itertools.zip_longest", "tabulate.tabulate", "detectron2.utils.logger.log_first_n", "numpy.asarray", "len", "itertools.chain", "itertools.zip_longest.extend", "numpy.histogram", "len", "len", "termcolor.colored", "np.asarray.min", "np.asarray.max", "np.asarray.min", "np.asarray.max", "len", "range", "x.get", "build.print_instances_class_histogram.short_name"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_first_n", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.get_detection_dataset_dicts": [[209, 257], ["isinstance", "len", "zip", "list", "len", "catalog.DatasetCatalog.get", "len", "itertools.chain.from_iterable", "build.filter_images_with_only_crowd_annotations", "build.filter_images_with_few_keypoints", "len", "len", "build.load_proposals_into_dataset", "detection_utils.check_metadata_consistency", "build.print_instances_class_histogram", "zip", "catalog.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.filter_images_with_only_crowd_annotations", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.filter_images_with_few_keypoints", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.load_proposals_into_dataset", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.print_instances_class_histogram", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_batch_data_loader": [[259, 303], ["detectron2.utils.comm.get_world_size", "torch.utils.data.DataLoader", "common.AspectRatioGroupedDataset", "torch.utils.data.sampler.BatchSampler", "torch.utils.data.DataLoader", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build._train_loader_from_config": [[306, 342], ["build.get_detection_dataset_dicts", "detectron2.utils.logger._log_api_usage", "dataset_mapper.DatasetMapper", "logging.getLogger", "logging.getLogger.info", "samplers.TrainingSampler", "len", "samplers.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency", "samplers.RepeatFactorTrainingSampler", "ValueError"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.get_detection_dataset_dicts", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger._log_api_usage", "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_detection_train_loader": [[346, 390], ["detectron2.config.configurable", "isinstance", "isinstance", "build.build_batch_data_loader", "common.DatasetFromList", "common.MapDataset", "samplers.TrainingSampler", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.configurable", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_batch_data_loader"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build._test_loader_from_config": [[393, 410], ["build.get_detection_dataset_dicts", "dataset_mapper.DatasetMapper", "list().index", "list"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.get_detection_dataset_dicts", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_detection_test_loader": [[412, 461], ["detectron2.config.configurable", "isinstance", "torch.utils.data.sampler.BatchSampler", "torch.utils.data.DataLoader", "common.DatasetFromList", "common.MapDataset", "samplers.InferenceSampler", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.configurable"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.trivial_batch_collator": [[463, 468], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.worker_init_reset_seed": [[470, 473], ["detectron2.utils.env.seed_all_rng", "torch.initial_seed"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.env.seed_all_rng"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.__init__": [[37, 85], ["transforms.AugmentationList", "logging.getLogger", "logging.getLogger.info"], "methods", ["None"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "is_train", ":", "bool", ",", "\n", "*", ",", "\n", "augmentations", ":", "List", "[", "Union", "[", "T", ".", "Augmentation", ",", "T", ".", "Transform", "]", "]", ",", "\n", "image_format", ":", "str", ",", "\n", "use_instance_mask", ":", "bool", "=", "False", ",", "\n", "use_keypoint", ":", "bool", "=", "False", ",", "\n", "instance_mask_format", ":", "str", "=", "\"polygon\"", ",", "\n", "keypoint_hflip_indices", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "precomputed_proposal_topk", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "recompute_boxes", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            is_train: whether it's used in training or inference\n            augmentations: a list of augmentations or deterministic transforms to apply\n            image_format: an image format supported by :func:`detection_utils.read_image`.\n            use_instance_mask: whether to process instance segmentation annotations, if available\n            use_keypoint: whether to process keypoint annotations if available\n            instance_mask_format: one of \"polygon\" or \"bitmask\". Process instance segmentation\n                masks into this format.\n            keypoint_hflip_indices: see :func:`detection_utils.create_keypoint_hflip_indices`\n            precomputed_proposal_topk: if given, will load pre-computed\n                proposals from dataset_dict and keep the top k proposals for each image.\n            recompute_boxes: whether to overwrite bounding box annotations\n                by computing tight bounding boxes from instance mask annotations.\n        \"\"\"", "\n", "if", "recompute_boxes", ":", "\n", "            ", "assert", "use_instance_mask", ",", "\"recompute_boxes requires instance masks\"", "\n", "# fmt: off", "\n", "", "self", ".", "is_train", "=", "is_train", "\n", "# augmentations = [T.ResizeShortestEdge(short_edge_length=(1088,1088), max_size=1333, sample_style='choice')]", "\n", "self", ".", "augmentations", "=", "T", ".", "AugmentationList", "(", "augmentations", ")", "\n", "self", ".", "image_format", "=", "image_format", "\n", "self", ".", "use_instance_mask", "=", "use_instance_mask", "\n", "self", ".", "instance_mask_format", "=", "instance_mask_format", "\n", "self", ".", "use_keypoint", "=", "use_keypoint", "\n", "self", ".", "keypoint_hflip_indices", "=", "keypoint_hflip_indices", "\n", "self", ".", "proposal_topk", "=", "precomputed_proposal_topk", "\n", "self", ".", "recompute_boxes", "=", "recompute_boxes", "\n", "# fmt: on", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "mode", "=", "\"training\"", "if", "is_train", "else", "\"inference\"", "\n", "logger", ".", "info", "(", "f\"[DatasetMapper] Augmentations used in {mode}: {augmentations}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.from_config": [[86, 115], ["detection_utils.build_augmentation", "detection_utils.build_augmentation.insert", "detection_utils.create_keypoint_hflip_indices", "transforms.RandomCrop"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.build_augmentation", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.create_keypoint_hflip_indices"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "is_train", ":", "bool", "=", "True", ")", ":", "\n", "        ", "augs", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "augs", ".", "insert", "(", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", ")", "\n", "recompute_boxes", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "", "else", ":", "\n", "            ", "recompute_boxes", "=", "False", "\n", "\n", "", "ret", "=", "{", "\n", "\"is_train\"", ":", "is_train", ",", "\n", "\"augmentations\"", ":", "augs", ",", "\n", "\"image_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"use_instance_mask\"", ":", "cfg", ".", "MODEL", ".", "MASK_ON", ",", "\n", "\"instance_mask_format\"", ":", "cfg", ".", "INPUT", ".", "MASK_FORMAT", ",", "\n", "\"use_keypoint\"", ":", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\n", "\"recompute_boxes\"", ":", "recompute_boxes", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "ret", "[", "\"keypoint_hflip_indices\"", "]", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "cfg", ".", "DATASETS", ".", "TRAIN", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", ":", "\n", "            ", "ret", "[", "\"precomputed_proposal_topk\"", "]", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.dataset_mapper.DatasetMapper.__call__": [[116, 189], ["copy.deepcopy", "detection_utils.read_image", "detection_utils.check_image_size", "dataset_mapper.DatasetMapper.AugInput", "dataset_mapper.DatasetMapper.augmentations", "torch.as_tensor", "detection_utils.read_image().squeeze", "numpy.ascontiguousarray", "torch.as_tensor", "detection_utils.transform_proposals", "copy.deepcopy.pop", "copy.deepcopy.pop", "detection_utils.annotations_to_instances", "detection_utils.filter_empty_instances", "detection_utils.read_image.transpose", "detection_utils.read_image().squeeze.astype", "detection_utils.transform_instance_annotations", "detection_utils.annotations_to_instances.gt_masks.get_bounding_boxes", "detection_utils.read_image", "anno.pop", "anno.pop", "copy.deepcopy.pop", "copy.deepcopy.pop", "obj.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_image_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.annotations_to_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.filter_empty_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_instance_annotations", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.get_bounding_boxes", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n\n        Returns:\n            dict: a format that builtin models in detectron2 accept\n        \"\"\"", "\n", "dataset_dict", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "# it will be modified by code below", "\n", "# USER: Write your own image loading if it's not from a file", "\n", "image", "=", "utils", ".", "read_image", "(", "dataset_dict", "[", "\"file_name\"", "]", ",", "format", "=", "self", ".", "image_format", ")", "\n", "utils", ".", "check_image_size", "(", "dataset_dict", ",", "image", ")", "\n", "\n", "# USER: Remove if you don't do semantic/panoptic segmentation.", "\n", "if", "\"sem_seg_file_name\"", "in", "dataset_dict", ":", "\n", "            ", "sem_seg_gt", "=", "utils", ".", "read_image", "(", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ")", ",", "\"L\"", ")", ".", "squeeze", "(", "2", ")", "\n", "", "else", ":", "\n", "            ", "sem_seg_gt", "=", "None", "\n", "\n", "", "aug_input", "=", "T", ".", "AugInput", "(", "image", ",", "sem_seg", "=", "sem_seg_gt", ")", "\n", "transforms", "=", "self", ".", "augmentations", "(", "aug_input", ")", "\n", "image", ",", "sem_seg_gt", "=", "aug_input", ".", "image", ",", "aug_input", ".", "sem_seg", "\n", "\n", "image_shape", "=", "image", ".", "shape", "[", ":", "2", "]", "# h, w", "\n", "# Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,", "\n", "# but not efficient on large generic data structures due to the use of pickle & mp.Queue.", "\n", "# Therefore it's important to use torch.Tensor.", "\n", "dataset_dict", "[", "\"image\"", "]", "=", "torch", ".", "as_tensor", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "if", "sem_seg_gt", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "\"sem_seg\"", "]", "=", "torch", ".", "as_tensor", "(", "sem_seg_gt", ".", "astype", "(", "\"long\"", ")", ")", "\n", "\n", "# USER: Remove if you don't use pre-computed proposals.", "\n", "# Most users would not need this feature.", "\n", "", "if", "self", ".", "proposal_topk", "is", "not", "None", ":", "\n", "            ", "utils", ".", "transform_proposals", "(", "\n", "dataset_dict", ",", "image_shape", ",", "transforms", ",", "proposal_topk", "=", "self", ".", "proposal_topk", "\n", ")", "\n", "\n", "", "if", "not", "self", ".", "is_train", ":", "\n", "# USER: Modify this if you want to keep them for some reason.", "\n", "            ", "dataset_dict", ".", "pop", "(", "\"annotations\"", ",", "None", ")", "\n", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ",", "None", ")", "\n", "return", "dataset_dict", "\n", "\n", "", "if", "\"annotations\"", "in", "dataset_dict", ":", "\n", "# USER: Modify this if you want to keep them for some reason.", "\n", "            ", "for", "anno", "in", "dataset_dict", "[", "\"annotations\"", "]", ":", "\n", "                ", "if", "not", "self", ".", "use_instance_mask", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"segmentation\"", ",", "None", ")", "\n", "", "if", "not", "self", ".", "use_keypoint", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"keypoints\"", ",", "None", ")", "\n", "\n", "# USER: Implement additional transformations if you have other types of data", "\n", "", "", "annos", "=", "[", "\n", "utils", ".", "transform_instance_annotations", "(", "\n", "obj", ",", "transforms", ",", "image_shape", ",", "keypoint_hflip_indices", "=", "self", ".", "keypoint_hflip_indices", "\n", ")", "\n", "for", "obj", "in", "dataset_dict", ".", "pop", "(", "\"annotations\"", ")", "\n", "if", "obj", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "==", "0", "\n", "]", "\n", "instances", "=", "utils", ".", "annotations_to_instances", "(", "\n", "annos", ",", "image_shape", ",", "mask_format", "=", "self", ".", "instance_mask_format", "\n", ")", "\n", "\n", "# After transforms such as cropping are applied, the bounding box may no longer", "\n", "# tightly bound the object. As an example, imagine a triangle object", "\n", "# [(0,0), (2,0), (0,2)] cropped by a box [(1,0),(2,2)] (XYXY format). The tight", "\n", "# bounding box of the cropped triangle should be [(1,0),(2,1)], which is not equal to", "\n", "# the intersection of original bounding box and the cropping box.", "\n", "if", "self", ".", "recompute_boxes", ":", "\n", "                ", "instances", ".", "gt_boxes", "=", "instances", ".", "gt_masks", ".", "get_bounding_boxes", "(", ")", "\n", "", "dataset_dict", "[", "\"instances\"", "]", "=", "utils", ".", "filter_empty_instances", "(", "instances", ")", "\n", "", "return", "dataset_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes_panoptic.get_cityscapes_panoptic_files": [[18, 49], ["detectron2.utils.file_io.PathManager.ls", "logger.info", "len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "os.path.join", "detectron2.utils.file_io.PathManager.ls", "image_dict.get", "os.path.join", "files.append", "os.path.join", "basename.endswith", "len", "os.path.basename", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "get_cityscapes_panoptic_files", "(", "image_dir", ",", "gt_dir", ",", "json_info", ")", ":", "\n", "    ", "files", "=", "[", "]", "\n", "# scan through the directory", "\n", "cities", "=", "PathManager", ".", "ls", "(", "image_dir", ")", "\n", "logger", ".", "info", "(", "f\"{len(cities)} cities found in '{image_dir}'.\"", ")", "\n", "image_dict", "=", "{", "}", "\n", "for", "city", "in", "cities", ":", "\n", "        ", "city_img_dir", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "city", ")", "\n", "for", "basename", "in", "PathManager", ".", "ls", "(", "city_img_dir", ")", ":", "\n", "            ", "image_file", "=", "os", ".", "path", ".", "join", "(", "city_img_dir", ",", "basename", ")", "\n", "\n", "suffix", "=", "\"_leftImg8bit.png\"", "\n", "assert", "basename", ".", "endswith", "(", "suffix", ")", ",", "basename", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "basename", ")", "[", ":", "-", "len", "(", "suffix", ")", "]", "\n", "\n", "image_dict", "[", "basename", "]", "=", "image_file", "\n", "\n", "", "", "for", "ann", "in", "json_info", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_file", "=", "image_dict", ".", "get", "(", "ann", "[", "\"image_id\"", "]", ",", "None", ")", "\n", "assert", "image_file", "is", "not", "None", ",", "\"No image {} found for annotation {}\"", ".", "format", "(", "\n", "ann", "[", "\"image_id\"", "]", ",", "ann", "[", "\"file_name\"", "]", "\n", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "ann", "[", "\"file_name\"", "]", ")", "\n", "segments_info", "=", "ann", "[", "\"segments_info\"", "]", "\n", "\n", "files", ".", "append", "(", "(", "image_file", ",", "label_file", ",", "segments_info", ")", ")", "\n", "\n", "", "assert", "len", "(", "files", ")", ",", "\"No images found in {}\"", ".", "format", "(", "image_dir", ")", "\n", "assert", "PathManager", ".", "isfile", "(", "files", "[", "0", "]", "[", "0", "]", ")", ",", "files", "[", "0", "]", "[", "0", "]", "\n", "assert", "PathManager", ".", "isfile", "(", "files", "[", "0", "]", "[", "1", "]", ")", ",", "files", "[", "0", "]", "[", "1", "]", "\n", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes_panoptic.load_cityscapes_panoptic": [[51, 110], ["os.path.exists", "cityscapes_panoptic.get_cityscapes_panoptic_files", "len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "open", "json.load", "ret.append", "cityscapes_panoptic.load_cityscapes_panoptic._convert_category_id"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes_panoptic.get_cityscapes_panoptic_files", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["", "def", "load_cityscapes_panoptic", "(", "image_dir", ",", "gt_dir", ",", "gt_json", ",", "meta", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n        gt_dir (str): path to the raw annotations. e.g.,\n            \"~/cityscapes/gtFine/cityscapes_panoptic_train\".\n        gt_json (str): path to the json file. e.g.,\n            \"~/cityscapes/gtFine/cityscapes_panoptic_train.json\".\n        meta (dict): dictionary containing \"thing_dataset_id_to_contiguous_id\"\n            and \"stuff_dataset_id_to_contiguous_id\" to map category ids to\n            contiguous ids for training.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n    \"\"\"", "\n", "\n", "def", "_convert_category_id", "(", "segment_info", ",", "meta", ")", ":", "\n", "        ", "if", "segment_info", "[", "\"category_id\"", "]", "in", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "return", "segment_info", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "\n", "gt_json", "\n", ")", ",", "\"Please run `python cityscapesscripts/preparation/createPanopticImgs.py` to generate label files.\"", "# noqa", "\n", "with", "open", "(", "gt_json", ")", "as", "f", ":", "\n", "        ", "json_info", "=", "json", ".", "load", "(", "f", ")", "\n", "", "files", "=", "get_cityscapes_panoptic_files", "(", "image_dir", ",", "gt_dir", ",", "json_info", ")", "\n", "ret", "=", "[", "]", "\n", "for", "image_file", ",", "label_file", ",", "segments_info", "in", "files", ":", "\n", "        ", "sem_label_file", "=", "(", "\n", "image_file", ".", "replace", "(", "\"leftImg8bit\"", ",", "\"gtFine\"", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "+", "\"_labelTrainIds.png\"", "\n", ")", "\n", "segments_info", "=", "[", "_convert_category_id", "(", "x", ",", "meta", ")", "for", "x", "in", "segments_info", "]", "\n", "ret", ".", "append", "(", "\n", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "\"_\"", ".", "join", "(", "\n", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "image_file", ")", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", ":", "3", "]", "\n", ")", ",", "\n", "\"sem_seg_file_name\"", ":", "sem_label_file", ",", "\n", "\"pan_seg_file_name\"", ":", "label_file", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n", ")", "\n", "", "assert", "len", "(", "ret", ")", ",", "f\"No images found in {image_dir}!\"", "\n", "assert", "PathManager", ".", "isfile", "(", "\n", "ret", "[", "0", "]", "[", "\"sem_seg_file_name\"", "]", "\n", ")", ",", "\"Please generate labelTrainIds.png with cityscapesscripts/preparation/createTrainIdLabelImgs.py\"", "# noqa", "\n", "assert", "PathManager", ".", "isfile", "(", "\n", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", "\n", ")", ",", "\"Please generate panoptic annotation with python cityscapesscripts/preparation/createPanopticImgs.py\"", "# noqa", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes_panoptic.register_all_cityscapes_panoptic": [[127, 187], ["_RAW_CITYSCAPES_PANOPTIC_SPLITS.items", "os.path.join", "os.path.join", "os.path.join", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "cityscapes_panoptic.load_cityscapes_panoptic", "detectron2.data.MetadataCatalog.get", "os.path.join.replace"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes_panoptic.load_cityscapes_panoptic", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "register_all_cityscapes_panoptic", "(", "root", ")", ":", "\n", "    ", "meta", "=", "{", "}", "\n", "# The following metadata maps contiguous id from [0, #thing categories +", "\n", "# #stuff categories) to their names and colors. We have to replica of the", "\n", "# same name and color under \"thing_*\" and \"stuff_*\" because the current", "\n", "# visualization function in D2 handles thing and class classes differently", "\n", "# due to some heuristic used in Panoptic FPN. We keep the same naming to", "\n", "# enable reusing existing visualization functions.", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "stuff_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "stuff_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "\n", "meta", "[", "\"thing_classes\"", "]", "=", "thing_classes", "\n", "meta", "[", "\"thing_colors\"", "]", "=", "thing_colors", "\n", "meta", "[", "\"stuff_classes\"", "]", "=", "stuff_classes", "\n", "meta", "[", "\"stuff_colors\"", "]", "=", "stuff_colors", "\n", "\n", "# There are three types of ids in cityscapes panoptic segmentation:", "\n", "# (1) category id: like semantic segmentation, it is the class id for each", "\n", "#   pixel. Since there are some classes not used in evaluation, the category", "\n", "#   id is not always contiguous and thus we have two set of category ids:", "\n", "#       - original category id: category id in the original dataset, mainly", "\n", "#           used for evaluation.", "\n", "#       - contiguous category id: [0, #classes), in order to train the classifier", "\n", "# (2) instance id: this id is used to differentiate different instances from", "\n", "#   the same category. For \"stuff\" classes, the instance id is always 0; for", "\n", "#   \"thing\" classes, the instance id starts from 1 and 0 is reserved for", "\n", "#   ignored instances (e.g. crowd annotation).", "\n", "# (3) panoptic id: this is the compact id that encode both category and", "\n", "#   instance id by: category_id * 1000 + instance_id.", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "\n", "for", "k", "in", "CITYSCAPES_CATEGORIES", ":", "\n", "        ", "if", "k", "[", "\"isthing\"", "]", "==", "1", ":", "\n", "            ", "thing_dataset_id_to_contiguous_id", "[", "k", "[", "\"id\"", "]", "]", "=", "k", "[", "\"trainId\"", "]", "\n", "", "else", ":", "\n", "            ", "stuff_dataset_id_to_contiguous_id", "[", "k", "[", "\"id\"", "]", "]", "=", "k", "[", "\"trainId\"", "]", "\n", "\n", "", "", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "=", "thing_dataset_id_to_contiguous_id", "\n", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "=", "stuff_dataset_id_to_contiguous_id", "\n", "\n", "for", "key", ",", "(", "image_dir", ",", "gt_dir", ",", "gt_json", ")", "in", "_RAW_CITYSCAPES_PANOPTIC_SPLITS", ".", "items", "(", ")", ":", "\n", "        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "image_dir", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_dir", ")", "\n", "gt_json", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_json", ")", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "key", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ",", "z", "=", "gt_json", ":", "load_cityscapes_panoptic", "(", "x", ",", "y", ",", "z", ",", "meta", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "key", ")", ".", "set", "(", "\n", "panoptic_root", "=", "gt_dir", ",", "\n", "image_root", "=", "image_dir", ",", "\n", "panoptic_json", "=", "gt_json", ",", "\n", "gt_dir", "=", "gt_dir", ".", "replace", "(", "\"cityscapes_panoptic_\"", ",", "\"\"", ")", ",", "\n", "evaluator_type", "=", "\"cityscapes_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "label_divisor", "=", "1000", ",", "\n", "**", "meta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_coco_json": [[30, 223], ["fvcore.common.timer.Timer", "detectron2.utils.file_io.PathManager.get_local_path", "sorted", "COCO.loadImgs", "sum", "len", "list", "logger.info", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logger.info", "MetadataCatalog.get", "sorted", "COCO.loadCats", "COCO.imgs.keys", "logger.warning", "zip", "os.path.join", "dataset_dicts.append", "logger.warning", "io.StringIO", "COCO.getCatIds", "len", "len", "len", "len", "anno.get", "anno.get", "objs.append", "fvcore.common.timer.Timer.seconds", "sorted", "logger.warning", "enumerate", "set", "anno.get", "isinstance", "enumerate", "min", "max", "len", "isinstance", "pycocotools.frPyObjects", "len", "KeyError", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["def", "load_coco_json", "(", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ",", "extra_annotation_keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load a json file with COCO's instances annotation format.\n    Currently supports instance detection, instance segmentation,\n    and person keypoints annotations.\n\n    Args:\n        json_file (str): full path to the json file in COCO instances annotation format.\n        image_root (str or path-like): the directory where the images in this json file exists.\n        dataset_name (str or None): the name of the dataset (e.g., coco_2017_train).\n            When provided, this function will also do the following:\n\n            * Put \"thing_classes\" into the metadata associated with this dataset.\n            * Map the category ids into a contiguous range (needed by standard dataset format),\n              and add \"thing_dataset_id_to_contiguous_id\" to the metadata associated\n              with this dataset.\n\n            This option should usually be provided, unless users need to load\n            the original json content and apply more processing manually.\n        extra_annotation_keys (list[str]): list of per-annotation keys that should also be\n            loaded into the dataset dict (besides \"iscrowd\", \"bbox\", \"keypoints\",\n            \"category_id\", \"segmentation\"). The values for these keys will be returned as-is.\n            For example, the densepose annotations are loaded in this way.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard dataset dicts format (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ ) when `dataset_name` is not None.\n        If `dataset_name` is None, the returned `category_ids` may be\n        incontiguous and may not conform to the Detectron2 standard format.\n\n    Notes:\n        1. This function does not read the image files.\n           The results do not have the \"image\" field.\n    \"\"\"", "\n", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "        ", "coco_api", "=", "COCO", "(", "json_file", ")", "\n", "", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "", "id_map", "=", "None", "\n", "if", "dataset_name", "is", "not", "None", ":", "\n", "        ", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "cat_ids", "=", "sorted", "(", "coco_api", ".", "getCatIds", "(", ")", ")", "\n", "cats", "=", "coco_api", ".", "loadCats", "(", "cat_ids", ")", "\n", "# The categories in a custom json file may not be sorted.", "\n", "thing_classes", "=", "[", "c", "[", "\"name\"", "]", "for", "c", "in", "sorted", "(", "cats", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "]", "\n", "meta", ".", "thing_classes", "=", "thing_classes", "\n", "\n", "# In COCO, certain category ids are artificially removed,", "\n", "# and by convention they are always ignored.", "\n", "# We deal with COCO's id issue and translate", "\n", "# the category ids to contiguous ids in [0, 80).", "\n", "\n", "# It works by looking at the \"categories\" field in the json, therefore", "\n", "# if users' own json also have incontiguous ids, we'll", "\n", "# apply this mapping as well but print a warning.", "\n", "if", "not", "(", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "cat_ids", ")", ")", ":", "\n", "            ", "if", "\"coco\"", "not", "in", "dataset_name", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"\"\"\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\"\"\"", "\n", ")", "\n", "", "", "id_map", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "cat_ids", ")", "}", "\n", "meta", ".", "thing_dataset_id_to_contiguous_id", "=", "id_map", "\n", "\n", "# sort indices for reproducible results", "\n", "", "img_ids", "=", "sorted", "(", "coco_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "# imgs is a list of dicts, each looks something like:", "\n", "# {'license': 4,", "\n", "#  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',", "\n", "#  'file_name': 'COCO_val2014_000000001268.jpg',", "\n", "#  'height': 427,", "\n", "#  'width': 640,", "\n", "#  'date_captured': '2013-11-17 05:57:24',", "\n", "#  'id': 1268}", "\n", "imgs", "=", "coco_api", ".", "loadImgs", "(", "img_ids", ")", "\n", "# anns is a list[list[dict]], where each dict is an annotation", "\n", "# record for an object. The inner list enumerates the objects in an image", "\n", "# and the outer list enumerates over images. Example of anns[0]:", "\n", "# [{'segmentation': [[192.81,", "\n", "#     247.09,", "\n", "#     ...", "\n", "#     219.03,", "\n", "#     249.06]],", "\n", "#   'area': 1035.749,", "\n", "#   'iscrowd': 0,", "\n", "#   'image_id': 1268,", "\n", "#   'bbox': [192.81, 224.8, 74.73, 33.43],", "\n", "#   'category_id': 16,", "\n", "#   'id': 42986},", "\n", "#  ...]", "\n", "anns", "=", "[", "coco_api", ".", "imgToAnns", "[", "img_id", "]", "for", "img_id", "in", "img_ids", "]", "\n", "total_num_valid_anns", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "anns", "]", ")", "\n", "total_num_anns", "=", "len", "(", "coco_api", ".", "anns", ")", "\n", "if", "total_num_valid_anns", "<", "total_num_anns", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"{json_file} contains {total_num_anns} annotations, but only \"", "\n", "f\"{total_num_valid_anns} of them match to images in the file.\"", "\n", ")", "\n", "\n", "", "if", "\"minival\"", "not", "in", "json_file", ":", "\n", "# The popular valminusminival & minival annotations for COCO2014 contain this bug.", "\n", "# However the ratio of buggy annotations there is tiny and does not affect accuracy.", "\n", "# Therefore we explicitly white-list them.", "\n", "        ", "ann_ids", "=", "[", "ann", "[", "\"id\"", "]", "for", "anns_per_image", "in", "anns", "for", "ann", "in", "anns_per_image", "]", "\n", "assert", "len", "(", "set", "(", "ann_ids", ")", ")", "==", "len", "(", "ann_ids", ")", ",", "\"Annotation ids in '{}' are not unique!\"", ".", "format", "(", "\n", "json_file", "\n", ")", "\n", "\n", "", "imgs_anns", "=", "list", "(", "zip", "(", "imgs", ",", "anns", ")", ")", "\n", "logger", ".", "info", "(", "\"Loaded {} images in COCO format from {}\"", ".", "format", "(", "len", "(", "imgs_anns", ")", ",", "json_file", ")", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "\n", "ann_keys", "=", "[", "\"iscrowd\"", ",", "\"bbox\"", ",", "\"keypoints\"", ",", "\"category_id\"", "]", "+", "(", "extra_annotation_keys", "or", "[", "]", ")", "\n", "\n", "num_instances_without_valid_segmentation", "=", "0", "\n", "\n", "for", "(", "img_dict", ",", "anno_dict_list", ")", "in", "imgs_anns", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "os", ".", "path", ".", "join", "(", "image_root", ",", "img_dict", "[", "\"file_name\"", "]", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "anno_dict_list", ":", "\n", "# Check that the image_id in this annotation is the same as", "\n", "# the image_id we're looking at.", "\n", "# This fails only when the data parsing logic or the annotation file is buggy.", "\n", "\n", "# The original COCO valminusminival2014 & minival2014 annotation files", "\n", "# actually contains bugs that, together with certain ways of using COCO API,", "\n", "# can trigger this assertion.", "\n", "            ", "assert", "anno", "[", "\"image_id\"", "]", "==", "image_id", "\n", "\n", "assert", "anno", ".", "get", "(", "\"ignore\"", ",", "0", ")", "==", "0", ",", "'\"ignore\" in COCO json file is not supported.'", "\n", "\n", "obj", "=", "{", "key", ":", "anno", "[", "key", "]", "for", "key", "in", "ann_keys", "if", "key", "in", "anno", "}", "\n", "\n", "segm", "=", "anno", ".", "get", "(", "\"segmentation\"", ",", "None", ")", "\n", "if", "segm", ":", "# either list[list[float]] or dict(RLE)", "\n", "                ", "if", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "                    ", "if", "isinstance", "(", "segm", "[", "\"counts\"", "]", ",", "list", ")", ":", "\n", "# convert to compressed RLE", "\n", "                        ", "segm", "=", "mask_util", ".", "frPyObjects", "(", "segm", ",", "*", "segm", "[", "\"size\"", "]", ")", "\n", "", "", "else", ":", "\n", "# filter out invalid polygons (< 3 points)", "\n", "                    ", "segm", "=", "[", "poly", "for", "poly", "in", "segm", "if", "len", "(", "poly", ")", "%", "2", "==", "0", "and", "len", "(", "poly", ")", ">=", "6", "]", "\n", "if", "len", "(", "segm", ")", "==", "0", ":", "\n", "                        ", "num_instances_without_valid_segmentation", "+=", "1", "\n", "continue", "# ignore this instance", "\n", "", "", "obj", "[", "\"segmentation\"", "]", "=", "segm", "\n", "\n", "", "keypts", "=", "anno", ".", "get", "(", "\"keypoints\"", ",", "None", ")", "\n", "if", "keypts", ":", "# list[int]", "\n", "                ", "for", "idx", ",", "v", "in", "enumerate", "(", "keypts", ")", ":", "\n", "                    ", "if", "idx", "%", "3", "!=", "2", ":", "\n", "# COCO's segmentation coordinates are floating points in [0, H or W],", "\n", "# but keypoint coordinates are integers in [0, H-1 or W-1]", "\n", "# Therefore we assume the coordinates are \"pixel indices\" and", "\n", "# add 0.5 to convert to floating point coordinates.", "\n", "                        ", "keypts", "[", "idx", "]", "=", "v", "+", "0.5", "\n", "", "", "obj", "[", "\"keypoints\"", "]", "=", "keypts", "\n", "\n", "", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYWH_ABS", "\n", "if", "id_map", ":", "\n", "                ", "annotation_category_id", "=", "obj", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                    ", "obj", "[", "\"category_id\"", "]", "=", "id_map", "[", "annotation_category_id", "]", "\n", "", "except", "KeyError", "as", "e", ":", "\n", "                    ", "raise", "KeyError", "(", "\n", "f\"Encountered category_id={annotation_category_id} \"", "\n", "\"but this id does not exist in 'categories' of the json file.\"", "\n", ")", "from", "e", "\n", "", "", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "if", "num_instances_without_valid_segmentation", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Filtered out {} instances without valid segmentation. \"", ".", "format", "(", "\n", "num_instances_without_valid_segmentation", "\n", ")", "\n", "+", "\"There might be issues in your dataset generation process. \"", "\n", "\"A valid polygon should be a list[float] with even length >= 6.\"", "\n", ")", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_sem_seg": [[225, 299], ["sorted", "sorted", "logger.info", "zip", "os.path.normpath", "len", "len", "len", "logger.warn", "list", "sorted", "logger.warn", "dataset_dicts.append", "os.path.relpath", "os.path.splitext", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "detectron2.utils.file_io.PathManager.ls", "f.endswith", "coco.load_sem_seg.file2id"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "load_sem_seg", "(", "gt_root", ",", "image_root", ",", "gt_ext", "=", "\"png\"", ",", "image_ext", "=", "\"jpg\"", ")", ":", "\n", "    ", "\"\"\"\n    Load semantic segmentation datasets. All files under \"gt_root\" with \"gt_ext\" extension are\n    treated as ground truth annotations and all files under \"image_root\" with \"image_ext\" extension\n    as input images. Ground truth and input images are matched using file paths relative to\n    \"gt_root\" and \"image_root\" respectively without taking into account file extensions.\n    This works for COCO as well as some other datasets.\n\n    Args:\n        gt_root (str): full path to ground truth semantic segmentation files. Semantic segmentation\n            annotations are stored as images with integer values in pixels that represent\n            corresponding semantic labels.\n        image_root (str): the directory where the input images are.\n        gt_ext (str): file extension for ground truth annotations.\n        image_ext (str): file extension for input images.\n\n    Returns:\n        list[dict]:\n            a list of dicts in detectron2 standard format without instance-level\n            annotation.\n\n    Notes:\n        1. This function does not read the image and ground truth files.\n           The results do not have the \"image\" and \"sem_seg\" fields.\n    \"\"\"", "\n", "\n", "# We match input images with ground truth based on their relative filepaths (without file", "\n", "# extensions) starting from 'image_root' and 'gt_root' respectively.", "\n", "def", "file2id", "(", "folder_path", ",", "file_path", ")", ":", "\n", "# extract relative path starting from `folder_path`", "\n", "        ", "image_id", "=", "os", ".", "path", ".", "normpath", "(", "os", ".", "path", ".", "relpath", "(", "file_path", ",", "start", "=", "folder_path", ")", ")", "\n", "# remove file extension", "\n", "image_id", "=", "os", ".", "path", ".", "splitext", "(", "image_id", ")", "[", "0", "]", "\n", "return", "image_id", "\n", "\n", "", "input_files", "=", "sorted", "(", "\n", "(", "os", ".", "path", ".", "join", "(", "image_root", ",", "f", ")", "for", "f", "in", "PathManager", ".", "ls", "(", "image_root", ")", "if", "f", ".", "endswith", "(", "image_ext", ")", ")", ",", "\n", "key", "=", "lambda", "file_path", ":", "file2id", "(", "image_root", ",", "file_path", ")", ",", "\n", ")", "\n", "gt_files", "=", "sorted", "(", "\n", "(", "os", ".", "path", ".", "join", "(", "gt_root", ",", "f", ")", "for", "f", "in", "PathManager", ".", "ls", "(", "gt_root", ")", "if", "f", ".", "endswith", "(", "gt_ext", ")", ")", ",", "\n", "key", "=", "lambda", "file_path", ":", "file2id", "(", "gt_root", ",", "file_path", ")", ",", "\n", ")", "\n", "\n", "assert", "len", "(", "gt_files", ")", ">", "0", ",", "\"No annotations found in {}.\"", ".", "format", "(", "gt_root", ")", "\n", "\n", "# Use the intersection, so that val2017_100 annotations can run smoothly with val2017 images", "\n", "if", "len", "(", "input_files", ")", "!=", "len", "(", "gt_files", ")", ":", "\n", "        ", "logger", ".", "warn", "(", "\n", "\"Directory {} and {} has {} and {} files, respectively.\"", ".", "format", "(", "\n", "image_root", ",", "gt_root", ",", "len", "(", "input_files", ")", ",", "len", "(", "gt_files", ")", "\n", ")", "\n", ")", "\n", "input_basenames", "=", "[", "os", ".", "path", ".", "basename", "(", "f", ")", "[", ":", "-", "len", "(", "image_ext", ")", "]", "for", "f", "in", "input_files", "]", "\n", "gt_basenames", "=", "[", "os", ".", "path", ".", "basename", "(", "f", ")", "[", ":", "-", "len", "(", "gt_ext", ")", "]", "for", "f", "in", "gt_files", "]", "\n", "intersect", "=", "list", "(", "set", "(", "input_basenames", ")", "&", "set", "(", "gt_basenames", ")", ")", "\n", "# sort, otherwise each worker may obtain a list[dict] in different order", "\n", "intersect", "=", "sorted", "(", "intersect", ")", "\n", "logger", ".", "warn", "(", "\"Will use their intersection of {} files.\"", ".", "format", "(", "len", "(", "intersect", ")", ")", ")", "\n", "input_files", "=", "[", "os", ".", "path", ".", "join", "(", "image_root", ",", "f", "+", "image_ext", ")", "for", "f", "in", "intersect", "]", "\n", "gt_files", "=", "[", "os", ".", "path", ".", "join", "(", "gt_root", ",", "f", "+", "gt_ext", ")", "for", "f", "in", "intersect", "]", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"Loaded {} images with semantic segmentation from {}\"", ".", "format", "(", "len", "(", "input_files", ")", ",", "image_root", ")", "\n", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "for", "(", "img_path", ",", "gt_path", ")", "in", "zip", "(", "input_files", ",", "gt_files", ")", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "img_path", "\n", "record", "[", "\"sem_seg_file_name\"", "]", "=", "gt_path", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.convert_to_coco_dict": [[301, 438], ["DatasetCatalog.get", "MetadataCatalog.get", "hasattr", "logger.info", "enumerate", "logger.info", "coco_images.append", "image_dict.get", "str", "len", "reverse_id_mapper", "enumerate", "image_dict.get", "int", "int", "str", "isinstance", "detectron2.structures.BoxMode.convert", "float", "int", "int", "coco_annotations.append", "datetime.datetime.now", "MetadataCatalog.get.thing_dataset_id_to_contiguous_id.items", "bbox.tolist.tolist", "len", "ValueError", "isinstance", "enumerate", "len", "round", "annotation.get", "reverse_id_mapper", "isinstance", "len", "len", "ValueError", "len", "detectron2.structures.PolygonMasks", "[].item", "isinstance", "detectron2.structures.BoxMode.convert", "[].item", "[].item", "sum", "float", "pycocotools.area().item", "TypeError", "isinstance", "counts.decode", "detectron2.structures.PolygonMasks.area", "pycocotools.area", "detectron2.structures.Boxes().area", "detectron2.structures.RotatedBoxes().area", "type", "detectron2.structures.Boxes", "detectron2.structures.RotatedBoxes"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area"], ["", "def", "convert_to_coco_dict", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n    Convert an instance detection/segmentation or keypoint detection dataset\n    in detectron2's standard format into COCO json format.\n\n    Generic dataset description can be found here:\n    https://detectron2.readthedocs.io/tutorials/datasets.html#register-a-dataset\n\n    COCO data format description can be found here:\n    http://cocodataset.org/#format-data\n\n    Args:\n        dataset_name (str):\n            name of the source dataset\n            Must be registered in DatastCatalog and in detectron2's standard format.\n            Must have corresponding metadata \"thing_classes\"\n    Returns:\n        coco_dict: serializable dict in COCO json format\n    \"\"\"", "\n", "\n", "dataset_dicts", "=", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", "\n", "metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "\n", "# unmap the category mapping ids for COCO", "\n", "if", "hasattr", "(", "metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "        ", "reverse_id_mapping", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "}", "\n", "reverse_id_mapper", "=", "lambda", "contiguous_id", ":", "reverse_id_mapping", "[", "contiguous_id", "]", "# noqa", "\n", "", "else", ":", "\n", "        ", "reverse_id_mapper", "=", "lambda", "contiguous_id", ":", "contiguous_id", "# noqa", "\n", "\n", "", "categories", "=", "[", "\n", "{", "\"id\"", ":", "reverse_id_mapper", "(", "id", ")", ",", "\"name\"", ":", "name", "}", "\n", "for", "id", ",", "name", "in", "enumerate", "(", "metadata", ".", "thing_classes", ")", "\n", "]", "\n", "\n", "logger", ".", "info", "(", "\"Converting dataset dicts into COCO format\"", ")", "\n", "coco_images", "=", "[", "]", "\n", "coco_annotations", "=", "[", "]", "\n", "\n", "for", "image_id", ",", "image_dict", "in", "enumerate", "(", "dataset_dicts", ")", ":", "\n", "        ", "coco_image", "=", "{", "\n", "\"id\"", ":", "image_dict", ".", "get", "(", "\"image_id\"", ",", "image_id", ")", ",", "\n", "\"width\"", ":", "int", "(", "image_dict", "[", "\"width\"", "]", ")", ",", "\n", "\"height\"", ":", "int", "(", "image_dict", "[", "\"height\"", "]", ")", ",", "\n", "\"file_name\"", ":", "str", "(", "image_dict", "[", "\"file_name\"", "]", ")", ",", "\n", "}", "\n", "coco_images", ".", "append", "(", "coco_image", ")", "\n", "\n", "anns_per_image", "=", "image_dict", ".", "get", "(", "\"annotations\"", ",", "[", "]", ")", "\n", "for", "annotation", "in", "anns_per_image", ":", "\n", "# create a new dict with only COCO fields", "\n", "            ", "coco_annotation", "=", "{", "}", "\n", "\n", "# COCO requirement: XYWH box format for axis-align and XYWHA for rotated", "\n", "bbox", "=", "annotation", "[", "\"bbox\"", "]", "\n", "if", "isinstance", "(", "bbox", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "if", "bbox", ".", "ndim", "!=", "1", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"bbox has to be 1-dimensional. Got shape={bbox.shape}.\"", ")", "\n", "", "bbox", "=", "bbox", ".", "tolist", "(", ")", "\n", "", "if", "len", "(", "bbox", ")", "not", "in", "[", "4", ",", "5", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"bbox has to has length 4 or 5. Got {bbox}.\"", ")", "\n", "", "from_bbox_mode", "=", "annotation", "[", "\"bbox_mode\"", "]", "\n", "to_bbox_mode", "=", "BoxMode", ".", "XYWH_ABS", "if", "len", "(", "bbox", ")", "==", "4", "else", "BoxMode", ".", "XYWHA_ABS", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "from_bbox_mode", ",", "to_bbox_mode", ")", "\n", "\n", "# COCO requirement: instance area", "\n", "if", "\"segmentation\"", "in", "annotation", ":", "\n", "# Computing areas for instances by counting the pixels", "\n", "                ", "segmentation", "=", "annotation", "[", "\"segmentation\"", "]", "\n", "# TODO: check segmentation type: RLE, BinaryMask or Polygon", "\n", "if", "isinstance", "(", "segmentation", ",", "list", ")", ":", "\n", "                    ", "polygons", "=", "PolygonMasks", "(", "[", "segmentation", "]", ")", "\n", "area", "=", "polygons", ".", "area", "(", ")", "[", "0", "]", ".", "item", "(", ")", "\n", "", "elif", "isinstance", "(", "segmentation", ",", "dict", ")", ":", "# RLE", "\n", "                    ", "area", "=", "mask_util", ".", "area", "(", "segmentation", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "TypeError", "(", "f\"Unknown segmentation type {type(segmentation)}!\"", ")", "\n", "", "", "else", ":", "\n", "# Computing areas using bounding boxes", "\n", "                ", "if", "to_bbox_mode", "==", "BoxMode", ".", "XYWH_ABS", ":", "\n", "                    ", "bbox_xy", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "to_bbox_mode", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "area", "=", "Boxes", "(", "[", "bbox_xy", "]", ")", ".", "area", "(", ")", "[", "0", "]", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                    ", "area", "=", "RotatedBoxes", "(", "[", "bbox", "]", ")", ".", "area", "(", ")", "[", "0", "]", ".", "item", "(", ")", "\n", "\n", "", "", "if", "\"keypoints\"", "in", "annotation", ":", "\n", "                ", "keypoints", "=", "annotation", "[", "\"keypoints\"", "]", "# list[int]", "\n", "for", "idx", ",", "v", "in", "enumerate", "(", "keypoints", ")", ":", "\n", "                    ", "if", "idx", "%", "3", "!=", "2", ":", "\n", "# COCO's segmentation coordinates are floating points in [0, H or W],", "\n", "# but keypoint coordinates are integers in [0, H-1 or W-1]", "\n", "# For COCO format consistency we substract 0.5", "\n", "# https://github.com/facebookresearch/detectron2/pull/175#issuecomment-551202163", "\n", "                        ", "keypoints", "[", "idx", "]", "=", "v", "-", "0.5", "\n", "", "", "if", "\"num_keypoints\"", "in", "annotation", ":", "\n", "                    ", "num_keypoints", "=", "annotation", "[", "\"num_keypoints\"", "]", "\n", "", "else", ":", "\n", "                    ", "num_keypoints", "=", "sum", "(", "kp", ">", "0", "for", "kp", "in", "keypoints", "[", "2", ":", ":", "3", "]", ")", "\n", "\n", "# COCO requirement:", "\n", "#   linking annotations to images", "\n", "#   \"id\" field must start with 1", "\n", "", "", "coco_annotation", "[", "\"id\"", "]", "=", "len", "(", "coco_annotations", ")", "+", "1", "\n", "coco_annotation", "[", "\"image_id\"", "]", "=", "coco_image", "[", "\"id\"", "]", "\n", "coco_annotation", "[", "\"bbox\"", "]", "=", "[", "round", "(", "float", "(", "x", ")", ",", "3", ")", "for", "x", "in", "bbox", "]", "\n", "coco_annotation", "[", "\"area\"", "]", "=", "float", "(", "area", ")", "\n", "coco_annotation", "[", "\"iscrowd\"", "]", "=", "int", "(", "annotation", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", "\n", "coco_annotation", "[", "\"category_id\"", "]", "=", "int", "(", "reverse_id_mapper", "(", "annotation", "[", "\"category_id\"", "]", ")", ")", "\n", "\n", "# Add optional fields", "\n", "if", "\"keypoints\"", "in", "annotation", ":", "\n", "                ", "coco_annotation", "[", "\"keypoints\"", "]", "=", "keypoints", "\n", "coco_annotation", "[", "\"num_keypoints\"", "]", "=", "num_keypoints", "\n", "\n", "", "if", "\"segmentation\"", "in", "annotation", ":", "\n", "                ", "seg", "=", "coco_annotation", "[", "\"segmentation\"", "]", "=", "annotation", "[", "\"segmentation\"", "]", "\n", "if", "isinstance", "(", "seg", ",", "dict", ")", ":", "# RLE", "\n", "                    ", "counts", "=", "seg", "[", "\"counts\"", "]", "\n", "if", "not", "isinstance", "(", "counts", ",", "str", ")", ":", "\n", "# make it json-serializable", "\n", "                        ", "seg", "[", "\"counts\"", "]", "=", "counts", ".", "decode", "(", "\"ascii\"", ")", "\n", "\n", "", "", "", "coco_annotations", ".", "append", "(", "coco_annotation", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\n", "\"Conversion finished, \"", "\n", "f\"#images: {len(coco_images)}, #annotations: {len(coco_annotations)}\"", "\n", ")", "\n", "\n", "info", "=", "{", "\n", "\"date_created\"", ":", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ",", "\n", "\"description\"", ":", "\"Automatically generated COCO json file for Detectron2.\"", ",", "\n", "}", "\n", "coco_dict", "=", "{", "\"info\"", ":", "info", ",", "\"images\"", ":", "coco_images", ",", "\"categories\"", ":", "categories", ",", "\"licenses\"", ":", "None", "}", "\n", "if", "len", "(", "coco_annotations", ")", ">", "0", ":", "\n", "        ", "coco_dict", "[", "\"annotations\"", "]", "=", "coco_annotations", "\n", "", "return", "coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.convert_to_coco_json": [[440, 472], ["detectron2.utils.file_io.PathManager.mkdirs", "os.path.dirname", "iopath.common.file_io.file_lock", "detectron2.utils.file_io.PathManager.exists", "logger.warning", "logger.info", "coco.convert_to_coco_dict", "logger.info", "shutil.move", "detectron2.utils.file_io.PathManager.open", "json.dump"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.convert_to_coco_dict", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump"], ["", "def", "convert_to_coco_json", "(", "dataset_name", ",", "output_file", ",", "allow_cached", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Converts dataset into COCO format and saves it to a json file.\n    dataset_name must be registered in DatasetCatalog and in detectron2's standard format.\n\n    Args:\n        dataset_name:\n            reference from the config file to the catalogs\n            must be registered in DatasetCatalog and in detectron2's standard format\n        output_file: path of json file that will be saved to\n        allow_cached: if json file is already present then skip conversion\n    \"\"\"", "\n", "\n", "# TODO: The dataset or the conversion script *may* change,", "\n", "# a checksum would be useful for validating the cached data", "\n", "\n", "PathManager", ".", "mkdirs", "(", "os", ".", "path", ".", "dirname", "(", "output_file", ")", ")", "\n", "with", "file_lock", "(", "output_file", ")", ":", "\n", "        ", "if", "PathManager", ".", "exists", "(", "output_file", ")", "and", "allow_cached", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"Using previously cached COCO format annotations at '{output_file}'. \"", "\n", "\"You need to clear the cache file if your dataset has been modified.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Converting annotations of dataset '{dataset_name}' to COCO format ...)\"", ")", "\n", "coco_dict", "=", "convert_to_coco_dict", "(", "dataset_name", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Caching COCO format annotations at '{output_file}' ...\"", ")", "\n", "tmp_file", "=", "output_file", "+", "\".tmp\"", "\n", "with", "PathManager", ".", "open", "(", "tmp_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "coco_dict", ",", "f", ")", "\n", "", "shutil", ".", "move", "(", "tmp_file", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.register_coco_instances": [[474, 501], ["isinstance", "isinstance", "isinstance", "DatasetCatalog.register", "MetadataCatalog.get().set", "coco.load_coco_json", "MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_coco_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "", "def", "register_coco_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "json_file", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "json_file", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "# 1. register a function which returns dicts", "\n", "DatasetCatalog", ".", "register", "(", "name", ",", "lambda", ":", "load_coco_json", "(", "json_file", ",", "image_root", ",", "name", ")", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"coco\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.load_coco_panoptic_json": [[14, 64], ["len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.open", "json.load", "int", "os.path.join", "os.path.join", "ret.append", "coco_panoptic.load_coco_panoptic_json._convert_category_id"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["def", "load_coco_panoptic_json", "(", "json_file", ",", "image_dir", ",", "gt_dir", ",", "meta", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/coco/train2017\".\n        gt_dir (str): path to the raw annotations. e.g., \"~/coco/panoptic_train2017\".\n        json_file (str): path to the json file. e.g., \"~/coco/annotations/panoptic_train2017.json\".\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n    \"\"\"", "\n", "\n", "def", "_convert_category_id", "(", "segment_info", ",", "meta", ")", ":", "\n", "        ", "if", "segment_info", "[", "\"category_id\"", "]", "in", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "segment_info", "[", "\"isthing\"", "]", "=", "True", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "segment_info", "[", "\"isthing\"", "]", "=", "False", "\n", "", "return", "segment_info", "\n", "\n", "", "with", "PathManager", ".", "open", "(", "json_file", ")", "as", "f", ":", "\n", "        ", "json_info", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "ann", "in", "json_info", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_id", "=", "int", "(", "ann", "[", "\"image_id\"", "]", ")", "\n", "# TODO: currently we assume image and label has the same filename but", "\n", "# different extension, and images have extension \".jpg\" for COCO. Need", "\n", "# to make image extension a user-provided argument if we extend this", "\n", "# function to support other COCO-like datasets.", "\n", "image_file", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "os", ".", "path", ".", "splitext", "(", "ann", "[", "\"file_name\"", "]", ")", "[", "0", "]", "+", "\".jpg\"", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "ann", "[", "\"file_name\"", "]", ")", "\n", "segments_info", "=", "[", "_convert_category_id", "(", "x", ",", "meta", ")", "for", "x", "in", "ann", "[", "\"segments_info\"", "]", "]", "\n", "ret", ".", "append", "(", "\n", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"pan_seg_file_name\"", ":", "label_file", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n", ")", "\n", "", "assert", "len", "(", "ret", ")", ",", "f\"No images found in {image_dir}!\"", "\n", "assert", "PathManager", ".", "isfile", "(", "ret", "[", "0", "]", "[", "\"file_name\"", "]", ")", ",", "ret", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "assert", "PathManager", ".", "isfile", "(", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", ")", ",", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.register_coco_panoptic": [[66, 99], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco_panoptic.load_coco_panoptic_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.load_coco_panoptic_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "register_coco_panoptic", "(", "\n", "name", ",", "metadata", ",", "image_root", ",", "panoptic_root", ",", "panoptic_json", ",", "instances_json", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Register a \"standard\" version of COCO panoptic segmentation dataset named `name`.\n    The dictionaries in this registered dataset follows detectron2's standard format.\n    Hence it's called \"standard\".\n\n    Args:\n        name (str): the name that identifies a dataset,\n            e.g. \"coco_2017_train_panoptic\"\n        metadata (dict): extra metadata associated with this dataset.\n        image_root (str): directory which contains all the images\n        panoptic_root (str): directory which contains panoptic annotation images in COCO format\n        panoptic_json (str): path to the json panoptic annotation file in COCO format\n        sem_seg_root (none): not used, to be consistent with\n            `register_coco_panoptic_separated`.\n        instances_json (str): path to the json instance annotation file\n    \"\"\"", "\n", "panoptic_name", "=", "name", "\n", "DatasetCatalog", ".", "register", "(", "\n", "panoptic_name", ",", "\n", "lambda", ":", "load_coco_panoptic_json", "(", "panoptic_json", ",", "image_root", ",", "panoptic_root", ",", "metadata", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "panoptic_name", ")", ".", "set", "(", "\n", "panoptic_root", "=", "panoptic_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "panoptic_json", "=", "panoptic_json", ",", "\n", "json_file", "=", "instances_json", ",", "\n", "evaluator_type", "=", "\"coco_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "label_divisor", "=", "1000", ",", "\n", "**", "metadata", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.register_coco_panoptic_separated": [[102, 165], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco_panoptic.merge_to_panoptic", "detectron2.data.MetadataCatalog.get", "coco.load_sem_seg", "detectron2.data.MetadataCatalog.get", "coco.load_coco_json", "coco.load_sem_seg"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.merge_to_panoptic", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_sem_seg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_coco_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_sem_seg"], ["", "def", "register_coco_panoptic_separated", "(", "\n", "name", ",", "metadata", ",", "image_root", ",", "panoptic_root", ",", "panoptic_json", ",", "sem_seg_root", ",", "instances_json", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Register a \"separated\" version of COCO panoptic segmentation dataset named `name`.\n    The annotations in this registered dataset will contain both instance annotations and\n    semantic annotations, each with its own contiguous ids. Hence it's called \"separated\".\n\n    It follows the setting used by the PanopticFPN paper:\n\n    1. The instance annotations directly come from polygons in the COCO\n       instances annotation task, rather than from the masks in the COCO panoptic annotations.\n\n       The two format have small differences:\n       Polygons in the instance annotations may have overlaps.\n       The mask annotations are produced by labeling the overlapped polygons\n       with depth ordering.\n\n    2. The semantic annotations are converted from panoptic annotations, where\n       all \"things\" are assigned a semantic id of 0.\n       All semantic categories will therefore have ids in contiguous\n       range [1, #stuff_categories].\n\n    This function will also register a pure semantic segmentation dataset\n    named ``name + '_stuffonly'``.\n\n    Args:\n        name (str): the name that identifies a dataset,\n            e.g. \"coco_2017_train_panoptic\"\n        metadata (dict): extra metadata associated with this dataset.\n        image_root (str): directory which contains all the images\n        panoptic_root (str): directory which contains panoptic annotation images\n        panoptic_json (str): path to the json panoptic annotation file\n        sem_seg_root (str): directory which contains all the ground truth segmentation annotations.\n        instances_json (str): path to the json instance annotation file\n    \"\"\"", "\n", "panoptic_name", "=", "name", "+", "\"_separated\"", "\n", "DatasetCatalog", ".", "register", "(", "\n", "panoptic_name", ",", "\n", "lambda", ":", "merge_to_panoptic", "(", "\n", "load_coco_json", "(", "instances_json", ",", "image_root", ",", "panoptic_name", ")", ",", "\n", "load_sem_seg", "(", "sem_seg_root", ",", "image_root", ")", ",", "\n", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "panoptic_name", ")", ".", "set", "(", "\n", "panoptic_root", "=", "panoptic_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "panoptic_json", "=", "panoptic_json", ",", "\n", "sem_seg_root", "=", "sem_seg_root", ",", "\n", "json_file", "=", "instances_json", ",", "# TODO rename", "\n", "evaluator_type", "=", "\"coco_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "metadata", ",", "\n", ")", "\n", "\n", "semantic_name", "=", "name", "+", "\"_stuffonly\"", "\n", "DatasetCatalog", ".", "register", "(", "semantic_name", ",", "lambda", ":", "load_sem_seg", "(", "sem_seg_root", ",", "image_root", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "semantic_name", ")", ".", "set", "(", "\n", "sem_seg_root", "=", "sem_seg_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "evaluator_type", "=", "\"sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "metadata", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.merge_to_panoptic": [[168, 191], ["len", "copy.copy", "copy.copy.update", "results.append"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "merge_to_panoptic", "(", "detection_dicts", ",", "sem_seg_dicts", ")", ":", "\n", "    ", "\"\"\"\n    Create dataset dicts for panoptic segmentation, by\n    merging two dicts using \"file_name\" field to match their entries.\n\n    Args:\n        detection_dicts (list[dict]): lists of dicts for object detection or instance segmentation.\n        sem_seg_dicts (list[dict]): lists of dicts for semantic segmentation.\n\n    Returns:\n        list[dict] (one per input image): Each dict contains all (key, value) pairs from dicts in\n            both detection_dicts and sem_seg_dicts that correspond to the same image.\n            The function assumes that the same key in different dicts has the same value.\n    \"\"\"", "\n", "results", "=", "[", "]", "\n", "sem_seg_file_to_entry", "=", "{", "x", "[", "\"file_name\"", "]", ":", "x", "for", "x", "in", "sem_seg_dicts", "}", "\n", "assert", "len", "(", "sem_seg_file_to_entry", ")", ">", "0", "\n", "\n", "for", "det_dict", "in", "detection_dicts", ":", "\n", "        ", "dic", "=", "copy", ".", "copy", "(", "det_dict", ")", "\n", "dic", ".", "update", "(", "sem_seg_file_to_entry", "[", "dic", "[", "\"file_name\"", "]", "]", ")", "\n", "results", ".", "append", "(", "dic", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_instances_meta": [[235, 248], ["len", "len", "enumerate"], "function", ["None"], ["def", "_get_coco_instances_meta", "(", ")", ":", "\n", "    ", "thing_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "assert", "len", "(", "thing_ids", ")", "==", "80", ",", "len", "(", "thing_ids", ")", "\n", "# Mapping from the incontiguous COCO category id to an id in [0, 79]", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "thing_ids", ")", "}", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "ret", "=", "{", "\n", "\"thing_dataset_id_to_contiguous_id\"", ":", "thing_dataset_id_to_contiguous_id", ",", "\n", "\"thing_classes\"", ":", "thing_classes", ",", "\n", "\"thing_colors\"", ":", "thing_colors", ",", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_panoptic_separated_meta": [[250, 281], ["len", "ret.update", "len", "builtin_meta._get_coco_instances_meta", "enumerate", "k[].replace().replace", "k[].replace"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_instances_meta"], ["", "def", "_get_coco_panoptic_separated_meta", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns metadata for \"separated\" version of the panoptic segmentation dataset.\n    \"\"\"", "\n", "stuff_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "0", "]", "\n", "assert", "len", "(", "stuff_ids", ")", "==", "53", ",", "len", "(", "stuff_ids", ")", "\n", "\n", "# For semantic segmentation, this mapping maps from contiguous stuff id", "\n", "# (in [0, 53], used in models) to ids in the dataset (used for processing results)", "\n", "# The id 0 is mapped to an extra category \"thing\".", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "k", ":", "i", "+", "1", "for", "i", ",", "k", "in", "enumerate", "(", "stuff_ids", ")", "}", "\n", "# When converting COCO panoptic annotations to semantic annotations", "\n", "# We label the \"thing\" category to 0", "\n", "stuff_dataset_id_to_contiguous_id", "[", "0", "]", "=", "0", "\n", "\n", "# 54 names for COCO stuff categories (including \"things\")", "\n", "stuff_classes", "=", "[", "\"things\"", "]", "+", "[", "\n", "k", "[", "\"name\"", "]", ".", "replace", "(", "\"-other\"", ",", "\"\"", ")", ".", "replace", "(", "\"-merged\"", ",", "\"\"", ")", "\n", "for", "k", "in", "COCO_CATEGORIES", "\n", "if", "k", "[", "\"isthing\"", "]", "==", "0", "\n", "]", "\n", "\n", "# NOTE: I randomly picked a color for things", "\n", "stuff_colors", "=", "[", "[", "82", ",", "18", ",", "128", "]", "]", "+", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "0", "]", "\n", "ret", "=", "{", "\n", "\"stuff_dataset_id_to_contiguous_id\"", ":", "stuff_dataset_id_to_contiguous_id", ",", "\n", "\"stuff_classes\"", ":", "stuff_classes", ",", "\n", "\"stuff_colors\"", ":", "stuff_colors", ",", "\n", "}", "\n", "ret", ".", "update", "(", "_get_coco_instances_meta", "(", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_builtin_metadata": [[283, 351], ["KeyError", "builtin_meta._get_coco_instances_meta", "builtin_meta._get_coco_panoptic_separated_meta", "enumerate"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_instances_meta", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_panoptic_separated_meta"], ["", "def", "_get_builtin_metadata", "(", "dataset_name", ")", ":", "\n", "    ", "if", "dataset_name", "==", "\"coco\"", ":", "\n", "        ", "return", "_get_coco_instances_meta", "(", ")", "\n", "", "if", "dataset_name", "==", "\"coco_panoptic_separated\"", ":", "\n", "        ", "return", "_get_coco_panoptic_separated_meta", "(", ")", "\n", "", "elif", "dataset_name", "==", "\"coco_panoptic_standard\"", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "# The following metadata maps contiguous id from [0, #thing categories +", "\n", "# #stuff categories) to their names and colors. We have to replica of the", "\n", "# same name and color under \"thing_*\" and \"stuff_*\" because the current", "\n", "# visualization function in D2 handles thing and class classes differently", "\n", "# due to some heuristic used in Panoptic FPN. We keep the same naming to", "\n", "# enable reusing existing visualization functions.", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "stuff_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "stuff_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "\n", "meta", "[", "\"thing_classes\"", "]", "=", "thing_classes", "\n", "meta", "[", "\"thing_colors\"", "]", "=", "thing_colors", "\n", "meta", "[", "\"stuff_classes\"", "]", "=", "stuff_classes", "\n", "meta", "[", "\"stuff_colors\"", "]", "=", "stuff_colors", "\n", "\n", "# Convert category id for training:", "\n", "#   category id: like semantic segmentation, it is the class id for each", "\n", "#   pixel. Since there are some classes not used in evaluation, the category", "\n", "#   id is not always contiguous and thus we have two set of category ids:", "\n", "#       - original category id: category id in the original dataset, mainly", "\n", "#           used for evaluation.", "\n", "#       - contiguous category id: [0, #classes), in order to train the linear", "\n", "#           softmax classifier.", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "\n", "for", "i", ",", "cat", "in", "enumerate", "(", "COCO_CATEGORIES", ")", ":", "\n", "            ", "if", "cat", "[", "\"isthing\"", "]", ":", "\n", "                ", "thing_dataset_id_to_contiguous_id", "[", "cat", "[", "\"id\"", "]", "]", "=", "i", "\n", "", "else", ":", "\n", "                ", "stuff_dataset_id_to_contiguous_id", "[", "cat", "[", "\"id\"", "]", "]", "=", "i", "\n", "\n", "", "", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "=", "thing_dataset_id_to_contiguous_id", "\n", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "=", "stuff_dataset_id_to_contiguous_id", "\n", "\n", "return", "meta", "\n", "", "elif", "dataset_name", "==", "\"coco_person\"", ":", "\n", "        ", "return", "{", "\n", "\"thing_classes\"", ":", "[", "\"person\"", "]", ",", "\n", "\"keypoint_names\"", ":", "COCO_PERSON_KEYPOINT_NAMES", ",", "\n", "\"keypoint_flip_map\"", ":", "COCO_PERSON_KEYPOINT_FLIP_MAP", ",", "\n", "\"keypoint_connection_rules\"", ":", "KEYPOINT_CONNECTION_RULES", ",", "\n", "}", "\n", "", "elif", "dataset_name", "==", "\"cityscapes\"", ":", "\n", "# fmt: off", "\n", "        ", "CITYSCAPES_THING_CLASSES", "=", "[", "\n", "\"person\"", ",", "\"rider\"", ",", "\"car\"", ",", "\"truck\"", ",", "\n", "\"bus\"", ",", "\"train\"", ",", "\"motorcycle\"", ",", "\"bicycle\"", ",", "\n", "]", "\n", "CITYSCAPES_STUFF_CLASSES", "=", "[", "\n", "\"road\"", ",", "\"sidewalk\"", ",", "\"building\"", ",", "\"wall\"", ",", "\"fence\"", ",", "\"pole\"", ",", "\"traffic light\"", ",", "\n", "\"traffic sign\"", ",", "\"vegetation\"", ",", "\"terrain\"", ",", "\"sky\"", ",", "\"person\"", ",", "\"rider\"", ",", "\"car\"", ",", "\n", "\"truck\"", ",", "\"bus\"", ",", "\"train\"", ",", "\"motorcycle\"", ",", "\"bicycle\"", ",", "\n", "]", "\n", "# fmt: on", "\n", "return", "{", "\n", "\"thing_classes\"", ":", "CITYSCAPES_THING_CLASSES", ",", "\n", "\"stuff_classes\"", ":", "CITYSCAPES_STUFF_CLASSES", ",", "\n", "}", "\n", "", "raise", "KeyError", "(", "\"No built-in metadata for dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes._get_cityscapes_files": [[27, 51], ["detectron2.utils.file_io.PathManager.ls", "logger.info", "len", "os.path.join", "os.path.join", "detectron2.utils.file_io.PathManager.ls", "detectron2.utils.file_io.PathManager.isfile", "os.path.join", "basename.endswith", "os.path.join", "os.path.join", "os.path.join", "files.append", "len", "len"], "function", ["None"], ["def", "_get_cityscapes_files", "(", "image_dir", ",", "gt_dir", ")", ":", "\n", "    ", "files", "=", "[", "]", "\n", "# scan through the directory", "\n", "cities", "=", "PathManager", ".", "ls", "(", "image_dir", ")", "\n", "logger", ".", "info", "(", "f\"{len(cities)} cities found in '{image_dir}'.\"", ")", "\n", "for", "city", "in", "cities", ":", "\n", "        ", "city_img_dir", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "city", ")", "\n", "city_gt_dir", "=", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "city", ")", "\n", "for", "basename", "in", "PathManager", ".", "ls", "(", "city_img_dir", ")", ":", "\n", "            ", "image_file", "=", "os", ".", "path", ".", "join", "(", "city_img_dir", ",", "basename", ")", "\n", "\n", "suffix", "=", "\"leftImg8bit.png\"", "\n", "assert", "basename", ".", "endswith", "(", "suffix", ")", ",", "basename", "\n", "basename", "=", "basename", "[", ":", "-", "len", "(", "suffix", ")", "]", "\n", "\n", "instance_file", "=", "os", ".", "path", ".", "join", "(", "city_gt_dir", ",", "basename", "+", "\"gtFine_instanceIds.png\"", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "city_gt_dir", ",", "basename", "+", "\"gtFine_labelIds.png\"", ")", "\n", "json_file", "=", "os", ".", "path", ".", "join", "(", "city_gt_dir", ",", "basename", "+", "\"gtFine_polygons.json\"", ")", "\n", "\n", "files", ".", "append", "(", "(", "image_file", ",", "instance_file", ",", "label_file", ",", "json_file", ")", ")", "\n", "", "", "assert", "len", "(", "files", ")", ",", "\"No images found in {}\"", ".", "format", "(", "image_dir", ")", "\n", "for", "f", "in", "files", "[", "0", "]", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "f", ")", ",", "f", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes.load_cityscapes_instances": [[53, 93], ["cityscapes._get_cityscapes_files", "logger.info", "multiprocessing.Pool", "mp.Pool.map", "logger.info", "functools.partial", "max", "len", "enumerate", "multiprocessing.cpu_count", "detectron2.utils.comm.get_world_size"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes._get_cityscapes_files", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "load_cityscapes_instances", "(", "image_dir", ",", "gt_dir", ",", "from_json", "=", "True", ",", "to_polygons", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n        from_json (bool): whether to read annotations from the raw json file or the png files.\n        to_polygons (bool): whether to represent the segmentation as polygons\n            (COCO's format) instead of masks (cityscapes's format).\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n    \"\"\"", "\n", "if", "from_json", ":", "\n", "        ", "assert", "to_polygons", ",", "(", "\n", "\"Cityscapes's json annotations are in polygon format. \"", "\n", "\"Converting to mask format is not supported now.\"", "\n", ")", "\n", "", "files", "=", "_get_cityscapes_files", "(", "image_dir", ",", "gt_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Preprocessing cityscapes annotations ...\"", ")", "\n", "# This is still not fast: all workers will execute duplicate works and will", "\n", "# take up to 10m on a 8GPU server.", "\n", "pool", "=", "mp", ".", "Pool", "(", "processes", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "//", "get_world_size", "(", ")", "//", "2", ",", "4", ")", ")", "\n", "\n", "ret", "=", "pool", ".", "map", "(", "\n", "functools", ".", "partial", "(", "_cityscapes_files_to_dict", ",", "from_json", "=", "from_json", ",", "to_polygons", "=", "to_polygons", ")", ",", "\n", "files", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Loaded {} images from {}\"", ".", "format", "(", "len", "(", "ret", ")", ",", "image_dir", ")", ")", "\n", "\n", "# Map cityscape ids to contiguous ids", "\n", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "labels", "\n", "\n", "labels", "=", "[", "l", "for", "l", "in", "labels", "if", "l", ".", "hasInstances", "and", "not", "l", ".", "ignoreInEval", "]", "\n", "dataset_id_to_contiguous_id", "=", "{", "l", ".", "id", ":", "idx", "for", "idx", ",", "l", "in", "enumerate", "(", "labels", ")", "}", "\n", "for", "dict_per_image", "in", "ret", ":", "\n", "        ", "for", "anno", "in", "dict_per_image", "[", "\"annotations\"", "]", ":", "\n", "            ", "anno", "[", "\"category_id\"", "]", "=", "dataset_id_to_contiguous_id", "[", "anno", "[", "\"category_id\"", "]", "]", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes.load_cityscapes_semantic": [[95, 126], ["detectron2.utils.file_io.PathManager.get_local_path", "cityscapes._get_cityscapes_files", "len", "detectron2.utils.file_io.PathManager.isfile", "label_file.replace.replace", "ret.append", "detectron2.utils.file_io.PathManager.open", "json.load"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes._get_cityscapes_files"], ["", "def", "load_cityscapes_semantic", "(", "image_dir", ",", "gt_dir", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n\n    Returns:\n        list[dict]: a list of dict, each has \"file_name\" and\n            \"sem_seg_file_name\".\n    \"\"\"", "\n", "ret", "=", "[", "]", "\n", "# gt_dir is small and contain many small files. make sense to fetch to local first", "\n", "gt_dir", "=", "PathManager", ".", "get_local_path", "(", "gt_dir", ")", "\n", "for", "image_file", ",", "_", ",", "label_file", ",", "json_file", "in", "_get_cityscapes_files", "(", "image_dir", ",", "gt_dir", ")", ":", "\n", "        ", "label_file", "=", "label_file", ".", "replace", "(", "\"labelIds\"", ",", "\"labelTrainIds\"", ")", "\n", "\n", "with", "PathManager", ".", "open", "(", "json_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "jsonobj", "=", "json", ".", "load", "(", "f", ")", "\n", "", "ret", ".", "append", "(", "\n", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"sem_seg_file_name\"", ":", "label_file", ",", "\n", "\"height\"", ":", "jsonobj", "[", "\"imgHeight\"", "]", ",", "\n", "\"width\"", ":", "jsonobj", "[", "\"imgWidth\"", "]", ",", "\n", "}", "\n", ")", "\n", "", "assert", "len", "(", "ret", ")", ",", "f\"No images found in {image_dir}!\"", "\n", "assert", "PathManager", ".", "isfile", "(", "\n", "ret", "[", "0", "]", "[", "\"sem_seg_file_name\"", "]", "\n", ")", ",", "\"Please generate labelTrainIds.png with cityscapesscripts/preparation/createTrainIdLabelImgs.py\"", "# noqa", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes._cityscapes_files_to_dict": [[128, 279], ["Polygon", "numpy.unique", "detectron2.utils.file_io.PathManager.open", "json.load", "os.path.basename", "Polygon().buffer", "Polygon().buffer.difference", "polygons_union.union.union", "label_name.endswith", "isinstance", "annos.append", "detectron2.utils.file_io.PathManager.open", "numpy.asarray", "os.path.basename", "numpy.asarray", "numpy.nonzero", "annos.append", "numpy.asarray", "polygons_union.union.union", "isinstance", "poly_coord.append", "PIL.Image.open", "inds[].min", "inds[].max", "inds[].min", "inds[].max", "label_name.endswith", "Polygon", "NotImplementedError", "list", "cv2.findContours", "c.reshape().tolist", "len", "pycocotools.encode", "itertools.chain", "np.asarray.copy", "c.reshape", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode"], ["", "def", "_cityscapes_files_to_dict", "(", "files", ",", "from_json", ",", "to_polygons", ")", ":", "\n", "    ", "\"\"\"\n    Parse cityscapes annotation files to a instance segmentation dataset dict.\n\n    Args:\n        files (tuple): consists of (image_file, instance_id_file, label_id_file, json_file)\n        from_json (bool): whether to read annotations from the raw json file or the png files.\n        to_polygons (bool): whether to represent the segmentation as polygons\n            (COCO's format) instead of masks (cityscapes's format).\n\n    Returns:\n        A dict in Detectron2 Dataset format.\n    \"\"\"", "\n", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "id2label", ",", "name2label", "\n", "\n", "image_file", ",", "instance_id_file", ",", "_", ",", "json_file", "=", "files", "\n", "\n", "annos", "=", "[", "]", "\n", "\n", "if", "from_json", ":", "\n", "        ", "from", "shapely", ".", "geometry", "import", "MultiPolygon", ",", "Polygon", "\n", "\n", "with", "PathManager", ".", "open", "(", "json_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "jsonobj", "=", "json", ".", "load", "(", "f", ")", "\n", "", "ret", "=", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "os", ".", "path", ".", "basename", "(", "image_file", ")", ",", "\n", "\"height\"", ":", "jsonobj", "[", "\"imgHeight\"", "]", ",", "\n", "\"width\"", ":", "jsonobj", "[", "\"imgWidth\"", "]", ",", "\n", "}", "\n", "\n", "# `polygons_union` contains the union of all valid polygons.", "\n", "polygons_union", "=", "Polygon", "(", ")", "\n", "\n", "# CityscapesScripts draw the polygons in sequential order", "\n", "# and each polygon *overwrites* existing ones. See", "\n", "# (https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/preparation/json2instanceImg.py) # noqa", "\n", "# We use reverse order, and each polygon *avoids* early ones.", "\n", "# This will resolve the ploygon overlaps in the same way as CityscapesScripts.", "\n", "for", "obj", "in", "jsonobj", "[", "\"objects\"", "]", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "\"deleted\"", "in", "obj", ":", "# cityscapes data format specific", "\n", "                ", "continue", "\n", "", "label_name", "=", "obj", "[", "\"label\"", "]", "\n", "\n", "try", ":", "\n", "                ", "label", "=", "name2label", "[", "label_name", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "if", "label_name", ".", "endswith", "(", "\"group\"", ")", ":", "# crowd area", "\n", "                    ", "label", "=", "name2label", "[", "label_name", "[", ":", "-", "len", "(", "\"group\"", ")", "]", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "", "", "if", "label", ".", "id", "<", "0", ":", "# cityscapes data format", "\n", "                ", "continue", "\n", "\n", "# Cityscapes's raw annotations uses integer coordinates", "\n", "# Therefore +0.5 here", "\n", "", "poly_coord", "=", "np", ".", "asarray", "(", "obj", "[", "\"polygon\"", "]", ",", "dtype", "=", "\"f4\"", ")", "+", "0.5", "\n", "# CityscapesScript uses PIL.ImageDraw.polygon to rasterize", "\n", "# polygons for evaluation. This function operates in integer space", "\n", "# and draws each pixel whose center falls into the polygon.", "\n", "# Therefore it draws a polygon which is 0.5 \"fatter\" in expectation.", "\n", "# We therefore dilate the input polygon by 0.5 as our input.", "\n", "poly", "=", "Polygon", "(", "poly_coord", ")", ".", "buffer", "(", "0.5", ",", "resolution", "=", "4", ")", "\n", "\n", "if", "not", "label", ".", "hasInstances", "or", "label", ".", "ignoreInEval", ":", "\n", "# even if we won't store the polygon it still contributes to overlaps resolution", "\n", "                ", "polygons_union", "=", "polygons_union", ".", "union", "(", "poly", ")", "\n", "continue", "\n", "\n", "# Take non-overlapping part of the polygon", "\n", "", "poly_wo_overlaps", "=", "poly", ".", "difference", "(", "polygons_union", ")", "\n", "if", "poly_wo_overlaps", ".", "is_empty", ":", "\n", "                ", "continue", "\n", "", "polygons_union", "=", "polygons_union", ".", "union", "(", "poly", ")", "\n", "\n", "anno", "=", "{", "}", "\n", "anno", "[", "\"iscrowd\"", "]", "=", "label_name", ".", "endswith", "(", "\"group\"", ")", "\n", "anno", "[", "\"category_id\"", "]", "=", "label", ".", "id", "\n", "\n", "if", "isinstance", "(", "poly_wo_overlaps", ",", "Polygon", ")", ":", "\n", "                ", "poly_list", "=", "[", "poly_wo_overlaps", "]", "\n", "", "elif", "isinstance", "(", "poly_wo_overlaps", ",", "MultiPolygon", ")", ":", "\n", "                ", "poly_list", "=", "poly_wo_overlaps", ".", "geoms", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Unknown geometric structure {}\"", ".", "format", "(", "poly_wo_overlaps", ")", ")", "\n", "\n", "", "poly_coord", "=", "[", "]", "\n", "for", "poly_el", "in", "poly_list", ":", "\n", "# COCO API can work only with exterior boundaries now, hence we store only them.", "\n", "# TODO: store both exterior and interior boundaries once other parts of the", "\n", "# codebase support holes in polygons.", "\n", "                ", "poly_coord", ".", "append", "(", "list", "(", "chain", "(", "*", "poly_el", ".", "exterior", ".", "coords", ")", ")", ")", "\n", "", "anno", "[", "\"segmentation\"", "]", "=", "poly_coord", "\n", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", "=", "poly_wo_overlaps", ".", "bounds", "\n", "\n", "anno", "[", "\"bbox\"", "]", "=", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", "\n", "anno", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "\n", "annos", ".", "append", "(", "anno", ")", "\n", "", "", "else", ":", "\n", "# See also the official annotation parsing scripts at", "\n", "# https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/instances2dict.py  # noqa", "\n", "        ", "with", "PathManager", ".", "open", "(", "instance_id_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "inst_image", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "f", ")", ",", "order", "=", "\"F\"", ")", "\n", "# ids < 24 are stuff labels (filtering them first is about 5% faster)", "\n", "", "flattened_ids", "=", "np", ".", "unique", "(", "inst_image", "[", "inst_image", ">=", "24", "]", ")", "\n", "\n", "ret", "=", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "os", ".", "path", ".", "basename", "(", "image_file", ")", ",", "\n", "\"height\"", ":", "inst_image", ".", "shape", "[", "0", "]", ",", "\n", "\"width\"", ":", "inst_image", ".", "shape", "[", "1", "]", ",", "\n", "}", "\n", "\n", "for", "instance_id", "in", "flattened_ids", ":", "\n", "# For non-crowd annotations, instance_id // 1000 is the label_id", "\n", "# Crowd annotations have <1000 instance ids", "\n", "            ", "label_id", "=", "instance_id", "//", "1000", "if", "instance_id", ">=", "1000", "else", "instance_id", "\n", "label", "=", "id2label", "[", "label_id", "]", "\n", "if", "not", "label", ".", "hasInstances", "or", "label", ".", "ignoreInEval", ":", "\n", "                ", "continue", "\n", "\n", "", "anno", "=", "{", "}", "\n", "anno", "[", "\"iscrowd\"", "]", "=", "instance_id", "<", "1000", "\n", "anno", "[", "\"category_id\"", "]", "=", "label", ".", "id", "\n", "\n", "mask", "=", "np", ".", "asarray", "(", "inst_image", "==", "instance_id", ",", "dtype", "=", "np", ".", "uint8", ",", "order", "=", "\"F\"", ")", "\n", "\n", "inds", "=", "np", ".", "nonzero", "(", "mask", ")", "\n", "ymin", ",", "ymax", "=", "inds", "[", "0", "]", ".", "min", "(", ")", ",", "inds", "[", "0", "]", ".", "max", "(", ")", "\n", "xmin", ",", "xmax", "=", "inds", "[", "1", "]", ".", "min", "(", ")", ",", "inds", "[", "1", "]", ".", "max", "(", ")", "\n", "anno", "[", "\"bbox\"", "]", "=", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", "\n", "if", "xmax", "<=", "xmin", "or", "ymax", "<=", "ymin", ":", "\n", "                ", "continue", "\n", "", "anno", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "if", "to_polygons", ":", "\n", "# This conversion comes from D4809743 and D5171122,", "\n", "# when Mask-RCNN was first developed.", "\n", "                ", "contours", "=", "cv2", ".", "findContours", "(", "mask", ".", "copy", "(", ")", ",", "cv2", ".", "RETR_EXTERNAL", ",", "cv2", ".", "CHAIN_APPROX_NONE", ")", "[", "\n", "-", "2", "\n", "]", "\n", "polygons", "=", "[", "c", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "for", "c", "in", "contours", "if", "len", "(", "c", ")", ">=", "3", "]", "\n", "# opencv's can produce invalid polygons", "\n", "if", "len", "(", "polygons", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "anno", "[", "\"segmentation\"", "]", "=", "polygons", "\n", "", "else", ":", "\n", "                ", "anno", "[", "\"segmentation\"", "]", "=", "mask_util", ".", "encode", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ")", "[", "0", "]", "\n", "", "annos", ".", "append", "(", "anno", ")", "\n", "", "", "ret", "[", "\"annotations\"", "]", "=", "annos", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.register_lvis_instances": [[24, 37], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "lvis.load_lvis_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.load_lvis_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "register_lvis_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in LVIS's json annotation format for instance detection and segmentation.\n\n    Args:\n        name (str): a name that identifies the dataset, e.g. \"lvis_v0.5_train\".\n        metadata (dict): extra metadata associated with this dataset. It can be an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "DatasetCatalog", ".", "register", "(", "name", ",", "lambda", ":", "load_lvis_json", "(", "json_file", ",", "image_root", ",", "name", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"lvis\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.load_lvis_json": [[40, 153], ["detectron2.utils.file_io.PathManager.get_local_path", "fvcore.common.timer.Timer", "LVIS", "sorted", "LVIS.load_imgs", "list", "logger.info", "fvcore.common.timer.Timer.seconds", "logger.info", "lvis.get_lvis_instances_meta", "detectron2.data.MetadataCatalog.get().set", "LVIS.imgs.keys", "len", "len", "zip", "os.path.join", "lvis.load_lvis_json.get_file_name"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.get_lvis_instances_meta", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "def", "load_lvis_json", "(", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load a json file in LVIS's annotation format.\n\n    Args:\n        json_file (str): full path to the LVIS json annotation file.\n        image_root (str): the directory where the images in this json file exists.\n        dataset_name (str): the name of the dataset (e.g., \"lvis_v0.5_train\").\n            If provided, this function will put \"thing_classes\" into the metadata\n            associated with this dataset.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n\n    Notes:\n        1. This function does not read the image files.\n           The results do not have the \"image\" field.\n    \"\"\"", "\n", "from", "lvis", "import", "LVIS", "\n", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "lvis_api", "=", "LVIS", "(", "json_file", ")", "\n", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "", "if", "dataset_name", "is", "not", "None", ":", "\n", "        ", "meta", "=", "get_lvis_instances_meta", "(", "dataset_name", ")", "\n", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", ".", "set", "(", "**", "meta", ")", "\n", "\n", "# sort indices for reproducible results", "\n", "", "img_ids", "=", "sorted", "(", "lvis_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "# imgs is a list of dicts, each looks something like:", "\n", "# {'license': 4,", "\n", "#  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',", "\n", "#  'file_name': 'COCO_val2014_000000001268.jpg',", "\n", "#  'height': 427,", "\n", "#  'width': 640,", "\n", "#  'date_captured': '2013-11-17 05:57:24',", "\n", "#  'id': 1268}", "\n", "imgs", "=", "lvis_api", ".", "load_imgs", "(", "img_ids", ")", "\n", "# anns is a list[list[dict]], where each dict is an annotation", "\n", "# record for an object. The inner list enumerates the objects in an image", "\n", "# and the outer list enumerates over images. Example of anns[0]:", "\n", "# [{'segmentation': [[192.81,", "\n", "#     247.09,", "\n", "#     ...", "\n", "#     219.03,", "\n", "#     249.06]],", "\n", "#   'area': 1035.749,", "\n", "#   'image_id': 1268,", "\n", "#   'bbox': [192.81, 224.8, 74.73, 33.43],", "\n", "#   'category_id': 16,", "\n", "#   'id': 42986},", "\n", "#  ...]", "\n", "anns", "=", "[", "lvis_api", ".", "img_ann_map", "[", "img_id", "]", "for", "img_id", "in", "img_ids", "]", "\n", "\n", "# Sanity check that each annotation has a unique id", "\n", "ann_ids", "=", "[", "ann", "[", "\"id\"", "]", "for", "anns_per_image", "in", "anns", "for", "ann", "in", "anns_per_image", "]", "\n", "assert", "len", "(", "set", "(", "ann_ids", ")", ")", "==", "len", "(", "ann_ids", ")", ",", "\"Annotation ids in '{}' are not unique\"", ".", "format", "(", "\n", "json_file", "\n", ")", "\n", "\n", "imgs_anns", "=", "list", "(", "zip", "(", "imgs", ",", "anns", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loaded {} images in the LVIS format from {}\"", ".", "format", "(", "len", "(", "imgs_anns", ")", ",", "json_file", ")", ")", "\n", "\n", "def", "get_file_name", "(", "img_root", ",", "img_dict", ")", ":", "\n", "# Determine the path including the split folder (\"train2017\", \"val2017\", \"test2017\") from", "\n", "# the coco_url field. Example:", "\n", "#   'coco_url': 'http://images.cocodataset.org/train2017/000000155379.jpg'", "\n", "        ", "split_folder", ",", "file_name", "=", "img_dict", "[", "\"coco_url\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "img_root", "+", "split_folder", ",", "file_name", ")", "\n", "\n", "", "dataset_dicts", "=", "[", "]", "\n", "\n", "for", "(", "img_dict", ",", "anno_dict_list", ")", "in", "imgs_anns", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "get_file_name", "(", "image_root", ",", "img_dict", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "record", "[", "\"not_exhaustive_category_ids\"", "]", "=", "img_dict", ".", "get", "(", "\"not_exhaustive_category_ids\"", ",", "[", "]", ")", "\n", "record", "[", "\"neg_category_ids\"", "]", "=", "img_dict", ".", "get", "(", "\"neg_category_ids\"", ",", "[", "]", ")", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "anno_dict_list", ":", "\n", "# Check that the image_id in this annotation is the same as", "\n", "# the image_id we're looking at.", "\n", "# This fails only when the data parsing logic or the annotation file is buggy.", "\n", "            ", "assert", "anno", "[", "\"image_id\"", "]", "==", "image_id", "\n", "obj", "=", "{", "\"bbox\"", ":", "anno", "[", "\"bbox\"", "]", ",", "\"bbox_mode\"", ":", "BoxMode", ".", "XYWH_ABS", "}", "\n", "# LVIS data loader can be used to load COCO dataset categories. In this case `meta`", "\n", "# variable will have a field with COCO-specific category mapping.", "\n", "if", "dataset_name", "is", "not", "None", "and", "\"thing_dataset_id_to_contiguous_id\"", "in", "meta", ":", "\n", "                ", "obj", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "anno", "[", "\"category_id\"", "]", "]", "\n", "", "else", ":", "\n", "                ", "obj", "[", "\"category_id\"", "]", "=", "anno", "[", "\"category_id\"", "]", "-", "1", "# Convert 1-indexed to 0-indexed", "\n", "", "segm", "=", "anno", "[", "\"segmentation\"", "]", "# list[list[float]]", "\n", "# filter out invalid polygons (< 3 points)", "\n", "valid_segm", "=", "[", "poly", "for", "poly", "in", "segm", "if", "len", "(", "poly", ")", "%", "2", "==", "0", "and", "len", "(", "poly", ")", ">=", "6", "]", "\n", "assert", "len", "(", "segm", ")", "==", "len", "(", "\n", "valid_segm", "\n", ")", ",", "\"Annotation contains an invalid polygon with < 3 points\"", "\n", "assert", "len", "(", "segm", ")", ">", "0", "\n", "obj", "[", "\"segmentation\"", "]", "=", "segm", "\n", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.get_lvis_instances_meta": [[155, 172], ["ValueError", "builtin_meta._get_coco_instances_meta", "lvis._get_lvis_instances_meta_v0_5", "lvis._get_lvis_instances_meta_v1"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_coco_instances_meta", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis._get_lvis_instances_meta_v0_5", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis._get_lvis_instances_meta_v1"], ["", "def", "get_lvis_instances_meta", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n    Load LVIS metadata.\n\n    Args:\n        dataset_name (str): LVIS dataset name without the split name (e.g., \"lvis_v0.5\").\n\n    Returns:\n        dict: LVIS metadata with keys: thing_classes\n    \"\"\"", "\n", "if", "\"cocofied\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_coco_instances_meta", "(", ")", "\n", "", "if", "\"v0.5\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v0_5", "(", ")", "\n", "", "elif", "\"v1\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v1", "(", ")", "\n", "", "raise", "ValueError", "(", "\"No built-in metadata for dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis._get_lvis_instances_meta_v0_5": [[174, 185], ["sorted", "len", "min", "max", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_get_lvis_instances_meta_v0_5", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V0_5_CATEGORIES", ")", "==", "1230", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V0_5_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V0_5_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis._get_lvis_instances_meta_v1": [[187, 198], ["sorted", "len", "min", "max", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_get_lvis_instances_meta_v1", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V1_CATEGORIES", ")", "==", "1203", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V1_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V1_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin.register_all_coco": [[106, 144], ["_PREDEFINED_SPLITS_COCO.items", "_PREDEFINED_SPLITS_COCO_PANOPTIC.items", "splits_per_dataset.items", "detectron2.data.MetadataCatalog.get", "coco_panoptic.register_coco_panoptic_separated", "coco_panoptic.register_coco_panoptic", "coco.register_coco_instances", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "os.path.join", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.register_coco_panoptic_separated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco_panoptic.register_coco_panoptic", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.register_coco_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_builtin_metadata"], ["def", "register_all_coco", "(", "root", ")", ":", "\n", "    ", "for", "dataset_name", ",", "splits_per_dataset", "in", "_PREDEFINED_SPLITS_COCO", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "# Assume pre-defined datasets live in `./datasets`.", "\n", "            ", "register_coco_instances", "(", "\n", "key", ",", "\n", "_get_builtin_metadata", "(", "dataset_name", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", "if", "\"://\"", "not", "in", "json_file", "else", "json_file", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", ",", "\n", ")", "\n", "\n", "", "", "for", "(", "\n", "prefix", ",", "\n", "(", "panoptic_root", ",", "panoptic_json", ",", "semantic_root", ")", ",", "\n", ")", "in", "_PREDEFINED_SPLITS_COCO_PANOPTIC", ".", "items", "(", ")", ":", "\n", "        ", "prefix_instances", "=", "prefix", "[", ":", "-", "len", "(", "\"_panoptic\"", ")", "]", "\n", "instances_meta", "=", "MetadataCatalog", ".", "get", "(", "prefix_instances", ")", "\n", "image_root", ",", "instances_json", "=", "instances_meta", ".", "image_root", ",", "instances_meta", ".", "json_file", "\n", "# The \"separated\" version of COCO panoptic segmentation dataset,", "\n", "# e.g. used by Panoptic FPN", "\n", "register_coco_panoptic_separated", "(", "\n", "prefix", ",", "\n", "_get_builtin_metadata", "(", "\"coco_panoptic_separated\"", ")", ",", "\n", "image_root", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_root", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_json", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "semantic_root", ")", ",", "\n", "instances_json", ",", "\n", ")", "\n", "# The \"standard\" version of COCO panoptic segmentation dataset,", "\n", "# e.g. used by Panoptic-DeepLab", "\n", "register_coco_panoptic", "(", "\n", "prefix", ",", "\n", "_get_builtin_metadata", "(", "\"coco_panoptic_standard\"", ")", ",", "\n", "image_root", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_root", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_json", ")", ",", "\n", "instances_json", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin.register_all_lvis": [[170, 178], ["_PREDEFINED_SPLITS_LVIS.items", "splits_per_dataset.items", "lvis.register_lvis_instances", "lvis.get_lvis_instances_meta", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.register_lvis_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.lvis.get_lvis_instances_meta"], ["def", "register_all_lvis", "(", "root", ")", ":", "\n", "    ", "for", "dataset_name", ",", "splits_per_dataset", "in", "_PREDEFINED_SPLITS_LVIS", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "            ", "register_lvis_instances", "(", "\n", "key", ",", "\n", "get_lvis_instances_meta", "(", "dataset_name", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", "if", "\"://\"", "not", "in", "json_file", "else", "json_file", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin.register_all_cityscapes": [[189, 216], ["_RAW_CITYSCAPES_SPLITS.items", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "key.format", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "key.format", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "cityscapes.load_cityscapes_instances", "detectron2.data.MetadataCatalog.get", "cityscapes.load_cityscapes_semantic", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes.load_cityscapes_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.cityscapes.load_cityscapes_semantic", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "register_all_cityscapes", "(", "root", ")", ":", "\n", "    ", "for", "key", ",", "(", "image_dir", ",", "gt_dir", ")", "in", "_RAW_CITYSCAPES_SPLITS", ".", "items", "(", ")", ":", "\n", "        ", "meta", "=", "_get_builtin_metadata", "(", "\"cityscapes\"", ")", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "image_dir", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_dir", ")", "\n", "\n", "inst_key", "=", "key", ".", "format", "(", "task", "=", "\"instance_seg\"", ")", "\n", "DatasetCatalog", ".", "register", "(", "\n", "inst_key", ",", "\n", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_cityscapes_instances", "(", "\n", "x", ",", "y", ",", "from_json", "=", "True", ",", "to_polygons", "=", "True", "\n", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "inst_key", ")", ".", "set", "(", "\n", "image_dir", "=", "image_dir", ",", "gt_dir", "=", "gt_dir", ",", "evaluator_type", "=", "\"cityscapes_instance\"", ",", "**", "meta", "\n", ")", "\n", "\n", "sem_key", "=", "key", ".", "format", "(", "task", "=", "\"sem_seg\"", ")", "\n", "DatasetCatalog", ".", "register", "(", "\n", "sem_key", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_cityscapes_semantic", "(", "x", ",", "y", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "sem_key", ")", ".", "set", "(", "\n", "image_dir", "=", "image_dir", ",", "\n", "gt_dir", "=", "gt_dir", ",", "\n", "evaluator_type", "=", "\"cityscapes_sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "meta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin.register_all_pascal_voc": [[220, 234], ["pascal_voc.register_pascal_voc", "os.path.join", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.pascal_voc.register_pascal_voc", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "register_all_pascal_voc", "(", "root", ")", ":", "\n", "    ", "SPLITS", "=", "[", "\n", "(", "\"voc_2007_trainval\"", ",", "\"VOC2007\"", ",", "\"trainval\"", ")", ",", "\n", "(", "\"voc_2007_train\"", ",", "\"VOC2007\"", ",", "\"train\"", ")", ",", "\n", "(", "\"voc_2007_val\"", ",", "\"VOC2007\"", ",", "\"val\"", ")", ",", "\n", "(", "\"voc_2007_test\"", ",", "\"VOC2007\"", ",", "\"test\"", ")", ",", "\n", "(", "\"voc_2012_trainval\"", ",", "\"VOC2012\"", ",", "\"trainval\"", ")", ",", "\n", "(", "\"voc_2012_train\"", ",", "\"VOC2012\"", ",", "\"train\"", ")", ",", "\n", "(", "\"voc_2012_val\"", ",", "\"VOC2012\"", ",", "\"val\"", ")", ",", "\n", "]", "\n", "for", "name", ",", "dirname", ",", "split", "in", "SPLITS", ":", "\n", "        ", "year", "=", "2007", "if", "\"2007\"", "in", "name", "else", "2012", "\n", "register_pascal_voc", "(", "name", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dirname", ")", ",", "split", ",", "year", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "evaluator_type", "=", "\"pascal_voc\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.builtin.register_all_ade20k": [[236, 251], ["os.path.join", "os.path.join", "os.path.join", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco.load_sem_seg", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.load_sem_seg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "", "def", "register_all_ade20k", "(", "root", ")", ":", "\n", "    ", "root", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"ADEChallengeData2016\"", ")", "\n", "for", "name", ",", "dirname", "in", "[", "(", "\"train\"", ",", "\"training\"", ")", ",", "(", "\"val\"", ",", "\"validation\"", ")", "]", ":", "\n", "        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"images\"", ",", "dirname", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations_detectron2\"", ",", "dirname", ")", "\n", "name", "=", "f\"ade20k_sem_seg_{name}\"", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_sem_seg", "(", "y", ",", "x", ",", "gt_ext", "=", "\"png\"", ",", "image_ext", "=", "\"jpg\"", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "stuff_classes", "=", "ADE20K_SEM_SEG_CATEGORIES", "[", ":", "]", ",", "\n", "image_root", "=", "image_dir", ",", "\n", "sem_seg_root", "=", "gt_dir", ",", "\n", "evaluator_type", "=", "\"sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.pascal_voc.load_voc_instances": [[25, 76], ["detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.open", "numpy.loadtxt", "os.path.join", "os.path.join", "os.path.join", "ET.parse.findall", "dicts.append", "os.path.join", "detectron2.utils.file_io.PathManager.open", "xml.parse", "int", "int", "obj.find", "instances.append", "obj.find", "float", "class_names.index", "ET.parse.findall", "ET.parse.findall", "obj.find.find"], "function", ["None"], ["def", "load_voc_instances", "(", "dirname", ":", "str", ",", "split", ":", "str", ",", "class_names", ":", "Union", "[", "List", "[", "str", "]", ",", "Tuple", "[", "str", ",", "...", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Load Pascal VOC detection annotations to Detectron2 format.\n\n    Args:\n        dirname: Contain \"Annotations\", \"ImageSets\", \"JPEGImages\"\n        split (str): one of \"train\", \"test\", \"val\", \"trainval\"\n        class_names: list or tuple of class names\n    \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"ImageSets\"", ",", "\"Main\"", ",", "split", "+", "\".txt\"", ")", ")", "as", "f", ":", "\n", "        ", "fileids", "=", "np", ".", "loadtxt", "(", "f", ",", "dtype", "=", "np", ".", "str", ")", "\n", "\n", "# Needs to read many small annotation files. Makes sense at local", "\n", "", "annotation_dirname", "=", "PathManager", ".", "get_local_path", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"Annotations/\"", ")", ")", "\n", "dicts", "=", "[", "]", "\n", "for", "fileid", "in", "fileids", ":", "\n", "        ", "anno_file", "=", "os", ".", "path", ".", "join", "(", "annotation_dirname", ",", "fileid", "+", "\".xml\"", ")", "\n", "jpeg_file", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"JPEGImages\"", ",", "fileid", "+", "\".jpg\"", ")", "\n", "\n", "with", "PathManager", ".", "open", "(", "anno_file", ")", "as", "f", ":", "\n", "            ", "tree", "=", "ET", ".", "parse", "(", "f", ")", "\n", "\n", "", "r", "=", "{", "\n", "\"file_name\"", ":", "jpeg_file", ",", "\n", "\"image_id\"", ":", "fileid", ",", "\n", "\"height\"", ":", "int", "(", "tree", ".", "findall", "(", "\"./size/height\"", ")", "[", "0", "]", ".", "text", ")", ",", "\n", "\"width\"", ":", "int", "(", "tree", ".", "findall", "(", "\"./size/width\"", ")", "[", "0", "]", ".", "text", ")", ",", "\n", "}", "\n", "instances", "=", "[", "]", "\n", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "\"object\"", ")", ":", "\n", "            ", "cls", "=", "obj", ".", "find", "(", "\"name\"", ")", ".", "text", "\n", "# We include \"difficult\" samples in training.", "\n", "# Based on limited experiments, they don't hurt accuracy.", "\n", "# difficult = int(obj.find(\"difficult\").text)", "\n", "# if difficult == 1:", "\n", "# continue", "\n", "bbox", "=", "obj", ".", "find", "(", "\"bndbox\"", ")", "\n", "bbox", "=", "[", "float", "(", "bbox", ".", "find", "(", "x", ")", ".", "text", ")", "for", "x", "in", "[", "\"xmin\"", ",", "\"ymin\"", ",", "\"xmax\"", ",", "\"ymax\"", "]", "]", "\n", "# Original annotations are integers in the range [1, W or H]", "\n", "# Assuming they mean 1-based pixel indices (inclusive),", "\n", "# a box with annotation (xmin=1, xmax=W) covers the whole image.", "\n", "# In coordinate space this is represented by (xmin=0, xmax=W)", "\n", "bbox", "[", "0", "]", "-=", "1.0", "\n", "bbox", "[", "1", "]", "-=", "1.0", "\n", "instances", ".", "append", "(", "\n", "{", "\"category_id\"", ":", "class_names", ".", "index", "(", "cls", ")", ",", "\"bbox\"", ":", "bbox", ",", "\"bbox_mode\"", ":", "BoxMode", ".", "XYXY_ABS", "}", "\n", ")", "\n", "", "r", "[", "\"annotations\"", "]", "=", "instances", "\n", "dicts", ".", "append", "(", "r", ")", "\n", "", "return", "dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.pascal_voc.register_pascal_voc": [[78, 82], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "pascal_voc.load_voc_instances", "detectron2.data.MetadataCatalog.get", "list"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.pascal_voc.load_voc_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "register_pascal_voc", "(", "name", ",", "dirname", ",", "split", ",", "year", ",", "class_names", "=", "CLASS_NAMES", ")", ":", "\n", "    ", "DatasetCatalog", ".", "register", "(", "name", ",", "lambda", ":", "load_voc_instances", "(", "dirname", ",", "split", ",", "class_names", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "thing_classes", "=", "list", "(", "class_names", ")", ",", "dirname", "=", "dirname", ",", "year", "=", "year", ",", "split", "=", "split", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.grouped_batch_sampler.GroupedBatchSampler.__init__": [[14, 36], ["numpy.asarray", "numpy.unique().tolist", "isinstance", "ValueError", "numpy.unique"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ",", "group_ids", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sampler (Sampler): Base sampler.\n            group_ids (list[int]): If the sampler produces indices in range [0, N),\n                `group_ids` must be a list of `N` ints which contains the group id of each sample.\n                The group ids must be a set of integers in the range [0, num_groups).\n            batch_size (int): Size of mini-batch.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "sampler", ",", "Sampler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"sampler should be an instance of \"", "\n", "\"torch.utils.data.Sampler, but got sampler={}\"", ".", "format", "(", "sampler", ")", "\n", ")", "\n", "", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "group_ids", "=", "np", ".", "asarray", "(", "group_ids", ")", "\n", "assert", "self", ".", "group_ids", ".", "ndim", "==", "1", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "groups", "=", "np", ".", "unique", "(", "self", ".", "group_ids", ")", ".", "tolist", "(", ")", "\n", "\n", "# buffer the indices of each group until batch size is reached", "\n", "self", ".", "buffer_per_group", "=", "{", "k", ":", "[", "]", "for", "k", "in", "groups", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.grouped_batch_sampler.GroupedBatchSampler.__iter__": [[37, 45], ["group_buffer.append", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "            ", "group_id", "=", "self", ".", "group_ids", "[", "idx", "]", "\n", "group_buffer", "=", "self", ".", "buffer_per_group", "[", "group_id", "]", "\n", "group_buffer", ".", "append", "(", "idx", ")", "\n", "if", "len", "(", "group_buffer", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "group_buffer", "[", ":", "]", "# yield a copy of the list", "\n", "del", "group_buffer", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.grouped_batch_sampler.GroupedBatchSampler.__len__": [[46, 48], ["NotImplementedError"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"len() of GroupedBatchSampler is not well-defined.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.TrainingSampler.__init__": [[24, 42], ["int", "detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "detectron2.utils.comm.shared_random_seed"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.shared_random_seed"], ["def", "__init__", "(", "self", ",", "size", ":", "int", ",", "shuffle", ":", "bool", "=", "True", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n            shuffle (bool): whether to shuffle the indices or not\n            seed (int): the initial seed of the shuffle. Must be the same\n                across all workers. If None, will use a random seed shared\n                among workers (require synchronization among all workers).\n        \"\"\"", "\n", "self", ".", "_size", "=", "size", "\n", "assert", "size", ">", "0", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "comm", ".", "shared_random_seed", "(", ")", "\n", "", "self", ".", "_seed", "=", "int", "(", "seed", ")", "\n", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.TrainingSampler.__iter__": [[43, 46], ["itertools.islice", "distributed_sampler.TrainingSampler._infinite_indices"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "start", "=", "self", ".", "_rank", "\n", "yield", "from", "itertools", ".", "islice", "(", "self", ".", "_infinite_indices", "(", ")", ",", "start", ",", "None", ",", "self", ".", "_world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.TrainingSampler._infinite_indices": [[47, 55], ["torch.Generator", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.arange().tolist", "torch.randperm", "torch.arange"], "methods", ["None"], ["", "def", "_infinite_indices", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "_seed", ")", "\n", "while", "True", ":", "\n", "            ", "if", "self", ".", "_shuffle", ":", "\n", "                ", "yield", "from", "torch", ".", "randperm", "(", "self", ".", "_size", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "yield", "from", "torch", ".", "arange", "(", "self", ".", "_size", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler.__init__": [[63, 84], ["int", "detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "torch.trunc", "detectron2.utils.comm.shared_random_seed"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.shared_random_seed"], ["def", "__init__", "(", "self", ",", "repeat_factors", ",", "*", ",", "shuffle", "=", "True", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            repeat_factors (Tensor): a float vector, the repeat factor for each indice. When it's\n                full of ones, it is equivalent to ``TrainingSampler(len(repeat_factors), ...)``.\n            shuffle (bool): whether to shuffle the indices or not\n            seed (int): the initial seed of the shuffle. Must be the same\n                across all workers. If None, will use a random seed shared\n                among workers (require synchronization among all workers).\n        \"\"\"", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "comm", ".", "shared_random_seed", "(", ")", "\n", "", "self", ".", "_seed", "=", "int", "(", "seed", ")", "\n", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n", "# Split into whole number (_int_part) and fractional (_frac_part) parts.", "\n", "self", ".", "_int_part", "=", "torch", ".", "trunc", "(", "repeat_factors", ")", "\n", "self", ".", "_frac_part", "=", "repeat_factors", "-", "self", ".", "_int_part", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency": [[85, 131], ["collections.defaultdict", "len", "collections.defaultdict.items", "torch.tensor", "max", "max", "rep_factors.append", "math.sqrt", "collections.defaultdict.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "@", "staticmethod", "\n", "def", "repeat_factors_from_category_frequency", "(", "dataset_dicts", ",", "repeat_thresh", ")", ":", "\n", "        ", "\"\"\"\n        Compute (fractional) per-image repeat factors based on category frequency.\n        The repeat factor for an image is a function of the frequency of the rarest\n        category labeled in that image. The \"frequency of category c\" in [0, 1] is defined\n        as the fraction of images in the training set (without repeats) in which category c\n        appears.\n        See :paper:`lvis` (>= v2) Appendix B.2.\n\n        Args:\n            dataset_dicts (list[dict]): annotations in Detectron2 dataset format.\n            repeat_thresh (float): frequency threshold below which data is repeated.\n                If the frequency is half of `repeat_thresh`, the image will be\n                repeated twice.\n\n        Returns:\n            torch.Tensor:\n                the i-th element is the repeat factor for the dataset image at index i.\n        \"\"\"", "\n", "# 1. For each category c, compute the fraction of images that contain it: f(c)", "\n", "category_freq", "=", "defaultdict", "(", "int", ")", "\n", "for", "dataset_dict", "in", "dataset_dicts", ":", "# For each image (without repeats)", "\n", "            ", "cat_ids", "=", "{", "ann", "[", "\"category_id\"", "]", "for", "ann", "in", "dataset_dict", "[", "\"annotations\"", "]", "}", "\n", "for", "cat_id", "in", "cat_ids", ":", "\n", "                ", "category_freq", "[", "cat_id", "]", "+=", "1", "\n", "", "", "num_images", "=", "len", "(", "dataset_dicts", ")", "\n", "for", "k", ",", "v", "in", "category_freq", ".", "items", "(", ")", ":", "\n", "            ", "category_freq", "[", "k", "]", "=", "v", "/", "num_images", "\n", "\n", "# 2. For each category c, compute the category-level repeat factor:", "\n", "#    r(c) = max(1, sqrt(t / f(c)))", "\n", "", "category_rep", "=", "{", "\n", "cat_id", ":", "max", "(", "1.0", ",", "math", ".", "sqrt", "(", "repeat_thresh", "/", "cat_freq", ")", ")", "\n", "for", "cat_id", ",", "cat_freq", "in", "category_freq", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# 3. For each image I, compute the image-level repeat factor:", "\n", "#    r(I) = max_{c in I} r(c)", "\n", "rep_factors", "=", "[", "]", "\n", "for", "dataset_dict", "in", "dataset_dicts", ":", "\n", "            ", "cat_ids", "=", "{", "ann", "[", "\"category_id\"", "]", "for", "ann", "in", "dataset_dict", "[", "\"annotations\"", "]", "}", "\n", "rep_factor", "=", "max", "(", "{", "category_rep", "[", "cat_id", "]", "for", "cat_id", "in", "cat_ids", "}", ",", "default", "=", "1.0", ")", "\n", "rep_factors", ".", "append", "(", "rep_factor", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "rep_factors", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices": [[132, 154], ["torch.rand", "enumerate", "torch.tensor", "len", "indices.extend", "int", "rep_factor.item"], "methods", ["None"], ["", "def", "_get_epoch_indices", "(", "self", ",", "generator", ")", ":", "\n", "        ", "\"\"\"\n        Create a list of dataset indices (with repeats) to use for one epoch.\n\n        Args:\n            generator (torch.Generator): pseudo random number generator used for\n                stochastic rounding.\n\n        Returns:\n            torch.Tensor: list of dataset indices to use in one epoch. Each index\n                is repeated based on its calculated repeat factor.\n        \"\"\"", "\n", "# Since repeat factors are fractional, we use stochastic rounding so", "\n", "# that the target repeat factor is achieved in expectation over the", "\n", "# course of training", "\n", "rands", "=", "torch", ".", "rand", "(", "len", "(", "self", ".", "_frac_part", ")", ",", "generator", "=", "generator", ")", "\n", "rep_factors", "=", "self", ".", "_int_part", "+", "(", "rands", "<", "self", ".", "_frac_part", ")", ".", "float", "(", ")", "\n", "# Construct a list of indices in which we repeat images as specified", "\n", "indices", "=", "[", "]", "\n", "for", "dataset_index", ",", "rep_factor", "in", "enumerate", "(", "rep_factors", ")", ":", "\n", "            ", "indices", ".", "extend", "(", "[", "dataset_index", "]", "*", "int", "(", "rep_factor", ".", "item", "(", ")", ")", ")", "\n", "", "return", "torch", ".", "tensor", "(", "indices", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler.__iter__": [[155, 158], ["itertools.islice", "distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "start", "=", "self", ".", "_rank", "\n", "yield", "from", "itertools", ".", "islice", "(", "self", ".", "_infinite_indices", "(", ")", ",", "start", ",", "None", ",", "self", ".", "_world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices": [[159, 171], ["torch.Generator", "torch.Generator.manual_seed", "distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices", "torch.randperm", "len", "indices[].tolist", "distributed_sampler.RepeatFactorTrainingSampler.tolist"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices"], ["", "def", "_infinite_indices", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "_seed", ")", "\n", "while", "True", ":", "\n", "# Sample indices with repeats determined by stochastic rounding; each", "\n", "# \"epoch\" may have a slightly different size due to the rounding.", "\n", "            ", "indices", "=", "self", ".", "_get_epoch_indices", "(", "g", ")", "\n", "if", "self", ".", "_shuffle", ":", "\n", "                ", "randperm", "=", "torch", ".", "randperm", "(", "len", "(", "indices", ")", ",", "generator", "=", "g", ")", "\n", "yield", "from", "indices", "[", "randperm", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "yield", "from", "indices", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.InferenceSampler.__init__": [[181, 195], ["detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "min", "range"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["def", "__init__", "(", "self", ",", "size", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n        \"\"\"", "\n", "self", ".", "_size", "=", "size", "\n", "assert", "size", ">", "0", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n", "shard_size", "=", "(", "self", ".", "_size", "-", "1", ")", "//", "self", ".", "_world_size", "+", "1", "\n", "begin", "=", "shard_size", "*", "self", ".", "_rank", "\n", "end", "=", "min", "(", "shard_size", "*", "(", "self", ".", "_rank", "+", "1", ")", ",", "self", ".", "_size", ")", "\n", "self", ".", "_local_indices", "=", "range", "(", "begin", ",", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.InferenceSampler.__iter__": [[196, 198], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "_local_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.samplers.distributed_sampler.InferenceSampler.__len__": [[199, 201], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_local_indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomApply.__init__": [[47, 60], ["augmentation.Augmentation.__init__", "augmentation._transform_to_aug"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._transform_to_aug"], ["def", "__init__", "(", "self", ",", "tfm_or_aug", ",", "prob", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tfm_or_aug (Transform, Augmentation): the transform or augmentation\n                to be applied. It can either be a `Transform` or `Augmentation`\n                instance.\n            prob (float): probability between 0.0 and 1.0 that\n                the wrapper transformation is applied\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "aug", "=", "_transform_to_aug", "(", "tfm_or_aug", ")", "\n", "assert", "0.0", "<=", "prob", "<=", "1.0", ",", "f\"Probablity must be between 0.0 and 1.0 (given: {prob})\"", "\n", "self", ".", "prob", "=", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomApply.get_transform": [[61, 67], ["augmentation_impl.RandomApply._rand_range", "augmentation_impl.RandomApply.aug.get_transform", "fvcore.transforms.transform.NoOpTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._rand_range", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.get_transform"], ["", "def", "get_transform", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "return", "self", ".", "aug", ".", "get_transform", "(", "*", "args", ")", "\n", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomApply.__call__": [[68, 74], ["augmentation_impl.RandomApply._rand_range", "augmentation_impl.RandomApply.aug", "fvcore.transforms.transform.NoOpTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._rand_range"], ["", "", "def", "__call__", "(", "self", ",", "aug_input", ")", ":", "\n", "        ", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "return", "self", ".", "aug", "(", "aug_input", ")", "\n", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomFlip.__init__": [[81, 95], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomFlip._init", "ValueError", "ValueError", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "prob", "=", "0.5", ",", "*", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prob (float): probability of flip.\n            horizontal (boolean): whether to apply horizontal flipping\n            vertical (boolean): whether to apply vertical flipping\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "horizontal", "and", "vertical", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot do both horiz and vert. Please use two Flip instead.\"", ")", "\n", "", "if", "not", "horizontal", "and", "not", "vertical", ":", "\n", "            ", "raise", "ValueError", "(", "\"At least one of horiz or vert has to be True!\"", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomFlip.get_transform": [[96, 106], ["augmentation_impl.RandomFlip._rand_range", "fvcore.transforms.transform.NoOpTransform", "fvcore.transforms.transform.HFlipTransform", "fvcore.transforms.transform.VFlipTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._rand_range"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "if", "self", ".", "horizontal", ":", "\n", "                ", "return", "HFlipTransform", "(", "w", ")", "\n", "", "elif", "self", ".", "vertical", ":", "\n", "                ", "return", "VFlipTransform", "(", "h", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.Resize.__init__": [[111, 121], ["isinstance", "tuple", "augmentation_impl.Resize._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "shape", ",", "interp", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            shape: (h, w) tuple or a int\n            interp: PIL interpolation method\n        \"\"\"", "\n", "if", "isinstance", "(", "shape", ",", "int", ")", ":", "\n", "            ", "shape", "=", "(", "shape", ",", "shape", ")", "\n", "", "shape", "=", "tuple", "(", "shape", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.Resize.get_transform": [[122, 125], ["transform.ResizeTransform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "ResizeTransform", "(", "\n", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "self", ".", "shape", "[", "0", "]", ",", "self", ".", "shape", "[", "1", "]", ",", "self", ".", "interp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeShortestEdge.__init__": [[136, 160], ["augmentation.Augmentation.__init__", "isinstance", "augmentation_impl.ResizeShortestEdge._init", "locals", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["@", "torch", ".", "jit", ".", "unused", "\n", "def", "__init__", "(", "\n", "self", ",", "short_edge_length", ",", "max_size", "=", "sys", ".", "maxsize", ",", "sample_style", "=", "\"range\"", ",", "interp", "=", "Image", ".", "BILINEAR", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            short_edge_length (list[int]): If ``sample_style==\"range\"``,\n                a [min, max] interval from which to sample the shortest edge length.\n                If ``sample_style==\"choice\"``, a list of shortest edge lengths to sample from.\n            max_size (int): maximum allowed longest edge length.\n            sample_style (str): either \"range\" or \"choice\".\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "sample_style", "in", "[", "\"range\"", ",", "\"choice\"", "]", ",", "sample_style", "\n", "\n", "self", ".", "is_range", "=", "sample_style", "==", "\"range\"", "\n", "if", "isinstance", "(", "short_edge_length", ",", "int", ")", ":", "\n", "            ", "short_edge_length", "=", "(", "short_edge_length", ",", "short_edge_length", ")", "\n", "", "if", "self", ".", "is_range", ":", "\n", "            ", "assert", "len", "(", "short_edge_length", ")", "==", "2", ",", "(", "\n", "\"short_edge_length must be two values using 'range' sample style.\"", "\n", "f\" Got {short_edge_length}!\"", "\n", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeShortestEdge.get_transform": [[161, 173], ["augmentation_impl.ResizeShortestEdge.get_output_shape", "transform.ResizeTransform", "numpy.random.randint", "numpy.random.choice", "fvcore.transforms.transform.NoOpTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeShortestEdge.get_output_shape"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "if", "self", ".", "is_range", ":", "\n", "            ", "size", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "short_edge_length", "[", "0", "]", ",", "self", ".", "short_edge_length", "[", "1", "]", "+", "1", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "short_edge_length", ")", "\n", "", "if", "size", "==", "0", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n", "", "newh", ",", "neww", "=", "ResizeShortestEdge", ".", "get_output_shape", "(", "h", ",", "w", ",", "size", ",", "self", ".", "max_size", ")", "\n", "return", "ResizeTransform", "(", "h", ",", "w", ",", "newh", ",", "neww", ",", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeShortestEdge.get_output_shape": [[174, 195], ["int", "int", "min", "max", "max"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "@", "staticmethod", "\n", "def", "get_output_shape", "(", "\n", "oldh", ":", "int", ",", "oldw", ":", "int", ",", "short_edge_length", ":", "int", ",", "max_size", ":", "int", "\n", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Compute the output size given input size and target short edge length.\n        \"\"\"", "\n", "h", ",", "w", "=", "oldh", ",", "oldw", "\n", "size", "=", "short_edge_length", "*", "1.0", "\n", "scale", "=", "size", "/", "min", "(", "h", ",", "w", ")", "\n", "if", "h", "<", "w", ":", "\n", "            ", "newh", ",", "neww", "=", "size", ",", "scale", "*", "w", "\n", "", "else", ":", "\n", "            ", "newh", ",", "neww", "=", "scale", "*", "h", ",", "size", "\n", "", "if", "max", "(", "newh", ",", "neww", ")", ">", "max_size", ":", "\n", "            ", "scale", "=", "max_size", "*", "1.0", "/", "max", "(", "newh", ",", "neww", ")", "\n", "newh", "=", "newh", "*", "scale", "\n", "neww", "=", "neww", "*", "scale", "\n", "", "neww", "=", "int", "(", "neww", "+", "0.5", ")", "\n", "newh", "=", "int", "(", "newh", "+", "0.5", ")", "\n", "return", "(", "newh", ",", "neww", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeScale.__init__": [[206, 224], ["augmentation.Augmentation.__init__", "augmentation_impl.ResizeScale._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "\n", "self", ",", "\n", "min_scale", ":", "float", ",", "\n", "max_scale", ":", "float", ",", "\n", "target_height", ":", "int", ",", "\n", "target_width", ":", "int", ",", "\n", "interp", ":", "int", "=", "Image", ".", "BILINEAR", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            min_scale: minimum image scale range.\n            max_scale: maximum image scale range.\n            target_height: target image height.\n            target_width: target image width.\n            interp: image interpolation method.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeScale._get_resize": [[225, 240], ["numpy.multiply", "numpy.minimum", "numpy.round().astype", "transform.ResizeTransform", "numpy.round", "numpy.multiply"], "methods", ["None"], ["", "def", "_get_resize", "(", "self", ",", "image", ":", "np", ".", "ndarray", ",", "scale", ":", "float", ")", "->", "Transform", ":", "\n", "        ", "input_size", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Compute new target size given a scale.", "\n", "target_size", "=", "(", "self", ".", "target_height", ",", "self", ".", "target_width", ")", "\n", "target_scale_size", "=", "np", ".", "multiply", "(", "target_size", ",", "scale", ")", "\n", "\n", "# Compute actual rescaling applied to input image and output size.", "\n", "output_scale", "=", "np", ".", "minimum", "(", "\n", "target_scale_size", "[", "0", "]", "/", "input_size", "[", "0", "]", ",", "target_scale_size", "[", "1", "]", "/", "input_size", "[", "1", "]", "\n", ")", "\n", "output_size", "=", "np", ".", "round", "(", "np", ".", "multiply", "(", "input_size", ",", "output_scale", ")", ")", ".", "astype", "(", "int", ")", "\n", "\n", "return", "ResizeTransform", "(", "\n", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", ",", "output_size", "[", "0", "]", ",", "output_size", "[", "1", "]", ",", "self", ".", "interp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeScale.get_transform": [[242, 245], ["numpy.random.uniform", "augmentation_impl.ResizeScale._get_resize"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.ResizeScale._get_resize"], ["", "def", "get_transform", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", "->", "Transform", ":", "\n", "        ", "random_scale", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "min_scale", ",", "self", ".", "max_scale", ")", "\n", "return", "self", ".", "_get_resize", "(", "image", ",", "random_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomRotation.__init__": [[253, 276], ["augmentation.Augmentation.__init__", "isinstance", "augmentation_impl.RandomRotation._init", "isinstance", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "angle", ",", "expand", "=", "True", ",", "center", "=", "None", ",", "sample_style", "=", "\"range\"", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            angle (list[float]): If ``sample_style==\"range\"``,\n                a [min, max] interval from which to sample the angle (in degrees).\n                If ``sample_style==\"choice\"``, a list of angles to sample from\n            expand (bool): choose if the image should be resized to fit the whole\n                rotated image (default), or simply cropped\n            center (list[[float, float]]):  If ``sample_style==\"range\"``,\n                a [[minx, miny], [maxx, maxy]] relative interval from which to sample the center,\n                [0, 0] being the top left of the image and [1, 1] the bottom right.\n                If ``sample_style==\"choice\"``, a list of centers to sample from\n                Default: None, which means that the center of rotation is the center of the image\n                center has no effect if expand=True because it only affects shifting\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "sample_style", "in", "[", "\"range\"", ",", "\"choice\"", "]", ",", "sample_style", "\n", "self", ".", "is_range", "=", "sample_style", "==", "\"range\"", "\n", "if", "isinstance", "(", "angle", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "angle", "=", "(", "angle", ",", "angle", ")", "\n", "", "if", "center", "is", "not", "None", "and", "isinstance", "(", "center", "[", "0", "]", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "center", "=", "(", "center", ",", "center", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomRotation.get_transform": [[277, 299], ["transform.RotationTransform", "numpy.random.uniform", "numpy.random.choice", "fvcore.transforms.transform.NoOpTransform", "numpy.random.choice", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "center", "=", "None", "\n", "if", "self", ".", "is_range", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "angle", "[", "0", "]", ",", "self", ".", "angle", "[", "1", "]", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "(", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "0", "]", ",", "self", ".", "center", "[", "1", "]", "[", "0", "]", ")", ",", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "1", "]", ",", "self", ".", "center", "[", "1", "]", "[", "1", "]", ")", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "angle", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "center", ")", "\n", "\n", "", "", "if", "center", "is", "not", "None", ":", "\n", "            ", "center", "=", "(", "w", "*", "center", "[", "0", "]", ",", "h", "*", "center", "[", "1", "]", ")", "# Convert to absolute coordinates", "\n", "\n", "", "if", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n", "", "return", "RotationTransform", "(", "h", ",", "w", ",", "angle", ",", "expand", "=", "self", ".", "expand", ",", "center", "=", "center", ",", "interp", "=", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop.__init__": [[309, 318], ["augmentation.Augmentation.__init__", "augmentation_impl.FixedSizeCrop._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "crop_size", ":", "Tuple", "[", "int", "]", ",", "pad", ":", "bool", "=", "True", ",", "pad_value", ":", "float", "=", "128.0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            crop_size: target image (height, width).\n            pad: if True, will pad images smaller than `crop_size` up to `crop_size`\n            pad_value: the padding value.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop._get_crop": [[319, 331], ["numpy.subtract", "numpy.maximum", "numpy.multiply", "numpy.round().astype", "fvcore.transforms.transform.CropTransform", "numpy.random.uniform", "numpy.round"], "methods", ["None"], ["", "def", "_get_crop", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", "->", "Transform", ":", "\n", "# Compute the image scale and scaled size.", "\n", "        ", "input_size", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "output_size", "=", "self", ".", "crop_size", "\n", "\n", "# Add random crop if the image is scaled up.", "\n", "max_offset", "=", "np", ".", "subtract", "(", "input_size", ",", "output_size", ")", "\n", "max_offset", "=", "np", ".", "maximum", "(", "max_offset", ",", "0", ")", "\n", "offset", "=", "np", ".", "multiply", "(", "max_offset", ",", "np", ".", "random", ".", "uniform", "(", "0.0", ",", "1.0", ")", ")", "\n", "offset", "=", "np", ".", "round", "(", "offset", ")", ".", "astype", "(", "int", ")", "\n", "return", "CropTransform", "(", "\n", "offset", "[", "1", "]", ",", "offset", "[", "0", "]", ",", "output_size", "[", "1", "]", ",", "output_size", "[", "0", "]", ",", "input_size", "[", "1", "]", ",", "input_size", "[", "0", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop._get_pad": [[333, 344], ["numpy.subtract", "numpy.maximum", "numpy.minimum", "fvcore.transforms.transform.PadTransform"], "methods", ["None"], ["", "def", "_get_pad", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", "->", "Transform", ":", "\n", "# Compute the image scale and scaled size.", "\n", "        ", "input_size", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "output_size", "=", "self", ".", "crop_size", "\n", "\n", "# Add padding if the image is scaled down.", "\n", "pad_size", "=", "np", ".", "subtract", "(", "output_size", ",", "input_size", ")", "\n", "pad_size", "=", "np", ".", "maximum", "(", "pad_size", ",", "0", ")", "\n", "original_size", "=", "np", ".", "minimum", "(", "input_size", ",", "output_size", ")", "\n", "return", "PadTransform", "(", "\n", "0", ",", "0", ",", "pad_size", "[", "1", "]", ",", "pad_size", "[", "0", "]", ",", "original_size", "[", "1", "]", ",", "original_size", "[", "0", "]", ",", "self", ".", "pad_value", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop.get_transform": [[346, 351], ["fvcore.transforms.transform.TransformList", "augmentation_impl.FixedSizeCrop._get_crop", "transforms.append", "augmentation_impl.FixedSizeCrop._get_pad"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop._get_crop", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.FixedSizeCrop._get_pad"], ["", "def", "get_transform", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", "->", "TransformList", ":", "\n", "        ", "transforms", "=", "[", "self", ".", "_get_crop", "(", "image", ")", "]", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "transforms", ".", "append", "(", "self", ".", "_get_pad", "(", "image", ")", ")", "\n", "", "return", "TransformList", "(", "transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop.__init__": [[358, 378], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomCrop._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "crop_type", ":", "str", ",", "crop_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            crop_type (str): one of \"relative_range\", \"relative\", \"absolute\", \"absolute_range\".\n            crop_size (tuple[float, float]): two floats, explained below.\n        - \"relative\": crop a (H * crop_size[0], W * crop_size[1]) region from an input image of\n          size (H, W). crop size should be in (0, 1]\n        - \"relative_range\": uniformly sample two values from [crop_size[0], 1]\n          and [crop_size[1]], 1], and use them as in \"relative\" crop type.\n        - \"absolute\" crop a (crop_size[0], crop_size[1]) region from input image.\n          crop_size must be smaller than the input image size.\n        - \"absolute_range\", for an input of size (H, W), uniformly sample H_crop in\n          [crop_size[0], min(H, crop_size[1])] and W_crop in [crop_size[0], min(W, crop_size[1])].\n          Then crop a region (H_crop, W_crop).\n        \"\"\"", "\n", "# TODO style of relative_range and absolute_range are not consistent:", "\n", "# one takes (h, w) but another takes (min, max)", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "crop_type", "in", "[", "\"relative_range\"", ",", "\"relative\"", ",", "\"absolute\"", ",", "\"absolute_range\"", "]", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop.get_transform": [[379, 386], ["augmentation_impl.RandomCrop.get_crop_size", "numpy.random.randint", "numpy.random.randint", "fvcore.transforms.transform.CropTransform"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop.get_crop_size"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "croph", ",", "cropw", "=", "self", ".", "get_crop_size", "(", "(", "h", ",", "w", ")", ")", "\n", "assert", "h", ">=", "croph", "and", "w", ">=", "cropw", ",", "\"Shape computation in {} has bugs.\"", ".", "format", "(", "self", ")", "\n", "h0", "=", "np", ".", "random", ".", "randint", "(", "h", "-", "croph", "+", "1", ")", "\n", "w0", "=", "np", ".", "random", ".", "randint", "(", "w", "-", "cropw", "+", "1", ")", "\n", "return", "CropTransform", "(", "w0", ",", "h0", ",", "cropw", ",", "croph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop.get_crop_size": [[387, 411], ["int", "int", "numpy.asarray", "int", "int", "numpy.random.rand", "min", "min", "numpy.random.randint", "numpy.random.randint", "NotImplementedError", "min", "min", "min", "min"], "methods", ["None"], ["", "def", "get_crop_size", "(", "self", ",", "image_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_size (tuple): height, width\n        Returns:\n            crop_size (tuple): height, width in absolute pixels\n        \"\"\"", "\n", "h", ",", "w", "=", "image_size", "\n", "if", "self", ".", "crop_type", "==", "\"relative\"", ":", "\n", "            ", "ch", ",", "cw", "=", "self", ".", "crop_size", "\n", "return", "int", "(", "h", "*", "ch", "+", "0.5", ")", ",", "int", "(", "w", "*", "cw", "+", "0.5", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"relative_range\"", ":", "\n", "            ", "crop_size", "=", "np", ".", "asarray", "(", "self", ".", "crop_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ch", ",", "cw", "=", "crop_size", "+", "np", ".", "random", ".", "rand", "(", "2", ")", "*", "(", "1", "-", "crop_size", ")", "\n", "return", "int", "(", "h", "*", "ch", "+", "0.5", ")", ",", "int", "(", "w", "*", "cw", "+", "0.5", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"absolute\"", ":", "\n", "            ", "return", "(", "min", "(", "self", ".", "crop_size", "[", "0", "]", ",", "h", ")", ",", "min", "(", "self", ".", "crop_size", "[", "1", "]", ",", "w", ")", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"absolute_range\"", ":", "\n", "            ", "assert", "self", ".", "crop_size", "[", "0", "]", "<=", "self", ".", "crop_size", "[", "1", "]", "\n", "ch", "=", "np", ".", "random", ".", "randint", "(", "min", "(", "h", ",", "self", ".", "crop_size", "[", "0", "]", ")", ",", "min", "(", "h", ",", "self", ".", "crop_size", "[", "1", "]", ")", "+", "1", ")", "\n", "cw", "=", "np", ".", "random", ".", "randint", "(", "min", "(", "w", ",", "self", ".", "crop_size", "[", "0", "]", ")", ",", "min", "(", "w", ",", "self", ".", "crop_size", "[", "1", "]", ")", "+", "1", ")", "\n", "return", "ch", ",", "cw", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Unknown crop type {}\"", ".", "format", "(", "self", ".", "crop_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint.__init__": [[421, 439], ["augmentation_impl.RandomCrop", "augmentation_impl.RandomCrop_CategoryAreaConstraint._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "\n", "self", ",", "\n", "crop_type", ":", "str", ",", "\n", "crop_size", ",", "\n", "single_category_max_area", ":", "float", "=", "1.0", ",", "\n", "ignored_category", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            crop_type, crop_size: same as in :class:`RandomCrop`\n            single_category_max_area: the maximum allowed area ratio of a\n                category. Set to 1.0 to disable\n            ignored_category: allow this category in the semantic segmentation\n                ground truth to exceed the area ratio. Usually set to the category\n                that's ignored in training.\n        \"\"\"", "\n", "self", ".", "crop_aug", "=", "RandomCrop", "(", "crop_type", ",", "crop_size", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint.get_transform": [[440, 457], ["augmentation_impl.RandomCrop_CategoryAreaConstraint.crop_aug.get_transform", "range", "fvcore.transforms.transform.CropTransform", "augmentation_impl.RandomCrop_CategoryAreaConstraint.crop_aug.get_crop_size", "numpy.random.randint", "numpy.random.randint", "numpy.unique", "len", "numpy.max", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.get_transform", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomCrop.get_crop_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "get_transform", "(", "self", ",", "image", ",", "sem_seg", ")", ":", "\n", "        ", "if", "self", ".", "single_category_max_area", ">=", "1.0", ":", "\n", "            ", "return", "self", ".", "crop_aug", ".", "get_transform", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "w", "=", "sem_seg", ".", "shape", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "crop_size", "=", "self", ".", "crop_aug", ".", "get_crop_size", "(", "(", "h", ",", "w", ")", ")", "\n", "y0", "=", "np", ".", "random", ".", "randint", "(", "h", "-", "crop_size", "[", "0", "]", "+", "1", ")", "\n", "x0", "=", "np", ".", "random", ".", "randint", "(", "w", "-", "crop_size", "[", "1", "]", "+", "1", ")", "\n", "sem_seg_temp", "=", "sem_seg", "[", "y0", ":", "y0", "+", "crop_size", "[", "0", "]", ",", "x0", ":", "x0", "+", "crop_size", "[", "1", "]", "]", "\n", "labels", ",", "cnt", "=", "np", ".", "unique", "(", "sem_seg_temp", ",", "return_counts", "=", "True", ")", "\n", "if", "self", ".", "ignored_category", "is", "not", "None", ":", "\n", "                    ", "cnt", "=", "cnt", "[", "labels", "!=", "self", ".", "ignored_category", "]", "\n", "", "if", "len", "(", "cnt", ")", ">", "1", "and", "np", ".", "max", "(", "cnt", ")", "<", "np", ".", "sum", "(", "cnt", ")", "*", "self", ".", "single_category_max_area", ":", "\n", "                    ", "break", "\n", "", "", "crop_tfm", "=", "CropTransform", "(", "x0", ",", "y0", ",", "crop_size", "[", "1", "]", ",", "crop_size", "[", "0", "]", ")", "\n", "return", "crop_tfm", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomExtent.__init__": [[467, 479], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomExtent._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "scale_range", ",", "shift_range", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (h, w): Dimensions of output image\n            scale_range (l, h): Range of input-to-output size scaling factor\n            shift_range (x, y): Range of shifts of the cropped subrect. The rect\n                is shifted by [w / 2 * Uniform(-x, x), h / 2 * Uniform(-y, y)],\n                where (w, h) is the (width, height) of the input image. Set each\n                component to zero to crop at the image's center.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomExtent.get_transform": [[480, 500], ["numpy.array", "numpy.random.uniform", "transform.ExtentTransform", "numpy.random.rand", "numpy.random.rand", "int", "int"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "img_h", ",", "img_w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Initialize src_rect to fit the input image.", "\n", "src_rect", "=", "np", ".", "array", "(", "[", "-", "0.5", "*", "img_w", ",", "-", "0.5", "*", "img_h", ",", "0.5", "*", "img_w", ",", "0.5", "*", "img_h", "]", ")", "\n", "\n", "# Apply a random scaling to the src_rect.", "\n", "src_rect", "*=", "np", ".", "random", ".", "uniform", "(", "self", ".", "scale_range", "[", "0", "]", ",", "self", ".", "scale_range", "[", "1", "]", ")", "\n", "\n", "# Apply a random shift to the coordinates origin.", "\n", "src_rect", "[", "0", ":", ":", "2", "]", "+=", "self", ".", "shift_range", "[", "0", "]", "*", "img_w", "*", "(", "np", ".", "random", ".", "rand", "(", ")", "-", "0.5", ")", "\n", "src_rect", "[", "1", ":", ":", "2", "]", "+=", "self", ".", "shift_range", "[", "1", "]", "*", "img_h", "*", "(", "np", ".", "random", ".", "rand", "(", ")", "-", "0.5", ")", "\n", "\n", "# Map src_rect coordinates into image coordinates (center at corner).", "\n", "src_rect", "[", "0", ":", ":", "2", "]", "+=", "0.5", "*", "img_w", "\n", "src_rect", "[", "1", ":", ":", "2", "]", "+=", "0.5", "*", "img_h", "\n", "\n", "return", "ExtentTransform", "(", "\n", "src_rect", "=", "(", "src_rect", "[", "0", "]", ",", "src_rect", "[", "1", "]", ",", "src_rect", "[", "2", "]", ",", "src_rect", "[", "3", "]", ")", ",", "\n", "output_size", "=", "(", "int", "(", "src_rect", "[", "3", "]", "-", "src_rect", "[", "1", "]", ")", ",", "int", "(", "src_rect", "[", "2", "]", "-", "src_rect", "[", "0", "]", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomContrast.__init__": [[513, 521], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomContrast._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation\n            intensity_max (float): Maximum augmentation\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomContrast.get_transform": [[522, 525], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform", "image.mean"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "return", "BlendTransform", "(", "src_image", "=", "image", ".", "mean", "(", ")", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomBrightness.__init__": [[537, 545], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomBrightness._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation\n            intensity_max (float): Maximum augmentation\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomBrightness.get_transform": [[546, 549], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "return", "BlendTransform", "(", "src_image", "=", "0", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomSaturation.__init__": [[562, 570], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomSaturation._init", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation (1 preserves input).\n            intensity_max (float): Maximum augmentation (1 preserves input).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomSaturation.get_transform": [[571, 576], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform", "image.dot"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "assert", "image", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "\"RandomSaturation only works on RGB images\"", "\n", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "grayscale", "=", "image", ".", "dot", "(", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "return", "BlendTransform", "(", "src_image", "=", "grayscale", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomLighting.__init__": [[586, 597], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomLighting._init", "numpy.array", "numpy.array", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "scale", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            scale (float): Standard deviation of principal component weighting.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "self", ".", "eigen_vecs", "=", "np", ".", "array", "(", "\n", "[", "[", "-", "0.5675", ",", "0.7192", ",", "0.4009", "]", ",", "[", "-", "0.5808", ",", "-", "0.0045", ",", "-", "0.8140", "]", ",", "[", "-", "0.5836", ",", "-", "0.6948", ",", "0.4203", "]", "]", "\n", ")", "\n", "self", ".", "eigen_vals", "=", "np", ".", "array", "(", "[", "0.2175", ",", "0.0188", ",", "0.0045", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation_impl.RandomLighting.get_transform": [[598, 603], ["numpy.random.normal", "fvcore.transforms.transform.BlendTransform", "augmentation_impl.RandomLighting.eigen_vecs.dot"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "assert", "image", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "\"RandomLighting only works on RGB images\"", "\n", "weights", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "self", ".", "scale", ",", "size", "=", "3", ")", "\n", "return", "BlendTransform", "(", "\n", "src_image", "=", "self", ".", "eigen_vecs", ".", "dot", "(", "weights", "*", "self", ".", "eigen_vals", ")", ",", "src_weight", "=", "1.0", ",", "dst_weight", "=", "1.0", "\n", ")", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ExtentTransform.__init__": [[46, 56], ["fvcore.transforms.transform.Transform.__init__", "transform.ExtentTransform._set_attributes", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "src_rect", ",", "output_size", ",", "interp", "=", "Image", ".", "LINEAR", ",", "fill", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_rect (x0, y0, x1, y1): src coordinates\n            output_size (h, w): dst image size\n            interp: PIL interpolation methods\n            fill: Fill color used when src_rect extends outside image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ExtentTransform.apply_image": [[57, 74], ["PIL.Image.fromarray.transform", "numpy.asarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "numpy.expand_dims", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.transform"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "h", ",", "w", "=", "self", ".", "output_size", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "            ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", "[", ":", ",", ":", ",", "0", "]", ",", "mode", "=", "\"L\"", ")", "\n", "", "else", ":", "\n", "            ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "", "pil_image", "=", "pil_image", ".", "transform", "(", "\n", "size", "=", "(", "w", ",", "h", ")", ",", "\n", "method", "=", "Image", ".", "EXTENT", ",", "\n", "data", "=", "self", ".", "src_rect", ",", "\n", "resample", "=", "interp", "if", "interp", "else", "self", ".", "interp", ",", "\n", "fill", "=", "self", ".", "fill", ",", "\n", ")", "\n", "ret", "=", "np", ".", "asarray", "(", "pil_image", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "            ", "ret", "=", "np", ".", "expand_dims", "(", "ret", ",", "-", "1", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ExtentTransform.apply_coords": [[75, 88], ["coords.astype"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "# Transform image center from source coordinates into output coordinates", "\n", "# and then map the new origin to the corner of the output image.", "\n", "        ", "h", ",", "w", "=", "self", ".", "output_size", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "self", ".", "src_rect", "\n", "new_coords", "=", "coords", ".", "astype", "(", "np", ".", "float32", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "-=", "0.5", "*", "(", "x0", "+", "x1", ")", "\n", "new_coords", "[", ":", ",", "1", "]", "-=", "0.5", "*", "(", "y0", "+", "y1", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "*=", "w", "/", "(", "x1", "-", "x0", ")", "\n", "new_coords", "[", ":", ",", "1", "]", "*=", "h", "/", "(", "y1", "-", "y0", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "+=", "0.5", "*", "w", "\n", "new_coords", "[", ":", ",", "1", "]", "+=", "0.5", "*", "h", "\n", "return", "new_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ExtentTransform.apply_segmentation": [[89, 92], ["transform.ExtentTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "Image", ".", "NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ResizeTransform.__init__": [[99, 111], ["fvcore.transforms.transform.Transform.__init__", "transform.ResizeTransform._set_attributes", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "h", ",", "w", ",", "new_h", ",", "new_w", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h, w (int): original image size\n            new_h, new_w (int): new image size\n            interp: PIL interpolation methods, defaults to bilinear.\n        \"\"\"", "\n", "# TODO decide on PIL vs opencv", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "interp", "is", "None", ":", "\n", "            ", "interp", "=", "Image", ".", "BILINEAR", "\n", "", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ResizeTransform.apply_image": [[112, 148], ["len", "PIL.Image.fromarray.resize", "numpy.asarray", "any", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "list", "numpy.ascontiguousarray.view().permute", "torch.interpolate", "torch.interpolate", "numpy.ascontiguousarray.permute().view().numpy", "PIL.Image.fromarray", "PIL.Image.fromarray", "numpy.expand_dims", "numpy.ascontiguousarray", "len", "len", "numpy.ascontiguousarray.view", "numpy.ascontiguousarray.permute().view", "len", "numpy.ascontiguousarray.permute"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "assert", "img", ".", "shape", "[", ":", "2", "]", "==", "(", "self", ".", "h", ",", "self", ".", "w", ")", "\n", "assert", "len", "(", "img", ".", "shape", ")", "<=", "4", "\n", "interp_method", "=", "interp", "if", "interp", "is", "not", "None", "else", "self", ".", "interp", "\n", "\n", "if", "img", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "            ", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", "[", ":", ",", ":", ",", "0", "]", ",", "mode", "=", "\"L\"", ")", "\n", "", "else", ":", "\n", "                ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "", "pil_image", "=", "pil_image", ".", "resize", "(", "(", "self", ".", "new_w", ",", "self", ".", "new_h", ")", ",", "interp_method", ")", "\n", "ret", "=", "np", ".", "asarray", "(", "pil_image", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                ", "ret", "=", "np", ".", "expand_dims", "(", "ret", ",", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# PIL only supports uint8", "\n", "            ", "if", "any", "(", "x", "<", "0", "for", "x", "in", "img", ".", "strides", ")", ":", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", "\n", "shape", "=", "list", "(", "img", ".", "shape", ")", "\n", "shape_4d", "=", "shape", "[", ":", "2", "]", "+", "[", "1", "]", "*", "(", "4", "-", "len", "(", "shape", ")", ")", "+", "shape", "[", "2", ":", "]", "\n", "img", "=", "img", ".", "view", "(", "shape_4d", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "# hw(c) -> nchw", "\n", "_PIL_RESIZE_TO_INTERPOLATE_MODE", "=", "{", "\n", "Image", ".", "NEAREST", ":", "\"nearest\"", ",", "\n", "Image", ".", "BILINEAR", ":", "\"bilinear\"", ",", "\n", "Image", ".", "BICUBIC", ":", "\"bicubic\"", ",", "\n", "}", "\n", "mode", "=", "_PIL_RESIZE_TO_INTERPOLATE_MODE", "[", "interp_method", "]", "\n", "align_corners", "=", "None", "if", "mode", "==", "\"nearest\"", "else", "False", "\n", "img", "=", "F", ".", "interpolate", "(", "\n", "img", ",", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ")", ",", "mode", "=", "mode", ",", "align_corners", "=", "align_corners", "\n", ")", "\n", "shape", "[", ":", "2", "]", "=", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ")", "\n", "ret", "=", "img", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "view", "(", "shape", ")", ".", "numpy", "(", ")", "# nchw -> hw(c)", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ResizeTransform.apply_coords": [[149, 153], ["None"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "coords", "[", ":", ",", "0", "]", "=", "coords", "[", ":", ",", "0", "]", "*", "(", "self", ".", "new_w", "*", "1.0", "/", "self", ".", "w", ")", "\n", "coords", "[", ":", ",", "1", "]", "=", "coords", "[", ":", ",", "1", "]", "*", "(", "self", ".", "new_h", "*", "1.0", "/", "self", ".", "h", ")", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ResizeTransform.apply_segmentation": [[154, 157], ["transform.ResizeTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "Image", ".", "NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ResizeTransform.inverse": [[158, 160], ["transform.ResizeTransform"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "return", "ResizeTransform", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ",", "self", ".", "h", ",", "self", ".", "w", ",", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.__init__": [[168, 199], ["fvcore.transforms.transform.Transform.__init__", "numpy.array", "transform.RotationTransform._set_attributes", "transform.RotationTransform.create_rotation_matrix", "transform.RotationTransform.create_rotation_matrix", "abs", "abs", "numpy.rint().astype", "locals", "numpy.cos", "numpy.sin", "numpy.deg2rad", "numpy.deg2rad", "numpy.rint"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.create_rotation_matrix", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.create_rotation_matrix"], ["def", "__init__", "(", "self", ",", "h", ",", "w", ",", "angle", ",", "expand", "=", "True", ",", "center", "=", "None", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h, w (int): original image size\n            angle (float): degrees for rotation\n            expand (bool): choose if the image should be resized to fit the whole\n                rotated image (default), or simply cropped\n            center (tuple (width, height)): coordinates of the rotation center\n                if left to None, the center will be fit to the center of each image\n                center has no effect if expand=True because it only affects shifting\n            interp: cv2 interpolation method, default cv2.INTER_LINEAR\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "image_center", "=", "np", ".", "array", "(", "(", "w", "/", "2", ",", "h", "/", "2", ")", ")", "\n", "if", "center", "is", "None", ":", "\n", "            ", "center", "=", "image_center", "\n", "", "if", "interp", "is", "None", ":", "\n", "            ", "interp", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "abs_cos", ",", "abs_sin", "=", "(", "abs", "(", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ",", "abs", "(", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ")", "\n", "if", "expand", ":", "\n", "# find the new width and height bounds", "\n", "            ", "bound_w", ",", "bound_h", "=", "np", ".", "rint", "(", "\n", "[", "h", "*", "abs_sin", "+", "w", "*", "abs_cos", ",", "h", "*", "abs_cos", "+", "w", "*", "abs_sin", "]", "\n", ")", ".", "astype", "(", "int", ")", "\n", "", "else", ":", "\n", "            ", "bound_w", ",", "bound_h", "=", "w", ",", "h", "\n", "\n", "", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "self", ".", "rm_coords", "=", "self", ".", "create_rotation_matrix", "(", ")", "\n", "# Needed because of this problem https://github.com/opencv/opencv/issues/11784", "\n", "self", ".", "rm_image", "=", "self", ".", "create_rotation_matrix", "(", "offset", "=", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.apply_image": [[200, 209], ["cv2.warpAffine", "len"], "methods", ["None"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        img should be a numpy array, formatted as Height * Width * Nchannels\n        \"\"\"", "\n", "if", "len", "(", "img", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "img", "\n", "", "assert", "img", ".", "shape", "[", ":", "2", "]", "==", "(", "self", ".", "h", ",", "self", ".", "w", ")", "\n", "interp", "=", "interp", "if", "interp", "is", "not", "None", "else", "self", ".", "interp", "\n", "return", "cv2", ".", "warpAffine", "(", "img", ",", "self", ".", "rm_image", ",", "(", "self", ".", "bound_w", ",", "self", ".", "bound_h", ")", ",", "flags", "=", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.apply_coords": [[210, 218], ["numpy.asarray", "cv2.transform", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.transform"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "\"\"\"\n        coords should be a N * 2 array-like, containing N couples of (x, y) points\n        \"\"\"", "\n", "coords", "=", "np", ".", "asarray", "(", "coords", ",", "dtype", "=", "float", ")", "\n", "if", "len", "(", "coords", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "coords", "\n", "", "return", "cv2", ".", "transform", "(", "coords", "[", ":", ",", "np", ".", "newaxis", ",", ":", "]", ",", "self", ".", "rm_coords", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.apply_segmentation": [[219, 222], ["transform.RotationTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "cv2", ".", "INTER_NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.create_rotation_matrix": [[223, 234], ["cv2.getRotationMatrix2D", "tuple", "cv2.transform", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.transform"], ["", "def", "create_rotation_matrix", "(", "self", ",", "offset", "=", "0", ")", ":", "\n", "        ", "center", "=", "(", "self", ".", "center", "[", "0", "]", "+", "offset", ",", "self", ".", "center", "[", "1", "]", "+", "offset", ")", "\n", "rm", "=", "cv2", ".", "getRotationMatrix2D", "(", "tuple", "(", "center", ")", ",", "self", ".", "angle", ",", "1", ")", "\n", "if", "self", ".", "expand", ":", "\n", "# Find the coordinates of the center of rotation in the new image", "\n", "# The only point for which we know the future coordinates is the center of the image", "\n", "            ", "rot_im_center", "=", "cv2", ".", "transform", "(", "self", ".", "image_center", "[", "None", ",", "None", ",", ":", "]", "+", "offset", ",", "rm", ")", "[", "0", ",", "0", ",", ":", "]", "\n", "new_center", "=", "np", ".", "array", "(", "[", "self", ".", "bound_w", "/", "2", ",", "self", ".", "bound_h", "/", "2", "]", ")", "+", "offset", "-", "rot_im_center", "\n", "# shift the rotation center to the new coordinates", "\n", "rm", "[", ":", ",", "2", "]", "+=", "new_center", "\n", "", "return", "rm", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.RotationTransform.inverse": [[235, 248], ["transform.RotationTransform", "fvcore.transforms.transform.CropTransform", "fvcore.transforms.transform.TransformList", "NotImplementedError"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The inverse is to rotate it back with expand, and crop to get the original shape.\n        \"\"\"", "\n", "if", "not", "self", ".", "expand", ":", "# Not possible to inverse if a part of the image is lost", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "rotation", "=", "RotationTransform", "(", "\n", "self", ".", "bound_h", ",", "self", ".", "bound_w", ",", "-", "self", ".", "angle", ",", "True", ",", "None", ",", "self", ".", "interp", "\n", ")", "\n", "crop", "=", "CropTransform", "(", "\n", "(", "rotation", ".", "bound_w", "-", "self", ".", "w", ")", "//", "2", ",", "(", "rotation", ".", "bound_h", "-", "self", ".", "h", ")", "//", "2", ",", "self", ".", "w", ",", "self", ".", "h", "\n", ")", "\n", "return", "TransformList", "(", "[", "rotation", ",", "crop", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.__init__": [[258, 268], ["fvcore.transforms.transform.Transform.__init__", "transform.ColorTransform._set_attributes", "callable", "ValueError", "locals"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            op (Callable): operation to be applied to the image,\n                which takes in an ndarray and returns an ndarray.\n        \"\"\"", "\n", "if", "not", "callable", "(", "op", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"op parameter should be callable\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_image": [[269, 271], ["transform.ColorTransform.op"], "methods", ["None"], ["", "def", "apply_image", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "self", ".", "op", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_coords": [[272, 274], ["None"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.inverse": [[275, 277], ["fvcore.transforms.transform.NoOpTransform"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_segmentation": [[278, 280], ["None"], "methods", ["None"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.__init__": [[289, 301], ["transform.ColorTransform.__init__", "callable", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            op (Callable): operation to be applied to the image,\n                which takes in a PIL Image and returns a transformed\n                PIL Image.\n                For reference on possible operations see:\n                - https://pillow.readthedocs.io/en/stable/\n        \"\"\"", "\n", "if", "not", "callable", "(", "op", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"op parameter should be callable\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image": [[302, 305], ["PIL.Image.fromarray", "numpy.asarray", "transform.ColorTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image"], ["", "def", "apply_image", "(", "self", ",", "img", ")", ":", "\n", "        ", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "return", "np", ".", "asarray", "(", "super", "(", ")", ".", "apply_image", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.HFlip_rotated_box": [[307, 321], ["None"], "function", ["None"], ["", "", "def", "HFlip_rotated_box", "(", "transform", ",", "rotated_boxes", ")", ":", "\n", "    ", "\"\"\"\n    Apply the horizontal flip transform on rotated boxes.\n\n    Args:\n        rotated_boxes (ndarray): Nx5 floating point array of\n            (x_center, y_center, width, height, angle_degrees) format\n            in absolute coordinates.\n    \"\"\"", "\n", "# Transform x_center", "\n", "rotated_boxes", "[", ":", ",", "0", "]", "=", "transform", ".", "width", "-", "rotated_boxes", "[", ":", ",", "0", "]", "\n", "# Transform angle", "\n", "rotated_boxes", "[", ":", ",", "4", "]", "=", "-", "rotated_boxes", "[", ":", ",", "4", "]", "\n", "return", "rotated_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.Resize_rotated_box": [[323, 345], ["numpy.cos", "numpy.sin", "numpy.sqrt", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.square", "numpy.square", "numpy.arctan2"], "function", ["None"], ["", "def", "Resize_rotated_box", "(", "transform", ",", "rotated_boxes", ")", ":", "\n", "    ", "\"\"\"\n    Apply the resizing transform on rotated boxes. For details of how these (approximation)\n    formulas are derived, please refer to :meth:`RotatedBoxes.scale`.\n\n    Args:\n        rotated_boxes (ndarray): Nx5 floating point array of\n            (x_center, y_center, width, height, angle_degrees) format\n            in absolute coordinates.\n    \"\"\"", "\n", "scale_factor_x", "=", "transform", ".", "new_w", "*", "1.0", "/", "transform", ".", "w", "\n", "scale_factor_y", "=", "transform", ".", "new_h", "*", "1.0", "/", "transform", ".", "h", "\n", "rotated_boxes", "[", ":", ",", "0", "]", "*=", "scale_factor_x", "\n", "rotated_boxes", "[", ":", ",", "1", "]", "*=", "scale_factor_y", "\n", "theta", "=", "rotated_boxes", "[", ":", ",", "4", "]", "*", "np", ".", "pi", "/", "180.0", "\n", "c", "=", "np", ".", "cos", "(", "theta", ")", "\n", "s", "=", "np", ".", "sin", "(", "theta", ")", "\n", "rotated_boxes", "[", ":", ",", "2", "]", "*=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "scale_factor_x", "*", "c", ")", "+", "np", ".", "square", "(", "scale_factor_y", "*", "s", ")", ")", "\n", "rotated_boxes", "[", ":", ",", "3", "]", "*=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "scale_factor_x", "*", "s", ")", "+", "np", ".", "square", "(", "scale_factor_y", "*", "c", ")", ")", "\n", "rotated_boxes", "[", ":", ",", "4", "]", "=", "np", ".", "arctan2", "(", "scale_factor_x", "*", "s", ",", "scale_factor_y", "*", "c", ")", "*", "180", "/", "np", ".", "pi", "\n", "\n", "return", "rotated_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._init": [[106, 111], ["params.items", "setattr", "k.startswith"], "methods", ["None"], ["def", "_init", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", ":", "\n", "            ", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "!=", "\"self\"", "and", "not", "k", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                    ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.get_transform": [[112, 147], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_transform", "(", "self", ",", "*", "args", ")", "->", "Transform", ":", "\n", "        ", "\"\"\"\n        Execute the policy based on input data, and decide what transform to apply to inputs.\n\n        Args:\n            args: Any fixed-length positional arguments. By default, the name of the arguments\n                should exist in the :class:`AugInput` to be used.\n\n        Returns:\n            Transform: Returns the deterministic transform to apply to the input.\n\n        Examples:\n        ::\n            class MyAug:\n                # if a policy needs to know both image and semantic segmentation\n                def get_transform(image, sem_seg) -> T.Transform:\n                    pass\n            tfm: Transform = MyAug().get_transform(image, sem_seg)\n            new_image = tfm.apply_image(image)\n\n        Notes:\n            Users can freely use arbitrary new argument names in custom\n            :meth:`get_transform` method, as long as they are available in the\n            input data. In detectron2 we use the following convention:\n\n            * image: (H,W) or (H,W,C) ndarray of type uint8 in range [0, 255], or\n              floating point in range [0, 1] or [0, 255].\n            * boxes: (N,4) ndarray of float32. It represents the instance bounding boxes\n              of N instances. Each is in XYXY format in unit of absolute coordinates.\n            * sem_seg: (H,W) ndarray of type uint8. Each element is an integer label of pixel.\n\n            We do not specify convention for other types and do not include builtin\n            :class:`Augmentation` that uses other types in detectron2.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.__call__": [[148, 172], ["augmentation._get_aug_input_args", "augmentation.Augmentation.get_transform", "isinstance", "aug_input.transform", "type"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._get_aug_input_args", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.get_transform", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.transform"], ["", "def", "__call__", "(", "self", ",", "aug_input", ")", "->", "Transform", ":", "\n", "        ", "\"\"\"\n        Augment the given `aug_input` **in-place**, and return the transform that's used.\n\n        This method will be called to apply the augmentation. In most augmentation, it\n        is enough to use the default implementation, which calls :meth:`get_transform`\n        using the inputs. But a subclass can overwrite it to have more complicated logic.\n\n        Args:\n            aug_input (AugInput): an object that has attributes needed by this augmentation\n                (defined by ``self.get_transform``). Its ``transform`` method will be called\n                to in-place transform it.\n\n        Returns:\n            Transform: the transform that is applied on the input.\n        \"\"\"", "\n", "args", "=", "_get_aug_input_args", "(", "self", ",", "aug_input", ")", "\n", "tfm", "=", "self", ".", "get_transform", "(", "*", "args", ")", "\n", "assert", "isinstance", "(", "tfm", ",", "(", "Transform", ",", "TransformList", ")", ")", ",", "(", "\n", "f\"{type(self)}.get_transform must return an instance of Transform! \"", "\n", "\"Got {type(tfm)} instead.\"", "\n", ")", "\n", "aug_input", ".", "transform", "(", "tfm", ")", "\n", "return", "tfm", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation._rand_range": [[173, 182], ["numpy.random.uniform"], "methods", ["None"], ["", "def", "_rand_range", "(", "self", ",", "low", "=", "1.0", ",", "high", "=", "None", ",", "size", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Uniform float random number between low and high.\n        \"\"\"", "\n", "if", "high", "is", "None", ":", "\n", "            ", "low", ",", "high", "=", "0", ",", "low", "\n", "", "if", "size", "is", "None", ":", "\n", "            ", "size", "=", "[", "]", "\n", "", "return", "np", ".", "random", ".", "uniform", "(", "low", ",", "high", ",", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.Augmentation.__repr__": [[183, 212], ["inspect.signature", "inspect.signature.parameters.items", "type", "hasattr", "getattr", "pprint.pformat", "argstr.append", "super().__repr__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Produce something like:\n        \"MyAugmentation(field1={self.field1}, field2={self.field2})\"\n        \"\"\"", "\n", "try", ":", "\n", "            ", "sig", "=", "inspect", ".", "signature", "(", "self", ".", "__init__", ")", "\n", "classname", "=", "type", "(", "self", ")", ".", "__name__", "\n", "argstr", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "sig", ".", "parameters", ".", "items", "(", ")", ":", "\n", "                ", "assert", "(", "\n", "param", ".", "kind", "!=", "param", ".", "VAR_POSITIONAL", "and", "param", ".", "kind", "!=", "param", ".", "VAR_KEYWORD", "\n", ")", ",", "\"The default __repr__ doesn't support *args or **kwargs\"", "\n", "assert", "hasattr", "(", "self", ",", "name", ")", ",", "(", "\n", "\"Attribute {} not found! \"", "\n", "\"Default __repr__ only works if attributes match the constructor.\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "attr", "=", "getattr", "(", "self", ",", "name", ")", "\n", "default", "=", "param", ".", "default", "\n", "if", "default", "is", "attr", ":", "\n", "                    ", "continue", "\n", "", "attr_str", "=", "pprint", ".", "pformat", "(", "attr", ")", "\n", "if", "\"\\n\"", "in", "attr_str", ":", "\n", "# don't show it if pformat decides to use >1 lines", "\n", "                    ", "attr_str", "=", "\"...\"", "\n", "", "argstr", ".", "append", "(", "\"{}={}\"", ".", "format", "(", "name", ",", "attr_str", ")", ")", "\n", "", "return", "\"{}({})\"", ".", "format", "(", "classname", ",", "\", \"", ".", "join", "(", "argstr", ")", ")", "\n", "", "except", "AssertionError", ":", "\n", "            ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugmentationList.__init__": [[253, 260], ["super().__init__", "augmentation._transform_to_aug"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._transform_to_aug"], ["def", "__init__", "(", "self", ",", "augs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            augs (list[Augmentation or Transform]):\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "augs", "=", "[", "_transform_to_aug", "(", "x", ")", "for", "x", "in", "augs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugmentationList.__call__": [[261, 267], ["fvcore.transforms.transform.TransformList", "x", "tfms.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "aug_input", ")", "->", "Transform", ":", "\n", "        ", "tfms", "=", "[", "]", "\n", "for", "x", "in", "self", ".", "augs", ":", "\n", "            ", "tfm", "=", "x", "(", "aug_input", ")", "\n", "tfms", ".", "append", "(", "tfm", ")", "\n", "", "return", "TransformList", "(", "tfms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugmentationList.__repr__": [[268, 271], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msgs", "=", "[", "str", "(", "x", ")", "for", "x", "in", "self", ".", "augs", "]", "\n", "return", "\"AugmentationList[{}]\"", ".", "format", "(", "\", \"", ".", "join", "(", "msgs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugInput.__init__": [[307, 327], ["augmentation._check_img_dtype"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._check_img_dtype"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image", ":", "np", ".", "ndarray", ",", "\n", "*", ",", "\n", "boxes", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "sem_seg", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image (ndarray): (H,W) or (H,W,C) ndarray of type uint8 in range [0, 255], or\n                floating point in range [0, 1] or [0, 255]. The meaning of C is up\n                to users.\n            boxes (ndarray or None): Nx4 float32 boxes in XYXY_ABS mode\n            sem_seg (ndarray or None): HxW uint8 semantic segmentation mask. Each element\n                is an integer label of pixel.\n        \"\"\"", "\n", "_check_img_dtype", "(", "image", ")", "\n", "self", ".", "image", "=", "image", "\n", "self", ".", "boxes", "=", "boxes", "\n", "self", ".", "sem_seg", "=", "sem_seg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugInput.transform": [[328, 340], ["tfm.apply_image", "tfm.apply_box", "tfm.apply_segmentation"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.PILColorTransform.apply_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.transform.ColorTransform.apply_segmentation"], ["", "def", "transform", "(", "self", ",", "tfm", ":", "Transform", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        In-place transform all attributes of this class.\n\n        By \"in-place\", it means after calling this method, accessing an attribute such\n        as ``self.image`` will return transformed data.\n        \"\"\"", "\n", "self", ".", "image", "=", "tfm", ".", "apply_image", "(", "self", ".", "image", ")", "\n", "if", "self", ".", "boxes", "is", "not", "None", ":", "\n", "            ", "self", ".", "boxes", "=", "tfm", ".", "apply_box", "(", "self", ".", "boxes", ")", "\n", "", "if", "self", ".", "sem_seg", "is", "not", "None", ":", "\n", "            ", "self", ".", "sem_seg", "=", "tfm", ".", "apply_segmentation", "(", "self", ".", "sem_seg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.AugInput.apply_augmentations": [[341, 348], ["augmentation.AugmentationList"], "methods", ["None"], ["", "", "def", "apply_augmentations", "(", "\n", "self", ",", "augmentations", ":", "List", "[", "Union", "[", "Augmentation", ",", "Transform", "]", "]", "\n", ")", "->", "TransformList", ":", "\n", "        ", "\"\"\"\n        Equivalent of ``AugmentationList(augmentations)(self)``\n        \"\"\"", "\n", "return", "AugmentationList", "(", "augmentations", ")", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._check_img_dtype": [[27, 37], ["isinstance", "type", "isinstance"], "function", ["None"], ["def", "_check_img_dtype", "(", "img", ")", ":", "\n", "    ", "assert", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ",", "\"[Augmentation] Needs an numpy array, but got a {}!\"", ".", "format", "(", "\n", "type", "(", "img", ")", "\n", ")", "\n", "assert", "not", "isinstance", "(", "img", ".", "dtype", ",", "np", ".", "integer", ")", "or", "(", "\n", "img", ".", "dtype", "==", "np", ".", "uint8", "\n", ")", ",", "\"[Augmentation] Got image of type {}, use uint8 or floating points instead!\"", ".", "format", "(", "\n", "img", ".", "dtype", "\n", ")", "\n", "assert", "img", ".", "ndim", "in", "[", "2", ",", "3", "]", ",", "img", ".", "ndim", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._get_aug_input_args": [[39, 75], ["list", "tuple", "inspect.signature().parameters.items", "len", "args.append", "names.append", "getattr", "AttributeError", "TypeError", "inspect.signature", "type", "type", "type", "type"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "def", "_get_aug_input_args", "(", "aug", ",", "aug_input", ")", "->", "List", "[", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Get the arguments to be passed to ``aug.get_transform`` from the input ``aug_input``.\n    \"\"\"", "\n", "if", "aug", ".", "input_args", "is", "None", ":", "\n", "# Decide what attributes are needed automatically", "\n", "        ", "prms", "=", "list", "(", "inspect", ".", "signature", "(", "aug", ".", "get_transform", ")", ".", "parameters", ".", "items", "(", ")", ")", "\n", "# The default behavior is: if there is one parameter, then its \"image\"", "\n", "# (work automatically for majority of use cases, and also avoid BC breaking),", "\n", "# Otherwise, use the argument names.", "\n", "if", "len", "(", "prms", ")", "==", "1", ":", "\n", "            ", "names", "=", "(", "\"image\"", ",", ")", "\n", "", "else", ":", "\n", "            ", "names", "=", "[", "]", "\n", "for", "name", ",", "prm", "in", "prms", ":", "\n", "                ", "if", "prm", ".", "kind", "in", "(", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", ",", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "\n", "f\"\"\" \\\nThe default implementation of `{type(aug)}.__call__` does not allow \\\n`{type(aug)}.get_transform` to use variable-length arguments (*args, **kwargs)! \\\nIf arguments are unknown, reimplement `__call__` instead. \\\n\"\"\"", "\n", ")", "\n", "", "names", ".", "append", "(", "name", ")", "\n", "", "", "aug", ".", "input_args", "=", "tuple", "(", "names", ")", "\n", "\n", "", "args", "=", "[", "]", "\n", "for", "f", "in", "aug", ".", "input_args", ":", "\n", "        ", "try", ":", "\n", "            ", "args", ".", "append", "(", "getattr", "(", "aug_input", ",", "f", ")", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "f\"{type(aug)}.get_transform needs input attribute '{f}', \"", "\n", "f\"but it is not an attribute of {type(aug_input)}!\"", "\n", ")", "from", "e", "\n", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation._transform_to_aug": [[216, 239], ["isinstance", "isinstance", "_TransformToAug", "repr"], "function", ["None"], ["", "def", "_transform_to_aug", "(", "tfm_or_aug", ")", ":", "\n", "    ", "\"\"\"\n    Wrap Transform into Augmentation.\n    Private, used internally to implement augmentations.\n    \"\"\"", "\n", "assert", "isinstance", "(", "tfm_or_aug", ",", "(", "Transform", ",", "Augmentation", ")", ")", ",", "tfm_or_aug", "\n", "if", "isinstance", "(", "tfm_or_aug", ",", "Augmentation", ")", ":", "\n", "        ", "return", "tfm_or_aug", "\n", "", "else", ":", "\n", "\n", "        ", "class", "_TransformToAug", "(", "Augmentation", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "tfm", ":", "Transform", ")", ":", "\n", "                ", "self", ".", "tfm", "=", "tfm", "\n", "\n", "", "def", "get_transform", "(", "self", ",", "*", "args", ")", ":", "\n", "                ", "return", "self", ".", "tfm", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "                ", "return", "repr", "(", "self", ".", "tfm", ")", "\n", "\n", "", "__str__", "=", "__repr__", "\n", "\n", "", "return", "_TransformToAug", "(", "tfm_or_aug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.apply_augmentations": [[350, 362], ["isinstance", "AugInput.apply_augmentations", "augmentation.AugInput"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.transforms.augmentation.apply_augmentations"], ["", "", "def", "apply_augmentations", "(", "augmentations", ":", "List", "[", "Union", "[", "Transform", ",", "Augmentation", "]", "]", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Use ``T.AugmentationList(augmentations)(inputs)`` instead.\n    \"\"\"", "\n", "if", "isinstance", "(", "inputs", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle the common case of image-only Augmentation, also for backward compatibility", "\n", "        ", "image_only", "=", "True", "\n", "inputs", "=", "AugInput", "(", "inputs", ")", "\n", "", "else", ":", "\n", "        ", "image_only", "=", "False", "\n", "", "tfms", "=", "inputs", ".", "apply_augmentations", "(", "augmentations", ")", "\n", "return", "inputs", ".", "image", "if", "image_only", "else", "inputs", ",", "tfms", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.fast_eval_api.COCOeval_opt.evaluate": [[19, 96], ["time.time", "logger.info", "list", "sorted", "fast_eval_api.COCOeval_opt._prepare", "detectron2._C.COCOevalEvaluateImages", "copy.deepcopy", "time.time", "logger.info", "numpy.unique", "list", "computeIoU", "numpy.unique", "detectron2._C.InstanceAnnotation", "instances_cpp.append", "fast_eval_api.COCOeval_opt.evaluate.convert_instances_to_cpp"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.computeIoU"], ["def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run per image evaluation on given images and store results in self.evalImgs_cpp, a\n        datastructure that isn't readable from Python but is used by a c++ implementation of\n        accumulate().  Unlike the original COCO PythonAPI, we don't populate the datastructure\n        self.evalImgs because this datastructure is a computational bottleneck.\n        :return: None\n        \"\"\"", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "p", ".", "useSegm", "is", "not", "None", ":", "\n", "            ", "p", ".", "iouType", "=", "\"segm\"", "if", "p", ".", "useSegm", "==", "1", "else", "\"bbox\"", "\n", "", "logger", ".", "info", "(", "\"Evaluate annotation type *{}*\"", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "# bottleneck", "\n", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "==", "\"segm\"", "or", "p", ".", "iouType", "==", "\"bbox\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "\"keypoints\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "self", ".", "ious", "=", "{", "\n", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "for", "imgId", "in", "p", ".", "imgIds", "for", "catId", "in", "catIds", "\n", "}", "# bottleneck", "\n", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "\n", "# <<<< Beginning of code differences with original COCO API", "\n", "def", "convert_instances_to_cpp", "(", "instances", ",", "is_det", "=", "False", ")", ":", "\n", "# Convert annotations for a list of instances in an image to a format that's fast", "\n", "# to access in C++", "\n", "            ", "instances_cpp", "=", "[", "]", "\n", "for", "instance", "in", "instances", ":", "\n", "                ", "instance_cpp", "=", "_C", ".", "InstanceAnnotation", "(", "\n", "int", "(", "instance", "[", "\"id\"", "]", ")", ",", "\n", "instance", "[", "\"score\"", "]", "if", "is_det", "else", "instance", ".", "get", "(", "\"score\"", ",", "0.0", ")", ",", "\n", "instance", "[", "\"area\"", "]", ",", "\n", "bool", "(", "instance", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", ",", "\n", "bool", "(", "instance", ".", "get", "(", "\"ignore\"", ",", "0", ")", ")", ",", "\n", ")", "\n", "instances_cpp", ".", "append", "(", "instance_cpp", ")", "\n", "", "return", "instances_cpp", "\n", "\n", "# Convert GT annotations, detections, and IOUs to a format that's fast to access in C++", "\n", "", "ground_truth_instances", "=", "[", "\n", "[", "convert_instances_to_cpp", "(", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", ")", "for", "catId", "in", "p", ".", "catIds", "]", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "detected_instances", "=", "[", "\n", "[", "convert_instances_to_cpp", "(", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", ",", "is_det", "=", "True", ")", "for", "catId", "in", "p", ".", "catIds", "]", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "ious", "=", "[", "[", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "for", "catId", "in", "catIds", "]", "for", "imgId", "in", "p", ".", "imgIds", "]", "\n", "\n", "if", "not", "p", ".", "useCats", ":", "\n", "# For each image, flatten per-category lists into a single list", "\n", "            ", "ground_truth_instances", "=", "[", "[", "[", "o", "for", "c", "in", "i", "for", "o", "in", "c", "]", "]", "for", "i", "in", "ground_truth_instances", "]", "\n", "detected_instances", "=", "[", "[", "[", "o", "for", "c", "in", "i", "for", "o", "in", "c", "]", "]", "for", "i", "in", "detected_instances", "]", "\n", "\n", "# Call C++ implementation of self.evaluateImgs()", "\n", "", "self", ".", "_evalImgs_cpp", "=", "_C", ".", "COCOevalEvaluateImages", "(", "\n", "p", ".", "areaRng", ",", "maxDet", ",", "p", ".", "iouThrs", ",", "ious", ",", "ground_truth_instances", ",", "detected_instances", "\n", ")", "\n", "self", ".", "_evalImgs", "=", "None", "\n", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"COCOeval_opt.evaluate() finished in {:0.2f} seconds.\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "# >>>> End of code differences with original COCO API", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.fast_eval_api.COCOeval_opt.accumulate": [[98, 122], ["logger.info", "time.time", "hasattr", "detectron2._C.COCOevalAccumulate", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "time.time", "logger.info", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Accumulate per image evaluation results and store the result in self.eval.  Does not\n        support changing parameter settings from those used by self.evaluate()\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Accumulating evaluation results...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "assert", "hasattr", "(", "\n", "self", ",", "\"_evalImgs_cpp\"", "\n", ")", ",", "\"evaluate() must be called before accmulate() is called.\"", "\n", "\n", "self", ".", "eval", "=", "_C", ".", "COCOevalAccumulate", "(", "self", ".", "_paramsEval", ",", "self", ".", "_evalImgs_cpp", ")", "\n", "\n", "# recall is num_iou_thresholds X num_categories X num_area_ranges X num_max_detections", "\n", "self", ".", "eval", "[", "\"recall\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"recall\"", "]", ")", ".", "reshape", "(", "\n", "self", ".", "eval", "[", "\"counts\"", "]", "[", ":", "1", "]", "+", "self", ".", "eval", "[", "\"counts\"", "]", "[", "2", ":", "]", "\n", ")", "\n", "\n", "# precision and scores are num_iou_thresholds X num_recall_thresholds X num_categories X", "\n", "# num_area_ranges X num_max_detections", "\n", "self", ".", "eval", "[", "\"precision\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"precision\"", "]", ")", ".", "reshape", "(", "self", ".", "eval", "[", "\"counts\"", "]", ")", "\n", "self", ".", "eval", "[", "\"scores\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"scores\"", "]", ")", ".", "reshape", "(", "self", ".", "eval", "[", "\"counts\"", "]", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"COCOeval_opt.accumulate() finished in {:0.2f} seconds.\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.__init__": [[24, 73], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "len", "sem_seg_evaluation.SemSegEvaluator._logger.warn", "sem_seg_evaluation.SemSegEvaluator._logger.warn", "detectron2.data.DatasetCatalog.get", "c2d.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "None", ",", "\n", "*", ",", "\n", "num_classes", "=", "None", ",", "\n", "ignore_label", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n            distributed (bool): if True, will collect results from all ranks for evaluation.\n                Otherwise, will evaluate the results in the current process.\n            output_dir (str): an output directory to dump results.\n            num_classes, ignore_label: deprecated argument\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"SemSegEvaluator(num_classes) is deprecated! It should be obtained from metadata.\"", "\n", ")", "\n", "", "if", "ignore_label", "is", "not", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"SemSegEvaluator(ignore_label) is deprecated! It should be obtained from metadata.\"", "\n", ")", "\n", "", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "input_file_to_gt_file", "=", "{", "\n", "dataset_record", "[", "\"file_name\"", "]", ":", "dataset_record", "[", "\"sem_seg_file_name\"", "]", "\n", "for", "dataset_record", "in", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", "\n", "}", "\n", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "# Dict that maps contiguous training ids to COCO category ids", "\n", "try", ":", "\n", "            ", "c2d", "=", "meta", ".", "stuff_dataset_id_to_contiguous_id", "\n", "self", ".", "_contiguous_id_to_dataset_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "c2d", ".", "items", "(", ")", "}", "\n", "", "except", "AttributeError", ":", "\n", "            ", "self", ".", "_contiguous_id_to_dataset_id", "=", "None", "\n", "", "self", ".", "_class_names", "=", "meta", ".", "stuff_classes", "\n", "self", ".", "_num_classes", "=", "len", "(", "meta", ".", "stuff_classes", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "_num_classes", "==", "num_classes", ",", "f\"{self._num_classes} != {num_classes}\"", "\n", "", "self", ".", "_ignore_label", "=", "ignore_label", "if", "ignore_label", "is", "not", "None", "else", "meta", ".", "ignore_label", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.reset": [[74, 77], ["numpy.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_conf_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "_num_classes", "+", "1", ",", "self", ".", "_num_classes", "+", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.process": [[78, 102], ["zip", "output[].argmax().to", "numpy.array", "numpy.bincount().reshape", "sem_seg_evaluation.SemSegEvaluator._predictions.extend", "detectron2.utils.file_io.PathManager.open", "numpy.array", "sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg", "output[].argmax", "PIL.open", "numpy.bincount", "numpy.array.reshape", "numpy.array.reshape"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a model.\n                It is a list of dicts. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\".\n            outputs: the outputs of a model. It is either list of semantic segmentation predictions\n                (Tensor [H, W]) or list of dicts with key \"sem_seg\" that contains semantic\n                segmentation prediction in the same format.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "output", "=", "output", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "pred", "=", "np", ".", "array", "(", "output", ",", "dtype", "=", "np", ".", "int", ")", "\n", "with", "PathManager", ".", "open", "(", "self", ".", "input_file_to_gt_file", "[", "input", "[", "\"file_name\"", "]", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "gt", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "f", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "", "gt", "[", "gt", "==", "self", ".", "_ignore_label", "]", "=", "self", ".", "_num_classes", "\n", "\n", "self", ".", "_conf_matrix", "+=", "np", ".", "bincount", "(", "\n", "(", "self", ".", "_num_classes", "+", "1", ")", "*", "pred", ".", "reshape", "(", "-", "1", ")", "+", "gt", ".", "reshape", "(", "-", "1", ")", ",", "\n", "minlength", "=", "self", ".", "_conf_matrix", ".", "size", ",", "\n", ")", ".", "reshape", "(", "self", ".", "_conf_matrix", ".", "shape", ")", "\n", "\n", "self", ".", "_predictions", ".", "extend", "(", "self", ".", "encode_json_sem_seg", "(", "pred", ",", "input", "[", "\"file_name\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.evaluate": [[103, 163], ["numpy.full", "numpy.full", "[].astype", "numpy.sum().astype", "numpy.sum().astype", "numpy.sum", "enumerate", "enumerate", "collections.OrderedDict", "sem_seg_evaluation.SemSegEvaluator._logger.info", "detectron2.utils.comm.synchronize", "detectron2.utils.comm.all_gather", "detectron2.utils.comm.all_gather", "list", "numpy.zeros_like", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "os.path.join", "itertools.chain", "detectron2.utils.comm.is_main_process", "detectron2.utils.file_io.PathManager.open", "f.write", "numpy.sum", "numpy.sum", "detectron2.utils.file_io.PathManager.open", "torch.save", "json.dumps", "sem_seg_evaluation.SemSegEvaluator._conf_matrix.diagonal"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluates standard semantic segmentation metrics (http://cocodataset.org/#stuff-eval):\n\n        * Mean intersection-over-union averaged across classes (mIoU)\n        * Frequency Weighted IoU (fwIoU)\n        * Mean pixel accuracy averaged across classes (mACC)\n        * Pixel Accuracy (pACC)\n        \"\"\"", "\n", "if", "self", ".", "_distributed", ":", "\n", "            ", "synchronize", "(", ")", "\n", "conf_matrix_list", "=", "all_gather", "(", "self", ".", "_conf_matrix", ")", "\n", "self", ".", "_predictions", "=", "all_gather", "(", "self", ".", "_predictions", ")", "\n", "self", ".", "_predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "self", ".", "_predictions", ")", ")", "\n", "if", "not", "is_main_process", "(", ")", ":", "\n", "                ", "return", "\n", "\n", "", "self", ".", "_conf_matrix", "=", "np", ".", "zeros_like", "(", "self", ".", "_conf_matrix", ")", "\n", "for", "conf_matrix", "in", "conf_matrix_list", ":", "\n", "                ", "self", ".", "_conf_matrix", "+=", "conf_matrix", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"sem_seg_predictions.json\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "_predictions", ")", ")", "\n", "\n", "", "", "acc", "=", "np", ".", "full", "(", "self", ".", "_num_classes", ",", "np", ".", "nan", ",", "dtype", "=", "np", ".", "float", ")", "\n", "iou", "=", "np", ".", "full", "(", "self", ".", "_num_classes", ",", "np", ".", "nan", ",", "dtype", "=", "np", ".", "float", ")", "\n", "tp", "=", "self", ".", "_conf_matrix", ".", "diagonal", "(", ")", "[", ":", "-", "1", "]", ".", "astype", "(", "np", ".", "float", ")", "\n", "pos_gt", "=", "np", ".", "sum", "(", "self", ".", "_conf_matrix", "[", ":", "-", "1", ",", ":", "-", "1", "]", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "class_weights", "=", "pos_gt", "/", "np", ".", "sum", "(", "pos_gt", ")", "\n", "pos_pred", "=", "np", ".", "sum", "(", "self", ".", "_conf_matrix", "[", ":", "-", "1", ",", ":", "-", "1", "]", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "acc_valid", "=", "pos_gt", ">", "0", "\n", "acc", "[", "acc_valid", "]", "=", "tp", "[", "acc_valid", "]", "/", "pos_gt", "[", "acc_valid", "]", "\n", "iou_valid", "=", "(", "pos_gt", "+", "pos_pred", ")", ">", "0", "\n", "union", "=", "pos_gt", "+", "pos_pred", "-", "tp", "\n", "iou", "[", "acc_valid", "]", "=", "tp", "[", "acc_valid", "]", "/", "union", "[", "acc_valid", "]", "\n", "macc", "=", "np", ".", "sum", "(", "acc", "[", "acc_valid", "]", ")", "/", "np", ".", "sum", "(", "acc_valid", ")", "\n", "miou", "=", "np", ".", "sum", "(", "iou", "[", "acc_valid", "]", ")", "/", "np", ".", "sum", "(", "iou_valid", ")", "\n", "fiou", "=", "np", ".", "sum", "(", "iou", "[", "acc_valid", "]", "*", "class_weights", "[", "acc_valid", "]", ")", "\n", "pacc", "=", "np", ".", "sum", "(", "tp", ")", "/", "np", ".", "sum", "(", "pos_gt", ")", "\n", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"mIoU\"", "]", "=", "100", "*", "miou", "\n", "res", "[", "\"fwIoU\"", "]", "=", "100", "*", "fiou", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "            ", "res", "[", "\"IoU-{}\"", ".", "format", "(", "name", ")", "]", "=", "100", "*", "iou", "[", "i", "]", "\n", "", "res", "[", "\"mACC\"", "]", "=", "100", "*", "macc", "\n", "res", "[", "\"pACC\"", "]", "=", "100", "*", "pacc", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "            ", "res", "[", "\"ACC-{}\"", ".", "format", "(", "name", ")", "]", "=", "100", "*", "acc", "[", "i", "]", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"sem_seg_evaluation.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "res", ",", "f", ")", "\n", "", "", "results", "=", "OrderedDict", "(", "{", "\"sem_seg\"", ":", "res", "}", ")", "\n", "self", ".", "_logger", ".", "info", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg": [[164, 185], ["numpy.unique", "mask_rle[].decode", "json_list.append", "int", "pycocotools.encode", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode"], ["", "def", "encode_json_sem_seg", "(", "self", ",", "sem_seg", ",", "input_file_name", ")", ":", "\n", "        ", "\"\"\"\n        Convert semantic segmentation to COCO stuff format with segments encoded as RLEs.\n        See http://cocodataset.org/#format-results\n        \"\"\"", "\n", "json_list", "=", "[", "]", "\n", "for", "label", "in", "np", ".", "unique", "(", "sem_seg", ")", ":", "\n", "            ", "if", "self", ".", "_contiguous_id_to_dataset_id", "is", "not", "None", ":", "\n", "                ", "assert", "(", "\n", "label", "in", "self", ".", "_contiguous_id_to_dataset_id", "\n", ")", ",", "\"Label {} is not in the metadata info for {}\"", ".", "format", "(", "label", ",", "self", ".", "_dataset_name", ")", "\n", "dataset_id", "=", "self", ".", "_contiguous_id_to_dataset_id", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "dataset_id", "=", "int", "(", "label", ")", "\n", "", "mask", "=", "(", "sem_seg", "==", "label", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "mask_rle", "=", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ")", ")", "[", "0", "]", "\n", "mask_rle", "[", "\"counts\"", "]", "=", "mask_rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "json_list", ".", "append", "(", "\n", "{", "\"file_name\"", ":", "input_file_name", ",", "\"category_id\"", ":", "dataset_id", ",", "\"segmentation\"", ":", "mask_rle", "}", "\n", ")", "\n", "", "return", "json_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator.__init__": [[28, 65], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "LVIS", "isinstance", "lvis_evaluation.LVISEvaluator._logger.warn", "len", "lvis_evaluation.LVISEvaluator._lvis_api.get_ann_ids"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "__init__", "(", "self", ",", "dataset_name", ",", "tasks", "=", "None", ",", "distributed", "=", "True", ",", "output_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n                It must have the following corresponding metadata:\n                \"json_file\": the path to the LVIS format annotation\n            tasks (tuple[str]): tasks that can be evaluated under the given\n                configuration. A task is one of \"bbox\", \"segm\".\n                By default, will infer this automatically from predictions.\n            distributed (True): if True, will collect results from all ranks for evaluation.\n                Otherwise, will evaluate the results in the current process.\n            output_dir (str): optional, an output directory to dump results.\n        \"\"\"", "\n", "from", "boundary_iou_api", ".", "boundary_iou", ".", "lvis_instance_api", ".", "lvis", "import", "LVIS", "\n", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "if", "tasks", "is", "not", "None", "and", "isinstance", "(", "tasks", ",", "CfgNode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"COCO Evaluator instantiated using config, this is deprecated behavior.\"", "\n", "\" Please pass in explicit arguments instead.\"", "\n", ")", "\n", "self", ".", "_tasks", "=", "None", "# Infering it from predictions should be better", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tasks", "=", "tasks", "\n", "\n", "", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "json_file", ")", "\n", "self", ".", "_lvis_api", "=", "LVIS", "(", "json_file", ")", "\n", "# Test set json files do not contain annotations (evaluation must be", "\n", "# performed using the LVIS evaluation server).", "\n", "self", ".", "_do_evaluation", "=", "len", "(", "self", ".", "_lvis_api", ".", "get_ann_ids", "(", ")", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator.reset": [[66, 68], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator.process": [[69, 87], ["zip", "lvis_evaluation.LVISEvaluator._predictions.append", "output[].to", "coco_evaluation.instances_to_coco_json", "output[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.instances_to_coco_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a LVIS model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a LVIS model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"instances\"", "]", "=", "instances_to_coco_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator.evaluate": [[88, 116], ["collections.OrderedDict", "copy.deepcopy", "detectron2.synchronize", "detectron2.gather", "list", "len", "lvis_evaluation.LVISEvaluator._logger.warning", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "lvis_evaluation.LVISEvaluator._eval_box_proposals", "lvis_evaluation.LVISEvaluator._eval_predictions", "itertools.chain", "detectron2.is_main_process", "detectron2.utils.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._eval_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[LVISEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "if", "\"proposals\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_box_proposals", "(", "predictions", ")", "\n", "", "if", "\"instances\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_predictions", "(", "predictions", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator._tasks_from_predictions": [[117, 122], ["None"], "methods", ["None"], ["", "def", "_tasks_from_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "for", "pred", "in", "predictions", ":", "\n", "            ", "if", "\"segmentation\"", "in", "pred", ":", "\n", "                ", "return", "(", "\"bbox\"", ",", "\"segm\"", ")", "\n", "", "", "return", "(", "\"bbox\"", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator._eval_predictions": [[123, 164], ["lvis_evaluation.LVISEvaluator._logger.info", "list", "hasattr", "lvis_evaluation.LVISEvaluator._logger.info", "sorted", "itertools.chain", "lvis_evaluation.LVISEvaluator._tasks_from_predictions", "os.path.join", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation._evaluate_predictions_on_lvis", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "lvis_evaluation.LVISEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "json.dumps", "lvis_evaluation.LVISEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation._evaluate_predictions_on_lvis", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate predictions. Fill self._results with the metrics of the tasks.\n\n        Args:\n            predictions (list[dict]): list of outputs from the model\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results in the LVIS format ...\"", ")", "\n", "lvis_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "tasks", "=", "self", ".", "_tasks", "or", "self", ".", "_tasks_from_predictions", "(", "lvis_results", ")", "\n", "\n", "# LVIS evaluator can be used to evaluate results for COCO dataset categories.", "\n", "# In this case `_metadata` variable will have a field with COCO-specific category mapping.", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "reverse_id_mapping", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "for", "result", "in", "lvis_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "result", "[", "\"category_id\"", "]", "]", "\n", "", "", "else", ":", "\n", "# unmap the category ids for LVIS (from 0-indexed to 1-indexed)", "\n", "            ", "for", "result", "in", "lvis_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"lvis_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "lvis_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating predictions ...\"", ")", "\n", "for", "task", "in", "sorted", "(", "tasks", ")", ":", "\n", "            ", "res", "=", "_evaluate_predictions_on_lvis", "(", "\n", "self", ".", "_lvis_api", ",", "lvis_results", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation.LVISEvaluator._eval_box_proposals": [[165, 203], ["lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "areas.items", "ids.append", "boxes.append", "objectness_logits.append", "detectron2.utils.file_io.PathManager.open", "pickle.dump", "lvis_evaluation._evaluate_box_proposals", "float", "detectron2.utils.logger.create_small_table", "prediction[].proposal_boxes.tensor.numpy", "prediction[].objectness_logits.numpy", "os.path.join", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation._evaluate_box_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.create_small_table"], ["", "", "def", "_eval_box_proposals", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the box proposals in predictions.\n        Fill self._results with the metrics for \"box_proposals\" task.\n        \"\"\"", "\n", "if", "self", ".", "_output_dir", ":", "\n", "# Saving generated box proposals to file.", "\n", "# Predicted box_proposals are in XYXY_ABS mode.", "\n", "            ", "bbox_mode", "=", "BoxMode", ".", "XYXY_ABS", ".", "value", "\n", "ids", ",", "boxes", ",", "objectness_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "ids", ".", "append", "(", "prediction", "[", "\"image_id\"", "]", ")", "\n", "boxes", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "proposal_boxes", ".", "tensor", ".", "numpy", "(", ")", ")", "\n", "objectness_logits", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "objectness_logits", ".", "numpy", "(", ")", ")", "\n", "\n", "", "proposal_data", "=", "{", "\n", "\"boxes\"", ":", "boxes", ",", "\n", "\"objectness_logits\"", ":", "objectness_logits", ",", "\n", "\"ids\"", ":", "ids", ",", "\n", "\"bbox_mode\"", ":", "bbox_mode", ",", "\n", "}", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"box_proposals.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "proposal_data", ",", "f", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating bbox proposals ...\"", ")", "\n", "res", "=", "{", "}", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "_evaluate_box_proposals", "(", "predictions", ",", "self", ".", "_lvis_api", ",", "area", "=", "area", ",", "limit", "=", "limit", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", "[", "key", "]", "=", "float", "(", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "*", "100", ")", "\n", "", "", "self", ".", "_logger", ".", "info", "(", "\"Proposal metrics: \\n\"", "+", "create_small_table", "(", "res", ")", ")", "\n", "self", ".", "_results", "[", "\"box_proposals\"", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation._evaluate_box_proposals": [[207, 313], ["torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "lvis_api.get_ann_ids", "lvis_api.load_anns", "torch.as_tensor().reshape", "detectron2.structures.Boxes", "torch.as_tensor", "len", "detectron2.structures.pairwise_iou", "torch.zeros", "range", "gt_overlaps.append", "len", "torch.cat", "torch.zeros", "torch.arange", "predictions.objectness_logits.sort", "detectron2.structures.BoxMode.convert", "len", "len", "min", "detectron2.structures.pairwise_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "", "def", "_evaluate_box_proposals", "(", "dataset_predictions", ",", "lvis_api", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official LVIS API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "prediction_dict", "in", "dataset_predictions", ":", "\n", "        ", "predictions", "=", "prediction_dict", "[", "\"proposals\"", "]", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "predictions", ".", "objectness_logits", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "predictions", "=", "predictions", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "lvis_api", ".", "get_ann_ids", "(", "img_ids", "=", "[", "prediction_dict", "[", "\"image_id\"", "]", "]", ")", "\n", "anno", "=", "lvis_api", ".", "load_anns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "for", "obj", "in", "anno", "\n", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "Boxes", "(", "gt_boxes", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", "or", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "predictions", ")", ">", "limit", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "pairwise_iou", "(", "predictions", ".", "proposal_boxes", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "(", "\n", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "if", "len", "(", "gt_overlaps", ")", "else", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.lvis_evaluation._evaluate_predictions_on_lvis": [[316, 360], ["logging.getLogger", "LVISResults", "LVISEval", "LVISEval.run", "LVISEval.print_results", "LVISEval.get_results", "logging.getLogger.info", "len", "logging.getLogger.warn", "copy.deepcopy", "float", "float", "c.pop", "detectron2.utils.logger.create_small_table"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.create_small_table"], ["", "def", "_evaluate_predictions_on_lvis", "(", "lvis_gt", ",", "lvis_results", ",", "iou_type", ",", "class_names", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        iou_type (str):\n        kpt_oks_sigmas (list[float]):\n        class_names (None or list[str]): if provided, will use it to predict\n            per-category AP.\n\n    Returns:\n        a dict of {metric name: score}\n    \"\"\"", "\n", "metrics", "=", "{", "\n", "\"bbox\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", ",", "\"APr\"", ",", "\"APc\"", ",", "\"APf\"", "]", ",", "\n", "\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", ",", "\"APr\"", ",", "\"APc\"", ",", "\"APf\"", "]", ",", "\n", "}", "[", "iou_type", "]", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "if", "len", "(", "lvis_results", ")", "==", "0", ":", "# TODO: check if needed", "\n", "        ", "logger", ".", "warn", "(", "\"No predictions from the model!\"", ")", "\n", "return", "{", "metric", ":", "float", "(", "\"nan\"", ")", "for", "metric", "in", "metrics", "}", "\n", "\n", "", "if", "iou_type", "==", "\"segm\"", ":", "\n", "        ", "lvis_results", "=", "copy", ".", "deepcopy", "(", "lvis_results", ")", "\n", "# When evaluating mask AP, if the results contain bbox, LVIS API will", "\n", "# use the box area as the area of the instance, instead of the mask area.", "\n", "# This leads to a different definition of small/medium/large.", "\n", "# We remove the bbox field to let mask AP use mask area.", "\n", "for", "c", "in", "lvis_results", ":", "\n", "            ", "c", ".", "pop", "(", "\"bbox\"", ",", "None", ")", "\n", "\n", "# from lvis import LVISEval, LVISResults", "\n", "", "", "from", "boundary_iou", ".", "lvis_instance_api", ".", "eval", "import", "LVISEval", ",", "LVISResults", "\n", "\n", "lvis_results", "=", "LVISResults", "(", "lvis_gt", ",", "lvis_results", ")", "\n", "lvis_eval", "=", "LVISEval", "(", "lvis_gt", ",", "lvis_results", ",", "iou_type", "=", "\"boundary\"", ")", "\n", "lvis_eval", ".", "run", "(", ")", "\n", "lvis_eval", ".", "print_results", "(", ")", "\n", "\n", "# Pull the standard metrics from the LVIS results", "\n", "results", "=", "lvis_eval", ".", "get_results", "(", ")", "\n", "results", "=", "{", "metric", ":", "float", "(", "results", "[", "metric", "]", "*", "100", ")", "for", "metric", "in", "metrics", "}", "\n", "logger", ".", "info", "(", "\"Evaluation results for {}: \\n\"", ".", "format", "(", "iou_type", ")", "+", "create_small_table", "(", "results", ")", ")", "\n", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator.__init__": [[43, 122], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "isinstance", "coco_evaluation.COCOEvaluator._logger.warn", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "os.path.join", "detectron2.data.datasets.coco.convert_to_coco_json", "contextlib.redirect_stdout", "pycocotools.coco.COCO", "io.StringIO"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.datasets.coco.convert_to_coco_json"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "tasks", "=", "None", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "None", ",", "\n", "*", ",", "\n", "use_fast_impl", "=", "True", ",", "\n", "kpt_oks_sigmas", "=", "(", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n                It must have either the following corresponding metadata:\n\n                    \"json_file\": the path to the COCO format annotation\n\n                Or it must be in detectron2's standard dataset format\n                so it can be converted to COCO format automatically.\n            tasks (tuple[str]): tasks that can be evaluated under the given\n                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\n                By default, will infer this automatically from predictions.\n            distributed (True): if True, will collect results from all ranks and run evaluation\n                in the main process.\n                Otherwise, will only evaluate the results in the current process.\n            output_dir (str): optional, an output directory to dump all\n                results predicted on the dataset. The dump contains two files:\n\n                1. \"instances_predictions.pth\" a file that can be loaded with `torch.load` and\n                   contains all the results in the format they are produced by the model.\n                2. \"coco_instances_results.json\" a json file in COCO's result format.\n            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\n                Although the results should be very close to the official implementation in COCO\n                API, it is still recommended to compute results with the official API for use in\n                papers. The faster implementation also uses more RAM.\n            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\n                See http://cocodataset.org/#keypoints-eval\n                When empty, it will use the defaults in COCO.\n                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "self", ".", "_use_fast_impl", "=", "use_fast_impl", "\n", "\n", "if", "tasks", "is", "not", "None", "and", "isinstance", "(", "tasks", ",", "CfgNode", ")", ":", "\n", "            ", "kpt_oks_sigmas", "=", "(", "\n", "tasks", ".", "TEST", ".", "KEYPOINT_OKS_SIGMAS", "if", "not", "kpt_oks_sigmas", "else", "kpt_oks_sigmas", "\n", ")", "\n", "self", ".", "_logger", ".", "warn", "(", "\n", "\"COCO Evaluator instantiated using config, this is deprecated behavior.\"", "\n", "\" Please pass in explicit arguments instead.\"", "\n", ")", "\n", "self", ".", "_tasks", "=", "None", "# Infering it from predictions should be better", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tasks", "=", "tasks", "\n", "\n", "", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "if", "not", "hasattr", "(", "self", ".", "_metadata", ",", "\"json_file\"", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "f\"'{dataset_name}' is not registered by `register_coco_instances`.\"", "\n", "\" Therefore trying to convert it to COCO format ...\"", "\n", ")", "\n", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{dataset_name}_coco_format.json\"", ")", "\n", "self", ".", "_metadata", ".", "json_file", "=", "cache_path", "\n", "convert_to_coco_json", "(", "dataset_name", ",", "cache_path", ")", "\n", "\n", "", "json_file", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "            ", "self", ".", "_coco_api", "=", "COCO", "(", "json_file", ")", "\n", "\n", "# Test set json files do not contain annotations (evaluation must be", "\n", "# performed using the COCO evaluation server).", "\n", "", "self", ".", "_do_evaluation", "=", "\"annotations\"", "in", "self", ".", "_coco_api", ".", "dataset", "\n", "if", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_kpt_oks_sigmas", "=", "kpt_oks_sigmas", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator.reset": [[123, 125], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator.process": [[126, 145], ["zip", "output[].to", "coco_evaluation.instances_to_coco_json", "output[].to", "len", "coco_evaluation.COCOEvaluator._predictions.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.instances_to_coco_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a COCO model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"instances\"", "]", "=", "instances_to_coco_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "if", "len", "(", "prediction", ")", ">", "1", ":", "\n", "                ", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator.evaluate": [[146, 178], ["collections.OrderedDict", "copy.deepcopy", "detectron2.synchronize", "detectron2.gather", "list", "len", "coco_evaluation.COCOEvaluator._logger.warning", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "coco_evaluation.COCOEvaluator._eval_box_proposals", "coco_evaluation.COCOEvaluator._eval_predictions", "itertools.chain", "detectron2.is_main_process", "detectron2.utils.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._eval_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["", "", "", "def", "evaluate", "(", "self", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\n        \"\"\"", "\n", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "{", "}", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[COCOEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "if", "\"proposals\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_box_proposals", "(", "predictions", ")", "\n", "", "if", "\"instances\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_predictions", "(", "predictions", ",", "img_ids", "=", "img_ids", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions": [[179, 190], ["sorted", "tasks.add", "tasks.add"], "methods", ["None"], ["", "def", "_tasks_from_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\n        \"\"\"", "\n", "tasks", "=", "{", "\"bbox\"", "}", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "if", "\"segmentation\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"segm\"", ")", "\n", "", "if", "\"keypoints\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"keypoints\"", ")", "\n", "", "", "return", "sorted", "(", "tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._eval_predictions": [[191, 251], ["coco_evaluation.COCOEvaluator._logger.info", "list", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "sorted", "itertools.chain", "coco_evaluation.COCOEvaluator._tasks_from_predictions", "list", "len", "os.path.join", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._derive_coco_results", "dataset_id_to_contiguous_id.values", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "coco_evaluation._evaluate_predictions_on_coco", "min", "max", "dataset_id_to_contiguous_id.items", "json.dumps", "len", "coco_evaluation.COCOEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate predictions. Fill self._results with the metrics of the tasks.\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results for COCO format ...\"", ")", "\n", "coco_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "tasks", "=", "self", ".", "_tasks", "or", "self", ".", "_tasks_from_predictions", "(", "coco_results", ")", "\n", "\n", "# unmap the category ids for COCO", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "dataset_id_to_contiguous_id", "=", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", "\n", "all_contiguous_ids", "=", "list", "(", "dataset_id_to_contiguous_id", ".", "values", "(", ")", ")", "\n", "num_classes", "=", "len", "(", "all_contiguous_ids", ")", "\n", "assert", "min", "(", "all_contiguous_ids", ")", "==", "0", "and", "max", "(", "all_contiguous_ids", ")", "==", "num_classes", "-", "1", "\n", "\n", "reverse_id_mapping", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "dataset_id_to_contiguous_id", ".", "items", "(", ")", "}", "\n", "for", "result", "in", "coco_results", ":", "\n", "                ", "category_id", "=", "result", "[", "\"category_id\"", "]", "\n", "assert", "category_id", "<", "num_classes", ",", "(", "\n", "f\"A prediction has class={category_id}, \"", "\n", "f\"but the dataset only has {num_classes} classes and \"", "\n", "f\"predicted class id should be in [0, {num_classes - 1}].\"", "\n", ")", "\n", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "category_id", "]", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"coco_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "coco_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluating predictions with {} COCO API...\"", ".", "format", "(", "\n", "\"unofficial\"", "if", "self", ".", "_use_fast_impl", "else", "\"official\"", "\n", ")", "\n", ")", "\n", "for", "task", "in", "sorted", "(", "tasks", ")", ":", "\n", "            ", "assert", "task", "in", "{", "\"bbox\"", ",", "\"segm\"", ",", "\"keypoints\"", "}", ",", "f\"Got unknown task: {task}!\"", "\n", "coco_eval", "=", "(", "\n", "_evaluate_predictions_on_coco", "(", "\n", "self", ".", "_coco_api", ",", "\n", "coco_results", ",", "\n", "task", ",", "\n", "kpt_oks_sigmas", "=", "self", ".", "_kpt_oks_sigmas", ",", "\n", "use_fast_impl", "=", "self", ".", "_use_fast_impl", ",", "\n", "img_ids", "=", "img_ids", ",", "\n", ")", "\n", "if", "len", "(", "coco_results", ")", ">", "0", "\n", "else", "None", "# cocoapi does not handle empty results very well", "\n", ")", "\n", "\n", "res", "=", "self", ".", "_derive_coco_results", "(", "\n", "coco_eval", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals": [[252, 290], ["coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "areas.items", "ids.append", "boxes.append", "objectness_logits.append", "detectron2.utils.file_io.PathManager.open", "pickle.dump", "coco_evaluation._evaluate_box_proposals", "float", "detectron2.utils.logger.create_small_table", "prediction[].proposal_boxes.tensor.numpy", "prediction[].objectness_logits.numpy", "os.path.join", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.dump", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation._evaluate_box_proposals", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.create_small_table"], ["", "", "def", "_eval_box_proposals", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the box proposals in predictions.\n        Fill self._results with the metrics for \"box_proposals\" task.\n        \"\"\"", "\n", "if", "self", ".", "_output_dir", ":", "\n", "# Saving generated box proposals to file.", "\n", "# Predicted box_proposals are in XYXY_ABS mode.", "\n", "            ", "bbox_mode", "=", "BoxMode", ".", "XYXY_ABS", ".", "value", "\n", "ids", ",", "boxes", ",", "objectness_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "ids", ".", "append", "(", "prediction", "[", "\"image_id\"", "]", ")", "\n", "boxes", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "proposal_boxes", ".", "tensor", ".", "numpy", "(", ")", ")", "\n", "objectness_logits", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "objectness_logits", ".", "numpy", "(", ")", ")", "\n", "\n", "", "proposal_data", "=", "{", "\n", "\"boxes\"", ":", "boxes", ",", "\n", "\"objectness_logits\"", ":", "objectness_logits", ",", "\n", "\"ids\"", ":", "ids", ",", "\n", "\"bbox_mode\"", ":", "bbox_mode", ",", "\n", "}", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"box_proposals.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "proposal_data", ",", "f", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating bbox proposals ...\"", ")", "\n", "res", "=", "{", "}", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "_evaluate_box_proposals", "(", "predictions", ",", "self", ".", "_coco_api", ",", "area", "=", "area", ",", "limit", "=", "limit", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", "[", "key", "]", "=", "float", "(", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "*", "100", ")", "\n", "", "", "self", ".", "_logger", ".", "info", "(", "\"Proposal metrics: \\n\"", "+", "create_small_table", "(", "res", ")", ")", "\n", "self", ".", "_results", "[", "\"box_proposals\"", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results": [[291, 358], ["coco_evaluation.COCOEvaluator._logger.info", "enumerate", "min", "list", "itertools.zip_longest", "tabulate.tabulate.tabulate", "coco_evaluation.COCOEvaluator._logger.info", "results.update", "coco_evaluation.COCOEvaluator._logger.warn", "float", "numpy.isfinite", "coco_evaluation.COCOEvaluator._logger.info", "len", "results_per_category.append", "itertools.chain", "float", "enumerate", "detectron2.utils.logger.create_small_table", "sum", "len", "numpy.mean", "float", "len", "results.values", "float", "range"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.create_small_table"], ["", "def", "_derive_coco_results", "(", "self", ",", "coco_eval", ",", "iou_type", ",", "class_names", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Derive the desired score numbers from summarized COCOeval.\n\n        Args:\n            coco_eval (None or COCOEval): None represents no predictions from model.\n            iou_type (str):\n            class_names (None or list[str]): if provided, will use it to predict\n                per-category AP.\n\n        Returns:\n            a dict of {metric name: score}\n        \"\"\"", "\n", "\n", "metrics", "=", "{", "\n", "\"bbox\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"keypoints\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "}", "[", "iou_type", "]", "\n", "\n", "if", "coco_eval", "is", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\"No predictions from the model!\"", ")", "\n", "return", "{", "metric", ":", "float", "(", "\"nan\"", ")", "for", "metric", "in", "metrics", "}", "\n", "\n", "# the standard metrics", "\n", "", "results", "=", "{", "\n", "metric", ":", "float", "(", "coco_eval", ".", "stats", "[", "idx", "]", "*", "100", "if", "coco_eval", ".", "stats", "[", "idx", "]", ">=", "0", "else", "\"nan\"", ")", "\n", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "\n", "}", "\n", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluation results for {}: \\n\"", ".", "format", "(", "iou_type", ")", "+", "create_small_table", "(", "results", ")", "\n", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "sum", "(", "results", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Some metrics cannot be computed and is shown as NaN.\"", ")", "\n", "\n", "", "if", "class_names", "is", "None", "or", "len", "(", "class_names", ")", "<=", "1", ":", "\n", "            ", "return", "results", "\n", "# Compute per-category AP", "\n", "# from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa", "\n", "", "precisions", "=", "coco_eval", ".", "eval", "[", "\"precision\"", "]", "\n", "# precision has dims (iou, recall, cls, area range, max dets)", "\n", "assert", "len", "(", "class_names", ")", "==", "precisions", ".", "shape", "[", "2", "]", "\n", "\n", "results_per_category", "=", "[", "]", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "class_names", ")", ":", "\n", "# area range index 0: all area ranges", "\n", "# max dets index -1: typically 100 per image", "\n", "            ", "precision", "=", "precisions", "[", ":", ",", ":", ",", "idx", ",", "0", ",", "-", "1", "]", "\n", "precision", "=", "precision", "[", "precision", ">", "-", "1", "]", "\n", "ap", "=", "np", ".", "mean", "(", "precision", ")", "if", "precision", ".", "size", "else", "float", "(", "\"nan\"", ")", "\n", "results_per_category", ".", "append", "(", "(", "\"{}\"", ".", "format", "(", "name", ")", ",", "float", "(", "ap", "*", "100", ")", ")", ")", "\n", "\n", "# tabulate it", "\n", "", "N_COLS", "=", "min", "(", "6", ",", "len", "(", "results_per_category", ")", "*", "2", ")", "\n", "results_flatten", "=", "list", "(", "itertools", ".", "chain", "(", "*", "results_per_category", ")", ")", "\n", "results_2d", "=", "itertools", ".", "zip_longest", "(", "*", "[", "results_flatten", "[", "i", ":", ":", "N_COLS", "]", "for", "i", "in", "range", "(", "N_COLS", ")", "]", ")", "\n", "table", "=", "tabulate", "(", "\n", "results_2d", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "headers", "=", "[", "\"category\"", ",", "\"AP\"", "]", "*", "(", "N_COLS", "//", "2", ")", ",", "\n", "numalign", "=", "\"left\"", ",", "\n", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Per-category {} AP: \\n\"", ".", "format", "(", "iou_type", ")", "+", "table", ")", "\n", "\n", "results", ".", "update", "(", "{", "\"AP-\"", "+", "name", ":", "ap", "for", "name", ",", "ap", "in", "results_per_category", "}", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.instances_to_coco_json": [[360, 420], ["len", "instances.pred_boxes.tensor.numpy", "detectron2.structures.BoxMode.convert", "boxes.tolist.tolist", "instances.scores.tolist", "instances.pred_classes.tolist", "instances.has", "instances.has", "range", "results.append", "rle[].decode", "keypoints[].flatten().tolist", "pycocotools.encode", "numpy.array", "keypoints[].flatten"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "instances_to_coco_json", "(", "instances", ",", "img_id", ")", ":", "\n", "    ", "\"\"\"\n    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n\n    Args:\n        instances (Instances):\n        img_id (int): the image id\n\n    Returns:\n        list[dict]: list of json annotations in COCO format.\n    \"\"\"", "\n", "num_instance", "=", "len", "(", "instances", ")", "\n", "if", "num_instance", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "boxes", "=", "BoxMode", ".", "convert", "(", "boxes", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "boxes", "=", "boxes", ".", "tolist", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "has_mask", "=", "instances", ".", "has", "(", "\"pred_masks\"", ")", "\n", "if", "has_mask", ":", "\n", "# use RLE to encode the masks, because they are too large and takes memory", "\n", "# since this evaluator stores outputs of the entire dataset", "\n", "        ", "rles", "=", "[", "\n", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ",", "dtype", "=", "\"uint8\"", ")", ")", "[", "0", "]", "\n", "for", "mask", "in", "instances", ".", "pred_masks", "\n", "]", "\n", "for", "rle", "in", "rles", ":", "\n", "# \"counts\" is an array encoded by mask_util as a byte-stream. Python3's", "\n", "# json writer which always produces strings cannot serialize a bytestream", "\n", "# unless you decode it. Thankfully, utf-8 works out (which is also what", "\n", "# the pycocotools/_mask.pyx does).", "\n", "            ", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "", "has_keypoints", "=", "instances", ".", "has", "(", "\"pred_keypoints\"", ")", "\n", "if", "has_keypoints", ":", "\n", "        ", "keypoints", "=", "instances", ".", "pred_keypoints", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_instance", ")", ":", "\n", "        ", "result", "=", "{", "\n", "\"image_id\"", ":", "img_id", ",", "\n", "\"category_id\"", ":", "classes", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "boxes", "[", "k", "]", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "if", "has_mask", ":", "\n", "            ", "result", "[", "\"segmentation\"", "]", "=", "rles", "[", "k", "]", "\n", "", "if", "has_keypoints", ":", "\n", "# In COCO annotations,", "\n", "# keypoints coordinates are pixel indices.", "\n", "# However our predictions are floating point coordinates.", "\n", "# Therefore we subtract 0.5 to be consistent with the annotation format.", "\n", "# This is the inverse of data loading logic in `datasets/coco.py`.", "\n", "            ", "keypoints", "[", "k", "]", "[", ":", ",", ":", "2", "]", "-=", "0.5", "\n", "result", "[", "\"keypoints\"", "]", "=", "keypoints", "[", "k", "]", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation._evaluate_box_proposals": [[424, 532], ["torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "coco_api.getAnnIds", "coco_api.loadAnns", "torch.as_tensor().reshape", "detectron2.structures.Boxes", "torch.as_tensor", "len", "detectron2.structures.pairwise_iou", "torch.zeros", "range", "gt_overlaps.append", "len", "torch.cat", "torch.zeros", "torch.arange", "predictions.objectness_logits.sort", "detectron2.structures.BoxMode.convert", "len", "len", "min", "detectron2.structures.pairwise_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_evaluate_box_proposals", "(", "dataset_predictions", ",", "coco_api", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official COCO API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "prediction_dict", "in", "dataset_predictions", ":", "\n", "        ", "predictions", "=", "prediction_dict", "[", "\"proposals\"", "]", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "predictions", ".", "objectness_logits", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "predictions", "=", "predictions", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "coco_api", ".", "getAnnIds", "(", "imgIds", "=", "prediction_dict", "[", "\"image_id\"", "]", ")", "\n", "anno", "=", "coco_api", ".", "loadAnns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "for", "obj", "in", "anno", "\n", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "\n", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "Boxes", "(", "gt_boxes", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", "or", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "predictions", ")", ">", "limit", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "pairwise_iou", "(", "predictions", ".", "proposal_boxes", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "(", "\n", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "if", "len", "(", "gt_overlaps", ")", "else", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation._evaluate_predictions_on_coco": [[535, 580], ["coco_gt.loadRes", "coco_eval.evaluate", "coco_eval.accumulate", "coco_eval.summarize", "len", "copy.deepcopy", "len", "c.pop", "hasattr", "numpy.array", "len", "len", "next", "iter", "coco_gt.anns.values"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.fast_eval_api.COCOeval_opt.accumulate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter"], ["", "def", "_evaluate_predictions_on_coco", "(", "\n", "coco_gt", ",", "coco_results", ",", "iou_type", ",", "kpt_oks_sigmas", "=", "None", ",", "use_fast_impl", "=", "True", ",", "img_ids", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate the coco results using COCOEval API.\n    \"\"\"", "\n", "assert", "len", "(", "coco_results", ")", ">", "0", "\n", "\n", "if", "iou_type", "==", "\"segm\"", ":", "\n", "        ", "coco_results", "=", "copy", ".", "deepcopy", "(", "coco_results", ")", "\n", "# When evaluating mask AP, if the results contain bbox, cocoapi will", "\n", "# use the box area as the area of the instance, instead of the mask area.", "\n", "# This leads to a different definition of small/medium/large.", "\n", "# We remove the bbox field to let mask AP use mask area.", "\n", "for", "c", "in", "coco_results", ":", "\n", "            ", "c", ".", "pop", "(", "\"bbox\"", ",", "None", ")", "\n", "\n", "", "", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "coco_results", ")", "\n", "coco_eval", "=", "(", "COCOeval_opt", "if", "use_fast_impl", "else", "COCOeval", ")", "(", "coco_gt", ",", "coco_dt", ",", "iou_type", ")", "\n", "if", "img_ids", "is", "not", "None", ":", "\n", "        ", "coco_eval", ".", "params", ".", "imgIds", "=", "img_ids", "\n", "\n", "", "if", "iou_type", "==", "\"keypoints\"", ":", "\n", "# Use the COCO default keypoint OKS sigmas unless overrides are specified", "\n", "        ", "if", "kpt_oks_sigmas", ":", "\n", "            ", "assert", "hasattr", "(", "coco_eval", ".", "params", ",", "\"kpt_oks_sigmas\"", ")", ",", "\"pycocotools is too old!\"", "\n", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", "=", "np", ".", "array", "(", "kpt_oks_sigmas", ")", "\n", "# COCOAPI requires every detection and every gt to have keypoints, so", "\n", "# we just take the first entry from both", "\n", "", "num_keypoints_dt", "=", "len", "(", "coco_results", "[", "0", "]", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_gt", "=", "len", "(", "next", "(", "iter", "(", "coco_gt", ".", "anns", ".", "values", "(", ")", ")", ")", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_oks", "=", "len", "(", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", ")", "\n", "assert", "num_keypoints_oks", "==", "num_keypoints_dt", "==", "num_keypoints_gt", ",", "(", "\n", "f\"[COCOEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"", "\n", "f\"Ground truth contains {num_keypoints_gt} keypoints. \"", "\n", "f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"", "\n", "\"They have to agree with each other. For meaning of OKS, please refer to \"", "\n", "\"http://cocodataset.org/#keypoints-eval.\"", "\n", ")", "\n", "\n", "", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n", "return", "coco_eval", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator.__init__": [[32, 49], ["detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.mkdirs", "panoptic_evaluation.COCOPanopticEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "panoptic_evaluation.COCOPanopticEvaluator._metadata.stuff_dataset_id_to_contiguous_id.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "__init__", "(", "self", ",", "dataset_name", ":", "str", ",", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name: name of the dataset\n            output_dir: output directory to save results for evaluation.\n        \"\"\"", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "self", ".", "_thing_contiguous_id_to_dataset_id", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "_stuff_contiguous_id_to_dataset_id", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "stuff_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "if", "self", ".", "_output_dir", "is", "not", "None", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator.reset": [[50, 52], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id": [[53, 67], ["segment_info.pop"], "methods", ["None"], ["", "def", "_convert_category_id", "(", "self", ",", "segment_info", ")", ":", "\n", "        ", "isthing", "=", "segment_info", ".", "pop", "(", "\"isthing\"", ",", "None", ")", "\n", "if", "isthing", "is", "None", ":", "\n", "# the model produces panoptic category id directly. No more conversion needed", "\n", "            ", "return", "segment_info", "\n", "", "if", "isthing", "is", "True", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "self", ".", "_thing_contiguous_id_to_dataset_id", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "self", ".", "_stuff_contiguous_id_to_dataset_id", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "return", "segment_info", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator.process": [[68, 111], ["zip", "panoptic_img.cpu().numpy.cpu().numpy.cpu().numpy", "os.path.basename", "numpy.unique", "io.BytesIO", "PIL.Image.fromarray().save", "panoptic_evaluation.COCOPanopticEvaluator._predictions.append", "panoptic_img.cpu().numpy.cpu().numpy.cpu", "segments_info.append", "os.path.splitext", "panoptic_evaluation.COCOPanopticEvaluator._convert_category_id", "panoptic_evaluation.COCOPanopticEvaluator._metadata.thing_dataset_id_to_contiguous_id.values", "PIL.Image.fromarray", "out.getvalue", "int", "bool", "id2rgb", "int"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "panopticapi", ".", "utils", "import", "id2rgb", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "panoptic_img", ",", "segments_info", "=", "output", "[", "\"panoptic_seg\"", "]", "\n", "panoptic_img", "=", "panoptic_img", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "segments_info", "is", "None", ":", "\n", "# If \"segments_info\" is None, we assume \"panoptic_img\" is a", "\n", "# H*W int32 image storing the panoptic_id in the format of", "\n", "# category_id * label_divisor + instance_id. We reserve -1 for", "\n", "# VOID label, and add 1 to panoptic_img since the official", "\n", "# evaluation script uses 0 for VOID label.", "\n", "                ", "label_divisor", "=", "self", ".", "_metadata", ".", "label_divisor", "\n", "segments_info", "=", "[", "]", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_img", ")", ":", "\n", "                    ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "# VOID region.", "\n", "                        ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "label_divisor", "\n", "isthing", "=", "(", "\n", "pred_class", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", ")", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "int", "(", "panoptic_label", ")", "+", "1", ",", "\n", "\"category_id\"", ":", "int", "(", "pred_class", ")", ",", "\n", "\"isthing\"", ":", "bool", "(", "isthing", ")", ",", "\n", "}", "\n", ")", "\n", "# Official evaluation script uses 0 for VOID label.", "\n", "", "panoptic_img", "+=", "1", "\n", "\n", "", "file_name", "=", "os", ".", "path", ".", "basename", "(", "input", "[", "\"file_name\"", "]", ")", "\n", "file_name_png", "=", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "0", "]", "+", "\".png\"", "\n", "with", "io", ".", "BytesIO", "(", ")", "as", "out", ":", "\n", "                ", "Image", ".", "fromarray", "(", "id2rgb", "(", "panoptic_img", ")", ")", ".", "save", "(", "out", ",", "format", "=", "\"PNG\"", ")", "\n", "segments_info", "=", "[", "self", ".", "_convert_category_id", "(", "x", ")", "for", "x", "in", "segments_info", "]", "\n", "self", ".", "_predictions", ".", "append", "(", "\n", "{", "\n", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", ",", "\n", "\"file_name\"", ":", "file_name_png", ",", "\n", "\"png_string\"", ":", "out", ".", "getvalue", "(", ")", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation.COCOPanopticEvaluator.evaluate": [[114, 166], ["detectron2.utils.comm.synchronize", "detectron2.utils.comm.gather", "list", "detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.get_local_path", "collections.OrderedDict", "panoptic_evaluation._print_panoptic_results", "itertools.chain", "detectron2.utils.comm.is_main_process", "tempfile.TemporaryDirectory", "logger.info", "os.path.join", "open", "json.load", "detectron2.utils.file_io.PathManager.open", "f.write", "contextlib.redirect_stdout", "pq_compute", "open", "f.write", "json.dumps", "io.StringIO", "detectron2.utils.file_io.PathManager.get_local_path", "os.path.join", "p.pop"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation._print_panoptic_results", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "comm", ".", "synchronize", "(", ")", "\n", "\n", "self", ".", "_predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ")", "\n", "self", ".", "_predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "self", ".", "_predictions", ")", ")", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "# PanopticApi requires local files", "\n", "", "gt_json", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "panoptic_json", ")", "\n", "gt_folder", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "panoptic_root", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"panoptic_eval\"", ")", "as", "pred_dir", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing all panoptic predictions to {} ...\"", ".", "format", "(", "pred_dir", ")", ")", "\n", "for", "p", "in", "self", ".", "_predictions", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "pred_dir", ",", "p", "[", "\"file_name\"", "]", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "p", ".", "pop", "(", "\"png_string\"", ")", ")", "\n", "\n", "", "", "with", "open", "(", "gt_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "json_data", "[", "\"annotations\"", "]", "=", "self", ".", "_predictions", "\n", "\n", "output_dir", "=", "self", ".", "_output_dir", "or", "pred_dir", "\n", "predictions_json", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"predictions.json\"", ")", "\n", "with", "PathManager", ".", "open", "(", "predictions_json", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "json_data", ")", ")", "\n", "\n", "", "from", "panopticapi", ".", "evaluation", "import", "pq_compute", "\n", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "                ", "pq_res", "=", "pq_compute", "(", "\n", "gt_json", ",", "\n", "PathManager", ".", "get_local_path", "(", "predictions_json", ")", ",", "\n", "gt_folder", "=", "gt_folder", ",", "\n", "pred_folder", "=", "pred_dir", ",", "\n", ")", "\n", "\n", "", "", "res", "=", "{", "}", "\n", "res", "[", "\"PQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"rq\"", "]", "\n", "res", "[", "\"PQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"rq\"", "]", "\n", "res", "[", "\"PQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"rq\"", "]", "\n", "\n", "results", "=", "OrderedDict", "(", "{", "\"panoptic_seg\"", ":", "res", "}", ")", "\n", "_print_panoptic_results", "(", "pq_res", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.panoptic_evaluation._print_panoptic_results": [[168, 178], ["tabulate.tabulate", "logger.info", "data.append"], "function", ["None"], ["", "", "def", "_print_panoptic_results", "(", "pq_res", ")", ":", "\n", "    ", "headers", "=", "[", "\"\"", ",", "\"PQ\"", ",", "\"SQ\"", ",", "\"RQ\"", ",", "\"#categories\"", "]", "\n", "data", "=", "[", "]", "\n", "for", "name", "in", "[", "\"All\"", ",", "\"Things\"", ",", "\"Stuff\"", "]", ":", "\n", "        ", "row", "=", "[", "name", "]", "+", "[", "pq_res", "[", "name", "]", "[", "k", "]", "*", "100", "for", "k", "in", "[", "\"pq\"", ",", "\"sq\"", ",", "\"rq\"", "]", "]", "+", "[", "pq_res", "[", "name", "]", "[", "\"n\"", "]", "]", "\n", "data", ".", "append", "(", "row", ")", "\n", "", "table", "=", "tabulate", "(", "\n", "data", ",", "headers", "=", "headers", ",", "tablefmt", "=", "\"pipe\"", ",", "floatfmt", "=", "\".3f\"", ",", "stralign", "=", "\"center\"", ",", "numalign", "=", "\"center\"", "\n", ")", "\n", "logger", ".", "info", "(", "\"Panoptic Evaluation Results:\\n\"", "+", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.__init__": [[31, 50], ["detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "os.path.join", "os.path.join", "torch.device", "logging.getLogger", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "__init__", "(", "self", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset, e.g., \"voc_2007_test\"\n        \"\"\"", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "\n", "# Too many tiny files, download all to local for speed.", "\n", "annotation_dir_local", "=", "PathManager", ".", "get_local_path", "(", "\n", "os", ".", "path", ".", "join", "(", "meta", ".", "dirname", ",", "\"Annotations/\"", ")", "\n", ")", "\n", "self", ".", "_anno_file_template", "=", "os", ".", "path", ".", "join", "(", "annotation_dir_local", ",", "\"{}.xml\"", ")", "\n", "self", ".", "_image_set_path", "=", "os", ".", "path", ".", "join", "(", "meta", ".", "dirname", ",", "\"ImageSets\"", ",", "\"Main\"", ",", "meta", ".", "split", "+", "\".txt\"", ")", "\n", "self", ".", "_class_names", "=", "meta", ".", "thing_classes", "\n", "assert", "meta", ".", "year", "in", "[", "2007", ",", "2012", "]", ",", "meta", ".", "year", "\n", "self", ".", "_is_2007", "=", "meta", ".", "year", "==", "2007", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.reset": [[51, 53], ["collections.defaultdict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "defaultdict", "(", "list", ")", "# class name -> list of prediction strings", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.process": [[54, 68], ["zip", "output[].to", "output[].to.pred_boxes.tensor.numpy", "output[].to.scores.tolist", "output[].to.pred_classes.tolist", "zip", "pascal_voc_evaluation.PascalVOCDetectionEvaluator._predictions[].append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "image_id", "=", "input", "[", "\"image_id\"", "]", "\n", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "for", "box", ",", "score", ",", "cls", "in", "zip", "(", "boxes", ",", "scores", ",", "classes", ")", ":", "\n", "                ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "box", "\n", "# The inverse of data loading logic in `datasets/pascal_voc.py`", "\n", "xmin", "+=", "1", "\n", "ymin", "+=", "1", "\n", "self", ".", "_predictions", "[", "cls", "]", ".", "append", "(", "\n", "f\"{image_id} {score:.3f} {xmin:.1f} {ymin:.1f} {xmax:.1f} {ymax:.1f}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.evaluate": [[70, 116], ["detectron2.utils.comm.gather", "collections.defaultdict", "pascal_voc_evaluation.PascalVOCDetectionEvaluator._logger.info", "collections.OrderedDict", "detectron2.utils.comm.is_main_process", "predictions_per_rank.items", "tempfile.TemporaryDirectory", "os.path.join", "collections.defaultdict", "enumerate", "numpy.mean", "numpy.mean", "predictions[].extend", "collections.defaultdict.get", "range", "collections.defaultdict.items", "list", "open", "f.write", "pascal_voc_evaluation.voc_eval", "aps[].append", "mAP.values", "os.path.join.format"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.voc_eval"], ["", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: has a key \"segm\", whose value is a dict of \"AP\", \"AP50\", and \"AP75\".\n        \"\"\"", "\n", "all_predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "return", "\n", "", "predictions", "=", "defaultdict", "(", "list", ")", "\n", "for", "predictions_per_rank", "in", "all_predictions", ":", "\n", "            ", "for", "clsid", ",", "lines", "in", "predictions_per_rank", ".", "items", "(", ")", ":", "\n", "                ", "predictions", "[", "clsid", "]", ".", "extend", "(", "lines", ")", "\n", "", "", "del", "all_predictions", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluating {} using {} metric. \"", "\n", "\"Note that results do not use the official Matlab API.\"", ".", "format", "(", "\n", "self", ".", "_dataset_name", ",", "2007", "if", "self", ".", "_is_2007", "else", "2012", "\n", ")", "\n", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"pascal_voc_eval_\"", ")", "as", "dirname", ":", "\n", "            ", "res_file_template", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"{}.txt\"", ")", "\n", "\n", "aps", "=", "defaultdict", "(", "list", ")", "# iou -> ap per class", "\n", "for", "cls_id", ",", "cls_name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "                ", "lines", "=", "predictions", ".", "get", "(", "cls_id", ",", "[", "\"\"", "]", ")", "\n", "\n", "with", "open", "(", "res_file_template", ".", "format", "(", "cls_name", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "lines", ")", ")", "\n", "\n", "", "for", "thresh", "in", "range", "(", "50", ",", "100", ",", "5", ")", ":", "\n", "                    ", "rec", ",", "prec", ",", "ap", "=", "voc_eval", "(", "\n", "res_file_template", ",", "\n", "self", ".", "_anno_file_template", ",", "\n", "self", ".", "_image_set_path", ",", "\n", "cls_name", ",", "\n", "ovthresh", "=", "thresh", "/", "100.0", ",", "\n", "use_07_metric", "=", "self", ".", "_is_2007", ",", "\n", ")", "\n", "aps", "[", "thresh", "]", ".", "append", "(", "ap", "*", "100", ")", "\n", "\n", "", "", "", "ret", "=", "OrderedDict", "(", ")", "\n", "mAP", "=", "{", "iou", ":", "np", ".", "mean", "(", "x", ")", "for", "iou", ",", "x", "in", "aps", ".", "items", "(", ")", "}", "\n", "ret", "[", "\"bbox\"", "]", "=", "{", "\"AP\"", ":", "np", ".", "mean", "(", "list", "(", "mAP", ".", "values", "(", ")", ")", ")", ",", "\"AP50\"", ":", "mAP", "[", "50", "]", ",", "\"AP75\"", ":", "mAP", "[", "75", "]", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.parse_rec": [[131, 153], ["functools.lru_cache", "ET.parse.findall", "detectron2.utils.file_io.PathManager.open", "xml.parse", "int", "int", "obj.find", "objects.append", "obj.find", "obj.find", "int", "int", "int", "int", "obj.find", "obj.find", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["None"], ["@", "lru_cache", "(", "maxsize", "=", "None", ")", "\n", "def", "parse_rec", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Parse a PASCAL VOC xml file.\"\"\"", "\n", "with", "PathManager", ".", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "tree", "=", "ET", ".", "parse", "(", "f", ")", "\n", "", "objects", "=", "[", "]", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "\"object\"", ")", ":", "\n", "        ", "obj_struct", "=", "{", "}", "\n", "obj_struct", "[", "\"name\"", "]", "=", "obj", ".", "find", "(", "\"name\"", ")", ".", "text", "\n", "obj_struct", "[", "\"pose\"", "]", "=", "obj", ".", "find", "(", "\"pose\"", ")", ".", "text", "\n", "obj_struct", "[", "\"truncated\"", "]", "=", "int", "(", "obj", ".", "find", "(", "\"truncated\"", ")", ".", "text", ")", "\n", "obj_struct", "[", "\"difficult\"", "]", "=", "int", "(", "obj", ".", "find", "(", "\"difficult\"", ")", ".", "text", ")", "\n", "bbox", "=", "obj", ".", "find", "(", "\"bndbox\"", ")", "\n", "obj_struct", "[", "\"bbox\"", "]", "=", "[", "\n", "int", "(", "bbox", ".", "find", "(", "\"xmin\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"ymin\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"xmax\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"ymax\"", ")", ".", "text", ")", ",", "\n", "]", "\n", "objects", ".", "append", "(", "obj_struct", ")", "\n", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.voc_ap": [[155, 185], ["numpy.arange", "numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where", "numpy.sum", "numpy.max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute VOC AP given precision and recall. If use_07_metric is true, uses\n    the VOC 07 11-point method (default:False).\n    \"\"\"", "\n", "if", "use_07_metric", ":", "\n", "# 11 point metric", "\n", "        ", "ap", "=", "0.0", "\n", "for", "t", "in", "np", ".", "arange", "(", "0.0", ",", "1.1", ",", "0.1", ")", ":", "\n", "            ", "if", "np", ".", "sum", "(", "rec", ">=", "t", ")", "==", "0", ":", "\n", "                ", "p", "=", "0", "\n", "", "else", ":", "\n", "                ", "p", "=", "np", ".", "max", "(", "prec", "[", "rec", ">=", "t", "]", ")", "\n", "", "ap", "=", "ap", "+", "p", "/", "11.0", "\n", "", "", "else", ":", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "        ", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "rec", ",", "[", "1.0", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "prec", ",", "[", "0.0", "]", ")", ")", "\n", "\n", "# compute the precision envelope", "\n", "for", "i", "in", "range", "(", "mpre", ".", "size", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "mpre", "[", "i", "-", "1", "]", "=", "np", ".", "maximum", "(", "mpre", "[", "i", "-", "1", "]", ",", "mpre", "[", "i", "]", ")", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.voc_eval": [[187, 301], ["detpath.format", "numpy.array", "numpy.array().reshape", "numpy.argsort", "len", "numpy.zeros", "numpy.zeros", "range", "numpy.cumsum", "numpy.cumsum", "pascal_voc_evaluation.voc_ap", "detectron2.utils.file_io.PathManager.open", "f.readlines", "x.strip", "pascal_voc_evaluation.parse_rec", "numpy.array", "numpy.array().astype", "open", "f.readlines", "x.strip().split", "BB[].astype", "R[].astype", "float", "numpy.maximum", "annopath.format", "len", "sum", "float", "numpy.array", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.max", "numpy.argmax", "numpy.array", "x.strip", "numpy.finfo", "float"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.voc_ap", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.pascal_voc_evaluation.parse_rec", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "voc_eval", "(", "detpath", ",", "annopath", ",", "imagesetfile", ",", "classname", ",", "ovthresh", "=", "0.5", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"rec, prec, ap = voc_eval(detpath,\n                                annopath,\n                                imagesetfile,\n                                classname,\n                                [ovthresh],\n                                [use_07_metric])\n\n    Top level function that does the PASCAL VOC evaluation.\n\n    detpath: Path to detections\n        detpath.format(classname) should produce the detection results file.\n    annopath: Path to annotations\n        annopath.format(imagename) should be the xml annotations file.\n    imagesetfile: Text file containing the list of images, one image per line.\n    classname: Category name (duh)\n    [ovthresh]: Overlap threshold (default = 0.5)\n    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n        (default False)\n    \"\"\"", "\n", "# assumes detections are in detpath.format(classname)", "\n", "# assumes annotations are in annopath.format(imagename)", "\n", "# assumes imagesetfile is a text file with each line an image name", "\n", "\n", "# first load gt", "\n", "# read list of images", "\n", "with", "PathManager", ".", "open", "(", "imagesetfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "imagenames", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "lines", "]", "\n", "\n", "# load annots", "\n", "recs", "=", "{", "}", "\n", "for", "imagename", "in", "imagenames", ":", "\n", "        ", "recs", "[", "imagename", "]", "=", "parse_rec", "(", "annopath", ".", "format", "(", "imagename", ")", ")", "\n", "\n", "# extract gt objects for this class", "\n", "", "class_recs", "=", "{", "}", "\n", "npos", "=", "0", "\n", "for", "imagename", "in", "imagenames", ":", "\n", "        ", "R", "=", "[", "obj", "for", "obj", "in", "recs", "[", "imagename", "]", "if", "obj", "[", "\"name\"", "]", "==", "classname", "]", "\n", "bbox", "=", "np", ".", "array", "(", "[", "x", "[", "\"bbox\"", "]", "for", "x", "in", "R", "]", ")", "\n", "difficult", "=", "np", ".", "array", "(", "[", "x", "[", "\"difficult\"", "]", "for", "x", "in", "R", "]", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "# difficult = np.array([False for x in R]).astype(np.bool)  # treat all \"difficult\" as GT", "\n", "det", "=", "[", "False", "]", "*", "len", "(", "R", ")", "\n", "npos", "=", "npos", "+", "sum", "(", "~", "difficult", ")", "\n", "class_recs", "[", "imagename", "]", "=", "{", "\"bbox\"", ":", "bbox", ",", "\"difficult\"", ":", "difficult", ",", "\"det\"", ":", "det", "}", "\n", "\n", "# read dets", "\n", "", "detfile", "=", "detpath", ".", "format", "(", "classname", ")", "\n", "with", "open", "(", "detfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "x", "in", "lines", "]", "\n", "image_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "splitlines", "]", "\n", "confidence", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "1", "]", ")", "for", "x", "in", "splitlines", "]", ")", "\n", "BB", "=", "np", ".", "array", "(", "[", "[", "float", "(", "z", ")", "for", "z", "in", "x", "[", "2", ":", "]", "]", "for", "x", "in", "splitlines", "]", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "\n", "# sort by confidence", "\n", "sorted_ind", "=", "np", ".", "argsort", "(", "-", "confidence", ")", "\n", "BB", "=", "BB", "[", "sorted_ind", ",", ":", "]", "\n", "image_ids", "=", "[", "image_ids", "[", "x", "]", "for", "x", "in", "sorted_ind", "]", "\n", "\n", "# go down dets and mark TPs and FPs", "\n", "nd", "=", "len", "(", "image_ids", ")", "\n", "tp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "for", "d", "in", "range", "(", "nd", ")", ":", "\n", "        ", "R", "=", "class_recs", "[", "image_ids", "[", "d", "]", "]", "\n", "bb", "=", "BB", "[", "d", ",", ":", "]", ".", "astype", "(", "float", ")", "\n", "ovmax", "=", "-", "np", ".", "inf", "\n", "BBGT", "=", "R", "[", "\"bbox\"", "]", ".", "astype", "(", "float", ")", "\n", "\n", "if", "BBGT", ".", "size", ">", "0", ":", "\n", "# compute overlaps", "\n", "# intersection", "\n", "            ", "ixmin", "=", "np", ".", "maximum", "(", "BBGT", "[", ":", ",", "0", "]", ",", "bb", "[", "0", "]", ")", "\n", "iymin", "=", "np", ".", "maximum", "(", "BBGT", "[", ":", ",", "1", "]", ",", "bb", "[", "1", "]", ")", "\n", "ixmax", "=", "np", ".", "minimum", "(", "BBGT", "[", ":", ",", "2", "]", ",", "bb", "[", "2", "]", ")", "\n", "iymax", "=", "np", ".", "minimum", "(", "BBGT", "[", ":", ",", "3", "]", ",", "bb", "[", "3", "]", ")", "\n", "iw", "=", "np", ".", "maximum", "(", "ixmax", "-", "ixmin", "+", "1.0", ",", "0.0", ")", "\n", "ih", "=", "np", ".", "maximum", "(", "iymax", "-", "iymin", "+", "1.0", ",", "0.0", ")", "\n", "inters", "=", "iw", "*", "ih", "\n", "\n", "# union", "\n", "uni", "=", "(", "\n", "(", "bb", "[", "2", "]", "-", "bb", "[", "0", "]", "+", "1.0", ")", "*", "(", "bb", "[", "3", "]", "-", "bb", "[", "1", "]", "+", "1.0", ")", "\n", "+", "(", "BBGT", "[", ":", ",", "2", "]", "-", "BBGT", "[", ":", ",", "0", "]", "+", "1.0", ")", "*", "(", "BBGT", "[", ":", ",", "3", "]", "-", "BBGT", "[", ":", ",", "1", "]", "+", "1.0", ")", "\n", "-", "inters", "\n", ")", "\n", "\n", "overlaps", "=", "inters", "/", "uni", "\n", "ovmax", "=", "np", ".", "max", "(", "overlaps", ")", "\n", "jmax", "=", "np", ".", "argmax", "(", "overlaps", ")", "\n", "\n", "", "if", "ovmax", ">", "ovthresh", ":", "\n", "            ", "if", "not", "R", "[", "\"difficult\"", "]", "[", "jmax", "]", ":", "\n", "                ", "if", "not", "R", "[", "\"det\"", "]", "[", "jmax", "]", ":", "\n", "                    ", "tp", "[", "d", "]", "=", "1.0", "\n", "R", "[", "\"det\"", "]", "[", "jmax", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "fp", "[", "d", "]", "=", "1.0", "\n", "", "", "", "else", ":", "\n", "            ", "fp", "[", "d", "]", "=", "1.0", "\n", "\n", "# compute precision recall", "\n", "", "", "fp", "=", "np", ".", "cumsum", "(", "fp", ")", "\n", "tp", "=", "np", ".", "cumsum", "(", "tp", ")", "\n", "rec", "=", "tp", "/", "float", "(", "npos", ")", "\n", "# avoid divide by zero in case the first detection matches a difficult", "\n", "# ground truth", "\n", "prec", "=", "tp", "/", "np", ".", "maximum", "(", "tp", "+", "fp", ",", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", ")", "\n", "ap", "=", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", ")", "\n", "\n", "return", "rec", ",", "prec", ",", "ap", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.print_csv_format": [[10, 27], ["logging.getLogger", "results.items", "isinstance", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "len", "res.items"], "function", ["None"], ["from", "detectron2", ".", "structures", "import", "Boxes", ",", "Instances", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "\"\"\"\nInternal utilities for tests. Don't use except for writing tests.\n\"\"\"", "\n", "\n", "\n", "def", "get_model_no_weights", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Like model_zoo.get, but do not load any weights (even pretrained)\n    \"\"\"", "\n", "cfg", "=", "model_zoo", ".", "get_config", "(", "config_path", ")", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "", "return", "build_model", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.verify_results": [[29, 64], ["logging.getLogger", "len", "results[].get", "abs", "logging.getLogger.error", "logging.getLogger.error", "logging.getLogger.error", "sys.exit", "logging.getLogger.info", "numpy.isfinite", "str", "pprint.pformat"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "random_boxes", "(", "num_boxes", ",", "max_coord", "=", "100", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    Create a random Nx4 boxes tensor, with coordinates < max_coord.\n    \"\"\"", "\n", "boxes", "=", "torch", ".", "rand", "(", "num_boxes", ",", "4", ",", "device", "=", "device", ")", "*", "(", "max_coord", "*", "0.5", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "1.0", ")", "# tiny boxes cause numerical instability in box regression", "\n", "# Note: the implementation of this function in torchvision is:", "\n", "# boxes[:, 2:] += torch.rand(N, 2) * 100", "\n", "# but it does not guarantee non-negative widths/heights constraints:", "\n", "# boxes[:, 2] >= boxes[:, 0] and boxes[:, 3] >= boxes[:, 1]:", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n", "\n", "", "def", "get_sample_coco_image", "(", "tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        tensor (bool): if True, returns 3xHxW tensor.\n            else, returns a HxWx3 numpy array.\n\n    Returns:\n        an image, in BGR color.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "file_name", "=", "DatasetCatalog", ".", "get", "(", "\"coco_2017_val_100\"", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "if", "not", "PathManager", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# for public CI to run", "\n", "        ", "file_name", "=", "\"http://images.cocodataset.org/train2017/000000000009.jpg\"", "\n", "", "ret", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "\n", "if", "tensor", ":", "\n", "        ", "ret", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "ret", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "", "return", "ret", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.flatten_results_dict": [[66, 84], ["results.items", "isinstance", "testing.flatten_results_dict", "flatten_results_dict.items"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.flatten_results_dict"], ["    ", "\"\"\"\n    Convert a scripted Instances object to a regular :class:`Instances` object\n    \"\"\"", "\n", "ret", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "for", "name", "in", "instances", ".", "_field_names", ":", "\n", "        ", "val", "=", "getattr", "(", "instances", ",", "\"_\"", "+", "name", ",", "None", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "            ", "ret", ".", "set", "(", "name", ",", "val", ")", "\n", "", "", "return", "ret", "\n", "\n", "\n", "", "def", "assert_instances_allclose", "(", "input", ",", "other", ",", "*", ",", "rtol", "=", "1e-5", ",", "msg", "=", "\"\"", ",", "size_as_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input, other (Instances):\n        size_as_tensor: compare image_size of the Instances as tensors (instead of tuples).\n             Useful for comparing outputs of tracing.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input", ",", "Instances", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluator.reset": [[25, 31], ["None"], "methods", ["None"], ["def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Preparation for a new round of evaluation.\n        Should be called before starting a round of evaluation.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluator.process": [[32, 48], ["None"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Process the pair of inputs and outputs.\n        If they contain batches, the pairs can be consumed one-by-one using `zip`:\n\n        .. code-block:: python\n\n            for input_, output in zip(inputs, outputs):\n                # do evaluation on single input/output pair\n                ...\n\n        Args:\n            inputs (list): the inputs that's used to call the model.\n            outputs (list): the return value of `model(inputs)`\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluator.evaluate": [[49, 63], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate/summarize the performance, after processing all input/output pairs.\n\n        Returns:\n            dict:\n                A new evaluator class can return a dict of arbitrary format\n                as long as the user can process the results.\n                In our train_net.py, we expect the following format:\n\n                * key: the name of the task (e.g., bbox)\n                * value: a dict of {metric name: score}, e.g.: {\"AP50\": 80}\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluators.__init__": [[73, 80], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "evaluators", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            evaluators (list): the evaluators to combine.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_evaluators", "=", "evaluators", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluators.reset": [[81, 84], ["evaluator.reset"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluators.process": [[85, 88], ["evaluator.process"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.process"], ["", "", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.DatasetEvaluators.evaluate": [[89, 100], ["collections.OrderedDict", "evaluator.evaluate", "detectron2.utils.comm.is_main_process", "evaluator.evaluate.items"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "result", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "if", "is_main_process", "(", ")", "and", "result", "is", "not", "None", ":", "\n", "                ", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                    ", "assert", "(", "\n", "k", "not", "in", "results", "\n", ")", ",", "\"Different evaluators produce results with the same key {}\"", ".", "format", "(", "k", ")", "\n", "results", "[", "k", "]", "=", "v", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.inference_on_dataset": [[102, 188], ["detectron2.utils.comm.get_world_size", "logging.getLogger", "logging.getLogger.info", "len", "evaluator.DatasetEvaluators.reset", "min", "time.perf_counter", "str", "logging.getLogger.info", "str", "logging.getLogger.info", "evaluator.DatasetEvaluators.evaluate", "evaluator.DatasetEvaluators", "contextlib.ExitStack", "isinstance", "stack.enter_context", "enumerate", "time.perf_counter", "datetime.timedelta", "datetime.timedelta", "len", "stack.enter_context", "torch.no_grad", "time.perf_counter", "model", "torch.cuda.is_available", "evaluator.DatasetEvaluators.process", "evaluator.inference_context", "time.perf_counter", "torch.cuda.synchronize", "time.perf_counter", "datetime.timedelta", "detectron2.utils.logger.log_every_n_seconds", "int", "int", "time.perf_counter", "int", "str"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.inference_context", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.logger.log_every_n_seconds"], ["", "", "def", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", ":", "\n", "    ", "\"\"\"\n    Run model on the data_loader and evaluate the metrics with evaluator.\n    Also benchmark the inference speed of `model.__call__` accurately.\n    The model will be used in eval mode.\n\n    Args:\n        model (callable): a callable which takes an object from\n            `data_loader` and returns some outputs.\n\n            If it's an nn.Module, it will be temporarily set to `eval` mode.\n            If you wish to evaluate a model in `training` mode instead, you can\n            wrap the given model and override its behavior of `.eval()` and `.train()`.\n        data_loader: an iterable object with a length.\n            The elements it generates will be the inputs to the model.\n        evaluator (DatasetEvaluator): the evaluator to run. Use `None` if you only want\n            to benchmark, but don't want to do any evaluation.\n\n    Returns:\n        The return value of `evaluator.evaluate()`\n    \"\"\"", "\n", "num_devices", "=", "get_world_size", "(", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Start inference on {} images\"", ".", "format", "(", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "total", "=", "len", "(", "data_loader", ")", "# inference data loader must have a fixed length", "\n", "if", "evaluator", "is", "None", ":", "\n", "# create a no-op evaluator", "\n", "        ", "evaluator", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "", "evaluator", ".", "reset", "(", ")", "\n", "\n", "num_warmup", "=", "min", "(", "5", ",", "total", "-", "1", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "stack", ".", "enter_context", "(", "inference_context", "(", "model", ")", ")", "\n", "", "stack", ".", "enter_context", "(", "torch", ".", "no_grad", "(", ")", ")", "\n", "\n", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "if", "idx", "==", "num_warmup", ":", "\n", "                ", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "\n", "", "start_compute_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "total_compute_time", "+=", "time", ".", "perf_counter", "(", ")", "-", "start_compute_time", "\n", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n", "iters_after_start", "=", "idx", "+", "1", "-", "num_warmup", "*", "int", "(", "idx", ">=", "num_warmup", ")", "\n", "seconds_per_img", "=", "total_compute_time", "/", "iters_after_start", "\n", "if", "idx", ">=", "num_warmup", "*", "2", "or", "seconds_per_img", ">", "5", ":", "\n", "                ", "total_seconds_per_img", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "start_time", ")", "/", "iters_after_start", "\n", "eta", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_seconds_per_img", "*", "(", "total", "-", "idx", "-", "1", ")", ")", ")", "\n", "log_every_n_seconds", "(", "\n", "logging", ".", "INFO", ",", "\n", "\"Inference done {}/{}. {:.4f} s / img. ETA={}\"", ".", "format", "(", "\n", "idx", "+", "1", ",", "total", ",", "seconds_per_img", ",", "str", "(", "eta", ")", "\n", ")", ",", "\n", "n", "=", "5", ",", "\n", ")", "\n", "\n", "# Measure the time only for this worker (before the synchronization barrier)", "\n", "", "", "", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_time", ")", ")", "\n", "# NOTE this format is parsed by grep", "\n", "logger", ".", "info", "(", "\n", "\"Total inference time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "total_compute_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_compute_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total inference pure compute time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_compute_time_str", ",", "total_compute_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "\n", "results", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "# An evaluator may return None when not in main process.", "\n", "# Replace it by an empty dict instead to make it easier for downstream code to handle", "\n", "if", "results", "is", "None", ":", "\n", "        ", "results", "=", "{", "}", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.evaluator.inference_context": [[190, 203], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train"], ["", "@", "contextmanager", "\n", "def", "inference_context", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n\n    Args:\n        model: a torch Module\n    \"\"\"", "\n", "training_mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "training_mode", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated": [[16, 32], ["type", "type", "numpy.all", "numpy.array", "len", "type", "type"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "is_rotated", "(", "box_list", ")", ":", "\n", "        ", "if", "type", "(", "box_list", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "return", "box_list", ".", "shape", "[", "1", "]", "==", "5", "\n", "", "elif", "type", "(", "box_list", ")", "==", "list", ":", "\n", "            ", "if", "box_list", "==", "[", "]", ":", "# cannot decide the box_dim", "\n", "                ", "return", "False", "\n", "", "return", "np", ".", "all", "(", "\n", "np", ".", "array", "(", "\n", "[", "\n", "(", "len", "(", "obj", ")", "==", "5", ")", "and", "(", "(", "type", "(", "obj", ")", "==", "list", ")", "or", "(", "type", "(", "obj", ")", "==", "np", ".", "ndarray", ")", ")", "\n", "for", "obj", "in", "box_list", "\n", "]", "\n", ")", "\n", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor": [[33, 56], ["type", "torch.from_numpy", "type", "Exception", "detectron2.structures.BoxMode.convert", "Exception", "torch.zeros", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["", "@", "staticmethod", "\n", "def", "boxlist_to_tensor", "(", "boxlist", ",", "output_box_dim", ")", ":", "\n", "        ", "if", "type", "(", "boxlist", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "box_tensor", "=", "torch", ".", "from_numpy", "(", "boxlist", ")", "\n", "", "elif", "type", "(", "boxlist", ")", "==", "list", ":", "\n", "            ", "if", "boxlist", "==", "[", "]", ":", "\n", "                ", "return", "torch", ".", "zeros", "(", "(", "0", ",", "output_box_dim", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "box_tensor", "=", "torch", ".", "FloatTensor", "(", "boxlist", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unrecognized boxlist type\"", ")", "\n", "\n", "", "input_box_dim", "=", "box_tensor", ".", "shape", "[", "1", "]", "\n", "if", "input_box_dim", "!=", "output_box_dim", ":", "\n", "            ", "if", "input_box_dim", "==", "4", "and", "output_box_dim", "==", "5", ":", "\n", "                ", "box_tensor", "=", "BoxMode", ".", "convert", "(", "box_tensor", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYWHA_ABS", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Unable to convert from {}-dim box to {}-dim box\"", ".", "format", "(", "\n", "input_box_dim", ",", "output_box_dim", "\n", ")", "\n", ")", "\n", "", "", "return", "box_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt": [[57, 67], ["rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "all", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes", "detectron2.structures.pairwise_iou_rotated", "pycocotools.cocoeval.maskUtils.iou", "rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor", "rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.rotated_boxes.pairwise_iou_rotated", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor"], ["", "def", "compute_iou_dt_gt", "(", "self", ",", "dt", ",", "gt", ",", "is_crowd", ")", ":", "\n", "        ", "if", "self", ".", "is_rotated", "(", "dt", ")", "or", "self", ".", "is_rotated", "(", "gt", ")", ":", "\n", "# TODO: take is_crowd into consideration", "\n", "            ", "assert", "all", "(", "c", "==", "0", "for", "c", "in", "is_crowd", ")", "\n", "dt", "=", "RotatedBoxes", "(", "self", ".", "boxlist_to_tensor", "(", "dt", ",", "output_box_dim", "=", "5", ")", ")", "\n", "gt", "=", "RotatedBoxes", "(", "self", ".", "boxlist_to_tensor", "(", "gt", ",", "output_box_dim", "=", "5", ")", ")", "\n", "return", "pairwise_iou_rotated", "(", "dt", ",", "gt", ")", "\n", "", "else", ":", "\n", "# This is the same as the classical COCO evaluation", "\n", "            ", "return", "maskUtils", ".", "iou", "(", "dt", ",", "gt", ",", "is_crowd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.computeIoU": [[68, 95], ["numpy.argsort", "rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt", "len", "int", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt"], ["", "", "def", "computeIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "assert", "p", ".", "iouType", "==", "\"bbox\"", ",", "\"unsupported iouType for iou computation\"", "\n", "\n", "g", "=", "[", "g", "[", "\"bbox\"", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "\"bbox\"", "]", "for", "d", "in", "dt", "]", "\n", "\n", "# compute iou between each dt and gt region", "\n", "iscrowd", "=", "[", "int", "(", "o", "[", "\"iscrowd\"", "]", ")", "for", "o", "in", "gt", "]", "\n", "\n", "# Note: this function is copied from cocoeval.py in cocoapi", "\n", "# and the major difference is here.", "\n", "ious", "=", "self", ".", "compute_iou_dt_gt", "(", "d", ",", "g", ",", "iscrowd", ")", "\n", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.process": [[104, 123], ["zip", "rotated_coco_evaluation.RotatedCOCOEvaluator._predictions.append", "output[].to", "rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json", "output[].to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a COCO model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "\n", "prediction", "[", "\"instances\"", "]", "=", "self", ".", "instances_to_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json": [[124, 147], ["len", "instances.pred_boxes.tensor.numpy", "detectron2.structures.BoxMode.convert.tolist", "instances.scores.tolist", "instances.pred_classes.tolist", "range", "detectron2.structures.BoxMode.convert", "results.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert"], ["", "", "def", "instances_to_json", "(", "self", ",", "instances", ",", "img_id", ")", ":", "\n", "        ", "num_instance", "=", "len", "(", "instances", ")", "\n", "if", "num_instance", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "if", "boxes", ".", "shape", "[", "1", "]", "==", "4", ":", "\n", "            ", "boxes", "=", "BoxMode", ".", "convert", "(", "boxes", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "", "boxes", "=", "boxes", ".", "tolist", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_instance", ")", ":", "\n", "            ", "result", "=", "{", "\n", "\"image_id\"", ":", "img_id", ",", "\n", "\"category_id\"", ":", "classes", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "boxes", "[", "k", "]", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._eval_predictions": [[148, 191], ["rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "list", "hasattr", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._derive_coco_results", "itertools.chain", "os.path.join", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "set", "len", "rotated_coco_evaluation.RotatedCOCOEvaluator._metadata.get", "rotated_coco_evaluation.RotatedCOCOEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ",", "img_ids", "=", "None", ")", ":", "# img_ids: unused", "\n", "        ", "\"\"\"\n        Evaluate predictions on the given tasks.\n        Fill self._results with the metrics of the tasks.\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results for COCO format ...\"", ")", "\n", "coco_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "\n", "# unmap the category ids for COCO", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "reverse_id_mapping", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "for", "result", "in", "coco_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "result", "[", "\"category_id\"", "]", "]", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"coco_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "coco_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating predictions ...\"", ")", "\n", "\n", "assert", "self", ".", "_tasks", "is", "None", "or", "set", "(", "self", ".", "_tasks", ")", "==", "{", "\n", "\"bbox\"", "\n", "}", ",", "\"[RotatedCOCOEvaluator] Only bbox evaluation is supported\"", "\n", "coco_eval", "=", "(", "\n", "self", ".", "_evaluate_predictions_on_coco", "(", "self", ".", "_coco_api", ",", "coco_results", ")", "\n", "if", "len", "(", "coco_results", ")", ">", "0", "\n", "else", "None", "# cocoapi does not handle empty results very well", "\n", ")", "\n", "\n", "task", "=", "\"bbox\"", "\n", "res", "=", "self", ".", "_derive_coco_results", "(", "\n", "coco_eval", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco": [[192, 208], ["coco_gt.loadRes", "rotated_coco_evaluation.RotatedCOCOeval", "RotatedCOCOeval.evaluate", "RotatedCOCOeval.accumulate", "RotatedCOCOeval.summarize", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.fast_eval_api.COCOeval_opt.accumulate"], ["", "def", "_evaluate_predictions_on_coco", "(", "self", ",", "coco_gt", ",", "coco_results", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the coco results using COCOEval API.\n        \"\"\"", "\n", "assert", "len", "(", "coco_results", ")", ">", "0", "\n", "\n", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "coco_results", ")", "\n", "\n", "# Only bbox is supported for now", "\n", "coco_eval", "=", "RotatedCOCOeval", "(", "coco_gt", ",", "coco_dt", ",", "iouType", "=", "\"bbox\"", ")", "\n", "\n", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n", "return", "coco_eval", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.__init__": [[23, 33], ["detectron2.data.MetadataCatalog.get", "torch.device", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device"], ["def", "__init__", "(", "self", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): the name of the dataset.\n                It must have the following metadata associated with it:\n                \"thing_classes\", \"gt_dir\".\n        \"\"\"", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset": [[34, 44], ["tempfile.TemporaryDirectory", "cityscapes_evaluation.CityscapesEvaluator._logger.info", "detectron2.utils.comm.all_gather", "cityscapes_evaluation.CityscapesEvaluator._working_dir.cleanup"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_working_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"cityscapes_eval_\"", ")", "\n", "self", ".", "_temp_dir", "=", "self", ".", "_working_dir", ".", "name", "\n", "# All workers will write to the same results directory", "\n", "# TODO this does not work in distributed training", "\n", "self", ".", "_temp_dir", "=", "comm", ".", "all_gather", "(", "self", ".", "_temp_dir", ")", "[", "0", "]", "\n", "if", "self", ".", "_temp_dir", "!=", "self", ".", "_working_dir", ".", "name", ":", "\n", "            ", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "", "self", ".", "_logger", ".", "info", "(", "\n", "\"Writing cityscapes results to temporary directory {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesInstanceEvaluator.process": [[57, 87], ["zip", "os.path.join", "os.path.splitext", "output[].to", "len", "os.path.basename", "open", "range", "open", "output[].to.pred_masks[].numpy().astype", "os.path.join", "PIL.Image.fromarray().save", "fout.write", "output[].to.pred_masks[].numpy", "PIL.Image.fromarray", "os.path.basename"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.CommonMetricPrinter.write"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "name2label", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "file_name", "=", "input", "[", "\"file_name\"", "]", "\n", "basename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "0", "]", "\n", "pred_txt", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "basename", "+", "\"_pred.txt\"", ")", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "output", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "num_instances", "=", "len", "(", "output", ")", "\n", "with", "open", "(", "pred_txt", ",", "\"w\"", ")", "as", "fout", ":", "\n", "                    ", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "                        ", "pred_class", "=", "output", ".", "pred_classes", "[", "i", "]", "\n", "classes", "=", "self", ".", "_metadata", ".", "thing_classes", "[", "pred_class", "]", "\n", "class_id", "=", "name2label", "[", "classes", "]", ".", "id", "\n", "score", "=", "output", ".", "scores", "[", "i", "]", "\n", "mask", "=", "output", ".", "pred_masks", "[", "i", "]", ".", "numpy", "(", ")", ".", "astype", "(", "\"uint8\"", ")", "\n", "png_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_temp_dir", ",", "basename", "+", "\"_{}_{}.png\"", ".", "format", "(", "i", ",", "classes", ")", "\n", ")", "\n", "\n", "Image", ".", "fromarray", "(", "mask", "*", "255", ")", ".", "save", "(", "png_filename", ")", "\n", "fout", ".", "write", "(", "\n", "\"{} {} {}\\n\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "png_filename", ")", ",", "class_id", ",", "score", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "# Cityscapes requires a prediction file for every ground truth image.", "\n", "                ", "with", "open", "(", "pred_txt", ",", "\"w\"", ")", "as", "fout", ":", "\n", "                    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesInstanceEvaluator.evaluate": [[88, 127], ["detectron2.utils.comm.synchronize", "cityscapes_evaluation.CityscapesInstanceEvaluator._logger.info", "os.path.abspath", "os.path.join", "detectron2.utils.file_io.PathManager.get_local_path", "glob.glob", "len", "collections.OrderedDict", "cityscapes_evaluation.CityscapesInstanceEvaluator._working_dir.cleanup", "detectron2.utils.comm.get_rank", "os.path.join", "predictionImgList.append", "cityscapes_eval.evaluateImgLists", "cityscapes_eval.getPrediction"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: has a key \"segm\", whose value is a dict of \"AP\" and \"AP50\".\n        \"\"\"", "\n", "comm", ".", "synchronize", "(", ")", "\n", "if", "comm", ".", "get_rank", "(", ")", ">", "0", ":", "\n", "            ", "return", "\n", "", "import", "cityscapesscripts", ".", "evaluation", ".", "evalInstanceLevelSemanticLabeling", "as", "cityscapes_eval", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Evaluating results under {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", ")", "\n", "\n", "# set some global states in cityscapes evaluation API, before evaluating", "\n", "cityscapes_eval", ".", "args", ".", "predictionPath", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "_temp_dir", ")", "\n", "cityscapes_eval", ".", "args", ".", "predictionWalk", "=", "None", "\n", "cityscapes_eval", ".", "args", ".", "JSONOutput", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "colorized", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "gtInstancesFile", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "\"gtInstances.json\"", ")", "\n", "\n", "# These lines are adopted from", "\n", "# https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalInstanceLevelSemanticLabeling.py # noqa", "\n", "gt_dir", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "gt_dir", ")", "\n", "groundTruthImgList", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "\"*\"", ",", "\"*_gtFine_instanceIds.png\"", ")", ")", "\n", "assert", "len", "(", "\n", "groundTruthImgList", "\n", ")", ",", "\"Cannot find any ground truth images to use for evaluation. Searched for: {}\"", ".", "format", "(", "\n", "cityscapes_eval", ".", "args", ".", "groundTruthSearch", "\n", ")", "\n", "predictionImgList", "=", "[", "]", "\n", "for", "gt", "in", "groundTruthImgList", ":", "\n", "            ", "predictionImgList", ".", "append", "(", "cityscapes_eval", ".", "getPrediction", "(", "gt", ",", "cityscapes_eval", ".", "args", ")", ")", "\n", "", "results", "=", "cityscapes_eval", ".", "evaluateImgLists", "(", "\n", "predictionImgList", ",", "groundTruthImgList", ",", "cityscapes_eval", ".", "args", "\n", ")", "[", "\"averages\"", "]", "\n", "\n", "ret", "=", "OrderedDict", "(", ")", "\n", "ret", "[", "\"segm\"", "]", "=", "{", "\"AP\"", ":", "results", "[", "\"allAp\"", "]", "*", "100", ",", "\"AP50\"", ":", "results", "[", "\"allAp50%\"", "]", "*", "100", "}", "\n", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.process": [[139, 154], ["zip", "os.path.join", "output[].argmax().to().numpy", "trainId2label.items", "PIL.Image.fromarray().save", "os.path.splitext", "numpy.ones", "os.path.basename", "output[].argmax().to", "PIL.Image.fromarray", "output[].argmax"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "trainId2label", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "file_name", "=", "input", "[", "\"file_name\"", "]", "\n", "basename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "0", "]", "\n", "pred_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "basename", "+", "\"_pred.png\"", ")", "\n", "\n", "output", "=", "output", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "_cpu_device", ")", ".", "numpy", "(", ")", "\n", "pred", "=", "255", "*", "np", ".", "ones", "(", "output", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "train_id", ",", "label", "in", "trainId2label", ".", "items", "(", ")", ":", "\n", "                ", "if", "label", ".", "ignoreInEval", ":", "\n", "                    ", "continue", "\n", "", "pred", "[", "output", "==", "train_id", "]", "=", "label", ".", "id", "\n", "", "Image", ".", "fromarray", "(", "pred", ")", ".", "save", "(", "pred_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.evaluate": [[155, 195], ["detectron2.utils.comm.synchronize", "cityscapes_evaluation.CityscapesSemSegEvaluator._logger.info", "os.path.abspath", "detectron2.utils.file_io.PathManager.get_local_path", "glob.glob", "len", "cityscapes_eval.evaluateImgLists", "collections.OrderedDict", "cityscapes_evaluation.CityscapesSemSegEvaluator._working_dir.cleanup", "detectron2.utils.comm.get_rank", "os.path.join", "predictionImgList.append", "cityscapes_eval.getPrediction"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.comm.synchronize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "comm", ".", "synchronize", "(", ")", "\n", "if", "comm", ".", "get_rank", "(", ")", ">", "0", ":", "\n", "            ", "return", "\n", "# Load the Cityscapes eval script *after* setting the required env var,", "\n", "# since the script reads CITYSCAPES_DATASET into global variables at load time.", "\n", "", "import", "cityscapesscripts", ".", "evaluation", ".", "evalPixelLevelSemanticLabeling", "as", "cityscapes_eval", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Evaluating results under {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", ")", "\n", "\n", "# set some global states in cityscapes evaluation API, before evaluating", "\n", "cityscapes_eval", ".", "args", ".", "predictionPath", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "_temp_dir", ")", "\n", "cityscapes_eval", ".", "args", ".", "predictionWalk", "=", "None", "\n", "cityscapes_eval", ".", "args", ".", "JSONOutput", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "colorized", "=", "False", "\n", "\n", "# These lines are adopted from", "\n", "# https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalPixelLevelSemanticLabeling.py # noqa", "\n", "gt_dir", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "gt_dir", ")", "\n", "groundTruthImgList", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "\"*\"", ",", "\"*_gtFine_labelIds.png\"", ")", ")", "\n", "assert", "len", "(", "\n", "groundTruthImgList", "\n", ")", ",", "\"Cannot find any ground truth images to use for evaluation. Searched for: {}\"", ".", "format", "(", "\n", "cityscapes_eval", ".", "args", ".", "groundTruthSearch", "\n", ")", "\n", "predictionImgList", "=", "[", "]", "\n", "for", "gt", "in", "groundTruthImgList", ":", "\n", "            ", "predictionImgList", ".", "append", "(", "cityscapes_eval", ".", "getPrediction", "(", "cityscapes_eval", ".", "args", ",", "gt", ")", ")", "\n", "", "results", "=", "cityscapes_eval", ".", "evaluateImgLists", "(", "\n", "predictionImgList", ",", "groundTruthImgList", ",", "cityscapes_eval", ".", "args", "\n", ")", "\n", "ret", "=", "OrderedDict", "(", ")", "\n", "ret", "[", "\"sem_seg\"", "]", "=", "{", "\n", "\"IoU\"", ":", "100.0", "*", "results", "[", "\"averageScoreClasses\"", "]", ",", "\n", "\"iIoU\"", ":", "100.0", "*", "results", "[", "\"averageScoreInstClasses\"", "]", ",", "\n", "\"IoU_sup\"", ":", "100.0", "*", "results", "[", "\"averageScoreCategories\"", "]", ",", "\n", "\"iIoU_sup\"", ":", "100.0", "*", "results", "[", "\"averageScoreInstCategories\"", "]", ",", "\n", "}", "\n", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build._create_gradient_clipper": [[23, 41], ["copy.deepcopy", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "build.GradientClipType"], "function", ["None"], ["model", ".", "to", "(", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", ")", "\n", "_log_api_usage", "(", "\"modeling.meta_arch.\"", "+", "meta_arch", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build._generate_optimizer_class_with_gradient_clipping": [[43, 75], ["type", "super().step", "itertools.chain", "global_clipper", "per_param_clipper", "type"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.maybe_add_gradient_clipping": [[77, 111], ["isinstance", "build._create_gradient_clipper", "build._generate_optimizer_class_with_gradient_clipping", "isinstance", "type", "issubclass", "torch.optim.SGD"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build._create_gradient_clipper", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build._generate_optimizer_class_with_gradient_clipping"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.build_optimizer": [[113, 130], ["build.get_default_optimizer_params", "build.maybe_add_gradient_clipping"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.get_default_optimizer_params", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.maybe_add_gradient_clipping"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.get_default_optimizer_params": [[133, 218], ["len", "set", "model.modules", "module.named_parameters", "ValueError", "ValueError", "memo.add", "copy.copy", "copy.copy.update", "params.append", "isinstance", "overrides.get"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.build_lr_scheduler": [[220, 253], ["lr_scheduler.WarmupParamScheduler", "lr_scheduler.LRMultiplier", "fvcore.common.param_scheduler.MultiStepParamScheduler", "len", "len", "logging.getLogger", "logging.getLogger.warning", "fvcore.common.param_scheduler.CosineParamScheduler", "ValueError", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupParamScheduler.__init__": [[22, 49], ["scheduler", "fvcore.common.param_scheduler.CompositeParamScheduler.__init__", "scheduler", "fvcore.common.param_scheduler.ConstantParamScheduler", "fvcore.common.param_scheduler.LinearParamScheduler", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "scheduler", ":", "ParamScheduler", ",", "\n", "warmup_factor", ":", "float", ",", "\n", "warmup_length", ":", "float", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            scheduler: warmup will be added at the beginning of this scheduler\n            warmup_factor: the factor w.r.t the initial value of ``scheduler``, e.g. 0.001\n            warmup_length: the relative length (in [0, 1]) of warmup steps w.r.t the entire\n                training, e.g. 0.01\n            warmup_method: one of \"linear\" or \"constant\"\n        \"\"\"", "\n", "end_value", "=", "scheduler", "(", "warmup_length", ")", "# the value to reach when warmup ends", "\n", "start_value", "=", "warmup_factor", "*", "scheduler", "(", "0.0", ")", "\n", "if", "warmup_method", "==", "\"constant\"", ":", "\n", "            ", "warmup", "=", "ConstantParamScheduler", "(", "start_value", ")", "\n", "", "elif", "warmup_method", "==", "\"linear\"", ":", "\n", "            ", "warmup", "=", "LinearParamScheduler", "(", "start_value", ",", "end_value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown warmup method: {}\"", ".", "format", "(", "warmup_method", ")", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "[", "warmup", ",", "scheduler", "]", ",", "\n", "interval_scaling", "=", "[", "\"rescaled\"", ",", "\"fixed\"", "]", ",", "\n", "lengths", "=", "[", "warmup_length", ",", "1", "-", "warmup_length", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.__init__": [[86, 109], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "multiplier", ":", "ParamScheduler", ",", "\n", "max_iter", ":", "int", ",", "\n", "last_iter", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            optimizer, last_iter: See ``torch.optim.lr_scheduler._LRScheduler``.\n                ``last_iter`` is the same as ``last_epoch``.\n            multiplier: a fvcore ParamScheduler that defines the multiplier on\n                every LR of the optimizer\n            max_iter: the total number of training iterations\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "multiplier", ",", "ParamScheduler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"_LRMultiplier(multiplier=) must be an instance of fvcore \"", "\n", "f\"ParamScheduler. Got {multiplier} instead.\"", "\n", ")", "\n", "", "self", ".", "_multiplier", "=", "multiplier", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", "=", "last_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.state_dict": [[110, 113], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "# fvcore schedulers are stateless. Only keep pytorch scheduler states", "\n", "        ", "return", "{", "\"base_lrs\"", ":", "self", ".", "base_lrs", ",", "\"last_epoch\"", ":", "self", ".", "last_epoch", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.get_lr": [[114, 117], ["lr_scheduler.LRMultiplier._multiplier"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "multiplier", "=", "self", ".", "_multiplier", "(", "self", ".", "last_epoch", "/", "self", ".", "_max_iter", ")", "\n", "return", "[", "base_lr", "*", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupMultiStepLR.__init__": [[133, 156], ["logger.warning", "super().__init__", "ValueError", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "milestones", ":", "List", "[", "int", "]", ",", "\n", "gamma", ":", "float", "=", "0.1", ",", "\n", "warmup_factor", ":", "float", "=", "0.001", ",", "\n", "warmup_iters", ":", "int", "=", "1000", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"WarmupMultiStepLR is deprecated! Use LRMultipilier with fvcore ParamScheduler instead!\"", "\n", ")", "\n", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "milestones", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupMultiStepLR.get_lr": [[157, 164], ["lr_scheduler._get_warmup_factor_at_iter", "bisect.bisect_right"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler._get_warmup_factor_at_iter"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "warmup_factor", "=", "_get_warmup_factor_at_iter", "(", "\n", "self", ".", "warmup_method", ",", "self", ".", "last_epoch", ",", "self", ".", "warmup_iters", ",", "self", ".", "warmup_factor", "\n", ")", "\n", "return", "[", "\n", "base_lr", "*", "warmup_factor", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupMultiStepLR._compute_values": [[166, 169], ["lr_scheduler.WarmupMultiStepLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupCosineLR.get_lr"], ["", "def", "_compute_values", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "# The new interface", "\n", "        ", "return", "self", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupCosineLR.__init__": [[172, 189], ["logger.warning", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "max_iters", ":", "int", ",", "\n", "warmup_factor", ":", "float", "=", "0.001", ",", "\n", "warmup_iters", ":", "int", "=", "1000", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"WarmupCosineLR is deprecated! Use LRMultipilier with fvcore ParamScheduler instead!\"", "\n", ")", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupCosineLR.get_lr": [[190, 205], ["lr_scheduler._get_warmup_factor_at_iter", "math.cos"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler._get_warmup_factor_at_iter"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "warmup_factor", "=", "_get_warmup_factor_at_iter", "(", "\n", "self", ".", "warmup_method", ",", "self", ".", "last_epoch", ",", "self", ".", "warmup_iters", ",", "self", ".", "warmup_factor", "\n", ")", "\n", "# Different definitions of half-cosine with warmup are possible. For", "\n", "# simplicity we multiply the standard half-cosine schedule by the warmup", "\n", "# factor. An alternative is to start the period of the cosine at warmup_iters", "\n", "# instead of at 0. In the case that warmup_iters << max_iters the two are", "\n", "# very close to each other.", "\n", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "0.5", "\n", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "self", ".", "last_epoch", "/", "self", ".", "max_iters", ")", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupCosineLR._compute_values": [[207, 210], ["lr_scheduler.WarmupCosineLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.WarmupCosineLR.get_lr"], ["", "def", "_compute_values", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "# The new interface", "\n", "        ", "return", "self", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler._get_warmup_factor_at_iter": [[212, 239], ["ValueError"], "function", ["None"], ["", "", "def", "_get_warmup_factor_at_iter", "(", "\n", "method", ":", "str", ",", "iter", ":", "int", ",", "warmup_iters", ":", "int", ",", "warmup_factor", ":", "float", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Return the learning rate warmup factor at a specific iteration.\n    See :paper:`ImageNet in 1h` for more details.\n\n    Args:\n        method (str): warmup method; either \"constant\" or \"linear\".\n        iter (int): iteration at which to calculate the warmup factor.\n        warmup_iters (int): the number of warmup iterations.\n        warmup_factor (float): the base warmup factor (the meaning changes according\n            to the method used).\n\n    Returns:\n        float: the effective warmup factor at the given iteration.\n    \"\"\"", "\n", "if", "iter", ">=", "warmup_iters", ":", "\n", "        ", "return", "1.0", "\n", "\n", "", "if", "method", "==", "\"constant\"", ":", "\n", "        ", "return", "warmup_factor", "\n", "", "elif", "method", "==", "\"linear\"", ":", "\n", "        ", "alpha", "=", "iter", "/", "warmup_iters", "\n", "return", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown warmup method: {}\"", ".", "format", "(", "method", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.MaskLoader.MaskLoader.__init__": [[40, 65], ["isinstance", "os.path.join", "os.path.join", "list", "print", "open", "json.load", "ann.get", "list.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "__init__", "(", "self", ",", "root", "=", "\"datasets\"", ",", "dataset", "=", "\"coco_2017_train\"", ",", "size", "=", "28", ",", "transform", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "\n", "\n", "", "data_info", "=", "DATASETS", "[", "dataset", "]", "\n", "img_dir", ",", "ann_file", "=", "data_info", "[", "'img_dir'", "]", ",", "data_info", "[", "'ann_file'", "]", "\n", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "img_dir", ")", "# actually we do not use it.", "\n", "ann_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "ann_file", ")", "\n", "\n", "with", "open", "(", "ann_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "anns", "=", "json", ".", "load", "(", "f", ")", "\n", "", "anns", "=", "anns", "[", "'annotations'", "]", "\n", "coco", "=", "list", "(", ")", "\n", "for", "ann", "in", "anns", ":", "\n", "            ", "if", "ann", ".", "get", "(", "'iscrowd'", ",", "0", ")", "==", "0", ":", "\n", "                ", "coco", ".", "append", "(", "ann", ")", "\n", "", "", "self", ".", "coco", "=", "coco", "\n", "print", "(", "\"Removed {} images with no usable annotations. {} images left.\"", ".", "format", "(", "\n", "len", "(", "anns", ")", "-", "len", "(", "self", ".", "coco", ")", ",", "len", "(", "self", ".", "coco", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.MaskLoader.MaskLoader.__len__": [[66, 68], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "coco", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.MaskLoader.MaskLoader.__getitem__": [[69, 84], ["numpy.array", "detectron2.structures.BoxMode.convert", "detectron2.structures.Boxes", "detectron2.structures.PolygonMasks", "mask.crop_and_resize().float.crop_and_resize().float.crop_and_resize().float", "mask.crop_and_resize().float.crop_and_resize().float.crop_and_resize"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "ann", "=", "self", ".", "coco", "[", "index", "]", "\n", "\n", "# bbox transform.", "\n", "bbox", "=", "np", ".", "array", "(", "[", "ann", "[", "\"bbox\"", "]", "]", ")", "# xmin, ymin, w, h", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "# x1y1x2y2", "\n", "bbox", "=", "Boxes", "(", "bbox", ")", "\n", "\n", "# label", "\n", "\n", "# mask transform.", "\n", "mask", "=", "PolygonMasks", "(", "[", "ann", "[", "\"segmentation\"", "]", "]", ")", "\n", "mask", "=", "mask", ".", "crop_and_resize", "(", "bbox", ".", "tensor", ",", "self", ".", "size", ")", ".", "float", "(", ")", "\n", "\n", "return", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.mask_generation.mask_encoding": [[20, 43], ["sklearn.decomposition.IncrementalPCA", "sklearn.decomposition.IncrementalPCA.fit", "components_c.append", "mean_c.append", "ratio_c.append", "explained_variance_c.append", "sklearn.decomposition.IncrementalPCA.explained_variance_ratio_.sum", "numpy.maximum", "numpy.where", "utils.inverse_sigmoid", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.inverse_sigmoid"], ["def", "mask_encoding", "(", "masks", ",", "n_components", "=", "60", ",", "class_agnostic", "=", "True", ",", "whiten", "=", "True", ",", "sigmoid", "=", "True", ",", "batch_size", "=", "1024", ")", ":", "\n", "    ", "components_c", "=", "[", "]", "\n", "mean_c", "=", "[", "]", "\n", "ratio_c", "=", "[", "]", "\n", "explained_variance_c", "=", "[", "]", "\n", "if", "class_agnostic", ":", "\n", "        ", "if", "sigmoid", ":", "\n", "            ", "value_random", "=", "VALUE_MAX", "*", "np", ".", "random", ".", "rand", "(", "masks", ".", "shape", "[", "0", "]", ",", "masks", ".", "shape", "[", "1", "]", ")", "\n", "value_random", "=", "np", ".", "maximum", "(", "value_random", ",", "VALUE_MIN", ")", "\n", "masks", "=", "np", ".", "where", "(", "masks", ">", "value_random", ",", "1", "-", "value_random", ",", "value_random", ")", "\n", "masks", "=", "inverse_sigmoid", "(", "masks", ")", "\n", "", "pca", "=", "IncrementalPCA", "(", "n_components", "=", "n_components", ",", "copy", "=", "False", ",", "whiten", "=", "whiten", ",", "batch_size", "=", "batch_size", ")", "\n", "pca", ".", "fit", "(", "masks", ")", "\n", "components_c", ".", "append", "(", "pca", ".", "components_", "[", "np", ".", "newaxis", ",", ":", ",", ":", "]", ")", "\n", "mean_c", ".", "append", "(", "pca", ".", "mean_", "[", "np", ".", "newaxis", ",", ":", "]", ")", "\n", "ratio_c", ".", "append", "(", "pca", ".", "explained_variance_ratio_", "[", "np", ".", "newaxis", ",", ":", "]", ")", "\n", "explained_variance_c", ".", "append", "(", "pca", ".", "explained_variance_", "[", "np", ".", "newaxis", ",", ":", "]", ")", "\n", "ratio", "=", "pca", ".", "explained_variance_ratio_", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "# TODO: We have not achieve the function in class-specific.", "\n", "        ", "raise", "NotImplemented", "\n", "\n", "", "return", "components_c", ",", "mean_c", ",", "ratio_c", ",", "explained_variance_c", ",", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.mask_generation.parse_args": [[45, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.mask_evaluation.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PCA Mask Encoding for local mask.'", ")", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "default", "=", "'datasets'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'coco_2017_train'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "default", "=", "'./projects/LME'", ",", "type", "=", "str", ")", "\n", "# mask encoding params.", "\n", "parser", ".", "add_argument", "(", "'--mask_size'", ",", "default", "=", "28", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--n_components'", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--class_agnostic'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--whiten'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--sigmoid'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "1024", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.IOUMetric.__init__": [[97, 100], ["numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "hist", "=", "np", ".", "zeros", "(", "(", "num_classes", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.IOUMetric._fast_hist": [[101, 107], ["numpy.bincount().reshape", "numpy.bincount", "label_true[].astype"], "methods", ["None"], ["", "def", "_fast_hist", "(", "self", ",", "label_pred", ",", "label_true", ")", ":", "\n", "        ", "mask", "=", "(", "label_true", ">=", "0", ")", "&", "(", "label_true", "<", "self", ".", "num_classes", ")", "\n", "hist", "=", "np", ".", "bincount", "(", "\n", "self", ".", "num_classes", "*", "label_true", "[", "mask", "]", ".", "astype", "(", "int", ")", "+", "\n", "label_pred", "[", "mask", "]", ",", "minlength", "=", "self", ".", "num_classes", "**", "2", ")", ".", "reshape", "(", "self", ".", "num_classes", ",", "self", ".", "num_classes", ")", "\n", "return", "hist", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.IOUMetric.add_batch": [[108, 111], ["zip", "utils.IOUMetric._fast_hist", "lp.flatten", "lt.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric._fast_hist", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "add_batch", "(", "self", ",", "predictions", ",", "gts", ")", ":", "\n", "        ", "for", "lp", ",", "lt", "in", "zip", "(", "predictions", ",", "gts", ")", ":", "\n", "            ", "self", ".", "hist", "+=", "self", ".", "_fast_hist", "(", "lp", ".", "flatten", "(", ")", ",", "lt", ".", "flatten", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.IOUMetric.evaluate": [[112, 121], ["numpy.nanmean", "numpy.nanmean", "numpy.diag().sum", "utils.IOUMetric.hist.sum", "numpy.diag", "utils.IOUMetric.hist.sum", "numpy.diag", "utils.IOUMetric.hist.sum", "utils.IOUMetric.hist.sum", "numpy.diag", "numpy.diag", "utils.IOUMetric.hist.sum", "utils.IOUMetric.hist.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "acc", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", ".", "sum", "(", ")", "/", "self", ".", "hist", ".", "sum", "(", ")", "\n", "acc_cls", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", "/", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "\n", "acc_cls", "=", "np", ".", "nanmean", "(", "acc_cls", ")", "\n", "iu", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", "/", "(", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "+", "self", ".", "hist", ".", "sum", "(", "axis", "=", "0", ")", "-", "np", ".", "diag", "(", "self", ".", "hist", ")", ")", "\n", "mean_iu", "=", "np", ".", "nanmean", "(", "iu", ")", "\n", "freq", "=", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "/", "self", ".", "hist", ".", "sum", "(", ")", "\n", "fwavacc", "=", "(", "freq", "[", "freq", ">", "0", "]", "*", "iu", "[", "freq", ">", "0", "]", ")", ".", "sum", "(", ")", "\n", "return", "acc", ",", "acc_cls", ",", "iu", ",", "mean_iu", ",", "fwavacc", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.direct_sigmoid": [[6, 12], ["numpy.exp"], "function", ["None"], ["def", "direct_sigmoid", "(", "x", ")", ":", "\n", "    ", "\"\"\"Apply the sigmoid operation.\n    \"\"\"", "\n", "y", "=", "1.", "/", "(", "1.", "+", "1.", "/", "np", ".", "exp", "(", "x", ")", ")", "\n", "dy", "=", "y", "*", "(", "1", "-", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.inverse_sigmoid": [[14, 20], ["numpy.log"], "function", ["None"], ["", "def", "inverse_sigmoid", "(", "x", ")", ":", "\n", "    ", "\"\"\"Apply the inverse sigmoid operation.\n            y = -ln(1-x/x)\n    \"\"\"", "\n", "y", "=", "-", "1", "*", "np", ".", "log", "(", "(", "1", "-", "x", ")", "/", "x", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.transform": [[22, 54], ["numpy.dot", "numpy.sqrt"], "function", ["None"], ["", "def", "transform", "(", "X", ",", "components_", ",", "explained_variance_", ",", "mean_", "=", "None", ",", "whiten", "=", "False", ")", ":", "\n", "    ", "\"\"\"Apply dimensionality reduction to X.\n    X is projected on the first principal components previously extracted\n    from a training set.\n    Parameters\n    ----------\n    X: array-like, shape (n_samples, n_features)\n        New data, where n_samples is the number of samples\n        and n_features is the number of features.\n    components_: array-like, shape (n_components, n_features)\n    mean_: array-like, shape (n_features,)\n    explained_variance_: array-like, shape (n_components,)\n                        Variance explained by each of the selected components.\n    whiten : bool, optional\n        When True (False by default) the ``components_`` vectors are divided\n        by ``n_samples`` times ``components_`` to ensure uncorrelated outputs\n        with unit component-wise variances.\n        Whitening will remove some information from the transformed signal\n        (the relative variance scales of the components) but can sometimes\n        improve the predictive accuracy of the downstream estimators by\n        making data respect some hard-wired assumptions.\n    Returns\n    -------\n    X_new : array-like, shape (n_samples, n_components)\n    \"\"\"", "\n", "\n", "if", "mean_", "is", "not", "None", ":", "\n", "        ", "X", "=", "X", "-", "mean_", "\n", "", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "components_", ".", "T", ")", "\n", "if", "whiten", ":", "\n", "        ", "X_transformed", "/=", "np", ".", "sqrt", "(", "explained_variance_", ")", "\n", "", "return", "X_transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.utils.inverse_transform": [[56, 90], ["numpy.dot", "numpy.dot", "numpy.sqrt"], "function", ["None"], ["", "def", "inverse_transform", "(", "X", ",", "components_", ",", "explained_variance_", ",", "mean_", "=", "None", ",", "whiten", "=", "False", ")", ":", "\n", "    ", "\"\"\"Transform data back to its original space.\n    In other words, return an input X_original whose transform would be X.\n    Parameters\n    ----------\n    X : array-like, shape (n_samples, n_components)\n        New data, where n_samples is the number of samples\n        and n_components is the number of components.\n    components_: array-like, shape (n_components, n_features)\n    mean_: array-like, shape (n_features,)\n    explained_variance_: array-like, shape (n_components,)\n                        Variance explained by each of the selected components.\n    whiten : bool, optional\n        When True (False by default) the ``components_`` vectors are divided\n        by ``n_samples`` times ``components_`` to ensure uncorrelated outputs\n        with unit component-wise variances.\n        Whitening will remove some information from the transformed signal\n        (the relative variance scales of the components) but can sometimes\n        improve the predictive accuracy of the downstream estimators by\n        making data respect some hard-wired assumptions.\n\n    Returns\n    -------\n    X_original array-like, shape (n_samples, n_features)\n    \"\"\"", "\n", "if", "whiten", ":", "\n", "        ", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "np", ".", "sqrt", "(", "explained_variance_", "[", ":", ",", "np", ".", "newaxis", "]", ")", "*", "components_", ")", "\n", "", "else", ":", "\n", "        ", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "components_", ")", "\n", "\n", "", "if", "mean_", "is", "not", "None", ":", "\n", "        ", "X_transformed", "=", "X_transformed", "+", "mean_", "\n", "\n", "", "return", "X_transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.mask_evaluation.parse_args": [[22, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.LME.mask_evaluation.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluation for PCA Mask Encoding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "default", "=", "'datasets'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'coco_2017_val'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--matrix'", ",", "default", "=", "'./projects/LME/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_128.npz'", ",", "type", "=", "str", ")", "\n", "# mask encoding params.", "\n", "parser", ".", "add_argument", "(", "'--mask_size'", ",", "default", "=", "28", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--n_components'", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--class_agnostic'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--whiten'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--sigmoid'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "1024", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_evaluator": [[21, 32], ["detectron2.evaluation.COCOEvaluator", "os.path.join"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create evaluator(s) for a given dataset.\n        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n        For your own dataset, you can simply create an evaluator manually in your\n        script and do not have to worry about the hacky if-else logic here.\n        \"\"\"", "\n", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_train_loader": [[39, 43], ["istr.ISTRDatasetMapper", "detectron2.data.build_detection_train_loader"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.build.build_detection_train_loader"], ["", "@", "classmethod", "\n", "def", "build_train_loader", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "mapper", "=", "ISTRDatasetMapper", "(", "cfg", ",", "is_train", "=", "True", ")", "\n", "return", "build_detection_train_loader", "(", "cfg", ",", "mapper", "=", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.Trainer.build_optimizer": [[44, 92], ["set", "model.named_parameters", "memo.add", "detectron2.solver.build.maybe_add_gradient_clipping", "train_net.Trainer.build_optimizer.maybe_add_full_model_gradient_clipping"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.build.maybe_add_gradient_clipping"], ["", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "cfg", ",", "model", ")", ":", "\n", "        ", "params", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "[", "]", "\n", "memo", ":", "Set", "[", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "]", "=", "set", "(", ")", "\n", "for", "key", ",", "value", "in", "model", ".", "named_parameters", "(", "recurse", "=", "True", ")", ":", "\n", "            ", "if", "not", "value", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "# Avoid duplicating parameters", "\n", "", "if", "value", "in", "memo", ":", "\n", "                ", "continue", "\n", "", "memo", ".", "add", "(", "value", ")", "\n", "lr", "=", "cfg", ".", "SOLVER", ".", "BASE_LR", "\n", "weight_decay", "=", "cfg", ".", "SOLVER", ".", "WEIGHT_DECAY", "\n", "if", "\"backbone\"", "in", "key", ":", "\n", "                ", "lr", "=", "lr", "*", "cfg", ".", "SOLVER", ".", "BACKBONE_MULTIPLIER", "\n", "", "params", "+=", "[", "{", "\"params\"", ":", "[", "value", "]", ",", "\"lr\"", ":", "lr", ",", "\"weight_decay\"", ":", "weight_decay", "}", "]", "\n", "\n", "", "def", "maybe_add_full_model_gradient_clipping", "(", "optim", ")", ":", "# optim: the optimizer class", "\n", "# detectron2 doesn't have full model gradient clipping now", "\n", "            ", "clip_norm_val", "=", "cfg", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "CLIP_VALUE", "\n", "enable", "=", "(", "\n", "cfg", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "ENABLED", "\n", "and", "cfg", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "CLIP_TYPE", "==", "\"full_model\"", "\n", "and", "clip_norm_val", ">", "0.0", "\n", ")", "\n", "\n", "class", "FullModelGradientClippingOptimizer", "(", "optim", ")", ":", "\n", "                ", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "                    ", "all_params", "=", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"params\"", "]", "for", "x", "in", "self", ".", "param_groups", "]", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "all_params", ",", "clip_norm_val", ")", "\n", "super", "(", ")", ".", "step", "(", "closure", "=", "closure", ")", "\n", "\n", "", "", "return", "FullModelGradientClippingOptimizer", "if", "enable", "else", "optim", "\n", "\n", "", "optimizer_type", "=", "cfg", ".", "SOLVER", ".", "OPTIMIZER", "\n", "if", "optimizer_type", "==", "\"SGD\"", ":", "\n", "            ", "optimizer", "=", "maybe_add_full_model_gradient_clipping", "(", "torch", ".", "optim", ".", "SGD", ")", "(", "\n", "params", ",", "cfg", ".", "SOLVER", ".", "BASE_LR", ",", "momentum", "=", "cfg", ".", "SOLVER", ".", "MOMENTUM", "\n", ")", "\n", "", "elif", "optimizer_type", "==", "\"ADAMW\"", ":", "\n", "            ", "optimizer", "=", "maybe_add_full_model_gradient_clipping", "(", "torch", ".", "optim", ".", "AdamW", ")", "(", "\n", "params", ",", "cfg", ".", "SOLVER", ".", "BASE_LR", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"no optimizer type {optimizer_type}\"", ")", "\n", "", "if", "not", "cfg", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "CLIP_TYPE", "==", "\"full_model\"", ":", "\n", "            ", "optimizer", "=", "maybe_add_gradient_clipping", "(", "cfg", ",", "optimizer", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.setup": [[94, 105], ["detectron2.config.get_cfg", "istr.add_ISTR_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.get_cfg", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.config.add_ISTR_config", "home.repos.pwc.inspect_result.hujiecpp_ISTR.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.default_setup"], ["", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Create configs and perform basic setups.\n    \"\"\"", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "add_ISTR_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "default_setup", "(", "cfg", ",", "args", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.main": [[107, 121], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.is_main_process", "detectron2.evaluation.verify_results", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.ISTR.train_net.setup", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.build_model", "home.repos.pwc.inspect_result.hujiecpp_ISTR.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.test", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.evaluation.testing.verify_results"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", ")", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "model", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "verify_results", "(", "cfg", ",", "res", ")", "\n", "", "return", "res", "\n", "\n", "", "trainer", "=", "Trainer", "(", "cfg", ")", "\n", "trainer", ".", "resume_or_load", "(", "resume", "=", "args", ".", "resume", ")", "\n", "return", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.config.add_ISTR_config": [[4, 68], ["detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["import", "functools", "\n", "import", "inspect", "\n", "import", "logging", "\n", "from", "fvcore", ".", "common", ".", "config", "import", "CfgNode", "as", "_CfgNode", "\n", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n", "\n", "if", "loaded_ver", "==", "self", ".", "VERSION", ":", "\n", "            ", "self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "", "else", ":", "\n", "# compat.py needs to import CfgNode", "\n", "            ", "from", ".", "compat", "import", "upgrade_config", ",", "downgrade_config", "\n", "\n", "logger", ".", "warning", "(", "\n", "\"Loading an old v{} config file '{}' by automatically upgrading to v{}. \"", "\n", "\"See docs/CHANGELOG.md for instructions to update your files.\"", ".", "format", "(", "\n", "loaded_ver", ",", "cfg_filename", ",", "self", ".", "VERSION", "\n", ")", "\n", ")", "\n", "# To convert, first obtain a full config at an old version", "\n", "old_self", "=", "downgrade_config", "(", "self", ",", "to_version", "=", "loaded_ver", ")", "\n", "old_self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "new_config", "=", "upgrade_config", "(", "old_self", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.Mlp.__init__": [[23, 31], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.Mlp.forward": [[32, 39], ["swin_transformer.Mlp.fc1", "swin_transformer.Mlp.act", "swin_transformer.Mlp.drop", "swin_transformer.Mlp.fc2", "swin_transformer.Mlp.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.WindowAttention.__init__": [[84, 117], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "relative_coords.permute().contiguous.permute().contiguous.permute().contiguous", "relative_coords.permute().contiguous.permute().contiguous.sum", "swin_transformer.WindowAttention.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "timm.models.layers.trunc_normal_", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "relative_coords.permute().contiguous.permute().contiguous.permute"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["def", "__init__", "(", "self", ",", "dim", ",", "window_size", ",", "num_heads", ",", "qkv_bias", "=", "True", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "window_size", "=", "window_size", "# Wh, Ww", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "# define a parameter table of relative position bias", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", ",", "num_heads", ")", ")", "# 2*Wh-1 * 2*Ww-1, nH", "\n", "\n", "# get pair-wise relative position index for each token inside the window", "\n", "coords_h", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "0", "]", ")", "\n", "coords_w", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "1", "]", ")", "\n", "coords", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "[", "coords_h", ",", "coords_w", "]", ")", ")", "# 2, Wh, Ww", "\n", "coords_flatten", "=", "torch", ".", "flatten", "(", "coords", ",", "1", ")", "# 2, Wh*Ww", "\n", "relative_coords", "=", "coords_flatten", "[", ":", ",", ":", ",", "None", "]", "-", "coords_flatten", "[", ":", ",", "None", ",", ":", "]", "# 2, Wh*Ww, Wh*Ww", "\n", "relative_coords", "=", "relative_coords", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "# Wh*Ww, Wh*Ww, 2", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "+=", "self", ".", "window_size", "[", "0", "]", "-", "1", "# shift to start from 0", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "+=", "self", ".", "window_size", "[", "1", "]", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "*=", "2", "*", "self", ".", "window_size", "[", "1", "]", "-", "1", "\n", "relative_position_index", "=", "relative_coords", ".", "sum", "(", "-", "1", ")", "# Wh*Ww, Wh*Ww", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "relative_position_index", ")", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "relative_position_bias_table", ",", "std", "=", ".02", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.WindowAttention.forward": [[118, 150], ["swin_transformer.WindowAttention.qkv().reshape().permute", "swin_transformer.WindowAttention.relative_position_bias_table[].view", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "swin_transformer.WindowAttention.attn_drop", "swin_transformer.WindowAttention.proj", "swin_transformer.WindowAttention.proj_drop", "k.transpose", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "swin_transformer.WindowAttention.view", "swin_transformer.WindowAttention.softmax", "swin_transformer.WindowAttention.softmax", "swin_transformer.WindowAttention.qkv().reshape", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "swin_transformer.WindowAttention.view", "mask.unsqueeze().unsqueeze", "swin_transformer.WindowAttention.qkv", "swin_transformer.WindowAttention.relative_position_index.view", "mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Forward function.\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"", "\n", "B_", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B_", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "-", "1", ")", "# Wh*Ww,Wh*Ww,nH", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wh*Ww, Wh*Ww", "\n", "attn", "=", "attn", "+", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "nW", "=", "mask", ".", "shape", "[", "0", "]", "\n", "attn", "=", "attn", ".", "view", "(", "B_", "//", "nW", ",", "nW", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "+", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "attn", "=", "attn", ".", "view", "(", "-", "1", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "\n", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "\n", "", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B_", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformerBlock.__init__": [[169, 192], ["torch.Module.__init__", "norm_layer", "swin_transformer.WindowAttention", "norm_layer", "int", "swin_transformer.Mlp", "timm.models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "timm.models.layers.to_2tuple"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "window_size", "=", "7", ",", "shift_size", "=", "0", ",", "\n", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "qk_scale", "=", "None", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "shift_size", "\n", "self", ".", "mlp_ratio", "=", "mlp_ratio", "\n", "assert", "0", "<=", "self", ".", "shift_size", "<", "self", ".", "window_size", ",", "\"shift_size must in 0-window_size\"", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "WindowAttention", "(", "\n", "dim", ",", "window_size", "=", "to_2tuple", "(", "self", ".", "window_size", ")", ",", "num_heads", "=", "num_heads", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "self", ".", "H", "=", "None", "\n", "self", ".", "W", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformerBlock.forward": [[193, 250], ["swin_transformer.SwinTransformerBlock.norm1", "x[].contiguous.view", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "swin_transformer.window_partition", "x_windows.view.view.view", "swin_transformer.SwinTransformerBlock.attn", "attn_windows.view.view.view", "swin_transformer.window_reverse", "x[].contiguous.view", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "x[].contiguous", "swin_transformer.SwinTransformerBlock.drop_path", "swin_transformer.SwinTransformerBlock.drop_path", "swin_transformer.SwinTransformerBlock.mlp", "swin_transformer.SwinTransformerBlock.norm2"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.window_partition", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.window_reverse"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask_matrix", ")", ":", "\n", "        ", "\"\"\" Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n            mask_matrix: Attention mask for cyclic shift.\n        \"\"\"", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "H", ",", "W", "=", "self", ".", "H", ",", "self", ".", "W", "\n", "assert", "L", "==", "H", "*", "W", ",", "\"input feature has wrong size\"", "\n", "\n", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "# pad feature maps to multiples of window size", "\n", "pad_l", "=", "pad_t", "=", "0", "\n", "pad_r", "=", "(", "self", ".", "window_size", "-", "W", "%", "self", ".", "window_size", ")", "%", "self", ".", "window_size", "\n", "pad_b", "=", "(", "self", ".", "window_size", "-", "H", "%", "self", ".", "window_size", ")", "%", "self", ".", "window_size", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "pad_l", ",", "pad_r", ",", "pad_t", ",", "pad_b", ")", ")", "\n", "_", ",", "Hp", ",", "Wp", ",", "_", "=", "x", ".", "shape", "\n", "\n", "# cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "shifted_x", "=", "torch", ".", "roll", "(", "x", ",", "shifts", "=", "(", "-", "self", ".", "shift_size", ",", "-", "self", ".", "shift_size", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "attn_mask", "=", "mask_matrix", "\n", "", "else", ":", "\n", "            ", "shifted_x", "=", "x", "\n", "attn_mask", "=", "None", "\n", "\n", "# partition windows", "\n", "", "x_windows", "=", "window_partition", "(", "shifted_x", ",", "self", ".", "window_size", ")", "# nW*B, window_size, window_size, C", "\n", "x_windows", "=", "x_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "*", "self", ".", "window_size", ",", "C", ")", "# nW*B, window_size*window_size, C", "\n", "\n", "# W-MSA/SW-MSA", "\n", "attn_windows", "=", "self", ".", "attn", "(", "x_windows", ",", "mask", "=", "attn_mask", ")", "# nW*B, window_size*window_size, C", "\n", "\n", "# merge windows", "\n", "attn_windows", "=", "attn_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", ",", "self", ".", "window_size", ",", "C", ")", "\n", "shifted_x", "=", "window_reverse", "(", "attn_windows", ",", "self", ".", "window_size", ",", "Hp", ",", "Wp", ")", "# B H' W' C", "\n", "\n", "# reverse cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "shifted_x", ",", "shifts", "=", "(", "self", ".", "shift_size", ",", "self", ".", "shift_size", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "shifted_x", "\n", "\n", "", "if", "pad_r", ">", "0", "or", "pad_b", ">", "0", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "H", ",", ":", "W", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "B", ",", "H", "*", "W", ",", "C", ")", "\n", "\n", "# FFN", "\n", "x", "=", "shortcut", "+", "self", ".", "drop_path", "(", "x", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.PatchMerging.__init__": [[258, 263], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "4", "*", "dim", ",", "2", "*", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "4", "*", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.PatchMerging.forward": [[264, 291], ["torch.pad.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.pad.view", "swin_transformer.PatchMerging.norm", "swin_transformer.PatchMerging.reduction", "torch.pad", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "x", ",", "H", ",", "W", ")", ":", "\n", "        ", "\"\"\" Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n        \"\"\"", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "assert", "L", "==", "H", "*", "W", ",", "\"input feature has wrong size\"", "\n", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "# padding", "\n", "pad_input", "=", "(", "H", "%", "2", "==", "1", ")", "or", "(", "W", "%", "2", "==", "1", ")", "\n", "if", "pad_input", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "W", "%", "2", ",", "0", ",", "H", "%", "2", ")", ")", "\n", "\n", "", "x0", "=", "x", "[", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x1", "=", "x", "[", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x2", "=", "x", "[", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x3", "=", "x", "[", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x0", ",", "x1", ",", "x2", ",", "x3", "]", ",", "-", "1", ")", "# B H/2 W/2 4*C", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "-", "1", ",", "4", "*", "C", ")", "# B H/2*W/2 4*C", "\n", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "reduction", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.BasicLayer.__init__": [[311, 352], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "downsample", "swin_transformer.SwinTransformerBlock", "range", "isinstance"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dim", ",", "\n", "depth", ",", "\n", "num_heads", ",", "\n", "window_size", "=", "7", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop", "=", "0.", ",", "\n", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "downsample", "=", "None", ",", "\n", "use_checkpoint", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "window_size", "//", "2", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "use_checkpoint", "=", "use_checkpoint", "\n", "\n", "# build blocks", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SwinTransformerBlock", "(", "\n", "dim", "=", "dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "window_size", ",", "\n", "shift_size", "=", "0", "if", "(", "i", "%", "2", "==", "0", ")", "else", "window_size", "//", "2", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop", ",", "\n", "attn_drop", "=", "attn_drop", ",", "\n", "drop_path", "=", "drop_path", "[", "i", "]", "if", "isinstance", "(", "drop_path", ",", "list", ")", "else", "drop_path", ",", "\n", "norm_layer", "=", "norm_layer", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "# patch merging layer", "\n", "if", "downsample", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "downsample", "(", "dim", "=", "dim", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.BasicLayer.forward": [[353, 393], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin_transformer.window_partition", "mask_windows.view.view.view", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill().masked_fill", "int", "int", "slice", "slice", "slice", "slice", "slice", "slice", "mask_windows.view.view.unsqueeze", "mask_windows.view.view.unsqueeze", "float", "swin_transformer.BasicLayer.downsample", "numpy.ceil", "numpy.ceil", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "blk", "float"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.window_partition"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "H", ",", "W", ")", ":", "\n", "        ", "\"\"\" Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n        \"\"\"", "\n", "\n", "# calculate attention mask for SW-MSA", "\n", "Hp", "=", "int", "(", "np", ".", "ceil", "(", "H", "/", "self", ".", "window_size", ")", ")", "*", "self", ".", "window_size", "\n", "Wp", "=", "int", "(", "np", ".", "ceil", "(", "W", "/", "self", ".", "window_size", ")", ")", "*", "self", ".", "window_size", "\n", "img_mask", "=", "torch", ".", "zeros", "(", "(", "1", ",", "Hp", ",", "Wp", ",", "1", ")", ",", "device", "=", "x", ".", "device", ")", "# 1 Hp Wp 1", "\n", "h_slices", "=", "(", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "-", "self", ".", "shift_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", "\n", "w_slices", "=", "(", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "-", "self", ".", "shift_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", "\n", "cnt", "=", "0", "\n", "for", "h", "in", "h_slices", ":", "\n", "            ", "for", "w", "in", "w_slices", ":", "\n", "                ", "img_mask", "[", ":", ",", "h", ",", "w", ",", ":", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "", "mask_windows", "=", "window_partition", "(", "img_mask", ",", "self", ".", "window_size", ")", "# nW, window_size, window_size, 1", "\n", "mask_windows", "=", "mask_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "*", "self", ".", "window_size", ")", "\n", "attn_mask", "=", "mask_windows", ".", "unsqueeze", "(", "1", ")", "-", "mask_windows", ".", "unsqueeze", "(", "2", ")", "\n", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", "!=", "0", ",", "float", "(", "-", "100.0", ")", ")", ".", "masked_fill", "(", "attn_mask", "==", "0", ",", "float", "(", "0.0", ")", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "blk", ".", "H", ",", "blk", ".", "W", "=", "H", ",", "W", "\n", "if", "self", ".", "use_checkpoint", ":", "\n", "                ", "x", "=", "checkpoint", ".", "checkpoint", "(", "blk", ",", "x", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "blk", "(", "x", ",", "attn_mask", ")", "\n", "", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "x_down", "=", "self", ".", "downsample", "(", "x", ",", "H", ",", "W", ")", "\n", "Wh", ",", "Ww", "=", "(", "H", "+", "1", ")", "//", "2", ",", "(", "W", "+", "1", ")", "//", "2", "\n", "return", "x", ",", "H", ",", "W", ",", "x_down", ",", "Wh", ",", "Ww", "\n", "", "else", ":", "\n", "            ", "return", "x", ",", "H", ",", "W", ",", "x", ",", "H", ",", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.PatchEmbed.__init__": [[404, 417], ["torch.Module.__init__", "timm.models.layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "patch_size", "=", "4", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "96", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "if", "norm_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.PatchEmbed.forward": [[418, 435], ["x.transpose().view.transpose().view.size", "swin_transformer.PatchEmbed.proj", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "x.transpose().view.transpose().view.flatten().transpose", "swin_transformer.PatchEmbed.norm", "x.transpose().view.transpose().view.transpose().view", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.flatten", "x.transpose().view.transpose().view.transpose"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# padding", "\n", "_", ",", "_", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "if", "W", "%", "self", ".", "patch_size", "[", "1", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "self", ".", "patch_size", "[", "1", "]", "-", "W", "%", "self", ".", "patch_size", "[", "1", "]", ")", ")", "\n", "", "if", "H", "%", "self", ".", "patch_size", "[", "0", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "0", "]", "-", "H", "%", "self", ".", "patch_size", "[", "0", "]", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "# B C Wh Ww", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "Wh", ",", "Ww", "=", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "view", "(", "-", "1", ",", "self", ".", "embed_dim", ",", "Wh", ",", "Ww", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.__init__": [[465, 554], ["detectron2.modeling.backbone.Backbone.__init__", "len", "swin_transformer.PatchEmbed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "swin_transformer.SwinTransformer._freeze_stages", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "timm.models.layers.trunc_normal_", "x.item", "swin_transformer.BasicLayer", "swin_transformer.SwinTransformer.layers.append", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "range", "norm_layer", "swin_transformer.SwinTransformer.add_module", "sum", "int", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer._freeze_stages"], ["def", "__init__", "(", "self", ",", "\n", "pretrain_img_size", "=", "224", ",", "\n", "patch_size", "=", "4", ",", "\n", "in_chans", "=", "3", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "[", "2", ",", "2", ",", "6", ",", "2", "]", ",", "\n", "num_heads", "=", "[", "3", ",", "6", ",", "12", ",", "24", "]", ",", "\n", "window_size", "=", "7", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.2", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "ape", "=", "False", ",", "\n", "patch_norm", "=", "True", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "use_checkpoint", "=", "False", ",", "\n", "out_features", "=", "None", ")", ":", "\n", "        ", "super", "(", "SwinTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pretrain_img_size", "=", "pretrain_img_size", "\n", "self", ".", "num_layers", "=", "len", "(", "depths", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "ape", "=", "ape", "\n", "self", ".", "patch_norm", "=", "patch_norm", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "# split image into non-overlapping patches", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "\n", "norm_layer", "=", "norm_layer", "if", "self", ".", "patch_norm", "else", "None", ")", "\n", "\n", "# absolute position embedding", "\n", "if", "self", ".", "ape", ":", "\n", "            ", "pretrain_img_size", "=", "to_2tuple", "(", "pretrain_img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "patches_resolution", "=", "[", "pretrain_img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "pretrain_img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", "]", "\n", "\n", "self", ".", "absolute_pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "embed_dim", ",", "patches_resolution", "[", "0", "]", ",", "patches_resolution", "[", "1", "]", ")", ")", "\n", "trunc_normal_", "(", "self", ".", "absolute_pos_embed", ",", "std", "=", ".02", ")", "\n", "\n", "", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "# stochastic depth", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", "]", "# stochastic depth decay rule", "\n", "\n", "self", ".", "_out_feature_strides", "=", "{", "}", "\n", "self", ".", "_out_feature_channels", "=", "{", "}", "\n", "\n", "# build layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i_layer", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "layer", "=", "BasicLayer", "(", "\n", "dim", "=", "int", "(", "embed_dim", "*", "2", "**", "i_layer", ")", ",", "\n", "depth", "=", "depths", "[", "i_layer", "]", ",", "\n", "num_heads", "=", "num_heads", "[", "i_layer", "]", ",", "\n", "window_size", "=", "window_size", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "dpr", "[", "sum", "(", "depths", "[", ":", "i_layer", "]", ")", ":", "sum", "(", "depths", "[", ":", "i_layer", "+", "1", "]", ")", "]", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "downsample", "=", "PatchMerging", "if", "(", "i_layer", "<", "self", ".", "num_layers", "-", "1", ")", "else", "None", ",", "\n", "use_checkpoint", "=", "use_checkpoint", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "\n", "stage", "=", "f'stage{i_layer+2}'", "\n", "if", "stage", "in", "self", ".", "out_features", ":", "\n", "                ", "self", ".", "_out_feature_channels", "[", "stage", "]", "=", "embed_dim", "*", "2", "**", "i_layer", "\n", "self", ".", "_out_feature_strides", "[", "stage", "]", "=", "4", "*", "2", "**", "i_layer", "\n", "\n", "", "", "num_features", "=", "[", "int", "(", "embed_dim", "*", "2", "**", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "self", ".", "num_features", "=", "num_features", "\n", "\n", "# add a norm layer for each output", "\n", "for", "i_layer", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "stage", "=", "f'stage{i_layer+2}'", "\n", "if", "stage", "in", "self", ".", "out_features", ":", "\n", "                ", "layer", "=", "norm_layer", "(", "num_features", "[", "i_layer", "]", ")", "\n", "layer_name", "=", "f'norm{i_layer}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "layer", ")", "\n", "\n", "", "", "self", ".", "_freeze_stages", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer._freeze_stages": [[555, 571], ["swin_transformer.SwinTransformer.patch_embed.eval", "swin_transformer.SwinTransformer.patch_embed.parameters", "swin_transformer.SwinTransformer.pos_drop.eval", "range", "m.eval", "m.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "patch_embed", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "patch_embed", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "self", ".", "frozen_stages", ">=", "1", "and", "self", ".", "ape", ":", "\n", "            ", "self", ".", "absolute_pos_embed", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "self", ".", "frozen_stages", ">=", "2", ":", "\n", "            ", "self", ".", "pos_drop", ".", "eval", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "frozen_stages", "-", "1", ")", ":", "\n", "                ", "m", "=", "self", ".", "layers", "[", "i", "]", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.init_weights": [[572, 589], ["swin_transformer.SwinTransformer.apply", "isinstance", "timm.models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize the weights in backbone.\n        Args:\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"", "\n", "\n", "def", "_init_weights", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.forward": [[590, 615], ["swin_transformer.SwinTransformer.patch_embed", "swin_transformer.SwinTransformer.pos_drop", "range", "x.flatten().transpose.flatten().transpose.size", "x.flatten().transpose.flatten().transpose.size", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "x.flatten().transpose.flatten().transpose.flatten().transpose", "layer", "getattr", "getattr.", "getattr.view().permute().contiguous", "x.flatten().transpose.flatten().transpose.flatten", "getattr.view().permute", "getattr.view"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "Wh", ",", "Ww", "=", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", "\n", "if", "self", ".", "ape", ":", "\n", "# interpolate the position embedding to the corresponding size", "\n", "            ", "absolute_pos_embed", "=", "F", ".", "interpolate", "(", "self", ".", "absolute_pos_embed", ",", "size", "=", "(", "Wh", ",", "Ww", ")", ",", "mode", "=", "'bicubic'", ")", "\n", "x", "=", "(", "x", "+", "absolute_pos_embed", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "# B Wh*Ww C", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "outs", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "layer", "=", "self", ".", "layers", "[", "i", "]", "\n", "x_out", ",", "H", ",", "W", ",", "x", ",", "Wh", ",", "Ww", "=", "layer", "(", "x", ",", "Wh", ",", "Ww", ")", "\n", "name", "=", "f'stage{i+2}'", "\n", "if", "name", "in", "self", ".", "out_features", ":", "\n", "                ", "norm_layer", "=", "getattr", "(", "self", ",", "f'norm{i}'", ")", "\n", "x_out", "=", "norm_layer", "(", "x_out", ")", "\n", "out", "=", "x_out", ".", "view", "(", "-", "1", ",", "H", ",", "W", ",", "self", ".", "num_features", "[", "i", "]", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "outs", "[", "name", "]", "=", "out", "\n", "\n", "", "", "return", "outs", "#{\"stage%d\" % (i+2,): out for i, out in enumerate(outs)} #tuple(outs)", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.train": [[616, 620], ["super().train", "swin_transformer.SwinTransformer._freeze_stages"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Convert the model into training mode while keep layers freezed.\"\"\"", "\n", "super", "(", "SwinTransformer", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape": [[621, 627], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.LastLevelP6.__init__": [[685, 692], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "weight_init.c2_xavier_fill"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "in_features", "=", "\"res5\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_levels", "=", "1", "\n", "self", ".", "in_feature", "=", "in_features", "\n", "self", ".", "p6", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "for", "module", "in", "[", "self", ".", "p6", "]", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.LastLevelP6.forward": [[693, 696], ["swin_transformer.LastLevelP6.p6"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "p6", "=", "self", ".", "p6", "(", "x", ")", "\n", "return", "[", "p6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.window_partition": [[41, 53], ["x.view.view", "x.view.permute().contiguous().view", "x.view.permute().contiguous", "x.view.permute"], "function", ["None"], ["", "", "def", "window_partition", "(", "x", ",", "window_size", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "window_size", ",", "window_size", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.window_reverse": [[55, 69], ["int", "windows.view", "x.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute"], "function", ["None"], ["", "def", "window_reverse", "(", "windows", ",", "window_size", ",", "H", ",", "W", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"", "\n", "B", "=", "int", "(", "windows", ".", "shape", "[", "0", "]", "/", "(", "H", "*", "W", "/", "window_size", "/", "window_size", ")", ")", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "window_size", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.build_swint_backbone": [[629, 656], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "swin_transformer.SwinTransformer"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_swint_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a SwinT instance from config.\n    Returns:\n        VoVNet: a :class:`VoVNet` instance.\n    \"\"\"", "\n", "out_features", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "OUT_FEATURES", "\n", "\n", "return", "SwinTransformer", "(", "\n", "patch_size", "=", "4", ",", "\n", "in_chans", "=", "input_shape", ".", "channels", ",", "\n", "embed_dim", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "EMBED_DIM", ",", "\n", "depths", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "DEPTHS", ",", "\n", "num_heads", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "NUM_HEADS", ",", "\n", "window_size", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "WINDOW_SIZE", ",", "\n", "mlp_ratio", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "MLP_RATIO", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "DROP_PATH_RATE", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "ape", "=", "cfg", ".", "MODEL", ".", "SWINT", ".", "APE", ",", "\n", "patch_norm", "=", "True", ",", "\n", "frozen_stages", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", ",", "\n", "out_features", "=", "out_features", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.build_swint_fpn_backbone": [[659, 679], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "swin_transformer.build_swint_backbone", "detectron2.modeling.backbone.fpn.FPN", "detectron2.modeling.backbone.fpn.LastLevelMaxPool"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.build_swint_backbone"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_swint_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_swint_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "LastLevelMaxPool", "(", ")", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.build_retinanet_swint_fpn_backbone": [[697, 725], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "swin_transformer.build_swint_backbone", "detectron2.modeling.backbone.fpn.FPN", "detectron2.modeling.backbone.fpn.LastLevelP6P7", "swin_transformer.LastLevelP6"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._DatasetCatalog.register", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.build_swint_backbone"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_retinanet_swint_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_swint_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "top_levels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "TOP_LEVELS", "\n", "in_channels_top", "=", "out_channels", "\n", "if", "top_levels", "==", "2", ":", "\n", "        ", "top_block", "=", "LastLevelP6P7", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "if", "top_levels", "==", "1", ":", "\n", "        ", "top_block", "=", "LastLevelP6", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "elif", "top_levels", "==", "0", ":", "\n", "        ", "top_block", "=", "None", "\n", "", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "top_block", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.ISTRDatasetMapper.__init__": [[76, 97], ["dataset_mapper.build_transform_gen", "logging.getLogger().info", "dataset_mapper.build_transform_gen_lsj", "logging.getLogger().info", "detectron2.data.transforms.ResizeShortestEdge", "detectron2.data.transforms.RandomCrop", "logging.getLogger", "str", "str", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.build_transform_gen", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.build_transform_gen_lsj"], ["self", ".", "instance_mask_format", "=", "instance_mask_format", "\n", "self", ".", "use_keypoint", "=", "use_keypoint", "\n", "self", ".", "keypoint_hflip_indices", "=", "keypoint_hflip_indices", "\n", "self", ".", "proposal_topk", "=", "precomputed_proposal_topk", "\n", "self", ".", "recompute_boxes", "=", "recompute_boxes", "\n", "# fmt: on", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "mode", "=", "\"training\"", "if", "is_train", "else", "\"inference\"", "\n", "logger", ".", "info", "(", "f\"[DatasetMapper] Augmentations used in {mode}: {augmentations}\"", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "is_train", ":", "bool", "=", "True", ")", ":", "\n", "        ", "augs", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "augs", ".", "insert", "(", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", ")", "\n", "recompute_boxes", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "", "else", ":", "\n", "            ", "recompute_boxes", "=", "False", "\n", "\n", "", "ret", "=", "{", "\n", "\"is_train\"", ":", "is_train", ",", "\n", "\"augmentations\"", ":", "augs", ",", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.ISTRDatasetMapper.__call__": [[98, 152], ["copy.deepcopy", "detectron2.data.detection_utils.read_image", "detectron2.data.detection_utils.check_image_size", "torch.as_tensor", "detectron2.data.transforms.apply_transform_gens", "numpy.ascontiguousarray", "copy.deepcopy.pop", "detectron2.data.detection_utils.annotations_to_instances", "detectron2.data.detection_utils.filter_empty_instances", "detectron2.data.transforms.apply_transform_gens", "detectron2.data.detection_utils.read_image.transpose", "anno.pop", "detectron2.data.detection_utils.transform_instance_annotations", "numpy.random.rand", "detectron2.data.transforms.apply_transform_gens", "detectron2.data.transforms.apply_transform_gens", "copy.deepcopy.pop", "obj.get"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.read_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.check_image_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.annotations_to_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.filter_empty_instances", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.detection_utils.transform_instance_annotations", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["\"image_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"use_instance_mask\"", ":", "cfg", ".", "MODEL", ".", "MASK_ON", ",", "\n", "\"instance_mask_format\"", ":", "cfg", ".", "INPUT", ".", "MASK_FORMAT", ",", "\n", "\"use_keypoint\"", ":", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\n", "\"recompute_boxes\"", ":", "recompute_boxes", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "ret", "[", "\"keypoint_hflip_indices\"", "]", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "cfg", ".", "DATASETS", ".", "TRAIN", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", ":", "\n", "            ", "ret", "[", "\"precomputed_proposal_topk\"", "]", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "return", "ret", "\n", "\n", "", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n\n        Returns:\n            dict: a format that builtin models in detectron2 accept\n        \"\"\"", "\n", "dataset_dict", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "# it will be modified by code below", "\n", "# USER: Write your own image loading if it's not from a file", "\n", "image", "=", "utils", ".", "read_image", "(", "dataset_dict", "[", "\"file_name\"", "]", ",", "format", "=", "self", ".", "image_format", ")", "\n", "utils", ".", "check_image_size", "(", "dataset_dict", ",", "image", ")", "\n", "\n", "# USER: Remove if you don't do semantic/panoptic segmentation.", "\n", "if", "\"sem_seg_file_name\"", "in", "dataset_dict", ":", "\n", "            ", "sem_seg_gt", "=", "utils", ".", "read_image", "(", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ")", ",", "\"L\"", ")", ".", "squeeze", "(", "2", ")", "\n", "", "else", ":", "\n", "            ", "sem_seg_gt", "=", "None", "\n", "\n", "", "aug_input", "=", "T", ".", "AugInput", "(", "image", ",", "sem_seg", "=", "sem_seg_gt", ")", "\n", "transforms", "=", "self", ".", "augmentations", "(", "aug_input", ")", "\n", "image", ",", "sem_seg_gt", "=", "aug_input", ".", "image", ",", "aug_input", ".", "sem_seg", "\n", "\n", "image_shape", "=", "image", ".", "shape", "[", ":", "2", "]", "# h, w", "\n", "# Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,", "\n", "# but not efficient on large generic data structures due to the use of pickle & mp.Queue.", "\n", "# Therefore it's important to use torch.Tensor.", "\n", "dataset_dict", "[", "\"image\"", "]", "=", "torch", ".", "as_tensor", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "if", "sem_seg_gt", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "\"sem_seg\"", "]", "=", "torch", ".", "as_tensor", "(", "sem_seg_gt", ".", "astype", "(", "\"long\"", ")", ")", "\n", "\n", "# USER: Remove if you don't use pre-computed proposals.", "\n", "# Most users would not need this feature.", "\n", "", "if", "self", ".", "proposal_topk", "is", "not", "None", ":", "\n", "            ", "utils", ".", "transform_proposals", "(", "\n", "dataset_dict", ",", "image_shape", ",", "transforms", ",", "proposal_topk", "=", "self", ".", "proposal_topk", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.build_transform_gen": [[14, 39], ["logging.getLogger", "tfm_gens.append", "tfm_gens.append", "detectron2.data.transforms.ResizeShortestEdge", "logging.getLogger.info", "len", "len", "detectron2.data.transforms.RandomFlip", "str"], "function", ["None"], ["\n", "\n", "__all__", "=", "[", "\"DatasetMapper\"", "]", "\n", "\n", "\n", "class", "DatasetMapper", ":", "\n", "    ", "\"\"\"\n    A callable which takes a dataset dict in Detectron2 Dataset format,\n    and map it into a format used by the model.\n\n    This is the default callable to be used to map your dataset dict into training data.\n    You may need to follow it to implement your own one for customized logic,\n    such as a different way to read or transform images.\n    See :doc:`/tutorials/data_loading` for details.\n\n    The callable currently does the following:\n\n    1. Read the image from \"file_name\"\n    2. Applies cropping/geometric transforms to the image and annotations\n    3. Prepare data and annotations to Tensor and :class:`Instances`\n    \"\"\"", "\n", "\n", "@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.dataset_mapper.build_transform_gen_lsj": [[41, 71], ["augmentation.extend", "augmentation.append", "detectron2.data.transforms.RandomFlip", "detectron2.data.transforms.ResizeScale", "detectron2.data.transforms.FixedSizeCrop"], "function", ["None"], ["*", ",", "\n", "augmentations", ":", "List", "[", "Union", "[", "T", ".", "Augmentation", ",", "T", ".", "Transform", "]", "]", ",", "\n", "image_format", ":", "str", ",", "\n", "use_instance_mask", ":", "bool", "=", "False", ",", "\n", "use_keypoint", ":", "bool", "=", "False", ",", "\n", "instance_mask_format", ":", "str", "=", "\"polygon\"", ",", "\n", "keypoint_hflip_indices", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "precomputed_proposal_topk", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "recompute_boxes", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            is_train: whether it's used in training or inference\n            augmentations: a list of augmentations or deterministic transforms to apply\n            image_format: an image format supported by :func:`detection_utils.read_image`.\n            use_instance_mask: whether to process instance segmentation annotations, if available\n            use_keypoint: whether to process keypoint annotations if available\n            instance_mask_format: one of \"polygon\" or \"bitmask\". Process instance segmentation\n                masks into this format.\n            keypoint_hflip_indices: see :func:`detection_utils.create_keypoint_hflip_indices`\n            precomputed_proposal_topk: if given, will load pre-computed\n                proposals from dataset_dict and keep the top k proposals for each image.\n            recompute_boxes: whether to overwrite bounding box annotations\n                by computing tight bounding boxes from instance mask annotations.\n        \"\"\"", "\n", "if", "recompute_boxes", ":", "\n", "            ", "assert", "use_instance_mask", ",", "\"recompute_boxes requires instance masks\"", "\n", "# fmt: off", "\n", "", "self", ".", "is_train", "=", "is_train", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.__init__": [[15, 28], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "num_classes", ",", "matcher", ",", "weight_dict", ",", "eos_coef", ",", "losses", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "matcher", "=", "matcher", "\n", "self", ".", "weight_dict", "=", "weight_dict", "\n", "self", ".", "eos_coef", "=", "eos_coef", "\n", "self", ".", "losses", "=", "losses", "\n", "\n", "self", ".", "focal_loss_alpha", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "ALPHA", "\n", "self", ".", "focal_loss_gamma", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "GAMMA", "\n", "\n", "self", ".", "mask_size", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_SIZE", "\n", "self", ".", "mask_feat_dim", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_FEAT_DIM", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.loss_labels": [[29, 56], ["loss.SetCriterion._get_src_permutation_idx", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full", "torch.full", "torch.full", "torch.full", "src_logits.flatten.flatten.flatten", "target_classes.flatten.flatten.flatten", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "fvcore.nn.sigmoid_focal_loss_jit", "zip"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion._get_src_permutation_idx", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "loss_labels", "(", "self", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ")", ":", "\n", "        ", "assert", "'pred_logits'", "in", "outputs", "\n", "src_logits", "=", "outputs", "[", "'pred_logits'", "]", "\n", "\n", "idx", "=", "self", ".", "_get_src_permutation_idx", "(", "indices", ")", "\n", "target_classes_o", "=", "torch", ".", "cat", "(", "[", "t", "[", "\"labels\"", "]", "[", "J", "]", "for", "t", ",", "(", "_", ",", "J", ")", "in", "zip", "(", "targets", ",", "indices", ")", "]", ")", "\n", "target_classes", "=", "torch", ".", "full", "(", "src_logits", ".", "shape", "[", ":", "2", "]", ",", "self", ".", "num_classes", ",", "\n", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "src_logits", ".", "device", ")", "\n", "target_classes", "[", "idx", "]", "=", "target_classes_o", "\n", "\n", "src_logits", "=", "src_logits", ".", "flatten", "(", "0", ",", "1", ")", "\n", "\n", "target_classes", "=", "target_classes", ".", "flatten", "(", "0", ",", "1", ")", "\n", "pos_inds", "=", "torch", ".", "nonzero", "(", "target_classes", "!=", "self", ".", "num_classes", ",", "as_tuple", "=", "True", ")", "[", "0", "]", "\n", "labels", "=", "torch", ".", "zeros_like", "(", "src_logits", ")", "\n", "labels", "[", "pos_inds", ",", "target_classes", "[", "pos_inds", "]", "]", "=", "1", "\n", "\n", "class_loss", "=", "sigmoid_focal_loss_jit", "(", "\n", "src_logits", ",", "\n", "labels", ",", "\n", "alpha", "=", "self", ".", "focal_loss_alpha", ",", "\n", "gamma", "=", "self", ".", "focal_loss_gamma", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "/", "num_boxes", "\n", "losses", "=", "{", "'loss_ce'", ":", "class_loss", "}", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.loss_boxes": [[58, 76], ["loss.SetCriterion._get_src_permutation_idx", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.l1_loss", "torch.l1_loss", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "loss_giou.sum", "torch.l1_loss.sum", "util.box_ops.generalized_box_iou", "zip"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion._get_src_permutation_idx", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.generalized_box_iou"], ["", "def", "loss_boxes", "(", "self", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ")", ":", "\n", "        ", "assert", "'pred_boxes'", "in", "outputs", "\n", "idx", "=", "self", ".", "_get_src_permutation_idx", "(", "indices", ")", "\n", "src_boxes", "=", "outputs", "[", "'pred_boxes'", "]", "[", "idx", "]", "\n", "target_boxes", "=", "torch", ".", "cat", "(", "[", "t", "[", "'boxes_xyxy'", "]", "[", "i", "]", "for", "t", ",", "(", "_", ",", "i", ")", "in", "zip", "(", "targets", ",", "indices", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "loss_giou", "=", "1", "-", "torch", ".", "diag", "(", "box_ops", ".", "generalized_box_iou", "(", "src_boxes", ",", "target_boxes", ")", ")", "\n", "losses", "[", "'loss_giou'", "]", "=", "loss_giou", ".", "sum", "(", ")", "/", "num_boxes", "\n", "\n", "image_size", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"image_size_xyxy_tgt\"", "]", "for", "v", "in", "targets", "]", ")", "\n", "src_boxes_", "=", "src_boxes", "/", "image_size", "\n", "target_boxes_", "=", "target_boxes", "/", "image_size", "\n", "\n", "loss_bbox", "=", "F", ".", "l1_loss", "(", "src_boxes_", ",", "target_boxes_", ",", "reduction", "=", "'none'", ")", "\n", "losses", "[", "'loss_bbox'", "]", "=", "loss_bbox", ".", "sum", "(", ")", "/", "num_boxes", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.loss_masks": [[77, 132], ["mask_loss_func.SetCriterion._get_src_permutation_idx", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "src_boxes[].detach", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "tmp.append", "target_masks.flatten.flatten.size", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "mask_E", "torch.nn.SmoothL1Loss.", "mask_D().flatten", "target_masks.flatten.flatten.flatten", "zip", "t.crop_and_resize().float", "target_masks.flatten.flatten.unsqueeze", "nn.SmoothL1Loss.sum", "src_masks_feat.sum", "src_masks_feat.sum", "nn.SmoothL1Loss.sum", "mask_D", "t.crop_and_resize", "src_masks_feat.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion._get_src_permutation_idx", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "loss_masks", "(", "self", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ",", "mask_E", ",", "mask_D", ")", ":", "\n", "        ", "assert", "'pred_masks'", "in", "outputs", "\n", "idx", "=", "self", ".", "_get_src_permutation_idx", "(", "indices", ")", "\n", "src_masks_feat", "=", "outputs", "[", "'pred_masks'", "]", "[", "idx", "]", "\n", "src_boxes", "=", "outputs", "[", "'pred_boxes'", "]", "[", "idx", "]", "\n", "\n", "src_roi_feat", "=", "outputs", "[", "'pred_roi_feats'", "]", "[", "idx", "]", "\n", "\n", "target_masks", "=", "[", "t", "[", "'gt_masks'", "]", "[", "i", "]", "for", "t", ",", "(", "_", ",", "i", ")", "in", "zip", "(", "targets", ",", "indices", ")", "]", "\n", "\n", "tmp", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "target_masks", ")", ":", "\n", "            ", "num", "=", "len", "(", "t", ")", "\n", "proposals_np", "=", "src_boxes", "[", "cnt", ":", "cnt", "+", "num", "]", ".", "detach", "(", ")", "#.cpu().numpy()", "\n", "maxw", ",", "maxh", "=", "targets", "[", "i", "]", "[", "'image_size_xyxy'", "]", "[", "0", "]", ",", "targets", "[", "i", "]", "[", "'image_size_xyxy'", "]", "[", "1", "]", "\n", "\n", "proposals_np", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "torch", ".", "clamp", "(", "proposals_np", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "0", ",", "maxw", ")", "\n", "proposals_np", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "torch", ".", "clamp", "(", "proposals_np", "[", ":", ",", "[", "1", ",", "3", "]", "]", ",", "0", ",", "maxh", ")", "\n", "\n", "tmp", ".", "append", "(", "t", ".", "crop_and_resize", "(", "proposals_np", ",", "self", ".", "mask_size", ")", ".", "float", "(", ")", ")", "\n", "\n", "cnt", "=", "cnt", "+", "num", "\n", "", "target_masks", "=", "torch", ".", "cat", "(", "tmp", ",", "dim", "=", "0", ")", "\n", "\n", "if", "target_masks", ".", "size", "(", "0", ")", "!=", "0", ":", "\n", "            ", "mask_loss_func", "=", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "\"none\"", ")", "\n", "\n", "target_masks_feat", "=", "mask_E", "(", "target_masks", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "loss", "=", "mask_loss_func", "(", "src_masks_feat", ",", "target_masks_feat", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", "[", "'loss_feat'", "]", "=", "loss", ".", "sum", "(", ")", "/", "num_boxes", "/", "self", ".", "mask_feat_dim", "\n", "\n", "eps", "=", "1e-5", "\n", "src_masks", "=", "mask_D", "(", "src_masks_feat", ".", "flatten", "(", "1", ")", ",", "src_roi_feat", ")", ".", "flatten", "(", "1", ")", "\n", "target_masks", "=", "target_masks", ".", "flatten", "(", "1", ")", "\n", "intersection", "=", "(", "src_masks", "*", "target_masks", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "union", "=", "(", "src_masks", "**", "2.0", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "(", "target_masks", "**", "2.0", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "eps", "\n", "loss", "=", "1.", "-", "(", "2", "*", "intersection", "/", "union", ")", "\n", "losses", "[", "'loss_dice'", "]", "=", "loss", ".", "sum", "(", ")", "/", "num_boxes", "\n", "", "else", ":", "\n", "            ", "losses", "=", "{", "}", "\n", "losses", "[", "'loss_feat'", "]", "=", "src_masks_feat", ".", "sum", "(", ")", "*", "0.0", "\n", "# eps = 1e-5", "\n", "# src_masks = mask_D(src_masks_feat.flatten(1), src_roi_feat).flatten(1)", "\n", "# target_masks = target_masks.flatten(1)", "\n", "# intersection = (src_masks * target_masks).sum(dim=1)", "\n", "# union = (src_masks ** 2.0).sum(dim=1) + (target_masks ** 2.0).sum(dim=1) + eps", "\n", "# loss = 1. - (2 * intersection / union)", "\n", "# losses['loss_dice'] = loss.sum() / num_boxes", "\n", "losses", "[", "'loss_dice'", "]", "=", "src_masks_feat", ".", "sum", "(", ")", "*", "0.0", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion._get_src_permutation_idx": [[133, 138], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "enumerate"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "_get_src_permutation_idx", "(", "self", ",", "indices", ")", ":", "\n", "# permute predictions following indices", "\n", "        ", "batch_idx", "=", "torch", ".", "cat", "(", "[", "torch", ".", "full_like", "(", "src", ",", "i", ")", "for", "i", ",", "(", "src", ",", "_", ")", "in", "enumerate", "(", "indices", ")", "]", ")", "\n", "src_idx", "=", "torch", ".", "cat", "(", "[", "src", "for", "(", "src", ",", "_", ")", "in", "indices", "]", ")", "\n", "return", "batch_idx", ",", "src_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion._get_tgt_permutation_idx": [[139, 144], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "enumerate"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "def", "_get_tgt_permutation_idx", "(", "self", ",", "indices", ")", ":", "\n", "# permute targets following indices", "\n", "        ", "batch_idx", "=", "torch", ".", "cat", "(", "[", "torch", ".", "full_like", "(", "tgt", ",", "i", ")", "for", "i", ",", "(", "_", ",", "tgt", ")", "in", "enumerate", "(", "indices", ")", "]", ")", "\n", "tgt_idx", "=", "torch", ".", "cat", "(", "[", "tgt", "for", "(", "_", ",", "tgt", ")", "in", "indices", "]", ")", "\n", "return", "batch_idx", ",", "tgt_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.get_loss": [[145, 153], ["None"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "loss", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss_map", "=", "{", "\n", "'labels'", ":", "self", ".", "loss_labels", ",", "\n", "'boxes'", ":", "self", ".", "loss_boxes", ",", "\n", "'masks'", ":", "self", ".", "loss_masks", "\n", "}", "\n", "assert", "loss", "in", "loss_map", ",", "f'do you really want to compute {loss} loss?'", "\n", "return", "loss_map", "[", "loss", "]", "(", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.forward": [[154, 193], ["loss.SetCriterion.matcher", "sum", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "util.misc.is_dist_avail_and_initialized", "torch.clamp().item", "torch.clamp().item", "torch.clamp().item", "torch.clamp().item", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "len", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "loss.SetCriterion.get_loss", "losses.update", "loss.SetCriterion.get_loss", "losses.update", "next", "iter", "util.misc.get_world_size", "loss.SetCriterion.items", "loss.SetCriterion.items", "outputs.values"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_dist_avail_and_initialized", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.get_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.SetCriterion.get_loss", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "forward", "(", "self", ",", "outputs", ",", "targets", ",", "mask_E", ",", "mask_D", ",", "stage", ")", ":", "\n", "# Retrieve the matching between the outputs of the last layer and the targets", "\n", "        ", "indices", "=", "self", ".", "matcher", "(", "outputs", ",", "targets", ",", "mask_E", ")", "\n", "\n", "# Compute the average number of target boxes accross all nodes, for normalization purposes", "\n", "num_boxes", "=", "sum", "(", "len", "(", "t", "[", "\"labels\"", "]", ")", "for", "t", "in", "targets", ")", "\n", "num_boxes", "=", "torch", ".", "as_tensor", "(", "[", "num_boxes", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "next", "(", "iter", "(", "outputs", ".", "values", "(", ")", ")", ")", ".", "device", ")", "\n", "if", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "num_boxes", ")", "\n", "", "num_boxes", "=", "torch", ".", "clamp", "(", "num_boxes", "/", "get_world_size", "(", ")", ",", "min", "=", "1", ")", ".", "item", "(", ")", "\n", "\n", "# Compute all the requested losses", "\n", "losses", "=", "{", "}", "\n", "for", "loss", "in", "self", ".", "losses", ":", "\n", "            ", "if", "loss", "==", "'masks'", ":", "\n", "                ", "kwargs", "=", "{", "'mask_E'", ":", "mask_E", ",", "'mask_D'", ":", "mask_D", "}", "\n", "l_dict", "=", "self", ".", "get_loss", "(", "loss", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ",", "**", "kwargs", ")", "\n", "l_dict", "=", "{", "k", "+", "f'_{stage}'", ":", "v", "for", "k", ",", "v", "in", "l_dict", ".", "items", "(", ")", "}", "\n", "losses", ".", "update", "(", "l_dict", ")", "\n", "", "else", ":", "\n", "                ", "kwargs", "=", "{", "}", "\n", "l_dict", "=", "self", ".", "get_loss", "(", "loss", ",", "outputs", ",", "targets", ",", "indices", ",", "num_boxes", ",", "**", "kwargs", ")", "\n", "l_dict", "=", "{", "k", "+", "f'_{stage}'", ":", "v", "for", "k", ",", "v", "in", "l_dict", ".", "items", "(", ")", "}", "\n", "losses", ".", "update", "(", "l_dict", ")", "\n", "\n", "# In case of auxiliary losses, we repeat this process with the output of each intermediate layer.", "\n", "# if 'aux_outputs' in outputs:", "\n", "#     for i, aux_outputs in enumerate(outputs['aux_outputs']):", "\n", "#         indices = self.matcher(aux_outputs, targets, mask_E)", "\n", "#         for loss in self.losses:", "\n", "#             # if loss == 'masks':", "\n", "#             #     # Intermediate masks losses are too costly to compute, we ignore them.", "\n", "#             #     continue", "\n", "#             kwargs = {}", "\n", "#             l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_boxes, mask_E, mask_D, **kwargs)", "\n", "#             l_dict = {k + f'_{i}': v for k, v in l_dict.items()}", "\n", "#             losses.update(l_dict)", "\n", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.HungarianMatcher.__init__": [[197, 207], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "cost_class", ":", "float", "=", "1", ",", "cost_bbox", ":", "float", "=", "1", ",", "cost_giou", ":", "float", "=", "1", ",", "cost_mask", ":", "float", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cost_class", "=", "cost_class", "\n", "self", ".", "cost_bbox", "=", "cost_bbox", "\n", "self", ".", "cost_giou", "=", "cost_giou", "\n", "self", ".", "cost_mask", "=", "cost_mask", "\n", "self", ".", "focal_loss_alpha", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "ALPHA", "\n", "self", ".", "focal_loss_gamma", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "GAMMA", "\n", "self", ".", "mask_size", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_SIZE", "\n", "assert", "cost_class", "!=", "0", "or", "cost_bbox", "!=", "0", "or", "cost_giou", "!=", "0", ",", "\"all costs cant be 0\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.loss.HungarianMatcher.forward": [[208, 261], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "outputs[].flatten().sigmoid", "outputs[].flatten", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_size_out.unsqueeze().repeat().flatten.unsqueeze().repeat().flatten.unsqueeze().repeat().flatten", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cdist", "torch.cdist", "torch.cdist", "torch.cdist", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "util.box_ops.generalized_box_iou", "torch.cat().unsqueeze.size", "torch.cat().unsqueeze.size", "mask_E", "outputs[].flatten().flatten", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "C.view().cpu.view().cpu.view().cpu", "C.view().cpu.view().cpu.view().cpu", "len", "scipy.optimize.linear_sum_assignment", "outputs[].flatten", "v[].unsqueeze", "image_size_out.unsqueeze().repeat().flatten.unsqueeze().repeat().flatten.unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "outputs[].flatten", "C.view().cpu.view().cpu.view", "C.view().cpu.view().cpu.view", "C.view().cpu.view().cpu.split", "image_size_out.unsqueeze().repeat().flatten.unsqueeze().repeat().flatten.unsqueeze", "v[].crop_and_resize().float", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "v[].crop_and_resize"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.generalized_box_iou", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "self", ",", "outputs", ",", "targets", ",", "mask_E", ")", ":", "\n", "        ", "bs", ",", "num_queries", "=", "outputs", "[", "\"pred_logits\"", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "out_prob", "=", "outputs", "[", "\"pred_logits\"", "]", ".", "flatten", "(", "0", ",", "1", ")", ".", "sigmoid", "(", ")", "# [batch_size * num_queries, num_classes]", "\n", "out_bbox", "=", "outputs", "[", "\"pred_boxes\"", "]", ".", "flatten", "(", "0", ",", "1", ")", "# [batch_size * num_queries, 4]", "\n", "\n", "# Also concat the target labels and boxes", "\n", "tgt_ids", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"labels\"", "]", "for", "v", "in", "targets", "]", ")", "\n", "tgt_bbox", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"boxes_xyxy\"", "]", "for", "v", "in", "targets", "]", ")", "\n", "\n", "alpha", "=", "self", ".", "focal_loss_alpha", "\n", "gamma", "=", "self", ".", "focal_loss_gamma", "\n", "neg_cost_class", "=", "(", "1", "-", "alpha", ")", "*", "(", "out_prob", "**", "gamma", ")", "*", "(", "-", "(", "1", "-", "out_prob", "+", "1e-8", ")", ".", "log", "(", ")", ")", "\n", "pos_cost_class", "=", "alpha", "*", "(", "(", "1", "-", "out_prob", ")", "**", "gamma", ")", "*", "(", "-", "(", "out_prob", "+", "1e-8", ")", ".", "log", "(", ")", ")", "\n", "cost_class", "=", "pos_cost_class", "[", ":", ",", "tgt_ids", "]", "-", "neg_cost_class", "[", ":", ",", "tgt_ids", "]", "\n", "\n", "# Compute the L1 cost between boxes", "\n", "image_size_out", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"image_size_xyxy\"", "]", ".", "unsqueeze", "(", "0", ")", "for", "v", "in", "targets", "]", ")", "\n", "image_size_out", "=", "image_size_out", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_queries", ",", "1", ")", ".", "flatten", "(", "0", ",", "1", ")", "\n", "image_size_tgt", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"image_size_xyxy_tgt\"", "]", "for", "v", "in", "targets", "]", ")", "\n", "\n", "out_bbox_", "=", "out_bbox", "/", "image_size_out", "\n", "tgt_bbox_", "=", "tgt_bbox", "/", "image_size_tgt", "\n", "cost_bbox", "=", "torch", ".", "cdist", "(", "out_bbox_", ",", "tgt_bbox_", ",", "p", "=", "1", ")", "\n", "\n", "# Compute the giou cost betwen boxes", "\n", "# cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))", "\n", "cost_giou", "=", "-", "generalized_box_iou", "(", "out_bbox", ",", "tgt_bbox", ")", "\n", "\n", "tgt_mask", "=", "torch", ".", "cat", "(", "[", "v", "[", "\"gt_masks\"", "]", ".", "crop_and_resize", "(", "v", "[", "\"boxes_xyxy\"", "]", ",", "self", ".", "mask_size", ")", ".", "float", "(", ")", "for", "v", "in", "targets", "]", ")", ".", "unsqueeze", "(", "1", ")", "#.flatten(1)", "\n", "\n", "if", "tgt_mask", ".", "size", "(", "0", ")", "!=", "0", ":", "\n", "            ", "tgt_mask_feat", "=", "mask_E", "(", "tgt_mask", ")", "\n", "out_mask_feat", "=", "outputs", "[", "\"pred_masks\"", "]", ".", "flatten", "(", "0", ",", "1", ")", ".", "flatten", "(", "1", ")", "\n", "\n", "tgt_mask_feat", "=", "nn", ".", "functional", ".", "normalize", "(", "tgt_mask_feat", ",", "p", "=", "2", ")", "\n", "out_mask_feat", "=", "nn", ".", "functional", ".", "normalize", "(", "out_mask_feat", ",", "p", "=", "2", ")", "\n", "\n", "# cost_mask = -torch.mm(out_mask, tgt_mask.T)", "\n", "cost_mask", "=", "-", "(", "torch", ".", "mm", "(", "out_mask_feat", ",", "tgt_mask_feat", ".", "T", ")", "+", "1.0", ")", "/", "2.0", "\n", "\n", "# Final cost matrix", "\n", "C", "=", "self", ".", "cost_bbox", "*", "cost_bbox", "+", "self", ".", "cost_class", "*", "cost_class", "+", "self", ".", "cost_giou", "*", "cost_giou", "+", "self", ".", "cost_mask", "*", "cost_mask", "\n", "C", "=", "C", ".", "view", "(", "bs", ",", "num_queries", ",", "-", "1", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "# Final cost matrix", "\n", "            ", "C", "=", "self", ".", "cost_bbox", "*", "cost_bbox", "+", "self", ".", "cost_class", "*", "cost_class", "+", "self", ".", "cost_giou", "*", "cost_giou", "\n", "C", "=", "C", ".", "view", "(", "bs", ",", "num_queries", ",", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n", "", "sizes", "=", "[", "len", "(", "v", "[", "\"boxes_xyxy\"", "]", ")", "for", "v", "in", "targets", "]", "\n", "indices", "=", "[", "linear_sum_assignment", "(", "c", "[", "i", "]", ")", "for", "i", ",", "c", "in", "enumerate", "(", "C", ".", "split", "(", "sizes", ",", "-", "1", ")", ")", "]", "\n", "return", "[", "(", "torch", ".", "as_tensor", "(", "i", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "torch", ".", "as_tensor", "(", "j", ",", "dtype", "=", "torch", ".", "int64", ")", ")", "for", "i", ",", "j", "in", "indices", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead.__init__": [[15, 38], ["torch.nn.Module.__init__", "head.DynamicHead._init_box_pooler", "head.DynamicHead._init_mask_pooler", "head.RCNNHead", "head._get_clones", "head.DynamicHead._reset_parameters", "math.log"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._init_box_pooler", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._init_mask_pooler", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head._get_clones", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "roi_input_shape", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Build RoI.", "\n", "self", ".", "box_pooler", "=", "self", ".", "_init_box_pooler", "(", "cfg", ",", "roi_input_shape", ")", "\n", "self", ".", "mask_pooler", "=", "self", ".", "_init_mask_pooler", "(", "cfg", ",", "roi_input_shape", ")", "\n", "\n", "# Build heads.", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_CLASSES", "\n", "d_model", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "HIDDEN_DIM", "\n", "dim_feedforward", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "DIM_FEEDFORWARD", "\n", "nhead", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NHEADS", "\n", "dropout", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "DROPOUT", "\n", "self", ".", "num_heads", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_HEADS", "\n", "rcnn_head", "=", "RCNNHead", "(", "cfg", ",", "d_model", ",", "num_classes", ",", "dim_feedforward", ",", "nhead", ",", "dropout", ")", "\n", "self", ".", "head_series", "=", "_get_clones", "(", "rcnn_head", ",", "self", ".", "num_heads", ")", "\n", "self", ".", "return_intermediate", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "DEEP_SUPERVISION", "\n", "\n", "# Init parameters.", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "prior_prob", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "PRIOR_PROB", "\n", "self", ".", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "self", ".", "_reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._reset_parameters": [[39, 48], ["head.DynamicHead.parameters", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "# init all parameters.", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n", "# initialize the bias for focal loss.", "\n", "", "if", "p", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "num_classes", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "p", ",", "self", ".", "bias_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._init_box_pooler": [[49, 71], ["tuple", "detectron2.modeling.poolers.ROIPooler", "len", "set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "", "", "@", "staticmethod", "\n", "def", "_init_box_pooler", "(", "cfg", ",", "input_shape", ")", ":", "\n", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "\n", "# If StandardROIHeads is applied on multiple feature maps (as in FPN),", "\n", "# then we share the same predictors and therefore the channel counts must be the same", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "return", "box_pooler", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead._init_mask_pooler": [[72, 94], ["tuple", "detectron2.modeling.poolers.ROIPooler", "len", "set"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog.Metadata.set"], ["", "@", "staticmethod", "\n", "def", "_init_mask_pooler", "(", "cfg", ",", "input_shape", ")", ":", "\n", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "28", "#cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "\n", "# If StandardROIHeads is applied on multiple feature maps (as in FPN),", "\n", "# then we share the same predictors and therefore the channel counts must be the same", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "\n", "mask_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "return", "mask_pooler", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicHead.forward": [[95, 141], ["init_features.clone", "enumerate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "pred_bboxes.detach", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "rcnn_head", "torch.mean.append", "torch.mean.append", "torch.mean.append", "torch.mean.append", "rcnn_head", "criterion", "losses.update", "torch.mean.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "forward", "(", "self", ",", "features", ",", "init_bboxes", ",", "init_features", ",", "targets", "=", "None", ",", "criterion", "=", "None", ",", "mask_E", "=", "None", ",", "mask_D", "=", "None", ")", ":", "\n", "\n", "        ", "bboxes", "=", "init_bboxes", "\n", "\n", "proposal_features", "=", "init_features", ".", "clone", "(", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "\n", "inter_class_logits", "=", "[", "]", "\n", "inter_pred_bboxes", "=", "[", "]", "\n", "inter_mask_logits", "=", "[", "]", "\n", "inter_roi_feats", "=", "[", "]", "\n", "\n", "for", "stage", ",", "rcnn_head", "in", "enumerate", "(", "self", ".", "head_series", ")", ":", "\n", "\n", "            ", "if", "criterion", "!=", "None", "or", "stage", "==", "self", ".", "num_heads", "-", "1", ":", "\n", "                ", "class_logits", ",", "pred_bboxes", ",", "proposal_features", ",", "mask_logits", ",", "ret_roi_features", "=", "rcnn_head", "(", "features", ",", "bboxes", ",", "proposal_features", ",", "self", ".", "box_pooler", ",", "self", ".", "mask_pooler", ")", "\n", "\n", "inter_class_logits", ".", "append", "(", "class_logits", ")", "\n", "inter_pred_bboxes", ".", "append", "(", "pred_bboxes", ")", "\n", "inter_mask_logits", ".", "append", "(", "mask_logits", ")", "\n", "inter_roi_feats", ".", "append", "(", "ret_roi_features", ")", "\n", "\n", "", "else", ":", "\n", "                ", "class_logits", ",", "pred_bboxes", ",", "proposal_features", "=", "rcnn_head", "(", "features", ",", "bboxes", ",", "proposal_features", ",", "self", ".", "box_pooler", ",", "None", ")", "\n", "\n", "if", "stage", ">=", "2", ":", "\n", "                    ", "inter_class_logits", ".", "append", "(", "class_logits", ")", "\n", "\n", "", "", "if", "criterion", "!=", "None", ":", "\n", "                ", "output", "=", "{", "'pred_logits'", ":", "class_logits", ",", "'pred_boxes'", ":", "pred_bboxes", ",", "'pred_masks'", ":", "mask_logits", ",", "'pred_roi_feats'", ":", "ret_roi_features", "}", "\n", "tmp_loss", "=", "criterion", "(", "output", ",", "targets", ",", "mask_E", ",", "mask_D", ",", "stage", ")", "\n", "losses", ".", "update", "(", "tmp_loss", ")", "\n", "\n", "", "bboxes", "=", "pred_bboxes", ".", "detach", "(", ")", "\n", "\n", "", "if", "criterion", "!=", "None", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "inter_class_logits", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "inter_class_logits", ")", ",", "0", ")", "\n", "inter_pred_bboxes", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "inter_pred_bboxes", ")", ",", "0", ")", "\n", "inter_mask_logits", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "inter_mask_logits", ")", ",", "0", ")", "\n", "inter_roi_feats", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "inter_roi_feats", ")", ",", "0", ")", "\n", "\n", "# return class_logits[None], pred_bboxes[None], mask_logits[None], ret_roi_features[None]", "\n", "return", "inter_class_logits", "[", "None", "]", ",", "inter_pred_bboxes", "[", "None", "]", ",", "inter_mask_logits", "[", "None", "]", ",", "inter_roi_feats", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.conv_block.__init__": [[147, 157], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ELU", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ELU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "conv_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.conv_block.forward": [[159, 162], ["head.conv_block.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.__init__": [[165, 224], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "head.DynamicConv", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ELU", "list", "range", "torch.nn.ModuleList", "list", "range", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ELU", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ELU", "torch.nn.Conv2d", "head.conv_block", "head.conv_block", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.ELU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "d_model", ",", "num_classes", ",", "dim_feedforward", "=", "2048", ",", "nhead", "=", "8", ",", "dropout", "=", "0.1", ",", "scale_clamp", ":", "float", "=", "_DEFAULT_SCALE_CLAMP", ",", "bbox_weights", "=", "(", "2.0", ",", "2.0", ",", "1.0", ",", "1.0", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "# dynamic.", "\n", "self", ".", "self_attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "inst_interact", "=", "DynamicConv", "(", "cfg", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm3", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", "\n", "# cls.", "\n", "num_cls", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_CLS", "\n", "cls_module", "=", "list", "(", ")", "\n", "for", "_", "in", "range", "(", "num_cls", ")", ":", "\n", "            ", "cls_module", ".", "append", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "False", ")", ")", "\n", "cls_module", ".", "append", "(", "nn", ".", "LayerNorm", "(", "d_model", ")", ")", "\n", "cls_module", ".", "append", "(", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ")", "\n", "", "self", ".", "cls_module", "=", "nn", ".", "ModuleList", "(", "cls_module", ")", "\n", "\n", "# reg.", "\n", "num_reg", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_REG", "\n", "reg_module", "=", "list", "(", ")", "\n", "for", "_", "in", "range", "(", "num_reg", ")", ":", "\n", "            ", "reg_module", ".", "append", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "False", ")", ")", "\n", "reg_module", ".", "append", "(", "nn", ".", "LayerNorm", "(", "d_model", ")", ")", "\n", "reg_module", ".", "append", "(", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ")", "\n", "", "self", ".", "reg_module", "=", "nn", ".", "ModuleList", "(", "reg_module", ")", "\n", "\n", "self", ".", "mask_module", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "d_model", ",", "d_model", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "d_model", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "d_model", ",", "d_model", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "d_model", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "d_model", ",", "d_model", ",", "7", ",", "1", ")", ",", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_ENCODING_METHOD", "==", "'AE'", ":", "\n", "            ", "self", ".", "ret_roi_layer_1", "=", "conv_block", "(", "in_ch", "=", "d_model", ",", "out_ch", "=", "64", ")", "\n", "self", ".", "ret_roi_layer_2", "=", "conv_block", "(", "in_ch", "=", "64", ",", "out_ch", "=", "32", ")", "\n", "\n", "# pred.", "\n", "", "self", ".", "class_logits", "=", "nn", ".", "Linear", "(", "d_model", ",", "num_classes", ")", "\n", "self", ".", "bboxes_delta", "=", "nn", ".", "Linear", "(", "d_model", ",", "4", ")", "\n", "self", ".", "scale_clamp", "=", "scale_clamp", "\n", "self", ".", "bbox_weights", "=", "bbox_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.forward": [[226, 290], ["list", "range", "pooler_box", "roi_features.view().permute.view().permute.view().permute", "pro_features.view().permute().reshape.view().permute().reshape.view().permute", "head.RCNNHead.norm1", "pro_features.view().permute().reshape.view().permute().reshape.view().permute().reshape", "head.RCNNHead.inst_interact", "head.RCNNHead.norm2", "head.RCNNHead.linear2", "head.RCNNHead.norm3", "head.RCNNHead.transpose().reshape", "head.RCNNHead.transpose().reshape.clone", "head.RCNNHead.transpose().reshape.clone", "head.RCNNHead.class_logits", "head.RCNNHead.bboxes_delta", "head.RCNNHead.apply_deltas().view", "list.append", "head.RCNNHead.self_attn", "head.RCNNHead.dropout1", "head.RCNNHead.dropout2", "head.RCNNHead.dropout", "head.RCNNHead.dropout3", "cls_layer", "reg_layer", "list", "range", "pooler_mask", "head.RCNNHead.mask_module", "detectron2.structures.Boxes", "roi_features.view().permute.view().permute.view", "pro_features.view().permute().reshape.view().permute().reshape.view", "pro_features.view().permute().reshape.view().permute().reshape.view().permute", "head.RCNNHead.activation", "head.RCNNHead.transpose", "head.RCNNHead.apply_deltas", "list.append", "head.RCNNHead.ret_roi_layer_1", "head.RCNNHead.ret_roi_layer_2", "head.RCNNHead.view", "head.RCNNHead.view", "head.RCNNHead.view", "head.RCNNHead.view", "head.RCNNHead.linear1", "bboxes.view", "detectron2.structures.Boxes", "pro_features.view().permute().reshape.view().permute().reshape.view"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas"], ["", "def", "forward", "(", "self", ",", "features", ",", "bboxes", ",", "pro_features", ",", "pooler_box", ",", "pooler_mask", ")", ":", "\n", "        ", "\"\"\"\n        :param bboxes: (N, nr_boxes, 4)\n        :param pro_features: (N, nr_boxes, d_model)\n        \"\"\"", "\n", "\n", "N", ",", "nr_boxes", "=", "bboxes", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# roi_feature.", "\n", "proposal_boxes", "=", "list", "(", ")", "\n", "for", "b", "in", "range", "(", "N", ")", ":", "\n", "            ", "proposal_boxes", ".", "append", "(", "Boxes", "(", "bboxes", "[", "b", "]", ")", ")", "\n", "", "roi_features", "=", "pooler_box", "(", "features", ",", "proposal_boxes", ")", "\n", "\n", "roi_features", "=", "roi_features", ".", "view", "(", "N", "*", "nr_boxes", ",", "self", ".", "d_model", ",", "-", "1", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "# self_att.", "\n", "pro_features", "=", "pro_features", ".", "view", "(", "N", ",", "nr_boxes", ",", "self", ".", "d_model", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "pro_features2", "=", "self", ".", "self_attn", "(", "pro_features", ",", "pro_features", ",", "value", "=", "pro_features", ")", "[", "0", "]", "\n", "pro_features", "=", "pro_features", "+", "self", ".", "dropout1", "(", "pro_features2", ")", "\n", "\n", "pro_features", "=", "self", ".", "norm1", "(", "pro_features", ")", "\n", "\n", "# inst_interact.", "\n", "pro_features", "=", "pro_features", ".", "view", "(", "nr_boxes", ",", "N", ",", "self", ".", "d_model", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "reshape", "(", "1", ",", "N", "*", "nr_boxes", ",", "self", ".", "d_model", ")", "\n", "pro_features2", "=", "self", ".", "inst_interact", "(", "pro_features", ",", "roi_features", ")", "\n", "pro_features", "=", "pro_features", "+", "self", ".", "dropout2", "(", "pro_features2", ")", "\n", "\n", "obj_features", "=", "self", ".", "norm2", "(", "pro_features", ")", "\n", "\n", "# obj_feature.", "\n", "obj_features2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "obj_features", ")", ")", ")", ")", "\n", "obj_features", "=", "obj_features", "+", "self", ".", "dropout3", "(", "obj_features2", ")", "\n", "\n", "obj_features", "=", "self", ".", "norm3", "(", "obj_features", ")", "\n", "\n", "fc_feature", "=", "obj_features", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "N", "*", "nr_boxes", ",", "-", "1", ")", "\n", "cls_feature", "=", "fc_feature", ".", "clone", "(", ")", "\n", "reg_feature", "=", "fc_feature", ".", "clone", "(", ")", "\n", "\n", "for", "cls_layer", "in", "self", ".", "cls_module", ":", "\n", "            ", "cls_feature", "=", "cls_layer", "(", "cls_feature", ")", "\n", "", "for", "reg_layer", "in", "self", ".", "reg_module", ":", "\n", "            ", "reg_feature", "=", "reg_layer", "(", "reg_feature", ")", "\n", "", "class_logits", "=", "self", ".", "class_logits", "(", "cls_feature", ")", "\n", "bboxes_deltas", "=", "self", ".", "bboxes_delta", "(", "reg_feature", ")", "\n", "\n", "pred_bboxes", "=", "self", ".", "apply_deltas", "(", "bboxes_deltas", ",", "bboxes", ".", "view", "(", "-", "1", ",", "4", ")", ")", ".", "view", "(", "N", ",", "nr_boxes", ",", "-", "1", ")", "\n", "\n", "if", "pooler_mask", "!=", "None", ":", "\n", "            ", "proposal_boxes", "=", "list", "(", ")", "\n", "for", "b", "in", "range", "(", "N", ")", ":", "\n", "                ", "proposal_boxes", ".", "append", "(", "Boxes", "(", "pred_bboxes", "[", "b", "]", ")", ")", "\n", "", "ret_roi_features", "=", "pooler_mask", "(", "features", ",", "proposal_boxes", ")", "\n", "\n", "mask_logits", "=", "self", ".", "mask_module", "(", "ret_roi_features", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_ENCODING_METHOD", "==", "'AE'", ":", "\n", "                ", "ret_roi_features", "=", "self", ".", "ret_roi_layer_1", "(", "ret_roi_features", ")", "\n", "ret_roi_features", "=", "self", ".", "ret_roi_layer_2", "(", "ret_roi_features", ")", "\n", "\n", "", "return", "class_logits", ".", "view", "(", "N", ",", "nr_boxes", ",", "-", "1", ")", ",", "pred_bboxes", ",", "obj_features", ",", "mask_logits", ".", "view", "(", "N", ",", "nr_boxes", ",", "-", "1", ")", ",", "ret_roi_features", ".", "view", "(", "N", ",", "nr_boxes", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "class_logits", ".", "view", "(", "N", ",", "nr_boxes", ",", "-", "1", ")", ",", "pred_bboxes", ",", "obj_features", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.RCNNHead.apply_deltas": [[292, 331], ["boxes.to.to.to", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "", "def", "apply_deltas", "(", "self", ",", "deltas", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"", "\n", "boxes", "=", "boxes", ".", "to", "(", "deltas", ".", "dtype", ")", "\n", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "widths", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "bbox_weights", "\n", "dx", "=", "deltas", "[", ":", ",", "0", ":", ":", "4", "]", "/", "wx", "\n", "dy", "=", "deltas", "[", ":", ",", "1", ":", ":", "4", "]", "/", "wy", "\n", "dw", "=", "deltas", "[", ":", ",", "2", ":", ":", "4", "]", "/", "ww", "\n", "dh", "=", "deltas", "[", ":", ",", "3", ":", ":", "4", "]", "/", "wh", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "\n", "pred_ctr_x", "=", "dx", "*", "widths", "[", ":", ",", "None", "]", "+", "ctr_x", "[", ":", ",", "None", "]", "\n", "pred_ctr_y", "=", "dy", "*", "heights", "[", ":", ",", "None", "]", "+", "ctr_y", "[", ":", ",", "None", "]", "\n", "pred_w", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "[", ":", ",", "None", "]", "\n", "pred_h", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "[", ":", ",", "None", "]", "\n", "\n", "pred_boxes", "=", "torch", ".", "zeros_like", "(", "deltas", ")", "\n", "pred_boxes", "[", ":", ",", "0", ":", ":", "4", "]", "=", "pred_ctr_x", "-", "0.5", "*", "pred_w", "# x1", "\n", "pred_boxes", "[", ":", ",", "1", ":", ":", "4", "]", "=", "pred_ctr_y", "-", "0.5", "*", "pred_h", "# y1", "\n", "pred_boxes", "[", ":", ",", "2", ":", ":", "4", "]", "=", "pred_ctr_x", "+", "0.5", "*", "pred_w", "# x2", "\n", "pred_boxes", "[", ":", ",", "3", ":", ":", "4", "]", "=", "pred_ctr_y", "+", "0.5", "*", "pred_h", "# y2", "\n", "\n", "return", "pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicConv.__init__": [[335, 353], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_dim", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "HIDDEN_DIM", "\n", "self", ".", "dim_dynamic", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "DIM_DYNAMIC", "\n", "self", ".", "num_dynamic", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_DYNAMIC", "\n", "self", ".", "num_params", "=", "self", ".", "hidden_dim", "*", "self", ".", "dim_dynamic", "\n", "self", ".", "dynamic_layer", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_dynamic", "*", "self", ".", "num_params", ")", "\n", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "self", ".", "dim_dynamic", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "self", ".", "hidden_dim", ")", "\n", "\n", "self", ".", "activation", "=", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "num_output", "=", "self", ".", "hidden_dim", "*", "pooler_resolution", "**", "2", "\n", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "num_output", ",", "self", ".", "hidden_dim", ")", "\n", "self", ".", "norm3", "=", "nn", ".", "LayerNorm", "(", "self", ".", "hidden_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head.DynamicConv.forward": [[354, 382], ["roi_features.permute", "head.DynamicConv.dynamic_layer().permute", "parameters[].view", "parameters[].view", "torch.bmm", "head.DynamicConv.norm1", "head.DynamicConv.activation", "torch.bmm", "head.DynamicConv.norm2", "head.DynamicConv.activation", "head.DynamicConv.flatten", "head.DynamicConv.out_layer", "head.DynamicConv.norm3", "head.DynamicConv.activation", "head.DynamicConv.dynamic_layer"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "forward", "(", "self", ",", "pro_features", ",", "roi_features", ")", ":", "\n", "        ", "'''\n        pro_features: (1,  N * nr_boxes, self.d_model)\n        roi_features: (49, N * nr_boxes, self.d_model)\n        '''", "\n", "features", "=", "roi_features", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "parameters", "=", "self", ".", "dynamic_layer", "(", "pro_features", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "param1", "=", "parameters", "[", ":", ",", ":", ",", ":", "self", ".", "num_params", "]", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim_dynamic", ")", "\n", "param2", "=", "parameters", "[", ":", ",", ":", ",", "self", ".", "num_params", ":", "]", ".", "view", "(", "-", "1", ",", "self", ".", "dim_dynamic", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "\n", "features", "=", "torch", ".", "bmm", "(", "features", ",", "param1", ")", "\n", "\n", "features", "=", "self", ".", "norm1", "(", "features", ")", "\n", "features", "=", "self", ".", "activation", "(", "features", ")", "\n", "\n", "features", "=", "torch", ".", "bmm", "(", "features", ",", "param2", ")", "\n", "\n", "features", "=", "self", ".", "norm2", "(", "features", ")", "\n", "features_roi", "=", "self", ".", "activation", "(", "features", ")", "\n", "\n", "features", "=", "features_roi", ".", "flatten", "(", "1", ")", "\n", "features", "=", "self", ".", "out_layer", "(", "features", ")", "\n", "features", "=", "self", ".", "norm3", "(", "features", ")", "\n", "features", "=", "self", ".", "activation", "(", "features", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.head._get_clones": [[384, 386], ["torch.nn.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "", "def", "_get_clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "i", "in", "range", "(", "N", ")", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.__init__": [[15, 24], ["maskencoding.DctMaskEncoding.get_dct_vector_coords"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.get_dct_vector_coords"], ["def", "__init__", "(", "self", ",", "vec_dim", ",", "mask_size", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        vec_dim: the dimension of the encoded vector, int\n        mask_size: the resolution of the initial binary mask representaiton.\n        \"\"\"", "\n", "self", ".", "vec_dim", "=", "vec_dim", "\n", "self", ".", "mask_size", "=", "mask_size", "\n", "assert", "vec_dim", "<=", "mask_size", "*", "mask_size", "\n", "self", ".", "dct_vector_coords", "=", "self", ".", "get_dct_vector_coords", "(", "r", "=", "mask_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.encode": [[25, 38], ["masks.view.view.view", "torch_dct.dct_2d"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        Encode the mask to vector of vec_dim or specific dimention.\n        \"\"\"", "\n", "# if dim is None:", "\n", "dct_vector_coords", "=", "self", ".", "dct_vector_coords", "[", ":", "self", ".", "vec_dim", "]", "\n", "# else:", "\n", "# dct_vector_coords = self.dct_vector_coords[:dim]", "\n", "masks", "=", "masks", ".", "view", "(", "[", "-", "1", ",", "self", ".", "mask_size", ",", "self", ".", "mask_size", "]", ")", "#.to(dtype=float)  # [N, H, W]", "\n", "dct_all", "=", "torch_dct", ".", "dct_2d", "(", "masks", ",", "norm", "=", "'ortho'", ")", "\n", "xs", ",", "ys", "=", "dct_vector_coords", "[", ":", ",", "0", "]", ",", "dct_vector_coords", "[", ":", ",", "1", "]", "\n", "dct_vectors", "=", "dct_all", "[", ":", ",", "xs", ",", "ys", "]", "# reshape as vector", "\n", "return", "dct_vectors", "# [N, D]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.decode": [[39, 57], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch_dct.idct_2d", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "decode", "(", "self", ",", "dct_vectors", ",", "roi_feat", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        intput: dct_vector numpy [N,dct_dim]\n        output: mask_rc mask reconstructed [N, mask_size, mask_size]\n        \"\"\"", "\n", "device", "=", "dct_vectors", ".", "device", "\n", "# if dim is None:", "\n", "dct_vector_coords", "=", "self", ".", "dct_vector_coords", "[", ":", "self", ".", "vec_dim", "]", "\n", "# else:", "\n", "#     dct_vector_coords = self.dct_vector_coords[:dim]", "\n", "#     dct_vectors = dct_vectors[:, :dim]", "\n", "\n", "N", "=", "dct_vectors", ".", "shape", "[", "0", "]", "\n", "dct_trans", "=", "torch", ".", "zeros", "(", "[", "N", ",", "self", ".", "mask_size", ",", "self", ".", "mask_size", "]", ",", "dtype", "=", "dct_vectors", ".", "dtype", ")", ".", "to", "(", "device", ")", "\n", "xs", ",", "ys", "=", "dct_vector_coords", "[", ":", ",", "0", "]", ",", "dct_vector_coords", "[", ":", ",", "1", "]", "\n", "dct_trans", "[", ":", ",", "xs", ",", "ys", "]", "=", "dct_vectors", "\n", "mask_rc", "=", "torch_dct", ".", "idct_2d", "(", "dct_trans", ",", "norm", "=", "'ortho'", ")", "# [N, mask_size, mask_size]", "\n", "return", "mask_rc", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.DctMaskEncoding.get_dct_vector_coords": [[58, 79], ["range", "range", "numpy.asarray", "dct_index.extend", "dct_index.extend", "dct_index.extend", "dct_index.extend", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "get_dct_vector_coords", "(", "self", ",", "r", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        Get the coordinates with zigzag order.\n        \"\"\"", "\n", "dct_index", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "# start with even number", "\n", "                ", "index", "=", "[", "(", "i", "-", "j", ",", "j", ")", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", "\n", "dct_index", ".", "extend", "(", "index", ")", "\n", "", "else", ":", "\n", "                ", "index", "=", "[", "(", "j", ",", "i", "-", "j", ")", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", "\n", "dct_index", ".", "extend", "(", "index", ")", "\n", "", "", "for", "i", "in", "range", "(", "r", ",", "2", "*", "r", "-", "1", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "index", "=", "[", "(", "i", "-", "j", ",", "j", ")", "for", "j", "in", "range", "(", "i", "-", "r", "+", "1", ",", "r", ")", "]", "\n", "dct_index", ".", "extend", "(", "index", ")", "\n", "", "else", ":", "\n", "                ", "index", "=", "[", "(", "j", ",", "i", "-", "j", ")", "for", "j", "in", "range", "(", "i", "-", "r", "+", "1", ",", "r", ")", "]", "\n", "dct_index", ".", "extend", "(", "index", ")", "\n", "", "", "dct_idxs", "=", "np", ".", "asarray", "(", "dct_index", ")", "\n", "return", "dct_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.__init__": [[104, 119], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "agnostic", "=", "True", "#cfg.MODEL.ISTR.AGNOSTIC", "\n", "self", ".", "whiten", "=", "True", "#cfg.MODEL.ISTR.WHITEN", "\n", "self", ".", "sigmoid", "=", "True", "#cfg.MODEL.ISTR.SIGMOID", "\n", "self", ".", "mask_feat_dim", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_FEAT_DIM", "\n", "self", ".", "mask_size", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_SIZE", "\n", "\n", "if", "self", ".", "agnostic", ":", "\n", "            ", "self", ".", "components", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "mask_feat_dim", ",", "self", ".", "mask_size", "**", "2", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "explained_variances", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "mask_feat_dim", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "means", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "mask_size", "**", "2", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.inverse_sigmoid": [[120, 131], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.log", "torch.log", "torch.log", "torch.log", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "", "def", "inverse_sigmoid", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Apply the inverse sigmoid operation.\n                y = -ln(1-x/x)\n        \"\"\"", "\n", "# In case of overflow", "\n", "value_random", "=", "VALUE_MAX", "*", "torch", ".", "rand_like", "(", "x", ")", "\n", "value_random", "=", "torch", ".", "where", "(", "value_random", ">", "VALUE_MIN", ",", "value_random", ",", "VALUE_MIN", "*", "torch", ".", "ones_like", "(", "x", ")", ")", "\n", "x", "=", "torch", ".", "where", "(", "x", ">", "value_random", ",", "1", "-", "value_random", ",", "value_random", ")", "\n", "# inverse sigmoid", "\n", "y", "=", "-", "1", "*", "torch", ".", "log", "(", "(", "1", "-", "x", ")", "/", "x", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.encoder": [[132, 162], ["maskencoding.PCAMaskEncoding.flatten", "print", "maskencoding.PCAMaskEncoding.inverse_sigmoid", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.inverse_sigmoid"], ["", "def", "encoder", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"Apply dimensionality reduction to X.\n        X is projected on the first principal components previously extracted\n        from a training set.\n        Parameters\n        ----------\n        X : Original features(tensor), shape (n_samples, n_features)\n            New data, where n_samples is the number of samples\n            and n_features is the number of features.\n        Returns\n        -------\n        X_transformed : Transformed features(tensor), shape (n_samples, n_features)\n        \"\"\"", "\n", "X", "=", "X", ".", "flatten", "(", "1", ")", "\n", "assert", "X", ".", "shape", "[", "1", "]", "==", "self", ".", "mask_size", "**", "2", ",", "print", "(", "\"The original mask_size of input should be equal to the supposed size.\"", ")", "\n", "\n", "if", "self", ".", "sigmoid", ":", "\n", "            ", "X", "=", "self", ".", "inverse_sigmoid", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "agnostic", ":", "\n", "            ", "if", "self", ".", "means", "is", "not", "None", ":", "\n", "                ", "X_transformed", "=", "X", "-", "self", ".", "means", "\n", "", "X_transformed", "=", "torch", ".", "matmul", "(", "X_transformed", ",", "self", ".", "components", ".", "T", ")", "\n", "if", "self", ".", "whiten", ":", "\n", "                ", "X_transformed", "/=", "torch", ".", "sqrt", "(", "self", ".", "explained_variances", ")", "\n", "", "", "else", ":", "\n", "# TODO: The class-specific version has not implemented.", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "X_transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.decoder": [[163, 194], ["X.flatten.flatten.flatten", "print", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "maskencoding.PCAMaskEncoding.explained_variances.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "decoder", "(", "self", ",", "X", ",", "roi_feat", "=", "None", ")", ":", "\n", "        ", "\"\"\"Transform data back to its original space.\n        In other words, return an input X_original whose transform would be X.\n        Parameters\n        ----------\n        X : Encoded features(tensor), shape (n_samples, n_components)\n            New data, where n_samples is the number of samples\n            and n_components is the number of components.\n        Returns\n        -------\n        X_original original features(tensor), shape (n_samples, n_features)\n        \"\"\"", "\n", "X", "=", "X", ".", "flatten", "(", "1", ")", "\n", "assert", "X", ".", "shape", "[", "1", "]", "==", "self", ".", "mask_feat_dim", ",", "print", "(", "\"The dim of transformed data should be equal to the supposed dim.\"", ")", "\n", "\n", "if", "self", ".", "agnostic", ":", "\n", "            ", "if", "self", ".", "whiten", ":", "\n", "                ", "components_", "=", "self", ".", "components", "*", "torch", ".", "sqrt", "(", "self", ".", "explained_variances", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "X_transformed", "=", "torch", ".", "matmul", "(", "X", ",", "components_", ")", "\n", "if", "self", ".", "means", "is", "not", "None", ":", "\n", "                ", "X_transformed", "=", "X_transformed", "+", "self", ".", "means", "\n", "", "", "else", ":", "\n", "# TODO: The class-specific version has not implemented.", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "sigmoid", ":", "\n", "            ", "X_transformed", "=", "torch", ".", "sigmoid", "(", "X_transformed", ")", "\n", "", "else", ":", "\n", "            ", "X_transformed", "=", "torch", ".", "clamp", "(", "X_transformed", ",", "min", "=", "0.01", ",", "max", "=", "0.99", ")", "\n", "\n", "", "return", "X_transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.View.__init__": [[208, 211], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "View", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.View.forward": [[212, 214], ["tensor.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.up_conv.__init__": [[220, 227], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Upsample", "torch.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ",", "size", ",", "scale_factor", ")", ":", "\n", "        ", "super", "(", "up_conv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "up", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Upsample", "(", "size", ",", "scale_factor", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.up_conv.forward": [[229, 232], ["maskencoding.up_conv.up"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "up", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.Encoder.__init__": [[235, 253], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "maskencoding.View"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_size", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "1", ",", "16", ",", "4", ",", "2", ",", "1", ")", ",", "# 56", "\n", "nn", ".", "BatchNorm2d", "(", "16", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "# 28", "\n", "nn", ".", "BatchNorm2d", "(", "32", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "# 14", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "4", ",", "2", ",", "1", ")", ",", "# 7", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "128", ",", "embedding_size", ",", "7", ",", "1", ")", ",", "\n", "View", "(", "(", "-", "1", ",", "embedding_size", "*", "1", "*", "1", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.Encoder.forward": [[255, 258], ["maskencoding.Encoder.encoder"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.encoder"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "f", "=", "self", ".", "encoder", "(", "x", ")", "\n", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.Decoder.__init__": [[261, 275], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "maskencoding.View", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "maskencoding.up_conv", "maskencoding.up_conv", "maskencoding.up_conv", "maskencoding.up_conv", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "maskencoding.View"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_size", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "View", "(", "(", "-", "1", ",", "embedding_size", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "embedding_size", ",", "128", ",", "7", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ",", "\n", "up_conv", "(", "128", ",", "64", ",", "None", ",", "2", ")", ",", "\n", "up_conv", "(", "64", ",", "32", ",", "None", ",", "2", ")", ",", "\n", "up_conv", "(", "32", ",", "16", ",", "None", ",", "2", ")", ",", "\n", "up_conv", "(", "16", ",", "16", ",", "None", ",", "2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "16", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", "View", "(", "(", "-", "1", ",", "1", ",", "mask_size", ",", "mask_size", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.Decoder.forward": [[277, 287], ["enumerate", "layer", "roi_feat.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "roi_feat", "=", "None", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "decoder", ")", ":", "\n", "            ", "if", "i", "==", "6", "and", "roi_feat", "!=", "None", ":", "\n", "                ", "shape", "=", "x", ".", "shape", "\n", "roi_feat", "=", "roi_feat", ".", "view", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", "\n", "x", "=", "x", "+", "roi_feat", "\n", "del", "roi_feat", "\n", "", "x", "=", "layer", "(", "x", ")", "\n", "# x_rec = self.decoder(f)", "\n", "", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.frozen": [[197, 205], ["getattr", "module.module", "module.parameters", "child.parameters"], "function", ["None"], ["", "", "def", "frozen", "(", "module", ")", ":", "\n", "    ", "if", "getattr", "(", "module", ",", "'module'", ",", "False", ")", ":", "\n", "        ", "for", "child", "in", "module", ".", "module", "(", ")", ":", "\n", "            ", "for", "param", "in", "child", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "", "else", ":", "\n", "        ", "for", "param", "in", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ImgFeatExtractor.__init__": [[21, 24], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ImgFeatExtractor.forward": [[25, 36], ["enumerate", "torch.mean.squeeze().squeeze().unsqueeze().repeat", "torch.mean", "torch.mean", "torch.mean.squeeze().squeeze().unsqueeze", "torch.mean", "torch.mean", "torch.mean.squeeze().squeeze", "torch.mean.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ")", ":", "\n", "        ", "for", "i", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "x", "=", "torch", ".", "mean", "(", "torch", ".", "mean", "(", "f", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "x_p", "=", "torch", ".", "mean", "(", "torch", ".", "mean", "(", "f", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "x", "+", "x_p", "\n", "\n", "", "", "img_feats", "=", "x", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_PROPOSALS", ",", "1", ",", ")", "\n", "\n", "return", "img_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.__init__": [[41, 140], ["torch.nn.Module.__init__", "torch.device", "detectron2.modeling.build_backbone", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.init.constant_", "torch.nn.init.constant_", "inseg.ImgFeatExtractor", "head.DynamicHead", "loss.HungarianMatcher", "loss.SetCriterion", "torch.Tensor().to().view", "torch.Tensor().to().view", "inseg.ISTR.to", "maskencoding.Encoder", "maskencoding.Decoder", "torch.load", "inseg.ISTR.mask_E.load_state_dict", "inseg.ISTR.mask_D.load_state_dict", "maskencoding.frozen", "range", "weight_dict.update", "maskencoding.PCAMaskEncoding", "numpy.load", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "inseg.ISTR.backbone.output_shape", "aux_weight_dict.update", "torch.Tensor().to", "torch.Tensor().to", "torch.device", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "maskencoding.DctMaskEncoding", "torch.Tensor", "torch.Tensor", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "weight_dict.items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.backbone.build.build_backbone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.frozen", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.swin_transformer.SwinTransformer.output_shape", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.device", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "\n", "self", ".", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "self", ".", "num_classes", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_CLASSES", "\n", "self", ".", "num_proposals", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_PROPOSALS", "\n", "self", ".", "hidden_dim", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "HIDDEN_DIM", "\n", "self", ".", "num_heads", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NUM_HEADS", "\n", "\n", "self", ".", "mask_size", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_SIZE", "\n", "self", ".", "mask_feat_dim", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_FEAT_DIM", "\n", "\n", "self", ".", "mask_encoding_method", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_ENCODING_METHOD", "\n", "\n", "# Build Backbone.", "\n", "self", ".", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "self", ".", "size_divisibility", "=", "self", ".", "backbone", ".", "size_divisibility", "\n", "\n", "# Build Proposals.", "\n", "self", ".", "pos_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "num_proposals", ",", "self", ".", "hidden_dim", ")", "\n", "self", ".", "init_proposal_boxes", "=", "nn", ".", "Embedding", "(", "self", ".", "num_proposals", ",", "4", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "init_proposal_boxes", ".", "weight", "[", ":", ",", ":", "2", "]", ",", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "init_proposal_boxes", ".", "weight", "[", ":", ",", "2", ":", "]", ",", "1.0", ")", "\n", "\n", "self", ".", "IFE", "=", "ImgFeatExtractor", "(", "cfg", ")", "\n", "\n", "if", "self", ".", "mask_encoding_method", "==", "'AE'", ":", "\n", "            ", "self", ".", "mask_E", "=", "Encoder", "(", "self", ".", "mask_size", ",", "self", ".", "mask_feat_dim", ")", "\n", "self", ".", "mask_D", "=", "Decoder", "(", "self", ".", "mask_size", ",", "self", ".", "mask_feat_dim", ")", "\n", "\n", "checkpoint_path", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "PATH_COMPONENTS", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "self", ".", "mask_E", ".", "load_state_dict", "(", "checkpoint", "[", "'E'", "]", ")", "\n", "self", ".", "mask_D", ".", "load_state_dict", "(", "checkpoint", "[", "'D'", "]", ")", "\n", "\n", "frozen", "(", "self", ".", "mask_E", ")", "\n", "# frozen(self.mask_D)", "\n", "", "elif", "self", ".", "mask_encoding_method", "==", "'PCA'", ":", "\n", "            ", "self", ".", "mask_encoding", "=", "PCAMaskEncoding", "(", "cfg", ")", "\n", "components_path", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "PATH_COMPONENTS", "\n", "# update parameters.", "\n", "parameters", "=", "np", ".", "load", "(", "components_path", ")", "\n", "components", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "parameters", "[", "'components_c'", "]", "[", "0", "]", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "explained_variances", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "parameters", "[", "'explained_variance_c'", "]", "[", "0", "]", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "means", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "parameters", "[", "'mean_c'", "]", "[", "0", "]", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "mask_encoding", ".", "components", "=", "components", "\n", "self", ".", "mask_encoding", ".", "explained_variances", "=", "explained_variances", "\n", "self", ".", "mask_encoding", ".", "means", "=", "means", "\n", "self", ".", "mask_E", "=", "self", ".", "mask_encoding", ".", "encoder", "\n", "self", ".", "mask_D", "=", "self", ".", "mask_encoding", ".", "decoder", "\n", "", "elif", "self", ".", "mask_encoding_method", "==", "'DCT'", ":", "\n", "            ", "self", ".", "mask_encoding", "=", "DctMaskEncoding", "(", "vec_dim", "=", "self", ".", "mask_feat_dim", ",", "mask_size", "=", "self", ".", "mask_size", ")", "\n", "self", ".", "mask_E", "=", "self", ".", "mask_encoding", ".", "encode", "\n", "self", ".", "mask_D", "=", "self", ".", "mask_encoding", ".", "decode", "\n", "\n", "# Build Dynamic Head.", "\n", "", "self", ".", "head", "=", "DynamicHead", "(", "cfg", "=", "cfg", ",", "roi_input_shape", "=", "self", ".", "backbone", ".", "output_shape", "(", ")", ")", "\n", "\n", "# Loss parameters:", "\n", "class_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "CLASS_WEIGHT", "\n", "giou_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "GIOU_WEIGHT", "\n", "l1_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "L1_WEIGHT", "\n", "no_object_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "NO_OBJECT_WEIGHT", "\n", "\n", "feat_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "FEAT_WEIGHT", "\n", "mask_weight", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "MASK_WEIGHT", "\n", "\n", "self", ".", "deep_supervision", "=", "cfg", ".", "MODEL", ".", "ISTR", ".", "DEEP_SUPERVISION", "\n", "\n", "# Build Criterion.", "\n", "matcher", "=", "HungarianMatcher", "(", "cfg", "=", "cfg", ",", "\n", "cost_class", "=", "class_weight", ",", "\n", "cost_bbox", "=", "l1_weight", ",", "\n", "cost_giou", "=", "giou_weight", ",", "\n", "cost_mask", "=", "feat_weight", ")", "\n", "weight_dict", "=", "{", "\"loss_ce\"", ":", "class_weight", ",", "\"loss_bbox\"", ":", "l1_weight", ",", "\"loss_giou\"", ":", "giou_weight", ",", "\"loss_feat\"", ":", "feat_weight", ",", "\"loss_dice\"", ":", "mask_weight", "}", "\n", "if", "self", ".", "deep_supervision", ":", "\n", "            ", "aux_weight_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "aux_weight_dict", ".", "update", "(", "{", "k", "+", "f\"_{i}\"", ":", "v", "for", "k", ",", "v", "in", "weight_dict", ".", "items", "(", ")", "}", ")", "\n", "", "weight_dict", ".", "update", "(", "aux_weight_dict", ")", "\n", "\n", "", "losses", "=", "[", "\"labels\"", ",", "\"boxes\"", ",", "\"masks\"", "]", "\n", "\n", "self", ".", "criterion", "=", "SetCriterion", "(", "cfg", "=", "cfg", ",", "\n", "num_classes", "=", "self", ".", "num_classes", ",", "\n", "matcher", "=", "matcher", ",", "\n", "weight_dict", "=", "weight_dict", ",", "\n", "eos_coef", "=", "no_object_weight", ",", "\n", "losses", "=", "losses", ")", "\n", "\n", "pixel_mean", "=", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ")", ".", "to", "(", "self", ".", "device", ")", ".", "view", "(", "3", ",", "1", ",", "1", ")", "\n", "pixel_std", "=", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_STD", ")", ".", "to", "(", "self", ".", "device", ")", ".", "view", "(", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "normalizer", "=", "lambda", "x", ":", "(", "x", "-", "pixel_mean", ")", "/", "pixel_std", "\n", "self", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.forward": [[142, 214], ["inseg.ISTR.preprocess_image", "isinstance", "inseg.ISTR.backbone", "list", "inseg.ISTR.init_proposal_boxes.weight.clone", "util.box_ops.box_cxcywh_to_xyxy", "inseg.ISTR.IFE", "len", "inseg.ISTR.pos_embeddings.weight[].repeat", "util.misc.nested_tensor_from_tensor_list", "list.append", "inseg.ISTR.prepare_targets", "inseg.ISTR.head", "inseg.ISTR.keys", "inseg.ISTR.head", "inseg.ISTR.inference", "zip", "x[].to", "input_per_image.get", "input_per_image.get", "detectron2.modeling.detector_postprocess", "processed_results.append"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_cxcywh_to_xyxy", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.nested_tensor_from_tensor_list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.prepare_targets", "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get", "home.repos.pwc.inspect_result.hujiecpp_ISTR.modeling.postprocessing.detector_postprocess"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n\n                * image: Tensor, image in (C, H, W) format.\n                * instances: Instances\n\n                Other information that's included in the original dicts, such as:\n\n                * \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n        \"\"\"", "\n", "images", ",", "images_whwh", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "if", "isinstance", "(", "images", ",", "(", "list", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "            ", "images", "=", "nested_tensor_from_tensor_list", "(", "images", ")", "\n", "\n", "# Feature Extraction.", "\n", "", "src", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "features", "=", "list", "(", ")", "\n", "for", "f", "in", "self", ".", "in_features", ":", "\n", "            ", "feature", "=", "src", "[", "f", "]", "\n", "features", ".", "append", "(", "feature", ")", "\n", "\n", "# Prepare Proposals.", "\n", "", "proposal_boxes", "=", "self", ".", "init_proposal_boxes", ".", "weight", ".", "clone", "(", ")", "\n", "proposal_boxes", "=", "box_cxcywh_to_xyxy", "(", "proposal_boxes", ")", "\n", "proposal_boxes", "=", "proposal_boxes", "[", "None", "]", "*", "images_whwh", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "img_feats", "=", "self", ".", "IFE", "(", "features", ")", "\n", "bs", "=", "len", "(", "features", "[", "0", "]", ")", "\n", "pos_embeddings", "=", "self", ".", "pos_embeddings", ".", "weight", "[", "None", "]", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "proposal_feats", "=", "img_feats", "+", "pos_embeddings", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "del", "images", "\n", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "self", ".", "prepare_targets", "(", "gt_instances", ")", "\n", "del", "gt_instances", "\n", "\n", "loss_dict", "=", "self", ".", "head", "(", "features", ",", "proposal_boxes", ",", "proposal_feats", ",", "targets", ",", "self", ".", "criterion", ",", "self", ".", "mask_E", ",", "self", ".", "mask_D", ")", "\n", "\n", "weight_dict", "=", "self", ".", "criterion", ".", "weight_dict", "\n", "for", "k", "in", "loss_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "k", "in", "weight_dict", ":", "\n", "                    ", "loss_dict", "[", "k", "]", "*=", "weight_dict", "[", "k", "]", "\n", "\n", "", "", "return", "loss_dict", "\n", "\n", "", "else", ":", "\n", "            ", "outputs_class", ",", "outputs_coord", ",", "outputs_mask", ",", "outputs_roi_feat", "=", "self", ".", "head", "(", "features", ",", "proposal_boxes", ",", "proposal_feats", ")", "\n", "\n", "output", "=", "{", "'pred_logits'", ":", "outputs_class", "[", "-", "1", "]", ",", "'pred_boxes'", ":", "outputs_coord", "[", "-", "1", "]", ",", "'pred_masks'", ":", "outputs_mask", "[", "-", "1", "]", ",", "'pred_roi_feats'", ":", "outputs_roi_feat", "[", "-", "1", "]", "}", "\n", "\n", "box_cls", "=", "output", "[", "\"pred_logits\"", "]", "\n", "box_pred", "=", "output", "[", "\"pred_boxes\"", "]", "\n", "mask_pred", "=", "output", "[", "\"pred_masks\"", "]", "\n", "roi_feat", "=", "output", "[", "\"pred_roi_feats\"", "]", "\n", "\n", "results", "=", "self", ".", "inference", "(", "box_cls", ",", "box_pred", ",", "mask_pred", ",", "images", ".", "image_sizes", ",", "roi_feat", ")", "\n", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ",", "0.45", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.prepare_targets": [[215, 240], ["torch.no_grad", "torch.as_tensor", "util.box_ops.box_xyxy_to_cxcywh", "gt_classes.to", "targets_per_image.gt_boxes.tensor.to", "torch.as_tensor.to", "torch.as_tensor.unsqueeze().repeat", "torch.as_tensor.unsqueeze().repeat.to", "targets_per_image.gt_boxes.area().to", "targets_per_image.gt_masks.to", "new_targets.append", "len", "torch.as_tensor.unsqueeze", "targets_per_image.gt_boxes.area"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_xyxy_to_cxcywh", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.Boxes.area"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "prepare_targets", "(", "self", ",", "targets", ")", ":", "\n", "        ", "new_targets", "=", "[", "]", "\n", "for", "targets_per_image", "in", "targets", ":", "\n", "            ", "target", "=", "{", "}", "\n", "h", ",", "w", "=", "targets_per_image", ".", "image_size", "\n", "image_size_xyxy", "=", "torch", ".", "as_tensor", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "gt_classes", "=", "targets_per_image", ".", "gt_classes", "\n", "gt_boxes", "=", "targets_per_image", ".", "gt_boxes", ".", "tensor", "/", "image_size_xyxy", "\n", "gt_boxes", "=", "box_xyxy_to_cxcywh", "(", "gt_boxes", ")", "\n", "target", "[", "\"labels\"", "]", "=", "gt_classes", ".", "to", "(", "self", ".", "device", ")", "\n", "# target[\"boxes\"] = gt_boxes.to(self.device)", "\n", "target", "[", "\"boxes_xyxy\"", "]", "=", "targets_per_image", ".", "gt_boxes", ".", "tensor", ".", "to", "(", "self", ".", "device", ")", "\n", "target", "[", "\"image_size_xyxy\"", "]", "=", "image_size_xyxy", ".", "to", "(", "self", ".", "device", ")", "\n", "image_size_xyxy_tgt", "=", "image_size_xyxy", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "len", "(", "gt_boxes", ")", ",", "1", ")", "\n", "target", "[", "\"image_size_xyxy_tgt\"", "]", "=", "image_size_xyxy_tgt", ".", "to", "(", "self", ".", "device", ")", "\n", "target", "[", "\"area\"", "]", "=", "targets_per_image", ".", "gt_boxes", ".", "area", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "target", "[", "\"gt_masks\"", "]", "=", "targets_per_image", ".", "gt_masks", ".", "to", "(", "self", ".", "device", ")", "\n", "# masks = target['gt_masks'].crop_and_resize(targets_per_image.gt_boxes, self.mask_size)", "\n", "# target[\"gt_masks\"] = masks.float()", "\n", "\n", "new_targets", ".", "append", "(", "target", ")", "\n", "\n", "", "return", "new_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.inference": [[241, 291], ["torch.no_grad", "torch.sigmoid", "enumerate", "len", "len", "zip", "detectron2.structures.Instances", "scores_per_image.flatten().topk", "mask_pred_per_image.view.view.view", "inseg.ISTR.mask_D", "mask_pred_per_image.view.view.view", "detectron2.structures.Boxes", "results.append", "scores_per_image.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "inference", "(", "self", ",", "box_cls", ",", "box_pred", ",", "mask_pred", ",", "image_sizes", ",", "roi_feats", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            box_cls (Tensor): tensor of shape (batch_size, num_proposals, K).\n                The tensor predicts the classification probability for each proposal.\n            box_pred (Tensor): tensors of shape (batch_size, num_proposals, 4).\n                The tensor predicts 4-vector (x,y,w,h) box\n                regression values for every proposal\n            image_sizes (List[torch.Size]): the input image sizes\n\n        Returns:\n            results (List[Instances]): a list of #images elements.\n        \"\"\"", "\n", "assert", "len", "(", "box_cls", ")", "==", "len", "(", "image_sizes", ")", "\n", "results", "=", "[", "]", "\n", "\n", "scores", "=", "torch", ".", "sigmoid", "(", "box_cls", ")", "\n", "\n", "for", "i", ",", "(", "scores_per_image", ",", "box_pred_per_image", ",", "mask_pred_per_image", ",", "image_size", ",", "roi_feat", ")", "in", "enumerate", "(", "zip", "(", "\n", "scores", ",", "box_pred", ",", "mask_pred", ",", "image_sizes", ",", "roi_feats", "\n", ")", ")", ":", "\n", "            ", "result", "=", "Instances", "(", "image_size", ")", "\n", "scores_per_image", ",", "topk_indices", "=", "scores_per_image", ".", "flatten", "(", "0", ",", "1", ")", ".", "topk", "(", "100", ",", "sorted", "=", "False", ")", "\n", "# scores_per_image, topk_indices = scores_per_image.flatten(0, 1).topk(self.num_proposals, sorted=False)", "\n", "\n", "# indices = (scores_per_image > 0.02).nonzero()", "\n", "# if indices.size(0) != 0:", "\n", "#     topk_indices = topk_indices.index_select(0, indices.squeeze(-1))", "\n", "#     scores_per_image = scores_per_image.index_select(0, indices.squeeze(-1))", "\n", "# else:", "\n", "#     print('------ no prediction ------')", "\n", "\n", "labels_per_image", "=", "topk_indices", "%", "self", ".", "num_classes", "\n", "box_pred_per_image", "=", "box_pred_per_image", "[", "topk_indices", "//", "self", ".", "num_classes", "]", "\n", "\n", "mask_pred_per_image", "=", "mask_pred_per_image", ".", "view", "(", "-", "1", ",", "self", ".", "mask_feat_dim", ")", "\n", "mask_pred_per_image", "=", "mask_pred_per_image", "[", "topk_indices", "//", "self", ".", "num_classes", "]", "\n", "roi_feat", "=", "roi_feat", "[", "topk_indices", "//", "self", ".", "num_classes", "]", "\n", "\n", "mask_pred_per_image", "=", "self", ".", "mask_D", "(", "mask_pred_per_image", ",", "roi_feat", ")", "\n", "mask_pred_per_image", "=", "mask_pred_per_image", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "mask_size", ",", "self", ".", "mask_size", ")", "\n", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "box_pred_per_image", ")", "\n", "result", ".", "scores", "=", "scores_per_image", "\n", "result", ".", "pred_classes", "=", "labels_per_image", "\n", "result", ".", "pred_masks", "=", "mask_pred_per_image", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.inseg.ISTR.preprocess_image": [[292, 306], ["detectron2.structures.ImageList.from_tensors", "list", "torch.stack", "inseg.ISTR.normalizer", "torch.stack.append", "x[].to", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "self", ".", "normalizer", "(", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "size_divisibility", ")", "\n", "\n", "images_whwh", "=", "list", "(", ")", "\n", "for", "bi", "in", "batched_inputs", ":", "\n", "            ", "h", ",", "w", "=", "bi", "[", "\"image\"", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "images_whwh", ".", "append", "(", "torch", ".", "tensor", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "", "images_whwh", "=", "torch", ".", "stack", "(", "images_whwh", ")", "\n", "\n", "return", "images", ",", "images_whwh", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.colormap.colormap": [[4, 92], ["numpy.array().astype", "np.array().astype.reshape", "numpy.array"], "function", ["None"], ["\n", "\n", "import", "numpy", "as", "np", "\n", "\n", "__all__", "=", "[", "\"colormap\"", ",", "\"random_color\"", "]", "\n", "\n", "# fmt: off", "\n", "# RGB:", "\n", "_COLORS", "=", "np", ".", "array", "(", "\n", "[", "\n", "0.000", ",", "0.447", ",", "0.741", ",", "\n", "0.850", ",", "0.325", ",", "0.098", ",", "\n", "0.929", ",", "0.694", ",", "0.125", ",", "\n", "0.494", ",", "0.184", ",", "0.556", ",", "\n", "0.466", ",", "0.674", ",", "0.188", ",", "\n", "0.301", ",", "0.745", ",", "0.933", ",", "\n", "0.635", ",", "0.078", ",", "0.184", ",", "\n", "0.300", ",", "0.300", ",", "0.300", ",", "\n", "0.600", ",", "0.600", ",", "0.600", ",", "\n", "1.000", ",", "0.000", ",", "0.000", ",", "\n", "1.000", ",", "0.500", ",", "0.000", ",", "\n", "0.749", ",", "0.749", ",", "0.000", ",", "\n", "0.000", ",", "1.000", ",", "0.000", ",", "\n", "0.000", ",", "0.000", ",", "1.000", ",", "\n", "0.667", ",", "0.000", ",", "1.000", ",", "\n", "0.333", ",", "0.333", ",", "0.000", ",", "\n", "0.333", ",", "0.667", ",", "0.000", ",", "\n", "0.333", ",", "1.000", ",", "0.000", ",", "\n", "0.667", ",", "0.333", ",", "0.000", ",", "\n", "0.667", ",", "0.667", ",", "0.000", ",", "\n", "0.667", ",", "1.000", ",", "0.000", ",", "\n", "1.000", ",", "0.333", ",", "0.000", ",", "\n", "1.000", ",", "0.667", ",", "0.000", ",", "\n", "1.000", ",", "1.000", ",", "0.000", ",", "\n", "0.000", ",", "0.333", ",", "0.500", ",", "\n", "0.000", ",", "0.667", ",", "0.500", ",", "\n", "0.000", ",", "1.000", ",", "0.500", ",", "\n", "0.333", ",", "0.000", ",", "0.500", ",", "\n", "0.333", ",", "0.333", ",", "0.500", ",", "\n", "0.333", ",", "0.667", ",", "0.500", ",", "\n", "0.333", ",", "1.000", ",", "0.500", ",", "\n", "0.667", ",", "0.000", ",", "0.500", ",", "\n", "0.667", ",", "0.333", ",", "0.500", ",", "\n", "0.667", ",", "0.667", ",", "0.500", ",", "\n", "0.667", ",", "1.000", ",", "0.500", ",", "\n", "1.000", ",", "0.000", ",", "0.500", ",", "\n", "1.000", ",", "0.333", ",", "0.500", ",", "\n", "1.000", ",", "0.667", ",", "0.500", ",", "\n", "1.000", ",", "1.000", ",", "0.500", ",", "\n", "0.000", ",", "0.333", ",", "1.000", ",", "\n", "0.000", ",", "0.667", ",", "1.000", ",", "\n", "0.000", ",", "1.000", ",", "1.000", ",", "\n", "0.333", ",", "0.000", ",", "1.000", ",", "\n", "0.333", ",", "0.333", ",", "1.000", ",", "\n", "0.333", ",", "0.667", ",", "1.000", ",", "\n", "0.333", ",", "1.000", ",", "1.000", ",", "\n", "0.667", ",", "0.000", ",", "1.000", ",", "\n", "0.667", ",", "0.333", ",", "1.000", ",", "\n", "0.667", ",", "0.667", ",", "1.000", ",", "\n", "0.667", ",", "1.000", ",", "1.000", ",", "\n", "1.000", ",", "0.000", ",", "1.000", ",", "\n", "1.000", ",", "0.333", ",", "1.000", ",", "\n", "1.000", ",", "0.667", ",", "1.000", ",", "\n", "0.333", ",", "0.000", ",", "0.000", ",", "\n", "0.500", ",", "0.000", ",", "0.000", ",", "\n", "0.667", ",", "0.000", ",", "0.000", ",", "\n", "0.833", ",", "0.000", ",", "0.000", ",", "\n", "1.000", ",", "0.000", ",", "0.000", ",", "\n", "0.000", ",", "0.167", ",", "0.000", ",", "\n", "0.000", ",", "0.333", ",", "0.000", ",", "\n", "0.000", ",", "0.500", ",", "0.000", ",", "\n", "0.000", ",", "0.667", ",", "0.000", ",", "\n", "0.000", ",", "0.833", ",", "0.000", ",", "\n", "0.000", ",", "1.000", ",", "0.000", ",", "\n", "0.000", ",", "0.000", ",", "0.167", ",", "\n", "0.000", ",", "0.000", ",", "0.333", ",", "\n", "0.000", ",", "0.000", ",", "0.500", ",", "\n", "0.000", ",", "0.000", ",", "0.667", ",", "\n", "0.000", ",", "0.000", ",", "0.833", ",", "\n", "0.000", ",", "0.000", ",", "1.000", ",", "\n", "0.000", ",", "0.000", ",", "0.000", ",", "\n", "0.143", ",", "0.143", ",", "0.143", ",", "\n", "0.857", ",", "0.857", ",", "0.857", ",", "\n", "1.000", ",", "1.000", ",", "1.000", "\n", "]", "\n", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.colormap.category": [[94, 179], ["None"], "function", ["None"], ["\n", "def", "colormap", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a float32 array of Nx3 colors, in range [0, 255] or [0, 1]\n    \"\"\"", "\n", "assert", "maximum", "in", "[", "255", ",", "1", "]", ",", "maximum", "\n", "c", "=", "_COLORS", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "c", "=", "c", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "c", "\n", "\n", "\n", "", "def", "random_color", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a vector of 3 numbers\n    \"\"\"", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "_COLORS", ")", ")", "\n", "ret", "=", "_COLORS", "[", "idx", "]", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "ret", "=", "ret", "[", ":", ":", "-", "1", "]", "\n", "", "return", "ret", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "cv2", "\n", "\n", "size", "=", "100", "\n", "H", ",", "W", "=", "10", ",", "10", "\n", "canvas", "=", "np", ".", "random", ".", "rand", "(", "H", "*", "size", ",", "W", "*", "size", ",", "3", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "for", "h", "in", "range", "(", "H", ")", ":", "\n", "        ", "for", "w", "in", "range", "(", "W", ")", ":", "\n", "            ", "idx", "=", "h", "*", "W", "+", "w", "\n", "if", "idx", ">=", "len", "(", "_COLORS", ")", ":", "\n", "                ", "break", "\n", "", "canvas", "[", "h", "*", "size", ":", "(", "h", "+", "1", ")", "*", "size", ",", "w", "*", "size", ":", "(", "w", "+", "1", ")", "*", "size", "]", "=", "_COLORS", "[", "idx", "]", "\n", "", "", "cv2", ".", "imshow", "(", "\"a\"", ",", "canvas", ")", "\n", "cv2", ".", "waitKey", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.plot_utils.plot_logs": [[13, 74], ["enumerate", "matplotlib.subplots", "zip", "zip", "isinstance", "isinstance", "pathlib.Path", "pandas.read_json", "seaborn.color_palette", "enumerate", "ax.legend", "ax.set_title", "print", "ValueError", "isinstance", "ValueError", "dir.exists", "ValueError", "pathlib.Path.exists", "print", "print", "len", "pathlib.Path", "len", "pandas.DataFrame().ewm().mean", "axs[].plot", "df.interpolate().ewm().mean().plot", "pathlib.Path", "type", "type", "pandas.DataFrame().ewm", "df.interpolate().ewm().mean", "pandas.DataFrame", "df.interpolate().ewm", "numpy.stack", "df.interpolate", "df.test_coco_eval_bbox.dropna"], "function", ["None"], ["def", "plot_logs", "(", "logs", ",", "fields", "=", "(", "'class_error'", ",", "'loss_bbox_unscaled'", ",", "'mAP'", ")", ",", "ewm_col", "=", "0", ",", "log_name", "=", "'log.txt'", ")", ":", "\n", "    ", "'''\n    Function to plot specific fields from training log(s). Plots both training and test results.\n\n    :: Inputs - logs = list containing Path objects, each pointing to individual dir with a log file\n              - fields = which results to plot from each log file - plots both training and test for each field.\n              - ewm_col = optional, which column to use as the exponential weighted smoothing of the plots\n              - log_name = optional, name of log file if different than default 'log.txt'.\n\n    :: Outputs - matplotlib plots of results in fields, color coded for each log file.\n               - solid lines are training results, dashed lines are test results.\n\n    '''", "\n", "func_name", "=", "\"plot_utils.py::plot_logs\"", "\n", "\n", "# verify logs is a list of Paths (list[Paths]) or single Pathlib object Path,", "\n", "# convert single Path to list to avoid 'not iterable' error", "\n", "\n", "if", "not", "isinstance", "(", "logs", ",", "list", ")", ":", "\n", "        ", "if", "isinstance", "(", "logs", ",", "PurePath", ")", ":", "\n", "            ", "logs", "=", "[", "logs", "]", "\n", "print", "(", "f\"{func_name} info: logs param expects a list argument, converted to list[Path].\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{func_name} - invalid argument for logs parameter.\\n \\\n            Expect list[Path] or single Path obj, received {type(logs)}\"", ")", "\n", "\n", "# Quality checks - verify valid dir(s), that every item in list is Path object, and that log_name exists in each dir", "\n", "", "", "for", "i", ",", "dir", "in", "enumerate", "(", "logs", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dir", ",", "PurePath", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{func_name} - non-Path object in logs argument of {type(dir)}: \\n{dir}\"", ")", "\n", "", "if", "not", "dir", ".", "exists", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{func_name} - invalid directory in logs argument:\\n{dir}\"", ")", "\n", "# verify log_name exists", "\n", "", "fn", "=", "Path", "(", "dir", "/", "log_name", ")", "\n", "if", "not", "fn", ".", "exists", "(", ")", ":", "\n", "            ", "print", "(", "f\"-> missing {log_name}.  Have you gotten to Epoch 1 in training?\"", ")", "\n", "print", "(", "f\"--> full path of missing log file: {fn}\"", ")", "\n", "return", "\n", "\n", "# load log file(s) and plot", "\n", "", "", "dfs", "=", "[", "pd", ".", "read_json", "(", "Path", "(", "p", ")", "/", "log_name", ",", "lines", "=", "True", ")", "for", "p", "in", "logs", "]", "\n", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "ncols", "=", "len", "(", "fields", ")", ",", "figsize", "=", "(", "16", ",", "5", ")", ")", "\n", "\n", "for", "df", ",", "color", "in", "zip", "(", "dfs", ",", "sns", ".", "color_palette", "(", "n_colors", "=", "len", "(", "logs", ")", ")", ")", ":", "\n", "        ", "for", "j", ",", "field", "in", "enumerate", "(", "fields", ")", ":", "\n", "            ", "if", "field", "==", "'mAP'", ":", "\n", "                ", "coco_eval", "=", "pd", ".", "DataFrame", "(", "\n", "np", ".", "stack", "(", "df", ".", "test_coco_eval_bbox", ".", "dropna", "(", ")", ".", "values", ")", "[", ":", ",", "1", "]", "\n", ")", ".", "ewm", "(", "com", "=", "ewm_col", ")", ".", "mean", "(", ")", "\n", "axs", "[", "j", "]", ".", "plot", "(", "coco_eval", ",", "c", "=", "color", ")", "\n", "", "else", ":", "\n", "                ", "df", ".", "interpolate", "(", ")", ".", "ewm", "(", "com", "=", "ewm_col", ")", ".", "mean", "(", ")", ".", "plot", "(", "\n", "y", "=", "[", "f'train_{field}'", ",", "f'test_{field}'", "]", ",", "\n", "ax", "=", "axs", "[", "j", "]", ",", "\n", "color", "=", "[", "color", "]", "*", "2", ",", "\n", "style", "=", "[", "'-'", ",", "'--'", "]", "\n", ")", "\n", "", "", "", "for", "ax", ",", "field", "in", "zip", "(", "axs", ",", "fields", ")", ":", "\n", "        ", "ax", ".", "legend", "(", "[", "Path", "(", "p", ")", ".", "name", "for", "p", "in", "logs", "]", ")", "\n", "ax", ".", "set_title", "(", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.plot_utils.plot_precision_recall": [[76, 108], ["matplotlib.subplots", "zip", "axs[].set_title", "axs[].legend", "axs[].set_title", "axs[].legend", "seaborn.color_palette", "torch.load", "precision[].mean", "scores[].mean", "precision[].mean.mean", "[].mean", "print", "axs[].plot", "axs[].plot", "ValueError", "len", "scores[].mean.mean"], "function", ["None"], ["", "", "def", "plot_precision_recall", "(", "files", ",", "naming_scheme", "=", "'iter'", ")", ":", "\n", "    ", "if", "naming_scheme", "==", "'exp_id'", ":", "\n", "# name becomes exp_id", "\n", "        ", "names", "=", "[", "f", ".", "parts", "[", "-", "3", "]", "for", "f", "in", "files", "]", "\n", "", "elif", "naming_scheme", "==", "'iter'", ":", "\n", "        ", "names", "=", "[", "f", ".", "stem", "for", "f", "in", "files", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'not supported {naming_scheme}'", ")", "\n", "", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "ncols", "=", "2", ",", "figsize", "=", "(", "16", ",", "5", ")", ")", "\n", "for", "f", ",", "color", ",", "name", "in", "zip", "(", "files", ",", "sns", ".", "color_palette", "(", "\"Blues\"", ",", "n_colors", "=", "len", "(", "files", ")", ")", ",", "names", ")", ":", "\n", "        ", "data", "=", "torch", ".", "load", "(", "f", ")", "\n", "# precision is n_iou, n_points, n_cat, n_area, max_det", "\n", "precision", "=", "data", "[", "'precision'", "]", "\n", "recall", "=", "data", "[", "'params'", "]", ".", "recThrs", "\n", "scores", "=", "data", "[", "'scores'", "]", "\n", "# take precision for all classes, all areas and 100 detections", "\n", "precision", "=", "precision", "[", "0", ",", ":", ",", ":", ",", "0", ",", "-", "1", "]", ".", "mean", "(", "1", ")", "\n", "scores", "=", "scores", "[", "0", ",", ":", ",", ":", ",", "0", ",", "-", "1", "]", ".", "mean", "(", "1", ")", "\n", "prec", "=", "precision", ".", "mean", "(", ")", "\n", "rec", "=", "data", "[", "'recall'", "]", "[", "0", ",", ":", ",", "0", ",", "-", "1", "]", ".", "mean", "(", ")", "\n", "print", "(", "f'{naming_scheme} {name}: mAP@50={prec * 100: 05.1f}, '", "+", "\n", "f'score={scores.mean():0.3f}, '", "+", "\n", "f'f1={2 * prec * rec / (prec + rec + 1e-8):0.3f}'", "\n", ")", "\n", "axs", "[", "0", "]", ".", "plot", "(", "recall", ",", "precision", ",", "c", "=", "color", ")", "\n", "axs", "[", "1", "]", ".", "plot", "(", "recall", ",", "scores", ",", "c", "=", "color", ")", "\n", "\n", "", "axs", "[", "0", "]", ".", "set_title", "(", "'Precision / Recall'", ")", "\n", "axs", "[", "0", "]", ".", "legend", "(", "names", ")", "\n", "axs", "[", "1", "]", ".", "set_title", "(", "'Scores / Recall'", ")", "\n", "axs", "[", "1", "]", ".", "legend", "(", "names", ")", "\n", "return", "fig", ",", "axs", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_cxcywh_to_xyxy": [[9, 14], ["x.unbind", "torch.stack"], "function", ["None"], ["def", "box_cxcywh_to_xyxy", "(", "x", ")", ":", "\n", "    ", "x_c", ",", "y_c", ",", "w", ",", "h", "=", "x", ".", "unbind", "(", "-", "1", ")", "\n", "b", "=", "[", "(", "x_c", "-", "0.5", "*", "w", ")", ",", "(", "y_c", "-", "0.5", "*", "h", ")", ",", "\n", "(", "x_c", "+", "0.5", "*", "w", ")", ",", "(", "y_c", "+", "0.5", "*", "h", ")", "]", "\n", "return", "torch", ".", "stack", "(", "b", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_xyxy_to_cxcywh": [[16, 21], ["x.unbind", "torch.stack"], "function", ["None"], ["", "def", "box_xyxy_to_cxcywh", "(", "x", ")", ":", "\n", "    ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "x", ".", "unbind", "(", "-", "1", ")", "\n", "b", "=", "[", "(", "x0", "+", "x1", ")", "/", "2", ",", "(", "y0", "+", "y1", ")", "/", "2", ",", "\n", "(", "x1", "-", "x0", ")", ",", "(", "y1", "-", "y0", ")", "]", "\n", "return", "torch", ".", "stack", "(", "b", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_iou": [[24, 38], ["torchvision.ops.boxes.box_area", "torchvision.ops.boxes.box_area", "torch.max", "torch.min"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "box_iou", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "    ", "area1", "=", "box_area", "(", "boxes1", ")", "\n", "area2", "=", "box_area", "(", "boxes2", ")", "\n", "\n", "lt", "=", "torch", ".", "max", "(", "boxes1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "boxes2", "[", ":", ",", ":", "2", "]", ")", "# [N,M,2]", "\n", "rb", "=", "torch", ".", "min", "(", "boxes1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "boxes2", "[", ":", ",", "2", ":", "]", ")", "# [N,M,2]", "\n", "\n", "wh", "=", "(", "rb", "-", "lt", ")", ".", "clamp", "(", "min", "=", "0", ")", "# [N,M,2]", "\n", "inter", "=", "wh", "[", ":", ",", ":", ",", "0", "]", "*", "wh", "[", ":", ",", ":", ",", "1", "]", "# [N,M]", "\n", "\n", "union", "=", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", "\n", "\n", "iou", "=", "inter", "/", "union", "\n", "return", "iou", ",", "union", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.generalized_box_iou": [[40, 62], ["box_ops.box_iou", "torch.min", "torch.max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.box_iou", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "generalized_box_iou", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "    ", "\"\"\"\n    Generalized IoU from https://giou.stanford.edu/\n\n    The boxes should be in [x0, y0, x1, y1] format\n\n    Returns a [N, M] pairwise matrix, where N = len(boxes1)\n    and M = len(boxes2)\n    \"\"\"", "\n", "# degenerate boxes gives inf / nan results", "\n", "# so do an early check", "\n", "assert", "(", "boxes1", "[", ":", ",", "2", ":", "]", ">=", "boxes1", "[", ":", ",", ":", "2", "]", ")", ".", "all", "(", ")", "\n", "assert", "(", "boxes2", "[", ":", ",", "2", ":", "]", ">=", "boxes2", "[", ":", ",", ":", "2", "]", ")", ".", "all", "(", ")", "\n", "iou", ",", "union", "=", "box_iou", "(", "boxes1", ",", "boxes2", ")", "\n", "\n", "lt", "=", "torch", ".", "min", "(", "boxes1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "boxes2", "[", ":", ",", ":", "2", "]", ")", "\n", "rb", "=", "torch", ".", "max", "(", "boxes1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "boxes2", "[", ":", ",", "2", ":", "]", ")", "\n", "\n", "wh", "=", "(", "rb", "-", "lt", ")", ".", "clamp", "(", "min", "=", "0", ")", "# [N,M,2]", "\n", "area", "=", "wh", "[", ":", ",", ":", ",", "0", "]", "*", "wh", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "return", "iou", "-", "(", "area", "-", "union", ")", "/", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.box_ops.masks_to_boxes": [[64, 89], ["torch.arange", "torch.arange", "torch.meshgrid", "torch.stack", "masks.numel", "torch.zeros", "torch.arange.unsqueeze", "x_mask.flatten().max", "x_mask.masked_fill().flatten().min", "torch.arange.unsqueeze", "y_mask.flatten().max", "y_mask.masked_fill().flatten().min", "x_mask.flatten", "x_mask.masked_fill().flatten", "y_mask.flatten", "y_mask.masked_fill().flatten", "x_mask.masked_fill", "y_mask.masked_fill", "masks.bool", "masks.bool"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "masks_to_boxes", "(", "masks", ")", ":", "\n", "    ", "\"\"\"Compute the bounding boxes around the provided masks\n\n    The masks should be in format [N, H, W] where N is the number of masks, (H, W) are the spatial dimensions.\n\n    Returns a [N, 4] tensors, with the boxes in xyxy format\n    \"\"\"", "\n", "if", "masks", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "(", "0", ",", "4", ")", ",", "device", "=", "masks", ".", "device", ")", "\n", "\n", "", "h", ",", "w", "=", "masks", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "y", "=", "torch", ".", "arange", "(", "0", ",", "h", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "x", "=", "torch", ".", "arange", "(", "0", ",", "w", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "y", ",", "x", "=", "torch", ".", "meshgrid", "(", "y", ",", "x", ")", "\n", "\n", "x_mask", "=", "(", "masks", "*", "x", ".", "unsqueeze", "(", "0", ")", ")", "\n", "x_max", "=", "x_mask", ".", "flatten", "(", "1", ")", ".", "max", "(", "-", "1", ")", "[", "0", "]", "\n", "x_min", "=", "x_mask", ".", "masked_fill", "(", "~", "(", "masks", ".", "bool", "(", ")", ")", ",", "1e8", ")", ".", "flatten", "(", "1", ")", ".", "min", "(", "-", "1", ")", "[", "0", "]", "\n", "\n", "y_mask", "=", "(", "masks", "*", "y", ".", "unsqueeze", "(", "0", ")", ")", "\n", "y_max", "=", "y_mask", ".", "flatten", "(", "1", ")", ".", "max", "(", "-", "1", ")", "[", "0", "]", "\n", "y_min", "=", "y_mask", ".", "masked_fill", "(", "~", "(", "masks", ".", "bool", "(", ")", ")", ",", "1e8", ")", ".", "flatten", "(", "1", ")", ".", "min", "(", "-", "1", ")", "[", "0", "]", "\n", "\n", "return", "torch", ".", "stack", "(", "[", "x_min", ",", "y_min", ",", "x_max", ",", "y_max", "]", ",", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.__init__": [[31, 38], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ",", "fmt", "=", "None", ")", ":", "\n", "        ", "if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "\"{median:.4f} ({global_avg:.4f})\"", "\n", "", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "fmt", "=", "fmt", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.update": [[39, 43], ["misc.SmoothedValue.deque.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "total", "+=", "value", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.synchronize_between_processes": [[44, 56], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.barrier", "torch.barrier", "torch.all_reduce", "torch.all_reduce", "t.tolist.tolist.tolist", "int", "misc.is_dist_avail_and_initialized"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_dist_avail_and_initialized"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"", "\n", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "            ", "return", "\n", "", "t", "=", "torch", ".", "tensor", "(", "[", "self", ".", "count", ",", "self", ".", "total", "]", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "\n", "dist", ".", "barrier", "(", ")", "\n", "dist", ".", "all_reduce", "(", "t", ")", "\n", "t", "=", "t", ".", "tolist", "(", ")", "\n", "self", ".", "count", "=", "int", "(", "t", "[", "0", "]", ")", "\n", "self", ".", "total", "=", "t", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median": [[57, 61], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.median().item", "torch.tensor.median().item", "list", "torch.tensor.median", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.avg": [[62, 66], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.mean().item", "torch.tensor.mean().item", "list", "torch.tensor.mean", "torch.tensor.mean"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.global_avg": [[67, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max": [[71, 74], ["misc.SmoothedValue.max"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "@", "property", "\n", "def", "max", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.value": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "deque", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.__str__": [[79, 86], ["misc.SmoothedValue.fmt.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fmt", ".", "format", "(", "\n", "median", "=", "self", ".", "median", ",", "\n", "avg", "=", "self", ".", "avg", ",", "\n", "global_avg", "=", "self", ".", "global_avg", ",", "\n", "max", "=", "self", ".", "max", ",", "\n", "value", "=", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.__init__": [[159, 162], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update": [[163, 169], ["kwargs.items", "isinstance", "isinstance", "misc.MetricLogger.meters[].update", "v.item.item.item"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.__getattr__": [[170, 177], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "in", "self", ".", "meters", ":", "\n", "            ", "return", "self", ".", "meters", "[", "attr", "]", "\n", "", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "attr", "]", "\n", "", "raise", "AttributeError", "(", "\"'{}' object has no attribute '{}'\"", ".", "format", "(", "\n", "type", "(", "self", ")", ".", "__name__", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.__str__": [[178, 185], ["misc.MetricLogger.meters.items", "misc.MetricLogger.delimiter.join", "loss_str.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", ".", "append", "(", "\n", "\"{}: {}\"", ".", "format", "(", "name", ",", "str", "(", "meter", ")", ")", "\n", ")", "\n", "", "return", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.synchronize_between_processes": [[186, 189], ["misc.MetricLogger.meters.values", "meter.synchronize_between_processes"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.synchronize_between_processes"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "            ", "meter", ".", "synchronize_between_processes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.add_meter": [[190, 192], ["None"], "methods", ["None"], ["", "", "def", "add_meter", "(", "self", ",", "name", ",", "meter", ")", ":", "\n", "        ", "self", ".", "meters", "[", "name", "]", "=", "meter", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.log_every": [[193, 246], ["time.time", "time.time", "misc.SmoothedValue", "misc.SmoothedValue", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "print", "misc.MetricLogger.delimiter.join", "misc.MetricLogger.delimiter.join", "misc.SmoothedValue.update", "misc.SmoothedValue.update", "time.time", "time.time", "datetime.timedelta", "str", "str", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "len", "time.time", "time.time", "datetime.timedelta", "print", "print", "int", "len", "str", "len", "len", "misc.MetricLogger.format", "misc.MetricLogger.format", "len", "int", "len", "len", "str", "str", "str", "str", "str", "str", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.MetricLogger.update"], ["", "def", "log_every", "(", "self", ",", "iterable", ",", "print_freq", ",", "header", "=", "None", ")", ":", "\n", "        ", "i", "=", "0", "\n", "if", "not", "header", ":", "\n", "            ", "header", "=", "''", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "iter_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "data_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "space_fmt", "=", "':'", "+", "str", "(", "len", "(", "str", "(", "len", "(", "iterable", ")", ")", ")", ")", "+", "'d'", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", ",", "\n", "'max mem: {memory:.0f}'", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", "\n", "]", ")", "\n", "", "MB", "=", "1024.0", "*", "1024.0", "\n", "for", "obj", "in", "iterable", ":", "\n", "            ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "yield", "obj", "\n", "iter_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "i", "%", "print_freq", "==", "0", "or", "i", "==", "len", "(", "iterable", ")", "-", "1", ":", "\n", "                ", "eta_seconds", "=", "iter_time", ".", "global_avg", "*", "(", "len", "(", "iterable", ")", "-", "i", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "MB", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ")", ")", "\n", "", "", "i", "+=", "1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'{} Total time: {} ({:.4f} s / it)'", ".", "format", "(", "\n", "header", ",", "total_time_str", ",", "total_time", "/", "len", "(", "iterable", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.__init__": [[284, 287], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tensors", ",", "mask", ":", "Optional", "[", "Tensor", "]", ")", ":", "\n", "        ", "self", ".", "tensors", "=", "tensors", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to": [[288, 298], ["misc.NestedTensor.tensors.to", "misc.NestedTensor", "mask.to"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "# type: (Device) -> NestedTensor # noqa", "\n", "        ", "cast_tensor", "=", "self", ".", "tensors", ".", "to", "(", "device", ")", "\n", "mask", "=", "self", ".", "mask", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "assert", "mask", "is", "not", "None", "\n", "cast_mask", "=", "mask", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "cast_mask", "=", "None", "\n", "", "return", "NestedTensor", "(", "cast_tensor", ",", "cast_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.decompose": [[299, 301], ["None"], "methods", ["None"], ["", "def", "decompose", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tensors", ",", "self", ".", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.__repr__": [[302, 304], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather": [[88, 129], ["misc.get_world_size", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.all_gather", "zip", "torch.tensor", "torch.tensor", "int", "tensor_list.append", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "data_list.append", "torch.ByteTensor", "torch.ByteTensor", "torch.cat.numel", "range", "size.item", "torch.empty", "torch.empty", "torch.cat.cpu().numpy().tobytes", "pickle.loads", "torch.cat.cpu().numpy", "torch.cat.cpu"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.all_gather", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.wrappers.cat"], ["", "", "def", "all_gather", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "# serialized to a Tensor", "\n", "", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "# obtain Tensor size of each rank", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "size_list", "=", "[", "torch", ".", "tensor", "(", "[", "0", "]", ",", "device", "=", "\"cuda\"", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "tensor_list", "=", "[", "]", "\n", "for", "_", "in", "size_list", ":", "\n", "        ", "tensor_list", ".", "append", "(", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", ")", "\n", "", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "empty", "(", "size", "=", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.reduce_dict": [[131, 156], ["misc.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.all_reduce", "input_dict.keys", "names.append", "torch.stack.append", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "all_reduce", "(", "values", ")", "\n", "if", "average", ":", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_sha": [[248, 266], ["os.path.dirname", "os.path.abspath", "subprocess.check_output().decode().strip", "misc.get_sha._run"], "function", ["None"], ["", "", "def", "get_sha", "(", ")", ":", "\n", "    ", "cwd", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "\n", "def", "_run", "(", "command", ")", ":", "\n", "        ", "return", "subprocess", ".", "check_output", "(", "command", ",", "cwd", "=", "cwd", ")", ".", "decode", "(", "'ascii'", ")", ".", "strip", "(", ")", "\n", "", "sha", "=", "'N/A'", "\n", "diff", "=", "\"clean\"", "\n", "branch", "=", "'N/A'", "\n", "try", ":", "\n", "        ", "sha", "=", "_run", "(", "[", "'git'", ",", "'rev-parse'", ",", "'HEAD'", "]", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'diff'", "]", ",", "cwd", "=", "cwd", ")", "\n", "diff", "=", "_run", "(", "[", "'git'", ",", "'diff-index'", ",", "'HEAD'", "]", ")", "\n", "diff", "=", "\"has uncommited changes\"", "if", "diff", "else", "\"clean\"", "\n", "branch", "=", "_run", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--abbrev-ref'", ",", "'HEAD'", "]", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "pass", "\n", "", "message", "=", "f\"sha: {sha}, status: {diff}, branch: {branch}\"", "\n", "return", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.collate_fn": [[268, 272], ["list", "misc.nested_tensor_from_tensor_list", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.nested_tensor_from_tensor_list"], ["", "def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "batch", "[", "0", "]", "=", "nested_tensor_from_tensor_list", "(", "batch", "[", "0", "]", ")", "\n", "return", "tuple", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc._max_by_axis": [[274, 281], ["enumerate", "max"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "def", "_max_by_axis", "(", "the_list", ")", ":", "\n", "# type: (List[List[int]]) -> List[int]", "\n", "    ", "maxes", "=", "the_list", "[", "0", "]", "\n", "for", "sublist", "in", "the_list", "[", "1", ":", "]", ":", "\n", "        ", "for", "index", ",", "item", "in", "enumerate", "(", "sublist", ")", ":", "\n", "            ", "maxes", "[", "index", "]", "=", "max", "(", "maxes", "[", "index", "]", ",", "item", ")", "\n", "", "", "return", "maxes", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.nested_tensor_from_tensor_list": [[306, 329], ["misc.NestedTensor", "torchvision._is_tracing", "misc._max_by_axis", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "zip", "ValueError", "misc._onnx_nested_tensor_from_tensor_list", "pad_img[].copy_", "list", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.proposal_generator.proposal_utils._is_tracing", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc._max_by_axis", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc._onnx_nested_tensor_from_tensor_list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list"], ["", "", "def", "nested_tensor_from_tensor_list", "(", "tensor_list", ":", "List", "[", "Tensor", "]", ")", ":", "\n", "# TODO make this more general", "\n", "    ", "if", "tensor_list", "[", "0", "]", ".", "ndim", "==", "3", ":", "\n", "        ", "if", "torchvision", ".", "_is_tracing", "(", ")", ":", "\n", "# nested_tensor_from_tensor_list() does not export well to ONNX", "\n", "# call _onnx_nested_tensor_from_tensor_list() instead", "\n", "            ", "return", "_onnx_nested_tensor_from_tensor_list", "(", "tensor_list", ")", "\n", "\n", "# TODO make it support different-sized images", "\n", "", "max_size", "=", "_max_by_axis", "(", "[", "list", "(", "img", ".", "shape", ")", "for", "img", "in", "tensor_list", "]", ")", "\n", "# min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))", "\n", "batch_shape", "=", "[", "len", "(", "tensor_list", ")", "]", "+", "max_size", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "batch_shape", "\n", "dtype", "=", "tensor_list", "[", "0", "]", ".", "dtype", "\n", "device", "=", "tensor_list", "[", "0", "]", ".", "device", "\n", "tensor", "=", "torch", ".", "zeros", "(", "batch_shape", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "b", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "for", "img", ",", "pad_img", ",", "m", "in", "zip", "(", "tensor_list", ",", "tensor", ",", "mask", ")", ":", "\n", "            ", "pad_img", "[", ":", "img", ".", "shape", "[", "0", "]", ",", ":", "img", ".", "shape", "[", "1", "]", ",", ":", "img", ".", "shape", "[", "2", "]", "]", ".", "copy_", "(", "img", ")", "\n", "m", "[", ":", "img", ".", "shape", "[", "1", "]", ",", ":", "img", ".", "shape", "[", "2", "]", "]", "=", "False", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'not supported'", ")", "\n", "", "return", "NestedTensor", "(", "tensor", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc._onnx_nested_tensor_from_tensor_list": [[333, 360], ["range", "tuple", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "misc.NestedTensor", "tensor_list[].dim", "torch.max().to", "torch.max().to", "tuple.append", "torch.nn.functional.pad", "torch.nn.functional.pad", "padded_imgs.append", "torch.zeros_like", "torch.zeros_like", "torch.nn.functional.pad", "torch.nn.functional.pad", "padded_masks.append", "torch.nn.functional.pad.to", "torch.max", "torch.max", "zip", "torch.stack().to", "torch.stack().to", "tuple", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.NestedTensor.to"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "_onnx_nested_tensor_from_tensor_list", "(", "tensor_list", ":", "List", "[", "Tensor", "]", ")", "->", "NestedTensor", ":", "\n", "    ", "max_size", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "tensor_list", "[", "0", "]", ".", "dim", "(", ")", ")", ":", "\n", "        ", "max_size_i", "=", "torch", ".", "max", "(", "torch", ".", "stack", "(", "[", "img", ".", "shape", "[", "i", "]", "for", "img", "in", "tensor_list", "]", ")", ".", "to", "(", "torch", ".", "float32", ")", ")", ".", "to", "(", "torch", ".", "int64", ")", "\n", "max_size", ".", "append", "(", "max_size_i", ")", "\n", "", "max_size", "=", "tuple", "(", "max_size", ")", "\n", "\n", "# work around for", "\n", "# pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)", "\n", "# m[: img.shape[1], :img.shape[2]] = False", "\n", "# which is not yet supported in onnx", "\n", "padded_imgs", "=", "[", "]", "\n", "padded_masks", "=", "[", "]", "\n", "for", "img", "in", "tensor_list", ":", "\n", "        ", "padding", "=", "[", "(", "s1", "-", "s2", ")", "for", "s1", ",", "s2", "in", "zip", "(", "max_size", ",", "tuple", "(", "img", ".", "shape", ")", ")", "]", "\n", "padded_img", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "img", ",", "(", "0", ",", "padding", "[", "2", "]", ",", "0", ",", "padding", "[", "1", "]", ",", "0", ",", "padding", "[", "0", "]", ")", ")", "\n", "padded_imgs", ".", "append", "(", "padded_img", ")", "\n", "\n", "m", "=", "torch", ".", "zeros_like", "(", "img", "[", "0", "]", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "img", ".", "device", ")", "\n", "padded_mask", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "m", ",", "(", "0", ",", "padding", "[", "2", "]", ",", "0", ",", "padding", "[", "1", "]", ")", ",", "\"constant\"", ",", "1", ")", "\n", "padded_masks", ".", "append", "(", "padded_mask", ".", "to", "(", "torch", ".", "bool", ")", ")", "\n", "\n", "", "tensor", "=", "torch", ".", "stack", "(", "padded_imgs", ")", "\n", "mask", "=", "torch", ".", "stack", "(", "padded_masks", ")", "\n", "\n", "return", "NestedTensor", "(", "tensor", ",", "mask", "=", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.setup_for_distributed": [[362, 375], ["kwargs.pop", "builtin_print"], "function", ["None"], ["", "def", "setup_for_distributed", "(", "is_master", ")", ":", "\n", "    ", "\"\"\"\n    This function disables printing when not in master process\n    \"\"\"", "\n", "import", "builtins", "as", "__builtin__", "\n", "builtin_print", "=", "__builtin__", ".", "print", "\n", "\n", "def", "print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "force", "=", "kwargs", ".", "pop", "(", "'force'", ",", "False", ")", "\n", "if", "is_master", "or", "force", ":", "\n", "            ", "builtin_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "__builtin__", ".", "print", "=", "print", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_dist_avail_and_initialized": [[377, 383], ["torch.is_available", "torch.is_initialized"], "function", ["None"], ["", "def", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size": [[385, 389], ["torch.get_world_size", "misc.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_world_size", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_dist_avail_and_initialized"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank": [[391, 395], ["torch.get_rank", "misc.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank", "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_dist_avail_and_initialized"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process": [[397, 399], ["misc.get_rank"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.save_on_master": [[401, 404], ["misc.is_main_process", "torch.save", "torch.save"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.is_main_process", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["", "def", "save_on_master", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.init_distributed_mode": [[406, 429], ["torch.cuda.set_device", "torch.cuda.set_device", "misc.setup_for_distributed.print", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.barrier", "torch.distributed.barrier", "misc.setup_for_distributed", "int", "int", "int", "int", "misc.setup_for_distributed.print", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.setup_for_distributed"], ["", "", "def", "init_distributed_mode", "(", "args", ")", ":", "\n", "    ", "if", "'RANK'", "in", "os", ".", "environ", "and", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "", "elif", "'SLURM_PROCID'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "args", ".", "gpu", "=", "args", ".", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Not using distributed mode'", ")", "\n", "args", ".", "distributed", "=", "False", "\n", "return", "\n", "\n", "", "args", ".", "distributed", "=", "True", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "args", ".", "dist_backend", "=", "'nccl'", "\n", "print", "(", "'| distributed init (rank {}): {}'", ".", "format", "(", "\n", "args", ".", "rank", ",", "args", ".", "dist_url", ")", ",", "flush", "=", "True", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "args", ".", "dist_backend", ",", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "rank", "=", "args", ".", "rank", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "setup_for_distributed", "(", "args", ".", "rank", "==", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.accuracy": [[431, 448], ["torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.numel", "target.view().expand_as", "correct[].view().float().sum", "res.append", "torch.zeros", "torch.zeros", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.util.misc.SmoothedValue.max"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "if", "target", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "[", "torch", ".", "zeros", "(", "[", "]", ",", "device", "=", "output", ".", "device", ")", "]", "\n", "", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.View.__init__": [[38, 41], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "View", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.View.forward": [[42, 44], ["tensor.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.conv_block.__init__": [[49, 59], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "conv_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.conv_block.forward": [[60, 64], ["mask_train.conv_block.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.up_conv.__init__": [[70, 77], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ",", "size", ",", "scale_factor", ")", ":", "\n", "        ", "super", "(", "up_conv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "up", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Upsample", "(", "size", ",", "scale_factor", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.up_conv.forward": [[79, 82], ["mask_train.up_conv.up"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "up", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Encoder.__init__": [[233, 251], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mask_train.View"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_size", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "1", ",", "16", ",", "4", ",", "2", ",", "1", ")", ",", "# 56", "\n", "nn", ".", "BatchNorm2d", "(", "16", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "# 28", "\n", "nn", ".", "BatchNorm2d", "(", "32", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "# 14", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "4", ",", "2", ",", "1", ")", ",", "# 7", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ELU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "128", ",", "embedding_size", ",", "7", ",", "1", ")", ",", "\n", "View", "(", "(", "-", "1", ",", "embedding_size", "*", "1", "*", "1", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Encoder.forward": [[253, 256], ["mask_train.Encoder.encoder"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.encoder"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "f", "=", "self", ".", "encoder", "(", "x", ")", "\n", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Decoder.__init__": [[258, 278], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mask_train.View", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.ELU", "mask_train.up_conv", "mask_train.up_conv", "mask_train.up_conv", "mask_train.up_conv", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "mask_train.View"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_size", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "View", "(", "(", "-", "1", ",", "embedding_size", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "embedding_size", ",", "128", ",", "7", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ",", "\n", "\n", "up_conv", "(", "128", ",", "64", ",", "None", ",", "2", ")", ",", "\n", "\n", "up_conv", "(", "64", ",", "32", ",", "None", ",", "2", ")", ",", "\n", "\n", "up_conv", "(", "32", ",", "16", ",", "None", ",", "2", ")", ",", "\n", "\n", "up_conv", "(", "16", ",", "16", ",", "None", ",", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "16", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", "\n", "View", "(", "(", "-", "1", ",", "1", ",", "mask_size", ",", "mask_size", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.Decoder.forward": [[280, 290], ["mask_train.Decoder.decoder"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.istr.maskencoding.PCAMaskEncoding.decoder"], ["", "def", "forward", "(", "self", ",", "x", ",", "roi_feat", "=", "None", ")", ":", "\n", "# for i, layer in enumerate(self.decoder):", "\n", "#     if i == 6 and roi_feat != None:", "\n", "#         shape = x.shape", "\n", "#         roi_feat = roi_feat.view(shape[0], shape[1], shape[2], shape[3])", "\n", "#         x = x + roi_feat", "\n", "#         del roi_feat", "\n", "#     x = layer(x)", "\n", "        ", "x", "=", "self", ".", "decoder", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.visualization": [[308, 335], ["os.path.join", "os.makedirs", "enumerate", "numpy.concatenate", "PIL.Image.fromarray", "Image.fromarray.save", "print", "zip", "a_mask.squeeze.squeeze", "b_mask.squeeze.squeeze", "np.concatenate.append", "os.path.join", "a_mask.squeeze.detach().cpu().numpy", "b_mask.squeeze.detach().cpu().numpy", "a_mask.squeeze.detach().cpu", "b_mask.squeeze.detach().cpu", "a_mask.squeeze.detach", "b_mask.squeeze.detach"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save"], ["def", "visualization", "(", "epoch", ",", "a", ",", "b", ")", ":", "\n", "    ", "save_dir", "=", "os", ".", "path", ".", "join", "(", "'./vis'", ")", "\n", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "res_mask", "=", "[", "]", "\n", "\n", "for", "idx", ",", "(", "a_mask", ",", "b_mask", ")", "in", "enumerate", "(", "zip", "(", "a", ",", "b", ")", ")", ":", "\n", "\n", "        ", "if", "idx", ">", "0", ":", "\n", "            ", "break", "\n", "\n", "", "a_mask", "=", "a_mask", ".", "squeeze", "(", ")", "\n", "a_mask", "=", "a_mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">=", "0.5", "\n", "\n", "b_mask", "=", "b_mask", ".", "squeeze", "(", ")", "# h,w", "\n", "b_mask", "=", "b_mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">=", "0.5", "\n", "\n", "\n", "img", "=", "a_mask", "#np.concatenate((a_mask, b_mask), axis=1)    ", "\n", "res_mask", ".", "append", "(", "img", ")", "\n", "\n", "", "res_mask", "=", "np", ".", "concatenate", "(", "res_mask", ",", "axis", "=", "0", ")", "\n", "\n", "img", "=", "Image", ".", "fromarray", "(", "res_mask", ")", "\n", "\n", "img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'vis_{}.png'", ".", "format", "(", "epoch", ")", ")", ")", "\n", "\n", "print", "(", "adfs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train": [[339, 369], ["E.train", "D.train", "enumerate", "x.reshape.cuda", "E", "D", "x.reshape.size", "x_rec.reshape.reshape", "x.reshape.reshape", "loss_rec.mean.mean", "optimizer.zero_grad", "loss_rec.mean.backward", "optimizer.step", "print", "len", "loss_rec.mean.item", "len", "len"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.train", "home.repos.pwc.inspect_result.hujiecpp_ISTR.layers.roi_align_rotated._ROIAlignRotated.backward", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.events.EventStorage.step"], ["", "def", "train", "(", "epoch", ")", ":", "\n", "    ", "E", ".", "train", "(", ")", "\n", "D", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "x", "in", "enumerate", "(", "mask_train_loader", ")", ":", "\n", "        ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "f", "=", "E", "(", "x", ")", "\n", "x_rec", "=", "D", "(", "f", ")", "\n", "\n", "# print(f.shape, x_rec.shape)", "\n", "\n", "# loss_rec = loss_MSE(x_rec, x)", "\n", "\n", "eps", "=", "1e-5", "\n", "n_inst", "=", "x", ".", "size", "(", "0", ")", "\n", "x_rec", "=", "x_rec", ".", "reshape", "(", "n_inst", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "reshape", "(", "n_inst", ",", "-", "1", ")", "\n", "intersection", "=", "(", "x_rec", "*", "x", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "union", "=", "(", "x_rec", "**", "2.0", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "(", "x", "**", "2.0", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "eps", "\n", "loss_rec", "=", "1.", "-", "(", "2", "*", "intersection", "/", "union", ")", "\n", "loss_rec", "=", "loss_rec", ".", "mean", "(", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss_rec", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "batch_idx", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss_rec: {:.5f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "len", "(", "x", ")", ",", "len", "(", "mask_train_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "batch_idx", "/", "len", "(", "mask_train_loader", ")", ",", "\n", "loss_rec", ".", "item", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.test": [[372, 406], ["E.eval", "D.eval", "utils.IOUMetric", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "utils.IOUMetric.evaluate", "print", "print", "torch.save", "torch.save", "torch.save", "x.cuda.cuda", "E", "D", "mask_train.visualization", "numpy.where", "utils.IOUMetric.add_batch", "E.state_dict", "D.state_dict", "os.path.isdir", "os.mkdir", "x.cuda.cpu().numpy", "np.where.cpu().numpy", "x.cuda.cpu", "np.where.cpu"], "function", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.mask_train.visualization", "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.add_batch", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.hujiecpp_ISTR.solver.lr_scheduler.LRMultiplier.state_dict"], ["", "", "", "def", "test", "(", "epoch", "=", "0", ")", ":", "\n", "    ", "global", "best_iou", "\n", "E", ".", "eval", "(", ")", "\n", "D", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "IoUevaluate", "=", "IOUMetric", "(", "2", ")", "\n", "print", "(", "\"Start evaluation...\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "x", "in", "enumerate", "(", "mask_val_loader", ")", ":", "\n", "            ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "f", "=", "E", "(", "x", ")", "\n", "x_rec", "=", "D", "(", "f", ")", "\n", "\n", "visualization", "(", "epoch", ",", "x", ",", "x_rec", ")", "\n", "\n", "x_rec", "=", "np", ".", "where", "(", "x_rec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">=", "0.5", ",", "1", ",", "0", ")", "\n", "IoUevaluate", ".", "add_batch", "(", "x_rec", ",", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "mean_iou", ",", "_", "=", "IoUevaluate", ".", "evaluate", "(", ")", "\n", "print", "(", "\"The mIoU: {}\"", ".", "format", "(", "mean_iou", ")", ")", "\n", "\n", "", "if", "mean_iou", ">", "best_iou", ":", "\n", "        ", "print", "(", "'Best...'", ")", "\n", "best_iou", "=", "mean_iou", "\n", "\n", "state", "=", "{", "\n", "'E'", ":", "E", ".", "state_dict", "(", ")", ",", "\n", "'D'", ":", "D", ".", "state_dict", "(", ")", ",", "\n", "'best_iou'", ":", "mean_iou", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'checkpoints'", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'checkpoints'", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "'./checkpoints/AE_{}_{}.t7'", ".", "format", "(", "args", ".", "mask_size", ",", "args", ".", "embedding_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.MaskLoader.MaskLoader.__init__": [[40, 65], ["isinstance", "os.path.join", "os.path.join", "list", "print", "open", "json.load", "ann.get", "list.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.hujiecpp_ISTR.data.catalog._MetadataCatalog.get"], ["def", "__init__", "(", "self", ",", "root", "=", "\"datasets\"", ",", "dataset", "=", "\"coco_2017_train\"", ",", "size", "=", "28", ",", "transform", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "\n", "\n", "", "data_info", "=", "DATASETS", "[", "dataset", "]", "\n", "img_dir", ",", "ann_file", "=", "data_info", "[", "'img_dir'", "]", ",", "data_info", "[", "'ann_file'", "]", "\n", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "img_dir", ")", "# actually we do not use it.", "\n", "ann_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "ann_file", ")", "\n", "\n", "with", "open", "(", "ann_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "anns", "=", "json", ".", "load", "(", "f", ")", "\n", "", "anns", "=", "anns", "[", "'annotations'", "]", "\n", "coco", "=", "list", "(", ")", "\n", "for", "ann", "in", "anns", ":", "\n", "            ", "if", "ann", ".", "get", "(", "'iscrowd'", ",", "0", ")", "==", "0", ":", "\n", "                ", "coco", ".", "append", "(", "ann", ")", "\n", "", "", "self", ".", "coco", "=", "coco", "\n", "print", "(", "\"Removed {} images with no usable annotations. {} images left.\"", ".", "format", "(", "\n", "len", "(", "anns", ")", "-", "len", "(", "self", ".", "coco", ")", ",", "len", "(", "self", ".", "coco", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.MaskLoader.MaskLoader.__len__": [[66, 68], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "coco", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.MaskLoader.MaskLoader.__getitem__": [[69, 84], ["numpy.array", "detectron2.structures.BoxMode.convert", "detectron2.structures.Boxes", "detectron2.structures.PolygonMasks", "mask.crop_and_resize().float.crop_and_resize().float.crop_and_resize().float", "mask.crop_and_resize().float.crop_and_resize().float.crop_and_resize"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.boxes.BoxMode.convert", "home.repos.pwc.inspect_result.hujiecpp_ISTR.structures.masks.PolygonMasks.crop_and_resize"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "ann", "=", "self", ".", "coco", "[", "index", "]", "\n", "\n", "# bbox transform.", "\n", "bbox", "=", "np", ".", "array", "(", "[", "ann", "[", "\"bbox\"", "]", "]", ")", "# xmin, ymin, w, h", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "# x1y1x2y2", "\n", "bbox", "=", "Boxes", "(", "bbox", ")", "\n", "\n", "# label", "\n", "\n", "# mask transform.", "\n", "mask", "=", "PolygonMasks", "(", "[", "ann", "[", "\"segmentation\"", "]", "]", ")", "\n", "mask", "=", "mask", ".", "crop_and_resize", "(", "bbox", ".", "tensor", ",", "self", ".", "size", ")", ".", "float", "(", ")", "\n", "\n", "return", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.__init__": [[97, 100], ["numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "hist", "=", "np", ".", "zeros", "(", "(", "num_classes", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric._fast_hist": [[101, 107], ["numpy.bincount().reshape", "numpy.bincount", "label_true[].astype"], "methods", ["None"], ["", "def", "_fast_hist", "(", "self", ",", "label_pred", ",", "label_true", ")", ":", "\n", "        ", "mask", "=", "(", "label_true", ">=", "0", ")", "&", "(", "label_true", "<", "self", ".", "num_classes", ")", "\n", "hist", "=", "np", ".", "bincount", "(", "\n", "self", ".", "num_classes", "*", "label_true", "[", "mask", "]", ".", "astype", "(", "int", ")", "+", "\n", "label_pred", "[", "mask", "]", ",", "minlength", "=", "self", ".", "num_classes", "**", "2", ")", ".", "reshape", "(", "self", ".", "num_classes", ",", "self", ".", "num_classes", ")", "\n", "return", "hist", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.add_batch": [[108, 111], ["zip", "utils.IOUMetric._fast_hist", "lp.flatten", "lt.flatten"], "methods", ["home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric._fast_hist", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.hujiecpp_ISTR.export.flatten.TensorWrapSchema.flatten"], ["", "def", "add_batch", "(", "self", ",", "predictions", ",", "gts", ")", ":", "\n", "        ", "for", "lp", ",", "lt", "in", "zip", "(", "predictions", ",", "gts", ")", ":", "\n", "            ", "self", ".", "hist", "+=", "self", ".", "_fast_hist", "(", "lp", ".", "flatten", "(", ")", ",", "lt", ".", "flatten", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.IOUMetric.evaluate": [[112, 121], ["numpy.nanmean", "numpy.nanmean", "numpy.diag().sum", "utils.IOUMetric.hist.sum", "numpy.diag", "utils.IOUMetric.hist.sum", "numpy.diag", "utils.IOUMetric.hist.sum", "utils.IOUMetric.hist.sum", "numpy.diag", "numpy.diag", "utils.IOUMetric.hist.sum", "utils.IOUMetric.hist.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "acc", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", ".", "sum", "(", ")", "/", "self", ".", "hist", ".", "sum", "(", ")", "\n", "acc_cls", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", "/", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "\n", "acc_cls", "=", "np", ".", "nanmean", "(", "acc_cls", ")", "\n", "iu", "=", "np", ".", "diag", "(", "self", ".", "hist", ")", "/", "(", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "+", "self", ".", "hist", ".", "sum", "(", "axis", "=", "0", ")", "-", "np", ".", "diag", "(", "self", ".", "hist", ")", ")", "\n", "mean_iu", "=", "np", ".", "nanmean", "(", "iu", ")", "\n", "freq", "=", "self", ".", "hist", ".", "sum", "(", "axis", "=", "1", ")", "/", "self", ".", "hist", ".", "sum", "(", ")", "\n", "fwavacc", "=", "(", "freq", "[", "freq", ">", "0", "]", "*", "iu", "[", "freq", ">", "0", "]", ")", ".", "sum", "(", ")", "\n", "return", "acc", ",", "acc_cls", ",", "iu", ",", "mean_iu", ",", "fwavacc", "", "", "", ""]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.direct_sigmoid": [[6, 12], ["numpy.exp"], "function", ["None"], ["def", "direct_sigmoid", "(", "x", ")", ":", "\n", "    ", "\"\"\"Apply the sigmoid operation.\n    \"\"\"", "\n", "y", "=", "1.", "/", "(", "1.", "+", "1.", "/", "np", ".", "exp", "(", "x", ")", ")", "\n", "dy", "=", "y", "*", "(", "1", "-", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.inverse_sigmoid": [[14, 20], ["numpy.log"], "function", ["None"], ["", "def", "inverse_sigmoid", "(", "x", ")", ":", "\n", "    ", "\"\"\"Apply the inverse sigmoid operation.\n            y = -ln(1-x/x)\n    \"\"\"", "\n", "y", "=", "-", "1", "*", "np", ".", "log", "(", "(", "1", "-", "x", ")", "/", "x", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.transform": [[22, 54], ["numpy.dot", "numpy.sqrt"], "function", ["None"], ["", "def", "transform", "(", "X", ",", "components_", ",", "explained_variance_", ",", "mean_", "=", "None", ",", "whiten", "=", "False", ")", ":", "\n", "    ", "\"\"\"Apply dimensionality reduction to X.\n    X is projected on the first principal components previously extracted\n    from a training set.\n    Parameters\n    ----------\n    X: array-like, shape (n_samples, n_features)\n        New data, where n_samples is the number of samples\n        and n_features is the number of features.\n    components_: array-like, shape (n_components, n_features)\n    mean_: array-like, shape (n_features,)\n    explained_variance_: array-like, shape (n_components,)\n                        Variance explained by each of the selected components.\n    whiten : bool, optional\n        When True (False by default) the ``components_`` vectors are divided\n        by ``n_samples`` times ``components_`` to ensure uncorrelated outputs\n        with unit component-wise variances.\n        Whitening will remove some information from the transformed signal\n        (the relative variance scales of the components) but can sometimes\n        improve the predictive accuracy of the downstream estimators by\n        making data respect some hard-wired assumptions.\n    Returns\n    -------\n    X_new : array-like, shape (n_samples, n_components)\n    \"\"\"", "\n", "\n", "if", "mean_", "is", "not", "None", ":", "\n", "        ", "X", "=", "X", "-", "mean_", "\n", "", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "components_", ".", "T", ")", "\n", "if", "whiten", ":", "\n", "        ", "X_transformed", "/=", "np", ".", "sqrt", "(", "explained_variance_", ")", "\n", "", "return", "X_transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.hujiecpp_ISTR.AE.utils.inverse_transform": [[56, 90], ["numpy.dot", "numpy.dot", "numpy.sqrt"], "function", ["None"], ["", "def", "inverse_transform", "(", "X", ",", "components_", ",", "explained_variance_", ",", "mean_", "=", "None", ",", "whiten", "=", "False", ")", ":", "\n", "    ", "\"\"\"Transform data back to its original space.\n    In other words, return an input X_original whose transform would be X.\n    Parameters\n    ----------\n    X : array-like, shape (n_samples, n_components)\n        New data, where n_samples is the number of samples\n        and n_components is the number of components.\n    components_: array-like, shape (n_components, n_features)\n    mean_: array-like, shape (n_features,)\n    explained_variance_: array-like, shape (n_components,)\n                        Variance explained by each of the selected components.\n    whiten : bool, optional\n        When True (False by default) the ``components_`` vectors are divided\n        by ``n_samples`` times ``components_`` to ensure uncorrelated outputs\n        with unit component-wise variances.\n        Whitening will remove some information from the transformed signal\n        (the relative variance scales of the components) but can sometimes\n        improve the predictive accuracy of the downstream estimators by\n        making data respect some hard-wired assumptions.\n\n    Returns\n    -------\n    X_original array-like, shape (n_samples, n_features)\n    \"\"\"", "\n", "if", "whiten", ":", "\n", "        ", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "np", ".", "sqrt", "(", "explained_variance_", "[", ":", ",", "np", ".", "newaxis", "]", ")", "*", "components_", ")", "\n", "", "else", ":", "\n", "        ", "X_transformed", "=", "np", ".", "dot", "(", "X", ",", "components_", ")", "\n", "\n", "", "if", "mean_", "is", "not", "None", ":", "\n", "        ", "X_transformed", "=", "X_transformed", "+", "mean_", "\n", "\n", "", "return", "X_transformed", "\n", "\n"]]}