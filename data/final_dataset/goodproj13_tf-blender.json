{"home.repos.pwc.inspect_result.goodproj13_tf-blender.None.setup.readme": [[9, 13], ["open", "f.read"], "function", ["None"], ["def", "readme", "(", ")", ":", "\n", "    ", "with", "open", "(", "'README.md'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "read", "(", ")", "\n", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.None.setup.get_version": [[18, 22], ["open", "exec", "locals", "compile", "f.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "version_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "exec", "(", "compile", "(", "f", ".", "read", "(", ")", ",", "version_file", ",", "'exec'", ")", ")", "\n", "", "return", "locals", "(", ")", "[", "'__version__'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.None.setup.make_cuda_ext": [[24, 47], ["extension", "torch.cuda.is_available", "print", "os.getenv", "os.path.join", "module.split"], "function", ["None"], ["", "def", "make_cuda_ext", "(", "name", ",", "module", ",", "sources", ",", "sources_cuda", "=", "[", "]", ")", ":", "\n", "\n", "    ", "define_macros", "=", "[", "]", "\n", "extra_compile_args", "=", "{", "'cxx'", ":", "[", "]", "}", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "or", "os", ".", "getenv", "(", "'FORCE_CUDA'", ",", "'0'", ")", "==", "'1'", ":", "\n", "        ", "define_macros", "+=", "[", "(", "'WITH_CUDA'", ",", "None", ")", "]", "\n", "extension", "=", "CUDAExtension", "\n", "extra_compile_args", "[", "'nvcc'", "]", "=", "[", "\n", "'-D__CUDA_NO_HALF_OPERATORS__'", ",", "\n", "'-D__CUDA_NO_HALF_CONVERSIONS__'", ",", "\n", "'-D__CUDA_NO_HALF2_OPERATORS__'", ",", "\n", "]", "\n", "sources", "+=", "sources_cuda", "\n", "", "else", ":", "\n", "        ", "print", "(", "f'Compiling {name} without CUDA'", ")", "\n", "extension", "=", "CppExtension", "\n", "\n", "", "return", "extension", "(", "\n", "name", "=", "f'{module}.{name}'", ",", "\n", "sources", "=", "[", "os", ".", "path", ".", "join", "(", "*", "module", ".", "split", "(", "'.'", ")", ",", "p", ")", "for", "p", "in", "sources", "]", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.None.setup.parse_requirements": [[49, 125], ["list", "line.strip.startswith", "exists", "setup.parse_requirements.gen_packages_items"], "function", ["None"], ["", "def", "parse_requirements", "(", "fname", "=", "'requirements.txt'", ",", "with_version", "=", "True", ")", ":", "\n", "    ", "\"\"\"Parse the package dependencies listed in a requirements file but strips\n    specific versioning information.\n\n    Args:\n        fname (str): path to requirements file\n        with_version (bool, default=False): if True include version specs\n\n    Returns:\n        List[str]: list of requirements items\n\n    CommandLine:\n        python -c \"import setup; print(setup.parse_requirements())\"\n    \"\"\"", "\n", "import", "sys", "\n", "from", "os", ".", "path", "import", "exists", "\n", "import", "re", "\n", "require_fpath", "=", "fname", "\n", "\n", "def", "parse_line", "(", "line", ")", ":", "\n", "        ", "\"\"\"Parse information from a line in a requirements text file.\"\"\"", "\n", "if", "line", ".", "startswith", "(", "'-r '", ")", ":", "\n", "# Allow specifying requirements in other files", "\n", "            ", "target", "=", "line", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "for", "info", "in", "parse_require_file", "(", "target", ")", ":", "\n", "                ", "yield", "info", "\n", "", "", "else", ":", "\n", "            ", "info", "=", "{", "'line'", ":", "line", "}", "\n", "if", "line", ".", "startswith", "(", "'-e '", ")", ":", "\n", "                ", "info", "[", "'package'", "]", "=", "line", ".", "split", "(", "'#egg='", ")", "[", "1", "]", "\n", "", "elif", "'@git+'", "in", "line", ":", "\n", "                ", "info", "[", "'package'", "]", "=", "line", "\n", "", "else", ":", "\n", "# Remove versioning from the package", "\n", "                ", "pat", "=", "'('", "+", "'|'", ".", "join", "(", "[", "'>='", ",", "'=='", ",", "'>'", "]", ")", "+", "')'", "\n", "parts", "=", "re", ".", "split", "(", "pat", ",", "line", ",", "maxsplit", "=", "1", ")", "\n", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "parts", "]", "\n", "\n", "info", "[", "'package'", "]", "=", "parts", "[", "0", "]", "\n", "if", "len", "(", "parts", ")", ">", "1", ":", "\n", "                    ", "op", ",", "rest", "=", "parts", "[", "1", ":", "]", "\n", "if", "';'", "in", "rest", ":", "\n", "# Handle platform specific dependencies", "\n", "# http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies", "\n", "                        ", "version", ",", "platform_deps", "=", "map", "(", "str", ".", "strip", ",", "\n", "rest", ".", "split", "(", "';'", ")", ")", "\n", "info", "[", "'platform_deps'", "]", "=", "platform_deps", "\n", "", "else", ":", "\n", "                        ", "version", "=", "rest", "# NOQA", "\n", "", "info", "[", "'version'", "]", "=", "(", "op", ",", "version", ")", "\n", "", "", "yield", "info", "\n", "\n", "", "", "def", "parse_require_file", "(", "fpath", ")", ":", "\n", "        ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "and", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                    ", "for", "info", "in", "parse_line", "(", "line", ")", ":", "\n", "                        ", "yield", "info", "\n", "\n", "", "", "", "", "", "def", "gen_packages_items", "(", ")", ":", "\n", "        ", "if", "exists", "(", "require_fpath", ")", ":", "\n", "            ", "for", "info", "in", "parse_require_file", "(", "require_fpath", ")", ":", "\n", "                ", "parts", "=", "[", "info", "[", "'package'", "]", "]", "\n", "if", "with_version", "and", "'version'", "in", "info", ":", "\n", "                    ", "parts", ".", "extend", "(", "info", "[", "'version'", "]", ")", "\n", "", "if", "not", "sys", ".", "version", ".", "startswith", "(", "'3.4'", ")", ":", "\n", "# apparently package_deps are broken in 3.4", "\n", "                    ", "platform_deps", "=", "info", ".", "get", "(", "'platform_deps'", ")", "\n", "if", "platform_deps", "is", "not", "None", ":", "\n", "                        ", "parts", ".", "append", "(", "';'", "+", "platform_deps", ")", "\n", "", "", "item", "=", "''", ".", "join", "(", "parts", ")", "\n", "yield", "item", "\n", "\n", "", "", "", "packages", "=", "list", "(", "gen_packages_items", "(", ")", ")", "\n", "return", "packages", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.demo.demo_sot.main": [[8, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmtrack.apis.init_model", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "cv2.VideoCapture.read", "mmtrack.apis.inference_sot", "cv2.rectangle", "cv2.VideoWriter.release", "int", "int", "list", "cv2.VideoWriter.write", "cv2.imshow", "ord", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.selectROI", "cv2.waitKey"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.init_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_sot", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'Config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "help", "=", "'input video file'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'output video file (mp4 format)'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'Checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'Device used for inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'whether to show visualizations.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--color'", ",", "default", "=", "(", "0", ",", "255", ",", "0", ")", ",", "help", "=", "'Color of tracked bbox lines.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--thickness'", ",", "default", "=", "3", ",", "help", "=", "'Thickness of bbox lines.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# build the model from a config file and a checkpoint file", "\n", "model", "=", "init_model", "(", "args", ".", "config", ",", "args", ".", "checkpoint", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "input", ")", "\n", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "save_out_video", "=", "True", "\n", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "size", "=", "(", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", ",", "\n", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", ")", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", "\n", "videoWriter", "=", "cv2", ".", "VideoWriter", "(", "args", ".", "output", ",", "fourcc", ",", "fps", ",", "size", ")", "\n", "\n", "", "frame_id", "=", "0", "\n", "while", "(", "cap", ".", "isOpened", "(", ")", ")", ":", "\n", "        ", "flag", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "flag", ":", "\n", "            ", "break", "\n", "\n", "", "if", "frame_id", "==", "0", ":", "\n", "            ", "init_bbox", "=", "list", "(", "cv2", ".", "selectROI", "(", "args", ".", "input", ",", "frame", ",", "False", ",", "False", ")", ")", "\n", "# convert (x1, y1, w, h) to (x1, y1, x2, y2)", "\n", "init_bbox", "[", "2", "]", "+=", "init_bbox", "[", "0", "]", "\n", "init_bbox", "[", "3", "]", "+=", "init_bbox", "[", "1", "]", "\n", "\n", "# test a single image", "\n", "", "result", "=", "inference_sot", "(", "model", ",", "frame", ",", "init_bbox", ",", "frame_id", ")", "\n", "\n", "track_bbox", "=", "result", "[", "'bbox'", "]", "\n", "cv2", ".", "rectangle", "(", "\n", "frame", ",", "(", "track_bbox", "[", "0", "]", ",", "track_bbox", "[", "1", "]", ")", ",", "\n", "(", "track_bbox", "[", "2", "]", ",", "track_bbox", "[", "3", "]", ")", ",", "\n", "args", ".", "color", ",", "\n", "thickness", "=", "args", ".", "thickness", ")", "\n", "\n", "if", "save_out_video", ":", "\n", "            ", "videoWriter", ".", "write", "(", "frame", ")", "\n", "\n", "", "if", "args", ".", "show", ":", "\n", "            ", "cv2", ".", "imshow", "(", "args", ".", "input", ",", "frame", ")", "\n", "\n", "", "if", "cv2", ".", "waitKey", "(", "1", ")", "&", "0xFF", "==", "ord", "(", "'q'", ")", ":", "\n", "            ", "break", "\n", "\n", "", "frame_id", "+=", "1", "\n", "\n", "", "cap", ".", "release", "(", ")", "\n", "if", "save_out_video", ":", "\n", "        ", "videoWriter", ".", "release", "(", ")", "\n", "", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.demo.demo_mot.main": [[11, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.isdir", "mmtrack.apis.init_model", "mmcv.ProgressBar", "enumerate", "sorted", "mmcv.VideoReader", "parser.parse_args.output.endswith", "len", "isinstance", "mmtrack.apis.inference_mot", "mmtrack.apis.init_model.show_result", "mmcv.ProgressBar.update", "print", "mmcv.frames2video", "tempfile.TemporaryDirectory.cleanup", "os.listdir", "os.listdir", "tempfile.TemporaryDirectory", "parser.parse_args.output.rsplit", "os.makedirs", "os.makedirs", "os.join", "ValueError", "len", "os.makedirs", "os.makedirs", "os.join", "os.join", "int", "osp.join.rsplit"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.init_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_mot", "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.show_result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "help", "=", "'input video file or folder'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "help", "=", "'output video file (mp4 format) or folder'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'device used for inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether show the results on the fly'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--backend'", ",", "\n", "choices", "=", "[", "'cv2'", ",", "'plt'", "]", ",", "\n", "default", "=", "'cv2'", ",", "\n", "help", "=", "'the backend to visualize the results'", ")", "\n", "parser", ".", "add_argument", "(", "'--fps'", ",", "help", "=", "'FPS of the output video'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "assert", "args", ".", "output", "or", "args", ".", "show", "\n", "# load images", "\n", "if", "osp", ".", "isdir", "(", "args", ".", "input", ")", ":", "\n", "        ", "imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "args", ".", "input", ")", ")", "\n", "IN_VIDEO", "=", "False", "\n", "", "else", ":", "\n", "        ", "imgs", "=", "mmcv", ".", "VideoReader", "(", "args", ".", "input", ")", "\n", "IN_VIDEO", "=", "True", "\n", "# define output", "\n", "", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "output", ".", "endswith", "(", "'.mp4'", ")", ":", "\n", "            ", "OUT_VIDEO", "=", "True", "\n", "if", "(", "not", "IN_VIDEO", ")", "and", "(", "not", "args", ".", "fps", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Please set the FPS for the output video.'", ")", "\n", "", "fps", "=", "args", ".", "fps", "if", "args", ".", "fps", "else", "imgs", ".", "fps", "\n", "out_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", "\n", "out_path", "=", "out_dir", ".", "name", "\n", "_out", "=", "args", ".", "output", ".", "rsplit", "(", "'/'", ",", "1", ")", "\n", "if", "len", "(", "_out", ")", ">", "1", ":", "\n", "                ", "os", ".", "makedirs", "(", "_out", "[", "0", "]", ",", "exist_ok", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "OUT_VIDEO", "=", "False", "\n", "out_path", "=", "args", ".", "output", "\n", "os", ".", "makedirs", "(", "out_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# build the model from a config file and a checkpoint file", "\n", "", "", "model", "=", "init_model", "(", "args", ".", "config", ",", "args", ".", "checkpoint", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "imgs", ")", ")", "\n", "# test and show/save the images", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "        ", "if", "isinstance", "(", "img", ",", "str", ")", ":", "\n", "            ", "img", "=", "osp", ".", "join", "(", "args", ".", "input", ",", "img", ")", "\n", "", "result", "=", "inference_mot", "(", "model", ",", "img", ",", "frame_id", "=", "i", ")", "\n", "result", "=", "result", "[", "'track_results'", "]", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "            ", "if", "IN_VIDEO", "or", "OUT_VIDEO", ":", "\n", "                ", "out_file", "=", "osp", ".", "join", "(", "out_path", ",", "f'{i:06d}.jpg'", ")", "\n", "", "else", ":", "\n", "                ", "out_file", "=", "osp", ".", "join", "(", "out_path", ",", "img", ".", "rsplit", "(", "'/'", ",", "1", ")", "[", "-", "1", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "out_file", "=", "None", "\n", "", "model", ".", "show_result", "(", "\n", "img", ",", "\n", "result", ",", "\n", "show", "=", "args", ".", "show", ",", "\n", "out_file", "=", "out_file", ",", "\n", "backend", "=", "args", ".", "backend", ")", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "if", "OUT_VIDEO", ":", "\n", "        ", "print", "(", "f'making the output video at {args.output} with a FPS of {fps}'", ")", "\n", "mmcv", ".", "frames2video", "(", "out_path", ",", "args", ".", "output", ",", "fps", "=", "int", "(", "fps", ")", ")", "\n", "out_dir", ".", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.demo.demo_vid.main": [[8, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmtrack.apis.init_model", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "cv2.VideoCapture.read", "mmtrack.apis.inference_vid", "mmtrack.apis.init_model.show_result", "cv2.VideoWriter.release", "int", "int", "cv2.VideoWriter.write", "cv2.imshow", "ord", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.waitKey"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.init_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.show_result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'Config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "help", "=", "'input video file'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'output video file (mp4 format)'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'Checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'Device used for inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'whether to show visualizations.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--score-thr'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "help", "=", "'bbox score threshold'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# build the model from a config file and a checkpoint file", "\n", "model", "=", "init_model", "(", "args", ".", "config", ",", "args", ".", "checkpoint", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "input", ")", "\n", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "save_out_video", "=", "True", "\n", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "size", "=", "(", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", ",", "\n", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", ")", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", "\n", "videoWriter", "=", "cv2", ".", "VideoWriter", "(", "args", ".", "output", ",", "fourcc", ",", "fps", ",", "size", ")", "\n", "\n", "", "frame_id", "=", "0", "\n", "while", "(", "cap", ".", "isOpened", "(", ")", ")", ":", "\n", "        ", "flag", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "flag", ":", "\n", "            ", "break", "\n", "\n", "# test a single image", "\n", "", "result", "=", "inference_vid", "(", "model", ",", "frame", ",", "frame_id", ")", "\n", "vis_frame", "=", "model", ".", "show_result", "(", "\n", "frame", ",", "result", ",", "score_thr", "=", "args", ".", "score_thr", ",", "show", "=", "False", ")", "\n", "\n", "if", "save_out_video", ":", "\n", "            ", "videoWriter", ".", "write", "(", "vis_frame", ")", "\n", "\n", "", "if", "args", ".", "show", ":", "\n", "            ", "cv2", ".", "imshow", "(", "args", ".", "input", ",", "vis_frame", ")", "\n", "\n", "", "if", "cv2", ".", "waitKey", "(", "1", ")", "&", "0xFF", "==", "ord", "(", "'q'", ")", ":", "\n", "            ", "break", "\n", "\n", "", "frame_id", "+=", "1", "\n", "\n", "", "cap", ".", "release", "(", ")", "\n", "if", "save_out_video", ":", "\n", "        ", "videoWriter", ".", "release", "(", ")", "\n", "", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.demo.demo_vid_img.main": [[8, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmtrack.apis.init_model", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "cv2.VideoCapture.read", "mmtrack.apis.inference_vid", "mmtrack.apis.init_model.show_result", "cv2.VideoWriter.release", "int", "int", "cv2.VideoWriter.write", "cv2.imshow", "ord", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.waitKey"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.init_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.show_result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'Config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "help", "=", "'input video file'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'output video file (mp4 format)'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'Checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'Device used for inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'whether to show visualizations.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--score-thr'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "help", "=", "'bbox score threshold'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# build the model from a config file and a checkpoint file", "\n", "model", "=", "init_model", "(", "args", ".", "config", ",", "args", ".", "checkpoint", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "input", ")", "\n", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "save_out_video", "=", "True", "\n", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "size", "=", "(", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", ",", "\n", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", ")", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", "\n", "videoWriter", "=", "cv2", ".", "VideoWriter", "(", "args", ".", "output", ",", "fourcc", ",", "fps", ",", "size", ")", "\n", "\n", "", "frame_id", "=", "0", "\n", "while", "(", "cap", ".", "isOpened", "(", ")", ")", ":", "\n", "        ", "flag", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "flag", ":", "\n", "            ", "break", "\n", "\n", "# test a single image", "\n", "", "result", "=", "inference_vid", "(", "model", ",", "frame", ",", "frame_id", ")", "\n", "vis_frame", "=", "model", ".", "show_result", "(", "\n", "frame", ",", "result", ",", "score_thr", "=", "args", ".", "score_thr", ",", "show", "=", "False", ")", "\n", "\n", "if", "save_out_video", ":", "\n", "            ", "videoWriter", ".", "write", "(", "vis_frame", ")", "\n", "\n", "", "if", "args", ".", "show", ":", "\n", "            ", "cv2", ".", "imshow", "(", "args", ".", "input", ",", "vis_frame", ")", "\n", "\n", "", "if", "cv2", ".", "waitKey", "(", "1", ")", "&", "0xFF", "==", "ord", "(", "'q'", ")", ":", "\n", "            ", "break", "\n", "\n", "", "frame_id", "+=", "1", "\n", "\n", "", "cap", ".", "release", "(", ")", "\n", "if", "save_out_video", ":", "\n", "        ", "videoWriter", ".", "release", "(", ")", "\n", "", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.publish_model.parse_args": [[7, 14], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Process a checkpoint to be published'", ")", "\n", "parser", ".", "add_argument", "(", "'in_file'", ",", "help", "=", "'input checkpoint filename'", ")", "\n", "parser", ".", "add_argument", "(", "'out_file'", ",", "help", "=", "'output checkpoint filename'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.publish_model.process_checkpoint": [[16, 31], ["torch.load", "torch.save", "subprocess.check_output().decode", "out_file.endswith", "subprocess.Popen", "subprocess.check_output"], "function", ["None"], ["", "def", "process_checkpoint", "(", "in_file", ",", "out_file", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "in_file", ",", "map_location", "=", "'cpu'", ")", "\n", "# remove optimizer for smaller file size", "\n", "if", "'optimizer'", "in", "checkpoint", ":", "\n", "        ", "del", "checkpoint", "[", "'optimizer'", "]", "\n", "# if it is necessary to remove some sensitive data in checkpoint['meta'],", "\n", "# add the code here.", "\n", "", "torch", ".", "save", "(", "checkpoint", ",", "out_file", ")", "\n", "sha", "=", "subprocess", ".", "check_output", "(", "[", "'sha256sum'", ",", "out_file", "]", ")", ".", "decode", "(", ")", "\n", "if", "out_file", ".", "endswith", "(", "'.pth'", ")", ":", "\n", "        ", "out_file_name", "=", "out_file", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "        ", "out_file_name", "=", "out_file", "\n", "", "final_file", "=", "out_file_name", "+", "f'-{sha[:8]}.pth'", "\n", "subprocess", ".", "Popen", "(", "[", "'mv'", ",", "out_file", ",", "final_file", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.publish_model.main": [[33, 36], ["publish_model.parse_args", "publish_model.process_checkpoint"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.publish_model.process_checkpoint"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "process_checkpoint", "(", "args", ".", "in_file", ",", "args", ".", "out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.print_config.parse_args": [[6, 14], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Print the whole config'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--options'", ",", "nargs", "=", "'+'", ",", "action", "=", "DictAction", ",", "help", "=", "'arguments in dict'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.print_config.main": [[16, 23], ["print_config.parse_args", "mmcv.Config.fromfile", "print", "Config.fromfile.merge_from_dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "args", ".", "options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "options", ")", "\n", "", "print", "(", "f'Config:\\n{cfg.pretty_text}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_param_search.parse_args": [[18, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'mmtrack test model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "help", "=", "'output result file'", ")", "\n", "parser", ".", "add_argument", "(", "'--log'", ",", "help", "=", "'log file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format-only'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Format the output results without perform evaluation. It is'", "\n", "'useful when you want to format the result to a specific format and '", "\n", "'submit it to the test server'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'eval types'", ")", "\n", "parser", ".", "add_argument", "(", "'--show'", ",", "action", "=", "'store_true'", ",", "help", "=", "'show results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-dir'", ",", "help", "=", "'directory where painted images will be saved'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_param_search.get_search_params": [[71, 86], ["cfg.items", "dict", "isinstance", "isinstance", "mmcv.print_log", "mot_param_search.get_search_params"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_param_search.get_search_params"], ["", "def", "get_search_params", "(", "cfg", ",", "search_params", "=", "None", ",", "prefix", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "    ", "if", "search_params", "is", "None", ":", "\n", "        ", "search_params", "=", "dict", "(", ")", "\n", "", "for", "k", ",", "v", "in", "cfg", ".", "items", "(", ")", ":", "\n", "        ", "if", "prefix", "is", "not", "None", ":", "\n", "            ", "entire_k", "=", "prefix", "+", "'.'", "+", "k", "\n", "", "else", ":", "\n", "            ", "entire_k", "=", "k", "\n", "", "if", "isinstance", "(", "v", ",", "list", ")", ":", "\n", "            ", "print_log", "(", "f'search `{entire_k}` in {v}.'", ",", "logger", ")", "\n", "search_params", "[", "entire_k", "]", "=", "v", "\n", "", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "search_params", "=", "get_search_params", "(", "v", ",", "search_params", ",", "entire_k", ",", "\n", "logger", ")", "\n", "", "", "return", "search_params", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_param_search.main": [[88, 214], ["mot_param_search.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "Config.fromfile.get", "hasattr", "mmdet.datasets.build_dataset", "build_dataloader", "mmcv.get_logger", "mot_param_search.get_search_params", "mmcv.print_log", "search_cfgs[].copy", "Config.fromfile.get", "Config.fromfile.get", "mmcv.print_log", "enumerate", "ValueError", "ValueError", "Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "dotty_dict.dotty", "enumerate", "search_cfgs.append", "build_model", "build_model", "mmdet.core.wrap_fp16_model", "mmcv.runner.load_checkpoint", "hasattr", "mmcv.cnn.fuse_conv_bn", "mmcv.parallel.MMDataParallel", "mmcv.parallel.MMDistributedDataParallel", "mmcv.runner.get_dist_info", "parse_args.out.endswith", "itertools.product", "Config.fromfile.model.tracker.copy", "get_search_params.keys", "dict", "mmcv.parallel.MMDistributedDataParallel.cuda", "mmtrack.models.build_tracker", "single_gpu_test", "mmtrack.models.build_tracker", "multi_gpu_test", "len", "print", "mmcv.dump", "mmdet.datasets.build_dataset.format_results", "Config.fromfile.get().copy", "cfg.get().copy.update", "mmdet.datasets.build_dataset.evaluate", "mmcv.print_log", "get_search_params.values", "torch.cuda.current_device", "cfg.get().copy.pop", "dict", "isinstance", "Config.fromfile.get", "_records.append", "_records.append"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_param_search.get_search_params", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_tracker", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.single_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_tracker", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.multi_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "assert", "args", ".", "out", "or", "args", ".", "eval", "or", "args", ".", "format_only", "or", "args", ".", "show", "or", "args", ".", "show_dir", ",", "(", "'Please specify at least one operation (save/eval/format/show the '", "\n", "'results / save the results) with the argument \"--out\", \"--eval\"'", "\n", "', \"--format-only\", \"--show\" or \"--show-dir\"'", ")", "\n", "\n", "if", "args", ".", "eval", "and", "args", ".", "format_only", ":", "\n", "        ", "raise", "ValueError", "(", "'--eval and --format_only cannot be both specified'", ")", "\n", "\n", "", "if", "args", ".", "out", "is", "not", "None", "and", "not", "args", ".", "out", ".", "endswith", "(", "(", "'.pkl'", ",", "'.pickle'", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The output file must be a pkl file.'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmdet", ".", "models", "import", "build_detector", "as", "build_model", "\n", "from", "mmdet", ".", "datasets", "import", "build_dataloader", "\n", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "from", "mmtrack", ".", "datasets", "import", "build_dataloader", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "# cfg.model.pretrains = None", "\n", "", "if", "hasattr", "(", "cfg", ".", "model", ",", "'detector'", ")", ":", "\n", "        ", "cfg", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# build the dataloader", "\n", "", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "logger", "=", "get_logger", "(", "'ParamsSearcher'", ",", "log_file", "=", "args", ".", "log", ")", "\n", "# get all cases", "\n", "search_params", "=", "get_search_params", "(", "cfg", ".", "model", ".", "tracker", ",", "logger", "=", "logger", ")", "\n", "combinations", "=", "[", "p", "for", "p", "in", "product", "(", "*", "search_params", ".", "values", "(", ")", ")", "]", "\n", "search_cfgs", "=", "[", "]", "\n", "for", "c", "in", "combinations", ":", "\n", "        ", "search_cfg", "=", "dotty", "(", "cfg", ".", "model", ".", "tracker", ".", "copy", "(", ")", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "search_params", ".", "keys", "(", ")", ")", ":", "\n", "            ", "search_cfg", "[", "k", "]", "=", "c", "[", "i", "]", "\n", "", "search_cfgs", ".", "append", "(", "dict", "(", "search_cfg", ")", ")", "\n", "", "print_log", "(", "f'Totally {len(search_cfgs)} cases.'", ",", "logger", ")", "\n", "# init with the first one", "\n", "cfg", ".", "model", ".", "tracker", "=", "search_cfgs", "[", "0", "]", ".", "copy", "(", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "if", "cfg", ".", "get", "(", "'test_cfg'", ",", "False", ")", ":", "\n", "        ", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "cfg", ".", "train_cfg", ",", "test_cfg", "=", "cfg", ".", "test_cfg", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "load_checkpoint", "(", "\n", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "            ", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "if", "not", "hasattr", "(", "model", ",", "'CLASSES'", ")", ":", "\n", "        ", "model", ".", "CLASSES", "=", "dataset", ".", "CLASSES", "\n", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "if", "not", "distributed", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ")", "\n", "\n", "", "print_log", "(", "f'Record {cfg.search_metrics}.'", ",", "logger", ")", "\n", "for", "i", ",", "search_cfg", "in", "enumerate", "(", "search_cfgs", ")", ":", "\n", "        ", "if", "not", "distributed", ":", "\n", "            ", "model", ".", "tracker", "=", "build_tracker", "(", "search_cfg", ")", "\n", "outputs", "=", "single_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "show", ",", "\n", "args", ".", "show_dir", ",", "args", ".", "show_score_thr", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "module", ".", "tracker", "=", "build_tracker", "(", "search_cfg", ")", "\n", "outputs", "=", "multi_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "tmpdir", ",", "\n", "args", ".", "gpu_collect", ")", "\n", "", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "if", "args", ".", "out", ":", "\n", "                ", "print", "(", "f'\\nwriting results to {args.out}'", ")", "\n", "mmcv", ".", "dump", "(", "outputs", ",", "args", ".", "out", ")", "\n", "", "kwargs", "=", "{", "}", "if", "args", ".", "eval_options", "is", "None", "else", "args", ".", "eval_options", "\n", "if", "args", ".", "format_only", ":", "\n", "                ", "dataset", ".", "format_results", "(", "outputs", ",", "**", "kwargs", ")", "\n", "", "if", "args", ".", "eval", ":", "\n", "                ", "eval_kwargs", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", ".", "copy", "(", ")", "\n", "# hard-code way to remove EvalHook args", "\n", "for", "key", "in", "[", "'interval'", ",", "'tmpdir'", ",", "'start'", ",", "'gpu_collect'", "]", ":", "\n", "                    ", "eval_kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "", "eval_kwargs", ".", "update", "(", "dict", "(", "metric", "=", "args", ".", "eval", ",", "**", "kwargs", ")", ")", "\n", "results", "=", "dataset", ".", "evaluate", "(", "outputs", ",", "**", "eval_kwargs", ")", "\n", "_records", "=", "[", "]", "\n", "for", "k", "in", "cfg", ".", "search_metrics", ":", "\n", "                    ", "if", "isinstance", "(", "results", "[", "k", "]", ",", "float", ")", ":", "\n", "                        ", "_records", ".", "append", "(", "f'{(results[k]):.3f}'", ")", "\n", "", "else", ":", "\n", "                        ", "_records", ".", "append", "(", "f'{(results[k])}'", ")", "\n", "", "", "print_log", "(", "f'{combinations[i]}: {_records}'", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.cal_train_time": [[10, 31], ["enumerate", "print", "log_dict.keys", "numpy.array", "np.array.mean", "all_times.mean.argmax", "all_times.mean.argmin", "all_times.mean.std", "print", "print", "print", "print", "print", "np.array.append", "np.array.append", "numpy.mean"], "function", ["None"], ["def", "cal_train_time", "(", "log_dicts", ",", "args", ")", ":", "\n", "    ", "for", "i", ",", "log_dict", "in", "enumerate", "(", "log_dicts", ")", ":", "\n", "        ", "print", "(", "f'{\"-\" * 5}Analyze train time of {args.json_logs[i]}{\"-\" * 5}'", ")", "\n", "all_times", "=", "[", "]", "\n", "for", "epoch", "in", "log_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "args", ".", "include_outliers", ":", "\n", "                ", "all_times", ".", "append", "(", "log_dict", "[", "epoch", "]", "[", "'time'", "]", ")", "\n", "", "else", ":", "\n", "                ", "all_times", ".", "append", "(", "log_dict", "[", "epoch", "]", "[", "'time'", "]", "[", "1", ":", "]", ")", "\n", "", "", "all_times", "=", "np", ".", "array", "(", "all_times", ")", "\n", "epoch_ave_time", "=", "all_times", ".", "mean", "(", "-", "1", ")", "\n", "slowest_epoch", "=", "epoch_ave_time", ".", "argmax", "(", ")", "\n", "fastest_epoch", "=", "epoch_ave_time", ".", "argmin", "(", ")", "\n", "std_over_epoch", "=", "epoch_ave_time", ".", "std", "(", ")", "\n", "print", "(", "f'slowest epoch {slowest_epoch + 1}, '", "\n", "f'average time is {epoch_ave_time[slowest_epoch]:.4f}'", ")", "\n", "print", "(", "f'fastest epoch {fastest_epoch + 1}, '", "\n", "f'average time is {epoch_ave_time[fastest_epoch]:.4f}'", ")", "\n", "print", "(", "f'time std over epochs is {std_over_epoch:.4f}'", ")", "\n", "print", "(", "f'average iter time: {np.mean(all_times):.4f} s/iter'", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.plot_curve": [[33, 90], ["seaborn.set_style", "len", "enumerate", "matplotlib.switch_backend", "len", "list", "enumerate", "matplotlib.show", "print", "matplotlib.savefig", "matplotlib.cla", "len", "len", "log_dict.keys", "print", "matplotlib.legend", "matplotlib.title", "legend.append", "KeyError", "numpy.arange", "matplotlib.gca", "plt.gca.set_xticks", "matplotlib.xlabel", "matplotlib.plot", "numpy.concatenate", "numpy.concatenate", "matplotlib.xlabel", "matplotlib.plot", "np.concatenate.append", "np.concatenate.append", "max", "numpy.array", "numpy.array", "len"], "function", ["None"], ["", "", "def", "plot_curve", "(", "log_dicts", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "backend", "is", "not", "None", ":", "\n", "        ", "plt", ".", "switch_backend", "(", "args", ".", "backend", ")", "\n", "", "sns", ".", "set_style", "(", "args", ".", "style", ")", "\n", "# if legend is None, use {filename}_{key} as legend", "\n", "legend", "=", "args", ".", "legend", "\n", "if", "legend", "is", "None", ":", "\n", "        ", "legend", "=", "[", "]", "\n", "for", "json_log", "in", "args", ".", "json_logs", ":", "\n", "            ", "for", "metric", "in", "args", ".", "keys", ":", "\n", "                ", "legend", ".", "append", "(", "f'{json_log}_{metric}'", ")", "\n", "", "", "", "assert", "len", "(", "legend", ")", "==", "(", "len", "(", "args", ".", "json_logs", ")", "*", "len", "(", "args", ".", "keys", ")", ")", "\n", "metrics", "=", "args", ".", "keys", "\n", "\n", "num_metrics", "=", "len", "(", "metrics", ")", "\n", "for", "i", ",", "log_dict", "in", "enumerate", "(", "log_dicts", ")", ":", "\n", "        ", "epochs", "=", "list", "(", "log_dict", ".", "keys", "(", ")", ")", "\n", "for", "j", ",", "metric", "in", "enumerate", "(", "metrics", ")", ":", "\n", "            ", "print", "(", "f'plot curve of {args.json_logs[i]}, metric is {metric}'", ")", "\n", "if", "metric", "not", "in", "log_dict", "[", "epochs", "[", "0", "]", "]", ":", "\n", "                ", "raise", "KeyError", "(", "\n", "f'{args.json_logs[i]} does not contain metric {metric}'", ")", "\n", "\n", "", "if", "'mAP'", "in", "metric", ":", "\n", "                ", "xs", "=", "np", ".", "arange", "(", "1", ",", "max", "(", "epochs", ")", "+", "1", ")", "\n", "ys", "=", "[", "]", "\n", "for", "epoch", "in", "epochs", ":", "\n", "                    ", "ys", "+=", "log_dict", "[", "epoch", "]", "[", "metric", "]", "\n", "", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "set_xticks", "(", "xs", ")", "\n", "plt", ".", "xlabel", "(", "'epoch'", ")", "\n", "plt", ".", "plot", "(", "xs", ",", "ys", ",", "label", "=", "legend", "[", "i", "*", "num_metrics", "+", "j", "]", ",", "marker", "=", "'o'", ")", "\n", "", "else", ":", "\n", "                ", "xs", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "num_iters_per_epoch", "=", "log_dict", "[", "epochs", "[", "0", "]", "]", "[", "'iter'", "]", "[", "-", "1", "]", "\n", "for", "epoch", "in", "epochs", ":", "\n", "                    ", "iters", "=", "log_dict", "[", "epoch", "]", "[", "'iter'", "]", "\n", "if", "log_dict", "[", "epoch", "]", "[", "'mode'", "]", "[", "-", "1", "]", "==", "'val'", ":", "\n", "                        ", "iters", "=", "iters", "[", ":", "-", "1", "]", "\n", "", "xs", ".", "append", "(", "\n", "np", ".", "array", "(", "iters", ")", "+", "(", "epoch", "-", "1", ")", "*", "num_iters_per_epoch", ")", "\n", "ys", ".", "append", "(", "np", ".", "array", "(", "log_dict", "[", "epoch", "]", "[", "metric", "]", "[", ":", "len", "(", "iters", ")", "]", ")", ")", "\n", "", "xs", "=", "np", ".", "concatenate", "(", "xs", ")", "\n", "ys", "=", "np", ".", "concatenate", "(", "ys", ")", "\n", "plt", ".", "xlabel", "(", "'iter'", ")", "\n", "plt", ".", "plot", "(", "\n", "xs", ",", "ys", ",", "label", "=", "legend", "[", "i", "*", "num_metrics", "+", "j", "]", ",", "linewidth", "=", "0.5", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "", "if", "args", ".", "title", "is", "not", "None", ":", "\n", "            ", "plt", ".", "title", "(", "args", ".", "title", ")", "\n", "", "", "if", "args", ".", "out", "is", "None", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f'save curve to: {args.out}'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "out", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.add_plot_parser": [[92, 118], ["subparsers.add_parser", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument"], "function", ["None"], ["", "", "def", "add_plot_parser", "(", "subparsers", ")", ":", "\n", "    ", "parser_plt", "=", "subparsers", ".", "add_parser", "(", "\n", "'plot_curve'", ",", "help", "=", "'parser for plotting curves'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'json_logs'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'path of train log in json format'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--keys'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "'bbox_mAP'", "]", ",", "\n", "help", "=", "'the metric that you want to plot'", ")", "\n", "parser_plt", ".", "add_argument", "(", "'--title'", ",", "type", "=", "str", ",", "help", "=", "'title of figure'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--legend'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'legend of each plot'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--backend'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'backend of plt'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--style'", ",", "type", "=", "str", ",", "default", "=", "'dark'", ",", "help", "=", "'style of plt'", ")", "\n", "parser_plt", ".", "add_argument", "(", "'--out'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.add_time_parser": [[120, 133], ["subparsers.add_parser", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument"], "function", ["None"], ["", "def", "add_time_parser", "(", "subparsers", ")", ":", "\n", "    ", "parser_time", "=", "subparsers", ".", "add_parser", "(", "\n", "'cal_train_time'", ",", "\n", "help", "=", "'parser for computing the average time per training iteration'", ")", "\n", "parser_time", ".", "add_argument", "(", "\n", "'json_logs'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'path of train log in json format'", ")", "\n", "parser_time", ".", "add_argument", "(", "\n", "'--include-outliers'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'include the first value of every epoch when computing '", "\n", "'the average time'", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.parse_args": [[136, 144], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "analyze_logs.add_plot_parser", "analyze_logs.add_time_parser", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.add_plot_parser", "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.add_time_parser", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Analyze Json Log'", ")", "\n", "# currently only support plot curve and calculate average train time", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", "dest", "=", "'task'", ",", "help", "=", "'task parser'", ")", "\n", "add_plot_parser", "(", "subparsers", ")", "\n", "add_time_parser", "(", "subparsers", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.load_json_logs": [[146, 164], ["zip", "dict", "open", "json.loads", "json.loads.pop", "json.loads.items", "line.strip", "collections.defaultdict", "[].append"], "function", ["None"], ["", "def", "load_json_logs", "(", "json_logs", ")", ":", "\n", "# load and convert json_logs to log_dict, key is epoch, value is a sub dict", "\n", "# keys of sub dict is different metrics, e.g. memory, bbox_mAP", "\n", "# value of sub dict is a list of corresponding values of all iterations", "\n", "    ", "log_dicts", "=", "[", "dict", "(", ")", "for", "_", "in", "json_logs", "]", "\n", "for", "json_log", ",", "log_dict", "in", "zip", "(", "json_logs", ",", "log_dicts", ")", ":", "\n", "        ", "with", "open", "(", "json_log", ",", "'r'", ")", "as", "log_file", ":", "\n", "            ", "for", "line", "in", "log_file", ":", "\n", "                ", "log", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "# skip lines without `epoch` field", "\n", "if", "'epoch'", "not", "in", "log", ":", "\n", "                    ", "continue", "\n", "", "epoch", "=", "log", ".", "pop", "(", "'epoch'", ")", "\n", "if", "epoch", "not", "in", "log_dict", ":", "\n", "                    ", "log_dict", "[", "epoch", "]", "=", "defaultdict", "(", "list", ")", "\n", "", "for", "k", ",", "v", "in", "log", ".", "items", "(", ")", ":", "\n", "                    ", "log_dict", "[", "epoch", "]", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "", "return", "log_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.main": [[166, 176], ["analyze_logs.parse_args", "analyze_logs.load_json_logs", "json_log.endswith", "eval"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.analyze_logs.load_json_logs"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "json_logs", "=", "args", ".", "json_logs", "\n", "for", "json_log", "in", "json_logs", ":", "\n", "        ", "assert", "json_log", ".", "endswith", "(", "'.json'", ")", "\n", "\n", "", "log_dicts", "=", "load_json_logs", "(", "json_logs", ")", "\n", "\n", "eval", "(", "args", ".", "task", ")", "(", "log_dicts", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.test2.parse_args": [[14, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'mmtrack test model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "help", "=", "'output result file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format-only'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Format the output results without perform evaluation. It is'", "\n", "'useful when you want to format the result to a specific format and '", "\n", "'submit it to the test server'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'eval types'", ")", "\n", "parser", ".", "add_argument", "(", "'--show'", ",", "action", "=", "'store_true'", ",", "help", "=", "'show results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "help", "=", "'score threshold (default: 0.3)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-dir'", ",", "help", "=", "'directory where painted images will be saved'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.test2.main": [[71, 171], ["test2.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "Config.fromfile.get", "hasattr", "mmdet.datasets.build_dataset", "Config.fromfile.get", "Config.fromfile.get", "mmcv.runner.get_dist_info", "ValueError", "ValueError", "Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "build_model", "build_model", "mmdet.core.wrap_fp16_model", "mmcv.runner.load_checkpoint", "hasattr", "mmcv.cnn.fuse_conv_bn", "print", "parse_args.out.endswith", "open", "pickle.load", "mmdet.datasets.build_dataset.format_results", "Config.fromfile.get().copy", "cfg.get().copy.update", "print", "cfg.get().copy.pop", "dict", "mmdet.datasets.build_dataset.evaluate", "Config.fromfile.get"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "assert", "args", ".", "out", "or", "args", ".", "eval", "or", "args", ".", "format_only", "or", "args", ".", "show", "or", "args", ".", "show_dir", ",", "(", "'Please specify at least one operation (save/eval/format/show the '", "\n", "'results / save the results) with the argument \"--out\", \"--eval\"'", "\n", "', \"--format-only\", \"--show\" or \"--show-dir\"'", ")", "\n", "\n", "if", "args", ".", "eval", "and", "args", ".", "format_only", ":", "\n", "        ", "raise", "ValueError", "(", "'--eval and --format_only cannot be both specified'", ")", "\n", "\n", "", "if", "args", ".", "out", "is", "not", "None", "and", "not", "args", ".", "out", ".", "endswith", "(", "(", "'.pkl'", ",", "'.pickle'", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The output file must be a pkl file.'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmdet", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmdet", ".", "models", "import", "build_detector", "as", "build_model", "\n", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmtrack", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "# cfg.model.pretrains = None", "\n", "", "if", "hasattr", "(", "cfg", ".", "model", ",", "'detector'", ")", ":", "\n", "        ", "cfg", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# build the dataloader", "\n", "", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "# data_loader = build_dataloader(", "\n", "#     dataset,", "\n", "#     samples_per_gpu=1,", "\n", "#     workers_per_gpu=cfg.data.workers_per_gpu,", "\n", "#     dist=distributed,", "\n", "#     shuffle=False)", "\n", "\n", "# build the model and load checkpoint", "\n", "if", "cfg", ".", "get", "(", "'test_cfg'", ",", "False", ")", ":", "\n", "        ", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "cfg", ".", "train_cfg", ",", "test_cfg", "=", "cfg", ".", "test_cfg", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "load_checkpoint", "(", "\n", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "            ", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "if", "not", "hasattr", "(", "model", ",", "'CLASSES'", ")", ":", "\n", "        ", "model", ".", "CLASSES", "=", "dataset", ".", "CLASSES", "\n", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "# if not distributed:", "\n", "#     model = MMDataParallel(model, device_ids=[0])", "\n", "#     outputs = single_gpu_test(model, data_loader, args.show, args.show_dir,", "\n", "#                               args.show_score_thr)", "\n", "# else:", "\n", "#     model = MMDistributedDataParallel(", "\n", "#         model.cuda(),", "\n", "#         device_ids=[torch.cuda.current_device()],", "\n", "#         broadcast_buffers=False)", "\n", "#     outputs = multi_gpu_test(model, data_loader, args.tmpdir,", "\n", "#                              args.gpu_collect)", "\n", "\n", "", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "# if args.out:", "\n", "#     print(f'\\nwriting results to {args.out}')", "\n", "#     mmcv.dump(outputs, args.out)", "\n", "        ", "with", "open", "(", "'results.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "outputs", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "print", "(", "\"Results loaded!!! \\n\"", ")", "\n", "kwargs", "=", "{", "}", "if", "args", ".", "eval_options", "is", "None", "else", "args", ".", "eval_options", "\n", "if", "args", ".", "format_only", ":", "\n", "            ", "dataset", ".", "format_results", "(", "outputs", ",", "**", "kwargs", ")", "\n", "", "if", "args", ".", "eval", ":", "\n", "            ", "eval_kwargs", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", ".", "copy", "(", ")", "\n", "# hard-code way to remove EvalHook args", "\n", "for", "key", "in", "[", "'interval'", ",", "'tmpdir'", ",", "'start'", ",", "'gpu_collect'", "]", ":", "\n", "                ", "eval_kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "", "eval_kwargs", ".", "update", "(", "dict", "(", "metric", "=", "args", ".", "eval", ",", "**", "kwargs", ")", ")", "\n", "print", "(", "dataset", ".", "evaluate", "(", "outputs", ",", "**", "eval_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.train.parse_args": [[18, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_mutually_exclusive_group", "parser.add_mutually_exclusive_group.add_argument", "parser.add_mutually_exclusive_group.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--work-dir'", ",", "help", "=", "'the dir to save logs and models'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume-from'", ",", "help", "=", "'the checkpoint file to resume from'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no-validate'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether not to evaluate the checkpoint during training'", ")", "\n", "group_gpus", "=", "parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpus'", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'number of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpu-ids'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'ids of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--deterministic'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to set deterministic options for CUDNN backend.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.train.main": [[64, 165], ["train.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "Config.fromfile.get", "mmcv.mkdir_or_exist", "Config.fromfile.dump", "time.strftime", "os.join", "mmtrack.utils.get_root_logger", "dict", "mmtrack.utils.collect_env", "mmtrack.utils.get_root_logger.info", "mmtrack.utils.get_root_logger.info", "mmtrack.utils.get_root_logger.info", "Config.fromfile.get", "train_model", "Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "os.abspath", "os.join", "time.localtime", "mmtrack.utils.get_root_logger.info", "mmdet.apis.set_random_seed", "build_model", "build_model", "mmdet.datasets.build_dataset", "len", "copy.deepcopy", "datasets.append", "dict", "Config.fromfile.get", "os.join", "range", "range", "os.basename", "mmdet.datasets.build_dataset", "mmtrack.utils.collect_env.items", "os.splitext", "os.basename"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.collect_env.collect_env", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.train.train_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "train_detector", "as", "train_model", "\n", "from", "mmtrack", ".", "models", "import", "build_detector", "as", "build_model", "\n", "if", "'detector'", "in", "cfg", ".", "model", ":", "\n", "            ", "cfg", ".", "model", "=", "cfg", ".", "model", ".", "detector", "\n", "", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "train_model", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# work_dir is determined in this priority: CLI > segment in file > filename", "\n", "", "if", "args", ".", "work_dir", "is", "not", "None", ":", "\n", "# update configs according to CLI args if args.work_dir is not None", "\n", "        ", "cfg", ".", "work_dir", "=", "args", ".", "work_dir", "\n", "", "elif", "cfg", ".", "get", "(", "'work_dir'", ",", "None", ")", "is", "None", ":", "\n", "# use config filename as default work_dir if cfg.work_dir is None", "\n", "        ", "cfg", ".", "work_dir", "=", "osp", ".", "join", "(", "'./work_dirs'", ",", "\n", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", "[", "0", "]", ")", "\n", "", "if", "args", ".", "resume_from", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "resume_from", "=", "args", ".", "resume_from", "\n", "", "if", "args", ".", "gpu_ids", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "args", ".", "gpu_ids", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "range", "(", "1", ")", "if", "args", ".", "gpus", "is", "None", "else", "range", "(", "args", ".", "gpus", ")", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# create work_dir", "\n", "", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "abspath", "(", "cfg", ".", "work_dir", ")", ")", "\n", "# dump config", "\n", "cfg", ".", "dump", "(", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", ")", "\n", "# init the logger before other steps", "\n", "timestamp", "=", "time", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "log_file", "=", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "f'{timestamp}.log'", ")", "\n", "logger", "=", "get_root_logger", "(", "log_file", "=", "log_file", ",", "log_level", "=", "cfg", ".", "log_level", ")", "\n", "\n", "# init the meta dict to record some important information such as", "\n", "# environment info and seed, which will be logged", "\n", "meta", "=", "dict", "(", ")", "\n", "# log env info", "\n", "env_info_dict", "=", "collect_env", "(", ")", "\n", "env_info", "=", "'\\n'", ".", "join", "(", "[", "(", "f'{k}: {v}'", ")", "for", "k", ",", "v", "in", "env_info_dict", ".", "items", "(", ")", "]", ")", "\n", "dash_line", "=", "'-'", "*", "60", "+", "'\\n'", "\n", "logger", ".", "info", "(", "'Environment info:\\n'", "+", "dash_line", "+", "env_info", "+", "'\\n'", "+", "\n", "dash_line", ")", "\n", "meta", "[", "'env_info'", "]", "=", "env_info", "\n", "\n", "# log some basic info", "\n", "logger", ".", "info", "(", "f'Distributed training: {distributed}'", ")", "\n", "logger", ".", "info", "(", "f'Config:\\n{cfg.pretty_text}'", ")", "\n", "\n", "# set random seeds", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "f'Set random seed to {args.seed}, '", "\n", "f'deterministic: {args.deterministic}'", ")", "\n", "set_random_seed", "(", "args", ".", "seed", ",", "deterministic", "=", "args", ".", "deterministic", ")", "\n", "", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "meta", "[", "'seed'", "]", "=", "args", ".", "seed", "\n", "\n", "if", "cfg", ".", "get", "(", "'train_cfg'", ",", "False", ")", ":", "\n", "        ", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "cfg", ".", "train_cfg", ",", "test_cfg", "=", "cfg", ".", "test_cfg", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "\n", "", "datasets", "=", "[", "build_dataset", "(", "cfg", ".", "data", ".", "train", ")", "]", "\n", "if", "len", "(", "cfg", ".", "workflow", ")", "==", "2", ":", "\n", "        ", "val_dataset", "=", "copy", ".", "deepcopy", "(", "cfg", ".", "data", ".", "val", ")", "\n", "val_dataset", ".", "pipeline", "=", "cfg", ".", "data", ".", "train", ".", "pipeline", "\n", "datasets", ".", "append", "(", "build_dataset", "(", "val_dataset", ")", ")", "\n", "", "if", "cfg", ".", "checkpoint_config", "is", "not", "None", ":", "\n", "# save mmtrack version, config file content and class names in", "\n", "# checkpoints as meta data", "\n", "        ", "cfg", ".", "checkpoint_config", ".", "meta", "=", "dict", "(", "\n", "mmtrack_version", "=", "__version__", ",", "\n", "config", "=", "cfg", ".", "pretty_text", ",", "\n", "CLASSES", "=", "datasets", "[", "0", "]", ".", "CLASSES", ")", "\n", "# add an attribute for visualization convenience", "\n", "", "model", ".", "CLASSES", "=", "datasets", "[", "0", "]", ".", "CLASSES", "\n", "train_model", "(", "\n", "model", ",", "\n", "datasets", ",", "\n", "cfg", ",", "\n", "distributed", "=", "distributed", ",", "\n", "validate", "=", "(", "not", "args", ".", "no_validate", ")", ",", "\n", "timestamp", "=", "timestamp", ",", "\n", "meta", "=", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.benchmark.parse_args": [[15, 28], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMTrack benchmark a model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log-interval'", ",", "default", "=", "50", ",", "help", "=", "'interval of logging'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.benchmark.main": [[30, 99], ["benchmark.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "Config.fromfile.get", "hasattr", "Config.fromfile.data.test.pop", "mmtrack.datasets.build_dataset", "mmtrack.datasets.build_dataloader", "mmtrack.models.build_model", "Config.fromfile.get", "mmcv.parallel.MMDataParallel", "mmcv.cnn.fuse_conv_bn.eval", "enumerate", "import_modules_from_strings", "mmdet.datasets.replace_ImageToTensor", "mmcv.runner.wrap_fp16_model", "mmcv.runner.load_checkpoint", "mmcv.cnn.fuse_conv_bn", "torch.cuda.synchronize", "time.perf_counter", "torch.cuda.synchronize", "torch.no_grad", "mmcv.cnn.fuse_conv_bn.", "time.perf_counter", "print", "print"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "# import modules from string list.", "\n", "if", "cfg", ".", "get", "(", "'custom_imports'", ",", "None", ")", ":", "\n", "        ", "from", "mmcv", ".", "utils", "import", "import_modules_from_strings", "\n", "import_modules_from_strings", "(", "**", "cfg", "[", "'custom_imports'", "]", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "if", "hasattr", "(", "cfg", ".", "model", ",", "'detector'", ")", ":", "\n", "        ", "cfg", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# build the dataloader", "\n", "samples_per_gpu", "=", "cfg", ".", "data", ".", "test", ".", "pop", "(", "'samples_per_gpu'", ",", "1", ")", "\n", "if", "samples_per_gpu", ">", "1", ":", "\n", "# Replace 'ImageToTensor' to 'DefaultFormatBundle'", "\n", "        ", "cfg", ".", "data", ".", "test", ".", "pipeline", "=", "replace_ImageToTensor", "(", "cfg", ".", "data", ".", "test", ".", "pipeline", ")", "\n", "", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "False", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "        ", "load_checkpoint", "(", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# the first several iterations may be very slow so skip them", "\n", "num_warmup", "=", "5", "\n", "pure_inf_time", "=", "0", "\n", "\n", "# benchmark with 2000 image and take the average", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "elapsed", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "\n", "if", "i", ">=", "num_warmup", ":", "\n", "            ", "pure_inf_time", "+=", "elapsed", "\n", "if", "(", "i", "+", "1", ")", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "                ", "fps", "=", "(", "i", "+", "1", "-", "num_warmup", ")", "/", "pure_inf_time", "\n", "print", "(", "f'Done image [{i + 1:<3}/ 2000], fps: {fps:.1f} img / s'", ")", "\n", "\n", "", "", "if", "(", "i", "+", "1", ")", "==", "2000", ":", "\n", "            ", "pure_inf_time", "+=", "elapsed", "\n", "fps", "=", "(", "i", "+", "1", "-", "num_warmup", ")", "/", "pure_inf_time", "\n", "print", "(", "f'Overall fps: {fps:.1f} img / s'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.test.parse_args": [[14, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'mmtrack test model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "help", "=", "'output result file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format-only'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Format the output results without perform evaluation. It is'", "\n", "'useful when you want to format the result to a specific format and '", "\n", "'submit it to the test server'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'eval types'", ")", "\n", "parser", ".", "add_argument", "(", "'--show'", ",", "action", "=", "'store_true'", ",", "help", "=", "'show results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "help", "=", "'score threshold (default: 0.3)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-dir'", ",", "help", "=", "'directory where painted images will be saved'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.test.main": [[71, 168], ["test.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "Config.fromfile.get", "hasattr", "mmdet.datasets.build_dataset", "build_dataloader", "Config.fromfile.get", "Config.fromfile.get", "mmcv.runner.get_dist_info", "ValueError", "ValueError", "Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "build_model", "build_model", "mmdet.core.wrap_fp16_model", "mmcv.runner.load_checkpoint", "hasattr", "mmcv.cnn.fuse_conv_bn", "mmcv.parallel.MMDataParallel", "single_gpu_test", "mmcv.parallel.MMDistributedDataParallel", "multi_gpu_test", "parse_args.out.endswith", "mmcv.parallel.MMDistributedDataParallel.cuda", "print", "mmcv.dump", "mmdet.datasets.build_dataset.format_results", "Config.fromfile.get().copy", "cfg.get().copy.update", "print", "cfg.get().copy.pop", "dict", "mmdet.datasets.build_dataset.evaluate", "torch.cuda.current_device", "Config.fromfile.get"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.single_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.multi_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "assert", "args", ".", "out", "or", "args", ".", "eval", "or", "args", ".", "format_only", "or", "args", ".", "show", "or", "args", ".", "show_dir", ",", "(", "'Please specify at least one operation (save/eval/format/show the '", "\n", "'results / save the results) with the argument \"--out\", \"--eval\"'", "\n", "', \"--format-only\", \"--show\" or \"--show-dir\"'", ")", "\n", "\n", "if", "args", ".", "eval", "and", "args", ".", "format_only", ":", "\n", "        ", "raise", "ValueError", "(", "'--eval and --format_only cannot be both specified'", ")", "\n", "\n", "", "if", "args", ".", "out", "is", "not", "None", "and", "not", "args", ".", "out", ".", "endswith", "(", "(", "'.pkl'", ",", "'.pickle'", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The output file must be a pkl file.'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmdet", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmdet", ".", "models", "import", "build_detector", "as", "build_model", "\n", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmtrack", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "# cfg.model.pretrains = None", "\n", "", "if", "hasattr", "(", "cfg", ".", "model", ",", "'detector'", ")", ":", "\n", "        ", "cfg", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# build the dataloader", "\n", "", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "if", "cfg", ".", "get", "(", "'test_cfg'", ",", "False", ")", ":", "\n", "        ", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "cfg", ".", "train_cfg", ",", "test_cfg", "=", "cfg", ".", "test_cfg", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "load_checkpoint", "(", "\n", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "            ", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "if", "not", "hasattr", "(", "model", ",", "'CLASSES'", ")", ":", "\n", "        ", "model", ".", "CLASSES", "=", "dataset", ".", "CLASSES", "\n", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "if", "not", "distributed", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "outputs", "=", "single_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "show", ",", "args", ".", "show_dir", ",", "\n", "args", ".", "show_score_thr", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ")", "\n", "outputs", "=", "multi_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "tmpdir", ",", "\n", "args", ".", "gpu_collect", ")", "\n", "\n", "", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "if", "args", ".", "out", ":", "\n", "            ", "print", "(", "f'\\nwriting results to {args.out}'", ")", "\n", "mmcv", ".", "dump", "(", "outputs", ",", "args", ".", "out", ")", "\n", "", "kwargs", "=", "{", "}", "if", "args", ".", "eval_options", "is", "None", "else", "args", ".", "eval_options", "\n", "if", "args", ".", "format_only", ":", "\n", "            ", "dataset", ".", "format_results", "(", "outputs", ",", "**", "kwargs", ")", "\n", "", "if", "args", ".", "eval", ":", "\n", "            ", "eval_kwargs", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", ".", "copy", "(", ")", "\n", "# hard-code way to remove EvalHook args", "\n", "for", "key", "in", "[", "'interval'", ",", "'tmpdir'", ",", "'start'", ",", "'gpu_collect'", "]", ":", "\n", "                ", "eval_kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "", "eval_kwargs", ".", "update", "(", "dict", "(", "metric", "=", "args", ".", "eval", ",", "**", "kwargs", ")", ")", "\n", "print", "(", "dataset", ".", "evaluate", "(", "outputs", ",", "**", "eval_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_dummy_results.parse_args": [[8, 15], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Make dummy results for MOT Challenge.'", ")", "\n", "parser", ".", "add_argument", "(", "'json_file'", ",", "help", "=", "'Input JSON file.'", ")", "\n", "parser", ".", "add_argument", "(", "'out_folder'", ",", "help", "=", "'Output folder.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.tools.mot_dummy_results.main": [[17, 28], ["mot_dummy_results.parse_args", "mmcv.load", "os.exists", "os.makedirs", "os.makedirs", "open", "open.close", "os.join"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "anns", "=", "mmcv", ".", "load", "(", "args", ".", "json_file", ")", "\n", "\n", "if", "not", "osp", ".", "exists", "(", "args", ".", "out_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "out_folder", ")", "\n", "", "for", "video", "in", "anns", "[", "'videos'", "]", ":", "\n", "        ", "name", "=", "video", "[", "'name'", "]", "\n", "txt_name", "=", "f'{name}.txt'", "\n", "f", "=", "open", "(", "osp", ".", "join", "(", "args", ".", "out_folder", ",", "txt_name", ")", ",", "'wt'", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.parse_args": [[44, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert MOT label and detections to COCO-VID format.'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--input'", ",", "help", "=", "'path of MOT data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-o'", ",", "'--output'", ",", "help", "=", "'path to save coco formatted label file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--convert-det'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'convert offical detection results.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--split-train'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'split the train set into half-train and half-validate.'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.parse_gts": [[61, 85], ["collections.defaultdict", "gt.strip().split.strip().split", "map", "list", "float", "int", "float", "dict", "outputs[].append", "map", "gt.strip().split.strip"], "function", ["None"], ["", "def", "parse_gts", "(", "gts", ")", ":", "\n", "    ", "outputs", "=", "defaultdict", "(", "list", ")", "\n", "for", "gt", "in", "gts", ":", "\n", "        ", "gt", "=", "gt", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "frame_id", ",", "ins_id", "=", "map", "(", "int", ",", "gt", "[", ":", "2", "]", ")", "\n", "bbox", "=", "list", "(", "map", "(", "float", ",", "gt", "[", "2", ":", "6", "]", ")", ")", "\n", "conf", "=", "float", "(", "gt", "[", "6", "]", ")", "\n", "class_id", "=", "int", "(", "gt", "[", "7", "]", ")", "\n", "visibility", "=", "float", "(", "gt", "[", "8", "]", ")", "\n", "if", "class_id", "in", "USELESS", ":", "\n", "            ", "continue", "\n", "", "elif", "class_id", "in", "IGNORES", ":", "\n", "            ", "continue", "\n", "", "anns", "=", "dict", "(", "\n", "category_id", "=", "1", ",", "\n", "bbox", "=", "bbox", ",", "\n", "area", "=", "bbox", "[", "2", "]", "*", "bbox", "[", "3", "]", ",", "\n", "iscrowd", "=", "False", ",", "\n", "visibility", "=", "visibility", ",", "\n", "mot_instance_id", "=", "ins_id", ",", "\n", "mot_conf", "=", "conf", ",", "\n", "mot_class_id", "=", "class_id", ")", "\n", "outputs", "[", "frame_id", "]", ".", "append", "(", "anns", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.parse_dets": [[87, 101], ["collections.defaultdict", "det.strip().split.strip().split", "map", "list", "outputs[].append", "map", "det.strip().split.strip"], "function", ["None"], ["", "def", "parse_dets", "(", "dets", ")", ":", "\n", "    ", "outputs", "=", "defaultdict", "(", "list", ")", "\n", "for", "det", "in", "dets", ":", "\n", "        ", "det", "=", "det", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "frame_id", ",", "ins_id", "=", "map", "(", "int", ",", "det", "[", ":", "2", "]", ")", "\n", "assert", "ins_id", "==", "-", "1", "\n", "bbox", "=", "list", "(", "map", "(", "float", ",", "det", "[", "2", ":", "7", "]", ")", ")", "\n", "# [x1, y1, x2, y2] to be consistent with mmdet", "\n", "bbox", "=", "[", "\n", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", ",", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ",", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ",", "bbox", "[", "4", "]", "\n", "]", "\n", "outputs", "[", "frame_id", "]", ".", "append", "(", "bbox", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.main": [[103, 215], ["mot2coco.parse_args", "os.exists", "os.makedirs", "os.makedirs", "print", "os.join", "collections.defaultdict", "os.listdir", "os.listdir", "tqdm.tqdm", "print", "mmcv.dump", "os.join", "os.join", "dict", "os.join", "dict", "dict", "os.join", "mmcv.list_from_file", "os.listdir", "os.listdir", "sorted", "int", "int", "int", "int", "dict", "enumerate", "outputs[].append", "mmcv.dump", "print", "print", "infos[].strip().split", "len", "mmcv.list_from_file", "mot2coco.parse_gts", "mmcv.list_from_file", "mot2coco.parse_dets", "os.join", "int", "dict", "outputs[].append", "dict", "infos[].strip().split", "infos[].strip().split", "infos[].strip().split", "infos[].strip().split", "infos[].strip().split", "str", "open", "numpy.array", "infos[].strip", "ValueError", "int", "name.split", "gt.update", "outputs[].append", "numpy.zeros", "infos[].strip", "infos[].strip", "infos[].strip", "infos[].strip", "infos[].strip", "f.writelines", "len", "_.split", "gt.split"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.parse_gts", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.mot2coco.parse_dets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "if", "not", "osp", ".", "exists", "(", "args", ".", "output", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output", ")", "\n", "\n", "", "sets", "=", "[", "'train'", ",", "'test'", "]", "\n", "if", "args", ".", "split_train", ":", "\n", "        ", "sets", "+=", "[", "'half-train'", ",", "'half-val'", "]", "\n", "", "vid_id", ",", "img_id", ",", "ann_id", "=", "1", ",", "1", ",", "1", "\n", "\n", "for", "subset", "in", "sets", ":", "\n", "        ", "ins_id", "=", "0", "\n", "print", "(", "f'Converting {subset} set to COCO format'", ")", "\n", "if", "'half'", "in", "subset", ":", "\n", "            ", "in_folder", "=", "osp", ".", "join", "(", "args", ".", "input", ",", "'train'", ")", "\n", "", "else", ":", "\n", "            ", "in_folder", "=", "osp", ".", "join", "(", "args", ".", "input", ",", "subset", ")", "\n", "", "out_file", "=", "osp", ".", "join", "(", "args", ".", "output", ",", "f'{subset}_cocoformat.json'", ")", "\n", "outputs", "=", "defaultdict", "(", "list", ")", "\n", "outputs", "[", "'categories'", "]", "=", "[", "dict", "(", "id", "=", "1", ",", "name", "=", "'pedestrian'", ")", "]", "\n", "if", "args", ".", "convert_det", ":", "\n", "            ", "det_file", "=", "osp", ".", "join", "(", "args", ".", "output", ",", "f'{subset}_detections.pkl'", ")", "\n", "detections", "=", "dict", "(", "bbox_results", "=", "dict", "(", ")", ")", "\n", "", "video_names", "=", "os", ".", "listdir", "(", "in_folder", ")", "\n", "for", "video_name", "in", "tqdm", "(", "video_names", ")", ":", "\n", "# basic params", "\n", "            ", "parse_gt", "=", "'test'", "not", "in", "subset", "\n", "ins_maps", "=", "dict", "(", ")", "\n", "# load video infos", "\n", "video_folder", "=", "osp", ".", "join", "(", "in_folder", ",", "video_name", ")", "\n", "infos", "=", "mmcv", ".", "list_from_file", "(", "f'{video_folder}/seqinfo.ini'", ")", "\n", "# video-level infos", "\n", "assert", "video_name", "==", "infos", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", "\n", "img_folder", "=", "infos", "[", "2", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", "\n", "img_names", "=", "os", ".", "listdir", "(", "f'{video_folder}/{img_folder}'", ")", "\n", "img_names", "=", "sorted", "(", "img_names", ")", "\n", "fps", "=", "int", "(", "infos", "[", "3", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", ")", "\n", "num_imgs", "=", "int", "(", "infos", "[", "4", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", ")", "\n", "assert", "num_imgs", "==", "len", "(", "img_names", ")", "\n", "width", "=", "int", "(", "infos", "[", "5", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", ")", "\n", "height", "=", "int", "(", "infos", "[", "6", "]", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "[", "1", "]", ")", "\n", "video", "=", "dict", "(", "\n", "id", "=", "vid_id", ",", "\n", "name", "=", "video_name", ",", "\n", "fps", "=", "fps", ",", "\n", "width", "=", "width", ",", "\n", "height", "=", "height", ")", "\n", "# parse annotations", "\n", "if", "parse_gt", ":", "\n", "                ", "gts", "=", "mmcv", ".", "list_from_file", "(", "f'{video_folder}/gt/gt.txt'", ")", "\n", "img2gts", "=", "parse_gts", "(", "gts", ")", "\n", "", "if", "args", ".", "convert_det", ":", "\n", "                ", "dets", "=", "mmcv", ".", "list_from_file", "(", "f'{video_folder}/det/det.txt'", ")", "\n", "img2dets", "=", "parse_dets", "(", "dets", ")", "\n", "# make half sets", "\n", "", "if", "'half'", "in", "subset", ":", "\n", "                ", "split_frame", "=", "num_imgs", "//", "2", "+", "1", "\n", "if", "'train'", "in", "subset", ":", "\n", "                    ", "img_names", "=", "img_names", "[", ":", "split_frame", "]", "\n", "", "elif", "'val'", "in", "subset", ":", "\n", "                    ", "img_names", "=", "img_names", "[", "split_frame", ":", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'subset must be named with `train` or `val`'", ")", "\n", "", "mot_frame_ids", "=", "[", "str", "(", "int", "(", "_", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", ")", "for", "_", "in", "img_names", "]", "\n", "with", "open", "(", "f'{video_folder}/gt/gt_{subset}.txt'", ",", "'wt'", ")", "as", "f", ":", "\n", "                    ", "for", "gt", "in", "gts", ":", "\n", "                        ", "if", "gt", ".", "split", "(", "','", ")", "[", "0", "]", "in", "mot_frame_ids", ":", "\n", "                            ", "f", ".", "writelines", "(", "f'{gt}\\n'", ")", "\n", "# image and box level infos", "\n", "", "", "", "", "for", "frame_id", ",", "name", "in", "enumerate", "(", "img_names", ")", ":", "\n", "                ", "img_name", "=", "osp", ".", "join", "(", "video_name", ",", "img_folder", ",", "name", ")", "\n", "mot_frame_id", "=", "int", "(", "name", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "image", "=", "dict", "(", "\n", "id", "=", "img_id", ",", "\n", "video_id", "=", "vid_id", ",", "\n", "file_name", "=", "img_name", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "mot_frame_id", "=", "mot_frame_id", ")", "\n", "if", "parse_gt", ":", "\n", "                    ", "gts", "=", "img2gts", "[", "mot_frame_id", "]", "\n", "for", "gt", "in", "gts", ":", "\n", "                        ", "gt", ".", "update", "(", "id", "=", "ann_id", ",", "image_id", "=", "img_id", ")", "\n", "mot_ins_id", "=", "gt", "[", "'mot_instance_id'", "]", "\n", "if", "mot_ins_id", "in", "ins_maps", ":", "\n", "                            ", "gt", "[", "'instance_id'", "]", "=", "ins_maps", "[", "mot_ins_id", "]", "\n", "", "else", ":", "\n", "                            ", "gt", "[", "'instance_id'", "]", "=", "ins_id", "\n", "ins_maps", "[", "mot_ins_id", "]", "=", "ins_id", "\n", "ins_id", "+=", "1", "\n", "", "outputs", "[", "'annotations'", "]", ".", "append", "(", "gt", ")", "\n", "ann_id", "+=", "1", "\n", "", "", "if", "args", ".", "convert_det", ":", "\n", "                    ", "dets", "=", "np", ".", "array", "(", "img2dets", "[", "mot_frame_id", "]", ")", "\n", "if", "dets", ".", "ndim", "==", "1", ":", "\n", "                        ", "assert", "len", "(", "dets", ")", "==", "0", "\n", "dets", "=", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ")", "\n", "", "detections", "[", "'bbox_results'", "]", "[", "img_name", "]", "=", "[", "dets", "]", "\n", "", "outputs", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "img_id", "+=", "1", "\n", "", "outputs", "[", "'videos'", "]", ".", "append", "(", "video", ")", "\n", "vid_id", "+=", "1", "\n", "outputs", "[", "'num_instances'", "]", "=", "ins_id", "\n", "", "print", "(", "f'{subset} has {ins_id} instances.'", ")", "\n", "mmcv", ".", "dump", "(", "outputs", ",", "out_file", ")", "\n", "if", "args", ".", "convert_det", ":", "\n", "            ", "mmcv", ".", "dump", "(", "detections", ",", "det_file", ")", "\n", "print", "(", "f'Done! Saved as {out_file} and {det_file}'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f'Done! Saved as {out_file}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.lasot2coco.parse_args": [[9, 23], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'LaSOT test dataset to COCO Video format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-i'", ",", "\n", "'--input'", ",", "\n", "help", "=", "'root directory of LaSOT test dataset'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-o'", ",", "\n", "'--output'", ",", "\n", "help", "=", "'directory to save coco formatted label file'", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.lasot2coco.convert_lasot_test": [[25, 92], ["dict", "os.join", "mmcv.list_from_file", "tqdm.tqdm", "mmcv.dump", "print", "print", "print", "print", "print", "print", "dict", "os.join", "dict", "lasot_test[].append", "mmcv.list_from_file", "mmcv.list_from_file", "full_occlusion[].split", "mmcv.list_from_file", "out_of_view[].split", "mmcv.imread", "enumerate", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "dict", "lasot_test[].append", "gt_bbox.split", "dict", "lasot_test[].append", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "convert_lasot_test", "(", "lasot_test", ",", "ann_dir", ",", "save_dir", ")", ":", "\n", "    ", "\"\"\"Convert lasot dataset to COCO style.\n\n    Args:\n        lasot_test (dict): The converted COCO style annotations.\n        ann_dir (str): The path of lasot test dataset\n        save_dir (str): The path to save `lasot_test`.\n    \"\"\"", "\n", "records", "=", "dict", "(", "vid_id", "=", "1", ",", "img_id", "=", "1", ",", "ann_id", "=", "1", ",", "global_instance_id", "=", "1", ")", "\n", "videos_list", "=", "osp", ".", "join", "(", "ann_dir", ",", "'testing_set.txt'", ")", "\n", "videos_list", "=", "mmcv", ".", "list_from_file", "(", "videos_list", ")", "\n", "\n", "lasot_test", "[", "'categories'", "]", "=", "[", "dict", "(", "id", "=", "0", ",", "name", "=", "0", ")", "]", "\n", "\n", "for", "video_name", "in", "tqdm", "(", "videos_list", ")", ":", "\n", "        ", "video_path", "=", "osp", ".", "join", "(", "ann_dir", ",", "video_name", ")", "\n", "video", "=", "dict", "(", "id", "=", "records", "[", "'vid_id'", "]", ",", "name", "=", "video_name", ")", "\n", "lasot_test", "[", "'videos'", "]", ".", "append", "(", "video", ")", "\n", "\n", "gt_bboxes", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "video_path", ",", "'groundtruth.txt'", ")", ")", "\n", "full_occlusion", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "video_path", ",", "'full_occlusion.txt'", ")", ")", "\n", "full_occlusion", "=", "full_occlusion", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "out_of_view", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "video_path", ",", "'out_of_view.txt'", ")", ")", "\n", "out_of_view", "=", "out_of_view", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "\n", "img", "=", "mmcv", ".", "imread", "(", "osp", ".", "join", "(", "video_path", ",", "'img/00000001.jpg'", ")", ")", "\n", "height", ",", "width", ",", "_", "=", "img", ".", "shape", "\n", "for", "frame_id", ",", "gt_bbox", "in", "enumerate", "(", "gt_bboxes", ")", ":", "\n", "            ", "file_name", "=", "'%08d'", "%", "(", "frame_id", "+", "1", ")", "+", "'.jpg'", "\n", "file_name", "=", "osp", ".", "join", "(", "video_name", ",", "'img'", ",", "file_name", ")", "\n", "image", "=", "dict", "(", "\n", "file_name", "=", "file_name", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "id", "=", "records", "[", "'img_id'", "]", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "video_id", "=", "records", "[", "'vid_id'", "]", ")", "\n", "lasot_test", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "\n", "x1", ",", "y1", ",", "w", ",", "h", "=", "gt_bbox", ".", "split", "(", "','", ")", "\n", "ann", "=", "dict", "(", "\n", "id", "=", "records", "[", "'ann_id'", "]", ",", "\n", "image_id", "=", "records", "[", "'img_id'", "]", ",", "\n", "instance_id", "=", "records", "[", "'global_instance_id'", "]", ",", "\n", "category_id", "=", "0", ",", "\n", "bbox", "=", "[", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", ",", "int", "(", "w", ")", ",", "\n", "int", "(", "h", ")", "]", ",", "\n", "area", "=", "int", "(", "w", ")", "*", "int", "(", "h", ")", ",", "\n", "full_occlusion", "=", "full_occlusion", "[", "frame_id", "]", "==", "'1'", ",", "\n", "out_of_view", "=", "out_of_view", "[", "frame_id", "]", "==", "'1'", ")", "\n", "lasot_test", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "\n", "records", "[", "'ann_id'", "]", "+=", "1", "\n", "records", "[", "'img_id'", "]", "+=", "1", "\n", "", "records", "[", "'global_instance_id'", "]", "+=", "1", "\n", "records", "[", "'vid_id'", "]", "+=", "1", "\n", "\n", "", "mmcv", ".", "dump", "(", "lasot_test", ",", "osp", ".", "join", "(", "save_dir", ",", "'lasot_test.json'", ")", ")", "\n", "print", "(", "'-----LaSOT Test Dataset------'", ")", "\n", "print", "(", "f'{records[\"vid_id\"]- 1} videos'", ")", "\n", "print", "(", "f'{records[\"global_instance_id\"]- 1} instances'", ")", "\n", "print", "(", "f'{records[\"img_id\"]- 1} images'", ")", "\n", "print", "(", "f'{records[\"ann_id\"] - 1} objects'", ")", "\n", "print", "(", "'-----------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.lasot2coco.main": [[94, 98], ["lasot2coco.parse_args", "collections.defaultdict", "lasot2coco.convert_lasot_test"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.lasot2coco.convert_lasot_test"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "lasot_test", "=", "defaultdict", "(", "list", ")", "\n", "convert_lasot_test", "(", "lasot_test", ",", "args", ".", "input", ",", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.parse_args": [[31, 45], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'ImageNet DET to COCO Video format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-i'", ",", "\n", "'--input'", ",", "\n", "help", "=", "'root directory of ImageNet DET annotations'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-o'", ",", "\n", "'--output'", ",", "\n", "help", "=", "'directory to save coco formatted label file'", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.parse_xml": [[47, 117], ["xml.parse", "ET.parse.getroot", "tree.getroot.find", "int", "int", "dict", "DET[].append", "tree.getroot.findall", "tree.getroot.findall", "print", "obj.find", "dict", "DET[].append", "root.find.find", "root.find.find", "obj.find", "int", "int", "int", "int", "len", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["None"], ["", "def", "parse_xml", "(", "img_name", ",", "xml_path", ",", "is_vid_train_frame", ",", "records", ",", "DET", ",", "\n", "obj_num_classes", ")", ":", "\n", "    ", "\"\"\"Parse xml annotations and record them.\n\n    Args:\n        img_name (str): image file path.\n        xml_path (str): annotation file path.\n        is_vid_train_frame (bool): If True, the image is used for the training\n            of video object detection task, otherwise, not used.\n        records (dict): The record information like image id, annotation id.\n        DET (dict): The converted COCO style annotations.\n        obj_num_classes (dict): The number of objects per class.\n\n    Returns:\n        tuple: (records, DET, obj_num_classes), records is the updated record\n            information like image id, annotation id, DET is the updated\n            COCO style annotations, obj_num_classes is the updated number of\n            objects per class.\n    \"\"\"", "\n", "tree", "=", "ET", ".", "parse", "(", "xml_path", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "size", "=", "root", ".", "find", "(", "'size'", ")", "\n", "width", "=", "int", "(", "size", ".", "find", "(", "'width'", ")", ".", "text", ")", "\n", "height", "=", "int", "(", "size", ".", "find", "(", "'height'", ")", ".", "text", ")", "\n", "image", "=", "dict", "(", "\n", "file_name", "=", "img_name", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "id", "=", "records", "[", "'img_id'", "]", ",", "\n", "is_vid_train_frame", "=", "is_vid_train_frame", ")", "\n", "DET", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "if", "is_vid_train_frame", ":", "\n", "        ", "records", "[", "'vid_train_frames'", "]", "+=", "1", "\n", "\n", "", "if", "root", ".", "findall", "(", "'object'", ")", "==", "[", "]", ":", "\n", "        ", "print", "(", "f'{xml_path} has no objects.'", ")", "\n", "records", "[", "'num_no_objects'", "]", "+=", "1", "\n", "records", "[", "'img_id'", "]", "+=", "1", "\n", "return", "records", ",", "DET", ",", "obj_num_classes", "\n", "\n", "", "for", "obj", "in", "root", ".", "findall", "(", "'object'", ")", ":", "\n", "        ", "name", "=", "obj", ".", "find", "(", "'name'", ")", ".", "text", "\n", "if", "name", "in", "cats_id_maps", ":", "\n", "            ", "category_id", "=", "cats_id_maps", "[", "name", "]", "\n", "", "else", ":", "\n", "            ", "category_id", "=", "len", "(", "cats_id_maps", ")", "+", "1", "\n", "", "bnd_box", "=", "obj", ".", "find", "(", "'bndbox'", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "\n", "int", "(", "bnd_box", ".", "find", "(", "'xmin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'ymin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'xmax'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'ymax'", ")", ".", "text", ")", "\n", "]", "\n", "w", "=", "x2", "-", "x1", "\n", "h", "=", "y2", "-", "y1", "\n", "ann", "=", "dict", "(", "\n", "id", "=", "records", "[", "'ann_id'", "]", ",", "\n", "image_id", "=", "records", "[", "'img_id'", "]", ",", "\n", "category_id", "=", "category_id", ",", "\n", "bbox", "=", "[", "x1", ",", "y1", ",", "w", ",", "h", "]", ",", "\n", "area", "=", "w", "*", "h", ",", "\n", "iscrowd", "=", "False", ")", "\n", "DET", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "if", "category_id", "not", "in", "obj_num_classes", ":", "\n", "            ", "obj_num_classes", "[", "category_id", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "obj_num_classes", "[", "category_id", "]", "+=", "1", "\n", "", "records", "[", "'ann_id'", "]", "+=", "1", "\n", "", "records", "[", "'img_id'", "]", "+=", "1", "\n", "return", "records", ",", "DET", ",", "obj_num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.convert_det": [[119, 180], ["dict", "dict", "os.join", "mmcv.list_from_file", "tqdm.tqdm", "tqdm.tqdm", "mmcv.dump", "print", "print", "print", "print", "print", "print", "range", "vid_train_img_names.append", "os.join", "imagenet2coco_det.parse_xml", "os.join", "tqdm.tqdm", "os.join", "print", "img_name.replace.replace", "sorted", "sorted", "osp.join.replace", "img_name.replace.replace", "imagenet2coco_det.parse_xml", "len", "glob.glob", "glob.glob", "os.join", "os.join", "vid_train_img_info.split"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.parse_xml", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.parse_xml"], ["", "def", "convert_det", "(", "DET", ",", "ann_dir", ",", "save_dir", ")", ":", "\n", "    ", "\"\"\"Convert ImageNet DET dataset in COCO style.\n\n    Args:\n        DET (dict): The converted COCO style annotations.\n        ann_dir (str): The path of ImageNet DET dataset\n        save_dir (str): The path to save `DET`.\n    \"\"\"", "\n", "dataset_sets", "=", "(", "'train/ILSVRC2013_train'", ",", "'train/ILSVRC2014_train_0000'", ",", "\n", "'train/ILSVRC2014_train_0001'", ",", "\n", "'train/ILSVRC2014_train_0002'", ",", "\n", "'train/ILSVRC2014_train_0003'", ",", "\n", "'train/ILSVRC2014_train_0004'", ",", "\n", "'train/ILSVRC2014_train_0005'", ",", "\n", "'train/ILSVRC2014_train_0006'", ")", "\n", "records", "=", "dict", "(", "img_id", "=", "1", ",", "ann_id", "=", "1", ",", "num_no_objects", "=", "0", ",", "vid_train_frames", "=", "0", ")", "\n", "obj_num_classes", "=", "dict", "(", ")", "\n", "\n", "vid_train_img_list", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Lists/DET_train_30classes.txt'", ")", "\n", "vid_train_img_list", "=", "mmcv", ".", "list_from_file", "(", "vid_train_img_list", ")", "\n", "vid_train_img_names", "=", "[", "]", "\n", "for", "vid_train_img_info", "in", "vid_train_img_list", ":", "\n", "        ", "vid_train_img_names", ".", "append", "(", "f\"{vid_train_img_info.split(' ')[0]}.JPEG\"", ")", "\n", "\n", "", "for", "img_name", "in", "tqdm", "(", "vid_train_img_names", ")", ":", "\n", "        ", "xml_path", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Annotations/DET'", ",", "\n", "img_name", ".", "replace", "(", "'JPEG'", ",", "'xml'", ")", ")", "\n", "records", ",", "DET", ",", "obj_num_classes", "=", "parse_xml", "(", "img_name", ",", "xml_path", ",", "True", ",", "\n", "records", ",", "DET", ",", "\n", "obj_num_classes", ")", "\n", "\n", "", "for", "sub_set", "in", "tqdm", "(", "dataset_sets", ")", ":", "\n", "        ", "sub_set_base_path", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Annotations/DET'", ",", "sub_set", ")", "\n", "if", "'train/ILSVRC2013_train'", "==", "sub_set", ":", "\n", "            ", "xml_paths", "=", "sorted", "(", "\n", "glob", ".", "glob", "(", "osp", ".", "join", "(", "sub_set_base_path", ",", "'*'", ",", "'*.xml'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "xml_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "osp", ".", "join", "(", "sub_set_base_path", ",", "'*.xml'", ")", ")", ")", "\n", "\n", "", "for", "xml_path", "in", "tqdm", "(", "xml_paths", ")", ":", "\n", "            ", "img_name", "=", "xml_path", ".", "replace", "(", "sub_set_base_path", ",", "sub_set", ")", "\n", "img_name", "=", "img_name", ".", "replace", "(", "'xml'", ",", "'JPEG'", ")", "\n", "is_vid_train_frame", "=", "False", "\n", "if", "img_name", "in", "vid_train_img_names", ":", "\n", "                ", "continue", "\n", "\n", "", "records", ",", "DET", ",", "obj_num_classes", "=", "parse_xml", "(", "img_name", ",", "xml_path", ",", "\n", "is_vid_train_frame", ",", "\n", "records", ",", "DET", ",", "\n", "obj_num_classes", ")", "\n", "\n", "", "", "mmcv", ".", "dump", "(", "DET", ",", "osp", ".", "join", "(", "save_dir", ",", "'imagenet_det_30plus1cls.json'", ")", ")", "\n", "print", "(", "'-----ImageNet DET------'", ")", "\n", "print", "(", "f'total {records[\"img_id\"] - 1} images'", ")", "\n", "print", "(", "f'{records[\"num_no_objects\"]} images have no objects'", ")", "\n", "print", "(", "f'total {records[\"vid_train_frames\"]} images '", "\n", "'for video detection training'", ")", "\n", "print", "(", "f'{records[\"ann_id\"] - 1} objects are annotated.'", ")", "\n", "print", "(", "'-----------------------'", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "CLASSES", ")", "+", "1", ")", ":", "\n", "        ", "print", "(", "f'Class {i} {CLASSES[i - 1]} has {obj_num_classes[i]} objects.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.main": [[182, 193], ["imagenet2coco_det.parse_args", "collections.defaultdict", "enumerate", "imagenet2coco_det.convert_det", "len", "DET[].append", "DET[].append", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_det.convert_det"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "DET", "=", "defaultdict", "(", "list", ")", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "CLASSES", ",", "1", ")", ":", "\n", "        ", "if", "k", "==", "len", "(", "CLASSES", ")", ":", "\n", "            ", "DET", "[", "'categories'", "]", ".", "append", "(", "dict", "(", "id", "=", "k", ",", "name", "=", "v", ",", "encode_name", "=", "None", ")", ")", "\n", "", "else", ":", "\n", "            ", "DET", "[", "'categories'", "]", ".", "append", "(", "\n", "dict", "(", "id", "=", "k", ",", "name", "=", "v", ",", "encode_name", "=", "CLASSES_ENCODES", "[", "k", "-", "1", "]", ")", ")", "\n", "", "", "convert_det", "(", "DET", ",", "args", ".", "input", ",", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args": [[29, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'ImageNet VID to COCO Video format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-i'", ",", "\n", "'--input'", ",", "\n", "help", "=", "'root directory of ImageNet VID annotations'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-o'", ",", "\n", "'--output'", ",", "\n", "help", "=", "'directory to save coco formatted label file'", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_train_list": [[45, 58], ["os.join", "mmcv.list_from_file", "collections.defaultdict", "info.split.split", "dict", "[].append", "int", "int", "int"], "function", ["None"], ["", "def", "parse_train_list", "(", "ann_dir", ")", ":", "\n", "    ", "\"\"\"Parse the txt file of ImageNet VID train dataset.\"\"\"", "\n", "img_list", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Lists/VID_train_15frames.txt'", ")", "\n", "img_list", "=", "mmcv", ".", "list_from_file", "(", "img_list", ")", "\n", "train_infos", "=", "defaultdict", "(", "list", ")", "\n", "for", "info", "in", "img_list", ":", "\n", "        ", "info", "=", "info", ".", "split", "(", "' '", ")", "\n", "if", "info", "[", "0", "]", "not", "in", "train_infos", ":", "\n", "            ", "train_infos", "[", "info", "[", "0", "]", "]", "=", "dict", "(", "\n", "vid_train_frames", "=", "[", "int", "(", "info", "[", "2", "]", ")", "-", "1", "]", ",", "num_frames", "=", "int", "(", "info", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "train_infos", "[", "info", "[", "0", "]", "]", "[", "'vid_train_frames'", "]", ".", "append", "(", "int", "(", "info", "[", "2", "]", ")", "-", "1", ")", "\n", "", "", "return", "train_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_val_list": [[60, 69], ["os.join", "mmcv.list_from_file", "collections.defaultdict", "info.split.split", "dict", "int"], "function", ["None"], ["", "def", "parse_val_list", "(", "ann_dir", ")", ":", "\n", "    ", "\"\"\"Parse the txt file of ImageNet VID val dataset.\"\"\"", "\n", "img_list", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Lists/VID_val_videos.txt'", ")", "\n", "img_list", "=", "mmcv", ".", "list_from_file", "(", "img_list", ")", "\n", "val_infos", "=", "defaultdict", "(", "list", ")", "\n", "for", "info", "in", "img_list", ":", "\n", "        ", "info", "=", "info", ".", "split", "(", "' '", ")", "\n", "val_infos", "[", "info", "[", "0", "]", "]", "=", "dict", "(", "num_frames", "=", "int", "(", "info", "[", "-", "1", "]", ")", ")", "\n", "", "return", "val_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.convert_vid": [[71, 183], ["dict", "dict", "os.join", "tqdm.tqdm", "mmcv.dump", "print", "print", "print", "print", "print", "print", "print", "range", "imagenet2coco_vid.parse_train_list", "imagenet2coco_vid.parse_val_list", "dict", "vid_infos[].get", "len", "dict", "VID[].append", "range", "os.join", "print", "os.join", "os.join", "xml.parse", "ET.parse.getroot", "tree.getroot.find", "int", "int", "dict", "VID[].append", "tree.getroot.findall", "len", "tree.getroot.findall", "print", "obj.find", "dict", "VID[].append", "root.find.find", "root.find.find", "obj.find", "int", "int", "int", "int", "obj.find", "obj.find", "obj.find", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_train_list", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_val_list", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "convert_vid", "(", "VID", ",", "ann_dir", ",", "save_dir", ",", "mode", "=", "'train'", ")", ":", "\n", "    ", "\"\"\"Convert ImageNet VID dataset in COCO style.\n\n    Args:\n        VID (dict): The converted COCO style annotations.\n        ann_dir (str): The path of ImageNet VID dataset.\n        save_dir (str): The path to save `VID`.\n        mode (str): Convert train dataset or validation dataset. Options are\n            'train', 'val'. Default: 'train'.\n    \"\"\"", "\n", "assert", "mode", "in", "[", "'train'", ",", "'val'", "]", "\n", "records", "=", "dict", "(", "\n", "vid_id", "=", "1", ",", "\n", "img_id", "=", "1", ",", "\n", "ann_id", "=", "1", ",", "\n", "global_instance_id", "=", "1", ",", "\n", "num_vid_train_frames", "=", "0", ",", "\n", "num_no_objects", "=", "0", ")", "\n", "obj_num_classes", "=", "dict", "(", ")", "\n", "xml_dir", "=", "osp", ".", "join", "(", "ann_dir", ",", "'Annotations/VID/'", ")", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "vid_infos", "=", "parse_train_list", "(", "ann_dir", ")", "\n", "", "else", ":", "\n", "        ", "vid_infos", "=", "parse_val_list", "(", "ann_dir", ")", "\n", "", "for", "vid_info", "in", "tqdm", "(", "vid_infos", ")", ":", "\n", "        ", "instance_id_maps", "=", "dict", "(", ")", "\n", "vid_train_frames", "=", "vid_infos", "[", "vid_info", "]", ".", "get", "(", "'vid_train_frames'", ",", "[", "]", ")", "\n", "records", "[", "'num_vid_train_frames'", "]", "+=", "len", "(", "vid_train_frames", ")", "\n", "video", "=", "dict", "(", "\n", "id", "=", "records", "[", "'vid_id'", "]", ",", "\n", "name", "=", "vid_info", ",", "\n", "vid_train_frames", "=", "vid_train_frames", ")", "\n", "VID", "[", "'videos'", "]", ".", "append", "(", "video", ")", "\n", "num_frames", "=", "vid_infos", "[", "vid_info", "]", "[", "'num_frames'", "]", "\n", "for", "frame_id", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "is_vid_train_frame", "=", "True", "if", "frame_id", "in", "vid_train_frames", "else", "False", "\n", "img_prefix", "=", "osp", ".", "join", "(", "vid_info", ",", "'%06d'", "%", "frame_id", ")", "\n", "xml_name", "=", "osp", ".", "join", "(", "xml_dir", ",", "f'{img_prefix}.xml'", ")", "\n", "# parse XML annotation file", "\n", "tree", "=", "ET", ".", "parse", "(", "xml_name", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "size", "=", "root", ".", "find", "(", "'size'", ")", "\n", "width", "=", "int", "(", "size", ".", "find", "(", "'width'", ")", ".", "text", ")", "\n", "height", "=", "int", "(", "size", ".", "find", "(", "'height'", ")", ".", "text", ")", "\n", "image", "=", "dict", "(", "\n", "file_name", "=", "f'{img_prefix}.JPEG'", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "id", "=", "records", "[", "'img_id'", "]", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "video_id", "=", "records", "[", "'vid_id'", "]", ",", "\n", "is_vid_train_frame", "=", "is_vid_train_frame", ")", "\n", "VID", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "if", "root", ".", "findall", "(", "'object'", ")", "==", "[", "]", ":", "\n", "                ", "print", "(", "xml_name", ",", "'has no objects.'", ")", "\n", "records", "[", "'num_no_objects'", "]", "+=", "1", "\n", "records", "[", "'img_id'", "]", "+=", "1", "\n", "continue", "\n", "", "for", "obj", "in", "root", ".", "findall", "(", "'object'", ")", ":", "\n", "                ", "name", "=", "obj", ".", "find", "(", "'name'", ")", ".", "text", "\n", "if", "name", "not", "in", "cats_id_maps", ":", "\n", "                    ", "continue", "\n", "", "category_id", "=", "cats_id_maps", "[", "name", "]", "\n", "bnd_box", "=", "obj", ".", "find", "(", "'bndbox'", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "\n", "int", "(", "bnd_box", ".", "find", "(", "'xmin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'ymin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'xmax'", ")", ".", "text", ")", ",", "\n", "int", "(", "bnd_box", ".", "find", "(", "'ymax'", ")", ".", "text", ")", "\n", "]", "\n", "w", "=", "x2", "-", "x1", "\n", "h", "=", "y2", "-", "y1", "\n", "track_id", "=", "obj", ".", "find", "(", "'trackid'", ")", ".", "text", "\n", "if", "track_id", "in", "instance_id_maps", ":", "\n", "                    ", "instance_id", "=", "instance_id_maps", "[", "track_id", "]", "\n", "", "else", ":", "\n", "                    ", "instance_id", "=", "records", "[", "'global_instance_id'", "]", "\n", "records", "[", "'global_instance_id'", "]", "+=", "1", "\n", "instance_id_maps", "[", "track_id", "]", "=", "instance_id", "\n", "", "occluded", "=", "obj", ".", "find", "(", "'occluded'", ")", ".", "text", "\n", "generated", "=", "obj", ".", "find", "(", "'generated'", ")", ".", "text", "\n", "ann", "=", "dict", "(", "\n", "id", "=", "records", "[", "'ann_id'", "]", ",", "\n", "video_id", "=", "records", "[", "'vid_id'", "]", ",", "\n", "image_id", "=", "records", "[", "'img_id'", "]", ",", "\n", "category_id", "=", "category_id", ",", "\n", "instance_id", "=", "instance_id", ",", "\n", "bbox", "=", "[", "x1", ",", "y1", ",", "w", ",", "h", "]", ",", "\n", "area", "=", "w", "*", "h", ",", "\n", "iscrowd", "=", "False", ",", "\n", "occluded", "=", "occluded", "==", "'1'", ",", "\n", "generated", "=", "generated", "==", "'1'", ")", "\n", "if", "category_id", "not", "in", "obj_num_classes", ":", "\n", "                    ", "obj_num_classes", "[", "category_id", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "obj_num_classes", "[", "category_id", "]", "+=", "1", "\n", "", "VID", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "records", "[", "'ann_id'", "]", "+=", "1", "\n", "", "records", "[", "'img_id'", "]", "+=", "1", "\n", "", "records", "[", "'vid_id'", "]", "+=", "1", "\n", "", "mmcv", ".", "dump", "(", "VID", ",", "osp", ".", "join", "(", "save_dir", ",", "f'imagenet_vid_{mode}.json'", ")", ")", "\n", "print", "(", "f'-----ImageNet VID {mode}------'", ")", "\n", "print", "(", "f'{records[\"vid_id\"]- 1} videos'", ")", "\n", "print", "(", "f'{records[\"img_id\"]- 1} images'", ")", "\n", "print", "(", "\n", "f'{records[\"num_vid_train_frames\"]} train frames for video detection'", ")", "\n", "print", "(", "f'{records[\"num_no_objects\"]} images have no objects'", ")", "\n", "print", "(", "f'{records[\"ann_id\"] - 1} objects'", ")", "\n", "print", "(", "'-----------------------'", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "CLASSES", ")", "+", "1", ")", ":", "\n", "        ", "print", "(", "f'Class {i} {CLASSES[i - 1]} has {obj_num_classes[i]} objects.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.main": [[185, 200], ["imagenet2coco_vid.parse_args", "enumerate", "collections.defaultdict", "imagenet2coco_vid.convert_vid", "collections.defaultdict", "imagenet2coco_vid.convert_vid", "categories.append", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.parse_args", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.convert_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.convert_datasets.imagenet2coco_vid.convert_vid"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "categories", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "CLASSES", ",", "1", ")", ":", "\n", "        ", "categories", ".", "append", "(", "\n", "dict", "(", "id", "=", "k", ",", "name", "=", "v", ",", "encode_name", "=", "CLASSES_ENCODES", "[", "k", "-", "1", "]", ")", ")", "\n", "\n", "", "VID_train", "=", "defaultdict", "(", "list", ")", "\n", "VID_train", "[", "'categories'", "]", "=", "categories", "\n", "convert_vid", "(", "VID_train", ",", "args", ".", "input", ",", "args", ".", "output", ",", "'train'", ")", "\n", "\n", "VID_val", "=", "defaultdict", "(", "list", ")", "\n", "VID_val", "[", "'categories'", "]", "=", "categories", "\n", "convert_vid", "(", "VID_val", ",", "args", ".", "input", ",", "args", ".", "output", ",", "'val'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.docs.conf.get_version": [[26, 30], ["open", "exec", "locals", "compile", "f.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "version_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "exec", "(", "compile", "(", "f", ".", "read", "(", ")", ",", "version_file", ",", "'exec'", ")", ")", "\n", "", "return", "locals", "(", ")", "[", "'__version__'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mmtrack.version.parse_version_info": [[6, 16], ["version_str.split", "tuple", "x.isdigit", "version_info.append", "int", "x.find", "x.split", "version_info.append", "version_info.append", "int"], "function", ["None"], ["def", "parse_version_info", "(", "version_str", ")", ":", "\n", "    ", "version_info", "=", "[", "]", "\n", "for", "x", "in", "version_str", ".", "split", "(", "'.'", ")", ":", "\n", "        ", "if", "x", ".", "isdigit", "(", ")", ":", "\n", "            ", "version_info", ".", "append", "(", "int", "(", "x", ")", ")", "\n", "", "elif", "x", ".", "find", "(", "'rc'", ")", "!=", "-", "1", ":", "\n", "            ", "patch_version", "=", "x", ".", "split", "(", "'rc'", ")", "\n", "version_info", ".", "append", "(", "int", "(", "patch_version", "[", "0", "]", ")", ")", "\n", "version_info", ".", "append", "(", "f'rc{patch_version[1]}'", ")", "\n", "", "", "return", "tuple", "(", "version_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger": [[6, 17], ["mmcv.utils.get_logger"], "function", ["None"], ["def", "get_root_logger", "(", "log_file", "=", "None", ",", "log_level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "\"\"\"Get root logger.\n\n    Args:\n        log_file (str): File path of log. Defaults to None.\n        log_level (int): The level of logger. Defaults to logging.INFO.\n\n    Returns:\n        :obj:`logging.Logger`: The obtained logger\n    \"\"\"", "\n", "return", "get_logger", "(", "'mmtrack'", ",", "log_file", ",", "log_level", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.collect_env.collect_env": [[14, 58], ["sys.version.replace", "torch.cuda.is_available", "subprocess.check_output", "gcc.decode().strip.decode().strip", "torch.__config__.show", "collections.defaultdict", "range", "collections.defaultdict.items", "os.isdir", "torch.cuda.device_count", "devices[].append", "gcc.decode().strip.decode", "os.join", "subprocess.check_output", "nvcc.decode().strip.decode().strip", "str", "nvcc.decode().strip.decode", "torch.cuda.get_device_name"], "function", ["None"], ["def", "collect_env", "(", ")", ":", "\n", "    ", "\"\"\"Collect the information of the running environments.\"\"\"", "\n", "env_info", "=", "{", "}", "\n", "env_info", "[", "'sys.platform'", "]", "=", "sys", ".", "platform", "\n", "env_info", "[", "'Python'", "]", "=", "sys", ".", "version", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "\n", "cuda_available", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "env_info", "[", "'CUDA available'", "]", "=", "cuda_available", "\n", "\n", "if", "cuda_available", ":", "\n", "        ", "from", "torch", ".", "utils", ".", "cpp_extension", "import", "CUDA_HOME", "\n", "env_info", "[", "'CUDA_HOME'", "]", "=", "CUDA_HOME", "\n", "\n", "if", "CUDA_HOME", "is", "not", "None", "and", "osp", ".", "isdir", "(", "CUDA_HOME", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "nvcc", "=", "osp", ".", "join", "(", "CUDA_HOME", ",", "'bin/nvcc'", ")", "\n", "nvcc", "=", "subprocess", ".", "check_output", "(", "\n", "f'\"{nvcc}\" -V | tail -n1'", ",", "shell", "=", "True", ")", "\n", "nvcc", "=", "nvcc", ".", "decode", "(", "'utf-8'", ")", ".", "strip", "(", ")", "\n", "", "except", "subprocess", ".", "SubprocessError", ":", "\n", "                ", "nvcc", "=", "'Not Available'", "\n", "", "env_info", "[", "'NVCC'", "]", "=", "nvcc", "\n", "\n", "", "devices", "=", "defaultdict", "(", "list", ")", "\n", "for", "k", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ":", "\n", "            ", "devices", "[", "torch", ".", "cuda", ".", "get_device_name", "(", "k", ")", "]", ".", "append", "(", "str", "(", "k", ")", ")", "\n", "", "for", "name", ",", "devids", "in", "devices", ".", "items", "(", ")", ":", "\n", "            ", "env_info", "[", "'GPU '", "+", "','", ".", "join", "(", "devids", ")", "]", "=", "name", "\n", "\n", "", "", "gcc", "=", "subprocess", ".", "check_output", "(", "'gcc --version | head -n1'", ",", "shell", "=", "True", ")", "\n", "gcc", "=", "gcc", ".", "decode", "(", "'utf-8'", ")", ".", "strip", "(", ")", "\n", "env_info", "[", "'GCC'", "]", "=", "gcc", "\n", "\n", "env_info", "[", "'PyTorch'", "]", "=", "torch", ".", "__version__", "\n", "env_info", "[", "'PyTorch compiling details'", "]", "=", "torch", ".", "__config__", ".", "show", "(", ")", "\n", "\n", "env_info", "[", "'TorchVision'", "]", "=", "torchvision", ".", "__version__", "\n", "\n", "env_info", "[", "'OpenCV'", "]", "=", "cv2", ".", "__version__", "\n", "\n", "env_info", "[", "'MMCV'", "]", "=", "mmcv", ".", "__version__", "\n", "env_info", "[", "'mmtrack'", "]", "=", "mmtrack", ".", "__version__", "\n", "\n", "return", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization.random_color": [[12, 18], ["random.seed", "seaborn.color_palette", "random.choice"], "function", ["None"], ["def", "random_color", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Random a color according to the input seed.\"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "colors", "=", "sns", ".", "color_palette", "(", ")", "\n", "color", "=", "random", ".", "choice", "(", "colors", ")", "\n", "return", "color", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization.imshow_tracks": [[20, 28], ["visualization._cv2_show_tracks", "visualization._plt_show_tracks", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization._cv2_show_tracks", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization._plt_show_tracks"], ["", "def", "imshow_tracks", "(", "*", "args", ",", "backend", "=", "'cv2'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Show the tracks on the input image.\"\"\"", "\n", "if", "backend", "==", "'cv2'", ":", "\n", "        ", "return", "_cv2_show_tracks", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "backend", "==", "'plt'", ":", "\n", "        ", "return", "_plt_show_tracks", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization._cv2_show_tracks": [[30, 90], ["isinstance", "numpy.clip", "numpy.clip", "zip", "mmcv.imread", "bbox[].astype", "float", "visualization.random_color", "cv2.rectangle", "str", "cv2.putText", "cv2.putText", "mmcv.imshow", "mmcv.imwrite", "len", "str", "len", "int"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization.random_color"], ["", "", "def", "_cv2_show_tracks", "(", "img", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "ids", ",", "\n", "classes", "=", "None", ",", "\n", "thickness", "=", "2", ",", "\n", "font_scale", "=", "0.4", ",", "\n", "show", "=", "False", ",", "\n", "out_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"Show the tracks with opencv.\"\"\"", "\n", "assert", "bboxes", ".", "ndim", "==", "2", "\n", "assert", "labels", ".", "ndim", "==", "1", "\n", "assert", "ids", ".", "ndim", "==", "1", "\n", "assert", "bboxes", ".", "shape", "[", "0", "]", "==", "labels", ".", "shape", "[", "0", "]", "\n", "assert", "bboxes", ".", "shape", "[", "1", "]", "==", "5", "\n", "if", "isinstance", "(", "img", ",", "str", ")", ":", "\n", "        ", "img", "=", "mmcv", ".", "imread", "(", "img", ")", "\n", "\n", "", "img_shape", "=", "img", ".", "shape", "\n", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "1", "]", ")", "\n", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "0", "]", ")", "\n", "\n", "text_width", ",", "text_height", "=", "10", ",", "15", "\n", "for", "bbox", ",", "label", ",", "id", "in", "zip", "(", "bboxes", ",", "labels", ",", "ids", ")", ":", "\n", "        ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "bbox", "[", ":", "4", "]", ".", "astype", "(", "np", ".", "int32", ")", "\n", "score", "=", "float", "(", "bbox", "[", "-", "1", "]", ")", "\n", "\n", "# bbox", "\n", "bbox_color", "=", "random_color", "(", "id", ")", "\n", "bbox_color", "=", "[", "int", "(", "255", "*", "_c", ")", "for", "_c", "in", "bbox_color", "]", "[", ":", ":", "-", "1", "]", "\n", "cv2", ".", "rectangle", "(", "img", ",", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ",", "bbox_color", ",", "thickness", "=", "thickness", ")", "\n", "\n", "# id", "\n", "text", "=", "str", "(", "id", ")", "\n", "width", "=", "len", "(", "text", ")", "*", "text_width", "\n", "img", "[", "y1", ":", "y1", "+", "text_height", ",", "x1", ":", "x1", "+", "width", ",", ":", "]", "=", "bbox_color", "\n", "cv2", ".", "putText", "(", "\n", "img", ",", "\n", "str", "(", "id", ")", ",", "(", "x1", ",", "y1", "+", "text_height", "-", "2", ")", ",", "\n", "cv2", ".", "FONT_HERSHEY_COMPLEX", ",", "\n", "font_scale", ",", "\n", "color", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "# score", "\n", "text", "=", "'{:.02f}'", ".", "format", "(", "score", ")", "\n", "width", "=", "len", "(", "text", ")", "*", "text_width", "\n", "img", "[", "y1", "-", "text_height", ":", "y1", ",", "x1", ":", "x1", "+", "width", ",", ":", "]", "=", "bbox_color", "\n", "cv2", ".", "putText", "(", "\n", "img", ",", "\n", "text", ",", "(", "x1", ",", "y1", "-", "2", ")", ",", "\n", "cv2", ".", "FONT_HERSHEY_COMPLEX", ",", "\n", "font_scale", ",", "\n", "color", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "if", "show", ":", "\n", "        ", "mmcv", ".", "imshow", "(", "img", ")", "\n", "", "if", "out_file", "is", "not", "None", ":", "\n", "        ", "mmcv", ".", "imwrite", "(", "img", ",", "out_file", ")", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization._plt_show_tracks": [[92, 159], ["isinstance", "numpy.clip", "numpy.clip", "matplotlib.imshow", "matplotlib.gca().set_axis_off", "matplotlib.autoscale", "matplotlib.subplots_adjust", "matplotlib.margins", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "zip", "matplotlib.show", "matplotlib.clf", "matplotlib.imread", "mmcv.bgr2rgb", "matplotlib.use", "matplotlib.use", "matplotlib.NullLocator", "matplotlib.NullLocator", "visualization.random_color", "matplotlib.gca().add_patch", "str", "matplotlib.gca().add_patch", "matplotlib.text", "matplotlib.savefig", "matplotlib.gca", "int", "int", "int", "int", "matplotlib.patches.Rectangle", "len", "matplotlib.patches.Rectangle", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization.random_color"], ["", "def", "_plt_show_tracks", "(", "img", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "ids", ",", "\n", "classes", "=", "None", ",", "\n", "thickness", "=", "1", ",", "\n", "font_scale", "=", "0.5", ",", "\n", "show", "=", "False", ",", "\n", "out_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"Show the tracks with matplotlib.\"\"\"", "\n", "assert", "bboxes", ".", "ndim", "==", "2", "\n", "assert", "labels", ".", "ndim", "==", "1", "\n", "assert", "ids", ".", "ndim", "==", "1", "\n", "assert", "bboxes", ".", "shape", "[", "0", "]", "==", "ids", ".", "shape", "[", "0", "]", "\n", "assert", "bboxes", ".", "shape", "[", "1", "]", "==", "4", "or", "bboxes", ".", "shape", "[", "1", "]", "==", "5", "\n", "\n", "if", "isinstance", "(", "img", ",", "str", ")", ":", "\n", "        ", "img", "=", "plt", ".", "imread", "(", "img", ")", "\n", "", "else", ":", "\n", "        ", "img", "=", "mmcv", ".", "bgr2rgb", "(", "img", ")", "\n", "\n", "", "img_shape", "=", "img", ".", "shape", "\n", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "1", "]", ")", "\n", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "0", "]", ")", "\n", "\n", "if", "not", "show", ":", "\n", "        ", "matplotlib", ".", "use", "(", "'Agg'", ")", "\n", "\n", "", "plt", ".", "imshow", "(", "img", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_axis_off", "(", ")", "\n", "plt", ".", "autoscale", "(", "False", ")", "\n", "plt", ".", "subplots_adjust", "(", "\n", "top", "=", "1", ",", "bottom", "=", "0", ",", "right", "=", "1", ",", "left", "=", "0", ",", "hspace", "=", "None", ",", "wspace", "=", "None", ")", "\n", "plt", ".", "margins", "(", "0", ",", "0", ")", "\n", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "plt", ".", "rcParams", "[", "'figure.figsize'", "]", "=", "img_shape", "[", "1", "]", ",", "img_shape", "[", "0", "]", "\n", "\n", "text_width", ",", "text_height", "=", "12", ",", "16", "\n", "for", "bbox", ",", "label", ",", "id", "in", "zip", "(", "bboxes", ",", "labels", ",", "ids", ")", ":", "\n", "        ", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "score", "=", "bbox", "\n", "w", ",", "h", "=", "int", "(", "x2", "-", "x1", ")", ",", "int", "(", "y2", "-", "y1", ")", "\n", "left_top", "=", "(", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", ")", "\n", "\n", "# bbox", "\n", "color", "=", "random_color", "(", "id", ")", "\n", "plt", ".", "gca", "(", ")", ".", "add_patch", "(", "\n", "Rectangle", "(", "\n", "left_top", ",", "w", ",", "h", ",", "thickness", ",", "edgecolor", "=", "color", ",", "facecolor", "=", "'none'", ")", ")", "\n", "\n", "# id", "\n", "text", "=", "str", "(", "id", ")", "\n", "width", "=", "len", "(", "text", ")", "*", "text_width", "\n", "plt", ".", "gca", "(", ")", ".", "add_patch", "(", "\n", "Rectangle", "(", "(", "left_top", "[", "0", "]", ",", "left_top", "[", "1", "]", ")", ",", "\n", "width", ",", "\n", "text_height", ",", "\n", "thickness", ",", "\n", "edgecolor", "=", "color", ",", "\n", "facecolor", "=", "color", ")", ")", "\n", "plt", ".", "text", "(", "left_top", "[", "0", "]", ",", "left_top", "[", "1", "]", "+", "text_height", "+", "2", ",", "text", ",", "fontsize", "=", "5", ")", "\n", "\n", "", "if", "out_file", "is", "not", "None", ":", "\n", "        ", "plt", ".", "savefig", "(", "out_file", ",", "dpi", "=", "300", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0.0", ")", "\n", "", "plt", ".", "show", "(", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.image.crop_image": [[5, 28], ["numpy.array().astype", "cv2.warpAffine", "numpy.array"], "function", ["None"], ["def", "crop_image", "(", "image", ",", "crop_region", ",", "crop_size", ",", "padding", "=", "(", "0", ",", "0", ",", "0", ")", ")", ":", "\n", "    ", "\"\"\"Crop image based on `crop_region` and `crop_size`.\n\n    Args:\n        image (ndarray): of shape (H, W, 3).\n        crop_region (ndarray): of shape (4, ) in [x1, y1, x2, y2] format.\n        crop_size (int): Crop size.\n        padding (tuple | ndarray): of shape (3, ) denoting the padding values.\n\n    Returns:\n        ndarray: Cropped image of shape (crop_size, crop_size, 3).\n    \"\"\"", "\n", "a", "=", "crop_size", "/", "(", "crop_region", "[", "2", "]", "-", "crop_region", "[", "0", "]", ")", "\n", "b", "=", "crop_size", "/", "(", "crop_region", "[", "3", "]", "-", "crop_region", "[", "1", "]", ")", "\n", "c", "=", "-", "a", "*", "crop_region", "[", "0", "]", "\n", "d", "=", "-", "b", "*", "crop_region", "[", "1", "]", "\n", "mapping", "=", "np", ".", "array", "(", "[", "[", "a", ",", "0", ",", "c", "]", ",", "[", "0", ",", "b", ",", "d", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "crop_image", "=", "cv2", ".", "warpAffine", "(", "\n", "image", ",", "\n", "mapping", ",", "(", "crop_size", ",", "crop_size", ")", ",", "\n", "borderMode", "=", "cv2", ".", "BORDER_CONSTANT", ",", "\n", "borderValue", "=", "padding", ")", "\n", "return", "crop_image", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.__init__": [[15, 18], ["coco_video_dataset.CocoVideoDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "load_as_video", "and", "not", "self", ".", "test_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.load_video_anns": [[19, 36], ["parsers.CocoVID", "sot_train_dataset.SOTTrainDataset.coco.get_vid_ids", "data_infos.append", "sot_train_dataset.SOTTrainDataset.coco.load_vids"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_vid_ids", "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.load_vids"], ["", "def", "load_video_anns", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCOVID style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCOVID api.\n        \"\"\"", "\n", "self", ".", "coco", "=", "CocoVID", "(", "ann_file", ",", "self", ".", "load_as_video", ")", "\n", "\n", "data_infos", "=", "[", "]", "\n", "self", ".", "vid_ids", "=", "self", ".", "coco", ".", "get_vid_ids", "(", ")", "\n", "for", "vid_id", "in", "self", ".", "vid_ids", ":", "\n", "            ", "info", "=", "self", ".", "coco", ".", "load_vids", "(", "[", "vid_id", "]", ")", "[", "0", "]", "\n", "data_infos", ".", "append", "(", "info", ")", "\n", "", "return", "data_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset._filter_imgs": [[37, 52], ["set", "enumerate", "valid_inds.append", "valid_vid_ids.append", "sot_train_dataset.SOTTrainDataset.coco.anns.values"], "methods", ["None"], ["", "def", "_filter_imgs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Filter videos without ground truths.\"\"\"", "\n", "valid_inds", "=", "[", "]", "\n", "# obtain videos that contain annotation", "\n", "ids_with_ann", "=", "set", "(", "_", "[", "'video_id'", "]", "for", "_", "in", "self", ".", "coco", ".", "anns", ".", "values", "(", ")", ")", "\n", "\n", "valid_vid_ids", "=", "[", "]", "\n", "for", "i", ",", "vid_info", "in", "enumerate", "(", "self", ".", "data_infos", ")", ":", "\n", "            ", "vid_id", "=", "self", ".", "vid_ids", "[", "i", "]", "\n", "if", "self", ".", "filter_empty_gt", "and", "vid_id", "not", "in", "ids_with_ann", ":", "\n", "                ", "continue", "\n", "", "valid_inds", ".", "append", "(", "i", ")", "\n", "valid_vid_ids", ".", "append", "(", "vid_id", ")", "\n", "", "self", ".", "vid_ids", "=", "valid_vid_ids", "\n", "return", "valid_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset._set_group_flag": [[53, 59], ["numpy.zeros", "len"], "methods", ["None"], ["", "def", "_set_group_flag", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set flag according to video aspect ratio.\n\n        It is not useful since all flags are set as 0.\n        \"\"\"", "\n", "self", ".", "flag", "=", "np", ".", "zeros", "(", "len", "(", "self", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.get_snippet_of_instance": [[60, 89], ["sot_train_dataset.SOTTrainDataset.coco.get_ins_ids_from_vid", "numpy.random.choice", "sot_train_dataset.SOTTrainDataset.coco.get_img_ids_from_ins_id", "numpy.random.choice", "len", "numpy.split", "snippets[].tolist", "numpy.array", "len", "numpy.where", "numpy.diff"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_ins_ids_from_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_ins_id"], ["", "def", "get_snippet_of_instance", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get a snippet of an instance in a video.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            tuple: (snippet, image_id, instance_id), snippet is a list\n            containing the successive image ids where the instance\n            appears, image_id is a random sampled image id from the\n            snippet.\n        \"\"\"", "\n", "vid_id", "=", "self", ".", "vid_ids", "[", "idx", "]", "\n", "instance_ids", "=", "self", ".", "coco", ".", "get_ins_ids_from_vid", "(", "vid_id", ")", "\n", "instance_id", "=", "np", ".", "random", ".", "choice", "(", "instance_ids", ")", "\n", "image_ids", "=", "self", ".", "coco", ".", "get_img_ids_from_ins_id", "(", "instance_id", ")", "\n", "if", "len", "(", "image_ids", ")", ">", "1", ":", "\n", "            ", "snippets", "=", "np", ".", "split", "(", "\n", "image_ids", ",", "\n", "np", ".", "array", "(", "np", ".", "where", "(", "np", ".", "diff", "(", "image_ids", ")", ">", "1", ")", "[", "0", "]", ")", "+", "1", ")", "\n", "# remove isolated frame", "\n", "snippets", "=", "[", "s", "for", "s", "in", "snippets", "if", "len", "(", "s", ")", ">", "1", "]", "\n", "# TODO: use random rather than -1", "\n", "snippet", "=", "snippets", "[", "-", "1", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "snippet", "=", "image_ids", "\n", "\n", "", "image_id", "=", "np", ".", "random", ".", "choice", "(", "snippet", ")", "\n", "return", "snippet", ",", "image_id", ",", "instance_id", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.ref_img_sampling": [[90, 167], ["isinstance", "ref_image_ids.append", "ref_instance_ids.append", "isinstance", "numpy.random.random", "snippet.index", "max", "numpy.random.choice", "sot_train_dataset.SOTTrainDataset.get_snippet_of_instance", "TypeError", "valid_ids.remove", "numpy.random.choice", "len", "isinstance", "range", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.get_snippet_of_instance"], ["", "def", "ref_img_sampling", "(", "self", ",", "\n", "snippet", ",", "\n", "image_id", ",", "\n", "instance_id", ",", "\n", "frame_range", "=", "5", ",", "\n", "pos_prob", "=", "0.8", ",", "\n", "filter_key_img", "=", "False", ",", "\n", "return_key_img", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Get a search image for an instance in an exemplar image.\n\n        If sampling a positive search image, the positive search image is\n        randomly sampled from the exemplar image, where the sampled range is\n        decided by `frame_range`.\n        If sampling a negative search image, the negative search image and\n        negative instance are randomly sampled from the entire dataset.\n\n        Args:\n            snippet (list[int]): The successive image ids where the instance\n                appears.\n            image_id (int): The id of exemplar image where the instance\n                appears.\n            instance_id (int): The id of the instance.\n            frame_range (List(int) | int): The frame range of sampling a\n                positive search image for the exemplar image. Default: 5.\n            pos_prob (float): The probability of sampling a positive search\n                image. Default: 0.8.\n            filter_key_img (bool): If False, the exemplar image will be in the\n                sampling candidates, otherwise, it is exclude. Default: False.\n            return_key_img (bool): If True, the `image_id` and `instance_id`\n                are returned, otherwise, not returned. Default: True.\n\n        Returns:\n            tuple: (image_ids, instance_ids, is_positive_pair), image_ids is\n            a list that must contain search image id and may contain\n            `image_id`, instance_ids is a list that must contain search\n            instance id and may contain `instance_id`, is_positive_pair is\n            a bool denoting postive or negative sample pair.\n        \"\"\"", "\n", "assert", "pos_prob", ">=", "0.0", "and", "pos_prob", "<=", "1.0", "\n", "if", "isinstance", "(", "frame_range", ",", "int", ")", ":", "\n", "            ", "assert", "frame_range", ">=", "0", ",", "'frame_range can not be a negative value.'", "\n", "frame_range", "=", "[", "-", "frame_range", ",", "frame_range", "]", "\n", "", "elif", "isinstance", "(", "frame_range", ",", "list", ")", ":", "\n", "            ", "assert", "len", "(", "frame_range", ")", "==", "2", ",", "'The length must be 2.'", "\n", "assert", "frame_range", "[", "0", "]", "<=", "0", "and", "frame_range", "[", "1", "]", ">=", "0", "\n", "for", "i", "in", "frame_range", ":", "\n", "                ", "assert", "isinstance", "(", "i", ",", "int", ")", ",", "'Each element must be int.'", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'The type of frame_range must be int or list.'", ")", "\n", "\n", "", "ref_image_ids", "=", "[", "]", "\n", "ref_instance_ids", "=", "[", "]", "\n", "if", "pos_prob", ">", "np", ".", "random", ".", "random", "(", ")", ":", "\n", "            ", "index", "=", "snippet", ".", "index", "(", "image_id", ")", "\n", "left", "=", "max", "(", "index", "+", "frame_range", "[", "0", "]", ",", "0", ")", "\n", "right", "=", "index", "+", "frame_range", "[", "1", "]", "+", "1", "\n", "valid_ids", "=", "snippet", "[", "left", ":", "right", "]", "\n", "if", "filter_key_img", "and", "image_id", "in", "valid_ids", ":", "\n", "                ", "valid_ids", ".", "remove", "(", "image_id", ")", "\n", "", "ref_image_id", "=", "np", ".", "random", ".", "choice", "(", "valid_ids", ")", "\n", "ref_instance_id", "=", "instance_id", "\n", "is_positive_pair", "=", "True", "\n", "", "else", ":", "\n", "            ", "(", "ref_snippet", ",", "ref_image_id", ",", "\n", "ref_instance_id", ")", "=", "self", ".", "get_snippet_of_instance", "(", "\n", "np", ".", "random", ".", "choice", "(", "range", "(", "len", "(", "self", ")", ")", ")", ")", "\n", "is_positive_pair", "=", "False", "\n", "\n", "", "ref_image_ids", ".", "append", "(", "ref_image_id", ")", "\n", "ref_instance_ids", ".", "append", "(", "ref_instance_id", ")", "\n", "\n", "if", "return_key_img", ":", "\n", "            ", "return", "[", "image_id", ",", "*", "ref_image_ids", "]", ",", "[", "instance_id", ",", "*", "ref_instance_ids", "]", ",", "is_positive_pair", "\n", "", "else", ":", "\n", "            ", "return", "ref_image_ids", ",", "ref_instance_ids", ",", "is_positive_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.prepare_results": [[168, 189], ["sot_train_dataset.SOTTrainDataset.coco.get_ann_ids", "sot_train_dataset.SOTTrainDataset.coco.load_anns", "sot_train_dataset.SOTTrainDataset._parse_ann_info", "dict", "sot_train_dataset.SOTTrainDataset.pre_pipeline", "sot_train_dataset.SOTTrainDataset.coco.load_imgs"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info"], ["", "", "def", "prepare_results", "(", "self", ",", "img_id", ",", "instance_id", ",", "is_positive_pair", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations.\n\n        Args:\n            img_id (int): The id of image.\n            instance_id (int): The id of instance.\n            is_positive_pair (bool): denoting postive or negative sample pair.\n\n        Returns:\n            dict: The information of training image and annotation.\n        \"\"\"", "\n", "img_info", "=", "self", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "img_info", "[", "'filename'", "]", "=", "img_info", "[", "'file_name'", "]", "\n", "ann_ids", "=", "self", ".", "coco", ".", "get_ann_ids", "(", "img_ids", "=", "[", "img_id", "]", ")", "\n", "ann_infos", "=", "self", ".", "coco", ".", "load_anns", "(", "ann_ids", ")", "\n", "ann", "=", "self", ".", "_parse_ann_info", "(", "instance_id", ",", "ann_infos", ")", "\n", "\n", "result", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann", ")", "\n", "self", ".", "pre_pipeline", "(", "result", ")", "\n", "result", "[", "'is_positive_pairs'", "]", "=", "is_positive_pair", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.prepare_train_img": [[190, 209], ["sot_train_dataset.SOTTrainDataset.get_snippet_of_instance", "sot_train_dataset.SOTTrainDataset.ref_img_sampling", "sot_train_dataset.SOTTrainDataset.pipeline", "sot_train_dataset.SOTTrainDataset.prepare_results", "zip"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset.get_snippet_of_instance", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results"], ["", "def", "prepare_train_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n            introduced by pipeline.\n        \"\"\"", "\n", "snippet", ",", "image_id", ",", "instance_id", "=", "self", ".", "get_snippet_of_instance", "(", "idx", ")", "\n", "image_ids", ",", "instance_ids", ",", "is_positive_pair", "=", "self", ".", "ref_img_sampling", "(", "\n", "snippet", ",", "image_id", ",", "instance_id", ",", "**", "self", ".", "ref_img_sampler", ")", "\n", "results", "=", "[", "\n", "self", ".", "prepare_results", "(", "img_id", ",", "instance_id", ",", "is_positive_pair", ")", "\n", "for", "img_id", ",", "instance_id", "in", "zip", "(", "image_ids", ",", "instance_ids", ")", "\n", "]", "\n", "results", "=", "self", ".", "pipeline", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.sot_train_dataset.SOTTrainDataset._parse_ann_info": [[210, 238], ["dict", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_parse_ann_info", "(", "self", ",", "instance_id", ",", "ann_infos", ")", ":", "\n", "        ", "\"\"\"Parse bbox annotation.\n\n        Parse a given instance annotation from annotation infos of an image.\n\n        Args:\n            instance_id (int): The instance_id of an image need be parsed.\n            ann_info (list[dict]): Annotation information of an image.\n\n        Returns:\n            dict: A dict containing the following keys: bboxes, labels. labels\n            is set to `np.array([0])`.\n        \"\"\"", "\n", "has_instance_id", "=", "0", "\n", "for", "ann_info", "in", "ann_infos", ":", "\n", "            ", "if", "ann_info", "[", "'instance_id'", "]", "==", "instance_id", ":", "\n", "                ", "has_instance_id", "=", "1", "\n", "break", "\n", "", "", "assert", "has_instance_id", "\n", "\n", "bbox", "=", "[", "[", "\n", "ann_info", "[", "'bbox'", "]", "[", "0", "]", ",", "ann_info", "[", "'bbox'", "]", "[", "1", "]", ",", "\n", "ann_info", "[", "'bbox'", "]", "[", "0", "]", "+", "ann_info", "[", "'bbox'", "]", "[", "2", "]", ",", "\n", "ann_info", "[", "'bbox'", "]", "[", "1", "]", "+", "ann_info", "[", "'bbox'", "]", "[", "3", "]", "\n", "]", "]", "\n", "ann", "=", "dict", "(", "\n", "bboxes", "=", "np", ".", "array", "(", "bbox", ",", "dtype", "=", "np", ".", "float32", ")", ",", "labels", "=", "np", ".", "array", "(", "[", "0", "]", ")", ")", "\n", "return", "ann", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.lasot_dataset.LaSOTDataset.__init__": [[18, 20], ["coco_video_dataset.CocoVideoDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.lasot_dataset.LaSOTDataset._parse_ann_info": [[21, 41], ["numpy.array", "numpy.array", "dict"], "methods", ["None"], ["", "def", "_parse_ann_info", "(", "self", ",", "img_info", ",", "ann_info", ")", ":", "\n", "        ", "\"\"\"Parse bbox annotations.\n\n        Args:\n            img_info (dict): image information.\n            ann_info (list[dict]): Annotation information of an image. Each\n                image only has one bbox annotation.\n\n        Returns:\n            dict: A dict containing the following keys: bboxes, labels,\n            ignore. labels are not useful in SOT.\n        \"\"\"", "\n", "gt_bboxes", "=", "np", ".", "array", "(", "ann_info", "[", "0", "]", "[", "'bbox'", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "# convert [x1, y1, w, h] to [x1, y1, x2, y2]", "\n", "gt_bboxes", "[", "2", "]", "+=", "gt_bboxes", "[", "0", "]", "\n", "gt_bboxes", "[", "3", "]", "+=", "gt_bboxes", "[", "1", "]", "\n", "gt_labels", "=", "np", ".", "array", "(", "self", ".", "cat2label", "[", "ann_info", "[", "0", "]", "[", "'category_id'", "]", "]", ")", "\n", "ignore", "=", "ann_info", "[", "0", "]", "[", "'full_occlusion'", "]", "or", "ann_info", "[", "0", "]", "[", "'out_of_view'", "]", "\n", "ann", "=", "dict", "(", "bboxes", "=", "gt_bboxes", ",", "labels", "=", "gt_labels", ",", "ignore", "=", "ignore", ")", "\n", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.lasot_dataset.LaSOTDataset.evaluate": [[42, 95], ["isinstance", "dict", "isinstance", "mmcv.utils.print_log", "len", "inds.append", "mmtrack.core.evaluation.eval_sot_ope", "dict.update", "dict.items", "mmcv.utils.print_log", "TypeError", "KeyError", "len", "len", "len", "lasot_dataset.LaSOTDataset.get_ann_info", "isinstance", "enumerate", "range", "range", "float"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.eval_sot_ope", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info"], ["", "def", "evaluate", "(", "self", ",", "results", ",", "metric", "=", "[", "'track'", "]", ",", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluation in OPE protocol.\n\n        Args:\n            results (dict): Testing results of the dataset.\n            metric (str | list[str]): Metrics to be evaluated. Options are\n                'track'.\n            logger (logging.Logger | str | None): Logger used for printing\n                related information during evaluation. Default: None.\n\n        Returns:\n            dict[str, float]: OPE style evaluation metric (i.e. success,\n            norm precision and precision).\n        \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "list", ")", ":", "\n", "            ", "metrics", "=", "metric", "\n", "", "elif", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metrics", "=", "[", "metric", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'metric must be a list or a str.'", ")", "\n", "", "allowed_metrics", "=", "[", "'track'", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported.'", ")", "\n", "\n", "", "", "eval_results", "=", "dict", "(", ")", "\n", "if", "'track'", "in", "metrics", ":", "\n", "            ", "assert", "len", "(", "self", ".", "data_infos", ")", "==", "len", "(", "results", "[", "'bbox'", "]", ")", "\n", "print_log", "(", "'Evaluate OPE Benchmark...'", ",", "logger", "=", "logger", ")", "\n", "inds", "=", "[", "\n", "i", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "data_infos", ")", "if", "_", "[", "'frame_id'", "]", "==", "0", "\n", "]", "\n", "num_vids", "=", "len", "(", "inds", ")", "\n", "inds", ".", "append", "(", "len", "(", "self", ".", "data_infos", ")", ")", "\n", "\n", "track_results", "=", "[", "\n", "results", "[", "'bbox'", "]", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", "for", "i", "in", "range", "(", "num_vids", ")", "\n", "]", "\n", "\n", "ann_infos", "=", "[", "self", ".", "get_ann_info", "(", "_", ")", "for", "_", "in", "self", ".", "data_infos", "]", "\n", "ann_infos", "=", "[", "\n", "ann_infos", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", "for", "i", "in", "range", "(", "num_vids", ")", "\n", "]", "\n", "track_eval_results", "=", "eval_sot_ope", "(", "\n", "results", "=", "track_results", ",", "annotations", "=", "ann_infos", ")", "\n", "eval_results", ".", "update", "(", "track_eval_results", ")", "\n", "\n", "for", "k", ",", "v", "in", "eval_results", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "float", ")", ":", "\n", "                    ", "eval_results", "[", "k", "]", "=", "float", "(", "f'{(v):.3f}'", ")", "\n", "", "", "print_log", "(", "eval_results", ",", "logger", "=", "logger", ")", "\n", "\n", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader": [[14, 76], ["mmcv.runner.get_dist_info", "torch.utils.data.DataLoader", "functools.partial", "mmdet.datasets.samplers.DistributedGroupSampler", "mmdet.datasets.samplers.GroupSampler", "functools.partial", "samplers.DistributedVideoSampler", "mmdet.datasets.samplers.DistributedSampler"], "function", ["None"], ["def", "build_dataloader", "(", "dataset", ",", "\n", "samples_per_gpu", ",", "\n", "workers_per_gpu", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Build PyTorch DataLoader.\n\n    In distributed training, each GPU/process has a dataloader.\n    In non-distributed training, there is only one dataloader for all GPUs.\n\n    Args:\n        dataset (Dataset): A PyTorch dataset.\n        samples_per_gpu (int): Number of training samples on each GPU, i.e.,\n            batch size of each GPU.\n        workers_per_gpu (int): How many subprocesses to use for data loading\n            for each GPU.\n        num_gpus (int): Number of GPUs. Only used in non-distributed training.\n        dist (bool): Distributed training/test or not. Default: True.\n        shuffle (bool): Whether to shuffle the data at every epoch.\n            Default: True.\n        kwargs: any keyword argument to be used to initialize DataLoader\n\n    Returns:\n        DataLoader: A PyTorch dataloader.\n    \"\"\"", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "dist", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "sampler", "=", "DistributedGroupSampler", "(", "dataset", ",", "samples_per_gpu", ",", "\n", "world_size", ",", "rank", ")", "\n", "", "else", ":", "\n", "            ", "if", "dataset", ".", "load_as_video", ":", "\n", "                ", "sampler", "=", "DistributedVideoSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "sampler", "=", "DistributedSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "False", ")", "\n", "", "", "batch_size", "=", "samples_per_gpu", "\n", "num_workers", "=", "workers_per_gpu", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "GroupSampler", "(", "dataset", ",", "samples_per_gpu", ")", "if", "shuffle", "else", "None", "\n", "batch_size", "=", "num_gpus", "*", "samples_per_gpu", "\n", "num_workers", "=", "num_gpus", "*", "workers_per_gpu", "\n", "\n", "", "init_fn", "=", "partial", "(", "\n", "worker_init_fn", ",", "num_workers", "=", "num_workers", ",", "rank", "=", "rank", ",", "\n", "seed", "=", "seed", ")", "if", "seed", "is", "not", "None", "else", "None", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "partial", "(", "collate", ",", "samples_per_gpu", "=", "samples_per_gpu", ")", ",", "\n", "pin_memory", "=", "False", ",", "\n", "worker_init_fn", "=", "init_fn", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.worker_init_fn": [[78, 84], ["numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "worker_init_fn", "(", "worker_id", ",", "num_workers", ",", "rank", ",", "seed", ")", ":", "\n", "# The seed of each worker equals to", "\n", "# num_worker * rank + worker_id + user_seed", "\n", "    ", "worker_seed", "=", "num_workers", "*", "rank", "+", "worker_id", "+", "seed", "\n", "np", ".", "random", ".", "seed", "(", "worker_seed", ")", "\n", "random", ".", "seed", "(", "worker_seed", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.__init__": [[29, 37], ["coco_video_dataset.CocoVideoDataset.__init__", "mot_challenge_dataset.MOTChallengeDataset.load_detections"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.load_detections"], ["def", "__init__", "(", "self", ",", "\n", "visibility_thr", "=", "-", "1", ",", "\n", "detection_file", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "visibility_thr", "=", "visibility_thr", "\n", "self", ".", "detections", "=", "self", ".", "load_detections", "(", "detection_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.load_detections": [[38, 60], ["mmcv.load", "isinstance", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "load_detections", "(", "self", ",", "detection_file", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load public detections.\"\"\"", "\n", "# support detections in three formats", "\n", "# 1. MMDet: [img_1, img_2, ...]", "\n", "# 2. MMTrack: dict(bbox_results=[img_1, img_2, ...])", "\n", "# 3. Public:", "\n", "#    1) dict(img1_name: [], img2_name: [], ...)", "\n", "#    2) dict(bbox_results=dict(img1_name: [], img2_name: [], ...))", "\n", "# return as a dict or a list", "\n", "if", "detection_file", "is", "not", "None", ":", "\n", "            ", "detections", "=", "mmcv", ".", "load", "(", "detection_file", ")", "\n", "if", "isinstance", "(", "detections", ",", "dict", ")", ":", "\n", "# results from mmtrack", "\n", "                ", "if", "'bbox_results'", "in", "detections", ":", "\n", "                    ", "detections", "=", "detections", "[", "'bbox_results'", "]", "\n", "", "", "else", ":", "\n", "# results from mmdet", "\n", "                ", "if", "not", "isinstance", "(", "detections", ",", "list", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "'detections must be a dict or a list.'", ")", "\n", "", "", "return", "detections", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.prepare_results": [[61, 71], ["super().prepare_results", "isinstance", "isinstance", "mot_challenge_dataset.MOTChallengeDataset.img_ids.index"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results"], ["", "", "def", "prepare_results", "(", "self", ",", "img_info", ")", ":", "\n", "        ", "\"\"\"Prepare results for image (e.g. the annotation information, ...).\"\"\"", "\n", "results", "=", "super", "(", ")", ".", "prepare_results", "(", "img_info", ")", "\n", "if", "self", ".", "detections", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "detections", ",", "dict", ")", ":", "\n", "                ", "indice", "=", "img_info", "[", "'file_name'", "]", "\n", "", "elif", "isinstance", "(", "self", ".", "detections", ",", "list", ")", ":", "\n", "                ", "indice", "=", "self", ".", "img_ids", ".", "index", "(", "img_info", "[", "'id'", "]", ")", "\n", "", "results", "[", "'detections'", "]", "=", "self", ".", "detections", "[", "indice", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset._parse_ann_info": [[72, 132], ["enumerate", "dict", "max", "max", "numpy.array", "numpy.array", "numpy.array", "numpy.zeros", "numpy.array", "numpy.array", "numpy.array", "numpy.zeros", "dict.get", "dict.get", "numpy.zeros.append", "numpy.zeros.append", "numpy.array.append", "numpy.array.append", "min", "max", "min", "max"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "_parse_ann_info", "(", "self", ",", "img_info", ",", "ann_info", ")", ":", "\n", "        ", "\"\"\"Parse bbox and mask annotation.\n\n        Args:\n            ann_info (list[dict]): Annotation info of an image.\n            with_mask (bool): Whether to parse mask annotations.\n\n        Returns:\n            dict: A dict containing the following keys: bboxes, bboxes_ignore,\\\n            labels, masks, seg_map. \"masks\" are raw annotations and not \\\n            decoded into binary masks.\n        \"\"\"", "\n", "gt_bboxes", "=", "[", "]", "\n", "gt_labels", "=", "[", "]", "\n", "gt_bboxes_ignore", "=", "[", "]", "\n", "gt_instance_ids", "=", "[", "]", "\n", "\n", "for", "i", ",", "ann", "in", "enumerate", "(", "ann_info", ")", ":", "\n", "            ", "if", "(", "not", "self", ".", "test_mode", ")", "and", "(", "ann", "[", "'visibility'", "]", "<", "\n", "self", ".", "visibility_thr", ")", ":", "\n", "                ", "continue", "\n", "", "x1", ",", "y1", ",", "w", ",", "h", "=", "ann", "[", "'bbox'", "]", "\n", "inter_w", "=", "max", "(", "0", ",", "min", "(", "x1", "+", "w", ",", "img_info", "[", "'width'", "]", ")", "-", "max", "(", "x1", ",", "0", ")", ")", "\n", "inter_h", "=", "max", "(", "0", ",", "min", "(", "y1", "+", "h", ",", "img_info", "[", "'height'", "]", ")", "-", "max", "(", "y1", ",", "0", ")", ")", "\n", "if", "inter_w", "*", "inter_h", "==", "0", ":", "\n", "                ", "continue", "\n", "", "if", "ann", "[", "'area'", "]", "<=", "0", "or", "w", "<", "1", "or", "h", "<", "1", ":", "\n", "                ", "continue", "\n", "", "if", "ann", "[", "'category_id'", "]", "not", "in", "self", ".", "cat_ids", ":", "\n", "                ", "continue", "\n", "", "bbox", "=", "[", "x1", ",", "y1", ",", "x1", "+", "w", ",", "y1", "+", "h", "]", "\n", "if", "ann", ".", "get", "(", "'ignore'", ",", "False", ")", "or", "ann", ".", "get", "(", "'iscrowd'", ",", "False", ")", ":", "\n", "# note: normally no `iscrowd` for MOT17Dataset", "\n", "                ", "gt_bboxes_ignore", ".", "append", "(", "bbox", ")", "\n", "", "else", ":", "\n", "                ", "gt_bboxes", ".", "append", "(", "bbox", ")", "\n", "gt_labels", ".", "append", "(", "self", ".", "cat2label", "[", "ann", "[", "'category_id'", "]", "]", ")", "\n", "gt_instance_ids", ".", "append", "(", "ann", "[", "'instance_id'", "]", ")", "\n", "\n", "", "", "if", "gt_bboxes", ":", "\n", "            ", "gt_bboxes", "=", "np", ".", "array", "(", "gt_bboxes", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "gt_labels", "=", "np", ".", "array", "(", "gt_labels", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "gt_instance_ids", "=", "np", ".", "array", "(", "gt_instance_ids", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "            ", "gt_bboxes", "=", "np", ".", "zeros", "(", "(", "0", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "gt_labels", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "gt_instance_ids", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "", "if", "gt_bboxes_ignore", ":", "\n", "            ", "gt_bboxes_ignore", "=", "np", ".", "array", "(", "gt_bboxes_ignore", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "gt_bboxes_ignore", "=", "np", ".", "zeros", "(", "(", "0", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "ann", "=", "dict", "(", "\n", "bboxes", "=", "gt_bboxes", ",", "\n", "labels", "=", "gt_labels", ",", "\n", "bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "instance_ids", "=", "gt_instance_ids", ")", "\n", "\n", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_results": [[133, 180], ["isinstance", "dict", "len", "inds.append", "mot_challenge_dataset.MOTChallengeDataset.coco.load_vids", "range", "tempfile.TemporaryDirectory", "os.exists", "os.exists", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "len", "mmcv.utils.print_log", "shutil.rmtree", "enumerate", "getattr", "getattr."], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.load_vids"], ["", "def", "format_results", "(", "self", ",", "results", ",", "resfile_path", "=", "None", ",", "metrics", "=", "[", "'track'", "]", ")", ":", "\n", "        ", "\"\"\"Format the results to txts (standard format for MOT Challenge).\n\n        Args:\n            results (dict(list[ndarray])): Testing results of the dataset.\n            resfile_path (str, optional): Path to save the formatted results.\n                Defaults to None.\n            metrics (list[str], optional): The results of the specifc metrics\n                will be formatted.. Defaults to ['track'].\n\n        Returns:\n            tuple: (resfiles, names, tmp_dir), resfiles is a dict containing\n            the filepaths, names is a list containing the name of the\n            videos, tmp_dir is the temporal directory created for saving\n            files.\n        \"\"\"", "\n", "assert", "isinstance", "(", "results", ",", "dict", ")", ",", "'results must be a dict.'", "\n", "if", "resfile_path", "is", "None", ":", "\n", "            ", "tmp_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", "\n", "resfile_path", "=", "tmp_dir", ".", "name", "\n", "", "else", ":", "\n", "            ", "tmp_dir", "=", "None", "\n", "if", "osp", ".", "exists", "(", "resfile_path", ")", ":", "\n", "                ", "print_log", "(", "'remove previous results.'", ",", "self", ".", "logger", ")", "\n", "import", "shutil", "\n", "shutil", ".", "rmtree", "(", "resfile_path", ")", "\n", "\n", "", "", "resfiles", "=", "dict", "(", ")", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "resfiles", "[", "metric", "]", "=", "osp", ".", "join", "(", "resfile_path", ",", "metric", ")", "\n", "os", ".", "makedirs", "(", "resfiles", "[", "metric", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "inds", "=", "[", "i", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "data_infos", ")", "if", "_", "[", "'frame_id'", "]", "==", "0", "]", "\n", "num_vids", "=", "len", "(", "inds", ")", "\n", "assert", "num_vids", "==", "len", "(", "self", ".", "vid_ids", ")", "\n", "inds", ".", "append", "(", "len", "(", "self", ".", "data_infos", ")", ")", "\n", "vid_infos", "=", "self", ".", "coco", ".", "load_vids", "(", "self", ".", "vid_ids", ")", "\n", "names", "=", "[", "_", "[", "'name'", "]", "for", "_", "in", "vid_infos", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_vids", ")", ":", "\n", "            ", "for", "metric", "in", "metrics", ":", "\n", "                ", "formatter", "=", "getattr", "(", "self", ",", "f'format_{metric}_results'", ")", "\n", "formatter", "(", "results", "[", "f'{metric}_results'", "]", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", ",", "\n", "self", ".", "data_infos", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", ",", "\n", "f'{resfiles[metric]}/{names[i]}.txt'", ")", "\n", "\n", "", "", "return", "resfiles", ",", "names", ",", "tmp_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_track_results": [[181, 195], ["open", "zip", "mmtrack.core.restore_result", "zip", "f.writelines"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result"], ["", "def", "format_track_results", "(", "self", ",", "results", ",", "infos", ",", "resfile", ")", ":", "\n", "        ", "\"\"\"Format tracking results.\"\"\"", "\n", "with", "open", "(", "resfile", ",", "'wt'", ")", "as", "f", ":", "\n", "            ", "for", "res", ",", "info", "in", "zip", "(", "results", ",", "infos", ")", ":", "\n", "                ", "if", "'mot_frame_id'", "in", "info", ":", "\n", "                    ", "frame", "=", "info", "[", "'mot_frame_id'", "]", "\n", "", "else", ":", "\n", "                    ", "frame", "=", "info", "[", "'frame_id'", "]", "+", "1", "\n", "", "bboxes", ",", "labels", ",", "ids", "=", "restore_result", "(", "res", ",", "return_ids", "=", "True", ")", "\n", "for", "bbox", ",", "label", ",", "id", "in", "zip", "(", "bboxes", ",", "labels", ",", "ids", ")", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "conf", "=", "bbox", "\n", "f", ".", "writelines", "(", "\n", "f'{frame},{id},{x1:.3f},{y1:.3f},{(x2-x1):.3f},'", "+", "\n", "f'{(y2-y1):.3f},{conf:.3f},-1,-1,-1\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_bbox_results": [[196, 211], ["open", "zip", "f.close", "mmtrack.core.restore_result", "zip", "f.writelines"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result"], ["", "", "", "", "def", "format_bbox_results", "(", "self", ",", "results", ",", "infos", ",", "resfile", ")", ":", "\n", "        ", "\"\"\"Format detection results.\"\"\"", "\n", "with", "open", "(", "resfile", ",", "'wt'", ")", "as", "f", ":", "\n", "            ", "for", "res", ",", "info", "in", "zip", "(", "results", ",", "infos", ")", ":", "\n", "                ", "if", "'mot_frame_id'", "in", "info", ":", "\n", "                    ", "frame", "=", "info", "[", "'mot_frame_id'", "]", "\n", "", "else", ":", "\n", "                    ", "frame", "=", "info", "[", "'frame_id'", "]", "+", "1", "\n", "", "bboxes", ",", "labels", "=", "restore_result", "(", "res", ")", "\n", "for", "bbox", ",", "label", "in", "zip", "(", "bboxes", ",", "labels", ")", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "conf", "=", "bbox", "\n", "f", ".", "writelines", "(", "\n", "f'{frame},-1,{x1:.3f},{y1:.3f},{(x2-x1):.3f},'", "+", "\n", "f'{(y2-y1):.3f},{conf:.3f}\\n'", ")", "\n", "", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.evaluate": [[212, 318], ["dict", "isinstance", "dict.items", "isinstance", "mot_challenge_dataset.MOTChallengeDataset.format_results", "mmcv.utils.print_log", "motmetrics.metrics.create", "motmetrics.metrics.create.compute_many", "motmetrics.io.render_summary", "print", "dict.update", "isinstance", "mmdet.core.eval_map", "isinstance", "TypeError", "KeyError", "os.join", "os.join", "motmetrics.io.loadtxt", "motmetrics.io.loadtxt", "os.join", "os.join", "os.exists", "os.exists", "accs.append", "tmp_dir.cleanup", "isinstance", "mot_challenge_dataset.MOTChallengeDataset.get_ann_info", "float", "os.join", "os.join", "motmetrics.utils.CLEAR_MOT_M", "motmetrics.utils.compare_to_groundtruth", "TypeError", "os.join", "os.join", "os.join", "os.join", "mm.metrics.create.compute_many.to_dict().items", "mm.metrics.create.compute_many.to_dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.format_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'track'", ",", "\n", "logger", "=", "None", ",", "\n", "resfile_path", "=", "None", ",", "\n", "bbox_iou_thr", "=", "0.5", ",", "\n", "track_iou_thr", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Evaluation in MOT Challenge.\n\n        Args:\n            results (list[list | tuple]): Testing results of the dataset.\n            metric (str | list[str]): Metrics to be evaluated. Options are\n                'bbox', 'track'. Defaults to 'track'.\n            logger (logging.Logger | str | None): Logger used for printing\n                related information during evaluation. Default: None.\n            resfile_path (str, optional): Path to save the formatted results.\n                Defaults to None.\n            bbox_iou_thr (float, optional): IoU threshold for detection\n                evaluation. Defaults to 0.5.\n            track_iou_thr (float, optional): IoU threshold for tracking\n                evaluation.. Defaults to 0.5.\n\n        Returns:\n            dict[str, float]: MOTChallenge style evaluation metric.\n        \"\"\"", "\n", "eval_results", "=", "dict", "(", ")", "\n", "if", "isinstance", "(", "metric", ",", "list", ")", ":", "\n", "            ", "metrics", "=", "metric", "\n", "", "elif", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metrics", "=", "[", "metric", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'metric must be a list or a str.'", ")", "\n", "", "allowed_metrics", "=", "[", "'bbox'", ",", "'track'", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported.'", ")", "\n", "\n", "", "", "if", "'track'", "in", "metrics", ":", "\n", "            ", "resfiles", ",", "names", ",", "tmp_dir", "=", "self", ".", "format_results", "(", "\n", "results", ",", "resfile_path", ",", "metrics", ")", "\n", "print_log", "(", "'Evaluate CLEAR MOT results.'", ",", "logger", "=", "logger", ")", "\n", "distth", "=", "1", "-", "track_iou_thr", "\n", "\n", "accs", "=", "[", "]", "\n", "for", "name", "in", "names", ":", "\n", "                ", "if", "'half-train'", "in", "self", ".", "ann_file", ":", "\n", "                    ", "gt_file", "=", "osp", ".", "join", "(", "self", ".", "img_prefix", ",", "\n", "f'{name}/gt/gt_half-train.txt'", ")", "\n", "", "elif", "'half-val'", "in", "self", ".", "ann_file", ":", "\n", "                    ", "gt_file", "=", "osp", ".", "join", "(", "self", ".", "img_prefix", ",", "\n", "f'{name}/gt/gt_half-val.txt'", ")", "\n", "", "else", ":", "\n", "                    ", "gt_file", "=", "osp", ".", "join", "(", "self", ".", "img_prefix", ",", "f'{name}/gt/gt.txt'", ")", "\n", "", "res_file", "=", "osp", ".", "join", "(", "resfiles", "[", "'track'", "]", ",", "f'{name}.txt'", ")", "\n", "gt", "=", "mm", ".", "io", ".", "loadtxt", "(", "gt_file", ")", "\n", "res", "=", "mm", ".", "io", ".", "loadtxt", "(", "res_file", ")", "\n", "ini_file", "=", "osp", ".", "join", "(", "self", ".", "img_prefix", ",", "f'{name}/seqinfo.ini'", ")", "\n", "if", "osp", ".", "exists", "(", "ini_file", ")", ":", "\n", "                    ", "acc", ",", "ana", "=", "mm", ".", "utils", ".", "CLEAR_MOT_M", "(", "\n", "gt", ",", "res", ",", "ini_file", ",", "distth", "=", "distth", ")", "\n", "", "else", ":", "\n", "                    ", "acc", "=", "mm", ".", "utils", ".", "compare_to_groundtruth", "(", "\n", "gt", ",", "res", ",", "distth", "=", "distth", ")", "\n", "", "accs", ".", "append", "(", "acc", ")", "\n", "\n", "", "mh", "=", "mm", ".", "metrics", ".", "create", "(", ")", "\n", "summary", "=", "mh", ".", "compute_many", "(", "\n", "accs", ",", "\n", "names", "=", "names", ",", "\n", "metrics", "=", "mm", ".", "metrics", ".", "motchallenge_metrics", ",", "\n", "generate_overall", "=", "True", ")", "\n", "str_summary", "=", "mm", ".", "io", ".", "render_summary", "(", "\n", "summary", ",", "\n", "formatters", "=", "mh", ".", "formatters", ",", "\n", "namemap", "=", "mm", ".", "io", ".", "motchallenge_metric_names", ")", "\n", "print", "(", "str_summary", ")", "\n", "\n", "eval_results", ".", "update", "(", "{", "\n", "mm", ".", "io", ".", "motchallenge_metric_names", "[", "k", "]", ":", "v", "[", "'OVERALL'", "]", "\n", "for", "k", ",", "v", "in", "summary", ".", "to_dict", "(", ")", ".", "items", "(", ")", "\n", "}", ")", "\n", "\n", "if", "tmp_dir", "is", "not", "None", ":", "\n", "                ", "tmp_dir", ".", "cleanup", "(", ")", "\n", "\n", "", "", "if", "'bbox'", "in", "metrics", ":", "\n", "            ", "if", "isinstance", "(", "results", ",", "dict", ")", ":", "\n", "                ", "bbox_results", "=", "results", "[", "'bbox_results'", "]", "\n", "", "elif", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "                ", "bbox_results", "=", "results", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'results must be a dict or a list.'", ")", "\n", "", "annotations", "=", "[", "self", ".", "get_ann_info", "(", "info", ")", "for", "info", "in", "self", ".", "data_infos", "]", "\n", "mean_ap", ",", "_", "=", "eval_map", "(", "\n", "bbox_results", ",", "\n", "annotations", ",", "\n", "iou_thr", "=", "bbox_iou_thr", ",", "\n", "dataset", "=", "self", ".", "CLASSES", ",", "\n", "logger", "=", "logger", ")", "\n", "eval_results", "[", "'mAP'", "]", "=", "mean_ap", "\n", "\n", "", "for", "k", ",", "v", "in", "eval_results", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "float", ")", ":", "\n", "                ", "eval_results", "[", "k", "]", "=", "float", "(", "f'{(v):.3f}'", ")", "\n", "\n", "", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.__init__": [[27, 46], ["dict", "dict", "mmdet.datasets.CocoDataset.__init__", "mmtrack.utils.get_root_logger"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger"], ["def", "__init__", "(", "self", ",", "\n", "load_as_video", "=", "True", ",", "\n", "key_img_sampler", "=", "dict", "(", "interval", "=", "1", ")", ",", "\n", "ref_img_sampler", "=", "dict", "(", "\n", "frame_range", "=", "10", ",", "\n", "stride", "=", "1", ",", "\n", "num_ref_imgs", "=", "1", ",", "\n", "filter_key_img", "=", "True", ",", "\n", "method", "=", "'uniform'", ",", "\n", "return_key_img", "=", "True", ")", ",", "\n", "test_load_ann", "=", "False", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "load_as_video", "=", "load_as_video", "\n", "self", ".", "key_img_sampler", "=", "key_img_sampler", "\n", "self", ".", "ref_img_sampler", "=", "ref_img_sampler", "\n", "self", ".", "test_load_ann", "=", "test_load_ann", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.load_annotations": [[47, 61], ["super().load_annotations", "coco_video_dataset.CocoVideoDataset.load_video_anns"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_annotations", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_video_anns"], ["", "def", "load_annotations", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCO/COCOVID style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCO/COCOVID api.\n        \"\"\"", "\n", "if", "not", "self", ".", "load_as_video", ":", "\n", "            ", "data_infos", "=", "super", "(", ")", ".", "load_annotations", "(", "ann_file", ")", "\n", "", "else", ":", "\n", "            ", "data_infos", "=", "self", ".", "load_video_anns", "(", "ann_file", ")", "\n", "", "return", "data_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.load_video_anns": [[62, 89], ["parsers.CocoVID", "coco_video_dataset.CocoVideoDataset.coco.get_cat_ids", "coco_video_dataset.CocoVideoDataset.coco.get_vid_ids", "coco_video_dataset.CocoVideoDataset.coco.get_img_ids_from_vid", "coco_video_dataset.CocoVideoDataset.img_ids.extend", "enumerate", "coco_video_dataset.CocoVideoDataset.key_img_sampling", "data_infos.append", "coco_video_dataset.CocoVideoDataset.coco.load_imgs"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_vid_ids", "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.key_img_sampling"], ["", "def", "load_video_anns", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCOVID style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCOVID api.\n        \"\"\"", "\n", "self", ".", "coco", "=", "CocoVID", "(", "ann_file", ")", "\n", "self", ".", "cat_ids", "=", "self", ".", "coco", ".", "get_cat_ids", "(", "cat_names", "=", "self", ".", "CLASSES", ")", "\n", "self", ".", "cat2label", "=", "{", "cat_id", ":", "i", "for", "i", ",", "cat_id", "in", "enumerate", "(", "self", ".", "cat_ids", ")", "}", "\n", "\n", "data_infos", "=", "[", "]", "\n", "self", ".", "vid_ids", "=", "self", ".", "coco", ".", "get_vid_ids", "(", ")", "\n", "self", ".", "img_ids", "=", "[", "]", "\n", "for", "vid_id", "in", "self", ".", "vid_ids", ":", "\n", "            ", "img_ids", "=", "self", ".", "coco", ".", "get_img_ids_from_vid", "(", "vid_id", ")", "\n", "if", "self", ".", "key_img_sampler", "is", "not", "None", ":", "\n", "                ", "img_ids", "=", "self", ".", "key_img_sampling", "(", "img_ids", ",", "\n", "**", "self", ".", "key_img_sampler", ")", "\n", "", "self", ".", "img_ids", ".", "extend", "(", "img_ids", ")", "\n", "for", "img_id", "in", "img_ids", ":", "\n", "                ", "info", "=", "self", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "info", "[", "'filename'", "]", "=", "info", "[", "'file_name'", "]", "\n", "data_infos", ".", "append", "(", "info", ")", "\n", "", "", "return", "data_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.key_img_sampling": [[90, 93], ["None"], "methods", ["None"], ["", "def", "key_img_sampling", "(", "self", ",", "img_ids", ",", "interval", "=", "1", ")", ":", "\n", "        ", "\"\"\"Sampling key images.\"\"\"", "\n", "return", "img_ids", "[", ":", ":", "interval", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling": [[94, 222], ["isinstance", "isinstance", "isinstance", "mmcv.utils.print_log", "range", "coco_video_dataset.CocoVideoDataset.coco.get_img_ids_from_vid", "max", "min", "sorted", "TypeError", "img_info.get", "sorted.append", "min", "ref_img_ids.extend", "sorted.append", "len", "isinstance", "img_info.copy", "len", "valid_ids.remove", "len", "random.sample", "coco_video_dataset.CocoVideoDataset.coco.load_imgs", "min", "random.sample", "ref_img_ids.extend", "valid_ids.remove", "len", "range", "float", "round", "ref_img_ids.append", "range", "range", "isinstance", "abs", "ref_img_ids.append", "min", "ref_img_ids.append", "min", "ref_img_ids.append", "len", "round", "round", "len", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_vid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "ref_img_sampling", "(", "self", ",", "\n", "img_info", ",", "\n", "frame_range", ",", "\n", "stride", "=", "1", ",", "\n", "num_ref_imgs", "=", "1", ",", "\n", "filter_key_img", "=", "True", ",", "\n", "method", "=", "'uniform'", ",", "\n", "return_key_img", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sampling reference frames in the same video for key frame.\n\n        Args:\n            img_info (dict): The information of key frame.\n            frame_range (List(int) | int): The sampling range of reference\n                frames in the same video for key frame.\n            stride (int): The sampling frame stride when sampling reference\n                images. Default: 1.\n            num_ref_imgs (int): The number of sampled reference images.\n                Default: 1.\n            filter_key_img (bool): If False, the key image will be in the\n                sampling reference candidates, otherwise, it is exclude.\n                Default: True.\n            method (str): The sampling method. Options are 'uniform',\n                'bilateral_uniform', 'test_with_adaptive_stride',\n                'test_with_fix_stride'. 'uniform' denotes reference images are\n                randomly sampled from the nearby frames of key frame.\n                'bilateral_uniform' denotes reference images are randomly\n                sampled from the two sides of the nearby frames of key frame.\n                'test_with_adaptive_stride' is only used in testing, and\n                denotes the sampling frame stride is equal to (video length /\n                the number of reference images). test_with_fix_stride is only\n                used in testing with sampling frame stride equalling to\n                `stride`. Default: 'uniform'.\n            return_key_img (bool): If True, the information of key frame is\n                returned, otherwise, not returned. Default: True.\n\n        Returns:\n            list(dict): `img_info` and the reference images informations or\n            only the reference images informations.\n        \"\"\"", "\n", "assert", "isinstance", "(", "img_info", ",", "dict", ")", "\n", "if", "isinstance", "(", "frame_range", ",", "int", ")", ":", "\n", "            ", "assert", "frame_range", ">=", "0", ",", "'frame_range can not be a negative value.'", "\n", "frame_range", "=", "[", "-", "frame_range", ",", "frame_range", "]", "\n", "", "elif", "isinstance", "(", "frame_range", ",", "list", ")", ":", "\n", "            ", "assert", "len", "(", "frame_range", ")", "==", "2", ",", "'The length must be 2.'", "\n", "assert", "frame_range", "[", "0", "]", "<=", "0", "and", "frame_range", "[", "1", "]", ">=", "0", "\n", "for", "i", "in", "frame_range", ":", "\n", "                ", "assert", "isinstance", "(", "i", ",", "int", ")", ",", "'Each element must be int.'", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'The type of frame_range must be int or list.'", ")", "\n", "\n", "", "if", "'test'", "in", "method", "and", "(", "frame_range", "[", "1", "]", "-", "frame_range", "[", "0", "]", ")", "!=", "num_ref_imgs", ":", "\n", "            ", "print_log", "(", "\n", "'Warning:'", "\n", "\"frame_range[1] - frame_range[0] isn't equal to num_ref_imgs.\"", "\n", "'Set num_ref_imgs to frame_range[1] - frame_range[0].'", ",", "\n", "logger", "=", "self", ".", "logger", ")", "\n", "self", ".", "ref_img_sampler", "[", "\n", "'num_ref_imgs'", "]", "=", "frame_range", "[", "1", "]", "-", "frame_range", "[", "0", "]", "\n", "\n", "", "if", "(", "not", "self", ".", "load_as_video", ")", "or", "img_info", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "<", "0", "or", "(", "frame_range", "[", "0", "]", "==", "0", "and", "frame_range", "[", "1", "]", "==", "0", ")", ":", "\n", "            ", "ref_img_infos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ref_imgs", ")", ":", "\n", "                ", "ref_img_infos", ".", "append", "(", "img_info", ".", "copy", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "vid_id", ",", "img_id", ",", "frame_id", "=", "img_info", "[", "'video_id'", "]", ",", "img_info", "[", "\n", "'id'", "]", ",", "img_info", "[", "'frame_id'", "]", "\n", "img_ids", "=", "self", ".", "coco", ".", "get_img_ids_from_vid", "(", "vid_id", ")", "\n", "left", "=", "max", "(", "0", ",", "frame_id", "+", "frame_range", "[", "0", "]", ")", "\n", "right", "=", "min", "(", "frame_id", "+", "frame_range", "[", "1", "]", ",", "len", "(", "img_ids", ")", "-", "1", ")", "\n", "\n", "ref_img_ids", "=", "[", "]", "\n", "if", "method", "==", "'uniform'", ":", "\n", "                ", "valid_ids", "=", "img_ids", "[", "left", ":", "right", "+", "1", "]", "\n", "if", "filter_key_img", "and", "img_id", "in", "valid_ids", ":", "\n", "                    ", "valid_ids", ".", "remove", "(", "img_id", ")", "\n", "", "num_samples", "=", "min", "(", "num_ref_imgs", ",", "len", "(", "valid_ids", ")", ")", "\n", "ref_img_ids", ".", "extend", "(", "random", ".", "sample", "(", "valid_ids", ",", "num_samples", ")", ")", "\n", "", "elif", "method", "==", "'bilateral_uniform'", ":", "\n", "                ", "assert", "num_ref_imgs", "%", "2", "==", "0", ",", "'only support load even number of ref_imgs.'", "\n", "for", "mode", "in", "[", "'left'", ",", "'right'", "]", ":", "\n", "                    ", "if", "mode", "==", "'left'", ":", "\n", "                        ", "valid_ids", "=", "img_ids", "[", "left", ":", "frame_id", "+", "1", "]", "\n", "", "else", ":", "\n", "                        ", "valid_ids", "=", "img_ids", "[", "frame_id", ":", "right", "+", "1", "]", "\n", "", "if", "filter_key_img", "and", "img_id", "in", "valid_ids", ":", "\n", "                        ", "valid_ids", ".", "remove", "(", "img_id", ")", "\n", "", "num_samples", "=", "min", "(", "num_ref_imgs", "//", "2", ",", "len", "(", "valid_ids", ")", ")", "\n", "sampled_inds", "=", "random", ".", "sample", "(", "valid_ids", ",", "num_samples", ")", "\n", "ref_img_ids", ".", "extend", "(", "sampled_inds", ")", "\n", "", "", "elif", "method", "==", "'test_with_adaptive_stride'", ":", "\n", "                ", "if", "frame_id", "==", "0", ":", "\n", "                    ", "stride", "=", "float", "(", "len", "(", "img_ids", ")", "-", "1", ")", "/", "(", "num_ref_imgs", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "num_ref_imgs", ")", ":", "\n", "                        ", "ref_id", "=", "round", "(", "i", "*", "stride", ")", "\n", "ref_img_ids", ".", "append", "(", "img_ids", "[", "ref_id", "]", ")", "\n", "", "", "", "elif", "method", "==", "'test_with_fix_stride'", ":", "\n", "                ", "if", "frame_id", "==", "0", ":", "\n", "                    ", "for", "i", "in", "range", "(", "frame_range", "[", "0", "]", ",", "1", ")", ":", "\n", "                        ", "ref_img_ids", ".", "append", "(", "img_ids", "[", "0", "]", ")", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frame_range", "[", "1", "]", "+", "1", ")", ":", "\n", "                        ", "ref_id", "=", "min", "(", "round", "(", "i", "*", "stride", ")", ",", "len", "(", "img_ids", ")", "-", "1", ")", "\n", "ref_img_ids", ".", "append", "(", "img_ids", "[", "ref_id", "]", ")", "\n", "", "", "elif", "frame_id", "%", "stride", "==", "0", ":", "\n", "                    ", "ref_id", "=", "min", "(", "\n", "round", "(", "frame_id", "+", "frame_range", "[", "1", "]", "*", "stride", ")", ",", "\n", "len", "(", "img_ids", ")", "-", "1", ")", "\n", "ref_img_ids", ".", "append", "(", "img_ids", "[", "ref_id", "]", ")", "\n", "", "img_info", "[", "'num_left_ref_imgs'", "]", "=", "abs", "(", "frame_range", "[", "0", "]", ")", "if", "isinstance", "(", "frame_range", ",", "list", ")", "else", "frame_range", "\n", "img_info", "[", "'frame_stride'", "]", "=", "stride", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "ref_img_infos", "=", "[", "]", "\n", "for", "ref_img_id", "in", "ref_img_ids", ":", "\n", "                ", "ref_img_info", "=", "self", ".", "coco", ".", "load_imgs", "(", "[", "ref_img_id", "]", ")", "[", "0", "]", "\n", "ref_img_info", "[", "'filename'", "]", "=", "ref_img_info", "[", "'file_name'", "]", "\n", "ref_img_infos", ".", "append", "(", "ref_img_info", ")", "\n", "", "ref_img_infos", "=", "sorted", "(", "ref_img_infos", ",", "key", "=", "lambda", "i", ":", "i", "[", "'frame_id'", "]", ")", "\n", "\n", "", "if", "return_key_img", ":", "\n", "            ", "return", "[", "img_info", ",", "*", "ref_img_infos", "]", "\n", "", "else", ":", "\n", "            ", "return", "ref_img_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info": [[223, 236], ["coco_video_dataset.CocoVideoDataset.coco.get_ann_ids", "coco_video_dataset.CocoVideoDataset.coco.load_anns", "coco_video_dataset.CocoVideoDataset._parse_ann_info"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info"], ["", "", "def", "get_ann_info", "(", "self", ",", "img_info", ")", ":", "\n", "        ", "\"\"\"Get COCO annotations by the information of image.\n\n        Args:\n            img_info (int): Information of image.\n\n        Returns:\n            dict: Annotation information of `img_info`.\n        \"\"\"", "\n", "img_id", "=", "img_info", "[", "'id'", "]", "\n", "ann_ids", "=", "self", ".", "coco", ".", "get_ann_ids", "(", "img_ids", "=", "[", "img_id", "]", ",", "cat_ids", "=", "self", ".", "cat_ids", ")", "\n", "ann_info", "=", "self", ".", "coco", ".", "load_anns", "(", "ann_ids", ")", "\n", "return", "self", ".", "_parse_ann_info", "(", "img_info", ",", "ann_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results": [[237, 249], ["dict", "super().pre_pipeline", "coco_video_dataset.CocoVideoDataset.get_ann_info", "coco_video_dataset.CocoVideoDataset.img_ids.index"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info"], ["", "def", "prepare_results", "(", "self", ",", "img_info", ")", ":", "\n", "        ", "\"\"\"Prepare results for image (e.g. the annotation information, ...).\"\"\"", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ")", "\n", "if", "not", "self", ".", "test_mode", "or", "self", ".", "test_load_ann", ":", "\n", "            ", "results", "[", "'ann_info'", "]", "=", "self", ".", "get_ann_info", "(", "img_info", ")", "\n", "", "if", "self", ".", "proposals", "is", "not", "None", ":", "\n", "            ", "idx", "=", "self", ".", "img_ids", ".", "index", "(", "img_info", "[", "'id'", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "self", ".", "proposals", "[", "idx", "]", "\n", "\n", "", "super", "(", ")", ".", "pre_pipeline", "(", "results", ")", "\n", "results", "[", "'is_video_data'", "]", "=", "self", ".", "load_as_video", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_data": [[250, 269], ["coco_video_dataset.CocoVideoDataset.pipeline", "coco_video_dataset.CocoVideoDataset.ref_img_sampling", "coco_video_dataset.CocoVideoDataset.prepare_results", "coco_video_dataset.CocoVideoDataset.prepare_results"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results"], ["", "def", "prepare_data", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Data and annotations after pipeline with new keys introduced\n            by pipeline.\n        \"\"\"", "\n", "img_info", "=", "self", ".", "data_infos", "[", "idx", "]", "\n", "if", "self", ".", "ref_img_sampler", "is", "not", "None", ":", "\n", "            ", "img_infos", "=", "self", ".", "ref_img_sampling", "(", "img_info", ",", "**", "self", ".", "ref_img_sampler", ")", "\n", "results", "=", "[", "\n", "self", ".", "prepare_results", "(", "img_info", ")", "for", "img_info", "in", "img_infos", "\n", "]", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "prepare_results", "(", "img_info", ")", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_train_img": [[270, 281], ["coco_video_dataset.CocoVideoDataset.prepare_data"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_data"], ["", "def", "prepare_train_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotations after pipeline with new keys\n            introduced by pipeline.\n        \"\"\"", "\n", "return", "self", ".", "prepare_data", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_test_img": [[282, 293], ["coco_video_dataset.CocoVideoDataset.prepare_data"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_data"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get testing data after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Testing data after pipeline with new keys intorduced by\n            pipeline.\n        \"\"\"", "\n", "return", "self", ".", "prepare_data", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info": [[294, 362], ["enumerate", "img_info[].replace", "dict", "dict.get", "max", "max", "dict.get", "numpy.array", "numpy.array", "numpy.zeros", "numpy.array", "numpy.array", "numpy.zeros", "numpy.array().astype", "numpy.arange", "numpy.zeros.append", "numpy.zeros.append", "numpy.array.append", "len", "min", "max", "min", "max", "gt_masks.append", "gt_instance_ids.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "_parse_ann_info", "(", "self", ",", "img_info", ",", "ann_info", ")", ":", "\n", "        ", "\"\"\"Parse bbox and mask annotations.\n\n        Args:\n            img_anfo (dict): Information of image.\n            ann_info (list[dict]): Annotation information of image.\n\n        Returns:\n            dict: A dict containing the following keys: bboxes, bboxes_ignore,\n            labels, instance_ids, masks, seg_map. \"masks\" are raw\n            annotations and not decoded into binary masks.\n        \"\"\"", "\n", "gt_bboxes", "=", "[", "]", "\n", "gt_labels", "=", "[", "]", "\n", "gt_bboxes_ignore", "=", "[", "]", "\n", "gt_masks", "=", "[", "]", "\n", "gt_instance_ids", "=", "[", "]", "\n", "\n", "for", "i", ",", "ann", "in", "enumerate", "(", "ann_info", ")", ":", "\n", "            ", "if", "ann", ".", "get", "(", "'ignore'", ",", "False", ")", ":", "\n", "                ", "continue", "\n", "", "x1", ",", "y1", ",", "w", ",", "h", "=", "ann", "[", "'bbox'", "]", "\n", "inter_w", "=", "max", "(", "0", ",", "min", "(", "x1", "+", "w", ",", "img_info", "[", "'width'", "]", ")", "-", "max", "(", "x1", ",", "0", ")", ")", "\n", "inter_h", "=", "max", "(", "0", ",", "min", "(", "y1", "+", "h", ",", "img_info", "[", "'height'", "]", ")", "-", "max", "(", "y1", ",", "0", ")", ")", "\n", "if", "inter_w", "*", "inter_h", "==", "0", ":", "\n", "                ", "continue", "\n", "", "if", "ann", "[", "'area'", "]", "<=", "0", "or", "w", "<", "1", "or", "h", "<", "1", ":", "\n", "                ", "continue", "\n", "", "if", "ann", "[", "'category_id'", "]", "not", "in", "self", ".", "cat_ids", ":", "\n", "                ", "continue", "\n", "", "bbox", "=", "[", "x1", ",", "y1", ",", "x1", "+", "w", ",", "y1", "+", "h", "]", "\n", "if", "ann", ".", "get", "(", "'iscrowd'", ",", "False", ")", ":", "\n", "                ", "gt_bboxes_ignore", ".", "append", "(", "bbox", ")", "\n", "", "else", ":", "\n", "                ", "gt_bboxes", ".", "append", "(", "bbox", ")", "\n", "gt_labels", ".", "append", "(", "self", ".", "cat2label", "[", "ann", "[", "'category_id'", "]", "]", ")", "\n", "if", "'segmentation'", "in", "ann", ":", "\n", "                    ", "gt_masks", ".", "append", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "", "if", "'instance_id'", "in", "ann", ":", "\n", "                    ", "gt_instance_ids", ".", "append", "(", "ann", "[", "'instance_id'", "]", ")", "\n", "\n", "", "", "", "if", "gt_bboxes", ":", "\n", "            ", "gt_bboxes", "=", "np", ".", "array", "(", "gt_bboxes", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "gt_labels", "=", "np", ".", "array", "(", "gt_labels", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "            ", "gt_bboxes", "=", "np", ".", "zeros", "(", "(", "0", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "gt_labels", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "", "if", "gt_bboxes_ignore", ":", "\n", "            ", "gt_bboxes_ignore", "=", "np", ".", "array", "(", "gt_bboxes_ignore", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "gt_bboxes_ignore", "=", "np", ".", "zeros", "(", "(", "0", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "seg_map", "=", "img_info", "[", "'filename'", "]", ".", "replace", "(", "'jpg'", ",", "'png'", ")", "\n", "\n", "ann", "=", "dict", "(", "\n", "bboxes", "=", "gt_bboxes", ",", "\n", "labels", "=", "gt_labels", ",", "\n", "bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "masks", "=", "gt_masks", ",", "\n", "seg_map", "=", "seg_map", ")", "\n", "\n", "if", "self", ".", "load_as_video", ":", "\n", "            ", "ann", "[", "'instance_ids'", "]", "=", "np", ".", "array", "(", "gt_instance_ids", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "", "else", ":", "\n", "            ", "ann", "[", "'instance_ids'", "]", "=", "np", ".", "arange", "(", "len", "(", "gt_labels", ")", ")", "\n", "\n", "", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate": [[363, 451], ["dict", "dict", "isinstance", "dict", "isinstance", "len", "inds.append", "mmtrack.core.eval_mot", "dict.update", "isinstance", "super().evaluate", "dict.update", "TypeError", "KeyError", "len", "len", "len", "coco_video_dataset.CocoVideoDataset.get_ann_info", "isinstance", "enumerate", "range", "range", "zip", "TypeError", "super_results.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.eval_mot", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "[", "'bbox'", ",", "'track'", "]", ",", "\n", "logger", "=", "None", ",", "\n", "bbox_kwargs", "=", "dict", "(", "\n", "classwise", "=", "False", ",", "\n", "proposal_nums", "=", "(", "100", ",", "300", ",", "1000", ")", ",", "\n", "iou_thrs", "=", "None", ",", "\n", "metric_items", "=", "None", ")", ",", "\n", "track_kwargs", "=", "dict", "(", "\n", "iou_thr", "=", "0.5", ",", "\n", "ignore_iof_thr", "=", "0.5", ",", "\n", "ignore_by_classes", "=", "False", ",", "\n", "nproc", "=", "4", ")", ")", ":", "\n", "        ", "\"\"\"Evaluation in COCO protocol and CLEAR MOT metric (e.g. MOTA, IDF1).\n\n        Args:\n            results (dict): Testing results of the dataset.\n            metric (str | list[str]): Metrics to be evaluated. Options are\n                'bbox', 'segm', 'track'.\n            logger (logging.Logger | str | None): Logger used for printing\n                related information during evaluation. Default: None.\n            bbox_kwargs (dict): Configuration for COCO styple evaluation.\n            track_kwargs (dict): Configuration for CLEAR MOT evaluation.\n\n        Returns:\n            dict[str, float]: COCO style and CLEAR MOT evaluation metric.\n        \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "list", ")", ":", "\n", "            ", "metrics", "=", "metric", "\n", "", "elif", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metrics", "=", "[", "metric", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'metric must be a list or a str.'", ")", "\n", "", "allowed_metrics", "=", "[", "'bbox'", ",", "'segm'", ",", "'track'", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported.'", ")", "\n", "\n", "", "", "eval_results", "=", "dict", "(", ")", "\n", "if", "'track'", "in", "metrics", ":", "\n", "            ", "assert", "len", "(", "self", ".", "data_infos", ")", "==", "len", "(", "results", "[", "'track_results'", "]", ")", "\n", "inds", "=", "[", "\n", "i", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "data_infos", ")", "if", "_", "[", "'frame_id'", "]", "==", "0", "\n", "]", "\n", "num_vids", "=", "len", "(", "inds", ")", "\n", "inds", ".", "append", "(", "len", "(", "self", ".", "data_infos", ")", ")", "\n", "\n", "track_results", "=", "[", "\n", "results", "[", "'track_results'", "]", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", "\n", "for", "i", "in", "range", "(", "num_vids", ")", "\n", "]", "\n", "ann_infos", "=", "[", "self", ".", "get_ann_info", "(", "_", ")", "for", "_", "in", "self", ".", "data_infos", "]", "\n", "ann_infos", "=", "[", "\n", "ann_infos", "[", "inds", "[", "i", "]", ":", "inds", "[", "i", "+", "1", "]", "]", "for", "i", "in", "range", "(", "num_vids", ")", "\n", "]", "\n", "track_eval_results", "=", "eval_mot", "(", "\n", "results", "=", "track_results", ",", "\n", "annotations", "=", "ann_infos", ",", "\n", "logger", "=", "logger", ",", "\n", "classes", "=", "self", ".", "CLASSES", ",", "\n", "**", "track_kwargs", ")", "\n", "eval_results", ".", "update", "(", "track_eval_results", ")", "\n", "\n", "# evaluate for detectors without tracker", "\n", "", "super_metrics", "=", "[", "'bbox'", ",", "'segm'", "]", "\n", "super_metrics", "=", "[", "_", "for", "_", "in", "metrics", "if", "_", "in", "super_metrics", "]", "\n", "if", "super_metrics", ":", "\n", "            ", "if", "isinstance", "(", "results", ",", "dict", ")", ":", "\n", "                ", "if", "'bbox'", "in", "super_metrics", "and", "'segm'", "in", "super_metrics", ":", "\n", "                    ", "super_results", "=", "[", "]", "\n", "for", "bbox", ",", "segm", "in", "zip", "(", "results", "[", "'bbox_results'", "]", ",", "\n", "results", "[", "'segm_results'", "]", ")", ":", "\n", "                        ", "super_results", ".", "append", "(", "(", "bbox", ",", "segm", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "super_results", "=", "results", "[", "'bbox_results'", "]", "\n", "", "", "elif", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "                ", "super_results", "=", "results", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Results must be a dict or a list.'", ")", "\n", "", "super_eval_results", "=", "super", "(", ")", ".", "evaluate", "(", "\n", "results", "=", "super_results", ",", "\n", "metric", "=", "super_metrics", ",", "\n", "logger", "=", "logger", ",", "\n", "**", "bbox_kwargs", ")", "\n", "eval_results", ".", "update", "(", "super_eval_results", ")", "\n", "\n", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.__init__": [[19, 21], ["coco_video_dataset.CocoVideoDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_annotations": [[22, 36], ["imagenet_vid_dataset.ImagenetVIDDataset.load_video_anns", "imagenet_vid_dataset.ImagenetVIDDataset.load_image_anns"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_video_anns", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_image_anns"], ["", "def", "load_annotations", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCO/COCOVID style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCO/COCOVID api.\n        \"\"\"", "\n", "if", "self", ".", "load_as_video", ":", "\n", "            ", "data_infos", "=", "self", ".", "load_video_anns", "(", "ann_file", ")", "\n", "", "else", ":", "\n", "            ", "data_infos", "=", "self", ".", "load_image_anns", "(", "ann_file", ")", "\n", "", "return", "data_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_image_anns": [[37, 60], ["pycocotools.coco.COCO", "imagenet_vid_dataset.ImagenetVIDDataset.coco.get_cat_ids", "imagenet_vid_dataset.ImagenetVIDDataset.coco.get_img_ids", "enumerate", "imagenet_vid_dataset.ImagenetVIDDataset.coco.load_imgs", "imagenet_vid_dataset.ImagenetVIDDataset.img_ids.append", "data_infos.append"], "methods", ["None"], ["", "def", "load_image_anns", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCO style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCO api.\n        \"\"\"", "\n", "self", ".", "coco", "=", "COCO", "(", "ann_file", ")", "\n", "self", ".", "cat_ids", "=", "self", ".", "coco", ".", "get_cat_ids", "(", "cat_names", "=", "self", ".", "CLASSES", ")", "\n", "self", ".", "cat2label", "=", "{", "cat_id", ":", "i", "for", "i", ",", "cat_id", "in", "enumerate", "(", "self", ".", "cat_ids", ")", "}", "\n", "\n", "all_img_ids", "=", "self", ".", "coco", ".", "get_img_ids", "(", ")", "\n", "self", ".", "img_ids", "=", "[", "]", "\n", "data_infos", "=", "[", "]", "\n", "for", "img_id", "in", "all_img_ids", ":", "\n", "            ", "info", "=", "self", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "info", "[", "'filename'", "]", "=", "info", "[", "'file_name'", "]", "\n", "if", "info", "[", "'is_vid_train_frame'", "]", ":", "\n", "                ", "self", ".", "img_ids", ".", "append", "(", "img_id", ")", "\n", "data_infos", ".", "append", "(", "info", ")", "\n", "", "", "return", "data_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.imagenet_vid_dataset.ImagenetVIDDataset.load_video_anns": [[61, 91], ["parsers.CocoVID", "imagenet_vid_dataset.ImagenetVIDDataset.coco.get_cat_ids", "imagenet_vid_dataset.ImagenetVIDDataset.coco.get_vid_ids", "imagenet_vid_dataset.ImagenetVIDDataset.coco.get_img_ids_from_vid", "enumerate", "imagenet_vid_dataset.ImagenetVIDDataset.coco.load_imgs", "imagenet_vid_dataset.ImagenetVIDDataset.img_ids.append", "data_infos.append", "imagenet_vid_dataset.ImagenetVIDDataset.img_ids.append", "data_infos.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_vid_ids", "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_vid"], ["", "def", "load_video_anns", "(", "self", ",", "ann_file", ")", ":", "\n", "        ", "\"\"\"Load annotations from COCOVID style annotation file.\n\n        Args:\n            ann_file (str): Path of annotation file.\n\n        Returns:\n            list[dict]: Annotation information from COCOVID api.\n        \"\"\"", "\n", "self", ".", "coco", "=", "CocoVID", "(", "ann_file", ")", "\n", "self", ".", "cat_ids", "=", "self", ".", "coco", ".", "get_cat_ids", "(", "cat_names", "=", "self", ".", "CLASSES", ")", "\n", "self", ".", "cat2label", "=", "{", "cat_id", ":", "i", "for", "i", ",", "cat_id", "in", "enumerate", "(", "self", ".", "cat_ids", ")", "}", "\n", "\n", "data_infos", "=", "[", "]", "\n", "self", ".", "vid_ids", "=", "self", ".", "coco", ".", "get_vid_ids", "(", ")", "\n", "self", ".", "img_ids", "=", "[", "]", "\n", "for", "vid_id", "in", "self", ".", "vid_ids", ":", "\n", "            ", "img_ids", "=", "self", ".", "coco", ".", "get_img_ids_from_vid", "(", "vid_id", ")", "\n", "for", "img_id", "in", "img_ids", ":", "\n", "                ", "info", "=", "self", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "info", "[", "'filename'", "]", "=", "info", "[", "'file_name'", "]", "\n", "if", "self", ".", "test_mode", ":", "\n", "                    ", "assert", "not", "info", "[", "'is_vid_train_frame'", "]", ",", "'is_vid_train_frame must be False in testing'", "\n", "self", ".", "img_ids", ".", "append", "(", "img_id", ")", "\n", "data_infos", ".", "append", "(", "info", ")", "\n", "", "elif", "info", "[", "'is_vid_train_frame'", "]", ":", "\n", "                    ", "self", ".", "img_ids", ".", "append", "(", "img_id", ")", "\n", "data_infos", ".", "append", "(", "info", ")", "\n", "", "", "", "return", "data_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.samplers.distributed_video_sampler.DistributedVideoSampler.__init__": [[18, 40], ["torch.utils.data.DistributedSampler.__init__", "len", "enumerate", "numpy.array_split", "split_flags.append", "len", "ValueError", "list", "first_frame_indices.append", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "assert", "not", "self", ".", "shuffle", ",", "'Specific for video sequential testing.'", "\n", "self", ".", "num_samples", "=", "len", "(", "dataset", ")", "\n", "\n", "first_frame_indices", "=", "[", "]", "\n", "for", "i", ",", "img_info", "in", "enumerate", "(", "self", ".", "dataset", ".", "data_infos", ")", ":", "\n", "            ", "if", "img_info", "[", "'frame_id'", "]", "==", "0", ":", "\n", "                ", "first_frame_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "", "if", "len", "(", "first_frame_indices", ")", "<", "num_replicas", ":", "\n", "            ", "raise", "ValueError", "(", "f'only {len(first_frame_indices)} videos loaded,'", "\n", "f'but {self.num_replicas} gpus were given.'", ")", "\n", "\n", "", "chunks", "=", "np", ".", "array_split", "(", "first_frame_indices", ",", "self", ".", "num_replicas", ")", "\n", "split_flags", "=", "[", "c", "[", "0", "]", "for", "c", "in", "chunks", "]", "\n", "split_flags", ".", "append", "(", "self", ".", "num_samples", ")", "\n", "\n", "self", ".", "indices", "=", "[", "\n", "list", "(", "range", "(", "split_flags", "[", "i", "]", ",", "split_flags", "[", "i", "+", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_replicas", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.samplers.distributed_video_sampler.DistributedVideoSampler.__iter__": [[42, 46], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Put videos to specify gpu.\"\"\"", "\n", "indices", "=", "self", ".", "indices", "[", "self", ".", "rank", "]", "\n", "return", "iter", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.__init__": [[25, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "context_amount", "=", "0.5", ",", "exemplar_size", "=", "127", ",", "crop_size", "=", "511", ")", ":", "\n", "        ", "self", ".", "context_amount", "=", "context_amount", "\n", "self", ".", "exemplar_size", "=", "exemplar_size", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.crop_like_SiamFC": [[30, 70], ["numpy.mean().tolist", "numpy.array", "numpy.sqrt", "numpy.array", "mmtrack.core.crop_image", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.image.crop_image"], ["", "def", "crop_like_SiamFC", "(", "self", ",", "\n", "image", ",", "\n", "bbox", ",", "\n", "context_amount", "=", "0.5", ",", "\n", "exemplar_size", "=", "127", ",", "\n", "crop_size", "=", "511", ")", ":", "\n", "        ", "\"\"\"Crop an image as SiamFC did.\n\n        Args:\n            image (ndarray): of shape (H, W, 3).\n            bbox (ndarray): of shape (4, ) in [x1, y1, x2, y2] format.\n            context_amount (float): The context amount around a bounding box.\n                Defaults to 0.5.\n            exemplar_size (int): Exemplar size. Defaults to 127.\n            crop_size (int): Crop size. Defaults to 511.\n\n        Returns:\n            ndarray: The cropped image of shape (crop_size, crop_size, 3).\n        \"\"\"", "\n", "padding", "=", "np", ".", "mean", "(", "image", ",", "axis", "=", "(", "0", ",", "1", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "bbox", "=", "np", ".", "array", "(", "[", "\n", "0.5", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "0", "]", ")", ",", "0.5", "*", "(", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", ")", ",", "\n", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", "\n", "]", ")", "\n", "z_width", "=", "bbox", "[", "2", "]", "+", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_height", "=", "bbox", "[", "3", "]", "+", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_size", "=", "np", ".", "sqrt", "(", "z_width", "*", "z_height", ")", "\n", "\n", "z_scale", "=", "exemplar_size", "/", "z_size", "\n", "d_search", "=", "(", "crop_size", "-", "exemplar_size", ")", "/", "2", "\n", "pad", "=", "d_search", "/", "z_scale", "\n", "x_size", "=", "z_size", "+", "2", "*", "pad", "\n", "x_bbox", "=", "np", ".", "array", "(", "[", "\n", "bbox", "[", "0", "]", "-", "0.5", "*", "x_size", ",", "bbox", "[", "1", "]", "-", "0.5", "*", "x_size", ",", "\n", "bbox", "[", "0", "]", "+", "0.5", "*", "x_size", ",", "bbox", "[", "1", "]", "+", "0.5", "*", "x_size", "\n", "]", ")", "\n", "\n", "x_crop_img", "=", "crop_image", "(", "image", ",", "x_bbox", ",", "crop_size", ",", "padding", ")", "\n", "return", "x_crop_img", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.generate_box": [[71, 99], ["numpy.sqrt", "numpy.array"], "methods", ["None"], ["", "def", "generate_box", "(", "self", ",", "image", ",", "gt_bbox", ",", "context_amount", ",", "exemplar_size", ")", ":", "\n", "        ", "\"\"\"Generate box based on cropped image.\n\n        Args:\n            image (ndarray): The cropped image of shape\n                (self.crop_size, self.crop_size, 3).\n            gt_bbox (ndarray): of shape (4, ) in [x1, y1, x2, y2] format.\n            context_amount (float): The context amount around a bounding box.\n            exemplar_size (int): Exemplar size. Defaults to 127.\n\n        Returns:\n            ndarray: Generated box of shape (4, ) in [x1, y1, x2, y2] format.\n        \"\"\"", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "w", ",", "h", "=", "gt_bbox", "[", "2", "]", "-", "gt_bbox", "[", "0", "]", ",", "gt_bbox", "[", "3", "]", "-", "gt_bbox", "[", "1", "]", "\n", "\n", "z_width", "=", "w", "+", "context_amount", "*", "(", "w", "+", "h", ")", "\n", "z_height", "=", "h", "+", "context_amount", "*", "(", "w", "+", "h", ")", "\n", "z_scale", "=", "np", ".", "sqrt", "(", "z_width", "*", "z_height", ")", "\n", "z_scale_factor", "=", "exemplar_size", "/", "z_scale", "\n", "w", "=", "w", "*", "z_scale_factor", "\n", "h", "=", "h", "*", "z_scale_factor", "\n", "cx", ",", "cy", "=", "img_w", "//", "2", ",", "img_h", "//", "2", "\n", "bbox", "=", "np", ".", "array", "(", "\n", "[", "cx", "-", "0.5", "*", "w", ",", "cy", "-", "0.5", "*", "h", ",", "cx", "+", "0.5", "*", "w", ",", "cy", "+", "0.5", "*", "h", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.__call__": [[100, 134], ["transforms.SeqCropLikeSiamFC.crop_like_SiamFC", "transforms.SeqCropLikeSiamFC.generate_box", "outs.append", "_results.get", "_results.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.crop_like_SiamFC", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqCropLikeSiamFC.generate_box", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, crop image like SiamFC did.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains cropped image and\n            corresponding ground truth box.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "image", "=", "_results", "[", "'img'", "]", "\n", "gt_bbox", "=", "_results", "[", "_results", ".", "get", "(", "'bbox_fields'", ",", "[", "]", ")", "[", "0", "]", "]", "[", "0", "]", "\n", "\n", "crop_img", "=", "self", ".", "crop_like_SiamFC", "(", "image", ",", "gt_bbox", ",", "\n", "self", ".", "context_amount", ",", "\n", "self", ".", "exemplar_size", ",", "\n", "self", ".", "crop_size", ")", "\n", "generated_bbox", "=", "self", ".", "generate_box", "(", "crop_img", ",", "gt_bbox", ",", "\n", "self", ".", "context_amount", ",", "\n", "self", ".", "exemplar_size", ")", "\n", "generated_bbox", "=", "generated_bbox", "[", "None", "]", "\n", "\n", "_results", "[", "'img'", "]", "=", "crop_img", "\n", "if", "'img_shape'", "in", "_results", ":", "\n", "                ", "_results", "[", "'img_shape'", "]", "=", "crop_img", ".", "shape", "\n", "", "_results", "[", "_results", ".", "get", "(", "'bbox_fields'", ",", "[", "]", ")", "[", "0", "]", "]", "=", "generated_bbox", "\n", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqShiftScaleAug.__init__": [[149, 156], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "target_size", "=", "[", "127", ",", "255", "]", ",", "\n", "shift", "=", "[", "4", ",", "64", "]", ",", "\n", "scale", "=", "[", "0.05", ",", "0.18", "]", ")", ":", "\n", "        ", "self", ".", "target_size", "=", "target_size", "\n", "self", ".", "shift", "=", "shift", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqShiftScaleAug._shift_scale_aug": [[157, 199], ["min", "min", "numpy.array", "max", "max", "numpy.array", "mmtrack.core.crop_image", "numpy.array", "numpy.array", "min", "min", "float", "float", "numpy.random.random", "numpy.random.random", "numpy.random.random", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.image.crop_image"], ["", "def", "_shift_scale_aug", "(", "self", ",", "image", ",", "bbox", ",", "target_size", ",", "shift", ",", "scale", ")", ":", "\n", "        ", "\"\"\"Shift and rescale an image and corresponding bounding box.\n\n        Args:\n            image (ndarray): of shape (H, W, 3). Typically H and W equal to\n                511.\n            bbox (ndarray): of shape (4, ) in [x1, y1, x2, y2] format.\n            target_size (int): Exemplar size or search size.\n            shift (int): The max shift offset.\n            scale (float): The max rescale factor.\n\n        Returns:\n            tuple(crop_img, bbox): crop_img is a ndarray of shape\n            (target_size, target_size, 3), bbox is the corrsponding ground\n            truth box in [x1, y1, x2, y2] format.\n        \"\"\"", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "scale_x", "=", "(", "2", "*", "np", ".", "random", ".", "random", "(", ")", "-", "1", ")", "*", "scale", "+", "1", "\n", "scale_y", "=", "(", "2", "*", "np", ".", "random", ".", "random", "(", ")", "-", "1", ")", "*", "scale", "+", "1", "\n", "scale_x", "=", "min", "(", "scale_x", ",", "float", "(", "img_w", ")", "/", "target_size", ")", "\n", "scale_y", "=", "min", "(", "scale_y", ",", "float", "(", "img_h", ")", "/", "target_size", ")", "\n", "crop_region", "=", "np", ".", "array", "(", "[", "\n", "img_w", "//", "2", "-", "0.5", "*", "scale_x", "*", "target_size", ",", "\n", "img_h", "//", "2", "-", "0.5", "*", "scale_y", "*", "target_size", ",", "\n", "img_w", "//", "2", "+", "0.5", "*", "scale_x", "*", "target_size", ",", "\n", "img_h", "//", "2", "+", "0.5", "*", "scale_y", "*", "target_size", "\n", "]", ")", "\n", "\n", "shift_x", "=", "(", "2", "*", "np", ".", "random", ".", "random", "(", ")", "-", "1", ")", "*", "shift", "\n", "shift_y", "=", "(", "2", "*", "np", ".", "random", ".", "random", "(", ")", "-", "1", ")", "*", "shift", "\n", "shift_x", "=", "max", "(", "-", "crop_region", "[", "0", "]", ",", "min", "(", "img_w", "-", "crop_region", "[", "2", "]", ",", "shift_x", ")", ")", "\n", "shift_y", "=", "max", "(", "-", "crop_region", "[", "1", "]", ",", "min", "(", "img_h", "-", "crop_region", "[", "3", "]", ",", "shift_y", ")", ")", "\n", "shift", "=", "np", ".", "array", "(", "[", "shift_x", ",", "shift_y", ",", "shift_x", ",", "shift_y", "]", ")", "\n", "crop_region", "+=", "shift", "\n", "\n", "crop_img", "=", "crop_image", "(", "image", ",", "crop_region", ",", "target_size", ")", "\n", "bbox", "-=", "np", ".", "array", "(", "\n", "[", "crop_region", "[", "0", "]", ",", "crop_region", "[", "1", "]", ",", "crop_region", "[", "0", "]", ",", "crop_region", "[", "1", "]", "]", ")", "\n", "bbox", "/=", "np", ".", "array", "(", "[", "scale_x", ",", "scale_y", ",", "scale_x", ",", "scale_y", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "crop_img", ",", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqShiftScaleAug.__call__": [[200, 230], ["enumerate", "transforms.SeqShiftScaleAug._shift_scale_aug", "outs.append", "_results.get", "_results.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqShiftScaleAug._shift_scale_aug", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, shift and rescale the image and the bounding\n        box in the dict.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains cropped image and\n            corresponding ground truth box.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "_results", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "image", "=", "_results", "[", "'img'", "]", "\n", "gt_bbox", "=", "_results", "[", "_results", ".", "get", "(", "'bbox_fields'", ",", "[", "]", ")", "[", "0", "]", "]", "[", "0", "]", "\n", "\n", "crop_img", ",", "crop_bbox", "=", "self", ".", "_shift_scale_aug", "(", "\n", "image", ",", "gt_bbox", ",", "self", ".", "target_size", "[", "i", "]", ",", "self", ".", "shift", "[", "i", "]", ",", "\n", "self", ".", "scale", "[", "i", "]", ")", "\n", "crop_bbox", "=", "crop_bbox", "[", "None", "]", "\n", "\n", "_results", "[", "'img'", "]", "=", "crop_img", "\n", "if", "'img_shape'", "in", "_results", ":", "\n", "                ", "_results", "[", "'img_shape'", "]", "=", "crop_img", ".", "shape", "\n", "", "_results", "[", "_results", ".", "get", "(", "'bbox_fields'", ",", "[", "]", ")", "[", "0", "]", "]", "=", "crop_bbox", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqColorAug.__init__": [[245, 252], ["numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "prob", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "rgb_var", "=", "[", "[", "-", "0.55919361", ",", "0.98062831", ",", "-", "0.41940627", "]", ",", "\n", "[", "1.72091413", ",", "0.19879334", ",", "-", "1.82968581", "]", ",", "\n", "[", "4.64467907", ",", "4.73710203", ",", "4.88324118", "]", "]", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "rgb_var", "=", "np", ".", "array", "(", "rgb_var", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqColorAug.__call__": [[253, 280], ["enumerate", "outs.append", "numpy.random.random", "numpy.dot", "offset.reshape.reshape.reshape", "numpy.random.randn"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, perform color augmention for image in the\n        dict.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains augmented color image.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "_results", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "image", "=", "_results", "[", "'img'", "]", "\n", "\n", "if", "self", ".", "prob", "[", "i", "]", ">", "np", ".", "random", ".", "random", "(", ")", ":", "\n", "                ", "offset", "=", "np", ".", "dot", "(", "self", ".", "rgb_var", ",", "np", ".", "random", ".", "randn", "(", "3", ",", "1", ")", ")", "\n", "# bgr to rgb", "\n", "offset", "=", "offset", "[", ":", ":", "-", "1", "]", "\n", "offset", "=", "offset", ".", "reshape", "(", "3", ")", "\n", "image", "=", "(", "image", "-", "offset", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "_results", "[", "'img'", "]", "=", "image", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqBlurAug.__init__": [[291, 293], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "prob", "=", "[", "0.0", ",", "0.2", "]", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqBlurAug.__call__": [[294, 324], ["enumerate", "outs.append", "numpy.random.random", "numpy.arange", "numpy.random.choice", "numpy.zeros", "int", "numpy.random.random", "cv2.filter2D"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, perform blur augmention for image in the\n        dict.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains augmented blur image.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "_results", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "image", "=", "_results", "[", "'img'", "]", "\n", "\n", "if", "self", ".", "prob", "[", "i", "]", ">", "np", ".", "random", ".", "random", "(", ")", ":", "\n", "                ", "sizes", "=", "np", ".", "arange", "(", "5", ",", "46", ",", "2", ")", "\n", "size", "=", "np", ".", "random", ".", "choice", "(", "sizes", ")", "\n", "kernel", "=", "np", ".", "zeros", "(", "(", "size", ",", "size", ")", ")", "\n", "c", "=", "int", "(", "size", "/", "2", ")", "\n", "wx", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "kernel", "[", ":", ",", "c", "]", "+=", "1.", "/", "size", "*", "wx", "\n", "kernel", "[", "c", ",", ":", "]", "+=", "1.", "/", "size", "*", "(", "1", "-", "wx", ")", "\n", "image", "=", "cv2", ".", "filter2D", "(", "image", ",", "-", "1", ",", "kernel", ")", "\n", "\n", "", "_results", "[", "'img'", "]", "=", "image", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqResize.__init__": [[338, 341], ["mmdet.datasets.pipelines.Resize.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "share_params", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "share_params", "=", "share_params", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqResize.__call__": [[342, 366], ["enumerate", "super().__call__", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, call the call function of `Resize` to resize\n        image and corresponding annotations.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains resized results,\n            'img_shape', 'pad_shape', 'scale_factor', 'keep_ratio' keys\n            are added into result dict.\n        \"\"\"", "\n", "outs", ",", "scale", "=", "[", "]", ",", "None", "\n", "for", "i", ",", "_results", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "if", "self", ".", "share_params", "and", "i", ">", "0", ":", "\n", "                ", "_results", "[", "'scale'", "]", "=", "scale", "\n", "", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "if", "self", ".", "share_params", "and", "i", "==", "0", ":", "\n", "                ", "scale", "=", "_results", "[", "'scale'", "]", "\n", "", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqNormalize.__init__": [[376, 378], ["mmdet.datasets.pipelines.Normalize.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqNormalize.__call__": [[379, 398], ["super().__call__", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, call the call function of `Normalize` to\n        normalize image.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains normalized results,\n            'img_norm_cfg' key is added into result dict.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomFlip.__init__": [[412, 415], ["mmdet.datasets.pipelines.RandomFlip.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "share_params", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "share_params", "=", "share_params", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomFlip.__call__": [[416, 460], ["isinstance", "isinstance", "numpy.random.choice", "super().__call__", "outs.append", "sum", "len", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, call `RandomFlip` to randomly flip image.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains flipped results, 'flip',\n            'flip_direction' keys are added into the dict.\n        \"\"\"", "\n", "if", "self", ".", "share_params", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "direction", ",", "list", ")", ":", "\n", "# None means non-flip", "\n", "                ", "direction_list", "=", "self", ".", "direction", "+", "[", "None", "]", "\n", "", "else", ":", "\n", "# None means non-flip", "\n", "                ", "direction_list", "=", "[", "self", ".", "direction", ",", "None", "]", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "flip_ratio", ",", "list", ")", ":", "\n", "                ", "non_flip_ratio", "=", "1", "-", "sum", "(", "self", ".", "flip_ratio", ")", "\n", "flip_ratio_list", "=", "self", ".", "flip_ratio", "+", "[", "non_flip_ratio", "]", "\n", "", "else", ":", "\n", "                ", "non_flip_ratio", "=", "1", "-", "self", ".", "flip_ratio", "\n", "# exclude non-flip", "\n", "single_ratio", "=", "self", ".", "flip_ratio", "/", "(", "len", "(", "direction_list", ")", "-", "1", ")", "\n", "flip_ratio_list", "=", "[", "single_ratio", "]", "*", "(", "len", "(", "direction_list", ")", "-", "\n", "1", ")", "+", "[", "non_flip_ratio", "]", "\n", "\n", "", "cur_dir", "=", "np", ".", "random", ".", "choice", "(", "direction_list", ",", "p", "=", "flip_ratio_list", ")", "\n", "flip", "=", "cur_dir", "is", "not", "None", "\n", "flip_direction", "=", "cur_dir", "\n", "\n", "for", "_results", "in", "results", ":", "\n", "                ", "_results", "[", "'flip'", "]", "=", "flip", "\n", "_results", "[", "'flip_direction'", "]", "=", "flip_direction", "\n", "\n", "", "", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPad.__init__": [[470, 472], ["mmdet.datasets.pipelines.Pad.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPad.__call__": [[473, 492], ["super().__call__", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, call the call function of `Pad` to pad image.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains padding results,\n            'pad_shape', 'pad_fixed_size' and 'pad_size_divisor' keys are\n            added into the dict.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.__init__": [[522, 540], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "crop_size", ",", "\n", "allow_negative_crop", "=", "False", ",", "\n", "share_params", "=", "False", ",", "\n", "bbox_clip_border", "=", "False", ")", ":", "\n", "        ", "assert", "crop_size", "[", "0", "]", ">", "0", "and", "crop_size", "[", "1", "]", ">", "0", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "allow_negative_crop", "=", "allow_negative_crop", "\n", "self", ".", "share_params", "=", "share_params", "\n", "self", ".", "bbox_clip_border", "=", "bbox_clip_border", "\n", "# The key correspondence from bboxes to labels and masks.", "\n", "self", ".", "bbox2label", "=", "{", "\n", "'gt_bboxes'", ":", "[", "'gt_labels'", ",", "'gt_instance_ids'", "]", ",", "\n", "'gt_bboxes_ignore'", ":", "[", "'gt_labels_ignore'", ",", "'gt_instance_ids_ignore'", "]", "\n", "}", "\n", "self", ".", "bbox2mask", "=", "{", "\n", "'gt_bboxes'", ":", "'gt_masks'", ",", "\n", "'gt_bboxes_ignore'", ":", "'gt_masks_ignore'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.get_offsets": [[542, 549], ["max", "max", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "get_offsets", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Random generate the offsets for cropping.\"\"\"", "\n", "margin_h", "=", "max", "(", "img", ".", "shape", "[", "0", "]", "-", "self", ".", "crop_size", "[", "0", "]", ",", "0", ")", "\n", "margin_w", "=", "max", "(", "img", ".", "shape", "[", "1", "]", "-", "self", ".", "crop_size", "[", "1", "]", ",", "0", ")", "\n", "offset_h", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_h", "+", "1", ")", "\n", "offset_w", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_w", "+", "1", ")", "\n", "return", "offset_h", ",", "offset_w", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.random_crop": [[550, 614], ["results.get", "results.get", "results.get", "numpy.array", "transforms.SeqRandomCrop.bbox2label.get", "transforms.SeqRandomCrop.bbox2mask.get", "transforms.SeqRandomCrop.get_offsets", "numpy.clip", "numpy.clip", "[].crop", "valid_inds.any", "numpy.asarray", "valid_inds.nonzero"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.get_offsets"], ["", "def", "random_crop", "(", "self", ",", "results", ",", "offsets", "=", "None", ")", ":", "\n", "        ", "\"\"\"Call function to randomly crop images, bounding boxes, masks,\n        semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n            offsets (tuple, optional): Pre-defined offsets for cropping.\n                Default to None.\n\n        Returns:\n            dict: Randomly cropped results, 'img_shape' key in result dict is\n            updated according to crop size.\n        \"\"\"", "\n", "\n", "for", "key", "in", "results", ".", "get", "(", "'img_fields'", ",", "[", "'img'", "]", ")", ":", "\n", "            ", "img", "=", "results", "[", "key", "]", "\n", "if", "offsets", "is", "not", "None", ":", "\n", "                ", "offset_h", ",", "offset_w", "=", "offsets", "\n", "", "else", ":", "\n", "                ", "offset_h", ",", "offset_w", "=", "self", ".", "get_offsets", "(", "img", ")", "\n", "", "results", "[", "'img_info'", "]", "[", "'crop_offsets'", "]", "=", "(", "offset_h", ",", "offset_w", ")", "\n", "crop_y1", ",", "crop_y2", "=", "offset_h", ",", "offset_h", "+", "self", ".", "crop_size", "[", "0", "]", "\n", "crop_x1", ",", "crop_x2", "=", "offset_w", ",", "offset_w", "+", "self", ".", "crop_size", "[", "1", "]", "\n", "\n", "# crop the image", "\n", "img", "=", "img", "[", "crop_y1", ":", "crop_y2", ",", "crop_x1", ":", "crop_x2", ",", "...", "]", "\n", "img_shape", "=", "img", ".", "shape", "\n", "results", "[", "key", "]", "=", "img", "\n", "", "results", "[", "'img_shape'", "]", "=", "img_shape", "\n", "\n", "# crop bboxes accordingly and clip to the image boundary", "\n", "for", "key", "in", "results", ".", "get", "(", "'bbox_fields'", ",", "[", "]", ")", ":", "\n", "# e.g. gt_bboxes and gt_bboxes_ignore", "\n", "            ", "bbox_offset", "=", "np", ".", "array", "(", "[", "offset_w", ",", "offset_h", ",", "offset_w", ",", "offset_h", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "bboxes", "=", "results", "[", "key", "]", "-", "bbox_offset", "\n", "if", "self", ".", "bbox_clip_border", ":", "\n", "                ", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "1", "]", ")", "\n", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", ",", "0", ",", "img_shape", "[", "0", "]", ")", "\n", "", "valid_inds", "=", "(", "bboxes", "[", ":", ",", "2", "]", ">", "bboxes", "[", ":", ",", "0", "]", ")", "&", "(", "\n", "bboxes", "[", ":", ",", "3", "]", ">", "bboxes", "[", ":", ",", "1", "]", ")", "\n", "# If the crop does not contain any gt-bbox area and", "\n", "# self.allow_negative_crop is False, skip this image.", "\n", "if", "(", "key", "==", "'gt_bboxes'", "and", "not", "valid_inds", ".", "any", "(", ")", "\n", "and", "not", "self", ".", "allow_negative_crop", ")", ":", "\n", "                ", "return", "None", "\n", "", "results", "[", "key", "]", "=", "bboxes", "[", "valid_inds", ",", ":", "]", "\n", "# label fields. e.g. gt_labels and gt_labels_ignore", "\n", "label_keys", "=", "self", ".", "bbox2label", ".", "get", "(", "key", ")", "\n", "for", "label_key", "in", "label_keys", ":", "\n", "                ", "if", "label_key", "in", "results", ":", "\n", "                    ", "results", "[", "label_key", "]", "=", "results", "[", "label_key", "]", "[", "valid_inds", "]", "\n", "\n", "# mask fields, e.g. gt_masks and gt_masks_ignore", "\n", "", "", "mask_key", "=", "self", ".", "bbox2mask", ".", "get", "(", "key", ")", "\n", "if", "mask_key", "in", "results", ":", "\n", "                ", "results", "[", "mask_key", "]", "=", "results", "[", "mask_key", "]", "[", "\n", "valid_inds", ".", "nonzero", "(", ")", "[", "0", "]", "]", ".", "crop", "(", "\n", "np", ".", "asarray", "(", "[", "crop_x1", ",", "crop_y1", ",", "crop_x2", ",", "crop_y2", "]", ")", ")", "\n", "\n", "# crop semantic seg", "\n", "", "", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "            ", "results", "[", "key", "]", "=", "results", "[", "key", "]", "[", "crop_y1", ":", "crop_y2", ",", "crop_x1", ":", "crop_x2", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.__call__": [[615, 639], ["transforms.SeqRandomCrop.get_offsets", "transforms.SeqRandomCrop.random_crop", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.get_offsets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqRandomCrop.random_crop"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to sequentially randomly crop images, bounding boxes,\n        masks, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Randomly cropped results, 'img_shape' key in result dict is\n            updated according to crop size.\n        \"\"\"", "\n", "if", "self", ".", "share_params", ":", "\n", "            ", "offsets", "=", "self", ".", "get_offsets", "(", "results", "[", "0", "]", "[", "'img'", "]", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "None", "\n", "\n", "", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "self", ".", "random_crop", "(", "_results", ",", "offsets", ")", "\n", "if", "_results", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "outs", ".", "append", "(", "_results", ")", "\n", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.__init__": [[663, 674], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "share_params", "=", "True", ",", "\n", "brightness_delta", "=", "32", ",", "\n", "contrast_range", "=", "(", "0.5", ",", "1.5", ")", ",", "\n", "saturation_range", "=", "(", "0.5", ",", "1.5", ")", ",", "\n", "hue_delta", "=", "18", ")", ":", "\n", "        ", "self", ".", "share_params", "=", "share_params", "\n", "self", ".", "brightness_delta", "=", "brightness_delta", "\n", "self", ".", "contrast_lower", ",", "self", ".", "contrast_upper", "=", "contrast_range", "\n", "self", ".", "saturation_lower", ",", "self", ".", "saturation_upper", "=", "saturation_range", "\n", "self", ".", "hue_delta", "=", "hue_delta", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.get_params": [[675, 710], ["dict", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.permutation"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate parameters.\"\"\"", "\n", "params", "=", "dict", "(", ")", "\n", "# delta", "\n", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "params", "[", "'delta'", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "brightness_delta", ",", "\n", "self", ".", "brightness_delta", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "'delta'", "]", "=", "None", "\n", "# mode", "\n", "", "mode", "=", "np", ".", "random", ".", "randint", "(", "2", ")", "\n", "params", "[", "'contrast_first'", "]", "=", "True", "if", "mode", "==", "1", "else", "0", "\n", "# alpha", "\n", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "params", "[", "'alpha'", "]", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "contrast_lower", ",", "\n", "self", ".", "contrast_upper", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "'alpha'", "]", "=", "None", "\n", "# saturation", "\n", "", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "params", "[", "'saturation'", "]", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "saturation_lower", ",", "\n", "self", ".", "saturation_upper", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "'saturation'", "]", "=", "None", "\n", "# hue", "\n", "", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "params", "[", "'hue'", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "hue_delta", ",", "self", ".", "hue_delta", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "'hue'", "]", "=", "None", "\n", "# swap", "\n", "", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "params", "[", "'permutation'", "]", "=", "np", ".", "random", ".", "permutation", "(", "3", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "'permutation'", "]", "=", "None", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.photo_metric_distortion": [[711, 769], ["mmcv.bgr2hsv", "mmcv.hsv2bgr", "transforms.SeqPhotoMetricDistortion.get_params"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.get_params"], ["", "def", "photo_metric_distortion", "(", "self", ",", "results", ",", "params", "=", "None", ")", ":", "\n", "        ", "\"\"\"Call function to perform photometric distortion on images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n            params (dict, optional): Pre-defined parameters. Default to None.\n\n        Returns:\n            dict: Result dict with images distorted.\n        \"\"\"", "\n", "if", "params", "is", "None", ":", "\n", "            ", "params", "=", "self", ".", "get_params", "(", ")", "\n", "", "results", "[", "'img_info'", "]", "[", "'color_jitter'", "]", "=", "params", "\n", "\n", "if", "'img_fields'", "in", "results", ":", "\n", "            ", "assert", "results", "[", "'img_fields'", "]", "==", "[", "'img'", "]", ",", "'Only single img_fields is allowed'", "\n", "", "img", "=", "results", "[", "'img'", "]", "\n", "assert", "img", ".", "dtype", "==", "np", ".", "float32", ",", "'PhotoMetricDistortion needs the input image of dtype np.float32,'", "' please set \"to_float32=True\" in \"LoadImageFromFile\" pipeline'", "\n", "# random brightness", "\n", "if", "params", "[", "'delta'", "]", "is", "not", "None", ":", "\n", "            ", "img", "+=", "params", "[", "'delta'", "]", "\n", "\n", "# mode == 0 --> do random contrast first", "\n", "# mode == 1 --> do random contrast last", "\n", "", "if", "params", "[", "'contrast_first'", "]", ":", "\n", "            ", "if", "params", "[", "'alpha'", "]", "is", "not", "None", ":", "\n", "                ", "img", "*=", "params", "[", "'alpha'", "]", "\n", "\n", "# convert color from BGR to HSV", "\n", "", "", "img", "=", "mmcv", ".", "bgr2hsv", "(", "img", ")", "\n", "\n", "# random saturation", "\n", "if", "params", "[", "'saturation'", "]", "is", "not", "None", ":", "\n", "            ", "img", "[", "...", ",", "1", "]", "*=", "params", "[", "'saturation'", "]", "\n", "\n", "# random hue", "\n", "", "if", "params", "[", "'hue'", "]", "is", "not", "None", ":", "\n", "            ", "img", "[", "...", ",", "0", "]", "+=", "params", "[", "'hue'", "]", "\n", "img", "[", "...", ",", "0", "]", "[", "img", "[", "...", ",", "0", "]", ">", "360", "]", "-=", "360", "\n", "img", "[", "...", ",", "0", "]", "[", "img", "[", "...", ",", "0", "]", "<", "0", "]", "+=", "360", "\n", "\n", "# convert color from HSV to BGR", "\n", "", "img", "=", "mmcv", ".", "hsv2bgr", "(", "img", ")", "\n", "\n", "# random contrast", "\n", "if", "not", "params", "[", "'contrast_first'", "]", ":", "\n", "            ", "if", "params", "[", "'alpha'", "]", "is", "not", "None", ":", "\n", "                ", "img", "*=", "params", "[", "'alpha'", "]", "\n", "\n", "# randomly swap channels", "\n", "", "", "if", "params", "[", "'permutation'", "]", "is", "not", "None", ":", "\n", "            ", "img", "=", "img", "[", "...", ",", "params", "[", "'permutation'", "]", "]", "\n", "\n", "", "results", "[", "'img'", "]", "=", "img", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.__call__": [[770, 790], ["transforms.SeqPhotoMetricDistortion.get_params", "transforms.SeqPhotoMetricDistortion.photo_metric_distortion", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.get_params", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.photo_metric_distortion"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to perform photometric distortion on images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Result dict with images distorted.\n        \"\"\"", "\n", "if", "self", ".", "share_params", ":", "\n", "            ", "params", "=", "self", ".", "get_params", "(", ")", "\n", "", "else", ":", "\n", "            ", "params", "=", "None", "\n", "\n", "", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "self", ".", "photo_metric_distortion", "(", "_results", ",", "params", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.transforms.SeqPhotoMetricDistortion.__repr__": [[791, 800], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(\\nbrightness_delta={self.brightness_delta},\\n'", "\n", "repr_str", "+=", "'contrast_range='", "\n", "repr_str", "+=", "f'{(self.contrast_lower, self.contrast_upper)},\\n'", "\n", "repr_str", "+=", "'saturation_range='", "\n", "repr_str", "+=", "f'{(self.saturation_lower, self.saturation_upper)},\\n'", "\n", "repr_str", "+=", "f'hue_delta={self.hue_delta})'", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.ConcatVideoReferences.__call__": [[26, 76], ["isinstance", "enumerate", "numpy.concatenate", "outs.append", "len", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "[].append", "numpy.full", "numpy.expand_dims"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "assert", "(", "isinstance", "(", "results", ",", "list", ")", ")", ",", "'results must be list'", "\n", "outs", "=", "results", "[", ":", "1", "]", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "results", "[", "1", ":", "]", ",", "1", ")", ":", "\n", "            ", "if", "'img'", "in", "result", ":", "\n", "                ", "img", "=", "result", "[", "'img'", "]", "\n", "if", "len", "(", "img", ".", "shape", ")", "<", "3", ":", "\n", "                    ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "-", "1", ")", "\n", "", "if", "i", "==", "1", ":", "\n", "                    ", "result", "[", "'img'", "]", "=", "np", ".", "expand_dims", "(", "img", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "outs", "[", "1", "]", "[", "'img'", "]", "=", "np", ".", "concatenate", "(", "\n", "(", "outs", "[", "1", "]", "[", "'img'", "]", ",", "np", ".", "expand_dims", "(", "img", ",", "-", "1", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "", "for", "key", "in", "[", "'img_metas'", ",", "'gt_masks'", "]", ":", "\n", "                ", "if", "key", "in", "result", ":", "\n", "                    ", "if", "i", "==", "1", ":", "\n", "                        ", "result", "[", "key", "]", "=", "[", "result", "[", "key", "]", "]", "\n", "", "else", ":", "\n", "                        ", "outs", "[", "1", "]", "[", "key", "]", ".", "append", "(", "result", "[", "key", "]", ")", "\n", "", "", "", "for", "key", "in", "[", "\n", "'proposals'", ",", "'gt_bboxes'", ",", "'gt_bboxes_ignore'", ",", "'gt_labels'", ",", "\n", "'gt_instance_ids'", "\n", "]", ":", "\n", "                ", "if", "key", "not", "in", "result", ":", "\n", "                    ", "continue", "\n", "", "value", "=", "result", "[", "key", "]", "\n", "if", "value", ".", "ndim", "==", "1", ":", "\n", "                    ", "value", "=", "value", "[", ":", ",", "None", "]", "\n", "", "N", "=", "value", ".", "shape", "[", "0", "]", "\n", "value", "=", "np", ".", "concatenate", "(", "(", "np", ".", "full", "(", "\n", "(", "N", ",", "1", ")", ",", "i", "-", "1", ",", "dtype", "=", "np", ".", "float32", ")", ",", "value", ")", ",", "\n", "axis", "=", "1", ")", "\n", "if", "i", "==", "1", ":", "\n", "                    ", "result", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "outs", "[", "1", "]", "[", "key", "]", "=", "np", ".", "concatenate", "(", "(", "outs", "[", "1", "]", "[", "key", "]", ",", "value", ")", ",", "\n", "axis", "=", "0", ")", "\n", "", "", "if", "'gt_semantic_seg'", "in", "result", ":", "\n", "                ", "if", "i", "==", "1", ":", "\n", "                    ", "result", "[", "'gt_semantic_seg'", "]", "=", "result", "[", "'gt_semantic_seg'", "]", "[", "...", ",", "\n", "None", ",", "\n", "None", "]", "\n", "", "else", ":", "\n", "                    ", "outs", "[", "1", "]", "[", "'gt_semantic_seg'", "]", "=", "np", ".", "concatenate", "(", "\n", "(", "outs", "[", "1", "]", "[", "'gt_semantic_seg'", "]", ",", "\n", "result", "[", "'gt_semantic_seg'", "]", "[", "...", ",", "None", ",", "None", "]", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "", "", "if", "i", "==", "1", ":", "\n", "                ", "outs", ".", "append", "(", "result", ")", "\n", "", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.MultiImagesToTensor.__init__": [[91, 93], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ref_prefix", "=", "'ref'", ")", ":", "\n", "        ", "self", ".", "ref_prefix", "=", "ref_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.MultiImagesToTensor.__call__": [[94, 121], ["data.update", "formatting.MultiImagesToTensor.images_to_tensor", "outs.append", "len", "outs[].items"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.MultiImagesToTensor.images_to_tensor"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Multi images to tensor.\n\n        1. Transpose and convert image/multi-images to Tensor.\n        2. Add prefix to every key in the second dict of the inputs. Then, add\n        these keys and corresponding values into the output dict.\n\n        Args:\n            results (list[dict]): List of two dicts.\n\n        Returns:\n            dict: Each key in the first dict of `results` remains unchanged.\n            Each key in the second dict of `results` adds `self.ref_prefix`\n            as prefix.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "self", ".", "images_to_tensor", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", ".", "update", "(", "outs", "[", "0", "]", ")", "\n", "if", "len", "(", "outs", ")", "==", "2", ":", "\n", "            ", "for", "k", ",", "v", "in", "outs", "[", "1", "]", ".", "items", "(", ")", ":", "\n", "                ", "data", "[", "f'{self.ref_prefix}_{k}'", "]", "=", "v", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.MultiImagesToTensor.images_to_tensor": [[122, 138], ["mmdet.datasets.pipelines.to_tensor", "mmdet.datasets.pipelines.to_tensor", "mmcv.parallel.DataContainer", "len", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray.transpose", "numpy.ascontiguousarray.transpose"], "methods", ["None"], ["", "def", "images_to_tensor", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Transpose and convert images/multi-images to Tensor.\"\"\"", "\n", "if", "'img'", "in", "results", ":", "\n", "            ", "img", "=", "results", "[", "'img'", "]", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "# (H, W, 3) to (3, H, W)", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "# (H, W, 3, N) to (N, 3, H, W)", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ".", "transpose", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "", "results", "[", "'img'", "]", "=", "to_tensor", "(", "img", ")", "\n", "", "if", "'proposals'", "in", "results", ":", "\n", "            ", "results", "[", "'proposals'", "]", "=", "to_tensor", "(", "results", "[", "'proposals'", "]", ")", "\n", "", "if", "'img_metas'", "in", "results", ":", "\n", "            ", "results", "[", "'img_metas'", "]", "=", "DC", "(", "results", "[", "'img_metas'", "]", ",", "cpu_only", "=", "True", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.SeqDefaultFormatBundle.__init__": [[166, 168], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ref_prefix", "=", "'ref'", ")", ":", "\n", "        ", "self", ".", "ref_prefix", "=", "ref_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.SeqDefaultFormatBundle.__call__": [[169, 191], ["data.update", "outs[].items", "formatting.SeqDefaultFormatBundle.default_format_bundle", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.SeqDefaultFormatBundle.default_format_bundle"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Sequence Default formatting bundle call function.\n\n        Args:\n            results (list[dict]): List of two dicts.\n\n        Returns:\n            dict: The result dict contains the data that is formatted with\n            default bundle. Each key in the second dict of the input list\n            adds `self.ref_prefix` as prefix.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "self", ".", "default_format_bundle", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", ".", "update", "(", "outs", "[", "0", "]", ")", "\n", "for", "k", ",", "v", "in", "outs", "[", "1", "]", ".", "items", "(", ")", ":", "\n", "            ", "data", "[", "f'{self.ref_prefix}_{k}'", "]", "=", "v", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.SeqDefaultFormatBundle.default_format_bundle": [[192, 229], ["mmcv.parallel.DataContainer", "mmcv.parallel.DataContainer", "mmcv.parallel.DataContainer", "len", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "mmdet.datasets.pipelines.to_tensor", "mmdet.datasets.pipelines.to_tensor", "mmcv.parallel.DataContainer", "len", "numpy.ascontiguousarray", "mmdet.datasets.pipelines.to_tensor", "numpy.ascontiguousarray.transpose", "numpy.ascontiguousarray.transpose", "numpy.ascontiguousarray.transpose"], "methods", ["None"], ["", "def", "default_format_bundle", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Transform and format common fields in results.\n\n        Args:\n            results (dict): Result dict contains the data to convert.\n\n        Returns:\n            dict: The result dict contains the data that is formatted with\n            default bundle.\n        \"\"\"", "\n", "if", "'img'", "in", "results", ":", "\n", "            ", "img", "=", "results", "[", "'img'", "]", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ".", "transpose", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "", "results", "[", "'img'", "]", "=", "DC", "(", "to_tensor", "(", "img", ")", ",", "stack", "=", "True", ")", "\n", "", "for", "key", "in", "[", "\n", "'proposals'", ",", "'gt_bboxes'", ",", "'gt_bboxes_ignore'", ",", "'gt_labels'", ",", "\n", "'gt_instance_ids'", ",", "'gt_match_indices'", "\n", "]", ":", "\n", "            ", "if", "key", "not", "in", "results", ":", "\n", "                ", "continue", "\n", "", "results", "[", "key", "]", "=", "DC", "(", "to_tensor", "(", "results", "[", "key", "]", ")", ")", "\n", "", "for", "key", "in", "[", "'img_metas'", ",", "'gt_masks'", "]", ":", "\n", "            ", "if", "key", "in", "results", ":", "\n", "                ", "results", "[", "key", "]", "=", "DC", "(", "results", "[", "key", "]", ",", "cpu_only", "=", "True", ")", "\n", "", "", "if", "'gt_semantic_seg'", "in", "results", ":", "\n", "            ", "semantic_seg", "=", "results", "[", "'gt_semantic_seg'", "]", "\n", "if", "len", "(", "semantic_seg", ".", "shape", ")", "==", "2", ":", "\n", "                ", "semantic_seg", "=", "semantic_seg", "[", "None", ",", "...", "]", "\n", "", "else", ":", "\n", "                ", "semantic_seg", "=", "np", ".", "ascontiguousarray", "(", "\n", "semantic_seg", ".", "transpose", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "", "results", "[", "'gt_semantic_seg'", "]", "=", "DC", "(", "\n", "to_tensor", "(", "results", "[", "'gt_semantic_seg'", "]", ")", ",", "stack", "=", "True", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.SeqDefaultFormatBundle.__repr__": [[230, 232], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect.__init__": [[249, 265], ["isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "keys", ",", "\n", "meta_keys", "=", "None", ",", "\n", "default_meta_keys", "=", "(", "'filename'", ",", "'ori_filename'", ",", "'ori_shape'", ",", "\n", "'img_shape'", ",", "'pad_shape'", ",", "'scale_factor'", ",", "\n", "'flip'", ",", "'flip_direction'", ",", "'img_norm_cfg'", ",", "\n", "'frame_id'", ",", "'is_video_data'", ")", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "meta_keys", "=", "default_meta_keys", "\n", "if", "meta_keys", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "meta_keys", ",", "str", ")", ":", "\n", "                ", "meta_keys", "=", "(", "meta_keys", ",", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "meta_keys", ",", "tuple", ")", ",", "'meta_keys must be str or tuple'", "\n", "", "self", ".", "meta_keys", "+=", "meta_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect.__call__": [[266, 296], ["isinstance", "formatting.VideoCollect._add_default_meta_keys", "formatting.VideoCollect._collect_meta_keys", "outs.append", "mmcv.parallel.DataContainer"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect._add_default_meta_keys", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect._collect_meta_keys"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to collect keys in results.\n\n        The keys in ``meta_keys`` and ``default_meta_keys`` will be converted\n        to :obj:mmcv.DataContainer.\n\n        Args:\n            results (list[dict] | dict): List of dict or dict which contains\n                the data to collect.\n\n        Returns:\n            list[dict] | dict: List of dict or dict that contains the\n            following keys:\n\n            - keys in ``self.keys``\n            - ``img_metas``\n        \"\"\"", "\n", "results_is_dict", "=", "isinstance", "(", "results", ",", "dict", ")", "\n", "if", "results_is_dict", ":", "\n", "            ", "results", "=", "[", "results", "]", "\n", "", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "self", ".", "_add_default_meta_keys", "(", "_results", ")", "\n", "_results", "=", "self", ".", "_collect_meta_keys", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "\n", "", "if", "results_is_dict", ":", "\n", "            ", "outs", "[", "0", "]", "[", "'img_metas'", "]", "=", "DC", "(", "outs", "[", "0", "]", "[", "'img_metas'", "]", ",", "cpu_only", "=", "True", ")", "\n", "\n", "", "return", "outs", "[", "0", "]", "if", "results_is_dict", "else", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect._collect_meta_keys": [[297, 310], ["None"], "methods", ["None"], ["", "def", "_collect_meta_keys", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Collect `self.keys` and `self.meta_keys` from `results` (dict).\"\"\"", "\n", "data", "=", "{", "}", "\n", "img_meta", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "meta_keys", ":", "\n", "            ", "if", "key", "in", "results", ":", "\n", "                ", "img_meta", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "", "elif", "key", "in", "results", "[", "'img_info'", "]", ":", "\n", "                ", "img_meta", "[", "key", "]", "=", "results", "[", "'img_info'", "]", "[", "key", "]", "\n", "", "", "data", "[", "'img_metas'", "]", "=", "img_meta", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "data", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.VideoCollect._add_default_meta_keys": [[311, 335], ["results.setdefault", "results.setdefault", "results.setdefault", "dict", "len", "numpy.zeros", "numpy.ones"], "methods", ["None"], ["", "def", "_add_default_meta_keys", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Add default meta keys.\n\n        We set default meta keys including `pad_shape`, `scale_factor` and\n        `img_norm_cfg` to avoid the case where no `Resize`, `Normalize` and\n        `Pad` are implemented during the whole pipeline.\n\n        Args:\n            results (dict): Result dict contains the data to convert.\n\n        Returns:\n            results (dict): Updated result dict contains the data to convert.\n        \"\"\"", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "results", ".", "setdefault", "(", "'pad_shape'", ",", "img", ".", "shape", ")", "\n", "results", ".", "setdefault", "(", "'scale_factor'", ",", "1.0", ")", "\n", "num_channels", "=", "1", "if", "len", "(", "img", ".", "shape", ")", "<", "3", "else", "img", ".", "shape", "[", "2", "]", "\n", "results", ".", "setdefault", "(", "\n", "'img_norm_cfg'", ",", "\n", "dict", "(", "\n", "mean", "=", "np", ".", "zeros", "(", "num_channels", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "std", "=", "np", ".", "ones", "(", "num_channels", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "to_rgb", "=", "False", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.formatting.ToList.__call__": [[348, 353], ["results.items"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "out", "[", "k", "]", "=", "[", "v", "]", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.processing.MatchInstances.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "skip_nomatch", "=", "True", ")", ":", "\n", "        ", "self", ".", "skip_nomatch", "=", "skip_nomatch", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.processing.MatchInstances._match_gts": [[18, 40], ["list", "list", "numpy.array", "numpy.array", "list.index", "list.index"], "methods", ["None"], ["", "def", "_match_gts", "(", "self", ",", "instance_ids", ",", "ref_instance_ids", ")", ":", "\n", "        ", "\"\"\"Matching objects according to ground truth `instance_ids`.\n\n        Args:\n            instance_ids (ndarray): of shape (N1, ).\n            ref_instance_ids (ndarray): of shape (N2, ).\n\n        Returns:\n            tuple: Matching results which contain the indices of the\n            matched target.\n        \"\"\"", "\n", "ins_ids", "=", "list", "(", "instance_ids", ")", "\n", "ref_ins_ids", "=", "list", "(", "ref_instance_ids", ")", "\n", "match_indices", "=", "np", ".", "array", "(", "[", "\n", "ref_ins_ids", ".", "index", "(", "i", ")", "if", "(", "i", "in", "ref_ins_ids", "and", "i", ">", "0", ")", "else", "-", "1", "\n", "for", "i", "in", "ins_ids", "\n", "]", ")", "\n", "ref_match_indices", "=", "np", ".", "array", "(", "[", "\n", "ins_ids", ".", "index", "(", "i", ")", "if", "(", "i", "in", "ins_ids", "and", "i", ">", "0", ")", "else", "-", "1", "\n", "for", "i", "in", "ref_ins_ids", "\n", "]", ")", "\n", "return", "match_indices", ",", "ref_match_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.processing.MatchInstances.__call__": [[41, 55], ["processing.MatchInstances._match_gts", "len", "NotImplementedError", "match_indices.copy", "ref_match_indices.copy"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.processing.MatchInstances._match_gts"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "if", "len", "(", "results", ")", "!=", "2", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Only support match 2 images now.'", ")", "\n", "\n", "", "match_indices", ",", "ref_match_indices", "=", "self", ".", "_match_gts", "(", "\n", "results", "[", "0", "]", "[", "'gt_instance_ids'", "]", ",", "results", "[", "1", "]", "[", "'gt_instance_ids'", "]", ")", "\n", "nomatch", "=", "(", "match_indices", "==", "-", "1", ")", ".", "all", "(", ")", "\n", "if", "self", ".", "skip_nomatch", "and", "nomatch", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "results", "[", "0", "]", "[", "'gt_match_indices'", "]", "=", "match_indices", ".", "copy", "(", ")", "\n", "results", "[", "1", "]", "[", "'gt_match_indices'", "]", "=", "ref_match_indices", ".", "copy", "(", ")", "\n", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadMultiImagesFromFile.__init__": [[15, 17], ["mmdet.datasets.pipelines.LoadImageFromFile.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadMultiImagesFromFile.__call__": [[18, 36], ["super().__call__", "outs.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in `results`, call the call function of\n        `LoadImageFromFile` to load image.\n\n        Args:\n            results (list[dict]): List of dict from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains loaded image.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.SeqLoadAnnotations.__init__": [[49, 52], ["mmdet.datasets.pipelines.LoadAnnotations.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "with_track", "=", "False", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "with_track", "=", "with_track", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.SeqLoadAnnotations._load_track": [[53, 66], ["[].copy"], "methods", ["None"], ["", "def", "_load_track", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Private function to load label annotations.\n\n        Args:\n            results (dict): Result dict from :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            dict: The dict contains loaded label annotations.\n        \"\"\"", "\n", "\n", "results", "[", "'gt_instance_ids'", "]", "=", "results", "[", "'ann_info'", "]", "[", "'instance_ids'", "]", ".", "copy", "(", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.SeqLoadAnnotations.__call__": [[67, 89], ["super().__call__", "outs.append", "loading.SeqLoadAnnotations._load_track"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.SeqLoadAnnotations._load_track"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function.\n\n        For each dict in results, call the call function of `LoadAnnotations`\n        to load annotation.\n\n        Args:\n            results (list[dict]): List of dict that from\n                :obj:`mmtrack.CocoVideoDataset`.\n\n        Returns:\n            list[dict]: List of dict that contains loaded annotations, such as\n            bounding boxes, labels, instance ids, masks and semantic\n            segmentation annotations.\n        \"\"\"", "\n", "outs", "=", "[", "]", "\n", "for", "_results", "in", "results", ":", "\n", "            ", "_results", "=", "super", "(", ")", ".", "__call__", "(", "_results", ")", "\n", "if", "self", ".", "with_track", ":", "\n", "                ", "_results", "=", "self", ".", "_load_track", "(", "_results", ")", "\n", "", "outs", ".", "append", "(", "_results", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.pipelines.loading.LoadDetections.__call__": [[99, 109], ["mmtrack.core.restore_result", "results[].append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "detections", "=", "results", "[", "'detections'", "]", "\n", "\n", "bboxes", ",", "labels", "=", "restore_result", "(", "detections", ")", "\n", "results", "[", "'public_bboxes'", "]", "=", "bboxes", "[", ":", ",", ":", "4", "]", "\n", "if", "bboxes", ".", "shape", "[", "1", "]", ">", "4", ":", "\n", "            ", "results", "[", "'public_scores'", "]", "=", "bboxes", "[", ":", ",", "-", "1", "]", "\n", "", "results", "[", "'public_labels'", "]", "=", "labels", "\n", "results", "[", "'bbox_fields'", "]", ".", "append", "(", "'public_bboxes'", ")", "\n", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.__init__": [[17, 21], ["pycocotools.coco.COCO.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "annotation_file", "=", "None", ",", "load_img_as_vid", "=", "False", ")", ":", "\n", "        ", "assert", "annotation_file", ",", "'Annotation file must be provided.'", "\n", "self", ".", "load_img_as_vid", "=", "load_img_as_vid", "\n", "super", "(", "CocoVID", ",", "self", ")", ".", "__init__", "(", "annotation_file", "=", "annotation_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.convert_img_to_vid": [[22, 37], ["enumerate", "enumerate", "videos.append", "dict"], "methods", ["None"], ["", "def", "convert_img_to_vid", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"Convert image data to video data.\"\"\"", "\n", "if", "'images'", "in", "self", ".", "dataset", ":", "\n", "            ", "videos", "=", "[", "]", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "self", ".", "dataset", "[", "'images'", "]", ")", ":", "\n", "                ", "videos", ".", "append", "(", "dict", "(", "id", "=", "img", "[", "'id'", "]", ",", "name", "=", "img", "[", "'file_name'", "]", ")", ")", "\n", "img", "[", "'video_id'", "]", "=", "img", "[", "'id'", "]", "\n", "img", "[", "'frame_id'", "]", "=", "0", "\n", "", "dataset", "[", "'videos'", "]", "=", "videos", "\n", "\n", "", "if", "'annotations'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "i", ",", "ann", "in", "enumerate", "(", "self", ".", "dataset", "[", "'annotations'", "]", ")", ":", "\n", "                ", "ann", "[", "'video_id'", "]", "=", "ann", "[", "'image_id'", "]", "\n", "ann", "[", "'instance_id'", "]", "=", "ann", "[", "'id'", "]", "\n", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.createIndex": [[38, 89], ["print", "print", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "coco_video_parser.CocoVID.convert_img_to_vid", "imgToAnns[].append", "vidToImgs[].append", "catToImgs[].append", "instancesToImgs[].append", "vidToInstances[].append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.convert_img_to_vid"], ["", "def", "createIndex", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create index.\"\"\"", "\n", "print", "(", "'creating index...'", ")", "\n", "anns", ",", "cats", ",", "imgs", ",", "vids", "=", "{", "}", ",", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "(", "imgToAnns", ",", "catToImgs", ",", "vidToImgs", ",", "vidToInstances", ",", "\n", "instancesToImgs", ")", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "\n", "list", ")", ",", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "\n", "if", "'videos'", "not", "in", "self", ".", "dataset", "and", "self", ".", "load_img_as_vid", ":", "\n", "            ", "self", ".", "dataset", "=", "self", ".", "convert_img_to_vid", "(", "self", ".", "dataset", ")", "\n", "\n", "", "if", "'videos'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "video", "in", "self", ".", "dataset", "[", "'videos'", "]", ":", "\n", "                ", "vids", "[", "video", "[", "'id'", "]", "]", "=", "video", "\n", "\n", "", "", "if", "'annotations'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "imgToAnns", "[", "ann", "[", "'image_id'", "]", "]", ".", "append", "(", "ann", ")", "\n", "anns", "[", "ann", "[", "'id'", "]", "]", "=", "ann", "\n", "if", "'instance_id'", "in", "ann", ":", "\n", "                    ", "instancesToImgs", "[", "ann", "[", "'instance_id'", "]", "]", ".", "append", "(", "ann", "[", "'image_id'", "]", ")", "\n", "if", "'video_id'", "in", "ann", "and", "ann", "[", "'instance_id'", "]", "not", "in", "vidToInstances", "[", "ann", "[", "'video_id'", "]", "]", ":", "\n", "                        ", "vidToInstances", "[", "ann", "[", "'video_id'", "]", "]", ".", "append", "(", "\n", "ann", "[", "'instance_id'", "]", ")", "\n", "\n", "", "", "", "", "if", "'images'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "                ", "vidToImgs", "[", "img", "[", "'video_id'", "]", "]", ".", "append", "(", "img", ")", "\n", "imgs", "[", "img", "[", "'id'", "]", "]", "=", "img", "\n", "\n", "", "", "if", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "cat", "in", "self", ".", "dataset", "[", "'categories'", "]", ":", "\n", "                ", "cats", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "\n", "", "", "if", "'annotations'", "in", "self", ".", "dataset", "and", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "catToImgs", "[", "ann", "[", "'category_id'", "]", "]", ".", "append", "(", "ann", "[", "'image_id'", "]", ")", "\n", "\n", "", "", "print", "(", "'index created!'", ")", "\n", "\n", "self", ".", "anns", "=", "anns", "\n", "self", ".", "imgToAnns", "=", "imgToAnns", "\n", "self", ".", "catToImgs", "=", "catToImgs", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "cats", "=", "cats", "\n", "self", ".", "videos", "=", "vids", "\n", "self", ".", "vidToImgs", "=", "vidToImgs", "\n", "self", ".", "vidToInstances", "=", "vidToInstances", "\n", "self", ".", "instancesToImgs", "=", "instancesToImgs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_vid_ids": [[90, 109], ["list", "pycocotools.coco._isArrayLike", "len", "coco_video_parser.CocoVID.videos.keys", "set"], "methods", ["None"], ["", "def", "get_vid_ids", "(", "self", ",", "vidIds", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"Get video ids that satisfy given filter conditions.\n\n        Default return all video ids.\n\n        Args:\n            vidIds (list[int]): The given video ids. Defaults to [].\n\n        Returns:\n            list[int]: Video ids.\n        \"\"\"", "\n", "vidIds", "=", "vidIds", "if", "_isArrayLike", "(", "vidIds", ")", "else", "[", "vidIds", "]", "\n", "\n", "if", "len", "(", "vidIds", ")", "==", "0", ":", "\n", "            ", "ids", "=", "self", ".", "videos", ".", "keys", "(", ")", "\n", "", "else", ":", "\n", "            ", "ids", "=", "set", "(", "vidIds", ")", "\n", "\n", "", "return", "list", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_vid": [[110, 124], ["list", "numpy.zeros", "len"], "methods", ["None"], ["", "def", "get_img_ids_from_vid", "(", "self", ",", "vidId", ")", ":", "\n", "        ", "\"\"\"Get image ids from given video id.\n\n        Args:\n            vidId (int): The given video id.\n\n        Returns:\n            list[int]: Image ids of given video id.\n        \"\"\"", "\n", "img_infos", "=", "self", ".", "vidToImgs", "[", "vidId", "]", "\n", "ids", "=", "list", "(", "np", ".", "zeros", "(", "[", "len", "(", "img_infos", ")", "]", ",", "dtype", "=", "np", ".", "int", ")", ")", "\n", "for", "img_info", "in", "img_infos", ":", "\n", "            ", "ids", "[", "img_info", "[", "'frame_id'", "]", "]", "=", "img_info", "[", "'id'", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_ins_ids_from_vid": [[125, 135], ["None"], "methods", ["None"], ["", "def", "get_ins_ids_from_vid", "(", "self", ",", "vidId", ")", ":", "\n", "        ", "\"\"\"Get instance ids from given video id.\n\n        Args:\n            vidId (int): The given video id.\n\n        Returns:\n            list[int]: Instance ids of given video id.\n        \"\"\"", "\n", "return", "self", ".", "vidToInstances", "[", "vidId", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.get_img_ids_from_ins_id": [[136, 146], ["None"], "methods", ["None"], ["", "def", "get_img_ids_from_ins_id", "(", "self", ",", "insId", ")", ":", "\n", "        ", "\"\"\"Get image ids from given instance id.\n\n        Args:\n            insId (int): The given instance id.\n\n        Returns:\n            list[int]: Image ids of given instance id.\n        \"\"\"", "\n", "return", "self", ".", "instancesToImgs", "[", "insId", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.parsers.coco_video_parser.CocoVID.load_vids": [[147, 162], ["pycocotools.coco._isArrayLike", "type"], "methods", ["None"], ["", "def", "load_vids", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"Get video information of given video ids.\n\n        Default return all videos information.\n\n        Args:\n            ids (list[int]): The given video ids. Defaults to [].\n\n        Returns:\n            list[dict]: List of video information.\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "videos", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "videos", "[", "ids", "]", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.init_model": [[12, 50], ["isinstance", "mmtrack.models.build_model", "mmtrack.models.build_model.to", "mmtrack.models.build_model.eval", "mmcv.Config.fromfile", "mmcv.Config.fromfile.merge_from_dict", "mmcv.runner.load_checkpoint", "hasattr", "isinstance", "TypeError", "hasattr", "hasattr", "print", "type"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model"], ["def", "init_model", "(", "config", ",", "checkpoint", "=", "None", ",", "device", "=", "'cuda:0'", ",", "cfg_options", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize a model from config file.\n\n    Args:\n        config (str or :obj:`mmcv.Config`): Config file path or the config\n            object.\n        checkpoint (str, optional): Checkpoint path. Default as None.\n        cfg_options (dict, optional): Options to override some settings in\n            the used config. Default to None.\n\n    Returns:\n        nn.Module: The constructed detector.\n    \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "        ", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config", ")", "\n", "", "elif", "not", "isinstance", "(", "config", ",", "mmcv", ".", "Config", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'config must be a filename or Config object, '", "\n", "f'but got {type(config)}'", ")", "\n", "", "if", "cfg_options", "is", "not", "None", ":", "\n", "        ", "config", ".", "merge_from_dict", "(", "cfg_options", ")", "\n", "", "if", "'detector'", "in", "config", ".", "model", ":", "\n", "        ", "config", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "model", "=", "build_model", "(", "config", ".", "model", ")", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "map_loc", "=", "'cpu'", "if", "device", "==", "'cpu'", "else", "None", "\n", "checkpoint", "=", "load_checkpoint", "(", "model", ",", "checkpoint", ",", "map_location", "=", "map_loc", ")", "\n", "if", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "            ", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "if", "not", "hasattr", "(", "model", ",", "'CLASSES'", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "'detector'", ")", "and", "hasattr", "(", "model", ".", "detector", ",", "'CLASSES'", ")", ":", "\n", "            ", "model", ".", "CLASSES", "=", "model", ".", "detector", ".", "CLASSES", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Warning: The model doesn't have classes\"", ")", "\n", "model", ".", "CLASSES", "=", "None", "\n", "", "", "model", ".", "cfg", "=", "config", "# save the config in the model for convenience", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_mot": [[52, 94], ["isinstance", "mmdet.datasets.pipelines.Compose", "mmdet.datasets.pipelines.Compose.", "mmcv.parallel.collate", "next", "dict", "cfg.copy.copy", "dict", "next", "model.modules", "torch.no_grad", "model", "model.parameters", "model.parameters", "mmcv.parallel.scatter", "dict", "dict", "isinstance"], "function", ["None"], ["", "def", "inference_mot", "(", "model", ",", "img", ",", "frame_id", ")", ":", "\n", "    ", "\"\"\"Inference image(s) with the mot model.\n\n    Args:\n        model (nn.Module): The loaded mot model.\n        img (str | ndarray): Either image name or loaded image.\n        frame_id (int): frame id.\n\n    Returns:\n        dict[str : ndarray]: The tracking results.\n    \"\"\"", "\n", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "# prepare data", "\n", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "# directly add img", "\n", "        ", "data", "=", "dict", "(", "img", "=", "img", ",", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ",", "img_prefix", "=", "None", ")", "\n", "cfg", "=", "cfg", ".", "copy", "(", ")", "\n", "# set loading pipeline type", "\n", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "0", "]", ".", "type", "=", "'LoadImageFromWebcam'", "\n", "", "else", ":", "\n", "# add information into dict", "\n", "        ", "data", "=", "dict", "(", "\n", "img_info", "=", "dict", "(", "filename", "=", "img", ",", "frame_id", "=", "frame_id", ")", ",", "img_prefix", "=", "None", ")", "\n", "# build the data pipeline", "\n", "", "test_pipeline", "=", "Compose", "(", "cfg", ".", "data", ".", "test", ".", "pipeline", ")", "\n", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "assert", "not", "isinstance", "(", "\n", "m", ",", "RoIPool", "\n", ")", ",", "'CPU inference with RoIPool is not supported currently.'", "\n", "# just get the actual data from DataContainer", "\n", "", "data", "[", "'img_metas'", "]", "=", "data", "[", "'img_metas'", "]", "[", "0", "]", ".", "data", "\n", "# forward the model", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_sot": [[96, 134], ["dict", "mmdet.datasets.pipelines.Compose", "mmdet.datasets.pipelines.Compose.", "mmcv.parallel.collate", "next", "next", "model.modules", "torch.no_grad", "model", "model.parameters", "image.astype", "numpy.array().astype", "dict", "model.parameters", "mmcv.parallel.scatter", "isinstance", "numpy.array"], "function", ["None"], ["", "def", "inference_sot", "(", "model", ",", "image", ",", "init_bbox", ",", "frame_id", ")", ":", "\n", "    ", "\"\"\"Inference image with the single object tracker.\n\n    Args:\n        model (nn.Module): The loaded tracker.\n        image (ndarray): Loaded images.\n        init_bbox (ndarray): The target needs to be tracked.\n        frame_id (int): frame id.\n\n    Returns:\n        dict[str : ndarray]: The tracking results.\n    \"\"\"", "\n", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "\n", "data", "=", "dict", "(", "\n", "img", "=", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "gt_bboxes", "=", "np", ".", "array", "(", "init_bbox", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ")", "\n", "# remove the \"LoadImageFromFile\" and \"LoadAnnotations\" in pipeline", "\n", "test_pipeline", "=", "Compose", "(", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "2", ":", "]", ")", "\n", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "assert", "not", "isinstance", "(", "\n", "m", ",", "RoIPool", "\n", ")", ",", "'CPU inference with RoIPool is not supported currently.'", "\n", "# just get the actual data from DataContainer", "\n", "", "data", "[", "'img_metas'", "]", "=", "data", "[", "'img_metas'", "]", "[", "0", "]", ".", "data", "\n", "\n", "# forward the model", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.inference.inference_vid": [[136, 210], ["dict", "mmdet.datasets.pipelines.Compose.", "mmcv.parallel.collate", "next", "dict", "mmdet.datasets.pipelines.Compose", "next", "model.modules", "torch.no_grad", "model", "model.parameters", "ref_img_sampler.get", "ref_img_sampler.get", "mmdet.datasets.pipelines.Compose", "print", "model.parameters", "mmcv.parallel.scatter", "image.astype().copy", "dict", "dict", "range", "isinstance", "dict", "dict.append", "dict", "dict.append", "image.astype", "image.astype().copy", "dict", "image.astype().copy", "dict", "image.astype().copy", "dict", "image.astype", "image.astype", "image.astype"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "inference_vid", "(", "model", ",", "\n", "image", ",", "\n", "frame_id", ",", "\n", "ref_img_sampler", "=", "dict", "(", "frame_stride", "=", "10", ",", "num_left_ref_imgs", "=", "10", ")", ")", ":", "\n", "    ", "\"\"\"Inference image with the video object detector.\n\n    Args:\n        model (nn.Module): The loaded detector.\n        image (ndarray): Loaded images.\n        frame_id (int): Frame id.\n        ref_img_sampler (dict): The configuration for sampling reference\n            images. Only used under video detector of fgfa style. Defaults to\n            dict(frame_stride=2, num_left_ref_imgs=10).\n\n    Returns:\n        dict[str : ndarray]: The detection results.\n    \"\"\"", "\n", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "\n", "if", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "0", "]", ".", "type", "==", "'LoadImageFromFile'", ":", "\n", "        ", "data", "=", "dict", "(", "\n", "img", "=", "image", ".", "astype", "(", "np", ".", "float32", ")", ".", "copy", "(", ")", ",", "\n", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ")", "\n", "\n", "# remove the \"LoadImageFromFile\" in pipeline", "\n", "test_pipeline", "=", "Compose", "(", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "1", ":", "]", ")", "\n", "\n", "", "elif", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "0", "]", ".", "type", "==", "'LoadMultiImagesFromFile'", ":", "\n", "        ", "data", "=", "[", "\n", "dict", "(", "\n", "img", "=", "image", ".", "astype", "(", "np", ".", "float32", ")", ".", "copy", "(", ")", ",", "\n", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ")", "\n", "]", "\n", "\n", "num_left_ref_imgs", "=", "ref_img_sampler", ".", "get", "(", "'num_left_ref_imgs'", ")", "\n", "frame_stride", "=", "ref_img_sampler", ".", "get", "(", "'frame_stride'", ")", "\n", "if", "frame_id", "==", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_left_ref_imgs", ")", ":", "\n", "                ", "one_ref_img", "=", "dict", "(", "\n", "img", "=", "image", ".", "astype", "(", "np", ".", "float32", ")", ".", "copy", "(", ")", ",", "\n", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ")", "\n", "data", ".", "append", "(", "one_ref_img", ")", "\n", "", "", "elif", "frame_id", "%", "frame_stride", "==", "0", ":", "\n", "            ", "one_ref_img", "=", "dict", "(", "\n", "img", "=", "image", ".", "astype", "(", "np", ".", "float32", ")", ".", "copy", "(", ")", ",", "\n", "img_info", "=", "dict", "(", "frame_id", "=", "frame_id", ")", ")", "\n", "data", ".", "append", "(", "one_ref_img", ")", "\n", "\n", "# remove the \"LoadMultiImagesFromFile\" in pipeline", "\n", "", "test_pipeline", "=", "Compose", "(", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "1", ":", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Not supported loading data pipeline type: '", "\n", "f'{cfg.data.test.pipeline[0].type}'", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "assert", "not", "isinstance", "(", "\n", "m", ",", "RoIPool", "\n", ")", ",", "'CPU inference with RoIPool is not supported currently.'", "\n", "# just get the actual data from DataContainer", "\n", "", "data", "[", "'img_metas'", "]", "=", "data", "[", "'img_metas'", "]", "[", "0", "]", ".", "data", "\n", "\n", "# forward the model", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.train.train_model": [[14, 137], ["mmtrack.utils.get_root_logger", "mmcv.runner.build_optimizer", "mmcv.runner.EpochBasedRunner", "cfg.get", "mmcv.runner.EpochBasedRunner.register_training_hooks", "cfg.get", "mmcv.runner.EpochBasedRunner.run", "isinstance", "mmtrack.utils.get_root_logger.warning", "mmtrack.datasets.build_dataloader", "cfg.get", "mmcv.parallel.MMDistributedDataParallel", "mmcv.parallel.MMDataParallel", "mmdet.core.Fp16OptimizerHook", "cfg.get", "mmcv.runner.EpochBasedRunner.register_hook", "mmdet.datasets.build_dataset", "mmtrack.datasets.build_dataloader", "cfg.get", "mmcv.runner.EpochBasedRunner.register_hook", "isinstance", "mmcv.runner.EpochBasedRunner.resume", "mmtrack.utils.get_root_logger.warning", "mmtrack.utils.get_root_logger.warning", "len", "mmcv.parallel.MMDataParallel.cuda", "mmcv.parallel.MMDataParallel.cuda", "mmcv.runner.OptimizerHook", "mmcv.runner.DistSamplerSeedHook", "dict", "eval_hook", "isinstance", "hook_cfg.copy.copy", "hook_cfg.copy.pop", "mmcv.utils.build_from_cfg", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.load_checkpoint", "type", "torch.cuda.current_device", "type"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["from", "mmtrack", "import", "__version__", "\n", "from", "mmtrack", ".", "utils", "import", "collect_env", ",", "get_root_logger", "\n", "\n", "\n", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--work-dir'", ",", "help", "=", "'the dir to save logs and models'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume-from'", ",", "help", "=", "'the checkpoint file to resume from'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no-validate'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether not to evaluate the checkpoint during training'", ")", "\n", "group_gpus", "=", "parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpus'", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'number of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpu-ids'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'ids of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--deterministic'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to set deterministic options for CUDNN backend.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "return", "args", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "train_detector", "as", "train_model", "\n", "from", "mmtrack", ".", "models", "import", "build_detector", "as", "build_model", "\n", "if", "'detector'", "in", "cfg", ".", "model", ":", "\n", "            ", "cfg", ".", "model", "=", "cfg", ".", "model", ".", "detector", "\n", "", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "train_model", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# work_dir is determined in this priority: CLI > segment in file > filename", "\n", "", "if", "args", ".", "work_dir", "is", "not", "None", ":", "\n", "# update configs according to CLI args if args.work_dir is not None", "\n", "        ", "cfg", ".", "work_dir", "=", "args", ".", "work_dir", "\n", "", "elif", "cfg", ".", "get", "(", "'work_dir'", ",", "None", ")", "is", "None", ":", "\n", "# use config filename as default work_dir if cfg.work_dir is None", "\n", "        ", "cfg", ".", "work_dir", "=", "osp", ".", "join", "(", "'./work_dirs'", ",", "\n", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", "[", "0", "]", ")", "\n", "", "if", "args", ".", "resume_from", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "resume_from", "=", "args", ".", "resume_from", "\n", "", "if", "args", ".", "gpu_ids", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "args", ".", "gpu_ids", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "range", "(", "1", ")", "if", "args", ".", "gpus", "is", "None", "else", "range", "(", "args", ".", "gpus", ")", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# create work_dir", "\n", "", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "abspath", "(", "cfg", ".", "work_dir", ")", ")", "\n", "# dump config", "\n", "cfg", ".", "dump", "(", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", ")", "\n", "# init the logger before other steps", "\n", "timestamp", "=", "time", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "log_file", "=", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "f'{timestamp}.log'", ")", "\n", "logger", "=", "get_root_logger", "(", "log_file", "=", "log_file", ",", "log_level", "=", "cfg", ".", "log_level", ")", "\n", "\n", "# init the meta dict to record some important information such as", "\n", "# environment info and seed, which will be logged", "\n", "meta", "=", "dict", "(", ")", "\n", "# log env info", "\n", "env_info_dict", "=", "collect_env", "(", ")", "\n", "env_info", "=", "'\\n'", ".", "join", "(", "[", "(", "f'{k}: {v}'", ")", "for", "k", ",", "v", "in", "env_info_dict", ".", "items", "(", ")", "]", ")", "\n", "dash_line", "=", "'-'", "*", "60", "+", "'\\n'", "\n", "logger", ".", "info", "(", "'Environment info:\\n'", "+", "dash_line", "+", "env_info", "+", "'\\n'", "+", "\n", "dash_line", ")", "\n", "meta", "[", "'env_info'", "]", "=", "env_info", "\n", "\n", "# log some basic info", "\n", "logger", ".", "info", "(", "f'Distributed training: {distributed}'", ")", "\n", "logger", ".", "info", "(", "f'Config:\\n{cfg.pretty_text}'", ")", "\n", "\n", "# set random seeds", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "f'Set random seed to {args.seed}, '", "\n", "f'deterministic: {args.deterministic}'", ")", "\n", "set_random_seed", "(", "args", ".", "seed", ",", "deterministic", "=", "args", ".", "deterministic", ")", "\n", "", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "meta", "[", "'seed'", "]", "=", "args", ".", "seed", "\n", "\n", "if", "cfg", ".", "get", "(", "'train_cfg'", ",", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.single_gpu_test": [[13, 50], ["model.eval", "collections.defaultdict", "mmcv.ProgressBar", "enumerate", "len", "model.items", "[].size", "range", "torch.no_grad", "torch.no_grad", "model", "results[].append", "mmcv.ProgressBar.update"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["\n", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'mmtrack test model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "help", "=", "'output result file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format-only'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Format the output results without perform evaluation. It is'", "\n", "'useful when you want to format the result to a specific format and '", "\n", "'submit it to the test server'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'eval types'", ")", "\n", "parser", ".", "add_argument", "(", "'--show'", ",", "action", "=", "'store_true'", ",", "help", "=", "'show results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "help", "=", "'score threshold (default: 0.3)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show-dir'", ",", "help", "=", "'directory where painted images will be saved'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.multi_gpu_test": [[52, 97], ["model.eval", "collections.defaultdict", "mmcv.runner.get_dist_info", "time.sleep", "enumerate", "mmcv.ProgressBar", "model.items", "test.collect_results_cpu", "len", "torch.no_grad", "torch.no_grad", "model", "results[].append", "[].size", "range", "mmcv.ProgressBar.update"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.collect_results_cpu", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["'in xxx=yyy format will be merged into config file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "", "return", "args", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "assert", "args", ".", "out", "or", "args", ".", "eval", "or", "args", ".", "format_only", "or", "args", ".", "show", "or", "args", ".", "show_dir", ",", "(", "'Please specify at least one operation (save/eval/format/show the '", "\n", "'results / save the results) with the argument \"--out\", \"--eval\"'", "\n", "', \"--format-only\", \"--show\" or \"--show-dir\"'", ")", "\n", "\n", "if", "args", ".", "eval", "and", "args", ".", "format_only", ":", "\n", "        ", "raise", "ValueError", "(", "'--eval and --format_only cannot be both specified'", ")", "\n", "\n", "", "if", "args", ".", "out", "is", "not", "None", "and", "not", "args", ".", "out", ".", "endswith", "(", "(", "'.pkl'", ",", "'.pickle'", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The output file must be a pkl file.'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "cfg", ".", "get", "(", "'USE_MMDET'", ",", "False", ")", ":", "\n", "        ", "from", "mmdet", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmdet", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmdet", ".", "models", "import", "build_detector", "as", "build_model", "\n", "", "else", ":", "\n", "        ", "from", "mmtrack", ".", "apis", "import", "multi_gpu_test", ",", "single_gpu_test", "\n", "from", "mmtrack", ".", "datasets", "import", "build_dataloader", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "# set cudnn_benchmark", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.collect_results_cpu": [[99, 148], ["mmcv.runner.get_dist_info", "mmcv.dump", "torch.barrier", "torch.full", "torch.full", "torch.broadcast", "torch.full.cpu().numpy().tobytes().decode().rstrip", "mmcv.mkdir_or_exist", "os.join", "collections.defaultdict", "range", "shutil.rmtree", "tempfile.mkdtemp", "torch.tensor", "torch.tensor", "os.join", "mmcv.load", "mmcv.load.items", "bytearray", "torch.full.cpu().numpy().tobytes().decode", "part_list[].extend", "torch.tensor.encode", "len", "torch.full.cpu().numpy().tobytes", "torch.full.cpu().numpy", "torch.full.cpu"], "function", ["None"], ["        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "# cfg.model.pretrains = None", "\n", "", "if", "hasattr", "(", "cfg", ".", "model", ",", "'detector'", ")", ":", "\n", "        ", "cfg", ".", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# build the dataloader", "\n", "", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "if", "cfg", ".", "get", "(", "'test_cfg'", ",", "False", ")", ":", "\n", "        ", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "cfg", ".", "train_cfg", ",", "test_cfg", "=", "cfg", ".", "test_cfg", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "cfg", ".", "model", ")", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "load_checkpoint", "(", "\n", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "            ", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "if", "not", "hasattr", "(", "model", ",", "'CLASSES'", ")", ":", "\n", "        ", "model", ".", "CLASSES", "=", "dataset", ".", "CLASSES", "\n", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "if", "not", "distributed", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "outputs", "=", "single_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "show", ",", "args", ".", "show_dir", ",", "\n", "args", ".", "show_score_thr", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build": [[12, 35], ["isinstance", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg", "torch.Sequential", "mmdet.models.DETECTORS", "mmdet.models.DETECTORS"], "function", ["None"], ["\n", "\n", "def", "build_dataloader", "(", "dataset", ",", "\n", "samples_per_gpu", ",", "\n", "workers_per_gpu", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_tracker": [[37, 40], ["builder.build"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], []], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_motion": [[42, 45], ["builder.build"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], ["rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "dist", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "sampler", "=", "DistributedGroupSampler", "(", "dataset", ",", "samples_per_gpu", ",", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_reid": [[47, 50], ["builder.build"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], ["", "else", ":", "\n", "            ", "if", "dataset", ".", "load_as_video", ":", "\n", "                ", "sampler", "=", "DistributedVideoSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_aggregator": [[52, 55], ["builder.build"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], ["                ", "sampler", "=", "DistributedSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "False", ")", "\n", "", "", "batch_size", "=", "samples_per_gpu", "\n", "num_workers", "=", "workers_per_gpu", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector": [[57, 64], ["builder.build", "builder.build", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], ["        ", "sampler", "=", "GroupSampler", "(", "dataset", ",", "samples_per_gpu", ")", "if", "shuffle", "else", "None", "\n", "batch_size", "=", "num_gpus", "*", "samples_per_gpu", "\n", "num_workers", "=", "num_gpus", "*", "workers_per_gpu", "\n", "\n", "", "init_fn", "=", "partial", "(", "\n", "worker_init_fn", ",", "num_workers", "=", "num_workers", ",", "rank", "=", "rank", ",", "\n", "seed", "=", "seed", ")", "if", "seed", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model": [[66, 72], ["builder.build", "builder.build", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build"], ["dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "partial", "(", "collate", ",", "samples_per_gpu", "=", "samples_per_gpu", ")", ",", "\n", "pin_memory", "=", "False", ",", "\n", "worker_init_fn", "=", "init_fn", ",", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.__init__": [[25, 45], ["numpy.eye", "range", "numpy.eye"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "center_only", "=", "False", ")", ":", "\n", "        ", "self", ".", "center_only", "=", "center_only", "\n", "if", "self", ".", "center_only", ":", "\n", "            ", "self", ".", "gating_threshold", "=", "self", ".", "chi2inv95", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "gating_threshold", "=", "self", ".", "chi2inv95", "[", "4", "]", "\n", "\n", "", "ndim", ",", "dt", "=", "4", ",", "1.", "\n", "\n", "# Create Kalman filter model matrices.", "\n", "self", ".", "_motion_mat", "=", "np", ".", "eye", "(", "2", "*", "ndim", ",", "2", "*", "ndim", ")", "\n", "for", "i", "in", "range", "(", "ndim", ")", ":", "\n", "            ", "self", ".", "_motion_mat", "[", "i", ",", "ndim", "+", "i", "]", "=", "dt", "\n", "", "self", ".", "_update_mat", "=", "np", ".", "eye", "(", "ndim", ",", "2", "*", "ndim", ")", "\n", "\n", "# Motion and observation uncertainty are chosen relative to the current", "\n", "# state estimate. These weights control the amount of uncertainty in", "\n", "# the model. This is a bit hacky.", "\n", "self", ".", "_std_weight_position", "=", "1.", "/", "20", "\n", "self", ".", "_std_weight_velocity", "=", "1.", "/", "160", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.initiate": [[46, 72], ["numpy.zeros_like", "numpy.diag", "numpy.square"], "methods", ["None"], ["", "def", "initiate", "(", "self", ",", "measurement", ")", ":", "\n", "        ", "\"\"\"Create track from unassociated measurement.\n\n        Args:\n            measurement (ndarray):  Bounding box coordinates (x, y, a, h) with\n            center position (x, y), aspect ratio a, and height h.\n\n        Returns:\n             (ndarray, ndarray): Returns the mean vector (8 dimensional) and\n                covariance matrix (8x8 dimensional) of the new track.\n                Unobserved velocities are initialized to 0 mean.\n        \"\"\"", "\n", "mean_pos", "=", "measurement", "\n", "mean_vel", "=", "np", ".", "zeros_like", "(", "mean_pos", ")", "\n", "mean", "=", "np", ".", "r_", "[", "mean_pos", ",", "mean_vel", "]", "\n", "\n", "std", "=", "[", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "1e-2", ",", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", ",", "1e-5", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", "\n", "]", "\n", "covariance", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "std", ")", ")", "\n", "return", "mean", ",", "covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.predict": [[73, 105], ["numpy.diag", "numpy.dot", "numpy.square", "numpy.linalg.multi_dot"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "mean", ",", "covariance", ")", ":", "\n", "        ", "\"\"\"Run Kalman filter prediction step.\n\n        Args:\n            mean (ndarray): The 8 dimensional mean vector of the object\n                state at the previous time step.\n\n            covariance (ndarray): The 8x8 dimensional covariance matrix\n                of the object state at the previous time step.\n\n        Returns:\n            (ndarray, ndarray): Returns the mean vector and covariance\n                matrix of the predicted state. Unobserved velocities are\n                initialized to 0 mean.\n        \"\"\"", "\n", "std_pos", "=", "[", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "1e-2", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", "\n", "]", "\n", "std_vel", "=", "[", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", ",", "1e-5", ",", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", "\n", "]", "\n", "motion_cov", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "np", ".", "r_", "[", "std_pos", ",", "std_vel", "]", ")", ")", "\n", "\n", "mean", "=", "np", ".", "dot", "(", "self", ".", "_motion_mat", ",", "mean", ")", "\n", "covariance", "=", "np", ".", "linalg", ".", "multi_dot", "(", "\n", "(", "self", ".", "_motion_mat", ",", "covariance", ",", "self", ".", "_motion_mat", ".", "T", ")", ")", "+", "motion_cov", "\n", "\n", "return", "mean", ",", "covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.project": [[106, 129], ["numpy.diag", "numpy.dot", "numpy.linalg.multi_dot", "numpy.square"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "mean", ",", "covariance", ")", ":", "\n", "        ", "\"\"\"Project state distribution to measurement space.\n\n        Args:\n            mean (ndarray): The state's mean vector (8 dimensional array).\n            covariance (ndarray): The state's covariance matrix (8x8\n                dimensional).\n\n        Returns:\n            (ndarray, ndarray):  Returns the projected mean and covariance\n            matrix of the given state estimate.\n        \"\"\"", "\n", "std", "=", "[", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "1e-1", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", "\n", "]", "\n", "innovation_cov", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "std", ")", ")", "\n", "\n", "mean", "=", "np", ".", "dot", "(", "self", ".", "_update_mat", ",", "mean", ")", "\n", "covariance", "=", "np", ".", "linalg", ".", "multi_dot", "(", "\n", "(", "self", ".", "_update_mat", ",", "covariance", ",", "self", ".", "_update_mat", ".", "T", ")", ")", "\n", "return", "mean", ",", "covariance", "+", "innovation_cov", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.update": [[130, 160], ["kalman_filter.KalmanFilter.project", "scipy.linalg.cho_factor", "scipy.linalg.cho_solve", "numpy.dot", "numpy.linalg.multi_dot", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.project"], ["", "def", "update", "(", "self", ",", "mean", ",", "covariance", ",", "measurement", ")", ":", "\n", "        ", "\"\"\"Run Kalman filter correction step.\n\n        Args:\n            mean (ndarray): The predicted state's mean vector (8 dimensional).\n            covariance (ndarray): The state's covariance matrix (8x8\n                dimensional).\n            measurement (ndarray): The 4 dimensional measurement vector\n                (x, y, a, h), where (x, y) is the center position, a the\n                aspect ratio, and h the height of the bounding box.\n\n\n        Returns:\n             (ndarray, ndarray): Returns the measurement-corrected state\n             distribution.\n        \"\"\"", "\n", "projected_mean", ",", "projected_cov", "=", "self", ".", "project", "(", "mean", ",", "covariance", ")", "\n", "\n", "chol_factor", ",", "lower", "=", "scipy", ".", "linalg", ".", "cho_factor", "(", "\n", "projected_cov", ",", "lower", "=", "True", ",", "check_finite", "=", "False", ")", "\n", "kalman_gain", "=", "scipy", ".", "linalg", ".", "cho_solve", "(", "(", "chol_factor", ",", "lower", ")", ",", "\n", "np", ".", "dot", "(", "covariance", ",", "\n", "self", ".", "_update_mat", ".", "T", ")", ".", "T", ",", "\n", "check_finite", "=", "False", ")", ".", "T", "\n", "innovation", "=", "measurement", "-", "projected_mean", "\n", "\n", "new_mean", "=", "mean", "+", "np", ".", "dot", "(", "innovation", ",", "kalman_gain", ".", "T", ")", "\n", "new_covariance", "=", "covariance", "-", "np", ".", "linalg", ".", "multi_dot", "(", "\n", "(", "kalman_gain", ",", "projected_cov", ",", "kalman_gain", ".", "T", ")", ")", "\n", "return", "new_mean", ",", "new_covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.gating_distance": [[161, 205], ["kalman_filter.KalmanFilter.project", "numpy.linalg.cholesky", "scipy.linalg.solve_triangular", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.project"], ["", "def", "gating_distance", "(", "self", ",", "\n", "mean", ",", "\n", "covariance", ",", "\n", "measurements", ",", "\n", "only_position", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute gating distance between state distribution and measurements.\n\n        A suitable distance threshold can be obtained from `chi2inv95`. If\n        `only_position` is False, the chi-square distribution has 4 degrees of\n        freedom, otherwise 2.\n\n        Args:\n            mean (ndarray): Mean vector over the state distribution (8\n                dimensional).\n            covariance (ndarray): Covariance of the state distribution (8x8\n                dimensional).\n            measurements (ndarray): An Nx4 dimensional matrix of N\n                measurements, each in format (x, y, a, h) where (x, y) is the\n                bounding box center position, a the aspect ratio, and h the\n                height.\n            only_position (bool, optional): If True, distance computation is\n                done with respect to the bounding box center position only.\n                Defaults to False.\n\n        Returns:\n            ndarray: Returns an array of length N, where the i-th element\n            contains the squared Mahalanobis distance between\n            (mean, covariance) and `measurements[i]`.\n        \"\"\"", "\n", "mean", ",", "covariance", "=", "self", ".", "project", "(", "mean", ",", "covariance", ")", "\n", "if", "only_position", ":", "\n", "            ", "mean", ",", "covariance", "=", "mean", "[", ":", "2", "]", ",", "covariance", "[", ":", "2", ",", ":", "2", "]", "\n", "measurements", "=", "measurements", "[", ":", ",", ":", "2", "]", "\n", "\n", "", "cholesky_factor", "=", "np", ".", "linalg", ".", "cholesky", "(", "covariance", ")", "\n", "d", "=", "measurements", "-", "mean", "\n", "z", "=", "scipy", ".", "linalg", ".", "solve_triangular", "(", "\n", "cholesky_factor", ",", "\n", "d", ".", "T", ",", "\n", "lower", "=", "True", ",", "\n", "check_finite", "=", "False", ",", "\n", "overwrite_b", "=", "True", ")", "\n", "squared_maha", "=", "np", ".", "sum", "(", "z", "*", "z", ",", "axis", "=", "0", ")", "\n", "return", "squared_maha", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.track": [[206, 229], ["tracks.items", "numpy.stack", "kalman_filter.KalmanFilter.predict", "kalman_filter.KalmanFilter.gating_distance", "numpy.stack.append", "bboxes.cpu().numpy", "bboxes.cpu"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.predict", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.gating_distance"], ["", "def", "track", "(", "self", ",", "tracks", ",", "bboxes", ")", ":", "\n", "        ", "\"\"\"Track forward.\n\n        Args:\n            tracks (dict[int:dict]): Track buffer.\n            bboxes (Tensor): Detected bounding boxes.\n\n        Returns:\n            (dict[int:dict], Tensor): Updated tracks and bboxes.\n        \"\"\"", "\n", "costs", "=", "[", "]", "\n", "for", "id", ",", "track", "in", "tracks", ".", "items", "(", ")", ":", "\n", "            ", "track", ".", "mean", ",", "track", ".", "covariance", "=", "self", ".", "predict", "(", "\n", "track", ".", "mean", ",", "track", ".", "covariance", ")", "\n", "gating_distance", "=", "self", ".", "gating_distance", "(", "track", ".", "mean", ",", "\n", "track", ".", "covariance", ",", "\n", "bboxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "self", ".", "center_only", ")", "\n", "costs", ".", "append", "(", "gating_distance", ")", "\n", "\n", "", "costs", "=", "np", ".", "stack", "(", "costs", ",", "0", ")", "\n", "costs", "[", "costs", ">", "self", ".", "gating_threshold", "]", "=", "np", ".", "nan", "\n", "return", "tracks", ",", "costs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.__init__": [[38, 143], ["torch.Module.__init__", "range", "range", "mmcv.cnn.bricks.ConvModule", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList.append", "range", "flownet_simple.FlowNetSimple.add_module", "flownet_simple.FlowNetSimple.conv_layers.append", "mmcv.cnn.bricks.ConvModule", "flownet_simple.FlowNetSimple.add_module", "flownet_simple.FlowNetSimple.deconv_layers.insert", "mmcv.cnn.bricks.ConvModule", "flownet_simple.FlowNetSimple.add_module", "flownet_simple.FlowNetSimple.flow_layers.insert", "mmcv.cnn.bricks.ConvModule", "flownet_simple.FlowNetSimple.add_module", "flownet_simple.FlowNetSimple.upflow_layers.insert", "mmcv.cnn.bricks.ConvModule", "torch.ModuleList.append", "len", "dict", "len", "mmcv.cnn.bricks.ConvModule", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "img_scale_factor", ",", "\n", "out_indices", "=", "[", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", ",", "\n", "flow_scale_factor", "=", "5.0", ",", "\n", "flow_img_norm_std", "=", "[", "255.0", ",", "255.0", ",", "255.0", "]", ",", "\n", "flow_img_norm_mean", "=", "[", "0.411", ",", "0.432", ",", "0.450", "]", ")", ":", "\n", "        ", "super", "(", "FlowNetSimple", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_scale_factor", "=", "img_scale_factor", "\n", "self", ".", "out_indices", "=", "out_indices", "\n", "self", ".", "flow_scale_factor", "=", "flow_scale_factor", "\n", "self", ".", "flow_img_norm_mean", "=", "flow_img_norm_mean", "\n", "self", ".", "flow_img_norm_std", "=", "flow_img_norm_std", "\n", "\n", "self", ".", "conv_layers", "=", "[", "]", "\n", "conv_layers_setting", "=", "self", ".", "arch_setting", "[", "'conv_layers'", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_layers_setting", "[", "'inplanes'", "]", ")", ")", ":", "\n", "            ", "num_convs", "=", "conv_layers_setting", "[", "'num_convs'", "]", "[", "i", "]", "\n", "kernel_size", "=", "conv_layers_setting", "[", "'kernel_size'", "]", "[", "i", "]", "\n", "inplanes", "=", "conv_layers_setting", "[", "'inplanes'", "]", "[", "i", "]", "\n", "if", "i", "==", "len", "(", "conv_layers_setting", "[", "'inplanes'", "]", ")", "-", "1", ":", "\n", "                ", "planes", "=", "2", "*", "inplanes", "\n", "", "else", ":", "\n", "                ", "planes", "=", "conv_layers_setting", "[", "'inplanes'", "]", "[", "i", "+", "1", "]", "\n", "\n", "", "conv_layer", "=", "nn", ".", "ModuleList", "(", ")", "\n", "conv_layer", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "inplanes", ",", "\n", "out_channels", "=", "planes", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "\n", "bias", "=", "True", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'LeakyReLU'", ",", "negative_slope", "=", "0.1", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "num_convs", ")", ":", "\n", "                ", "kernel_size", "=", "3", "if", "i", "==", "2", "else", "kernel_size", "\n", "conv_layer", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "planes", ",", "\n", "out_channels", "=", "planes", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "\n", "bias", "=", "True", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'LeakyReLU'", ",", "negative_slope", "=", "0.1", ")", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "f'conv{i+1}'", ",", "conv_layer", ")", "\n", "self", ".", "conv_layers", ".", "append", "(", "f'conv{i+1}'", ")", "\n", "\n", "", "self", ".", "deconv_layers", "=", "[", "]", "\n", "self", ".", "flow_layers", "=", "[", "]", "\n", "self", ".", "upflow_layers", "=", "[", "]", "\n", "deconv_layers_setting", "=", "self", ".", "arch_setting", "[", "'deconv_layers'", "]", "\n", "planes", "=", "deconv_layers_setting", "[", "'inplanes'", "]", "[", "-", "1", "]", "//", "2", "\n", "for", "i", "in", "range", "(", "len", "(", "deconv_layers_setting", "[", "'inplanes'", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "inplanes", "=", "deconv_layers_setting", "[", "'inplanes'", "]", "[", "i", "]", "\n", "\n", "deconv_layer", "=", "ConvModule", "(", "\n", "in_channels", "=", "inplanes", ",", "\n", "out_channels", "=", "planes", ",", "\n", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'deconv'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'LeakyReLU'", ",", "negative_slope", "=", "0.1", ")", ")", "\n", "self", ".", "add_module", "(", "f'deconv{i+2}'", ",", "deconv_layer", ")", "\n", "self", ".", "deconv_layers", ".", "insert", "(", "0", ",", "f'deconv{i+2}'", ")", "\n", "\n", "flow_layer", "=", "ConvModule", "(", "\n", "in_channels", "=", "inplanes", ",", "\n", "out_channels", "=", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "act_cfg", "=", "None", ")", "\n", "self", ".", "add_module", "(", "f'predict_flow{i+3}'", ",", "flow_layer", ")", "\n", "self", ".", "flow_layers", ".", "insert", "(", "0", ",", "f'predict_flow{i+3}'", ")", "\n", "\n", "upflow_layer", "=", "ConvModule", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'deconv'", ")", ",", "\n", "act_cfg", "=", "None", ")", "\n", "self", ".", "add_module", "(", "f'upsample_flow{i+2}'", ",", "upflow_layer", ")", "\n", "self", ".", "upflow_layers", ".", "insert", "(", "0", ",", "f'upsample_flow{i+2}'", ")", "\n", "planes", "=", "planes", "//", "2", "\n", "\n", "", "self", ".", "predict_flow", "=", "ConvModule", "(", "\n", "in_channels", "=", "planes", "*", "(", "2", "+", "4", ")", "+", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.init_weights": [[144, 148], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize the weight FlowNetSimple.\"\"\"", "\n", "# using the default initialization in ConvModule.", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.prepare_imgs": [[149, 193], ["torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "hasattr", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "hasattr", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat", "torch.tensor.repeat"], "methods", ["None"], ["", "def", "prepare_imgs", "(", "self", ",", "imgs", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Preprocess images pairs for computing flow.\n\n        Args:\n            imgs (Tensor): of shape (N, 6, H, W) encoding input images pairs.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n        Returns:\n            Tensor: of shape (N, 6, H, W) encoding the input images pairs for\n            FlowNetSimple.\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'img_norm_mean'", ")", ":", "\n", "            ", "mean", "=", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", "[", "'mean'", "]", "\n", "mean", "=", "torch", ".", "tensor", "(", "mean", ",", "device", "=", "imgs", ".", "device", ")", "\n", "self", ".", "img_norm_mean", "=", "mean", ".", "repeat", "(", "2", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "mean", "=", "self", ".", "flow_img_norm_mean", "\n", "mean", "=", "torch", ".", "tensor", "(", "mean", ",", "device", "=", "imgs", ".", "device", ")", "\n", "self", ".", "flow_img_norm_mean", "=", "mean", ".", "repeat", "(", "2", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'img_norm_std'", ")", ":", "\n", "            ", "std", "=", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", "[", "'std'", "]", "\n", "std", "=", "torch", ".", "tensor", "(", "std", ",", "device", "=", "imgs", ".", "device", ")", "\n", "self", ".", "img_norm_std", "=", "std", ".", "repeat", "(", "2", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "std", "=", "self", ".", "flow_img_norm_std", "\n", "std", "=", "torch", ".", "tensor", "(", "std", ",", "device", "=", "imgs", ".", "device", ")", "\n", "self", ".", "flow_img_norm_std", "=", "std", ".", "repeat", "(", "2", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "flow_img", "=", "imgs", "*", "self", ".", "img_norm_std", "+", "self", ".", "img_norm_mean", "\n", "flow_img", "=", "flow_img", "/", "self", ".", "flow_img_norm_std", "-", "self", ".", "flow_img_norm_mean", "\n", "flow_img", "[", ":", ",", ":", ",", "img_metas", "[", "0", "]", "[", "'img_shape'", "]", "[", "0", "]", ":", ",", ":", "]", "=", "0.0", "\n", "flow_img", "[", ":", ",", ":", ",", ":", ",", "img_metas", "[", "0", "]", "[", "'img_shape'", "]", "[", "1", "]", ":", "]", "=", "0.0", "\n", "flow_img", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "flow_img", ",", "\n", "scale_factor", "=", "self", ".", "img_scale_factor", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "return", "flow_img", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.forward": [[194, 245], ["flownet_simple.FlowNetSimple.prepare_imgs", "enumerate", "len", "zip", "flownet_simple.FlowNetSimple.predict_flow", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "getattr", "getattr", "getattr", "getattr", "getattr.", "flownet_simple.FlowNetSimple.crop_like", "flownet_simple.FlowNetSimple.crop_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "module", "conv_outs.append", "range", "getattr.", "getattr."], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.prepare_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.crop_like", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.crop_like"], ["", "def", "forward", "(", "self", ",", "imgs", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Compute the flow of images pairs.\n\n        Args:\n            imgs (Tensor): of shape (N, 6, H, W) encoding input images pairs.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n        Returns:\n            Tensor: of shape (N, 2, H, W) encoding flow of images pairs.\n        \"\"\"", "\n", "x", "=", "self", ".", "prepare_imgs", "(", "imgs", ",", "img_metas", ")", "\n", "conv_outs", "=", "[", "]", "\n", "for", "i", ",", "conv_name", "in", "enumerate", "(", "self", ".", "conv_layers", ",", "1", ")", ":", "\n", "            ", "conv_layer", "=", "getattr", "(", "self", ",", "conv_name", ")", "\n", "for", "module", "in", "conv_layer", ":", "\n", "                ", "x", "=", "module", "(", "x", ")", "\n", "", "if", "i", "in", "self", ".", "out_indices", ":", "\n", "                ", "conv_outs", ".", "append", "(", "x", ")", "\n", "\n", "", "", "num_outs", "=", "len", "(", "conv_outs", ")", "\n", "for", "i", ",", "deconv_name", ",", "flow_name", ",", "upflow_name", "in", "zip", "(", "\n", "range", "(", "1", ",", "num_outs", ")", "[", ":", ":", "-", "1", "]", ",", "self", ".", "deconv_layers", "[", ":", ":", "-", "1", "]", ",", "\n", "self", ".", "flow_layers", "[", ":", ":", "-", "1", "]", ",", "self", ".", "upflow_layers", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "            ", "deconv_layer", "=", "getattr", "(", "self", ",", "deconv_name", ")", "\n", "flow_layer", "=", "getattr", "(", "self", ",", "flow_name", ")", "\n", "upflow_layer", "=", "getattr", "(", "self", ",", "upflow_name", ")", "\n", "\n", "if", "i", "==", "num_outs", "-", "1", ":", "\n", "                ", "concat_out", "=", "conv_outs", "[", "i", "]", "\n", "", "flow", "=", "flow_layer", "(", "concat_out", ")", "\n", "upflow", "=", "self", ".", "crop_like", "(", "upflow_layer", "(", "flow", ")", ",", "conv_outs", "[", "i", "-", "1", "]", ")", "\n", "deconv_out", "=", "self", ".", "crop_like", "(", "\n", "deconv_layer", "(", "concat_out", ")", ",", "conv_outs", "[", "i", "-", "1", "]", ")", "\n", "concat_out", "=", "torch", ".", "cat", "(", "(", "conv_outs", "[", "i", "-", "1", "]", ",", "deconv_out", ",", "upflow", ")", ",", "\n", "dim", "=", "1", ")", "\n", "\n", "", "flow", "=", "self", ".", "predict_flow", "(", "concat_out", ")", "\n", "flow", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "flow", ",", "\n", "scale_factor", "=", "4", "/", "self", ".", "img_scale_factor", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "flow", "*=", "4", "/", "self", ".", "img_scale_factor", "\n", "flow", "*=", "self", ".", "flow_scale_factor", "\n", "\n", "return", "flow", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flownet_simple.FlowNetSimple.crop_like": [[246, 252], ["input.size", "target.size", "target.size", "target.size"], "methods", ["None"], ["", "def", "crop_like", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"Crop `input` as the size of `target`.\"\"\"", "\n", "if", "input", ".", "size", "(", ")", "[", "2", ":", "]", "==", "target", ".", "size", "(", ")", "[", "2", ":", "]", ":", "\n", "            ", "return", "input", "\n", "", "else", ":", "\n", "            ", "return", "input", "[", ":", ",", ":", ",", ":", "target", ".", "size", "(", "2", ")", ",", ":", "target", ".", "size", "(", "3", ")", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.__init__": [[17, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_samples", "=", "2", ",", "center_motion", "=", "False", ")", ":", "\n", "        ", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "center_motion", "=", "center_motion", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.center": [[21, 28], ["torch.Tensor().to", "torch.Tensor"], "methods", ["None"], ["", "def", "center", "(", "self", ",", "bbox", ")", ":", "\n", "        ", "\"\"\"Get the center of the box.\"\"\"", "\n", "if", "bbox", ".", "ndim", "==", "2", ":", "\n", "            ", "assert", "bbox", ".", "shape", "[", "0", "]", "==", "1", "\n", "bbox", "=", "bbox", "[", "0", "]", "\n", "", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "bbox", "\n", "return", "torch", ".", "Tensor", "(", "[", "(", "x2", "+", "x1", ")", "/", "2", ",", "(", "y2", "+", "y1", ")", "/", "2", "]", ")", ".", "to", "(", "bbox", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.get_velocity": [[29, 42], ["zip", "torch.stack().mean", "min", "vs.append", "len", "torch.stack", "linear_motion.LinearMotion.center", "linear_motion.LinearMotion.center"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.center", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.center"], ["", "def", "get_velocity", "(", "self", ",", "bboxes", ",", "num_samples", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get velocities of the input objects.\"\"\"", "\n", "if", "num_samples", "is", "None", ":", "\n", "            ", "num_samples", "=", "min", "(", "len", "(", "bboxes", ")", ",", "self", ".", "num_samples", ")", "\n", "\n", "", "vs", "=", "[", "]", "\n", "for", "(", "b1", ",", "b2", ")", "in", "zip", "(", "bboxes", "[", "-", "num_samples", ":", "]", ",", "bboxes", "[", "-", "num_samples", "+", "1", ":", "]", ")", ":", "\n", "            ", "if", "self", ".", "center_motion", ":", "\n", "                ", "v", "=", "self", ".", "center", "(", "b2", ")", "-", "self", ".", "center", "(", "b1", ")", "\n", "", "else", ":", "\n", "                ", "v", "=", "b2", "-", "b1", "\n", "", "vs", ".", "append", "(", "v", ")", "\n", "", "return", "torch", ".", "stack", "(", "vs", ",", "dim", "=", "0", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step": [[43, 63], ["isinstance", "linear_motion.LinearMotion.get_velocity", "torch.Tensor().to", "linear_motion.LinearMotion.center", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.get_velocity", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.center"], ["", "def", "step", "(", "self", ",", "bboxes", ",", "velocity", "=", "None", ")", ":", "\n", "        ", "\"\"\"Step forward with the velocity.\"\"\"", "\n", "assert", "isinstance", "(", "bboxes", ",", "list", ")", "\n", "if", "velocity", "is", "None", ":", "\n", "            ", "velocity", "=", "self", ".", "get_velocity", "(", "bboxes", ")", "\n", "", "bbox", "=", "bboxes", "[", "-", "1", "]", "\n", "if", "bbox", ".", "ndim", "==", "2", ":", "\n", "            ", "assert", "bbox", ".", "shape", "[", "0", "]", "==", "1", "\n", "bbox", "=", "bbox", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "center_motion", ":", "\n", "            ", "cx", ",", "cy", "=", "self", ".", "center", "(", "bbox", ")", "+", "velocity", "\n", "w", "=", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", "\n", "h", "=", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", "\n", "bbox", "=", "torch", ".", "Tensor", "(", "\n", "[", "cx", "-", "w", "/", "2", ",", "cy", "-", "h", "/", "2", ",", "cx", "+", "w", "/", "2", ",", "\n", "cy", "+", "h", "/", "2", "]", ")", ".", "to", "(", "bbox", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "bbox", "+=", "velocity", "\n", "", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.track": [[64, 78], ["tracks.items", "int", "len", "enumerate", "min", "linear_motion.LinearMotion.get_velocity", "zip", "linear_motion.LinearMotion.step"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.get_velocity", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step"], ["", "def", "track", "(", "self", ",", "tracks", ",", "frame_id", ")", ":", "\n", "        ", "\"\"\"Tracking forward.\"\"\"", "\n", "for", "k", ",", "v", "in", "tracks", ".", "items", "(", ")", ":", "\n", "            ", "if", "int", "(", "v", ".", "frame_ids", "[", "-", "1", "]", ")", "==", "frame_id", "-", "1", ":", "\n", "                ", "rids", "=", "v", ".", "frame_ids", "[", ":", ":", "-", "1", "]", "\n", "num_bboxes", "=", "len", "(", "v", ".", "bboxes", ")", "\n", "for", "n", ",", "(", "i", ",", "j", ")", "in", "enumerate", "(", "zip", "(", "rids", ",", "rids", "[", "1", ":", "]", ")", ",", "1", ")", ":", "\n", "                    ", "if", "i", "!=", "j", "+", "1", ":", "\n", "                        ", "num_bboxes", "=", "n", "\n", "", "", "num_samples", "=", "min", "(", "num_bboxes", ",", "self", ".", "num_samples", ")", "\n", "v", ".", "velocity", "=", "self", ".", "get_velocity", "(", "v", ".", "bboxes", ",", "num_samples", ")", "\n", "", "if", "'velocity'", "in", "v", ":", "\n", "                ", "v", ".", "bboxes", "[", "-", "1", "]", "=", "self", ".", "step", "(", "v", ".", "bboxes", ",", "v", ".", "velocity", ")", "[", "None", "]", "\n", "", "", "return", "tracks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.__init__": [[18, 25], ["eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "warp_mode", "=", "'cv2.MOTION_EUCLIDEAN'", ",", "\n", "num_iters", "=", "50", ",", "\n", "stop_eps", "=", "0.001", ")", ":", "\n", "        ", "self", ".", "warp_mode", "=", "eval", "(", "warp_mode", ")", "\n", "self", ".", "num_iters", "=", "num_iters", "\n", "self", ".", "stop_eps", "=", "stop_eps", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.get_warp_matrix": [[26, 39], ["cv2.cvtColor", "cv2.cvtColor", "numpy.eye", "cv2.findTransformECC", "torch.from_numpy"], "methods", ["None"], ["", "def", "get_warp_matrix", "(", "self", ",", "img", ",", "ref_img", ")", ":", "\n", "        ", "\"\"\"Calculate warping matrix between two images.\"\"\"", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "ref_img", "=", "cv2", ".", "cvtColor", "(", "ref_img", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "\n", "warp_matrix", "=", "np", ".", "eye", "(", "2", ",", "3", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "criteria", "=", "(", "cv2", ".", "TERM_CRITERIA_EPS", "|", "cv2", ".", "TERM_CRITERIA_COUNT", ",", "\n", "self", ".", "num_iters", ",", "self", ".", "stop_eps", ")", "\n", "cc", ",", "warp_matrix", "=", "cv2", ".", "findTransformECC", "(", "img", ",", "ref_img", ",", "warp_matrix", ",", "\n", "self", ".", "warp_mode", ",", "criteria", ",", "None", ",", "\n", "1", ")", "\n", "warp_matrix", "=", "torch", ".", "from_numpy", "(", "warp_matrix", ")", "\n", "return", "warp_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.warp_bboxes": [[40, 51], ["torch.cat", "torch.cat", "torch.mm().t", "torch.mm().t", "torch.cat", "torch.cat.to", "torch.ones().to", "torch.ones().to", "torch.mm", "torch.mm", "torch.cat.t", "torch.cat.t", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "warp_bboxes", "(", "self", ",", "bboxes", ",", "warp_matrix", ")", ":", "\n", "        ", "\"\"\"Warp bounding boxes according to the warping matrix.\"\"\"", "\n", "tl", ",", "br", "=", "bboxes", "[", ":", ",", ":", "2", "]", ",", "bboxes", "[", ":", ",", "2", ":", "]", "\n", "tl", "=", "torch", ".", "cat", "(", "(", "tl", ",", "torch", ".", "ones", "(", "tl", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "to", "(", "bboxes", ".", "device", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "br", "=", "torch", ".", "cat", "(", "(", "br", ",", "torch", ".", "ones", "(", "tl", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "to", "(", "bboxes", ".", "device", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "trans_tl", "=", "torch", ".", "mm", "(", "warp_matrix", ",", "tl", ".", "t", "(", ")", ")", ".", "t", "(", ")", "\n", "trans_br", "=", "torch", ".", "mm", "(", "warp_matrix", ",", "br", ".", "t", "(", ")", ")", ".", "t", "(", ")", "\n", "trans_bboxes", "=", "torch", ".", "cat", "(", "(", "trans_tl", ",", "trans_br", ")", ",", "dim", "=", "1", ")", "\n", "return", "trans_bboxes", ".", "to", "(", "bboxes", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.track": [[52, 76], ["img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose", "ref_img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose", "camera_motion_compensation.CameraMotionCompensation.get_warp_matrix", "tracks.items", "torch.cat", "camera_motion_compensation.CameraMotionCompensation.warp_bboxes", "torch.split", "zip", "num_bboxes.append", "torch.cat.extend", "camera_motion_compensation.CameraMotionCompensation.to", "tracks.items", "torch.split", "img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy", "ref_img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy", "int", "min", "len", "img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu", "ref_img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze().cpu", "img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze", "ref_img.squeeze().cpu().numpy().transpose.squeeze().cpu().numpy().transpose.squeeze"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.get_warp_matrix", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.warp_bboxes"], ["", "def", "track", "(", "self", ",", "img", ",", "ref_img", ",", "tracks", ",", "num_samples", ",", "frame_id", ")", ":", "\n", "        ", "\"\"\"Tracking forward.\"\"\"", "\n", "img", "=", "img", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "transpose", "(", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "ref_img", "=", "ref_img", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "transpose", "(", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "warp_matrix", "=", "self", ".", "get_warp_matrix", "(", "img", ",", "ref_img", ")", "\n", "\n", "bboxes", "=", "[", "]", "\n", "num_bboxes", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "tracks", ".", "items", "(", ")", ":", "\n", "            ", "if", "int", "(", "v", "[", "'frame_ids'", "]", "[", "-", "1", "]", ")", "<", "frame_id", "-", "1", ":", "\n", "                ", "_num", "=", "1", "\n", "", "else", ":", "\n", "                ", "_num", "=", "min", "(", "num_samples", ",", "len", "(", "v", ".", "bboxes", ")", ")", "\n", "", "num_bboxes", ".", "append", "(", "_num", ")", "\n", "bboxes", ".", "extend", "(", "v", ".", "bboxes", "[", "-", "_num", ":", "]", ")", "\n", "", "bboxes", "=", "torch", ".", "cat", "(", "bboxes", ",", "dim", "=", "0", ")", "\n", "warped_bboxes", "=", "self", ".", "warp_bboxes", "(", "bboxes", ",", "warp_matrix", ".", "to", "(", "bboxes", ".", "device", ")", ")", "\n", "\n", "warped_bboxes", "=", "torch", ".", "split", "(", "warped_bboxes", ",", "num_bboxes", ")", "\n", "for", "b", ",", "(", "k", ",", "v", ")", "in", "zip", "(", "warped_bboxes", ",", "tracks", ".", "items", "(", ")", ")", ":", "\n", "            ", "_num", "=", "b", ".", "shape", "[", "0", "]", "\n", "b", "=", "torch", ".", "split", "(", "b", ",", "[", "1", "]", "*", "_num", ")", "\n", "tracks", "[", "k", "]", ".", "bboxes", "[", "-", "_num", ":", "]", "=", "b", "\n", "", "return", "tracks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats": [[4, 42], ["torch.nn.functional.interpolate", "torch.meshgrid", "torch.cat", "grid.permute.permute", "torch.nn.functional.grid_sample", "len", "float", "torch.arange", "torch.arange", "h_grid.to().float", "w_grid.to().float", "len", "h_grid.to", "w_grid.to"], "function", ["None"], ["def", "flow_warp_feats", "(", "x", ",", "flow", ")", ":", "\n", "    ", "\"\"\"Use flow to warp feature map.\n\n    Args:\n        x (Tensor): of shape (N, C, H_x, W_x).\n        flow (Tensor): of shape (N, C, H_f, W_f).\n\n    Returns:\n        Tensor: The warpped feature map with shape (N, C, H_x, W_x).\n    \"\"\"", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "\n", "assert", "len", "(", "flow", ".", "shape", ")", "==", "4", "and", "flow", ".", "shape", "[", "1", "]", "==", "2", "\n", "# 1. resize the resolution of flow to be the same as x.", "\n", "scale_factor", "=", "float", "(", "x", ".", "shape", "[", "-", "1", "]", ")", "/", "flow", ".", "shape", "[", "-", "1", "]", "\n", "flow", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "flow", ",", "scale_factor", "=", "scale_factor", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "flow", "=", "flow", "*", "scale_factor", "\n", "\n", "# 2. compute the flow_field (grid in the code) used to warp features.", "\n", "H", ",", "W", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "h_grid", ",", "w_grid", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "H", ")", ",", "torch", ".", "arange", "(", "W", ")", ")", "\n", "# [1, 1, H, W]", "\n", "h_grid", "=", "h_grid", ".", "to", "(", "flow", ".", "device", ")", ".", "float", "(", ")", "[", "None", ",", "None", ",", "...", "]", "\n", "# [1, 1, H, W]", "\n", "w_grid", "=", "w_grid", ".", "to", "(", "flow", ".", "device", ")", ".", "float", "(", ")", "[", "None", ",", "None", ",", "...", "]", "\n", "# [1, 2, H, W]", "\n", "grid", "=", "torch", ".", "cat", "(", "(", "w_grid", ",", "h_grid", ")", ",", "dim", "=", "1", ")", "\n", "# [N, 2, H, W]", "\n", "grid", "=", "grid", "+", "flow", "\n", "grid", "[", ":", ",", "0", "]", "=", "grid", "[", ":", ",", "0", "]", "/", "W", "*", "2", "-", "1", "\n", "grid", "[", ":", ",", "1", "]", "=", "grid", "[", ":", ",", "1", "]", "/", "H", "*", "2", "-", "1", "\n", "# [N, H, W, 2]", "\n", "grid", "=", "grid", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "# 3. warp features.", "\n", "x_warp", "=", "torch", ".", "nn", ".", "functional", ".", "grid_sample", "(", "\n", "x", ",", "grid", ",", "padding_mode", "=", "'border'", ",", "align_corners", "=", "True", ")", "\n", "return", "x_warp", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.__init__": [[19, 53], ["dict", "torch.Module.__init__", "torch.Linear", "fc_module.FcModule.init_weights", "isinstance", "isinstance", "mmcv.cnn.build_norm_layer", "fc_module.FcModule.add_module", "act_cfg.copy", "mmcv.cnn.build_activation_layer", "act_cfg.copy.setdefault"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "inplace", "=", "True", ")", ":", "\n", "        ", "super", "(", "FcModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "norm_cfg", "is", "None", "or", "isinstance", "(", "norm_cfg", ",", "dict", ")", "\n", "assert", "act_cfg", "is", "None", "or", "isinstance", "(", "act_cfg", ",", "dict", ")", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n", "self", ".", "with_norm", "=", "norm_cfg", "is", "not", "None", "\n", "self", ".", "with_activation", "=", "act_cfg", "is", "not", "None", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_channels", ",", "out_channels", ")", "\n", "# build normalization layers", "\n", "if", "self", ".", "with_norm", ":", "\n", "            ", "self", ".", "norm_name", ",", "norm", "=", "build_norm_layer", "(", "norm_cfg", ",", "out_channels", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm_name", ",", "norm", ")", "\n", "\n", "# build activation layer", "\n", "", "if", "self", ".", "with_activation", ":", "\n", "            ", "act_cfg_", "=", "act_cfg", ".", "copy", "(", ")", "\n", "# nn.Tanh has no 'inplace' argument", "\n", "if", "act_cfg_", "[", "'type'", "]", "not", "in", "[", "\n", "'Tanh'", ",", "'PReLU'", ",", "'Sigmoid'", ",", "'HSigmoid'", ",", "'Swish'", "\n", "]", ":", "\n", "                ", "act_cfg_", ".", "setdefault", "(", "'inplace'", ",", "inplace", ")", "\n", "", "self", ".", "activate", "=", "build_activation_layer", "(", "act_cfg_", ")", "\n", "\n", "# Use msra init by default", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm": [[54, 58], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Normalization.\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.init_weights": [[59, 64], ["mmcv.cnn.kaiming_init", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize weights.\"\"\"", "\n", "kaiming_init", "(", "self", ".", "fc", ")", "\n", "if", "self", ".", "with_norm", ":", "\n", "            ", "constant_init", "(", "self", ".", "norm", ",", "1", ",", "bias", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.forward": [[65, 73], ["fc_module.FcModule.fc", "fc_module.FcModule.norm", "fc_module.FcModule.activate"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "activate", "=", "True", ",", "norm", "=", "True", ")", ":", "\n", "        ", "\"\"\"Model forward.\"\"\"", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "if", "norm", "and", "self", ".", "with_norm", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "activate", "and", "self", ".", "with_activation", ":", "\n", "            ", "x", "=", "self", ".", "activate", "(", "x", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.base_reid.BaseReID.__init__": [[10, 12], ["mmcls.models.ImageClassifier.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.base_reid.BaseReID.forward_train": [[13, 16], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward_train", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\"Training forward function.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.base_reid.BaseReID.simple_test": [[17, 24], ["img.nelement", "base_reid.BaseReID.extract_feat", "base_reid.BaseReID.head.simple_test", "img.new_zeros"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test"], ["", "def", "simple_test", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\"\"\"", "\n", "if", "img", ".", "nelement", "(", ")", ">", "0", ":", "\n", "            ", "x", "=", "self", ".", "extract_feat", "(", "img", ")", "\n", "return", "self", ".", "head", ".", "simple_test", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", ".", "new_zeros", "(", "0", ",", "self", ".", "head", ".", "out_channels", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.gap.GlobalAveragePooling.__init__": [[15, 21], ["mmcls.models.necks.GlobalAveragePooling.__init__", "torch.AdaptiveAvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", "=", "None", ",", "stride", "=", "None", ")", ":", "\n", "        ", "super", "(", "GlobalAveragePooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "kernel_size", "is", "None", "and", "stride", "is", "None", ":", "\n", "            ", "self", ".", "gap", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gap", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", ",", "stride", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead.__init__": [[27, 48], ["dict", "mmcls.models.ClsHead.__init__", "mmcls.models.builder.build_loss", "linear_reid_head.LinearReIDHead._init_layers"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead._init_layers"], ["def", "__init__", "(", "self", ",", "\n", "num_fcs", ",", "\n", "in_channels", ",", "\n", "fc_channels", ",", "\n", "out_channels", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "num_classes", "=", "None", ",", "\n", "loss", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ",", "loss_weight", "=", "1.0", ")", ",", "\n", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "        ", "super", "(", "LinearReIDHead", ",", "self", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "topk", "=", "topk", ")", "\n", "self", ".", "num_fcs", "=", "num_fcs", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "fc_channels", "=", "fc_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "loss", "=", "build_loss", "(", "loss", ")", "\n", "\n", "self", ".", "_init_layers", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead._init_layers": [[49, 60], ["torch.ModuleList", "range", "torch.Linear", "linear_reid_head.LinearReIDHead.fcs.append", "fc_module.FcModule"], "methods", ["None"], ["", "def", "_init_layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize fc layers.\"\"\"", "\n", "self", ".", "fcs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_fcs", ")", ":", "\n", "            ", "in_channels", "=", "self", ".", "in_channels", "if", "i", "==", "0", "else", "self", ".", "fc_channels", "\n", "self", ".", "fcs", ".", "append", "(", "\n", "FcModule", "(", "in_channels", ",", "self", ".", "fc_channels", ",", "self", ".", "norm_cfg", ",", "\n", "self", ".", "act_cfg", ")", ")", "\n", "", "in_channels", "=", "self", ".", "in_channels", "if", "self", ".", "num_fcs", "==", "0", "else", "self", ".", "fc_channels", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "in_channels", ",", "self", ".", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead.init_weights": [[61, 64], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initalize model weights.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_out", ",", "mean", "=", "0", ",", "std", "=", "0.01", ",", "bias", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead.simple_test": [[65, 71], ["linear_reid_head.LinearReIDHead.fc_out", "m"], "methods", ["None"], ["", "def", "simple_test", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\"\"\"", "\n", "for", "m", "in", "self", ".", "fcs", ":", "\n", "            ", "x", "=", "m", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fc_out", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.linear_reid_head.LinearReIDHead.forward_train": [[72, 80], ["linear_reid_head.LinearReIDHead.fcs", "linear_reid_head.LinearReIDHead.fc_out", "linear_reid_head.LinearReIDHead.loss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss"], ["", "def", "forward_train", "(", "self", ",", "x", ",", "gt_label", ")", ":", "\n", "        ", "\"\"\"Model forward.\"\"\"", "\n", "x", "=", "self", ".", "fcs", "(", "x", ")", "\n", "x", "=", "self", ".", "fc_out", "(", "x", ")", "\n", "if", "self", ".", "num_classes", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "losses", "=", "self", ".", "loss", "(", "x", ",", "gt_label", ")", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.CorrelationHead.__init__": [[31, 66], ["dict", "dict", "torch.Module.__init__", "mmcv.cnn.bricks.ConvModule", "mmcv.cnn.bricks.ConvModule", "torch.Sequential", "torch.Sequential", "mmcv.cnn.bricks.ConvModule", "mmcv.cnn.bricks.ConvModule"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "mid_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CorrelationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_convs", "=", "ConvModule", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "mid_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n", "self", ".", "search_convs", "=", "ConvModule", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "mid_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n", "self", ".", "head_convs", "=", "nn", ".", "Sequential", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "mid_channels", ",", "\n", "out_channels", "=", "mid_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", ",", "\n", "ConvModule", "(", "\n", "in_channels", "=", "mid_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "act_cfg", "=", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.CorrelationHead.forward": [[67, 73], ["siamese_rpn_head.CorrelationHead.kernel_convs", "siamese_rpn_head.CorrelationHead.search_convs", "mmtrack.core.track.depthwise_correlation", "siamese_rpn_head.CorrelationHead.head_convs"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.correlation.depthwise_correlation"], ["", "def", "forward", "(", "self", ",", "kernel", ",", "search", ")", ":", "\n", "        ", "kernel", "=", "self", ".", "kernel_convs", "(", "kernel", ")", "\n", "search", "=", "self", ".", "search_convs", "(", "search", ")", "\n", "correlation_maps", "=", "depthwise_correlation", "(", "search", ",", "kernel", ")", "\n", "out", "=", "self", ".", "head_convs", "(", "correlation_maps", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.__init__": [[113, 159], ["dict", "dict", "dict", "dict", "torch.Module.__init__", "mmdet.core.anchor.build_anchor_generator", "mmdet.core.build_bbox_coder", "mmdet.core.build_assigner", "mmdet.core.build_sampler", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "mmdet.models.build_loss", "mmdet.models.build_loss", "len", "siamese_rpn_head.SiameseRPNHead.cls_heads.append", "siamese_rpn_head.SiameseRPNHead.reg_heads.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "siamese_rpn_head.CorrelationHead", "siamese_rpn_head.CorrelationHead", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "anchor_generator", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "weighted_sum", "=", "False", ",", "\n", "bbox_coder", "=", "dict", "(", "\n", "type", "=", "'DeltaXYWHBBoxCoder'", ",", "\n", "target_means", "=", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "target_stds", "=", "[", "1.", ",", "1.", ",", "1.", ",", "1.", "]", ")", ",", "\n", "loss_cls", "=", "dict", "(", "\n", "type", "=", "'CrossEntropyLoss'", ",", "reduction", "=", "'sum'", ",", "\n", "loss_weight", "=", "1.0", ")", ",", "\n", "loss_bbox", "=", "dict", "(", "\n", "type", "=", "'L1Loss'", ",", "reduction", "=", "'sum'", ",", "loss_weight", "=", "1.2", ")", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SiameseRPNHead", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "anchor_generator", "=", "build_anchor_generator", "(", "anchor_generator", ")", "\n", "self", ".", "bbox_coder", "=", "build_bbox_coder", "(", "bbox_coder", ")", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "self", ".", "assigner", "=", "build_assigner", "(", "self", ".", "train_cfg", ".", "assigner", ")", "\n", "self", ".", "sampler", "=", "build_sampler", "(", "self", ".", "train_cfg", ".", "sampler", ")", "\n", "\n", "self", ".", "cls_heads", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "reg_heads", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "in_channels", ")", ")", ":", "\n", "            ", "self", ".", "cls_heads", ".", "append", "(", "\n", "CorrelationHead", "(", "in_channels", "[", "i", "]", ",", "in_channels", "[", "i", "]", ",", "\n", "2", "*", "self", ".", "anchor_generator", ".", "num_base_anchors", "[", "0", "]", ",", "\n", "kernel_size", ",", "norm_cfg", ")", ")", "\n", "self", ".", "reg_heads", ".", "append", "(", "\n", "CorrelationHead", "(", "in_channels", "[", "i", "]", ",", "in_channels", "[", "i", "]", ",", "\n", "4", "*", "self", ".", "anchor_generator", ".", "num_base_anchors", "[", "0", "]", ",", "\n", "kernel_size", ",", "norm_cfg", ")", ")", "\n", "\n", "", "self", ".", "weighted_sum", "=", "weighted_sum", "\n", "if", "self", ".", "weighted_sum", ":", "\n", "            ", "self", ".", "cls_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "len", "(", "in_channels", ")", ")", ")", "\n", "self", ".", "reg_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "len", "(", "in_channels", ")", ")", ")", "\n", "\n", "", "self", ".", "loss_cls", "=", "build_loss", "(", "loss_cls", ")", "\n", "self", ".", "loss_bbox", "=", "build_loss", "(", "loss_bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.forward": [[160, 198], ["range", "isinstance", "isinstance", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "len", "len", "len", "len", "len", "len", "range", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_feats", ",", "x_feats", ")", ":", "\n", "        ", "\"\"\"Forward with features `z_feats` of exemplar images and features\n        `x_feats` of search images.\n\n        Args:\n            z_feats (tuple[Tensor]): Tuple of Tensor with shape (N, C, H, W)\n                denoting the multi level feature maps of exemplar images.\n                Typically H and W equal to 7.\n            x_feats (tuple[Tensor]): Tuple of Tensor with shape (N, C, H, W)\n                denoting the multi level feature maps of search images.\n                Typically H and W equal to 31.\n\n        Returns:\n            tuple(cls_score, bbox_pred): cls_score is a Tensor with shape\n            (N, 2 * num_base_anchors, H, W), bbox_pred is a Tensor with shape\n            (N, 4 * num_base_anchors, H, W), Typically H and W equal to 25.\n        \"\"\"", "\n", "assert", "isinstance", "(", "z_feats", ",", "tuple", ")", "and", "isinstance", "(", "x_feats", ",", "tuple", ")", "\n", "assert", "len", "(", "z_feats", ")", "==", "len", "(", "x_feats", ")", "and", "len", "(", "z_feats", ")", "==", "len", "(", "\n", "self", ".", "cls_heads", ")", "\n", "\n", "if", "self", ".", "weighted_sum", ":", "\n", "            ", "cls_weight", "=", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "cls_weight", ",", "dim", "=", "0", ")", "\n", "reg_weight", "=", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "reg_weight", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "reg_weight", "=", "cls_weight", "=", "[", "\n", "1.0", "/", "len", "(", "z_feats", ")", "for", "i", "in", "range", "(", "len", "(", "z_feats", ")", ")", "\n", "]", "\n", "\n", "", "cls_score", "=", "0", "\n", "bbox_pred", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "z_feats", ")", ")", ":", "\n", "            ", "cls_score_single", "=", "self", ".", "cls_heads", "[", "i", "]", "(", "z_feats", "[", "i", "]", ",", "x_feats", "[", "i", "]", ")", "\n", "bbox_pred_single", "=", "self", ".", "reg_heads", "[", "i", "]", "(", "z_feats", "[", "i", "]", ",", "x_feats", "[", "i", "]", ")", "\n", "cls_score", "+=", "cls_weight", "[", "i", "]", "*", "cls_score_single", "\n", "bbox_pred", "+=", "reg_weight", "[", "i", "]", "*", "bbox_pred_single", "\n", "\n", "", "return", "cls_score", ",", "bbox_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_init_targets": [[199, 212], ["torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_get_init_targets", "(", "self", ",", "gt_bbox", ",", "score_maps_size", ")", ":", "\n", "        ", "\"\"\"Initialize the training targets based on the output size\n        `score_maps_size` of network.\"\"\"", "\n", "num_base_anchors", "=", "self", ".", "anchor_generator", ".", "num_base_anchors", "[", "0", "]", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "num_base_anchors", ",", "score_maps_size", "[", "0", "]", ",", "\n", "score_maps_size", "[", "1", "]", ")", ")", ".", "to", "(", "gt_bbox", ".", "device", ")", ".", "long", "(", ")", "\n", "labels_weights", "=", "torch", ".", "zeros", "(", "(", "num_base_anchors", ",", "score_maps_size", "[", "0", "]", ",", "\n", "score_maps_size", "[", "1", "]", ")", ")", ".", "to", "(", "gt_bbox", ".", "device", ")", "\n", "bbox_targets", "=", "torch", ".", "zeros", "(", "(", "4", ",", "num_base_anchors", ",", "score_maps_size", "[", "0", "]", ",", "\n", "score_maps_size", "[", "1", "]", ")", ")", ".", "to", "(", "gt_bbox", ".", "device", ")", "\n", "bbox_weights", "=", "torch", ".", "zeros", "(", "(", "num_base_anchors", ",", "score_maps_size", "[", "0", "]", ",", "\n", "score_maps_size", "[", "1", "]", ")", ")", ".", "to", "(", "gt_bbox", ".", "device", ")", "\n", "return", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "bbox_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_positive_pair_targets": [[213, 272], ["siamese_rpn_head.SiameseRPNHead._get_init_targets", "siamese_rpn_head.SiameseRPNHead.anchors.clone", "mmdet.core.bbox.transforms.bbox_cxcywh_to_xyxy", "siamese_rpn_head.SiameseRPNHead.assigner.assign", "siamese_rpn_head.SiameseRPNHead.sampler.sample", "int", "labels.reshape.reshape.view", "labels_weights.reshape.reshape.view", "bbox_weights[].repeat.view", "siamese_rpn_head.SiameseRPNHead.bbox_coder.encode", "labels.reshape.reshape.reshape", "labels_weights.reshape.reshape.reshape", "bbox_targets.T.reshape.T.reshape.T.reshape", "bbox_weights[].repeat.reshape", "bbox_weights[].repeat", "hasattr", "len", "len", "len", "gt_bbox[].repeat", "siamese_rpn_head.SiameseRPNHead.anchor_generator.grid_anchors", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_init_targets"], ["", "def", "_get_positive_pair_targets", "(", "self", ",", "gt_bbox", ",", "score_maps_size", ")", ":", "\n", "        ", "\"\"\"Generate the training targets for positive exemplar image and search\n        image pair.\n\n        Args:\n            gt_bbox (Tensor): Ground truth bboxes of an search image with\n                shape (1, 5) in [0.0, tl_x, tl_y, br_x, br_y] format.\n            score_maps_size (torch.size): denoting the output size\n                (height, width) of the network.\n\n        Returns:\n            tuple(labels, labels_weights, bbox_targets, bbox_weights): the\n            shape is (num_base_anchors, H, W), (num_base_anchors, H, W),\n            (4, num_base_anchors, H, W), (4, num_base_anchors, H, W),\n            respectively. All of them are Tensor.\n        \"\"\"", "\n", "(", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "\n", "bbox_weights", ")", "=", "self", ".", "_get_init_targets", "(", "gt_bbox", ",", "score_maps_size", ")", "\n", "\n", "C", ",", "H", ",", "W", "=", "labels", ".", "shape", "\n", "if", "not", "hasattr", "(", "self", ",", "'anchors'", ")", ":", "\n", "            ", "self", ".", "anchors", "=", "self", ".", "anchor_generator", ".", "grid_anchors", "(", "\n", "[", "score_maps_size", "]", ",", "gt_bbox", ".", "device", ")", "[", "0", "]", "\n", "", "anchors", "=", "self", ".", "anchors", ".", "clone", "(", ")", "\n", "anchors", "[", ":", ",", ":", "2", "]", "+=", "self", ".", "train_cfg", ".", "search_size", "//", "2", "\n", "anchors", "=", "bbox_cxcywh_to_xyxy", "(", "anchors", ")", "\n", "\n", "assign_result", "=", "self", ".", "assigner", ".", "assign", "(", "anchors", ",", "gt_bbox", "[", ":", ",", "1", ":", "]", ")", "\n", "sampling_result", "=", "self", ".", "sampler", ".", "sample", "(", "assign_result", ",", "anchors", ",", "\n", "gt_bbox", "[", ":", ",", "1", ":", "]", ")", "\n", "pos_inds", "=", "sampling_result", ".", "pos_inds", "\n", "neg_inds", "=", "sampling_result", ".", "neg_inds", "\n", "neg_upper_bound", "=", "int", "(", "self", ".", "sampler", ".", "num", "*", "\n", "(", "1", "-", "self", ".", "sampler", ".", "pos_fraction", ")", ")", "\n", "if", "len", "(", "neg_inds", ")", ">", "neg_upper_bound", ":", "\n", "            ", "neg_inds", "=", "neg_inds", "[", ":", "neg_upper_bound", "]", "\n", "\n", "", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "labels_weights", "=", "labels_weights", ".", "view", "(", "-", "1", ")", "\n", "bbox_weights", "=", "bbox_weights", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "len", "(", "pos_inds", ")", ">", "0", ":", "\n", "            ", "labels", "[", "pos_inds", "]", "=", "1", "\n", "labels_weights", "[", "pos_inds", "]", "=", "1.0", "/", "len", "(", "pos_inds", ")", "/", "2", "\n", "bbox_weights", "[", "pos_inds", "]", "=", "1.0", "/", "len", "(", "pos_inds", ")", "\n", "\n", "", "if", "len", "(", "neg_inds", ")", ">", "0", ":", "\n", "            ", "labels", "[", "neg_inds", "]", "=", "0", "\n", "labels_weights", "[", "neg_inds", "]", "=", "1.0", "/", "len", "(", "neg_inds", ")", "/", "2", "\n", "\n", "", "bbox_targets", "=", "self", ".", "bbox_coder", ".", "encode", "(", "\n", "anchors", ",", "gt_bbox", "[", ":", ",", "1", ":", "]", ".", "repeat", "(", "anchors", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "\n", "labels", "=", "labels", ".", "reshape", "(", "C", ",", "H", ",", "W", ")", "\n", "labels_weights", "=", "labels_weights", ".", "reshape", "(", "C", ",", "H", ",", "W", ")", "\n", "bbox_targets", "=", "bbox_targets", ".", "T", ".", "reshape", "(", "4", ",", "C", ",", "H", ",", "W", ")", "\n", "bbox_weights", "=", "bbox_weights", ".", "reshape", "(", "C", ",", "H", ",", "W", ")", "\n", "bbox_weights", "=", "bbox_weights", "[", "None", "]", ".", "repeat", "(", "4", ",", "1", ",", "1", ",", "1", ")", "\n", "return", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "bbox_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_negative_pair_targets": [[273, 330], ["siamese_rpn_head.SiameseRPNHead._get_init_targets", "int", "int", "max", "min", "max", "min", "labels.reshape.reshape.view", "labels_weights.reshape.reshape.view", "labels.reshape.reshape.reshape", "labels_weights.reshape.reshape.reshape", "bbox_weights[].repeat", "mmdet.core.bbox.transforms.bbox_xyxy_to_cxcywh", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len", "neg_inds.numel", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_init_targets"], ["", "def", "_get_negative_pair_targets", "(", "self", ",", "gt_bbox", ",", "score_maps_size", ")", ":", "\n", "        ", "\"\"\"Generate the training targets for negative exemplar image and search\n        image pair.\n\n        Args:\n            gt_bbox (Tensor): Ground truth bboxes of an search image with\n                shape (1, 5) in [0.0, tl_x, tl_y, br_x, br_y] format.\n            score_maps_size (torch.size): denoting the output size\n                (height, width) of the network.\n\n        Returns:\n            tuple(labels, labels_weights, bbox_targets, bbox_weights): the\n            shape is (num_base_anchors, H, W), (num_base_anchors, H, W),\n            (4, num_base_anchors, H, W), (4, num_base_anchors, H, W),\n            respectively. All of them are Tensor.\n        \"\"\"", "\n", "(", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "\n", "bbox_weights", ")", "=", "self", ".", "_get_init_targets", "(", "gt_bbox", ",", "score_maps_size", ")", "\n", "C", ",", "H", ",", "W", "=", "labels", ".", "shape", "\n", "target_cx", ",", "target_cy", ",", "target_w", ",", "target_h", "=", "bbox_xyxy_to_cxcywh", "(", "\n", "gt_bbox", "[", ":", ",", "1", ":", "]", ")", "[", "0", "]", "\n", "anchor_stride", "=", "self", ".", "anchor_generator", ".", "strides", "[", "0", "]", "\n", "\n", "cx", "=", "W", "//", "2", "\n", "cy", "=", "H", "//", "2", "\n", "cx", "+=", "int", "(", "\n", "torch", ".", "ceil", "(", "(", "target_cx", "-", "self", ".", "train_cfg", ".", "search_size", "//", "2", ")", "/", "\n", "anchor_stride", "[", "0", "]", "+", "0.5", ")", ")", "\n", "cy", "+=", "int", "(", "\n", "torch", ".", "ceil", "(", "(", "target_cy", "-", "self", ".", "train_cfg", ".", "search_size", "//", "2", ")", "/", "\n", "anchor_stride", "[", "1", "]", "+", "0.5", ")", ")", "\n", "\n", "left", "=", "max", "(", "0", ",", "cx", "-", "3", ")", "\n", "right", "=", "min", "(", "W", ",", "cx", "+", "4", ")", "\n", "top", "=", "max", "(", "0", ",", "cy", "-", "3", ")", "\n", "down", "=", "min", "(", "H", ",", "cy", "+", "4", ")", "\n", "\n", "labels", "[", "...", "]", "=", "-", "1", "\n", "labels", "[", ":", ",", "top", ":", "down", ",", "left", ":", "right", "]", "=", "0", "\n", "\n", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "labels_weights", "=", "labels_weights", ".", "view", "(", "-", "1", ")", "\n", "neg_inds", "=", "torch", ".", "nonzero", "(", "labels", "==", "0", ",", "as_tuple", "=", "False", ")", "[", ":", ",", "0", "]", "\n", "index", "=", "torch", ".", "randperm", "(", "\n", "neg_inds", ".", "numel", "(", ")", ",", "device", "=", "neg_inds", ".", "device", ")", "[", ":", "self", ".", "train_cfg", ".", "num_neg", "]", "\n", "neg_inds", "=", "neg_inds", "[", "index", "]", "\n", "\n", "labels", "[", "...", "]", "=", "-", "1", "\n", "if", "len", "(", "neg_inds", ")", ">", "0", ":", "\n", "            ", "labels", "[", "neg_inds", "]", "=", "0", "\n", "labels_weights", "[", "neg_inds", "]", "=", "1.0", "/", "len", "(", "neg_inds", ")", "/", "2", "\n", "", "labels", "[", "...", "]", "=", "0", "\n", "\n", "labels", "=", "labels", ".", "reshape", "(", "C", ",", "H", ",", "W", ")", "\n", "labels_weights", "=", "labels_weights", ".", "reshape", "(", "C", ",", "H", ",", "W", ")", "\n", "bbox_weights", "=", "bbox_weights", "[", "None", "]", ".", "repeat", "(", "4", ",", "1", ",", "1", ",", "1", ")", "\n", "return", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "bbox_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets": [[331, 378], ["zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.append", "torch.stack.append", "all_labels_weights.append", "torch.stack.append", "torch.stack.append", "all_bbox_weights.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "siamese_rpn_head.SiameseRPNHead._get_positive_pair_targets", "siamese_rpn_head.SiameseRPNHead._get_negative_pair_targets"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_positive_pair_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead._get_negative_pair_targets"], ["", "def", "get_targets", "(", "self", ",", "gt_bboxes", ",", "score_maps_size", ",", "is_positive_pairs", ")", ":", "\n", "        ", "\"\"\"Generate the training targets for exemplar image and search image\n        pairs.\n\n        Args:\n            gt_bboxes (list[Tensor]): Ground truth bboxes of each\n                search image with shape (1, 5) in [0.0, tl_x, tl_y, br_x, br_y]\n                format.\n            score_maps_size (torch.size): denoting the output size\n                (height, width) of the network.\n            is_positive_pairs (bool): list of bool denoting whether each ground\n                truth bbox in `gt_bboxes` is positive.\n\n        Returns:\n            tuple(all_labels, all_labels_weights, all_bbox_targets,\n            all_bbox_weights): the shape is (N, num_base_anchors, H, W),\n            (N, num_base_anchors, H, W), (N, 4, num_base_anchors, H, W),\n            (N, 4, num_base_anchors, H, W), respectively. All of them are\n            Tensor.\n        \"\"\"", "\n", "(", "all_labels", ",", "all_labels_weights", ",", "all_bbox_targets", ",", "\n", "all_bbox_weights", ")", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "gt_bbox", ",", "is_positive_pair", "in", "zip", "(", "gt_bboxes", ",", "is_positive_pairs", ")", ":", "\n", "            ", "if", "is_positive_pair", ":", "\n", "                ", "(", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "\n", "bbox_weights", ")", "=", "self", ".", "_get_positive_pair_targets", "(", "\n", "gt_bbox", ",", "score_maps_size", ")", "\n", "", "else", ":", "\n", "                ", "(", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "\n", "bbox_weights", ")", "=", "self", ".", "_get_negative_pair_targets", "(", "\n", "gt_bbox", ",", "score_maps_size", ")", "\n", "\n", "", "all_labels", ".", "append", "(", "labels", ")", "\n", "all_labels_weights", ".", "append", "(", "labels_weights", ")", "\n", "all_bbox_targets", ".", "append", "(", "bbox_targets", ")", "\n", "all_bbox_weights", ".", "append", "(", "bbox_weights", ")", "\n", "\n", "", "all_labels", "=", "torch", ".", "stack", "(", "all_labels", ")", "\n", "all_labels_weights", "=", "torch", ".", "stack", "(", "all_labels_weights", ")", "/", "len", "(", "\n", "all_labels_weights", ")", "\n", "all_bbox_targets", "=", "torch", ".", "stack", "(", "all_bbox_targets", ")", "\n", "all_bbox_weights", "=", "torch", ".", "stack", "(", "all_bbox_weights", ")", "/", "len", "(", "\n", "all_bbox_weights", ")", "\n", "\n", "return", "(", "all_labels", ",", "all_labels_weights", ",", "all_bbox_targets", ",", "\n", "all_bbox_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss": [[379, 409], ["cls_score.permute().contiguous().view.permute().contiguous().view.view", "cls_score.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "labels.view.view.view", "labels_weights.view.view.view", "siamese_rpn_head.SiameseRPNHead.loss_cls", "bbox_pred.view.view.view", "siamese_rpn_head.SiameseRPNHead.loss_bbox", "cls_score.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "cls_score.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "cls_score", ",", "bbox_pred", ",", "labels", ",", "labels_weights", ",", "bbox_targets", ",", "\n", "bbox_weights", ")", ":", "\n", "        ", "\"\"\"Compute loss.\n\n        Args:\n            cls_score (Tensor): of shape (N, 2 * num_base_anchors, H, W).\n            bbox_pred (Tensor): of shape (N, 4 * num_base_anchors, H, W).\n            labels (Tensor): of shape (N, num_base_anchors, H, W).\n            labels_weights (Tensor): of shape (N, num_base_anchors, H, W).\n            bbox_targets (Tensor): of shape (N, 4, num_base_anchors, H, W).\n            bbox_weights (Tensor): of shape (N, 4, num_base_anchors, H, W).\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "losses", "=", "{", "}", "\n", "N", ",", "_", ",", "H", ",", "W", "=", "cls_score", ".", "shape", "\n", "\n", "cls_score", "=", "cls_score", ".", "view", "(", "N", ",", "2", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "cls_score", "=", "cls_score", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "4", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "labels_weights", "=", "labels_weights", ".", "view", "(", "-", "1", ")", "\n", "losses", "[", "'loss_rpn_cls'", "]", "=", "self", ".", "loss_cls", "(", "\n", "cls_score", ",", "labels", ",", "weight", "=", "labels_weights", ")", "\n", "\n", "bbox_pred", "=", "bbox_pred", ".", "view", "(", "N", ",", "4", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "losses", "[", "'loss_rpn_bbox'", "]", "=", "self", ".", "loss_bbox", "(", "\n", "bbox_pred", ",", "bbox_targets", ",", "weight", "=", "bbox_weights", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_bbox": [[410, 482], ["cls_score.view().permute.view().permute.permute().contiguous", "cls_score.view().permute.view().permute.view().permute", "mmdet.core.bbox.transforms.bbox_xyxy_to_cxcywh.permute().contiguous().view", "mmdet.core.bbox.transforms.bbox_xyxy_to_cxcywh.permute", "mmdet.core.bbox.transforms.bbox_cxcywh_to_xyxy", "siamese_rpn_head.SiameseRPNHead.bbox_coder.decode", "mmdet.core.bbox.transforms.bbox_xyxy_to_cxcywh", "siamese_rpn_head.SiameseRPNHead.get_bbox.change_ratio"], "methods", ["None"], ["", "def", "get_bbox", "(", "self", ",", "cls_score", ",", "bbox_pred", ",", "prev_bbox", ",", "scale_factor", ")", ":", "\n", "        ", "\"\"\"Track `prev_bbox` to current frame based on the output of network.\n\n        Args:\n            cls_score (Tensor): of shape (1, 2 * num_base_anchors, H, W).\n            bbox_pred (Tensor): of shape (1, 4 * num_base_anchors, H, W).\n            prev_bbox (Tensor): of shape (4, ) in [cx, cy, w, h] format.\n            scale_factor (Tensr): scale factor.\n\n        Returns:\n            tuple(best_score, best_bbox): best_score is a Tensor denoting the\n            score of `best_bbox`, best_bbox is a Tensor of shape (4, )\n            with [cx, cy, w, h] format, which denotes the best tracked\n            bbox in current frame.\n        \"\"\"", "\n", "score_maps_size", "=", "[", "(", "cls_score", ".", "shape", "[", "2", ":", "]", ")", "]", "\n", "if", "not", "hasattr", "(", "self", ",", "'anchors'", ")", ":", "\n", "            ", "self", ".", "anchors", "=", "self", ".", "anchor_generator", ".", "grid_anchors", "(", "\n", "score_maps_size", ",", "cls_score", ".", "device", ")", "[", "0", "]", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'windows'", ")", ":", "\n", "            ", "self", ".", "windows", "=", "self", ".", "anchor_generator", ".", "gen_2d_hanning_windows", "(", "\n", "score_maps_size", ",", "cls_score", ".", "device", ")", "[", "0", "]", "\n", "\n", "", "cls_score", "=", "cls_score", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "cls_score", "=", "cls_score", ".", "view", "(", "2", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "cls_score", "=", "cls_score", ".", "softmax", "(", "dim", "=", "1", ")", "[", ":", ",", "1", "]", "\n", "\n", "bbox_pred", "=", "bbox_pred", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "4", ",", "-", "1", ")", "\n", "bbox_pred", "=", "bbox_pred", ".", "permute", "(", "1", ",", "0", ")", "\n", "anchors", "=", "bbox_cxcywh_to_xyxy", "(", "self", ".", "anchors", ")", "\n", "bbox_pred", "=", "self", ".", "bbox_coder", ".", "decode", "(", "anchors", ",", "bbox_pred", ")", "\n", "bbox_pred", "=", "bbox_xyxy_to_cxcywh", "(", "bbox_pred", ")", "\n", "\n", "def", "change_ratio", "(", "ratio", ")", ":", "\n", "            ", "return", "torch", ".", "max", "(", "ratio", ",", "1.", "/", "ratio", ")", "\n", "\n", "", "def", "enlarge_size", "(", "w", ",", "h", ")", ":", "\n", "            ", "pad", "=", "(", "w", "+", "h", ")", "*", "0.5", "\n", "return", "torch", ".", "sqrt", "(", "(", "w", "+", "pad", ")", "*", "(", "h", "+", "pad", ")", ")", "\n", "\n", "# scale penalty", "\n", "", "scale_penalty", "=", "change_ratio", "(", "\n", "enlarge_size", "(", "bbox_pred", "[", ":", ",", "2", "]", ",", "bbox_pred", "[", ":", ",", "3", "]", ")", "/", "enlarge_size", "(", "\n", "prev_bbox", "[", "2", "]", "*", "scale_factor", ",", "prev_bbox", "[", "3", "]", "*", "scale_factor", ")", ")", "\n", "\n", "# aspect ratio penalty", "\n", "aspect_ratio_penalty", "=", "change_ratio", "(", "\n", "(", "prev_bbox", "[", "2", "]", "/", "prev_bbox", "[", "3", "]", ")", "/", "\n", "(", "bbox_pred", "[", ":", ",", "2", "]", "/", "bbox_pred", "[", ":", ",", "3", "]", ")", ")", "\n", "\n", "# penalize cls_score", "\n", "penalty", "=", "torch", ".", "exp", "(", "-", "(", "aspect_ratio_penalty", "*", "scale_penalty", "-", "1", ")", "*", "\n", "self", ".", "test_cfg", ".", "penalty_k", ")", "\n", "penalty_score", "=", "penalty", "*", "cls_score", "\n", "\n", "# window penalty", "\n", "penalty_score", "=", "penalty_score", "*", "(", "1", "-", "self", ".", "test_cfg", ".", "window_influence", ")", "+", "self", ".", "windows", "*", "self", ".", "test_cfg", ".", "window_influence", "\n", "\n", "best_idx", "=", "torch", ".", "argmax", "(", "penalty_score", ")", "\n", "best_score", "=", "cls_score", "[", "best_idx", "]", "\n", "best_bbox", "=", "bbox_pred", "[", "best_idx", ",", ":", "]", "/", "scale_factor", "\n", "\n", "# smooth bbox", "\n", "final_bbox", "=", "torch", ".", "zeros_like", "(", "best_bbox", ")", "\n", "lr", "=", "penalty", "[", "best_idx", "]", "*", "cls_score", "[", "best_idx", "]", "*", "self", ".", "test_cfg", ".", "lr", "\n", "final_bbox", "[", "0", "]", "=", "best_bbox", "[", "0", "]", "+", "prev_bbox", "[", "0", "]", "\n", "final_bbox", "[", "1", "]", "=", "best_bbox", "[", "1", "]", "+", "prev_bbox", "[", "1", "]", "\n", "final_bbox", "[", "2", "]", "=", "prev_bbox", "[", "2", "]", "*", "(", "1", "-", "lr", ")", "+", "best_bbox", "[", "2", "]", "*", "lr", "\n", "final_bbox", "[", "3", "]", "=", "prev_bbox", "[", "3", "]", "*", "(", "1", "-", "lr", ")", "+", "best_bbox", "[", "3", "]", "*", "lr", "\n", "\n", "return", "best_score", ",", "final_bbox", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.tf_aggregator.TFBlenderAggregator.__init__": [[10, 63], ["dict", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "tf_aggregator.TFBlenderAggregator.tf_blenders.append", "tf_aggregator.TFBlenderAggregator.tf_blenders.append", "tf_aggregator.TFBlenderAggregator.tf_blenders.append", "tf_aggregator.TFBlenderAggregator.embed_convs.append", "mmcv.cnn.bricks.ConvModule", "mmcv.cnn.bricks.ConvModule", "mmcv.cnn.bricks.ConvModule", "mmcv.cnn.bricks.ConvModule"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "num_convs", "=", "1", ",", "\n", "channels", "=", "256", ",", "\n", "kernel_size", "=", "3", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ")", ":", "\n", "        ", "super", "(", "TFBlenderAggregator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_convs", ">", "0", ",", "'The number of convs must be bigger than 1.'", "\n", "self", ".", "embed_convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_convs", ")", ":", "\n", "            ", "if", "i", "==", "num_convs", "-", "1", ":", "\n", "                ", "new_norm_cfg", "=", "None", "\n", "new_act_cfg", "=", "None", "\n", "", "else", ":", "\n", "                ", "new_norm_cfg", "=", "norm_cfg", "\n", "new_act_cfg", "=", "act_cfg", "\n", "", "self", ".", "embed_convs", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "channels", ",", "\n", "out_channels", "=", "channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "\n", "norm_cfg", "=", "new_norm_cfg", ",", "\n", "act_cfg", "=", "new_act_cfg", ")", ")", "\n", "\n", "", "self", ".", "tf_blenders", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "new_norm_cfg", "=", "norm_cfg", "\n", "new_act_cfg", "=", "act_cfg", "\n", "self", ".", "tf_blenders", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "channels", "*", "8", ",", "\n", "out_channels", "=", "channels", "*", "4", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "norm_cfg", "=", "new_norm_cfg", ",", "\n", "act_cfg", "=", "new_act_cfg", ")", ")", "\n", "self", ".", "tf_blenders", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "channels", "*", "4", ",", "\n", "out_channels", "=", "channels", "*", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "norm_cfg", "=", "new_norm_cfg", ",", "\n", "act_cfg", "=", "new_act_cfg", ")", ")", "\n", "self", ".", "tf_blenders", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "channels", "*", "2", ",", "\n", "out_channels", "=", "channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.tf_aggregator.TFBlenderAggregator.forward": [[64, 110], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "ada_weights.softmax.softmax.softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "embed_conv", "embed_conv.norm", "embed_conv", "embed_conv.norm", "tf_blend", "len", "len", "embed_conv.repeat", "x.repeat", "embed_conv.repeat", "x.repeat", "embed_conv.repeat", "x.repeat"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm", "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "ref_x", ")", ":", "\n", "        ", "\"\"\"Aggregate reference feature maps `ref_x`.\n\n        The aggregation mainly contains two steps:\n        1. Computing the cos similarity between `x` and `ref_x`.\n        2. Use the normlized (i.e. softmax) cos similarity to weightedly sum\n        `ref_x`.\n\n        Args:\n            x (Tensor): of shape [1, C, H, W]\n            ref_x (Tensor): of shape [N, C, H, W]. N is the number of reference\n                feature maps.\n\n        Returns:\n            Tensor: The aggregated feature map with shape [1, C, H, W].\n        \"\"\"", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "and", "len", "(", "x", ")", "==", "1", ",", "\"Only support 'batch_size == 1' for x\"", "\n", "x_embed", "=", "x", "\n", "for", "embed_conv", "in", "self", ".", "embed_convs", ":", "\n", "            ", "x_embed", "=", "embed_conv", "(", "x_embed", ")", "\n", "", "x_embed", "=", "x_embed", "/", "x_embed", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "ref_x_embed", "=", "ref_x", "\n", "for", "embed_conv", "in", "self", ".", "embed_convs", ":", "\n", "            ", "ref_x_embed", "=", "embed_conv", "(", "ref_x_embed", ")", "\n", "", "ref_x_embed", "=", "ref_x_embed", "/", "ref_x_embed", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "tf_weight", "=", "torch", ".", "cat", "(", "(", "x_embed", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", ",", "ref_x_embed", ",", "x_embed", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", "-", "ref_x_embed", ",", "x", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", ",", "ref_x", ",", "x", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", "-", "ref_x", ",", "-", "x_embed", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", "+", "ref_x_embed", ",", "-", "x", ".", "repeat", "(", "ref_x_embed", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", "+", "ref_x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "for", "tf_blend", "in", "self", ".", "tf_blenders", ":", "\n", "            ", "tf_weight", "=", "tf_blend", "(", "tf_weight", ")", "\n", "\n", "", "ada_weights", "=", "tf_weight", "\n", "\n", "ada_weights", "=", "ada_weights", ".", "softmax", "(", "dim", "=", "0", ")", "\n", "agg_x", "=", "torch", ".", "sum", "(", "ref_x", "*", "ada_weights", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "return", "agg_x", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.selsa_aggregator.SelsaAggregator.__init__": [[21, 28], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "num_attention_blocks", "=", "16", ")", ":", "\n", "        ", "super", "(", "SelsaAggregator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Linear", "(", "in_channels", ",", "in_channels", ")", "\n", "self", ".", "ref_fc_embed", "=", "nn", ".", "Linear", "(", "in_channels", ",", "in_channels", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_channels", ",", "in_channels", ")", "\n", "self", ".", "ref_fc", "=", "nn", ".", "Linear", "(", "in_channels", ",", "in_channels", ")", "\n", "self", ".", "num_attention_blocks", "=", "num_attention_blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.selsa_aggregator.SelsaAggregator.forward": [[29, 74], ["selsa_aggregator.SelsaAggregator.fc_embed", "x_embed.view().permute.view().permute.view().permute", "selsa_aggregator.SelsaAggregator.ref_fc_embed", "ref_x_embed.view().permute.view().permute.view().permute", "weights.softmax.softmax.softmax", "selsa_aggregator.SelsaAggregator.ref_fc", "ref_x_new.view().permute.view().permute.view().permute", "torch.bmm().permute().contiguous", "torch.bmm().permute().contiguous", "torch.bmm().permute().contiguous", "torch.bmm().permute().contiguous", "selsa_aggregator.SelsaAggregator.fc", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "selsa_aggregator.SelsaAggregator.view", "x_embed.view().permute.view().permute.view", "ref_x_embed.view().permute.view().permute.view", "ref_x_new.view().permute.view().permute.view", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "ref_x", ")", ":", "\n", "        ", "\"\"\"Aggregate the features `ref_x` of reference proposals.\n\n        The aggregation mainly contains two steps:\n        1. Use multi-head attention to computing the weight between `x` and\n        `ref_x`.\n        2. Use the normlized (i.e. softmax) weight to weightedly sum `ref_x`.\n\n        Args:\n            x (Tensor): of shape [N, C]. N is the number of key frame\n                proposals.\n            ref_x (Tensor): of shape [M, C]. M is the number of reference frame\n                proposals.\n\n        Returns:\n            Tensor: The aggregated features of key frame proposals with shape\n            [N, C].\n        \"\"\"", "\n", "roi_n", "=", "x", ".", "shape", "[", "0", "]", "\n", "ref_roi_n", "=", "ref_x", ".", "shape", "[", "0", "]", "\n", "\n", "x_embed", "=", "self", ".", "fc_embed", "(", "x", ")", "\n", "# [num_attention_blocks, roi_n, C / num_attention_blocks]", "\n", "x_embed", "=", "x_embed", ".", "view", "(", "roi_n", ",", "self", ".", "num_attention_blocks", ",", "\n", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "ref_x_embed", "=", "self", ".", "ref_fc_embed", "(", "ref_x", ")", "\n", "# [num_attention_blocks, C / num_attention_blocks, ref_roi_n]", "\n", "ref_x_embed", "=", "ref_x_embed", ".", "view", "(", "ref_roi_n", ",", "self", ".", "num_attention_blocks", ",", "\n", "-", "1", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "# [num_attention_blocks, roi_n, ref_roi_n]", "\n", "weights", "=", "torch", ".", "bmm", "(", "x_embed", ",", "ref_x_embed", ")", "/", "(", "x_embed", ".", "shape", "[", "-", "1", "]", "**", "0.5", ")", "\n", "weights", "=", "weights", ".", "softmax", "(", "dim", "=", "2", ")", "\n", "\n", "ref_x_new", "=", "self", ".", "ref_fc", "(", "ref_x", ")", "\n", "# [num_attention_blocks, ref_roi_n, C / num_attention_blocks]", "\n", "ref_x_new", "=", "ref_x_new", ".", "view", "(", "ref_roi_n", ",", "self", ".", "num_attention_blocks", ",", "\n", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "# [roi_n, num_attention_blocks, C / num_attention_blocks]", "\n", "x_new", "=", "torch", ".", "bmm", "(", "weights", ",", "ref_x_new", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "# [roi_n, C]", "\n", "x_new", "=", "self", ".", "fc", "(", "x_new", ".", "view", "(", "roi_n", ",", "-", "1", ")", ")", "\n", "return", "x_new", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.embed_aggregator.EmbedAggregator.__init__": [[26, 50], ["dict", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "embed_aggregator.EmbedAggregator.embed_convs.append", "mmcv.cnn.bricks.ConvModule"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_convs", "=", "1", ",", "\n", "channels", "=", "256", ",", "\n", "kernel_size", "=", "3", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ")", ":", "\n", "        ", "super", "(", "EmbedAggregator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_convs", ">", "0", ",", "'The number of convs must be bigger than 1.'", "\n", "self", ".", "embed_convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_convs", ")", ":", "\n", "            ", "if", "i", "==", "num_convs", "-", "1", ":", "\n", "                ", "new_norm_cfg", "=", "None", "\n", "new_act_cfg", "=", "None", "\n", "", "else", ":", "\n", "                ", "new_norm_cfg", "=", "norm_cfg", "\n", "new_act_cfg", "=", "act_cfg", "\n", "", "self", ".", "embed_convs", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "channels", ",", "\n", "out_channels", "=", "channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "\n", "norm_cfg", "=", "new_norm_cfg", ",", "\n", "act_cfg", "=", "new_act_cfg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.aggregators.embed_aggregator.EmbedAggregator.forward": [[51, 98], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "ada_weights.softmax.softmax.softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "matplotlib.figure", "matplotlib.imshow", "matplotlib.axis", "matplotlib.figure", "matplotlib.imshow", "matplotlib.axis", "matplotlib.figure", "matplotlib.imshow", "matplotlib.axis", "matplotlib.figure", "matplotlib.imshow", "matplotlib.axis", "embed_conv", "embed_conv.norm", "embed_conv", "embed_conv.norm", "len", "len", "x.cpu().detach().numpy", "ref_x.cpu().detach().numpy", "ref_x.cpu().detach().numpy", "x.cpu().detach", "ref_x.cpu().detach", "ref_x.cpu().detach", "x.cpu", "ref_x.cpu", "ref_x.cpu"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm", "home.repos.pwc.inspect_result.goodproj13_tf-blender.reid.fc_module.FcModule.norm"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "ref_x", ")", ":", "\n", "        ", "\"\"\"Aggregate reference feature maps `ref_x`.\n\n        The aggregation mainly contains two steps:\n        1. Computing the cos similarity between `x` and `ref_x`.\n        2. Use the normlized (i.e. softmax) cos similarity to weightedly sum\n        `ref_x`.\n\n        Args:\n            x (Tensor): of shape [1, C, H, W]\n            ref_x (Tensor): of shape [N, C, H, W]. N is the number of reference\n                feature maps.\n\n        Returns:\n            Tensor: The aggregated feature map with shape [1, C, H, W].\n        \"\"\"", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "and", "len", "(", "x", ")", "==", "1", ",", "\"Only support 'batch_size == 1' for x\"", "\n", "x_embed", "=", "x", "\n", "for", "embed_conv", "in", "self", ".", "embed_convs", ":", "\n", "            ", "x_embed", "=", "embed_conv", "(", "x_embed", ")", "\n", "", "x_embed", "=", "x_embed", "/", "x_embed", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "ref_x_embed", "=", "ref_x", "\n", "for", "embed_conv", "in", "self", ".", "embed_convs", ":", "\n", "            ", "ref_x_embed", "=", "embed_conv", "(", "ref_x_embed", ")", "\n", "", "ref_x_embed", "=", "ref_x_embed", "/", "ref_x_embed", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "ada_weights", "=", "torch", ".", "sum", "(", "ref_x_embed", "*", "x_embed", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "ada_weights", "=", "ada_weights", ".", "softmax", "(", "dim", "=", "0", ")", "\n", "agg_x", "=", "torch", ".", "sum", "(", "ref_x", "*", "ada_weights", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "print", "(", "agg_x", ".", "shape", ",", "x", ".", "shape", ",", "ref_x", ".", "shape", ",", "ada_weights", ".", "shape", ")", "\n", "idx", "=", "1", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "idx", ",", ":", ",", ":", "]", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "ref_x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "idx", ",", ":", ",", ":", "]", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "(", "ref_x", "[", "0", ",", ":", ",", ":", ",", ":", "]", "*", "ada_weights", "[", "0", ",", ":", ",", ":", ",", ":", "]", "+", "ref_x", "[", "20", ",", ":", ",", ":", ",", ":", "]", "*", "ada_weights", "[", "20", ",", ":", ",", ":", ",", ":", "]", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "[", "idx", ",", ":", ",", ":", "]", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "ref_x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "[", "20", ",", "idx", ",", ":", ",", ":", "]", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "return", "agg_x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head.SelsaRoIHead.forward_train": [[9, 78], ["dict", "len", "range", "selsa_roi_head.SelsaRoIHead._bbox_forward_train", "dict.update", "selsa_roi_head.SelsaRoIHead._mask_forward_train", "selsa_roi_head.SelsaRoIHead.bbox_assigner.assign", "selsa_roi_head.SelsaRoIHead.bbox_sampler.sample", "sampling_results.append", "dict.update", "range"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["def", "forward_train", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "img_metas", ",", "\n", "proposal_list", ",", "\n", "ref_proposal_list", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (list[Tensor]): list of multi-level img features.\n            ref_x (list[Tensor]): list of multi-level ref_img features.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmdet/datasets/pipelines/formatting.py:Collect`.\n            proposal_list (list[Tensors]): list of region proposals.\n            ref_proposal_list (list[Tensors]): list of region proposals\n                from ref_imgs.\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with\n                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.\n            gt_labels (list[Tensor]): class indices corresponding to each box\n            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes can be ignored when computing the loss.\n            gt_masks (None | Tensor) : true segmentation masks for each box\n                used if the architecture supports a segmentation task.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "# assign gts and sample proposals", "\n", "if", "self", ".", "with_bbox", "or", "self", ".", "with_mask", ":", "\n", "            ", "num_imgs", "=", "len", "(", "img_metas", ")", "\n", "if", "gt_bboxes_ignore", "is", "None", ":", "\n", "                ", "gt_bboxes_ignore", "=", "[", "None", "for", "_", "in", "range", "(", "num_imgs", ")", "]", "\n", "", "sampling_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_imgs", ")", ":", "\n", "                ", "assign_result", "=", "self", ".", "bbox_assigner", ".", "assign", "(", "\n", "proposal_list", "[", "i", "]", ",", "gt_bboxes", "[", "i", "]", ",", "gt_bboxes_ignore", "[", "i", "]", ",", "\n", "gt_labels", "[", "i", "]", ")", "\n", "sampling_result", "=", "self", ".", "bbox_sampler", ".", "sample", "(", "\n", "assign_result", ",", "\n", "proposal_list", "[", "i", "]", ",", "\n", "gt_bboxes", "[", "i", "]", ",", "\n", "gt_labels", "[", "i", "]", ",", "\n", "feats", "=", "[", "lvl_feat", "[", "i", "]", "[", "None", "]", "for", "lvl_feat", "in", "x", "]", ")", "\n", "sampling_results", ".", "append", "(", "sampling_result", ")", "\n", "\n", "", "", "losses", "=", "dict", "(", ")", "\n", "# bbox head forward and loss", "\n", "if", "self", ".", "with_bbox", ":", "\n", "            ", "bbox_results", "=", "self", ".", "_bbox_forward_train", "(", "x", ",", "ref_x", ",", "sampling_results", ",", "\n", "ref_proposal_list", ",", "\n", "gt_bboxes", ",", "gt_labels", ")", "\n", "losses", ".", "update", "(", "bbox_results", "[", "'loss_bbox'", "]", ")", "\n", "\n", "# mask head forward and loss", "\n", "", "if", "self", ".", "with_mask", ":", "\n", "            ", "mask_results", "=", "self", ".", "_mask_forward_train", "(", "x", ",", "sampling_results", ",", "\n", "bbox_results", "[", "'bbox_feats'", "]", ",", "\n", "gt_masks", ",", "img_metas", ")", "\n", "# TODO: Support empty tensor input. #2280", "\n", "if", "mask_results", "[", "'loss_mask'", "]", "is", "not", "None", ":", "\n", "                ", "losses", ".", "update", "(", "mask_results", "[", "'loss_mask'", "]", ")", "\n", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head.SelsaRoIHead._bbox_forward": [[79, 100], ["selsa_roi_head.SelsaRoIHead.bbox_roi_extractor", "selsa_roi_head.SelsaRoIHead.bbox_roi_extractor", "selsa_roi_head.SelsaRoIHead.bbox_head", "selsa_roi_head.SelsaRoIHead.bbox_head", "dict", "dict", "selsa_roi_head.SelsaRoIHead.shared_head", "selsa_roi_head.SelsaRoIHead.shared_head"], "methods", ["None"], ["", "def", "_bbox_forward", "(", "self", ",", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", ":", "\n", "        ", "\"\"\"Box head forward function used in both training and testing.\"\"\"", "\n", "# TODO: a more flexible way to decide which feature maps to use", "\n", "bbox_feats", "=", "self", ".", "bbox_roi_extractor", "(", "\n", "x", "[", ":", "self", ".", "bbox_roi_extractor", ".", "num_inputs", "]", ",", "rois", ")", "\n", "ref_bbox_feats", "=", "self", ".", "bbox_roi_extractor", "(", "\n", "ref_x", "[", ":", "self", ".", "bbox_roi_extractor", ".", "num_inputs", "]", ",", "ref_rois", ")", "\n", "if", "self", ".", "with_shared_head", ":", "\n", "            ", "bbox_feats", "=", "self", ".", "shared_head", "(", "bbox_feats", ")", "\n", "ref_bbox_feats", "=", "self", ".", "shared_head", "(", "ref_bbox_feats", ")", "\n", "", "cls_score", ",", "bbox_pred", "=", "self", ".", "bbox_head", "(", "bbox_feats", ",", "ref_bbox_feats", ")", "\n", "# Consistent Supervision", "\n", "cls_score_cs", ",", "bbox_pred_cs", "=", "self", ".", "bbox_head", "(", "bbox_feats", ",", "ref_bbox_feats", ",", "with_ref", "=", "False", ")", "\n", "\n", "bbox_results", "=", "dict", "(", "\n", "cls_score", "=", "cls_score", ",", "bbox_pred", "=", "bbox_pred", ",", "bbox_feats", "=", "bbox_feats", ")", "\n", "\n", "bbox_results_cs", "=", "dict", "(", "\n", "cls_score", "=", "cls_score_cs", ",", "bbox_pred", "=", "bbox_pred_cs", ")", "\n", "\n", "return", "bbox_results", ",", "bbox_results_cs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head.SelsaRoIHead._bbox_forward_train": [[101, 126], ["mmdet.core.bbox2roi", "mmdet.core.bbox2roi", "selsa_roi_head.SelsaRoIHead._bbox_forward", "selsa_roi_head.SelsaRoIHead.bbox_head.get_targets", "selsa_roi_head.SelsaRoIHead.bbox_head.loss", "selsa_roi_head.SelsaRoIHead.bbox_head.loss", "dict", "bbox_results.update"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "_bbox_forward_train", "(", "self", ",", "x", ",", "ref_x", ",", "sampling_results", ",", "\n", "ref_proposal_list", ",", "gt_bboxes", ",", "gt_labels", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for box head in training.\"\"\"", "\n", "rois", "=", "bbox2roi", "(", "[", "res", ".", "bboxes", "for", "res", "in", "sampling_results", "]", ")", "\n", "ref_rois", "=", "bbox2roi", "(", "ref_proposal_list", ")", "\n", "bbox_results", ",", "bbox_results_cs", "=", "self", ".", "_bbox_forward", "(", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", "\n", "\n", "bbox_targets", "=", "self", ".", "bbox_head", ".", "get_targets", "(", "sampling_results", ",", "gt_bboxes", ",", "\n", "gt_labels", ",", "self", ".", "train_cfg", ")", "\n", "\n", "\n", "loss_bbox_key", "=", "self", ".", "bbox_head", ".", "loss", "(", "bbox_results", "[", "'cls_score'", "]", ",", "\n", "bbox_results", "[", "'bbox_pred'", "]", ",", "rois", ",", "\n", "*", "bbox_targets", ")", "\n", "loss_bbox_cs", "=", "self", ".", "bbox_head", ".", "loss", "(", "bbox_results_cs", "[", "'cls_score'", "]", ",", "\n", "bbox_results_cs", "[", "'bbox_pred'", "]", ",", "rois", ",", "\n", "*", "bbox_targets", ")", "\n", "\n", "loss_bbox", "=", "dict", "(", "loss_cls", "=", "loss_bbox_cs", "[", "'loss_cls'", "]", "+", "loss_bbox_key", "[", "'loss_cls'", "]", ",", "\n", "loss_bbox", "=", "loss_bbox_cs", "[", "'loss_bbox'", "]", "+", "loss_bbox_key", "[", "'loss_bbox'", "]", ",", "\n", "acc", "=", "loss_bbox_key", "[", "'acc'", "]", "\n", ")", "\n", "\n", "bbox_results", ".", "update", "(", "loss_bbox", "=", "loss_bbox", ")", "\n", "return", "bbox_results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head.SelsaRoIHead.simple_test": [[127, 158], ["selsa_roi_head.SelsaRoIHead.simple_test_bboxes", "mmdet.core.bbox2result", "selsa_roi_head.SelsaRoIHead.simple_test_mask", "list", "range", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes"], ["", "def", "simple_test", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals_list", ",", "\n", "ref_proposals_list", ",", "\n", "img_metas", ",", "\n", "proposals", "=", "None", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\"\"\"", "\n", "assert", "self", ".", "with_bbox", ",", "'Bbox head must be implemented.'", "\n", "\n", "det_bboxes", ",", "det_labels", "=", "self", ".", "simple_test_bboxes", "(", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals_list", ",", "\n", "ref_proposals_list", ",", "\n", "img_metas", ",", "\n", "self", ".", "test_cfg", ",", "\n", "rescale", "=", "rescale", ")", "\n", "bbox_results", "=", "[", "\n", "bbox2result", "(", "det_bboxes", "[", "i", "]", ",", "det_labels", "[", "i", "]", ",", "\n", "self", ".", "bbox_head", ".", "num_classes", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "det_bboxes", ")", ")", "\n", "]", "\n", "\n", "if", "not", "self", ".", "with_mask", ":", "\n", "            ", "return", "bbox_results", "\n", "", "else", ":", "\n", "            ", "segm_results", "=", "self", ".", "simple_test_mask", "(", "\n", "x", ",", "img_metas", ",", "det_bboxes", ",", "det_labels", ",", "rescale", "=", "rescale", ")", "\n", "return", "list", "(", "zip", "(", "bbox_results", ",", "segm_results", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head.SelsaRoIHead.simple_test_bboxes": [[159, 200], ["mmdet.core.bbox2roi", "mmdet.core.bbox2roi", "selsa_roi_head.SelsaRoIHead._bbox_forward", "tuple", "tuple", "tuple", "rois.split.split.split", "cls_score.split.split.split", "range", "bbox_pred.split", "len", "selsa_roi_head.SelsaRoIHead.bbox_head.get_bboxes", "det_bboxes.append", "det_labels.append", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward"], ["", "", "def", "simple_test_bboxes", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals", ",", "\n", "ref_proposals", ",", "\n", "img_metas", ",", "\n", "rcnn_test_cfg", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test only det bboxes without augmentation.\"\"\"", "\n", "rois", "=", "bbox2roi", "(", "proposals", ")", "\n", "ref_rois", "=", "bbox2roi", "(", "ref_proposals", ")", "\n", "bbox_results", "=", "self", ".", "_bbox_forward", "(", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", "\n", "img_shapes", "=", "tuple", "(", "meta", "[", "'img_shape'", "]", "for", "meta", "in", "img_metas", ")", "\n", "scale_factors", "=", "tuple", "(", "meta", "[", "'scale_factor'", "]", "for", "meta", "in", "img_metas", ")", "\n", "\n", "# split batch bbox prediction back to each image", "\n", "cls_score", "=", "bbox_results", "[", "'cls_score'", "]", "\n", "bbox_pred", "=", "bbox_results", "[", "'bbox_pred'", "]", "\n", "num_proposals_per_img", "=", "tuple", "(", "len", "(", "p", ")", "for", "p", "in", "proposals", ")", "\n", "rois", "=", "rois", ".", "split", "(", "num_proposals_per_img", ",", "0", ")", "\n", "cls_score", "=", "cls_score", ".", "split", "(", "num_proposals_per_img", ",", "0", ")", "\n", "# some detector with_reg is False, bbox_pred will be None", "\n", "bbox_pred", "=", "bbox_pred", ".", "split", "(", "\n", "num_proposals_per_img", ",", "\n", "0", ")", "if", "bbox_pred", "is", "not", "None", "else", "[", "None", ",", "None", "]", "\n", "\n", "# apply bbox post-processing to each image individually", "\n", "det_bboxes", "=", "[", "]", "\n", "det_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "proposals", ")", ")", ":", "\n", "            ", "det_bbox", ",", "det_label", "=", "self", ".", "bbox_head", ".", "get_bboxes", "(", "\n", "rois", "[", "i", "]", ",", "\n", "cls_score", "[", "i", "]", ",", "\n", "bbox_pred", "[", "i", "]", ",", "\n", "img_shapes", "[", "i", "]", ",", "\n", "scale_factors", "[", "i", "]", ",", "\n", "rescale", "=", "rescale", ",", "\n", "cfg", "=", "rcnn_test_cfg", ")", "\n", "det_bboxes", ".", "append", "(", "det_bbox", ")", "\n", "det_labels", ".", "append", "(", "det_label", ")", "\n", "", "return", "det_bboxes", ",", "det_labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.forward_train": [[9, 78], ["dict", "len", "range", "selsa_roi_head_origin.SelsaRoIHead._bbox_forward_train", "dict.update", "selsa_roi_head_origin.SelsaRoIHead._mask_forward_train", "selsa_roi_head_origin.SelsaRoIHead.bbox_assigner.assign", "selsa_roi_head_origin.SelsaRoIHead.bbox_sampler.sample", "sampling_results.append", "dict.update", "range"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["def", "forward_train", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "img_metas", ",", "\n", "proposal_list", ",", "\n", "ref_proposal_list", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (list[Tensor]): list of multi-level img features.\n            ref_x (list[Tensor]): list of multi-level ref_img features.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmdet/datasets/pipelines/formatting.py:Collect`.\n            proposal_list (list[Tensors]): list of region proposals.\n            ref_proposal_list (list[Tensors]): list of region proposals\n                from ref_imgs.\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with\n                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.\n            gt_labels (list[Tensor]): class indices corresponding to each box\n            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes can be ignored when computing the loss.\n            gt_masks (None | Tensor) : true segmentation masks for each box\n                used if the architecture supports a segmentation task.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "# assign gts and sample proposals", "\n", "if", "self", ".", "with_bbox", "or", "self", ".", "with_mask", ":", "\n", "            ", "num_imgs", "=", "len", "(", "img_metas", ")", "\n", "if", "gt_bboxes_ignore", "is", "None", ":", "\n", "                ", "gt_bboxes_ignore", "=", "[", "None", "for", "_", "in", "range", "(", "num_imgs", ")", "]", "\n", "", "sampling_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_imgs", ")", ":", "\n", "                ", "assign_result", "=", "self", ".", "bbox_assigner", ".", "assign", "(", "\n", "proposal_list", "[", "i", "]", ",", "gt_bboxes", "[", "i", "]", ",", "gt_bboxes_ignore", "[", "i", "]", ",", "\n", "gt_labels", "[", "i", "]", ")", "\n", "sampling_result", "=", "self", ".", "bbox_sampler", ".", "sample", "(", "\n", "assign_result", ",", "\n", "proposal_list", "[", "i", "]", ",", "\n", "gt_bboxes", "[", "i", "]", ",", "\n", "gt_labels", "[", "i", "]", ",", "\n", "feats", "=", "[", "lvl_feat", "[", "i", "]", "[", "None", "]", "for", "lvl_feat", "in", "x", "]", ")", "\n", "sampling_results", ".", "append", "(", "sampling_result", ")", "\n", "\n", "", "", "losses", "=", "dict", "(", ")", "\n", "# bbox head forward and loss", "\n", "if", "self", ".", "with_bbox", ":", "\n", "            ", "bbox_results", "=", "self", ".", "_bbox_forward_train", "(", "x", ",", "ref_x", ",", "sampling_results", ",", "\n", "ref_proposal_list", ",", "\n", "gt_bboxes", ",", "gt_labels", ")", "\n", "losses", ".", "update", "(", "bbox_results", "[", "'loss_bbox'", "]", ")", "\n", "\n", "# mask head forward and loss", "\n", "", "if", "self", ".", "with_mask", ":", "\n", "            ", "mask_results", "=", "self", ".", "_mask_forward_train", "(", "x", ",", "sampling_results", ",", "\n", "bbox_results", "[", "'bbox_feats'", "]", ",", "\n", "gt_masks", ",", "img_metas", ")", "\n", "# TODO: Support empty tensor input. #2280", "\n", "if", "mask_results", "[", "'loss_mask'", "]", "is", "not", "None", ":", "\n", "                ", "losses", ".", "update", "(", "mask_results", "[", "'loss_mask'", "]", ")", "\n", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward": [[79, 94], ["selsa_roi_head_origin.SelsaRoIHead.bbox_roi_extractor", "selsa_roi_head_origin.SelsaRoIHead.bbox_roi_extractor", "selsa_roi_head_origin.SelsaRoIHead.bbox_head", "dict", "selsa_roi_head_origin.SelsaRoIHead.shared_head", "selsa_roi_head_origin.SelsaRoIHead.shared_head"], "methods", ["None"], ["", "def", "_bbox_forward", "(", "self", ",", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", ":", "\n", "        ", "\"\"\"Box head forward function used in both training and testing.\"\"\"", "\n", "# TODO: a more flexible way to decide which feature maps to use", "\n", "bbox_feats", "=", "self", ".", "bbox_roi_extractor", "(", "\n", "x", "[", ":", "self", ".", "bbox_roi_extractor", ".", "num_inputs", "]", ",", "rois", ")", "\n", "ref_bbox_feats", "=", "self", ".", "bbox_roi_extractor", "(", "\n", "ref_x", "[", ":", "self", ".", "bbox_roi_extractor", ".", "num_inputs", "]", ",", "ref_rois", ")", "\n", "if", "self", ".", "with_shared_head", ":", "\n", "            ", "bbox_feats", "=", "self", ".", "shared_head", "(", "bbox_feats", ")", "\n", "ref_bbox_feats", "=", "self", ".", "shared_head", "(", "ref_bbox_feats", ")", "\n", "", "cls_score", ",", "bbox_pred", "=", "self", ".", "bbox_head", "(", "bbox_feats", ",", "ref_bbox_feats", ")", "\n", "\n", "bbox_results", "=", "dict", "(", "\n", "cls_score", "=", "cls_score", ",", "bbox_pred", "=", "bbox_pred", ",", "bbox_feats", "=", "bbox_feats", ")", "\n", "return", "bbox_results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward_train": [[95, 110], ["mmdet.core.bbox2roi", "mmdet.core.bbox2roi", "selsa_roi_head_origin.SelsaRoIHead._bbox_forward", "selsa_roi_head_origin.SelsaRoIHead.bbox_head.get_targets", "selsa_roi_head_origin.SelsaRoIHead.bbox_head.loss", "selsa_roi_head_origin.SelsaRoIHead.update"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "_bbox_forward_train", "(", "self", ",", "x", ",", "ref_x", ",", "sampling_results", ",", "\n", "ref_proposal_list", ",", "gt_bboxes", ",", "gt_labels", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for box head in training.\"\"\"", "\n", "rois", "=", "bbox2roi", "(", "[", "res", ".", "bboxes", "for", "res", "in", "sampling_results", "]", ")", "\n", "ref_rois", "=", "bbox2roi", "(", "ref_proposal_list", ")", "\n", "bbox_results", "=", "self", ".", "_bbox_forward", "(", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", "\n", "\n", "bbox_targets", "=", "self", ".", "bbox_head", ".", "get_targets", "(", "sampling_results", ",", "gt_bboxes", ",", "\n", "gt_labels", ",", "self", ".", "train_cfg", ")", "\n", "loss_bbox", "=", "self", ".", "bbox_head", ".", "loss", "(", "bbox_results", "[", "'cls_score'", "]", ",", "\n", "bbox_results", "[", "'bbox_pred'", "]", ",", "rois", ",", "\n", "*", "bbox_targets", ")", "\n", "\n", "bbox_results", ".", "update", "(", "loss_bbox", "=", "loss_bbox", ")", "\n", "return", "bbox_results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test": [[111, 142], ["selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes", "mmdet.core.bbox2result", "selsa_roi_head_origin.SelsaRoIHead.simple_test_mask", "list", "range", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes"], ["", "def", "simple_test", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals_list", ",", "\n", "ref_proposals_list", ",", "\n", "img_metas", ",", "\n", "proposals", "=", "None", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\"\"\"", "\n", "assert", "self", ".", "with_bbox", ",", "'Bbox head must be implemented.'", "\n", "\n", "det_bboxes", ",", "det_labels", "=", "self", ".", "simple_test_bboxes", "(", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals_list", ",", "\n", "ref_proposals_list", ",", "\n", "img_metas", ",", "\n", "self", ".", "test_cfg", ",", "\n", "rescale", "=", "rescale", ")", "\n", "bbox_results", "=", "[", "\n", "bbox2result", "(", "det_bboxes", "[", "i", "]", ",", "det_labels", "[", "i", "]", ",", "\n", "self", ".", "bbox_head", ".", "num_classes", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "det_bboxes", ")", ")", "\n", "]", "\n", "\n", "if", "not", "self", ".", "with_mask", ":", "\n", "            ", "return", "bbox_results", "\n", "", "else", ":", "\n", "            ", "segm_results", "=", "self", ".", "simple_test_mask", "(", "\n", "x", ",", "img_metas", ",", "det_bboxes", ",", "det_labels", ",", "rescale", "=", "rescale", ")", "\n", "return", "list", "(", "zip", "(", "bbox_results", ",", "segm_results", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes": [[143, 184], ["mmdet.core.bbox2roi", "mmdet.core.bbox2roi", "selsa_roi_head_origin.SelsaRoIHead._bbox_forward", "tuple", "tuple", "tuple", "rois.split.split.split", "cls_score.split.split.split", "range", "bbox_pred.split", "len", "selsa_roi_head_origin.SelsaRoIHead.bbox_head.get_bboxes", "det_bboxes.append", "det_labels.append", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead._bbox_forward"], ["", "", "def", "simple_test_bboxes", "(", "self", ",", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposals", ",", "\n", "ref_proposals", ",", "\n", "img_metas", ",", "\n", "rcnn_test_cfg", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test only det bboxes without augmentation.\"\"\"", "\n", "rois", "=", "bbox2roi", "(", "proposals", ")", "\n", "ref_rois", "=", "bbox2roi", "(", "ref_proposals", ")", "\n", "bbox_results", "=", "self", ".", "_bbox_forward", "(", "x", ",", "ref_x", ",", "rois", ",", "ref_rois", ")", "\n", "img_shapes", "=", "tuple", "(", "meta", "[", "'img_shape'", "]", "for", "meta", "in", "img_metas", ")", "\n", "scale_factors", "=", "tuple", "(", "meta", "[", "'scale_factor'", "]", "for", "meta", "in", "img_metas", ")", "\n", "\n", "# split batch bbox prediction back to each image", "\n", "cls_score", "=", "bbox_results", "[", "'cls_score'", "]", "\n", "bbox_pred", "=", "bbox_results", "[", "'bbox_pred'", "]", "\n", "num_proposals_per_img", "=", "tuple", "(", "len", "(", "p", ")", "for", "p", "in", "proposals", ")", "\n", "rois", "=", "rois", ".", "split", "(", "num_proposals_per_img", ",", "0", ")", "\n", "cls_score", "=", "cls_score", ".", "split", "(", "num_proposals_per_img", ",", "0", ")", "\n", "# some detector with_reg is False, bbox_pred will be None", "\n", "bbox_pred", "=", "bbox_pred", ".", "split", "(", "\n", "num_proposals_per_img", ",", "\n", "0", ")", "if", "bbox_pred", "is", "not", "None", "else", "[", "None", ",", "None", "]", "\n", "\n", "# apply bbox post-processing to each image individually", "\n", "det_bboxes", "=", "[", "]", "\n", "det_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "proposals", ")", ")", ":", "\n", "            ", "det_bbox", ",", "det_label", "=", "self", ".", "bbox_head", ".", "get_bboxes", "(", "\n", "rois", "[", "i", "]", ",", "\n", "cls_score", "[", "i", "]", ",", "\n", "bbox_pred", "[", "i", "]", ",", "\n", "img_shapes", "[", "i", "]", ",", "\n", "scale_factors", "[", "i", "]", ",", "\n", "rescale", "=", "rescale", ",", "\n", "cfg", "=", "rcnn_test_cfg", ")", "\n", "det_bboxes", ".", "append", "(", "det_bbox", ")", "\n", "det_labels", ".", "append", "(", "det_label", ")", "\n", "", "return", "det_bboxes", ",", "det_labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.bbox_heads.selsa_bbox_head.SelsaBBoxHead.__init__": [[18, 24], ["mmdet.models.ConvFCBBoxHead.__init__", "torch.ModuleList", "range", "torch.ReLU", "selsa_bbox_head.SelsaBBoxHead.aggregator.append", "mmtrack.models.build_aggregator"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_aggregator"], ["def", "__init__", "(", "self", ",", "aggregator", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", "SelsaBBoxHead", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "aggregator", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_shared_fcs", ")", ":", "\n", "\t\t\t", "self", ".", "aggregator", ".", "append", "(", "build_aggregator", "(", "aggregator", ")", ")", "\n", "", "self", ".", "inplace_false_relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.bbox_heads.selsa_bbox_head.SelsaBBoxHead.forward": [[25, 91], ["selsa_bbox_head.SelsaBBoxHead.flatten", "selsa_bbox_head.SelsaBBoxHead.flatten", "enumerate", "conv", "selsa_bbox_head.SelsaBBoxHead.dim", "selsa_bbox_head.SelsaBBoxHead.flatten", "selsa_bbox_head.SelsaBBoxHead.relu", "conv", "selsa_bbox_head.SelsaBBoxHead.dim", "selsa_bbox_head.SelsaBBoxHead.flatten", "selsa_bbox_head.SelsaBBoxHead.relu", "selsa_bbox_head.SelsaBBoxHead.fc_cls", "selsa_bbox_head.SelsaBBoxHead.fc_reg", "conv", "conv", "selsa_bbox_head.SelsaBBoxHead.avg_pool", "selsa_bbox_head.SelsaBBoxHead.avg_pool", "fc", "fc", "selsa_bbox_head.SelsaBBoxHead.inplace_false_relu", "selsa_bbox_head.SelsaBBoxHead.inplace_false_relu", "selsa_bbox_head.SelsaBBoxHead.avg_pool", "fc", "selsa_bbox_head.SelsaBBoxHead.avg_pool", "fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "ref_x", ",", "with_ref", "=", "True", ")", ":", "\n", "\t\t", "\"\"\"Computing the `cls_score` and `bbox_pred` of the features `x` of key\n\t\tframe proposals.\n\n\t\tArgs:\n\t\t\tx (Tensor): of shape [N, C, H, W]. N is the number of key frame\n\t\t\t\tproposals.\n\t\t\tref_x (Tensor): of shape [M, C, H, W]. M is the number of reference\n\t\t\t\tframe proposals.\n\n\t\tReturns:\n\t\t\ttuple(cls_score, bbox_pred): The predicted score of classes and\n\t\t\tthe predicted regression offsets.\n\t\t\"\"\"", "\n", "# shared part", "\n", "if", "self", ".", "num_shared_convs", ">", "0", ":", "\n", "\t\t\t", "for", "conv", "in", "self", ".", "shared_convs", ":", "\n", "\t\t\t\t", "x", "=", "conv", "(", "x", ")", "\n", "ref_x", "=", "conv", "(", "ref_x", ")", "\n", "\n", "", "", "if", "self", ".", "num_shared_fcs", ">", "0", ":", "\n", "\t\t\t", "if", "self", ".", "with_avg_pool", ":", "\n", "\t\t\t\t", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "ref_x", "=", "self", ".", "avg_pool", "(", "ref_x", ")", "\n", "\n", "", "x", "=", "x", ".", "flatten", "(", "1", ")", "\n", "ref_x", "=", "ref_x", ".", "flatten", "(", "1", ")", "\n", "\n", "for", "i", ",", "fc", "in", "enumerate", "(", "self", ".", "shared_fcs", ")", ":", "\n", "\t\t\t\t", "x", "=", "fc", "(", "x", ")", "\n", "ref_x", "=", "fc", "(", "ref_x", ")", "\n", "agg_x", "=", "self", ".", "aggregator", "[", "i", "]", "(", "x", ",", "ref_x", ")", "\n", "if", "with_ref", ":", "\n", "\t\t\t\t\t", "x", "=", "x", "+", "agg_x", "\n", "", "ref_x", "=", "self", ".", "inplace_false_relu", "(", "ref_x", ")", "\n", "x", "=", "self", ".", "inplace_false_relu", "(", "x", ")", "\n", "\n", "# separate branches", "\n", "", "", "if", "with_ref", ":", "\n", "\t\t\t", "x_cls", "=", "x", "\n", "x_reg", "=", "x", "\n", "", "else", ":", "\n", "\t\t\t", "x_cls", "=", "agg_x", "\n", "x_reg", "=", "agg_x", "\n", "\n", "", "for", "conv", "in", "self", ".", "cls_convs", ":", "\n", "\t\t\t", "x_cls", "=", "conv", "(", "x_cls", ")", "\n", "", "if", "x_cls", ".", "dim", "(", ")", ">", "2", ":", "\n", "\t\t\t", "if", "self", ".", "with_avg_pool", ":", "\n", "\t\t\t\t", "x_cls", "=", "self", ".", "avg_pool", "(", "x_cls", ")", "\n", "", "x_cls", "=", "x_cls", ".", "flatten", "(", "1", ")", "\n", "", "for", "fc", "in", "self", ".", "cls_fcs", ":", "\n", "\t\t\t", "x_cls", "=", "self", ".", "relu", "(", "fc", "(", "x_cls", ")", ")", "\n", "\n", "", "for", "conv", "in", "self", ".", "reg_convs", ":", "\n", "\t\t\t", "x_reg", "=", "conv", "(", "x_reg", ")", "\n", "", "if", "x_reg", ".", "dim", "(", ")", ">", "2", ":", "\n", "\t\t\t", "if", "self", ".", "with_avg_pool", ":", "\n", "\t\t\t\t", "x_reg", "=", "self", ".", "avg_pool", "(", "x_reg", ")", "\n", "", "x_reg", "=", "x_reg", ".", "flatten", "(", "1", ")", "\n", "", "for", "fc", "in", "self", ".", "reg_fcs", ":", "\n", "\t\t\t", "x_reg", "=", "self", ".", "relu", "(", "fc", "(", "x_reg", ")", ")", "\n", "\n", "", "cls_score", "=", "self", ".", "fc_cls", "(", "x_cls", ")", "if", "self", ".", "with_cls", "else", "None", "\n", "bbox_pred", "=", "self", ".", "fc_reg", "(", "x_reg", ")", "if", "self", ".", "with_reg", "else", "None", "\n", "return", "cls_score", ",", "bbox_pred", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.bbox_heads.selsa_bbox_head_origin.SelsaBBoxHead.__init__": [[18, 24], ["mmdet.models.ConvFCBBoxHead.__init__", "torch.ModuleList", "range", "torch.ReLU", "selsa_bbox_head_origin.SelsaBBoxHead.aggregator.append", "mmtrack.models.build_aggregator"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_aggregator"], ["def", "__init__", "(", "self", ",", "aggregator", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SelsaBBoxHead", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "aggregator", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_shared_fcs", ")", ":", "\n", "            ", "self", ".", "aggregator", ".", "append", "(", "build_aggregator", "(", "aggregator", ")", ")", "\n", "", "self", ".", "inplace_false_relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.bbox_heads.selsa_bbox_head_origin.SelsaBBoxHead.forward": [[25, 85], ["selsa_bbox_head_origin.SelsaBBoxHead.flatten", "selsa_bbox_head_origin.SelsaBBoxHead.flatten", "enumerate", "conv", "selsa_bbox_head_origin.SelsaBBoxHead.dim", "selsa_bbox_head_origin.SelsaBBoxHead.flatten", "selsa_bbox_head_origin.SelsaBBoxHead.relu", "conv", "selsa_bbox_head_origin.SelsaBBoxHead.dim", "selsa_bbox_head_origin.SelsaBBoxHead.flatten", "selsa_bbox_head_origin.SelsaBBoxHead.relu", "selsa_bbox_head_origin.SelsaBBoxHead.fc_cls", "selsa_bbox_head_origin.SelsaBBoxHead.fc_reg", "conv", "conv", "selsa_bbox_head_origin.SelsaBBoxHead.avg_pool", "selsa_bbox_head_origin.SelsaBBoxHead.avg_pool", "fc", "fc", "selsa_bbox_head_origin.SelsaBBoxHead.inplace_false_relu", "selsa_bbox_head_origin.SelsaBBoxHead.inplace_false_relu", "selsa_bbox_head_origin.SelsaBBoxHead.avg_pool", "fc", "selsa_bbox_head_origin.SelsaBBoxHead.avg_pool", "fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "ref_x", ")", ":", "\n", "        ", "\"\"\"Computing the `cls_score` and `bbox_pred` of the features `x` of key\n        frame proposals.\n\n        Args:\n            x (Tensor): of shape [N, C, H, W]. N is the number of key frame\n                proposals.\n            ref_x (Tensor): of shape [M, C, H, W]. M is the number of reference\n                frame proposals.\n\n        Returns:\n            tuple(cls_score, bbox_pred): The predicted score of classes and\n            the predicted regression offsets.\n        \"\"\"", "\n", "# shared part", "\n", "if", "self", ".", "num_shared_convs", ">", "0", ":", "\n", "            ", "for", "conv", "in", "self", ".", "shared_convs", ":", "\n", "                ", "x", "=", "conv", "(", "x", ")", "\n", "ref_x", "=", "conv", "(", "ref_x", ")", "\n", "\n", "", "", "if", "self", ".", "num_shared_fcs", ">", "0", ":", "\n", "            ", "if", "self", ".", "with_avg_pool", ":", "\n", "                ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "ref_x", "=", "self", ".", "avg_pool", "(", "ref_x", ")", "\n", "\n", "", "x", "=", "x", ".", "flatten", "(", "1", ")", "\n", "ref_x", "=", "ref_x", ".", "flatten", "(", "1", ")", "\n", "\n", "for", "i", ",", "fc", "in", "enumerate", "(", "self", ".", "shared_fcs", ")", ":", "\n", "                ", "x", "=", "fc", "(", "x", ")", "\n", "ref_x", "=", "fc", "(", "ref_x", ")", "\n", "x", "=", "x", "+", "self", ".", "aggregator", "[", "i", "]", "(", "x", ",", "ref_x", ")", "\n", "ref_x", "=", "self", ".", "inplace_false_relu", "(", "ref_x", ")", "\n", "x", "=", "self", ".", "inplace_false_relu", "(", "x", ")", "\n", "\n", "# separate branches", "\n", "", "", "x_cls", "=", "x", "\n", "x_reg", "=", "x", "\n", "\n", "for", "conv", "in", "self", ".", "cls_convs", ":", "\n", "            ", "x_cls", "=", "conv", "(", "x_cls", ")", "\n", "", "if", "x_cls", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "if", "self", ".", "with_avg_pool", ":", "\n", "                ", "x_cls", "=", "self", ".", "avg_pool", "(", "x_cls", ")", "\n", "", "x_cls", "=", "x_cls", ".", "flatten", "(", "1", ")", "\n", "", "for", "fc", "in", "self", ".", "cls_fcs", ":", "\n", "            ", "x_cls", "=", "self", ".", "relu", "(", "fc", "(", "x_cls", ")", ")", "\n", "\n", "", "for", "conv", "in", "self", ".", "reg_convs", ":", "\n", "            ", "x_reg", "=", "conv", "(", "x_reg", ")", "\n", "", "if", "x_reg", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "if", "self", ".", "with_avg_pool", ":", "\n", "                ", "x_reg", "=", "self", ".", "avg_pool", "(", "x_reg", ")", "\n", "", "x_reg", "=", "x_reg", ".", "flatten", "(", "1", ")", "\n", "", "for", "fc", "in", "self", ".", "reg_fcs", ":", "\n", "            ", "x_reg", "=", "self", ".", "relu", "(", "fc", "(", "x_reg", ")", ")", "\n", "\n", "", "cls_score", "=", "self", ".", "fc_cls", "(", "x_cls", ")", "if", "self", ".", "with_cls", "else", "None", "\n", "bbox_pred", "=", "self", ".", "fc_reg", "(", "x_reg", ")", "if", "self", ".", "with_reg", "else", "None", "\n", "return", "cls_score", ",", "bbox_pred", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.__init__": [[17, 20], ["torch.Module.__init__", "mmtrack.utils.get_root_logger"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseMultiObjectTracker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.init_module": [[21, 39], ["getattr", "mmcv.utils.print_log", "mmcv.runner.load_checkpoint", "getattr.init_weights"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["", "def", "init_module", "(", "self", ",", "module_name", ",", "pretrain", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of a sub-module.\n\n        Args:\n            module (nn.Module): A sub-module of the model.\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"", "\n", "module", "=", "getattr", "(", "self", ",", "module_name", ")", "\n", "if", "pretrain", "is", "not", "None", ":", "\n", "            ", "print_log", "(", "\n", "f'load {module_name} from: {pretrain}'", ",", "logger", "=", "self", ".", "logger", ")", "\n", "checkpoint", "=", "load_checkpoint", "(", "\n", "module", ",", "pretrain", ",", "strict", "=", "False", ",", "logger", "=", "self", ".", "logger", ")", "\n", "if", "'meta'", "in", "checkpoint", "and", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "                ", "module", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "else", ":", "\n", "            ", "module", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.freeze_module": [[40, 54], ["isinstance", "getattr", "getattr.eval", "getattr.parameters", "TypeError", "isinstance", "isinstance"], "methods", ["None"], ["", "", "def", "freeze_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Freeze module during training.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "str", ")", ":", "\n", "            ", "modules", "=", "[", "module", "]", "\n", "", "else", ":", "\n", "            ", "if", "not", "(", "isinstance", "(", "module", ",", "list", ")", "or", "isinstance", "(", "module", ",", "tuple", ")", ")", ":", "\n", "                ", "raise", "TypeError", "(", "'module must be a str or a list.'", ")", "\n", "", "else", ":", "\n", "                ", "modules", "=", "module", "\n", "", "", "for", "module", "in", "modules", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "module", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.with_detector": [[55, 59], ["hasattr"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "with_detector", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a detector.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'detector'", ")", "and", "self", ".", "detector", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.with_reid": [[60, 64], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_reid", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a reid model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.with_motion": [[65, 69], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_motion", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a motion model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.with_track_head": [[70, 74], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_track_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a track_head.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'track_head'", ")", "and", "self", ".", "track_head", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.with_tracker": [[75, 79], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_tracker", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a tracker.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'tracker'", ")", "and", "self", ".", "tracker", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.forward_train": [[80, 94], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward_train", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (list[Tensor]): List of tensors of shape (1, C, H, W).\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys, see\n                :class:`mmdet.datasets.pipelines.Collect`.\n            kwargs (keyword arguments): Specific to concrete implementation.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.simple_test": [[95, 99], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "simple_test", "(", "self", ",", "img", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with a single scale.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.aug_test": [[100, 103], ["None"], "methods", ["None"], ["", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.forward_test": [[104, 139], ["len", "len", "ValueError", "base.BaseMultiObjectTracker.simple_test", "base.BaseMultiObjectTracker.aug_test", "isinstance", "TypeError", "imgs[].size", "imgs[].size", "len", "len", "type"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.aug_test"], ["", "def", "forward_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            imgs (List[Tensor]): the outer list indicates test-time\n                augmentations and inner Tensor should have a shape NxCxHxW,\n                which contains all images in the batch.\n            img_metas (List[List[dict]]): the outer list indicates test-time\n                augs (multiscale, flip, etc.) and the inner list indicates\n                images in a batch.\n        \"\"\"", "\n", "for", "var", ",", "name", "in", "[", "(", "imgs", ",", "'imgs'", ")", ",", "(", "img_metas", ",", "'img_metas'", ")", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f'{name} must be a list, but got {type(var)}'", ")", "\n", "\n", "", "", "num_augs", "=", "len", "(", "imgs", ")", "\n", "if", "num_augs", "!=", "len", "(", "img_metas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'num of augmentations ({len(imgs)}) '", "\n", "f'!= num of image meta ({len(img_metas)})'", ")", "\n", "\n", "", "if", "num_augs", "==", "1", ":", "\n", "# proposals (List[List[Tensor]]): the outer list indicates", "\n", "# test-time augs (multiscale, flip, etc.) and the inner list", "\n", "# indicates images in a batch.", "\n", "# The Tensor should have a shape Px4, where P is the number of", "\n", "# proposals.", "\n", "            ", "if", "'proposals'", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "'proposals'", "]", "=", "kwargs", "[", "'proposals'", "]", "[", "0", "]", "\n", "", "return", "self", ".", "simple_test", "(", "imgs", "[", "0", "]", ",", "img_metas", "[", "0", "]", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "assert", "imgs", "[", "0", "]", ".", "size", "(", "0", ")", "==", "1", ",", "'aug test does not support '", "'inference with batch size '", "f'{imgs[0].size(0)}'", "\n", "# TODO: support test augmentation for predefined proposals", "\n", "assert", "'proposals'", "not", "in", "kwargs", "\n", "return", "self", ".", "aug_test", "(", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.forward": [[140, 155], ["mmcv.runner.auto_fp16", "base.BaseMultiObjectTracker.forward_train", "base.BaseMultiObjectTracker.forward_test"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward_test"], ["", "", "@", "auto_fp16", "(", "apply_to", "=", "(", "'img'", ",", ")", ")", "\n", "def", "forward", "(", "self", ",", "img", ",", "img_metas", ",", "return_loss", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calls either :func:`forward_train` or :func:`forward_test` depending\n        on whether ``return_loss`` is ``True``.\n\n        Note this setting will change the expected inputs. When\n        ``return_loss=True``, img and img_meta are single-nested (i.e. Tensor\n        and List[dict]), and when ``resturn_loss=False``, img and img_meta\n        should be double nested (i.e.  List[Tensor], List[List[dict]]), with\n        the outer list indicating test time augmentations.\n        \"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "forward_test", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker._parse_losses": [[156, 190], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["", "", "def", "_parse_losses", "(", "self", ",", "losses", ")", ":", "\n", "        ", "\"\"\"Parse the raw outputs (losses) of the network.\n\n        Args:\n            losses (dict): Raw output of the network, which usually contain\n                losses and other necessary infomation.\n\n        Returns:\n            tuple[Tensor, dict]: (loss, log_vars), loss is the loss tensor\n            which may be a weighted sum of all losses, log_vars contains\n            all the variables to be sent to the logger.\n        \"\"\"", "\n", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "f'{loss_name} is not a tensor or list of tensors'", ")", "\n", "\n", "", "", "loss", "=", "sum", "(", "_value", "for", "_key", ",", "_value", "in", "log_vars", ".", "items", "(", ")", "\n", "if", "'loss'", "in", "_key", ")", "\n", "\n", "log_vars", "[", "'loss'", "]", "=", "loss", "\n", "for", "loss_name", ",", "loss_value", "in", "log_vars", ".", "items", "(", ")", ":", "\n", "# reduce loss when distributed training", "\n", "            ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "loss_value", "=", "loss_value", ".", "data", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "loss_value", ".", "div_", "(", "dist", ".", "get_world_size", "(", ")", ")", ")", "\n", "", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "item", "(", ")", "\n", "\n", "", "return", "loss", ",", "log_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.train_step": [[191, 225], ["base.BaseMultiObjectTracker.", "base.BaseMultiObjectTracker._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["", "def", "train_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during training.\n\n        This method defines an iteration step during training, except for the\n        back propagation and optimizer updating, which are done in an optimizer\n        hook. Note that in some complicated cases or models, the whole process\n        including back propagation and optimizer updating is also defined in\n        this method, such as GAN.\n\n        Args:\n            data (dict): The output of dataloader.\n            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n                runner is passed to ``train_step()``. This argument is unused\n                and reserved.\n\n        Returns:\n            dict: It should contain at least 3 keys: ``loss``, ``log_vars``,\n            ``num_samples``.\n\n            - ``loss`` is a tensor for back propagation, which can be a\n            weighted sum of multiple losses.\n            - ``log_vars`` contains all the variables to be sent to the\n            logger.\n            - ``num_samples`` indicates the batch size (when the model is\n            DDP, it means the batch size on each GPU), which is used for\n            averaging the logs.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "log_vars", "=", "log_vars", ",", "num_samples", "=", "len", "(", "data", "[", "'img_metas'", "]", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.val_step": [[226, 240], ["base.BaseMultiObjectTracker.", "base.BaseMultiObjectTracker._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["", "def", "val_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during validation.\n\n        This method shares the same signature as :func:`train_step`, but used\n        during val epochs. Note that the evaluation after training epochs is\n        not implemented with this method, but an evaluation hook.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "log_vars", "=", "log_vars", ",", "num_samples", "=", "len", "(", "data", "[", "'img_metas'", "]", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.base.BaseMultiObjectTracker.show_result": [[241, 279], ["mmtrack.core.restore_result", "mmtrack.core.imshow_tracks"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.visualization.imshow_tracks"], ["", "def", "show_result", "(", "self", ",", "\n", "img", ",", "\n", "result", ",", "\n", "thickness", "=", "1", ",", "\n", "font_scale", "=", "0.5", ",", "\n", "show", "=", "False", ",", "\n", "out_file", "=", "None", ",", "\n", "backend", "=", "'cv2'", ")", ":", "\n", "        ", "\"\"\"Visualize tracking results.\n\n        Args:\n            img (str | ndarray): Filename of loaded image.\n            result (list[ndarray]): Tracking results.\n            thickness (int, optional): Thickness of lines. Defaults to 1.\n            font_scale (float, optional): Font scales of texts. Defaults\n                to 0.5.\n            show (bool, optional): Whether show the visualizations on the\n                fly. Defaults to False.\n            out_file (str | None, optional): Output filename. Defaults to None.\n            backend (str, optional): Backend to draw the bounding boxes,\n                options are `cv2` and `plt`. Defaults to 'cv2'.\n\n        Returns:\n            ndarray: Visualized image.\n        \"\"\"", "\n", "bboxes", ",", "labels", ",", "ids", "=", "restore_result", "(", "result", ",", "return_ids", "=", "True", ")", "\n", "img", "=", "imshow_tracks", "(", "\n", "img", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "ids", ",", "\n", "classes", "=", "self", ".", "CLASSES", ",", "\n", "thickness", "=", "thickness", ",", "\n", "font_scale", "=", "font_scale", ",", "\n", "show", "=", "show", ",", "\n", "out_file", "=", "out_file", ",", "\n", "backend", "=", "backend", ")", "\n", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.deep_sort.DeepSORT.__init__": [[16, 36], ["base.BaseMultiObjectTracker.__init__", "deep_sort.DeepSORT.init_weights", "builder.build_detector", "builder.build_reid", "builder.build_motion", "builder.build_tracker"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_reid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_motion", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_tracker"], ["def", "__init__", "(", "self", ",", "\n", "detector", "=", "None", ",", "\n", "reid", "=", "None", ",", "\n", "tracker", "=", "None", ",", "\n", "motion", "=", "None", ",", "\n", "pretrains", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "detector", "is", "not", "None", ":", "\n", "            ", "self", ".", "detector", "=", "build_detector", "(", "detector", ")", "\n", "\n", "", "if", "reid", "is", "not", "None", ":", "\n", "            ", "self", ".", "reid", "=", "build_reid", "(", "reid", ")", "\n", "\n", "", "if", "motion", "is", "not", "None", ":", "\n", "            ", "self", ".", "motion", "=", "build_motion", "(", "motion", ")", "\n", "\n", "", "if", "tracker", "is", "not", "None", ":", "\n", "            ", "self", ".", "tracker", "=", "build_tracker", "(", "tracker", ")", "\n", "\n", "", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.deep_sort.DeepSORT.init_weights": [[37, 50], ["isinstance", "dict", "dict.get", "deep_sort.DeepSORT.init_module", "dict.get", "deep_sort.DeepSORT.init_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module"], ["", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of the modules.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_detector", "and", "pretrain", ".", "get", "(", "'detector'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'detector'", ",", "pretrain", "[", "'detector'", "]", ")", "\n", "", "if", "self", ".", "with_reid", "and", "pretrain", ".", "get", "(", "'reid'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'reid'", ",", "pretrain", "[", "'reid'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.deep_sort.DeepSORT.forward_train": [[51, 56], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "forward_train", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function during training.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "'Please train `detector` and `reid` models first and \\\n                inference with Tracktor.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.deep_sort.DeepSORT.simple_test": [[57, 123], ["img_metas[].get", "deep_sort.DeepSORT.detector.extract_feat", "hasattr", "deep_sort.DeepSORT.tracker.track", "mmtrack.core.track2result", "mmdet.core.bbox2result", "dict", "deep_sort.DeepSORT.tracker.reset", "deep_sort.DeepSORT.detector.roi_head.simple_test_bboxes", "hasattr", "deep_sort.DeepSORT.detector.rpn_head.simple_test_rpn", "NotImplementedError", "TypeError"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.reset", "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes"], ["", "def", "simple_test", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "rescale", "=", "False", ",", "\n", "public_bboxes", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test without augmentations.\n\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n            rescale (bool, optional): If False, then returned bboxes and masks\n                will fit the scale of img, otherwise, returned bboxes and masks\n                will fit the scale of original image shape. Defaults to False.\n            public_bboxes (list[Tensor], optional): Public bounding boxes from\n                the benchmark. Defaults to None.\n\n        Returns:\n            dict[str : list(ndarray)]: The tracking results.\n        \"\"\"", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "if", "frame_id", "==", "0", ":", "\n", "            ", "self", ".", "tracker", ".", "reset", "(", ")", "\n", "\n", "", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "# TODO: check whether this is the case", "\n", "            ", "if", "public_bboxes", "is", "not", "None", ":", "\n", "                ", "public_bboxes", "=", "[", "_", "[", "0", "]", "for", "_", "in", "public_bboxes", "]", "\n", "proposals", "=", "public_bboxes", "\n", "", "else", ":", "\n", "                ", "proposals", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "x", ",", "img_metas", ")", "\n", "", "det_bboxes", ",", "det_labels", "=", "self", ".", "detector", ".", "roi_head", ".", "simple_test_bboxes", "(", "\n", "x", ",", "\n", "img_metas", ",", "\n", "proposals", ",", "\n", "self", ".", "detector", ".", "roi_head", ".", "test_cfg", ",", "\n", "rescale", "=", "rescale", ")", "\n", "# TODO: support batch inference", "\n", "det_bboxes", "=", "det_bboxes", "[", "0", "]", "\n", "det_labels", "=", "det_labels", "[", "0", "]", "\n", "num_classes", "=", "self", ".", "detector", ".", "roi_head", ".", "bbox_head", ".", "num_classes", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "num_classes", "=", "self", ".", "detector", ".", "bbox_head", ".", "num_classes", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "bboxes", ",", "labels", ",", "ids", "=", "self", ".", "tracker", ".", "track", "(", "\n", "img", "=", "img", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "model", "=", "self", ",", "\n", "feats", "=", "x", ",", "\n", "bboxes", "=", "det_bboxes", ",", "\n", "labels", "=", "det_labels", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "rescale", "=", "rescale", ",", "\n", "**", "kwargs", ")", "\n", "\n", "track_result", "=", "track2result", "(", "bboxes", ",", "labels", ",", "ids", ",", "num_classes", ")", "\n", "bbox_result", "=", "bbox2result", "(", "det_bboxes", ",", "det_labels", ",", "num_classes", ")", "\n", "return", "dict", "(", "bbox_results", "=", "bbox_result", ",", "track_results", "=", "track_result", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.__init__": [[17, 44], ["base.BaseMultiObjectTracker.__init__", "tracktor.Tracktor.init_weights", "builder.build_detector", "builder.build_reid", "builder.build_motion", "builder.build_tracker", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_reid", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_motion", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_tracker"], ["def", "__init__", "(", "self", ",", "\n", "detector", "=", "None", ",", "\n", "reid", "=", "None", ",", "\n", "tracker", "=", "None", ",", "\n", "motion", "=", "None", ",", "\n", "pretrains", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "detector", "is", "not", "None", ":", "\n", "            ", "self", ".", "detector", "=", "build_detector", "(", "detector", ")", "\n", "\n", "", "if", "reid", "is", "not", "None", ":", "\n", "            ", "self", ".", "reid", "=", "build_reid", "(", "reid", ")", "\n", "\n", "", "if", "motion", "is", "not", "None", ":", "\n", "            ", "self", ".", "motion", "=", "build_motion", "(", "motion", ")", "\n", "if", "not", "isinstance", "(", "self", ".", "motion", ",", "list", ")", ":", "\n", "                ", "self", ".", "motion", "=", "[", "self", ".", "motion", "]", "\n", "", "for", "m", "in", "self", ".", "motion", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "CameraMotionCompensation", ")", ":", "\n", "                    ", "self", ".", "cmc", "=", "m", "\n", "", "if", "isinstance", "(", "m", ",", "LinearMotion", ")", ":", "\n", "                    ", "self", ".", "linear_motion", "=", "m", "\n", "\n", "", "", "", "if", "tracker", "is", "not", "None", ":", "\n", "            ", "self", ".", "tracker", "=", "build_tracker", "(", "tracker", ")", "\n", "\n", "", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.init_weights": [[45, 58], ["isinstance", "dict", "dict.get", "tracktor.Tracktor.init_module", "dict.get", "tracktor.Tracktor.init_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module"], ["", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of the modules.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_detector", "and", "pretrain", ".", "get", "(", "'detector'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'detector'", ",", "pretrain", "[", "'detector'", "]", ")", "\n", "", "if", "self", ".", "with_reid", "and", "pretrain", ".", "get", "(", "'reid'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'reid'", ",", "pretrain", "[", "'reid'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.with_cmc": [[59, 65], ["hasattr"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "with_cmc", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a camera model compensation\n                model.\n        \"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'cmc'", ")", "and", "self", ".", "cmc", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.with_linear_motion": [[66, 71], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_linear_motion", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a linear motion model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "\n", "'linear_motion'", ")", "and", "self", ".", "linear_motion", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.forward_train": [[72, 77], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward_train", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function during training.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "'Please train `detector` and `reid` models first and \\\n                inference with Tracktor.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.mot.tracktor.Tracktor.simple_test": [[78, 144], ["img_metas[].get", "tracktor.Tracktor.detector.extract_feat", "hasattr", "tracktor.Tracktor.tracker.track", "mmtrack.core.track2result", "mmdet.core.bbox2result", "dict", "tracktor.Tracktor.tracker.reset", "tracktor.Tracktor.detector.roi_head.simple_test_bboxes", "hasattr", "tracktor.Tracktor.detector.rpn_head.simple_test_rpn", "NotImplementedError", "TypeError"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.reset", "home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes"], ["", "def", "simple_test", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "rescale", "=", "False", ",", "\n", "public_bboxes", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test without augmentations.\n\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n            rescale (bool, optional): If False, then returned bboxes and masks\n                will fit the scale of img, otherwise, returned bboxes and masks\n                will fit the scale of original image shape. Defaults to False.\n            public_bboxes (list[Tensor], optional): Public bounding boxes from\n                the benchmark. Defaults to None.\n\n        Returns:\n            dict[str : list(ndarray)]: The tracking results.\n        \"\"\"", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "if", "frame_id", "==", "0", ":", "\n", "            ", "self", ".", "tracker", ".", "reset", "(", ")", "\n", "\n", "", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "# TODO: check whether this is the case", "\n", "            ", "if", "public_bboxes", "is", "not", "None", ":", "\n", "                ", "public_bboxes", "=", "[", "_", "[", "0", "]", "for", "_", "in", "public_bboxes", "]", "\n", "proposals", "=", "public_bboxes", "\n", "", "else", ":", "\n", "                ", "proposals", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "x", ",", "img_metas", ")", "\n", "", "det_bboxes", ",", "det_labels", "=", "self", ".", "detector", ".", "roi_head", ".", "simple_test_bboxes", "(", "\n", "x", ",", "\n", "img_metas", ",", "\n", "proposals", ",", "\n", "self", ".", "detector", ".", "roi_head", ".", "test_cfg", ",", "\n", "rescale", "=", "rescale", ")", "\n", "# TODO: support batch inference", "\n", "det_bboxes", "=", "det_bboxes", "[", "0", "]", "\n", "det_labels", "=", "det_labels", "[", "0", "]", "\n", "num_classes", "=", "self", ".", "detector", ".", "roi_head", ".", "bbox_head", ".", "num_classes", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "num_classes", "=", "self", ".", "detector", ".", "bbox_head", ".", "num_classes", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "bboxes", ",", "labels", ",", "ids", "=", "self", ".", "tracker", ".", "track", "(", "\n", "img", "=", "img", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "model", "=", "self", ",", "\n", "feats", "=", "x", ",", "\n", "bboxes", "=", "det_bboxes", ",", "\n", "labels", "=", "det_labels", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "rescale", "=", "rescale", ",", "\n", "**", "kwargs", ")", "\n", "\n", "track_result", "=", "track2result", "(", "bboxes", ",", "labels", ",", "ids", ",", "num_classes", ")", "\n", "bbox_result", "=", "bbox2result", "(", "det_bboxes", ",", "det_labels", ",", "num_classes", ")", "\n", "return", "dict", "(", "bbox_results", "=", "bbox_result", ",", "track_results", "=", "track_result", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.tracktor_tracker.TracktorTracker.__init__": [[39, 56], ["dict", "dict", "base_tracker.BaseTracker.__init__", "dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "obj_score_thr", "=", "0.5", ",", "\n", "regression", "=", "dict", "(", "\n", "obj_score_thr", "=", "0.5", ",", "\n", "nms", "=", "dict", "(", "type", "=", "'nms'", ",", "iou_threshold", "=", "0.6", ")", ",", "\n", "match_iou_thr", "=", "0.3", ")", ",", "\n", "reid", "=", "dict", "(", "\n", "num_samples", "=", "10", ",", "\n", "img_scale", "=", "(", "256", ",", "128", ")", ",", "\n", "img_norm_cfg", "=", "None", ",", "\n", "match_score_thr", "=", "2.0", ",", "\n", "match_iou_thr", "=", "0.2", ")", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "obj_score_thr", "=", "obj_score_thr", "\n", "self", ".", "regression", "=", "regression", "\n", "self", ".", "reid", "=", "reid", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.tracktor_tracker.TracktorTracker.regress_tracks": [[57, 78], ["detector.roi_head.simple_test_bboxes", "mmdet.core.multiclass_nms", "torch.tensor().to", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.roi_heads.selsa_roi_head_origin.SelsaRoIHead.simple_test_bboxes"], ["", "def", "regress_tracks", "(", "self", ",", "x", ",", "img_metas", ",", "detector", ",", "frame_id", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Regress the tracks to current frame.\"\"\"", "\n", "memo", "=", "self", ".", "memo", "\n", "bboxes", "=", "memo", ".", "bboxes", "[", "memo", ".", "frame_ids", "==", "frame_id", "-", "1", "]", "\n", "ids", "=", "memo", ".", "ids", "[", "memo", ".", "frame_ids", "==", "frame_id", "-", "1", "]", "\n", "if", "rescale", ":", "\n", "            ", "bboxes", "*=", "torch", ".", "tensor", "(", "img_metas", "[", "0", "]", "[", "'scale_factor'", "]", ")", ".", "to", "(", "\n", "bboxes", ".", "device", ")", "\n", "", "track_bboxes", ",", "track_scores", "=", "detector", ".", "roi_head", ".", "simple_test_bboxes", "(", "\n", "x", ",", "img_metas", ",", "[", "bboxes", "]", ",", "None", ",", "rescale", "=", "rescale", ")", "\n", "track_bboxes", ",", "track_labels", ",", "valid_inds", "=", "multiclass_nms", "(", "\n", "track_bboxes", "[", "0", "]", ",", "\n", "track_scores", "[", "0", "]", ",", "\n", "0", ",", "\n", "self", ".", "regression", "[", "'nms'", "]", ",", "\n", "return_inds", "=", "True", ")", "\n", "ids", "=", "ids", "[", "valid_inds", "]", "\n", "\n", "valid_inds", "=", "track_bboxes", "[", ":", ",", "-", "1", "]", ">", "self", ".", "regression", "[", "'obj_score_thr'", "]", "\n", "return", "track_bboxes", "[", "valid_inds", "]", ",", "track_labels", "[", "valid_inds", "]", ",", "ids", "[", "\n", "valid_inds", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.tracktor_tracker.TracktorTracker.track": [[79, 215], ["tracktor_tracker.TracktorTracker.update", "tracktor_tracker.TracktorTracker.reid.get", "bboxes.new_zeros.new_zeros.size", "torch.arange", "tracktor_tracker.TracktorTracker.regress_tracks", "mmdet.core.bbox_overlaps", "torch.full", "torch.arange", "new_track_inds.sum", "torch.cat", "torch.cat", "torch.cat", "mmtrack.core.imrenormalize", "img.clone", "model.reid.simple_test", "model.cmc.track", "model.linear_motion.track", "model.reid.simple_test", "bboxes.new_zeros.new_zeros.new_zeros", "prop_bboxes.new_zeros.new_zeros.new_zeros", "torch.cat", "tracktor_tracker.TracktorTracker.crop_imgs", "bboxes.new_zeros.new_zeros.size", "tracktor_tracker.TracktorTracker.crop_imgs", "bboxes.new_zeros.new_zeros.size", "model.reid.simple_test", "model.reid.simple_test.new_zeros", "int", "tracktor_tracker.TracktorTracker.get", "torch.cdist().cpu().numpy", "tracktor_tracker.TracktorTracker.get", "mmdet.core.bbox_overlaps().cpu().numpy", "scipy.optimize.linear_sum_assignment", "zip", "new_track_inds.sum", "bboxes[].clone", "prop_bboxes[].clone", "tracktor_tracker.TracktorTracker.crop_imgs", "len", "bboxes.new_zeros.new_zeros.size", "tracktor_tracker.TracktorTracker.reid.get", "bboxes[].clone", "model.reid.simple_test.size", "torch.cdist().cpu", "mmdet.core.bbox_overlaps().cpu", "torch.cdist", "mmdet.core.bbox_overlaps"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.tracktor_tracker.TracktorTracker.regress_tracks", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.imrenormalize", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "track", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "model", ",", "\n", "feats", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "frame_id", ",", "\n", "rescale", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Tracking forward function.\n\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n            model (nn.Module): MOT model.\n            feats (tuple): Backbone features of the input image.\n            bboxes (Tensor): of shape (N, 5).\n            labels (Tensor): of shape (N, ).\n            frame_id (int): The id of current frame, 0-index.\n            rescale (bool, optional): If True, the bounding boxes should be\n                rescaled to fit the original scale of the image. Defaults to\n                False.\n\n        Returns:\n            tuple: Tracking results.\n        \"\"\"", "\n", "if", "self", ".", "with_reid", ":", "\n", "            ", "if", "self", ".", "reid", ".", "get", "(", "'img_norm_cfg'", ",", "False", ")", ":", "\n", "                ", "reid_img", "=", "imrenormalize", "(", "img", ",", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", ",", "\n", "self", ".", "reid", "[", "'img_norm_cfg'", "]", ")", "\n", "", "else", ":", "\n", "                ", "reid_img", "=", "img", ".", "clone", "(", ")", "\n", "\n", "", "", "valid_inds", "=", "bboxes", "[", ":", ",", "-", "1", "]", ">", "self", ".", "obj_score_thr", "\n", "bboxes", "=", "bboxes", "[", "valid_inds", "]", "\n", "labels", "=", "labels", "[", "valid_inds", "]", "\n", "\n", "if", "self", ".", "empty", ":", "\n", "            ", "num_new_tracks", "=", "bboxes", ".", "size", "(", "0", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "\n", "self", ".", "num_tracks", ",", "\n", "self", ".", "num_tracks", "+", "num_new_tracks", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "num_tracks", "+=", "num_new_tracks", "\n", "if", "self", ".", "with_reid", ":", "\n", "                ", "embeds", "=", "model", ".", "reid", ".", "simple_test", "(", "\n", "self", ".", "crop_imgs", "(", "reid_img", ",", "img_metas", ",", "bboxes", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "\n", "rescale", ")", ")", "\n", "", "", "else", ":", "\n", "# motion", "\n", "            ", "if", "model", ".", "with_cmc", ":", "\n", "                ", "if", "model", ".", "with_linear_motion", ":", "\n", "                    ", "num_samples", "=", "model", ".", "linear_motion", ".", "num_samples", "\n", "", "else", ":", "\n", "                    ", "num_samples", "=", "1", "\n", "", "self", ".", "tracks", "=", "model", ".", "cmc", ".", "track", "(", "self", ".", "last_img", ",", "img", ",", "self", ".", "tracks", ",", "\n", "num_samples", ",", "frame_id", ")", "\n", "\n", "", "if", "model", ".", "with_linear_motion", ":", "\n", "                ", "self", ".", "tracks", "=", "model", ".", "linear_motion", ".", "track", "(", "self", ".", "tracks", ",", "frame_id", ")", "\n", "\n", "# propagate tracks", "\n", "", "prop_bboxes", ",", "prop_labels", ",", "prop_ids", "=", "self", ".", "regress_tracks", "(", "\n", "feats", ",", "img_metas", ",", "model", ".", "detector", ",", "frame_id", ",", "rescale", ")", "\n", "\n", "# filter bboxes with propagated tracks", "\n", "ious", "=", "bbox_overlaps", "(", "bboxes", "[", ":", ",", ":", "4", "]", ",", "prop_bboxes", "[", ":", ",", ":", "4", "]", ")", "\n", "valid_inds", "=", "(", "ious", "<", "self", ".", "regression", "[", "'match_iou_thr'", "]", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "bboxes", "=", "bboxes", "[", "valid_inds", "]", "\n", "labels", "=", "labels", "[", "valid_inds", "]", "\n", "ids", "=", "torch", ".", "full", "(", "(", "bboxes", ".", "size", "(", "0", ")", ",", ")", ",", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "self", ".", "with_reid", ":", "\n", "                ", "prop_embeds", "=", "model", ".", "reid", ".", "simple_test", "(", "\n", "self", ".", "crop_imgs", "(", "reid_img", ",", "img_metas", ",", "\n", "prop_bboxes", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "rescale", ")", ")", "\n", "if", "bboxes", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                    ", "embeds", "=", "model", ".", "reid", ".", "simple_test", "(", "\n", "self", ".", "crop_imgs", "(", "reid_img", ",", "img_metas", ",", "\n", "bboxes", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "rescale", ")", ")", "\n", "", "else", ":", "\n", "                    ", "embeds", "=", "prop_embeds", ".", "new_zeros", "(", "(", "0", ",", "prop_embeds", ".", "size", "(", "1", ")", ")", ")", "\n", "# reid", "\n", "", "active_ids", "=", "[", "int", "(", "_", ")", "for", "_", "in", "self", ".", "ids", "if", "_", "not", "in", "prop_ids", "]", "\n", "if", "len", "(", "active_ids", ")", ">", "0", "and", "bboxes", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                    ", "track_embeds", "=", "self", ".", "get", "(", "\n", "'embeds'", ",", "\n", "active_ids", ",", "\n", "self", ".", "reid", ".", "get", "(", "'num_samples'", ",", "None", ")", ",", "\n", "behavior", "=", "'mean'", ")", "\n", "reid_dists", "=", "torch", ".", "cdist", "(", "track_embeds", ",", "\n", "embeds", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "track_bboxes", "=", "self", ".", "get", "(", "'bboxes'", ",", "active_ids", ")", "\n", "ious", "=", "bbox_overlaps", "(", "track_bboxes", ",", "\n", "bboxes", "[", ":", ",", ":", "4", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "iou_masks", "=", "ious", "<", "self", ".", "reid", "[", "'match_iou_thr'", "]", "\n", "reid_dists", "[", "iou_masks", "]", "=", "1e6", "\n", "\n", "row", ",", "col", "=", "linear_sum_assignment", "(", "reid_dists", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "row", ",", "col", ")", ":", "\n", "                        ", "dist", "=", "reid_dists", "[", "r", ",", "c", "]", "\n", "if", "dist", "<=", "self", ".", "reid", "[", "'match_score_thr'", "]", ":", "\n", "                            ", "ids", "[", "c", "]", "=", "active_ids", "[", "r", "]", "\n", "\n", "", "", "", "", "new_track_inds", "=", "ids", "==", "-", "1", "\n", "ids", "[", "new_track_inds", "]", "=", "torch", ".", "arange", "(", "\n", "self", ".", "num_tracks", ",", "\n", "self", ".", "num_tracks", "+", "new_track_inds", ".", "sum", "(", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "num_tracks", "+=", "new_track_inds", ".", "sum", "(", ")", "\n", "\n", "if", "bboxes", ".", "shape", "[", "1", "]", "==", "4", ":", "\n", "                ", "bboxes", "=", "bboxes", ".", "new_zeros", "(", "(", "0", ",", "5", ")", ")", "\n", "", "if", "prop_bboxes", ".", "shape", "[", "1", "]", "==", "4", ":", "\n", "                ", "prop_bboxes", "=", "prop_bboxes", ".", "new_zeros", "(", "(", "0", ",", "5", ")", ")", "\n", "\n", "", "bboxes", "=", "torch", ".", "cat", "(", "(", "prop_bboxes", ",", "bboxes", ")", ",", "dim", "=", "0", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "(", "prop_labels", ",", "labels", ")", ",", "dim", "=", "0", ")", "\n", "ids", "=", "torch", ".", "cat", "(", "(", "prop_ids", ",", "ids", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "with_reid", ":", "\n", "                ", "embeds", "=", "torch", ".", "cat", "(", "(", "prop_embeds", ",", "embeds", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "self", ".", "update", "(", "\n", "ids", "=", "ids", ",", "\n", "bboxes", "=", "bboxes", "[", ":", ",", ":", "4", "]", ",", "\n", "scores", "=", "bboxes", "[", ":", ",", "-", "1", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "embeds", "=", "embeds", "if", "self", ".", "with_reid", "else", "None", ",", "\n", "frame_ids", "=", "frame_id", ")", "\n", "self", ".", "last_img", "=", "img", "\n", "return", "bboxes", ",", "labels", ",", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.__init__": [[34, 49], ["dict", "base_tracker.BaseTracker.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "obj_score_thr", "=", "0.3", ",", "\n", "reid", "=", "dict", "(", "\n", "num_samples", "=", "10", ",", "\n", "img_scale", "=", "(", "256", ",", "128", ")", ",", "\n", "img_norm_cfg", "=", "None", ",", "\n", "match_score_thr", "=", "2.0", ")", ",", "\n", "match_iou_thr", "=", "0.7", ",", "\n", "num_tentatives", "=", "3", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "obj_score_thr", "=", "obj_score_thr", "\n", "self", ".", "reid", "=", "reid", "\n", "self", ".", "match_iou_thr", "=", "match_iou_thr", "\n", "self", ".", "num_tentatives", "=", "num_tentatives", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.xyxy2xyah": [[50, 58], ["torch.stack"], "methods", ["None"], ["", "def", "xyxy2xyah", "(", "self", ",", "bboxes", ")", ":", "\n", "        ", "\"\"\"Transform bounding boxes.\"\"\"", "\n", "cx", "=", "(", "bboxes", "[", ":", ",", "2", "]", "+", "bboxes", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "cy", "=", "(", "bboxes", "[", ":", ",", "3", "]", "+", "bboxes", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "w", "=", "bboxes", "[", ":", ",", "2", "]", "-", "bboxes", "[", ":", ",", "0", "]", "\n", "h", "=", "bboxes", "[", ":", ",", "3", "]", "-", "bboxes", "[", ":", ",", "1", "]", "\n", "xyah", "=", "torch", ".", "stack", "(", "[", "cx", ",", "cy", ",", "w", "/", "h", ",", "h", "]", ",", "-", "1", ")", "\n", "return", "xyah", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.confirmed_ids": [[59, 64], ["sort_tracker.SortTracker.tracks.items"], "methods", ["None"], ["", "@", "property", "\n", "def", "confirmed_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\"Confirmed ids in the tracker.\"\"\"", "\n", "ids", "=", "[", "id", "for", "id", ",", "track", "in", "self", ".", "tracks", ".", "items", "(", ")", "if", "not", "track", ".", "tentative", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.init_track": [[65, 74], ["super().init_track", "sort_tracker.SortTracker.xyxy2xyah", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze().cpu().numpy", "sort_tracker.SortTracker.kf.initiate", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze().cpu", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.init_track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.xyxy2xyah", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.kalman_filter.KalmanFilter.initiate"], ["", "def", "init_track", "(", "self", ",", "id", ",", "obj", ")", ":", "\n", "        ", "\"\"\"Initialize a track.\"\"\"", "\n", "super", "(", ")", ".", "init_track", "(", "id", ",", "obj", ")", "\n", "self", ".", "tracks", "[", "id", "]", ".", "tentative", "=", "True", "\n", "bbox", "=", "self", ".", "xyxy2xyah", "(", "self", ".", "tracks", "[", "id", "]", ".", "bboxes", "[", "-", "1", "]", ")", "# size = (1, 4)", "\n", "assert", "bbox", ".", "ndim", "==", "2", "and", "bbox", ".", "shape", "[", "0", "]", "==", "1", "\n", "bbox", "=", "bbox", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "tracks", "[", "id", "]", ".", "mean", ",", "self", ".", "tracks", "[", "id", "]", ".", "covariance", "=", "self", ".", "kf", ".", "initiate", "(", "\n", "bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.update_track": [[75, 86], ["super().update_track", "sort_tracker.SortTracker.xyxy2xyah", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze().cpu().numpy", "sort_tracker.SortTracker.kf.update", "len", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze().cpu", "bbox.squeeze().cpu().numpy.squeeze().cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update_track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.xyxy2xyah", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "update_track", "(", "self", ",", "id", ",", "obj", ")", ":", "\n", "        ", "\"\"\"Update a track.\"\"\"", "\n", "super", "(", ")", ".", "update_track", "(", "id", ",", "obj", ")", "\n", "if", "self", ".", "tracks", "[", "id", "]", ".", "tentative", ":", "\n", "            ", "if", "len", "(", "self", ".", "tracks", "[", "id", "]", "[", "'bboxes'", "]", ")", ">=", "self", ".", "num_tentatives", ":", "\n", "                ", "self", ".", "tracks", "[", "id", "]", ".", "tentative", "=", "False", "\n", "", "", "bbox", "=", "self", ".", "xyxy2xyah", "(", "self", ".", "tracks", "[", "id", "]", ".", "bboxes", "[", "-", "1", "]", ")", "# size = (1, 4)", "\n", "assert", "bbox", ".", "ndim", "==", "2", "and", "bbox", ".", "shape", "[", "0", "]", "==", "1", "\n", "bbox", "=", "bbox", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "tracks", "[", "id", "]", ".", "mean", ",", "self", ".", "tracks", "[", "id", "]", ".", "covariance", "=", "self", ".", "kf", ".", "update", "(", "\n", "self", ".", "tracks", "[", "id", "]", ".", "mean", ",", "self", ".", "tracks", "[", "id", "]", ".", "covariance", ",", "bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.pop_invalid_tracks": [[87, 99], ["sort_tracker.SortTracker.tracks.items", "sort_tracker.SortTracker.tracks.pop", "invalid_ids.append"], "methods", ["None"], ["", "def", "pop_invalid_tracks", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "\"\"\"Pop out invalid tracks.\"\"\"", "\n", "invalid_ids", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "tracks", ".", "items", "(", ")", ":", "\n", "# case1: disappeared frames >= self.num_frames_retrain", "\n", "            ", "case1", "=", "frame_id", "-", "v", "[", "'frame_ids'", "]", "[", "-", "1", "]", ">=", "self", ".", "num_frames_retain", "\n", "# case2: tentative tracks but not matched in this frame", "\n", "case2", "=", "v", ".", "tentative", "and", "v", "[", "'frame_ids'", "]", "[", "-", "1", "]", "!=", "frame_id", "\n", "if", "case1", "or", "case2", ":", "\n", "                ", "invalid_ids", ".", "append", "(", "k", ")", "\n", "", "", "for", "invalid_id", "in", "invalid_ids", ":", "\n", "            ", "self", ".", "tracks", ".", "pop", "(", "invalid_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.track": [[100, 218], ["sort_tracker.SortTracker.update", "hasattr", "sort_tracker.SortTracker.reid.get", "bboxes.size", "torch.arange", "torch.full", "torch.arange", "new_track_inds.sum", "mmtrack.core.imrenormalize", "img.clone", "bboxes.size", "model.reid.simple_test", "model.motion.track", "model.reid.simple_test", "len", "torch.nonzero().squeeze", "sort_tracker.SortTracker.get", "mmdet.core.bbox_overlaps().cpu().numpy", "motmetrics.lap.linear_sum_assignment", "zip", "sort_tracker.SortTracker.crop_imgs", "bboxes.size", "sort_tracker.SortTracker.xyxy2xyah", "sort_tracker.SortTracker.crop_imgs", "len", "sort_tracker.SortTracker.get", "torch.cdist().cpu().numpy", "motmetrics.lap.linear_sum_assignment", "zip", "new_track_inds.sum", "bboxes[].clone", "bboxes[].clone", "sort_tracker.SortTracker.reid.get", "list().index", "torch.nonzero", "mmdet.core.bbox_overlaps().cpu", "torch.cdist().cpu", "numpy.isfinite", "list", "numpy.isfinite", "mmdet.core.bbox_overlaps", "torch.cdist"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.imrenormalize", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.sort_tracker.SortTracker.xyxy2xyah", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "", "def", "track", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "model", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "frame_id", ",", "\n", "rescale", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Tracking forward function.\n\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n            model (nn.Module): MOT model.\n            bboxes (Tensor): of shape (N, 5).\n            labels (Tensor): of shape (N, ).\n            frame_id (int): The id of current frame, 0-index.\n            rescale (bool, optional): If True, the bounding boxes should be\n                rescaled to fit the original scale of the image. Defaults to\n                False.\n\n        Returns:\n            tuple: Tracking results.\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'kf'", ")", ":", "\n", "            ", "self", ".", "kf", "=", "model", ".", "motion", "\n", "\n", "", "if", "self", ".", "with_reid", ":", "\n", "            ", "if", "self", ".", "reid", ".", "get", "(", "'img_norm_cfg'", ",", "False", ")", ":", "\n", "                ", "reid_img", "=", "imrenormalize", "(", "img", ",", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", ",", "\n", "self", ".", "reid", "[", "'img_norm_cfg'", "]", ")", "\n", "", "else", ":", "\n", "                ", "reid_img", "=", "img", ".", "clone", "(", ")", "\n", "\n", "", "", "valid_inds", "=", "bboxes", "[", ":", ",", "-", "1", "]", ">", "self", ".", "obj_score_thr", "\n", "bboxes", "=", "bboxes", "[", "valid_inds", "]", "\n", "labels", "=", "labels", "[", "valid_inds", "]", "\n", "\n", "if", "self", ".", "empty", "or", "bboxes", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "            ", "num_new_tracks", "=", "bboxes", ".", "size", "(", "0", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "\n", "self", ".", "num_tracks", ",", "\n", "self", ".", "num_tracks", "+", "num_new_tracks", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "num_tracks", "+=", "num_new_tracks", "\n", "if", "self", ".", "with_reid", ":", "\n", "                ", "embeds", "=", "model", ".", "reid", ".", "simple_test", "(", "\n", "self", ".", "crop_imgs", "(", "reid_img", ",", "img_metas", ",", "bboxes", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "\n", "rescale", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "ids", "=", "torch", ".", "full", "(", "(", "bboxes", ".", "size", "(", "0", ")", ",", ")", ",", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# motion", "\n", "if", "model", ".", "with_motion", ":", "\n", "                ", "self", ".", "tracks", ",", "costs", "=", "model", ".", "motion", ".", "track", "(", "\n", "self", ".", "tracks", ",", "self", ".", "xyxy2xyah", "(", "bboxes", ")", ")", "\n", "\n", "", "active_ids", "=", "self", ".", "confirmed_ids", "\n", "if", "self", ".", "with_reid", ":", "\n", "                ", "embeds", "=", "model", ".", "reid", ".", "simple_test", "(", "\n", "self", ".", "crop_imgs", "(", "reid_img", ",", "img_metas", ",", "bboxes", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "\n", "rescale", ")", ")", "\n", "# reid", "\n", "if", "len", "(", "active_ids", ")", ">", "0", ":", "\n", "                    ", "track_embeds", "=", "self", ".", "get", "(", "\n", "'embeds'", ",", "\n", "active_ids", ",", "\n", "self", ".", "reid", ".", "get", "(", "'num_samples'", ",", "None", ")", ",", "\n", "behavior", "=", "'mean'", ")", "\n", "reid_dists", "=", "torch", ".", "cdist", "(", "track_embeds", ",", "\n", "embeds", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "valid_inds", "=", "[", "list", "(", "self", ".", "ids", ")", ".", "index", "(", "_", ")", "for", "_", "in", "active_ids", "]", "\n", "reid_dists", "[", "~", "np", ".", "isfinite", "(", "costs", "[", "valid_inds", ",", ":", "]", ")", "]", "=", "np", ".", "nan", "\n", "\n", "row", ",", "col", "=", "linear_sum_assignment", "(", "reid_dists", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "row", ",", "col", ")", ":", "\n", "                        ", "dist", "=", "reid_dists", "[", "r", ",", "c", "]", "\n", "if", "not", "np", ".", "isfinite", "(", "dist", ")", ":", "\n", "                            ", "continue", "\n", "", "if", "dist", "<=", "self", ".", "reid", "[", "'match_score_thr'", "]", ":", "\n", "                            ", "ids", "[", "c", "]", "=", "active_ids", "[", "r", "]", "\n", "\n", "", "", "", "", "active_ids", "=", "[", "\n", "id", "for", "id", "in", "self", ".", "ids", "if", "id", "not", "in", "ids", "\n", "and", "self", ".", "tracks", "[", "id", "]", ".", "frame_ids", "[", "-", "1", "]", "==", "frame_id", "-", "1", "\n", "]", "\n", "if", "len", "(", "active_ids", ")", ">", "0", ":", "\n", "                ", "active_dets", "=", "torch", ".", "nonzero", "(", "ids", "==", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "track_bboxes", "=", "self", ".", "get", "(", "'bboxes'", ",", "active_ids", ")", "\n", "ious", "=", "bbox_overlaps", "(", "\n", "track_bboxes", ",", "bboxes", "[", "active_dets", "]", "[", ":", ",", ":", "-", "1", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "dists", "=", "1", "-", "ious", "\n", "row", ",", "col", "=", "linear_sum_assignment", "(", "dists", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "row", ",", "col", ")", ":", "\n", "                    ", "dist", "=", "dists", "[", "r", ",", "c", "]", "\n", "if", "dist", "<", "1", "-", "self", ".", "match_iou_thr", ":", "\n", "                        ", "ids", "[", "active_dets", "[", "c", "]", "]", "=", "active_ids", "[", "r", "]", "\n", "\n", "", "", "", "new_track_inds", "=", "ids", "==", "-", "1", "\n", "ids", "[", "new_track_inds", "]", "=", "torch", ".", "arange", "(", "\n", "self", ".", "num_tracks", ",", "\n", "self", ".", "num_tracks", "+", "new_track_inds", ".", "sum", "(", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "num_tracks", "+=", "new_track_inds", ".", "sum", "(", ")", "\n", "\n", "", "self", ".", "update", "(", "\n", "ids", "=", "ids", ",", "\n", "bboxes", "=", "bboxes", "[", ":", ",", ":", "4", "]", ",", "\n", "scores", "=", "bboxes", "[", ":", ",", "-", "1", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "embeds", "=", "embeds", "if", "self", ".", "with_reid", "else", "None", ",", "\n", "frame_ids", "=", "frame_id", ")", "\n", "return", "bboxes", ",", "labels", ",", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.__init__": [[22, 30], ["super().__init__", "base_tracker.BaseTracker.reset", "isinstance"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.reset"], ["def", "__init__", "(", "self", ",", "momentums", "=", "None", ",", "num_frames_retain", "=", "10", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "momentums", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "momentums", ",", "dict", ")", ",", "'momentums must be a dict'", "\n", "", "self", ".", "momentums", "=", "momentums", "\n", "self", ".", "num_frames_retain", "=", "num_frames_retain", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.reset": [[31, 35], ["dict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the buffer of the tracker.\"\"\"", "\n", "self", ".", "num_tracks", "=", "0", "\n", "self", ".", "tracks", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.empty": [[36, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "empty", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether the buffer is empty or not.\"\"\"", "\n", "return", "False", "if", "self", ".", "tracks", "else", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.ids": [[41, 45], ["list", "base_tracker.BaseTracker.tracks.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "ids", "(", "self", ")", ":", "\n", "        ", "\"\"\"All ids in the tracker.\"\"\"", "\n", "return", "list", "(", "self", ".", "tracks", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.with_reid": [[46, 50], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_reid", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a reid model\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update": [[51, 89], ["len", "memo_items.index", "int", "isinstance", "kwargs.items", "zip", "base_tracker.BaseTracker.pop_invalid_tracks", "kwargs.pop", "hasattr", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "int", "kwargs.items", "kwargs.keys", "len", "ValueError", "kwargs.values", "base_tracker.BaseTracker.update_track", "base_tracker.BaseTracker.init_track"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.pop_invalid_tracks", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update_track", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.init_track"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Update the tracker.\n\n        Args:\n            kwargs (dict[str: Tensor | int]): The `str` indicates the\n                name of the input variable. `ids` and `frame_ids` are\n                obligatory in the keys.\n        \"\"\"", "\n", "memo_items", "=", "[", "k", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "]", "\n", "rm_items", "=", "[", "k", "for", "k", "in", "kwargs", ".", "keys", "(", ")", "if", "k", "not", "in", "memo_items", "]", "\n", "for", "item", "in", "rm_items", ":", "\n", "            ", "kwargs", ".", "pop", "(", "item", ")", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'memo_items'", ")", ":", "\n", "            ", "self", ".", "memo_items", "=", "memo_items", "\n", "", "else", ":", "\n", "            ", "assert", "memo_items", "==", "self", ".", "memo_items", "\n", "\n", "", "assert", "'ids'", "in", "memo_items", "\n", "num_objs", "=", "len", "(", "kwargs", "[", "'ids'", "]", ")", "\n", "id_indice", "=", "memo_items", ".", "index", "(", "'ids'", ")", "\n", "assert", "'frame_ids'", "in", "memo_items", "\n", "frame_id", "=", "int", "(", "kwargs", "[", "'frame_ids'", "]", ")", "\n", "if", "isinstance", "(", "kwargs", "[", "'frame_ids'", "]", ",", "int", ")", ":", "\n", "            ", "kwargs", "[", "'frame_ids'", "]", "=", "torch", ".", "tensor", "(", "[", "kwargs", "[", "'frame_ids'", "]", "]", "*", "\n", "num_objs", ")", "\n", "# cur_frame_id = int(kwargs['frame_ids'][0])", "\n", "", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "v", ")", "!=", "num_objs", ":", "\n", "                ", "raise", "ValueError", "(", ")", "\n", "\n", "", "", "for", "obj", "in", "zip", "(", "*", "kwargs", ".", "values", "(", ")", ")", ":", "\n", "            ", "id", "=", "int", "(", "obj", "[", "id_indice", "]", ")", "\n", "if", "id", "in", "self", ".", "tracks", ":", "\n", "                ", "self", ".", "update_track", "(", "id", ",", "obj", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "init_track", "(", "id", ",", "obj", ")", "\n", "\n", "", "", "self", ".", "pop_invalid_tracks", "(", "frame_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.pop_invalid_tracks": [[90, 98], ["base_tracker.BaseTracker.tracks.items", "base_tracker.BaseTracker.tracks.pop", "invalid_ids.append"], "methods", ["None"], ["", "def", "pop_invalid_tracks", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "\"\"\"Pop out invalid tracks.\"\"\"", "\n", "invalid_ids", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "tracks", ".", "items", "(", ")", ":", "\n", "            ", "if", "frame_id", "-", "v", "[", "'frame_ids'", "]", "[", "-", "1", "]", ">=", "self", ".", "num_frames_retain", ":", "\n", "                ", "invalid_ids", ".", "append", "(", "k", ")", "\n", "", "", "for", "invalid_id", "in", "invalid_ids", ":", "\n", "            ", "self", ".", "tracks", ".", "pop", "(", "invalid_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update_track": [[99, 108], ["zip", "[].append"], "methods", ["None"], ["", "", "def", "update_track", "(", "self", ",", "id", ",", "obj", ")", ":", "\n", "        ", "\"\"\"Update a track.\"\"\"", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "memo_items", ",", "obj", ")", ":", "\n", "            ", "v", "=", "v", "[", "None", "]", "\n", "if", "self", ".", "momentums", "is", "not", "None", "and", "k", "in", "self", ".", "momentums", ":", "\n", "                ", "m", "=", "self", ".", "momentums", "[", "k", "]", "\n", "self", ".", "tracks", "[", "id", "]", "[", "k", "]", "=", "(", "1", "-", "m", ")", "*", "self", ".", "tracks", "[", "id", "]", "[", "k", "]", "+", "m", "*", "v", "\n", "", "else", ":", "\n", "                ", "self", ".", "tracks", "[", "id", "]", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.init_track": [[109, 118], ["addict.Dict", "zip"], "methods", ["None"], ["", "", "", "def", "init_track", "(", "self", ",", "id", ",", "obj", ")", ":", "\n", "        ", "\"\"\"Initialize a track.\"\"\"", "\n", "self", ".", "tracks", "[", "id", "]", "=", "Dict", "(", ")", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "memo_items", ",", "obj", ")", ":", "\n", "            ", "v", "=", "v", "[", "None", "]", "\n", "if", "self", ".", "momentums", "is", "not", "None", "and", "k", "in", "self", ".", "momentums", ":", "\n", "                ", "self", ".", "tracks", "[", "id", "]", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "                ", "self", ".", "tracks", "[", "id", "]", "[", "k", "]", "=", "[", "v", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.memo": [[119, 139], ["addict.Dict", "base_tracker.BaseTracker.tracks.items", "addict.Dict.items", "objs.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "outs[].append"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "memo", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return all buffers in the tracker.\"\"\"", "\n", "outs", "=", "Dict", "(", ")", "\n", "for", "k", "in", "self", ".", "memo_items", ":", "\n", "            ", "outs", "[", "k", "]", "=", "[", "]", "\n", "\n", "", "for", "id", ",", "objs", "in", "self", ".", "tracks", ".", "items", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "objs", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "not", "in", "outs", ":", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "momentums", "is", "not", "None", "and", "k", "in", "self", ".", "momentums", ":", "\n", "                    ", "v", "=", "v", "\n", "", "else", ":", "\n", "                    ", "v", "=", "v", "[", "-", "1", "]", "\n", "", "outs", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n", "", "", "for", "k", ",", "v", "in", "outs", ".", "items", "(", ")", ":", "\n", "            ", "outs", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "dim", "=", "0", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get": [[140, 174], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "outs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "out.mean.mean.mean", "NotImplementedError"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "item", ",", "ids", "=", "None", ",", "num_samples", "=", "None", ",", "behavior", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get the buffer of a specific item.\n\n        Args:\n            item (str): The demanded item.\n            ids (list[int]): The demaned ids.\n            num_samples (int, optional): Number of samples to calculate the\n                results. Defaults to None.\n            behavior (str, optional): Behavior to calculate the results.\n                Options are `mean` | None. Defaults to None.\n\n        Returns:\n            Tensor: The results of the demanded item.\n        \"\"\"", "\n", "if", "ids", "is", "None", ":", "\n", "            ", "ids", "=", "self", ".", "ids", "\n", "\n", "", "outs", "=", "[", "]", "\n", "for", "id", "in", "ids", ":", "\n", "            ", "out", "=", "self", ".", "tracks", "[", "id", "]", "[", "item", "]", "\n", "if", "isinstance", "(", "out", ",", "list", ")", ":", "\n", "                ", "if", "num_samples", "is", "not", "None", ":", "\n", "                    ", "out", "=", "out", "[", "-", "num_samples", ":", "]", "\n", "out", "=", "torch", ".", "cat", "(", "out", ",", "dim", "=", "0", ")", "\n", "if", "behavior", "==", "'mean'", ":", "\n", "                        ", "out", "=", "out", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "", "elif", "behavior", "is", "None", ":", "\n", "                        ", "out", "=", "out", "[", "None", "]", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "out", "=", "out", "[", "-", "1", "]", "\n", "", "", "outs", ".", "append", "(", "out", ")", "\n", "", "return", "torch", ".", "cat", "(", "outs", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.track": [[175, 179], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "track", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Tracking forward function.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.crop_imgs": [[180, 225], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "map", "base_tracker.BaseTracker.reid.get", "crop_imgs.append", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "img.new_zeros", "torch.interpolate", "torch.interpolate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "crop_imgs", "(", "self", ",", "img", ",", "img_metas", ",", "bboxes", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Crop the images according to some bounding boxes. Typically for re-\n        identification sub-module.\n\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n            bboxes (Tensor): of shape (N, 4) or (N, 5).\n            rescale (bool, optional): If True, the bounding boxes should be\n                rescaled to fit the scale of the image. Defaults to False.\n\n        Returns:\n            Tensor: Image tensor of shape (N, C, H, W).\n        \"\"\"", "\n", "h", ",", "w", ",", "_", "=", "img_metas", "[", "0", "]", "[", "'img_shape'", "]", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "\n", "if", "rescale", ":", "\n", "            ", "bboxes", "[", ":", ",", ":", "4", "]", "*=", "torch", ".", "tensor", "(", "img_metas", "[", "0", "]", "[", "'scale_factor'", "]", ")", ".", "to", "(", "\n", "bboxes", ".", "device", ")", "\n", "", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "clamp", "(", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", ",", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "clamp", "(", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", ",", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "\n", "crop_imgs", "=", "[", "]", "\n", "for", "bbox", "in", "bboxes", ":", "\n", "            ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "map", "(", "int", ",", "bbox", ")", "\n", "if", "x2", "==", "x1", ":", "\n", "                ", "x2", "=", "x1", "+", "1", "\n", "", "if", "y2", "==", "y1", ":", "\n", "                ", "y2", "=", "y1", "+", "1", "\n", "", "crop_img", "=", "img", "[", ":", ",", ":", ",", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "\n", "if", "self", ".", "reid", ".", "get", "(", "'img_scale'", ",", "False", ")", ":", "\n", "                ", "crop_img", "=", "F", ".", "interpolate", "(", "\n", "crop_img", ",", "\n", "size", "=", "self", ".", "reid", "[", "'img_scale'", "]", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "", "crop_imgs", ".", "append", "(", "crop_img", ")", "\n", "\n", "", "if", "len", "(", "crop_imgs", ")", ">", "0", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "crop_imgs", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", ".", "new_zeros", "(", "(", "0", ",", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.backbones.sot_resnet.SOTBottleneck.__init__": [[10, 145], ["dict", "mmdet.models.backbones.resnet.Bottleneck.__init__", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_conv_layer", "sot_resnet.SOTBottleneck.add_module", "sot_resnet.SOTBottleneck.add_module", "mmcv.cnn.build_conv_layer", "sot_resnet.SOTBottleneck.add_module", "torch.ReLU", "isinstance", "isinstance", "all", "dcn.pop", "mmcv.cnn.build_conv_layer", "mmcv.cnn.build_conv_layer", "sot_resnet.SOTBottleneck.make_block_plugins", "sot_resnet.SOTBottleneck.make_block_plugins", "sot_resnet.SOTBottleneck.make_block_plugins", "dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ")", ":", "\n", "        ", "\"\"\"Bottleneck block for ResNet.\n\n        If style is \"pytorch\", the stride-two layer is the 3x3 conv layer, if\n        it is \"caffe\", the stride-two layer is the first 1x1 conv layer.\n        \"\"\"", "\n", "super", "(", "SOTBottleneck", ",", "self", ")", ".", "__init__", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ")", "\n", "assert", "style", "in", "[", "'pytorch'", ",", "'caffe'", "]", "\n", "assert", "dcn", "is", "None", "or", "isinstance", "(", "dcn", ",", "dict", ")", "\n", "assert", "plugins", "is", "None", "or", "isinstance", "(", "plugins", ",", "list", ")", "\n", "if", "plugins", "is", "not", "None", ":", "\n", "            ", "allowed_position", "=", "[", "'after_conv1'", ",", "'after_conv2'", ",", "'after_conv3'", "]", "\n", "assert", "all", "(", "p", "[", "'position'", "]", "in", "allowed_position", "for", "p", "in", "plugins", ")", "\n", "\n", "", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "dcn", "=", "dcn", "\n", "self", ".", "with_dcn", "=", "dcn", "is", "not", "None", "\n", "self", ".", "plugins", "=", "plugins", "\n", "self", ".", "with_plugins", "=", "plugins", "is", "not", "None", "\n", "\n", "padding", "=", "2", "-", "stride", "\n", "if", "dilation", ">", "1", ":", "\n", "            ", "padding", "=", "dilation", "\n", "if", "downsample", "is", "not", "None", ":", "\n", "                ", "dilation", "=", "dilation", "//", "2", "\n", "padding", "=", "dilation", "\n", "\n", "", "", "if", "self", ".", "with_plugins", ":", "\n", "# collect plugins for conv1/conv2/conv3", "\n", "            ", "self", ".", "after_conv1_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv1'", "\n", "]", "\n", "self", ".", "after_conv2_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv2'", "\n", "]", "\n", "self", ".", "after_conv3_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv3'", "\n", "]", "\n", "\n", "", "if", "self", ".", "style", "==", "'pytorch'", ":", "\n", "            ", "self", ".", "conv1_stride", "=", "1", "\n", "self", ".", "conv2_stride", "=", "stride", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1_stride", "=", "stride", "\n", "self", ".", "conv2_stride", "=", "1", "\n", "\n", "", "self", ".", "norm1_name", ",", "norm1", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "1", ")", "\n", "self", ".", "norm2_name", ",", "norm2", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "2", ")", "\n", "self", ".", "norm3_name", ",", "norm3", "=", "build_norm_layer", "(", "\n", "norm_cfg", ",", "planes", "*", "self", ".", "expansion", ",", "postfix", "=", "3", ")", "\n", "\n", "self", ".", "conv1", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "self", ".", "conv1_stride", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm1_name", ",", "norm1", ")", "\n", "fallback_on_stride", "=", "False", "\n", "if", "self", ".", "with_dcn", ":", "\n", "            ", "fallback_on_stride", "=", "dcn", ".", "pop", "(", "'fallback_on_stride'", ",", "False", ")", "\n", "", "if", "not", "self", ".", "with_dcn", "or", "fallback_on_stride", ":", "\n", "            ", "self", ".", "conv2", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "planes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "self", ".", "conv2_stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "conv_cfg", "is", "None", ",", "'conv_cfg must be None for DCN'", "\n", "self", ".", "conv2", "=", "build_conv_layer", "(", "\n", "dcn", ",", "\n", "planes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "self", ".", "conv2_stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "add_module", "(", "self", ".", "norm2_name", ",", "norm2", ")", "\n", "self", ".", "conv3", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "planes", ",", "\n", "planes", "*", "self", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm3_name", ",", "norm3", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "            ", "self", ".", "after_conv1_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", ",", "self", ".", "after_conv1_plugins", ")", "\n", "self", ".", "after_conv2_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", ",", "self", ".", "after_conv2_plugins", ")", "\n", "self", ".", "after_conv3_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", "*", "self", ".", "expansion", ",", "self", ".", "after_conv3_plugins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.backbones.sot_resnet.SOTResNet.__init__": [[161, 164], ["mmdet.models.backbones.resnet.ResNet.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "depth", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "depth", "==", "50", ",", "'Only support r50 backbone for sot.'", "\n", "super", "(", "SOTResNet", ",", "self", ")", ".", "__init__", "(", "depth", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.backbones.sot_resnet.SOTResNet.make_res_layer": [[165, 168], ["sot_resnet.SOTResLayer"], "methods", ["None"], ["", "def", "make_res_layer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Pack all blocks in a stage into a ``ResLayer``.\"\"\"", "\n", "return", "SOTResLayer", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.backbones.sot_resnet.SOTResNet._make_stem_layer": [[169, 216], ["torch.MaxPool2d", "torch.Sequential", "mmcv.cnn.build_conv_layer", "mmcv.cnn.build_norm_layer", "sot_resnet.SOTResNet.add_module", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer"], "methods", ["None"], ["", "def", "_make_stem_layer", "(", "self", ",", "in_channels", ",", "stem_channels", ")", ":", "\n", "        ", "if", "self", ".", "deep_stem", ":", "\n", "            ", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "in_channels", ",", "\n", "stem_channels", "//", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", "//", "2", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "stem_channels", "//", "2", ",", "\n", "stem_channels", "//", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", "//", "2", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "stem_channels", "//", "2", ",", "\n", "stem_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "in_channels", ",", "\n", "stem_channels", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "norm1_name", ",", "norm1", "=", "build_norm_layer", "(", "\n", "self", ".", "norm_cfg", ",", "stem_channels", ",", "postfix", "=", "1", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm1_name", ",", "norm1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.backbones.sot_resnet.SOTResLayer.__init__": [[237, 322], ["dict", "torch.Sequential.__init__", "torch.Sequential", "layers.append", "range", "range", "layers.append", "mmcv.cnn.build_conv_layer", "block", "layers.append", "layers.append", "block", "mmcv.cnn.build_norm_layer", "block", "block"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "num_blocks", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "avg_down", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "downsample_first", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "block", "=", "block", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "stride", "==", "1", "and", "dilation", "==", "1", ":", "\n", "                ", "kernel_size", "=", "1", "\n", "dd", "=", "1", "\n", "padding", "=", "0", "\n", "", "else", ":", "\n", "                ", "kernel_size", "=", "3", "\n", "if", "dilation", ">", "1", ":", "\n", "                    ", "dd", "=", "dilation", "//", "2", "\n", "padding", "=", "dd", "\n", "", "else", ":", "\n", "                    ", "dd", "=", "1", "\n", "padding", "=", "0", "\n", "", "", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dd", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "norm_cfg", ",", "planes", "*", "block", ".", "expansion", ")", "[", "1", "]", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "if", "downsample_first", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "downsample", "=", "downsample", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "num_blocks", ")", ":", "\n", "                ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "dilation", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "", "else", ":", "# downsample_first=False is for HourglassModule", "\n", "            ", "for", "_", "in", "range", "(", "num_blocks", "-", "1", ")", ":", "\n", "                ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "inplanes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "dilation", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "downsample", "=", "downsample", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "", "super", "(", "SOTResLayer", ",", "self", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.__init__": [[18, 21], ["torch.Module.__init__", "mmtrack.utils.get_root_logger"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger"], ["        ", "super", "(", "BaseMultiObjectTracker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "\n", "", "def", "init_module", "(", "self", ",", "module_name", ",", "pretrain", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.init_module": [[22, 38], ["mmcv.utils.print_log", "mmcv.runner.load_checkpoint", "getattr().init_weights", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["        ", "\"\"\"Initialize the weights of a sub-module.\n\n        Args:\n            module (nn.Module): A sub-module of the model.\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"", "\n", "module", "=", "getattr", "(", "self", ",", "module_name", ")", "\n", "if", "pretrain", "is", "not", "None", ":", "\n", "            ", "print_log", "(", "\n", "f'load {module_name} from: {pretrain}'", ",", "logger", "=", "self", ".", "logger", ")", "\n", "checkpoint", "=", "load_checkpoint", "(", "\n", "module", ",", "pretrain", ",", "strict", "=", "False", ",", "logger", "=", "self", ".", "logger", ")", "\n", "if", "'meta'", "in", "checkpoint", "and", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "                ", "module", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "", "", "else", ":", "\n", "            ", "module", ".", "init_weights", "(", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.freeze_module": [[39, 53], ["isinstance", "getattr", "getattr.eval", "getattr.parameters", "TypeError", "isinstance", "isinstance"], "methods", ["None"], ["\n", "", "", "def", "freeze_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Freeze module during training.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "str", ")", ":", "\n", "            ", "modules", "=", "[", "module", "]", "\n", "", "else", ":", "\n", "            ", "if", "not", "(", "isinstance", "(", "module", ",", "list", ")", "or", "isinstance", "(", "module", ",", "tuple", ")", ")", ":", "\n", "                ", "raise", "TypeError", "(", "'module must be a str or a list.'", ")", "\n", "", "else", ":", "\n", "                ", "modules", "=", "module", "\n", "", "", "for", "module", "in", "modules", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "module", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.with_detector": [[54, 58], ["hasattr"], "methods", ["None"], ["\n", "", "", "", "@", "property", "\n", "def", "with_detector", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a detector.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'detector'", ")", "and", "self", ".", "detector", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.with_motion": [[59, 63], ["hasattr"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "with_reid", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a reid model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.with_aggregator": [[64, 68], ["hasattr"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "with_motion", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a motion model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.forward_train": [[69, 83], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "with_track_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a track_head.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'track_head'", ")", "and", "self", ".", "track_head", "is", "not", "None", "\n", "\n", "", "@", "property", "\n", "def", "with_tracker", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a tracker.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'tracker'", ")", "and", "self", ".", "tracker", "is", "not", "None", "\n", "\n", "", "@", "abstractmethod", "\n", "def", "forward_train", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.simple_test": [[84, 87], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.aug_test": [[88, 91], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.forward_test": [[92, 136], ["isinstance", "isinstance", "isinstance", "len", "len", "ValueError", "base.BaseVideoDetector.simple_test", "base.BaseVideoDetector.aug_test", "isinstance", "TypeError", "isinstance", "TypeError", "imgs[].size", "imgs[].size", "len", "len", "type"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.aug_test"], ["\n", "pass", "\n", "\n", "", "@", "abstractmethod", "\n", "def", "simple_test", "(", "self", ",", "img", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with a single scale.\"\"\"", "\n", "pass", "\n", "\n", "", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "pass", "\n", "\n", "", "def", "forward_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            imgs (List[Tensor]): the outer list indicates test-time\n                augmentations and inner Tensor should have a shape NxCxHxW,\n                which contains all images in the batch.\n            img_metas (List[List[dict]]): the outer list indicates test-time\n                augs (multiscale, flip, etc.) and the inner list indicates\n                images in a batch.\n        \"\"\"", "\n", "for", "var", ",", "name", "in", "[", "(", "imgs", ",", "'imgs'", ")", ",", "(", "img_metas", ",", "'img_metas'", ")", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f'{name} must be a list, but got {type(var)}'", ")", "\n", "\n", "", "", "num_augs", "=", "len", "(", "imgs", ")", "\n", "if", "num_augs", "!=", "len", "(", "img_metas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'num of augmentations ({len(imgs)}) '", "\n", "f'!= num of image meta ({len(img_metas)})'", ")", "\n", "\n", "", "if", "num_augs", "==", "1", ":", "\n", "# proposals (List[List[Tensor]]): the outer list indicates", "\n", "# test-time augs (multiscale, flip, etc.) and the inner list", "\n", "# indicates images in a batch.", "\n", "# The Tensor should have a shape Px4, where P is the number of", "\n", "# proposals.", "\n", "            ", "if", "'proposals'", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "'proposals'", "]", "=", "kwargs", "[", "'proposals'", "]", "[", "0", "]", "\n", "", "return", "self", ".", "simple_test", "(", "imgs", "[", "0", "]", ",", "img_metas", "[", "0", "]", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "assert", "imgs", "[", "0", "]", ".", "size", "(", "0", ")", "==", "1", ",", "'aug test does not support '", "'inference with batch size '", "f'{imgs[0].size(0)}'", "\n", "# TODO: support test augmentation for predefined proposals", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.forward": [[137, 152], ["mmcv.runner.auto_fp16", "base.BaseVideoDetector.forward_train", "base.BaseVideoDetector.forward_test"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward_test"], ["assert", "'proposals'", "not", "in", "kwargs", "\n", "return", "self", ".", "aug_test", "(", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n", "", "", "@", "auto_fp16", "(", "apply_to", "=", "(", "'img'", ",", ")", ")", "\n", "def", "forward", "(", "self", ",", "img", ",", "img_metas", ",", "return_loss", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calls either :func:`forward_train` or :func:`forward_test` depending\n        on whether ``return_loss`` is ``True``.\n\n        Note this setting will change the expected inputs. When\n        ``return_loss=True``, img and img_meta are single-nested (i.e. Tensor\n        and List[dict]), and when ``resturn_loss=False``, img and img_meta\n        should be double nested (i.e.  List[Tensor], List[List[dict]]), with\n        the outer list indicating test time augmentations.\n        \"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector._parse_losses": [[153, 187], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["", "else", ":", "\n", "            ", "return", "self", ".", "forward_test", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n", "", "", "def", "_parse_losses", "(", "self", ",", "losses", ")", ":", "\n", "        ", "\"\"\"Parse the raw outputs (losses) of the network.\n\n        Args:\n            losses (dict): Raw output of the network, which usually contain\n                losses and other necessary infomation.\n\n        Returns:\n            tuple[Tensor, dict]: (loss, log_vars), loss is the loss tensor\n            which may be a weighted sum of all losses, log_vars contains\n            all the variables to be sent to the logger.\n        \"\"\"", "\n", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "f'{loss_name} is not a tensor or list of tensors'", ")", "\n", "\n", "", "", "loss", "=", "sum", "(", "_value", "for", "_key", ",", "_value", "in", "log_vars", ".", "items", "(", ")", "\n", "if", "'loss'", "in", "_key", ")", "\n", "\n", "log_vars", "[", "'loss'", "]", "=", "loss", "\n", "for", "loss_name", ",", "loss_value", "in", "log_vars", ".", "items", "(", ")", ":", "\n", "# reduce loss when distributed training", "\n", "            ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "loss_value", "=", "loss_value", ".", "data", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "loss_value", ".", "div_", "(", "dist", ".", "get_world_size", "(", ")", ")", ")", "\n", "", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "item", "(", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.train_step": [[188, 222], ["base.BaseVideoDetector.", "base.BaseVideoDetector._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["\n", "", "return", "loss", ",", "log_vars", "\n", "\n", "", "def", "train_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during training.\n\n        This method defines an iteration step during training, except for the\n        back propagation and optimizer updating, which are done in an optimizer\n        hook. Note that in some complicated cases or models, the whole process\n        including back propagation and optimizer updating is also defined in\n        this method, such as GAN.\n\n        Args:\n            data (dict): The output of dataloader.\n            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n                runner is passed to ``train_step()``. This argument is unused\n                and reserved.\n\n        Returns:\n            dict: It should contain at least 3 keys: ``loss``, ``log_vars``,\n            ``num_samples``.\n\n            - ``loss`` is a tensor for back propagation, which can be a\n            weighted sum of multiple losses.\n            - ``log_vars`` contains all the variables to be sent to the\n            logger.\n            - ``num_samples`` indicates the batch size (when the model is\n            DDP, it means the batch size on each GPU), which is used for\n            averaging the logs.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "log_vars", "=", "log_vars", ",", "num_samples", "=", "len", "(", "data", "[", "'img_metas'", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.val_step": [[223, 237], ["base.BaseVideoDetector.", "base.BaseVideoDetector._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["\n", "return", "outputs", "\n", "\n", "", "def", "val_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during validation.\n\n        This method shares the same signature as :func:`train_step`, but used\n        during val epochs. Note that the evaluation after training epochs is\n        not implemented with this method, but an evaluation hook.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "log_vars", "=", "log_vars", ",", "num_samples", "=", "len", "(", "data", "[", "'img_metas'", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.base.BaseVideoDetector.show_result": [[238, 322], ["mmcv.imread", "img.copy.copy.copy", "isinstance", "result.get", "result.get", "isinstance", "numpy.vstack", "numpy.concatenate", "mmcv.imshow_det_bboxes", "numpy.full", "mmcv.concat_list", "numpy.random.seed", "enumerate", "len", "numpy.where", "numpy.random.randint", "int", "segms[].astype", "range", "max"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["\n", "return", "outputs", "\n", "\n", "", "def", "show_result", "(", "self", ",", "\n", "img", ",", "\n", "result", ",", "\n", "thickness", "=", "1", ",", "\n", "font_scale", "=", "0.5", ",", "\n", "show", "=", "False", ",", "\n", "out_file", "=", "None", ",", "\n", "backend", "=", "'cv2'", ")", ":", "\n", "        ", "\"\"\"Visualize tracking results.\n\n        Args:\n            img (str | ndarray): Filename of loaded image.\n            result (list[ndarray]): Tracking results.\n            thickness (int, optional): Thickness of lines. Defaults to 1.\n            font_scale (float, optional): Font scales of texts. Defaults\n                to 0.5.\n            show (bool, optional): Whether show the visualizations on the\n                fly. Defaults to False.\n            out_file (str | None, optional): Output filename. Defaults to None.\n            backend (str, optional): Backend to draw the bounding boxes,\n                options are `cv2` and `plt`. Defaults to 'cv2'.\n\n        Returns:\n            ndarray: Visualized image.\n        \"\"\"", "\n", "bboxes", ",", "labels", ",", "ids", "=", "restore_result", "(", "result", ",", "return_ids", "=", "True", ")", "\n", "img", "=", "imshow_tracks", "(", "\n", "img", ",", "\n", "bboxes", ",", "\n", "labels", ",", "\n", "ids", ",", "\n", "classes", "=", "self", ".", "CLASSES", ",", "\n", "thickness", "=", "thickness", ",", "\n", "font_scale", "=", "font_scale", ",", "\n", "show", "=", "show", ",", "\n", "out_file", "=", "out_file", ",", "\n", "backend", "=", "backend", ")", "\n", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.__init__": [[18, 34], ["base.BaseVideoDetector.__init__", "builder.build_detector", "builder.build_motion", "dff.DFF.init_weights", "dff.DFF.freeze_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_motion", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.freeze_module"], ["def", "__init__", "(", "self", ",", "\n", "detector", ",", "\n", "motion", ",", "\n", "pretrains", "=", "None", ",", "\n", "frozen_modules", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "DFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "detector", "=", "build_detector", "(", "detector", ")", "\n", "self", ".", "motion", "=", "build_motion", "(", "motion", ")", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "if", "frozen_modules", "is", "not", "None", ":", "\n", "            ", "self", ".", "freeze_module", "(", "frozen_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.init_weights": [[35, 48], ["isinstance", "dict", "dict.get", "dff.DFF.init_module", "dff.DFF.init_module", "dict.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of modules in video object detector.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_detector", "and", "pretrain", ".", "get", "(", "'detector'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'detector'", ",", "pretrain", "[", "'detector'", "]", ")", "\n", "", "if", "self", ".", "with_motion", ":", "\n", "            ", "self", ".", "init_module", "(", "'motion'", ",", "pretrain", ".", "get", "(", "'motion'", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.forward_train": [[49, 183], ["torch.cat", "dff.DFF.motion", "dff.DFF.detector.extract_feat", "range", "dict", "hasattr", "len", "len", "mmtrack.core.motion.flow_warp_feats", "x.append", "dff.DFF.detector.roi_head.forward_train", "dict.update", "hasattr", "dff.DFF.detector.train_cfg.get", "dff.DFF.detector.rpn_head.forward_train", "dict.update", "dff.DFF.detector.bbox_head.forward_train", "dict.update", "TypeError"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "", "def", "forward_train", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", ",", "\n", "ref_img", ",", "\n", "ref_img_metas", ",", "\n", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", ",", "\n", "gt_instance_ids", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_masks", "=", "None", ",", "\n", "proposals", "=", "None", ",", "\n", "ref_gt_instance_ids", "=", "None", ",", "\n", "ref_gt_bboxes_ignore", "=", "None", ",", "\n", "ref_gt_masks", "=", "None", ",", "\n", "ref_proposals", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with\n                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.\n\n            gt_labels (list[Tensor]): class indices corresponding to each box.\n\n            ref_img (Tensor): of shape (N, 1, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n                1 denotes there is only one reference image for each input\n                image.\n\n            ref_img_metas (list[list[dict]]): The first list only has one\n                element. The second list contains reference image information\n                dict where each dict has: 'img_shape', 'scale_factor', 'flip',\n                and may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_gt_bboxes (list[Tensor]): The list only has one Tensor. The\n                Tensor contains ground truth bboxes for each reference image\n                with shape (num_all_ref_gts, 5) in\n                [ref_img_id, tl_x, tl_y, br_x, br_y] format. The ref_img_id\n                start from 0, and denotes the id of reference image for each\n                key image.\n\n            ref_gt_labels (list[Tensor]): The list only has one Tensor. The\n                Tensor contains class indices corresponding to each reference\n                box with shape (num_all_ref_gts, 2) in\n                [ref_img_id, class_indice].\n\n            gt_instance_ids (None | list[Tensor]): specify the instance id for\n                each ground truth bbox.\n\n            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes can be ignored when computing the loss.\n\n            gt_masks (None | Tensor) : true segmentation masks for each box\n                used if the architecture supports a segmentation task.\n\n            proposals (None | Tensor) : override rpn proposals with custom\n                proposals. Use when `with_rpn` is False.\n\n            ref_gt_instance_ids (None | list[Tensor]): specify the instance id\n                for each ground truth bboxes of reference images.\n\n            ref_gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes of reference images can be ignored when computing the\n                loss.\n\n            ref_gt_masks (None | Tensor) : True segmentation masks for each\n                box of reference image used if the architecture supports a\n                segmentation task.\n\n            ref_proposals (None | Tensor) : override rpn proposals with custom\n                proposals of reference images. Use when `with_rpn` is False.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "assert", "len", "(", "img", ")", "==", "1", ",", "'Dff video detectors only support 1 batch size per gpu for now.'", "\n", "is_video_data", "=", "img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "\n", "\n", "flow_img", "=", "torch", ".", "cat", "(", "(", "img", ",", "ref_img", "[", ":", ",", "0", "]", ")", ",", "dim", "=", "1", ")", "\n", "flow", "=", "self", ".", "motion", "(", "flow_img", ",", "img_metas", ")", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", ":", ",", "0", "]", ")", "\n", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "            ", "x_single", "=", "flow_warp_feats", "(", "ref_x", "[", "i", "]", ",", "flow", ")", "\n", "if", "not", "is_video_data", ":", "\n", "                ", "x_single", "=", "0", "*", "x_single", "+", "ref_x", "[", "i", "]", "\n", "", "x", ".", "append", "(", "x_single", ")", "\n", "\n", "", "losses", "=", "dict", "(", ")", "\n", "\n", "# Two stage detector", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "# RPN forward and loss", "\n", "            ", "if", "self", ".", "detector", ".", "with_rpn", ":", "\n", "                ", "proposal_cfg", "=", "self", ".", "detector", ".", "train_cfg", ".", "get", "(", "\n", "'rpn_proposal'", ",", "self", ".", "detector", ".", "test_cfg", ".", "rpn", ")", "\n", "rpn_losses", ",", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "forward_train", "(", "\n", "x", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "proposal_cfg", "=", "proposal_cfg", ")", "\n", "losses", ".", "update", "(", "rpn_losses", ")", "\n", "", "else", ":", "\n", "                ", "proposal_list", "=", "proposals", "\n", "\n", "", "roi_losses", "=", "self", ".", "detector", ".", "roi_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "proposal_list", ",", "gt_bboxes", ",", "gt_labels", ",", "\n", "gt_bboxes_ignore", ",", "gt_masks", ",", "**", "kwargs", ")", "\n", "losses", ".", "update", "(", "roi_losses", ")", "\n", "# Single stage detector", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "bbox_losses", "=", "self", ".", "detector", ".", "bbox_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_bboxes", ",", "gt_labels", ",", "gt_bboxes_ignore", ")", "\n", "losses", ".", "update", "(", "bbox_losses", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.extract_feats": [[184, 218], ["dff.DFF.test_cfg.get", "img_metas[].get", "addict.Dict", "dff.DFF.detector.extract_feat", "torch.cat", "dff.DFF.motion", "range", "len", "mmtrack.core.motion.flow_warp_feats", "dff.DFF.append"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats"], ["", "def", "extract_feats", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Extract features for `img` during testing.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n        Returns:\n            list[Tensor]: Multi level feature maps of `img`.\n        \"\"\"", "\n", "key_frame_interval", "=", "self", ".", "test_cfg", ".", "get", "(", "'key_frame_interval'", ",", "10", ")", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "assert", "frame_id", ">=", "0", "\n", "is_key_frame", "=", "False", "if", "frame_id", "%", "key_frame_interval", "else", "True", "\n", "\n", "if", "is_key_frame", ":", "\n", "            ", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "img", "=", "img", "\n", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "self", ".", "memo", ".", "feats", "=", "x", "\n", "", "else", ":", "\n", "            ", "flow_img", "=", "torch", ".", "cat", "(", "(", "img", ",", "self", ".", "memo", ".", "img", ")", ",", "dim", "=", "1", ")", "\n", "flow", "=", "self", ".", "motion", "(", "flow_img", ",", "img_metas", ")", "\n", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "memo", ".", "feats", ")", ")", ":", "\n", "                ", "x_single", "=", "flow_warp_feats", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", ",", "flow", ")", "\n", "x", ".", "append", "(", "x_single", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.simple_test": [[219, 275], ["dff.DFF.extract_feats", "hasattr", "dict", "dff.DFF.detector.roi_head.simple_test", "hasattr", "len", "dff.DFF.detector.rpn_head.simple_test_rpn", "dff.DFF.bbox_head", "dff.DFF.bbox_head.get_bboxes", "torch.onnx.is_in_onnx_export", "TypeError", "mmdet.core.bbox2result"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.extract_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_metas", ",", "proposals", "=", "None", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            proposals (None | Tensor): Override rpn proposals with custom\n                proposals. Use when `with_rpn` is False. Defaults to None.\n\n            rescale (bool): If False, then returned bboxes and masks will fit\n                the scale of img, otherwise, returned bboxes and masks\n                will fit the scale of original image shape. Defaults to False.\n\n        Returns:\n            dict[str : list(ndarray)]: The detection results.\n        \"\"\"", "\n", "x", "=", "self", ".", "extract_feats", "(", "img", ",", "img_metas", ")", "\n", "\n", "# Two stage detector", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "            ", "if", "proposals", "is", "None", ":", "\n", "                ", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "x", ",", "img_metas", ")", "\n", "", "else", ":", "\n", "                ", "proposal_list", "=", "proposals", "\n", "\n", "", "outs", "=", "self", ".", "detector", ".", "roi_head", ".", "simple_test", "(", "\n", "x", ",", "proposal_list", ",", "img_metas", ",", "rescale", "=", "rescale", ")", "\n", "# Single stage detector", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "outs", "=", "self", ".", "bbox_head", "(", "x", ")", "\n", "bbox_list", "=", "self", ".", "bbox_head", ".", "get_bboxes", "(", "\n", "*", "outs", ",", "img_metas", ",", "rescale", "=", "rescale", ")", "\n", "# skip post-processing when exporting to ONNX", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "                ", "return", "bbox_list", "\n", "\n", "", "outs", "=", "[", "\n", "bbox2result", "(", "det_bboxes", ",", "det_labels", ",", "self", ".", "bbox_head", ".", "num_classes", ")", "\n", "for", "det_bboxes", ",", "det_labels", "in", "bbox_list", "\n", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "results", "=", "dict", "(", ")", "\n", "results", "[", "'bbox_results'", "]", "=", "outs", "[", "0", "]", "\n", "if", "len", "(", "outs", ")", "==", "2", ":", "\n", "            ", "results", "[", "'segm_results'", "]", "=", "outs", "[", "1", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.dff.DFF.aug_test": [[276, 279], ["None"], "methods", ["None"], ["", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.__init__": [[16, 32], ["base.BaseVideoDetector.__init__", "builder.build_detector", "hasattr", "selsa.SELSA.init_weights", "selsa.SELSA.freeze_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.freeze_module"], ["def", "__init__", "(", "self", ",", "\n", "detector", ",", "\n", "pretrains", "=", "None", ",", "\n", "frozen_modules", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "SELSA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "detector", "=", "build_detector", "(", "detector", ")", "\n", "assert", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ",", "'selsa video detector only supports two stage detector'", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "if", "frozen_modules", "is", "not", "None", ":", "\n", "            ", "self", ".", "freeze_module", "(", "frozen_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.init_weights": [[33, 46], ["isinstance", "dict", "dict.get", "selsa.SELSA.init_module", "selsa.SELSA.init_module", "dict.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of modules in video object detector.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_detector", "and", "pretrain", ".", "get", "(", "'detector'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'detector'", ",", "pretrain", "[", "'detector'", "]", ")", "\n", "", "if", "self", ".", "with_motion", ":", "\n", "            ", "self", ".", "init_module", "(", "'motion'", ",", "pretrain", ".", "get", "(", "'motion'", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.forward_train": [[47, 171], ["torch.cat", "selsa.SELSA.detector.extract_feat", "range", "dict", "selsa.SELSA.detector.roi_head.forward_train", "dict.update", "len", "len", "x.append", "ref_x.append", "selsa.SELSA.detector.train_cfg.get", "selsa.SELSA.detector.rpn_head.forward_train", "dict.update", "selsa.SELSA.detector.rpn_head.simple_test_rpn"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "", "def", "forward_train", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", ",", "\n", "ref_img", ",", "\n", "ref_img_metas", ",", "\n", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", ",", "\n", "gt_instance_ids", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_masks", "=", "None", ",", "\n", "proposals", "=", "None", ",", "\n", "ref_gt_instance_ids", "=", "None", ",", "\n", "ref_gt_bboxes_ignore", "=", "None", ",", "\n", "ref_gt_masks", "=", "None", ",", "\n", "ref_proposals", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with\n                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.\n\n            gt_labels (list[Tensor]): class indices corresponding to each box.\n\n            ref_img (Tensor): of shape (N, 2, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n                2 denotes there is two reference images for each input image.\n\n            ref_img_metas (list[list[dict]]): The first list only has one\n                element. The second list contains reference image information\n                dict where each dict has: 'img_shape', 'scale_factor', 'flip',\n                and may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_gt_bboxes (list[Tensor]): The list only has one Tensor. The\n                Tensor contains ground truth bboxes for each reference image\n                with shape (num_all_ref_gts, 5) in\n                [ref_img_id, tl_x, tl_y, br_x, br_y] format. The ref_img_id\n                start from 0, and denotes the id of reference image for each\n                key image.\n\n            ref_gt_labels (list[Tensor]): The list only has one Tensor. The\n                Tensor contains class indices corresponding to each reference\n                box with shape (num_all_ref_gts, 2) in\n                [ref_img_id, class_indice].\n\n            gt_instance_ids (None | list[Tensor]): specify the instance id for\n                each ground truth bbox.\n\n            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes can be ignored when computing the loss.\n\n            gt_masks (None | Tensor) : true segmentation masks for each box\n                used if the architecture supports a segmentation task.\n\n            proposals (None | Tensor) : override rpn proposals with custom\n                proposals. Use when `with_rpn` is False.\n\n            ref_gt_instance_ids (None | list[Tensor]): specify the instance id\n                for each ground truth bboxes of reference images.\n\n            ref_gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes of reference images can be ignored when computing the\n                loss.\n\n            ref_gt_masks (None | Tensor) : True segmentation masks for each\n                box of reference image used if the architecture supports a\n                segmentation task.\n\n            ref_proposals (None | Tensor) : override rpn proposals with custom\n                proposals of reference images. Use when `with_rpn` is False.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "assert", "len", "(", "img", ")", "==", "1", ",", "'selsa video detector only supports 1 batch size per gpu for now.'", "\n", "\n", "all_imgs", "=", "torch", ".", "cat", "(", "(", "img", ",", "ref_img", "[", "0", "]", ")", ",", "dim", "=", "0", ")", "\n", "all_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "all_imgs", ")", "\n", "x", "=", "[", "]", "\n", "ref_x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "all_x", ")", ")", ":", "\n", "            ", "x", ".", "append", "(", "all_x", "[", "i", "]", "[", "[", "0", "]", "]", ")", "\n", "ref_x", ".", "append", "(", "all_x", "[", "i", "]", "[", "1", ":", "]", ")", "\n", "\n", "", "losses", "=", "dict", "(", ")", "\n", "\n", "# RPN forward and loss", "\n", "if", "self", ".", "detector", ".", "with_rpn", ":", "\n", "            ", "proposal_cfg", "=", "self", ".", "detector", ".", "train_cfg", ".", "get", "(", "\n", "'rpn_proposal'", ",", "self", ".", "detector", ".", "test_cfg", ".", "rpn", ")", "\n", "rpn_losses", ",", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "forward_train", "(", "\n", "x", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "proposal_cfg", "=", "proposal_cfg", ")", "\n", "losses", ".", "update", "(", "rpn_losses", ")", "\n", "\n", "ref_proposals_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "ref_x", ",", "ref_img_metas", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "proposal_list", "=", "proposals", "\n", "ref_proposals_list", "=", "ref_proposals", "\n", "\n", "", "roi_losses", "=", "self", ".", "detector", ".", "roi_head", ".", "forward_train", "(", "\n", "x", ",", "ref_x", ",", "img_metas", ",", "proposal_list", ",", "ref_proposals_list", ",", "gt_bboxes", ",", "\n", "gt_labels", ",", "gt_bboxes_ignore", ",", "gt_masks", ",", "**", "kwargs", ")", "\n", "losses", ".", "update", "(", "roi_losses", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.extract_feats": [[172, 261], ["img_metas[].get", "img_metas[].get", "img_metas[].get", "selsa.SELSA.detector.extract_feat", "selsa.SELSA.memo.feats.copy", "range", "selsa.SELSA.memo.img_metas.copy", "selsa.SELSA.extend", "selsa.SELSA.memo.feats.copy", "range", "selsa.SELSA.memo.img_metas.copy", "addict.Dict", "selsa.SELSA.detector.extract_feat", "range", "len", "torch.cat", "addict.Dict", "selsa.SELSA.detector.extract_feat", "range", "len", "len", "selsa.SELSA.memo.feats.append", "len", "selsa.SELSA.memo.feats.append", "selsa.SELSA.append", "selsa.SELSA.detector.extract_feat", "range", "selsa.SELSA.memo.img_metas.extend", "selsa.SELSA.detector.extract_feat", "len", "selsa.SELSA.append", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "extract_feats", "(", "self", ",", "img", ",", "img_metas", ",", "ref_img", ",", "ref_img_metas", ")", ":", "\n", "        ", "\"\"\"Extract features for `img` during testing.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_img (Tensor | None): of shape (1, N, C, H, W) encoding input\n                reference images. Typically these should be mean centered and\n                std scaled. N denotes the number of reference images. There\n                may be no reference images in some cases.\n\n            ref_img_metas (list[list[dict]] | None): The first list only has\n                one element. The second list contains image information dict\n                where each dict has: 'img_shape', 'scale_factor', 'flip', and\n                may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`. There\n                may be no reference images in some cases.\n\n        Returns:\n            tuple(x, img_metas, ref_x, ref_img_metas): x is the multi level\n                feature maps of `img`, ref_x is the multi level feature maps\n                of `ref_img`.\n        \"\"\"", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "assert", "frame_id", ">=", "0", "\n", "num_left_ref_imgs", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'num_left_ref_imgs'", ",", "-", "1", ")", "\n", "frame_stride", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_stride'", ",", "-", "1", ")", "\n", "\n", "# test with adaptive stride", "\n", "if", "frame_stride", "<", "1", ":", "\n", "            ", "if", "frame_id", "==", "0", ":", "\n", "                ", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "img_metas", "=", "ref_img_metas", "[", "0", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "# 'tuple' object (e.g. the output of FPN) does not support", "\n", "# item assignment", "\n", "self", ".", "memo", ".", "feats", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", ".", "append", "(", "ref_x", "[", "i", "]", ")", "\n", "\n", "", "", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "ref_x", "=", "self", ".", "memo", ".", "feats", ".", "copy", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", ":", "\n", "                ", "ref_x", "[", "i", "]", "=", "torch", ".", "cat", "(", "(", "ref_x", "[", "i", "]", ",", "x", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "ref_img_metas", "=", "self", ".", "memo", ".", "img_metas", ".", "copy", "(", ")", "\n", "ref_img_metas", ".", "extend", "(", "img_metas", ")", "\n", "# test with fixed stride", "\n", "", "else", ":", "\n", "            ", "if", "frame_id", "==", "0", ":", "\n", "                ", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "img_metas", "=", "ref_img_metas", "[", "0", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "# 'tuple' object (e.g. the output of FPN) does not support", "\n", "# item assignment", "\n", "self", ".", "memo", ".", "feats", "=", "[", "]", "\n", "# the features of img is same as ref_x[i][[num_left_ref_imgs]]", "\n", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", ".", "append", "(", "ref_x", "[", "i", "]", ")", "\n", "x", ".", "append", "(", "ref_x", "[", "i", "]", "[", "[", "num_left_ref_imgs", "]", "]", ")", "\n", "", "", "elif", "frame_id", "%", "frame_stride", "==", "0", ":", "\n", "                ", "assert", "ref_img", "is", "not", "None", "\n", "x", "=", "[", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", "[", "i", "]", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", ",", "ref_x", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "[", "1", ":", "]", "\n", "x", ".", "append", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", "[", "[", "num_left_ref_imgs", "]", "]", ")", "\n", "", "self", ".", "memo", ".", "img_metas", ".", "extend", "(", "ref_img_metas", "[", "0", "]", ")", "\n", "self", ".", "memo", ".", "img_metas", "=", "self", ".", "memo", ".", "img_metas", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                ", "assert", "ref_img", "is", "None", "\n", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "\n", "", "ref_x", "=", "self", ".", "memo", ".", "feats", ".", "copy", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", ":", "\n", "                ", "ref_x", "[", "i", "]", "[", "num_left_ref_imgs", "]", "=", "x", "[", "i", "]", "\n", "", "ref_img_metas", "=", "self", ".", "memo", ".", "img_metas", ".", "copy", "(", ")", "\n", "ref_img_metas", "[", "num_left_ref_imgs", "]", "=", "img_metas", "[", "0", "]", "\n", "\n", "", "return", "x", ",", "img_metas", ",", "ref_x", ",", "ref_img_metas", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.simple_test": [[262, 336], ["selsa.SELSA.extract_feats", "selsa.SELSA.detector.roi_head.simple_test", "dict", "selsa.SELSA.detector.rpn_head.simple_test_rpn", "selsa.SELSA.detector.rpn_head.simple_test_rpn", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.extract_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test"], ["", "def", "simple_test", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "ref_img", "=", "None", ",", "\n", "ref_img_metas", "=", "None", ",", "\n", "proposals", "=", "None", ",", "\n", "ref_proposals", "=", "None", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_img (list[Tensor] | None): The list only contains one Tensor\n                of shape (1, N, C, H, W) encoding input reference images.\n                Typically these should be mean centered and std scaled. N\n                denotes the number for reference images. There may be no\n                reference images in some cases.\n\n            ref_img_metas (list[list[list[dict]]] | None): The first and\n                second list only has one element. The third list contains\n                image information dict where each dict has: 'img_shape',\n                'scale_factor', 'flip', and may also contain 'filename',\n                'ori_shape', 'pad_shape', and 'img_norm_cfg'. For details on\n                the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`. There\n                may be no reference images in some cases.\n\n            proposals (None | Tensor): Override rpn proposals with custom\n                proposals. Use when `with_rpn` is False. Defaults to None.\n\n            rescale (bool): If False, then returned bboxes and masks will fit\n                the scale of img, otherwise, returned bboxes and masks\n                will fit the scale of original image shape. Defaults to False.\n\n        Returns:\n            dict[str : list(ndarray)]: The detection results.\n        \"\"\"", "\n", "if", "ref_img", "is", "not", "None", ":", "\n", "            ", "ref_img", "=", "ref_img", "[", "0", "]", "\n", "", "if", "ref_img_metas", "is", "not", "None", ":", "\n", "            ", "ref_img_metas", "=", "ref_img_metas", "[", "0", "]", "\n", "", "x", ",", "img_metas", ",", "ref_x", ",", "ref_img_metas", "=", "self", ".", "extract_feats", "(", "\n", "img", ",", "img_metas", ",", "ref_img", ",", "ref_img_metas", ")", "\n", "\n", "if", "proposals", "is", "None", ":", "\n", "            ", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "x", ",", "img_metas", ")", "\n", "ref_proposals_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "ref_x", ",", "ref_img_metas", ")", "\n", "", "else", ":", "\n", "            ", "proposal_list", "=", "proposals", "\n", "ref_proposals_list", "=", "ref_proposals", "\n", "\n", "", "outs", "=", "self", ".", "detector", ".", "roi_head", ".", "simple_test", "(", "\n", "x", ",", "\n", "ref_x", ",", "\n", "proposal_list", ",", "\n", "ref_proposals_list", ",", "\n", "img_metas", ",", "\n", "rescale", "=", "rescale", ")", "\n", "\n", "results", "=", "dict", "(", ")", "\n", "results", "[", "'bbox_results'", "]", "=", "outs", "[", "0", "]", "\n", "if", "len", "(", "outs", ")", "==", "2", ":", "\n", "            ", "results", "[", "'segm_results'", "]", "=", "outs", "[", "1", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.selsa.SELSA.aug_test": [[337, 340], ["None"], "methods", ["None"], ["", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.__init__": [[23, 41], ["base.BaseVideoDetector.__init__", "builder.build_detector", "builder.build_motion", "builder.build_aggregator", "fgfa.FGFA.init_weights", "fgfa.FGFA.freeze_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_detector", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_motion", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_aggregator", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.freeze_module"], ["def", "__init__", "(", "self", ",", "\n", "detector", ",", "\n", "motion", ",", "\n", "aggregator", ",", "\n", "pretrains", "=", "None", ",", "\n", "frozen_modules", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "FGFA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "detector", "=", "build_detector", "(", "detector", ")", "\n", "self", ".", "motion", "=", "build_motion", "(", "motion", ")", "\n", "self", ".", "aggregator", "=", "build_aggregator", "(", "aggregator", ")", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "if", "frozen_modules", "is", "not", "None", ":", "\n", "            ", "self", ".", "freeze_module", "(", "frozen_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.init_weights": [[42, 55], ["isinstance", "dict", "dict.get", "fgfa.FGFA.init_module", "fgfa.FGFA.init_module", "dict.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of modules in video object detector.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_detector", "and", "pretrain", ".", "get", "(", "'detector'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'detector'", ",", "pretrain", "[", "'detector'", "]", ")", "\n", "", "if", "self", ".", "with_motion", ":", "\n", "            ", "self", ".", "init_module", "(", "'motion'", ",", "pretrain", ".", "get", "(", "'motion'", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.forward_train": [[56, 211], ["torch.cat", "range", "fgfa.FGFA.motion", "torch.cat", "fgfa.FGFA.detector.extract_feat", "range", "dict", "hasattr", "len", "torch.cat", "torch.cat", "len", "mmtrack.core.flow_warp_feats", "fgfa.FGFA.aggregator", "x.append", "ref_x.append", "fgfa.FGFA.detector.roi_head.forward_train", "dict.update", "hasattr", "fgfa.FGFA.detector.train_cfg.get", "fgfa.FGFA.detector.rpn_head.forward_train", "range", "dict.update", "fgfa.FGFA.detector.bbox_head.forward_train", "dict.update", "TypeError", "len", "fgfa.FGFA.detector.rpn_head.forward_train", "fgfa.combine_dicts", "combine_dicts.copy", "torch.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.combine_dicts"], ["", "", "def", "forward_train", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", ",", "\n", "ref_img", ",", "\n", "ref_img_metas", ",", "\n", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", ",", "\n", "gt_instance_ids", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_masks", "=", "None", ",", "\n", "proposals", "=", "None", ",", "\n", "ref_gt_instance_ids", "=", "None", ",", "\n", "ref_gt_bboxes_ignore", "=", "None", ",", "\n", "ref_gt_masks", "=", "None", ",", "\n", "ref_proposals", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with\n                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.\n\n            gt_labels (list[Tensor]): class indices corresponding to each box.\n\n            ref_img (Tensor): of shape (N, 2, C, H, W) encoding input images.\n                Typically these should be mean centered and std scaled.\n                2 denotes there is two reference images for each input image.\n\n            ref_img_metas (list[list[dict]]): The first list only has one\n                element. The second list contains reference image information\n                dict where each dict has: 'img_shape', 'scale_factor', 'flip',\n                and may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_gt_bboxes (list[Tensor]): The list only has one Tensor. The\n                Tensor contains ground truth bboxes for each reference image\n                with shape (num_all_ref_gts, 5) in\n                [ref_img_id, tl_x, tl_y, br_x, br_y] format. The ref_img_id\n                start from 0, and denotes the id of reference image for each\n                key image.\n\n            ref_gt_labels (list[Tensor]): The list only has one Tensor. The\n                Tensor contains class indices corresponding to each reference\n                box with shape (num_all_ref_gts, 2) in\n                [ref_img_id, class_indice].\n\n            gt_instance_ids (None | list[Tensor]): specify the instance id for\n                each ground truth bbox.\n\n            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes can be ignored when computing the loss.\n\n            gt_masks (None | Tensor) : true segmentation masks for each box\n                used if the architecture supports a segmentation task.\n\n            proposals (None | Tensor) : override rpn proposals with custom\n                proposals. Use when `with_rpn` is False.\n\n            ref_gt_instance_ids (None | list[Tensor]): specify the instance id\n                for each ground truth bboxes of reference images.\n\n            ref_gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n                boxes of reference images can be ignored when computing the\n                loss.\n\n            ref_gt_masks (None | Tensor) : True segmentation masks for each\n                box of reference image used if the architecture supports a\n                segmentation task.\n\n            ref_proposals (None | Tensor) : override rpn proposals with custom\n                proposals of reference images. Use when `with_rpn` is False.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "assert", "len", "(", "img", ")", "==", "1", ",", "'fgfa video detectors only support 1 batch size per gpu for now.'", "\n", "\n", "flow_imgs", "=", "torch", ".", "cat", "(", "(", "img", ",", "ref_img", "[", ":", ",", "0", "]", ")", ",", "dim", "=", "1", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "ref_img", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "flow_img", "=", "torch", ".", "cat", "(", "(", "img", ",", "ref_img", "[", ":", ",", "i", "]", ")", ",", "dim", "=", "1", ")", "\n", "flow_imgs", "=", "torch", ".", "cat", "(", "(", "flow_imgs", ",", "flow_img", ")", ",", "dim", "=", "0", ")", "\n", "", "flows", "=", "self", ".", "motion", "(", "flow_imgs", ",", "img_metas", ")", "\n", "\n", "all_imgs", "=", "torch", ".", "cat", "(", "(", "img", ",", "ref_img", "[", "0", "]", ")", ",", "dim", "=", "0", ")", "\n", "all_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "all_imgs", ")", "\n", "x", "=", "[", "]", "\n", "ref_x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "all_x", ")", ")", ":", "\n", "            ", "ref_x_single", "=", "flow_warp_feats", "(", "all_x", "[", "i", "]", "[", "1", ":", "]", ",", "flows", ")", "\n", "agg_x_single", "=", "self", ".", "aggregator", "(", "all_x", "[", "i", "]", "[", "[", "0", "]", "]", ",", "ref_x_single", ")", "\n", "x", ".", "append", "(", "agg_x_single", ")", "\n", "ref_x", ".", "append", "(", "ref_x_single", ")", "\n", "\n", "", "losses", "=", "dict", "(", ")", "\n", "\n", "# Two stage detector", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "# RPN forward and loss", "\n", "            ", "if", "self", ".", "detector", ".", "with_rpn", ":", "\n", "                ", "proposal_cfg", "=", "self", ".", "detector", ".", "train_cfg", ".", "get", "(", "\n", "'rpn_proposal'", ",", "self", ".", "detector", ".", "test_cfg", ".", "rpn", ")", "\n", "\n", "rpn_losses_key", ",", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "forward_train", "(", "\n", "x", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "proposal_cfg", "=", "proposal_cfg", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", "[", "0", "]", ")", ")", ":", "\n", "                    ", "ref_x_curr", "=", "[", "torch", ".", "unsqueeze", "(", "ele", "[", "i", "]", ",", "0", ")", "for", "ele", "in", "ref_x", "]", "\n", "rpn_losses_curr", ",", "proposal_list_curr", "=", "self", ".", "detector", ".", "rpn_head", ".", "forward_train", "(", "\n", "ref_x_curr", ",", "\n", "img_metas", ",", "\n", "gt_bboxes", ",", "\n", "gt_labels", "=", "None", ",", "\n", "gt_bboxes_ignore", "=", "gt_bboxes_ignore", ",", "\n", "proposal_cfg", "=", "proposal_cfg", ")", "\n", "\n", "rpn_losses", "=", "combine_dicts", "(", "rpn_losses_key", ",", "rpn_losses_curr", ")", "\n", "rpn_losses_key", "=", "rpn_losses", ".", "copy", "(", ")", "\n", "proposal_list", "=", "proposal_list", "+", "proposal_list_curr", "\n", "\n", "", "losses", ".", "update", "(", "rpn_losses", ")", "\n", "", "else", ":", "\n", "                ", "proposal_list", "=", "proposals", "\n", "\n", "", "roi_losses", "=", "self", ".", "detector", ".", "roi_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "proposal_list", ",", "gt_bboxes", ",", "gt_labels", ",", "\n", "gt_bboxes_ignore", ",", "gt_masks", ",", "**", "kwargs", ")", "\n", "losses", ".", "update", "(", "roi_losses", ")", "\n", "# Single stage detector", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "bbox_losses", "=", "self", ".", "detector", ".", "bbox_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_bboxes", ",", "gt_labels", ",", "gt_bboxes_ignore", ")", "\n", "losses", ".", "update", "(", "bbox_losses", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.extract_feats": [[212, 301], ["img_metas[].get", "img_metas[].get", "img_metas[].get", "torch.cat", "fgfa.FGFA.motion", "range", "fgfa.FGFA.detector.extract_feat", "len", "mmtrack.core.flow_warp_feats", "fgfa.FGFA.aggregator", "agg_x.append", "addict.Dict", "fgfa.FGFA.detector.extract_feat", "range", "addict.Dict", "fgfa.FGFA.detector.extract_feat", "range", "img.repeat", "torch.cat", "len", "fgfa.FGFA.memo.feats.append", "len", "fgfa.FGFA.memo.feats.append", "fgfa.FGFA.append", "fgfa.FGFA.detector.extract_feat", "range", "fgfa.FGFA.detector.extract_feat", "len", "fgfa.FGFA.append", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats"], ["", "def", "extract_feats", "(", "self", ",", "img", ",", "img_metas", ",", "ref_img", ",", "ref_img_metas", ")", ":", "\n", "        ", "\"\"\"Extract features for `img` during testing.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_img (Tensor | None): of shape (1, N, C, H, W) encoding input\n                reference images. Typically these should be mean centered and\n                std scaled. N denotes the number of reference images. There\n                may be no reference images in some cases.\n\n            ref_img_metas (list[list[dict]] | None): The first list only has\n                one element. The second list contains image information dict\n                where each dict has: 'img_shape', 'scale_factor', 'flip', and\n                may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`. There\n                may be no reference images in some cases.\n\n        Returns:\n            list[Tensor]: Multi level feature maps of `img`.\n        \"\"\"", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "assert", "frame_id", ">=", "0", "\n", "num_left_ref_imgs", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'num_left_ref_imgs'", ",", "-", "1", ")", "\n", "frame_stride", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_stride'", ",", "-", "1", ")", "\n", "\n", "# test with adaptive stride", "\n", "if", "frame_stride", "<", "1", ":", "\n", "            ", "if", "frame_id", "==", "0", ":", "\n", "                ", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "img", "=", "ref_img", "[", "0", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "# 'tuple' object (e.g. the output of FPN) does not support", "\n", "# item assignment", "\n", "self", ".", "memo", ".", "feats", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", ".", "append", "(", "ref_x", "[", "i", "]", ")", "\n", "", "", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "# test with fixed stride", "\n", "", "else", ":", "\n", "            ", "if", "frame_id", "==", "0", ":", "\n", "                ", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "img", "=", "ref_img", "[", "0", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "# 'tuple' object (e.g. the output of FPN) does not support", "\n", "# item assignment", "\n", "self", ".", "memo", ".", "feats", "=", "[", "]", "\n", "# the features of img is same as ref_x[i][[num_left_ref_imgs]]", "\n", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", ".", "append", "(", "ref_x", "[", "i", "]", ")", "\n", "x", ".", "append", "(", "ref_x", "[", "i", "]", "[", "[", "num_left_ref_imgs", "]", "]", ")", "\n", "", "", "elif", "frame_id", "%", "frame_stride", "==", "0", ":", "\n", "                ", "assert", "ref_img", "is", "not", "None", "\n", "x", "=", "[", "]", "\n", "ref_x", "=", "self", ".", "detector", ".", "extract_feat", "(", "ref_img", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ref_x", ")", ")", ":", "\n", "                    ", "self", ".", "memo", ".", "feats", "[", "i", "]", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", ",", "ref_x", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "[", "1", ":", "]", "\n", "x", ".", "append", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", "[", "[", "num_left_ref_imgs", "]", "]", ")", "\n", "", "self", ".", "memo", ".", "img", "=", "torch", ".", "cat", "(", "(", "self", ".", "memo", ".", "img", ",", "ref_img", "[", "0", "]", ")", ",", "\n", "dim", "=", "0", ")", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                ", "assert", "ref_img", "is", "None", "\n", "x", "=", "self", ".", "detector", ".", "extract_feat", "(", "img", ")", "\n", "\n", "", "", "flow_imgs", "=", "torch", ".", "cat", "(", "\n", "(", "img", ".", "repeat", "(", "self", ".", "memo", ".", "img", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", ",", "self", ".", "memo", ".", "img", ")", ",", "\n", "dim", "=", "1", ")", "\n", "flows", "=", "self", ".", "motion", "(", "flow_imgs", ",", "img_metas", ")", "\n", "\n", "agg_x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", ":", "\n", "            ", "agg_x_single", "=", "flow_warp_feats", "(", "self", ".", "memo", ".", "feats", "[", "i", "]", ",", "flows", ")", "\n", "if", "frame_stride", "<", "1", ":", "\n", "                ", "agg_x_single", "=", "torch", ".", "cat", "(", "(", "x", "[", "i", "]", ",", "agg_x_single", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "agg_x_single", "[", "num_left_ref_imgs", "]", "=", "x", "[", "i", "]", "\n", "", "agg_x_single", "=", "self", ".", "aggregator", "(", "x", "[", "i", "]", ",", "agg_x_single", ")", "\n", "agg_x", ".", "append", "(", "agg_x_single", ")", "\n", "", "return", "agg_x", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.simple_test": [[302, 383], ["fgfa.FGFA.extract_feats", "hasattr", "dict", "fgfa.FGFA.detector.roi_head.simple_test", "hasattr", "len", "fgfa.FGFA.detector.rpn_head.simple_test_rpn", "fgfa.FGFA.bbox_head", "fgfa.FGFA.bbox_head.get_bboxes", "torch.onnx.is_in_onnx_export", "TypeError", "mmdet.core.bbox2result"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.extract_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test"], ["", "def", "simple_test", "(", "self", ",", "\n", "img", ",", "\n", "img_metas", ",", "\n", "ref_img", "=", "None", ",", "\n", "ref_img_metas", "=", "None", ",", "\n", "proposals", "=", "None", ",", "\n", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n                Typically these should be mean centered and std scaled.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            ref_img (list[Tensor] | None): The list only contains one Tensor\n                of shape (1, N, C, H, W) encoding input reference images.\n                Typically these should be mean centered and std scaled. N\n                denotes the number for reference images. There may be no\n                reference images in some cases.\n\n            ref_img_metas (list[list[list[dict]]] | None): The first and\n                second list only has one element. The third list contains\n                image information dict where each dict has: 'img_shape',\n                'scale_factor', 'flip', and may also contain 'filename',\n                'ori_shape', 'pad_shape', and 'img_norm_cfg'. For details on\n                the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`. There\n                may be no reference images in some cases.\n\n            proposals (None | Tensor): Override rpn proposals with custom\n                proposals. Use when `with_rpn` is False. Defaults to None.\n\n            rescale (bool): If False, then returned bboxes and masks will fit\n                the scale of img, otherwise, returned bboxes and masks\n                will fit the scale of original image shape. Defaults to False.\n\n        Returns:\n            dict[str : list(ndarray)]: The detection results.\n        \"\"\"", "\n", "if", "ref_img", "is", "not", "None", ":", "\n", "            ", "ref_img", "=", "ref_img", "[", "0", "]", "\n", "", "if", "ref_img_metas", "is", "not", "None", ":", "\n", "            ", "ref_img_metas", "=", "ref_img_metas", "[", "0", "]", "\n", "", "x", "=", "self", ".", "extract_feats", "(", "img", ",", "img_metas", ",", "ref_img", ",", "ref_img_metas", ")", "\n", "\n", "# Two stage detector", "\n", "if", "hasattr", "(", "self", ".", "detector", ",", "'roi_head'", ")", ":", "\n", "            ", "if", "proposals", "is", "None", ":", "\n", "                ", "proposal_list", "=", "self", ".", "detector", ".", "rpn_head", ".", "simple_test_rpn", "(", "\n", "x", ",", "img_metas", ")", "\n", "", "else", ":", "\n", "                ", "proposal_list", "=", "proposals", "\n", "\n", "", "outs", "=", "self", ".", "detector", ".", "roi_head", ".", "simple_test", "(", "\n", "x", ",", "proposal_list", ",", "img_metas", ",", "rescale", "=", "rescale", ")", "\n", "# Single stage detector", "\n", "", "elif", "hasattr", "(", "self", ".", "detector", ",", "'bbox_head'", ")", ":", "\n", "            ", "outs", "=", "self", ".", "bbox_head", "(", "x", ")", "\n", "bbox_list", "=", "self", ".", "bbox_head", ".", "get_bboxes", "(", "\n", "*", "outs", ",", "img_metas", ",", "rescale", "=", "rescale", ")", "\n", "# skip post-processing when exporting to ONNX", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "                ", "return", "bbox_list", "\n", "\n", "", "outs", "=", "[", "\n", "bbox2result", "(", "det_bboxes", ",", "det_labels", ",", "self", ".", "bbox_head", ".", "num_classes", ")", "\n", "for", "det_bboxes", ",", "det_labels", "in", "bbox_list", "\n", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'detector must has roi_head or bbox_head.'", ")", "\n", "\n", "", "results", "=", "dict", "(", ")", "\n", "results", "[", "'bbox_results'", "]", "=", "outs", "[", "0", "]", "\n", "if", "len", "(", "outs", ")", "==", "2", ":", "\n", "            ", "results", "[", "'segm_results'", "]", "=", "outs", "[", "1", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.FGFA.aug_test": [[384, 387], ["None"], "methods", ["None"], ["", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.vid.fgfa.combine_dicts": [[12, 14], ["a.get", "b.get", "set().union", "set"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["def", "combine_dicts", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "{", "x", ":", "a", ".", "get", "(", "x", ",", "0", ")", "+", "b", ".", "get", "(", "x", ",", "0", ")", "for", "x", "in", "set", "(", "a", ")", ".", "union", "(", "b", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.__init__": [[33, 47], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "neg_pos_ub", "=", "-", "1", ",", "\n", "pos_margin", "=", "-", "1", ",", "\n", "neg_margin", "=", "-", "1", ",", "\n", "hard_mining", "=", "False", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "loss_weight", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "L2Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "neg_pos_ub", "=", "neg_pos_ub", "\n", "self", ".", "pos_margin", "=", "pos_margin", "\n", "self", ".", "neg_margin", "=", "neg_margin", "\n", "self", ".", "hard_mining", "=", "hard_mining", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.forward": [[48, 75], ["l2_loss.L2Loss.update_weight", "l2_loss.l2_loss"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.update_weight", "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.l2_loss"], ["", "def", "forward", "(", "self", ",", "\n", "pred", ",", "\n", "target", ",", "\n", "weight", "=", "None", ",", "\n", "avg_factor", "=", "None", ",", "\n", "reduction_override", "=", "None", ")", ":", "\n", "        ", "\"\"\"Forward function.\n\n        Args:\n            pred (torch.Tensor): The prediction.\n            target (torch.Tensor): The learning target of the prediction.\n            weight (torch.Tensor, optional): The weight of loss for each\n                prediction. Defaults to None.\n            avg_factor (int, optional): Average factor that is used to average\n                the loss. Defaults to None.\n            reduction_override (str, optional): The reduction method used to\n                override the original reduction method of the loss.\n                Defaults to None.\n        \"\"\"", "\n", "assert", "reduction_override", "in", "(", "None", ",", "'none'", ",", "'mean'", ",", "'sum'", ")", "\n", "reduction", "=", "(", "\n", "reduction_override", "if", "reduction_override", "else", "self", ".", "reduction", ")", "\n", "pred", ",", "weight", ",", "avg_factor", "=", "self", ".", "update_weight", "(", "pred", ",", "target", ",", "weight", ",", "\n", "avg_factor", ")", "\n", "loss_bbox", "=", "self", ".", "loss_weight", "*", "l2_loss", "(", "\n", "pred", ",", "target", ",", "weight", ",", "reduction", "=", "reduction", ",", "avg_factor", "=", "avg_factor", ")", "\n", "return", "loss_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.update_weight": [[76, 115], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "int", "int", "target.new_ones", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "neg_inds.new_zeros().bool", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "target.size", "[].detach", "l2_loss.L2Loss.random_choice", "neg_inds.new_zeros", "neg_inds.size", "l2_loss.l2_loss", "[].detach.topk"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.random_choice", "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.l2_loss"], ["", "def", "update_weight", "(", "self", ",", "pred", ",", "target", ",", "weight", ",", "avg_factor", ")", ":", "\n", "        ", "\"\"\"Update the weight according to targets.\"\"\"", "\n", "if", "weight", "is", "None", ":", "\n", "            ", "weight", "=", "target", ".", "new_ones", "(", "target", ".", "size", "(", ")", ")", "\n", "\n", "", "invalid_inds", "=", "weight", "<=", "0", "\n", "target", "[", "invalid_inds", "]", "=", "-", "1", "\n", "pos_inds", "=", "target", "==", "1", "\n", "neg_inds", "=", "target", "==", "0", "\n", "\n", "if", "self", ".", "pos_margin", ">", "0", ":", "\n", "            ", "pred", "[", "pos_inds", "]", "-=", "self", ".", "pos_margin", "\n", "", "if", "self", ".", "neg_margin", ">", "0", ":", "\n", "            ", "pred", "[", "neg_inds", "]", "-=", "self", ".", "neg_margin", "\n", "", "pred", "=", "torch", ".", "clamp", "(", "pred", ",", "min", "=", "0", ",", "max", "=", "1", ")", "\n", "\n", "num_pos", "=", "int", "(", "(", "target", "==", "1", ")", ".", "sum", "(", ")", ")", "\n", "num_neg", "=", "int", "(", "(", "target", "==", "0", ")", ".", "sum", "(", ")", ")", "\n", "if", "self", ".", "neg_pos_ub", ">", "0", "and", "num_neg", "/", "(", "num_pos", "+", "\n", "1e-6", ")", ">", "self", ".", "neg_pos_ub", ":", "\n", "            ", "num_neg", "=", "num_pos", "*", "self", ".", "neg_pos_ub", "\n", "neg_idx", "=", "torch", ".", "nonzero", "(", "target", "==", "0", ",", "as_tuple", "=", "False", ")", "\n", "\n", "if", "self", ".", "hard_mining", ":", "\n", "                ", "costs", "=", "l2_loss", "(", "\n", "pred", ",", "target", ",", "reduction", "=", "'none'", ")", "[", "neg_idx", "[", ":", ",", "0", "]", ",", "\n", "neg_idx", "[", ":", ",", "1", "]", "]", ".", "detach", "(", ")", "\n", "neg_idx", "=", "neg_idx", "[", "costs", ".", "topk", "(", "num_neg", ")", "[", "1", "]", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "neg_idx", "=", "self", ".", "random_choice", "(", "neg_idx", ",", "num_neg", ")", "\n", "\n", "", "new_neg_inds", "=", "neg_inds", ".", "new_zeros", "(", "neg_inds", ".", "size", "(", ")", ")", ".", "bool", "(", ")", "\n", "new_neg_inds", "[", "neg_idx", "[", ":", ",", "0", "]", ",", "neg_idx", "[", ":", ",", "1", "]", "]", "=", "True", "\n", "\n", "invalid_neg_inds", "=", "torch", ".", "logical_xor", "(", "neg_inds", ",", "new_neg_inds", ")", "\n", "weight", "[", "invalid_neg_inds", "]", "=", "0", "\n", "\n", "", "avg_factor", "=", "(", "weight", ">", "0", ")", ".", "sum", "(", ")", "\n", "return", "pred", ",", "weight", ",", "avg_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.L2Loss.random_choice": [[116, 132], ["isinstance", "numpy.arange", "numpy.random.shuffle", "len", "numpy.array", "len", "isinstance", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_choice", "(", "gallery", ",", "num", ")", ":", "\n", "        ", "\"\"\"Random select some elements from the gallery.\n\n        It seems that Pytorch's implementation is slower than numpy so we use\n        numpy to randperm the indices.\n        \"\"\"", "\n", "assert", "len", "(", "gallery", ")", ">=", "num", "\n", "if", "isinstance", "(", "gallery", ",", "list", ")", ":", "\n", "            ", "gallery", "=", "np", ".", "array", "(", "gallery", ")", "\n", "", "cands", "=", "np", ".", "arange", "(", "len", "(", "gallery", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "cands", ")", "\n", "rand_inds", "=", "cands", "[", ":", "num", "]", "\n", "if", "not", "isinstance", "(", "gallery", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rand_inds", "=", "torch", ".", "from_numpy", "(", "rand_inds", ")", ".", "long", "(", ")", ".", "to", "(", "gallery", ".", "device", ")", "\n", "", "return", "gallery", "[", "rand_inds", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.losses.l2_loss.l2_loss": [[7, 21], ["torch.abs", "torch.abs", "pred.size", "target.size", "target.numel"], "function", ["None"], ["@", "weighted_loss", "\n", "def", "l2_loss", "(", "pred", ",", "target", ")", ":", "\n", "    ", "\"\"\"L2 loss.\n\n    Args:\n        pred (torch.Tensor): The prediction.\n        target (torch.Tensor): The learning target of the prediction.\n\n    Returns:\n        torch.Tensor: Calculated loss\n    \"\"\"", "\n", "assert", "pred", ".", "size", "(", ")", "==", "target", ".", "size", "(", ")", "and", "target", ".", "numel", "(", ")", ">", "0", "\n", "loss", "=", "torch", ".", "abs", "(", "pred", "-", "target", ")", "**", "2", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.__init__": [[16, 19], ["torch.Module.__init__", "mmtrack.utils.get_root_logger"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.utils.logger.get_root_logger"], ["\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseMultiObjectTracker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module": [[20, 36], ["mmcv.utils.print_log", "mmcv.runner.load_checkpoint", "getattr().init_weights", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["\n", "", "def", "init_module", "(", "self", ",", "module_name", ",", "pretrain", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of a sub-module.\n\n        Args:\n            module (nn.Module): A sub-module of the model.\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"", "\n", "module", "=", "getattr", "(", "self", ",", "module_name", ")", "\n", "if", "pretrain", "is", "not", "None", ":", "\n", "            ", "print_log", "(", "\n", "f'load {module_name} from: {pretrain}'", ",", "logger", "=", "self", ".", "logger", ")", "\n", "checkpoint", "=", "load_checkpoint", "(", "\n", "module", ",", "pretrain", ",", "strict", "=", "False", ",", "logger", "=", "self", ".", "logger", ")", "\n", "if", "'meta'", "in", "checkpoint", "and", "'CLASSES'", "in", "checkpoint", "[", "'meta'", "]", ":", "\n", "                ", "module", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.freeze_module": [[37, 51], ["isinstance", "getattr", "getattr.eval", "getattr.parameters", "TypeError", "isinstance", "isinstance"], "methods", ["None"], ["", "", "else", ":", "\n", "            ", "module", ".", "init_weights", "(", ")", "\n", "\n", "", "", "def", "freeze_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Freeze module during training.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "str", ")", ":", "\n", "            ", "modules", "=", "[", "module", "]", "\n", "", "else", ":", "\n", "            ", "if", "not", "(", "isinstance", "(", "module", ",", "list", ")", "or", "isinstance", "(", "module", ",", "tuple", ")", ")", ":", "\n", "                ", "raise", "TypeError", "(", "'module must be a str or a list.'", ")", "\n", "", "else", ":", "\n", "                ", "modules", "=", "module", "\n", "", "", "for", "module", "in", "modules", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "module", ")", "\n", "m", ".", "eval", "(", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.with_backbone": [[52, 56], ["hasattr"], "methods", ["None"], ["for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "@", "property", "\n", "def", "with_detector", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.with_neck": [[57, 61], ["hasattr"], "methods", ["None"], ["        ", "\"\"\"bool: whether the framework has a detector.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'detector'", ")", "and", "self", ".", "detector", "is", "not", "None", "\n", "\n", "", "@", "property", "\n", "def", "with_reid", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.with_head": [[62, 66], ["hasattr"], "methods", ["None"], ["        ", "\"\"\"bool: whether the framework has a reid model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n", "\n", "", "@", "property", "\n", "def", "with_motion", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward_train": [[67, 81], ["None"], "methods", ["None"], ["        ", "\"\"\"bool: whether the framework has a motion model.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'reid'", ")", "and", "self", ".", "reid", "is", "not", "None", "\n", "\n", "", "@", "property", "\n", "def", "with_track_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a track_head.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'track_head'", ")", "and", "self", ".", "track_head", "is", "not", "None", "\n", "\n", "", "@", "property", "\n", "def", "with_tracker", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the framework has a tracker.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'tracker'", ")", "and", "self", ".", "tracker", "is", "not", "None", "\n", "\n", "", "@", "abstractmethod", "\n", "def", "forward_train", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.simple_test": [[82, 85], ["None"], "methods", ["None"], ["        "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.aug_test": [[86, 89], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward_test": [[90, 134], ["isinstance", "isinstance", "isinstance", "len", "len", "ValueError", "base.BaseSingleObjectTracker.simple_test", "base.BaseSingleObjectTracker.aug_test", "isinstance", "TypeError", "isinstance", "TypeError", "imgs[].size", "imgs[].size", "len", "len", "type"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.aug_test"], ["\n", "pass", "\n", "\n", "", "@", "abstractmethod", "\n", "def", "simple_test", "(", "self", ",", "img", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with a single scale.\"\"\"", "\n", "pass", "\n", "\n", "", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test function with test time augmentation.\"\"\"", "\n", "pass", "\n", "\n", "", "def", "forward_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            imgs (List[Tensor]): the outer list indicates test-time\n                augmentations and inner Tensor should have a shape NxCxHxW,\n                which contains all images in the batch.\n            img_metas (List[List[dict]]): the outer list indicates test-time\n                augs (multiscale, flip, etc.) and the inner list indicates\n                images in a batch.\n        \"\"\"", "\n", "for", "var", ",", "name", "in", "[", "(", "imgs", ",", "'imgs'", ")", ",", "(", "img_metas", ",", "'img_metas'", ")", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f'{name} must be a list, but got {type(var)}'", ")", "\n", "\n", "", "", "num_augs", "=", "len", "(", "imgs", ")", "\n", "if", "num_augs", "!=", "len", "(", "img_metas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'num of augmentations ({len(imgs)}) '", "\n", "f'!= num of image meta ({len(img_metas)})'", ")", "\n", "\n", "", "if", "num_augs", "==", "1", ":", "\n", "# proposals (List[List[Tensor]]): the outer list indicates", "\n", "# test-time augs (multiscale, flip, etc.) and the inner list", "\n", "# indicates images in a batch.", "\n", "# The Tensor should have a shape Px4, where P is the number of", "\n", "# proposals.", "\n", "            ", "if", "'proposals'", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "'proposals'", "]", "=", "kwargs", "[", "'proposals'", "]", "[", "0", "]", "\n", "", "return", "self", ".", "simple_test", "(", "imgs", "[", "0", "]", ",", "img_metas", "[", "0", "]", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "assert", "imgs", "[", "0", "]", ".", "size", "(", "0", ")", "==", "1", ",", "'aug test does not support '", "'inference with batch size '"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward": [[135, 150], ["mmcv.runner.auto_fp16", "base.BaseSingleObjectTracker.forward_train", "base.BaseSingleObjectTracker.forward_test"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward_test"], ["f'{imgs[0].size(0)}'", "\n", "# TODO: support test augmentation for predefined proposals", "\n", "assert", "'proposals'", "not", "in", "kwargs", "\n", "return", "self", ".", "aug_test", "(", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n", "", "", "@", "auto_fp16", "(", "apply_to", "=", "(", "'img'", ",", ")", ")", "\n", "def", "forward", "(", "self", ",", "img", ",", "img_metas", ",", "return_loss", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calls either :func:`forward_train` or :func:`forward_test` depending\n        on whether ``return_loss`` is ``True``.\n\n        Note this setting will change the expected inputs. When\n        ``return_loss=True``, img and img_meta are single-nested (i.e. Tensor\n        and List[dict]), and when ``resturn_loss=False``, img and img_meta\n        should be double nested (i.e.  List[Tensor], List[List[dict]]), with\n        the outer list indicating test time augmentations.\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses": [[151, 185], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["if", "return_loss", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "forward_test", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n", "", "", "def", "_parse_losses", "(", "self", ",", "losses", ")", ":", "\n", "        ", "\"\"\"Parse the raw outputs (losses) of the network.\n\n        Args:\n            losses (dict): Raw output of the network, which usually contain\n                losses and other necessary infomation.\n\n        Returns:\n            tuple[Tensor, dict]: (loss, log_vars), loss is the loss tensor\n            which may be a weighted sum of all losses, log_vars contains\n            all the variables to be sent to the logger.\n        \"\"\"", "\n", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "f'{loss_name} is not a tensor or list of tensors'", ")", "\n", "\n", "", "", "loss", "=", "sum", "(", "_value", "for", "_key", ",", "_value", "in", "log_vars", ".", "items", "(", ")", "\n", "if", "'loss'", "in", "_key", ")", "\n", "\n", "log_vars", "[", "'loss'", "]", "=", "loss", "\n", "for", "loss_name", ",", "loss_value", "in", "log_vars", ".", "items", "(", ")", ":", "\n", "# reduce loss when distributed training", "\n", "            ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "loss_value", "=", "loss_value", ".", "data", ".", "clone", "(", ")", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.train_step": [[186, 220], ["base.BaseSingleObjectTracker.", "base.BaseSingleObjectTracker._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["dist", ".", "all_reduce", "(", "loss_value", ".", "div_", "(", "dist", ".", "get_world_size", "(", ")", ")", ")", "\n", "", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "item", "(", ")", "\n", "\n", "", "return", "loss", ",", "log_vars", "\n", "\n", "", "def", "train_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during training.\n\n        This method defines an iteration step during training, except for the\n        back propagation and optimizer updating, which are done in an optimizer\n        hook. Note that in some complicated cases or models, the whole process\n        including back propagation and optimizer updating is also defined in\n        this method, such as GAN.\n\n        Args:\n            data (dict): The output of dataloader.\n            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n                runner is passed to ``train_step()``. This argument is unused\n                and reserved.\n\n        Returns:\n            dict: It should contain at least 3 keys: ``loss``, ``log_vars``,\n            ``num_samples``.\n\n            - ``loss`` is a tensor for back propagation, which can be a\n            weighted sum of multiple losses.\n            - ``log_vars`` contains all the variables to be sent to the\n            logger.\n            - ``num_samples`` indicates the batch size (when the model is\n            DDP, it means the batch size on each GPU), which is used for\n            averaging the logs.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.val_step": [[221, 235], ["base.BaseSingleObjectTracker.", "base.BaseSingleObjectTracker._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses"], ["outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "log_vars", "=", "log_vars", ",", "num_samples", "=", "len", "(", "data", "[", "'img_metas'", "]", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n", "", "def", "val_step", "(", "self", ",", "data", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"The iteration step during validation.\n\n        This method shares the same signature as :func:`train_step`, but used\n        during val epochs. Note that the evaluation after training epochs is\n        not implemented with this method, but an evaluation hook.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.__init__": [[20, 42], ["base.BaseSingleObjectTracker.__init__", "mmdet.models.builder.build_backbone", "head.copy.copy.copy", "head.copy.copy.update", "mmdet.models.builder.build_head", "siamrpn.SiamRPN.init_weights", "mmdet.models.builder.build_neck", "siamrpn.SiamRPN.freeze_module"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.freeze_module"], ["def", "__init__", "(", "self", ",", "\n", "pretrains", "=", "None", ",", "\n", "backbone", "=", "None", ",", "\n", "neck", "=", "None", ",", "\n", "head", "=", "None", ",", "\n", "frozen_modules", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "SiamRPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "build_backbone", "(", "backbone", ")", "\n", "if", "neck", "is", "not", "None", ":", "\n", "            ", "self", ".", "neck", "=", "build_neck", "(", "neck", ")", "\n", "", "head", "=", "head", ".", "copy", "(", ")", "\n", "head", ".", "update", "(", "train_cfg", "=", "train_cfg", ".", "rpn", ",", "test_cfg", "=", "test_cfg", ".", "rpn", ")", "\n", "self", ".", "head", "=", "build_head", "(", "head", ")", "\n", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "\n", "self", ".", "init_weights", "(", "pretrains", ")", "\n", "if", "frozen_modules", "is", "not", "None", ":", "\n", "            ", "self", ".", "freeze_module", "(", "frozen_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights": [[43, 64], ["isinstance", "dict", "dict.get", "siamrpn.SiamRPN.init_module", "siamrpn.SiamRPN.neck.modules", "siamrpn.SiamRPN.head.modules", "isinstance", "isinstance", "m.reset_parameters", "isinstance", "isinstance", "m.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.init_module"], ["", "", "def", "init_weights", "(", "self", ",", "pretrain", ")", ":", "\n", "        ", "\"\"\"Initialize the weights of modules in single object tracker.\n\n        Args:\n            pretrained (dict): Path to pre-trained weights.\n        \"\"\"", "\n", "if", "pretrain", "is", "None", ":", "\n", "            ", "pretrain", "=", "dict", "(", ")", "\n", "", "assert", "isinstance", "(", "pretrain", ",", "dict", ")", ",", "'`pretrain` must be a dict.'", "\n", "if", "self", ".", "with_backbone", "and", "pretrain", ".", "get", "(", "'backbone'", ",", "False", ")", ":", "\n", "            ", "self", ".", "init_module", "(", "'backbone'", ",", "pretrain", "[", "'backbone'", "]", ")", "\n", "\n", "", "if", "self", ".", "with_neck", ":", "\n", "            ", "for", "m", "in", "self", ".", "neck", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_ConvNd", ")", "or", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "with_head", ":", "\n", "            ", "for", "m", "in", "self", ".", "head", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_ConvNd", ")", "or", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_template": [[65, 85], ["siamrpn.SiamRPN.backbone", "range", "tuple", "siamrpn.SiamRPN.neck", "len", "z_feat_center.append", "z_feat[].size"], "methods", ["None"], ["", "", "", "", "def", "forward_template", "(", "self", ",", "z_img", ")", ":", "\n", "        ", "\"\"\"Extract the features of exemplar images.\n\n        Args:\n            z_img (Tensor): of shape (N, C, H, W) encoding input exemplar\n                images. Typically H and W equal to 127.\n\n        Returns:\n            tuple(Tensor): Multi level feature map of exemplar images.\n        \"\"\"", "\n", "z_feat", "=", "self", ".", "backbone", "(", "z_img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "z_feat", "=", "self", ".", "neck", "(", "z_feat", ")", "\n", "\n", "", "z_feat_center", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "z_feat", ")", ")", ":", "\n", "            ", "left", "=", "(", "z_feat", "[", "i", "]", ".", "size", "(", "3", ")", "-", "self", ".", "test_cfg", ".", "center_size", ")", "//", "2", "\n", "right", "=", "left", "+", "self", ".", "test_cfg", ".", "center_size", "\n", "z_feat_center", ".", "append", "(", "z_feat", "[", "i", "]", "[", ":", ",", ":", ",", "left", ":", "right", ",", "left", ":", "right", "]", ")", "\n", "", "return", "tuple", "(", "z_feat_center", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_search": [[86, 100], ["siamrpn.SiamRPN.backbone", "siamrpn.SiamRPN.neck"], "methods", ["None"], ["", "def", "forward_search", "(", "self", ",", "x_img", ")", ":", "\n", "        ", "\"\"\"Extract the features of search images.\n\n        Args:\n            x_img (Tensor): of shape (N, C, H, W) encoding input search\n                images. Typically H and W equal to 255.\n\n        Returns:\n            tuple(Tensor): Multi level feature map of search images.\n        \"\"\"", "\n", "x_feat", "=", "self", ".", "backbone", "(", "x_img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x_feat", "=", "self", ".", "neck", "(", "x_feat", ")", "\n", "", "return", "x_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.get_cropped_img": [[101, 166], ["int", "int", "int", "int", "max", "max", "max", "max", "any", "torch.nn.functional.interpolate", "img.new_zeros"], "methods", ["None"], ["", "def", "get_cropped_img", "(", "self", ",", "img", ",", "center_xy", ",", "target_size", ",", "crop_size", ",", "\n", "avg_channel", ")", ":", "\n", "        ", "\"\"\"Crop image.\n\n        Only used during testing.\n\n        This function mainly contains two steps:\n        1. Crop `img` based on center `center_xy` and size `crop_size`. If the\n        cropped image is out of boundary of `img`, use `avg_channel` to pad.\n        2. Resize the cropped image to `target_size`.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding original input\n                image.\n            center_xy (Tensor): of shape (2, ) denoting the center point for\n                cropping image.\n            target_size (int): The output size of cropped image.\n            crop_size (Tensor): The size for cropping image.\n            avg_channel (Tensor): of shape (3, ) denoting the padding values.\n\n        Returns:\n            Tensor: of shape (1, C, target_size, target_size) encoding the\n            resized cropped image.\n        \"\"\"", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "img", ".", "shape", "\n", "context_xmin", "=", "int", "(", "center_xy", "[", "0", "]", "-", "crop_size", "/", "2", ")", "\n", "context_xmax", "=", "int", "(", "center_xy", "[", "0", "]", "+", "crop_size", "/", "2", ")", "\n", "context_ymin", "=", "int", "(", "center_xy", "[", "1", "]", "-", "crop_size", "/", "2", ")", "\n", "context_ymax", "=", "int", "(", "center_xy", "[", "1", "]", "+", "crop_size", "/", "2", ")", "\n", "\n", "left_pad", "=", "max", "(", "0", ",", "-", "context_xmin", ")", "\n", "top_pad", "=", "max", "(", "0", ",", "-", "context_ymin", ")", "\n", "right_pad", "=", "max", "(", "0", ",", "context_xmax", "-", "W", ")", "\n", "bottom_pad", "=", "max", "(", "0", ",", "context_ymax", "-", "H", ")", "\n", "\n", "context_xmin", "+=", "left_pad", "\n", "context_xmax", "+=", "left_pad", "\n", "context_ymin", "+=", "top_pad", "\n", "context_ymax", "+=", "top_pad", "\n", "\n", "avg_channel", "=", "avg_channel", "[", ":", ",", "None", ",", "None", "]", "\n", "if", "any", "(", "[", "top_pad", ",", "bottom_pad", ",", "left_pad", ",", "right_pad", "]", ")", ":", "\n", "            ", "new_img", "=", "img", ".", "new_zeros", "(", "N", ",", "C", ",", "H", "+", "top_pad", "+", "bottom_pad", ",", "\n", "W", "+", "left_pad", "+", "right_pad", ")", "\n", "new_img", "[", "...", ",", "top_pad", ":", "top_pad", "+", "H", ",", "left_pad", ":", "left_pad", "+", "W", "]", "=", "img", "\n", "if", "top_pad", ":", "\n", "                ", "new_img", "[", "...", ",", ":", "top_pad", ",", "left_pad", ":", "left_pad", "+", "W", "]", "=", "avg_channel", "\n", "", "if", "bottom_pad", ":", "\n", "                ", "new_img", "[", "...", ",", "H", "+", "top_pad", ":", ",", "left_pad", ":", "left_pad", "+", "W", "]", "=", "avg_channel", "\n", "", "if", "left_pad", ":", "\n", "                ", "new_img", "[", "...", ",", ":", "left_pad", "]", "=", "avg_channel", "\n", "", "if", "right_pad", ":", "\n", "                ", "new_img", "[", "...", ",", "W", "+", "left_pad", ":", "]", "=", "avg_channel", "\n", "", "crop_img", "=", "new_img", "[", "...", ",", "context_ymin", ":", "context_ymax", "+", "1", ",", "\n", "context_xmin", ":", "context_xmax", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "crop_img", "=", "img", "[", "...", ",", "context_ymin", ":", "context_ymax", "+", "1", ",", "\n", "context_xmin", ":", "context_xmax", "+", "1", "]", "\n", "\n", "", "crop_img", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "crop_img", ",", "\n", "size", "=", "(", "target_size", ",", "target_size", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "return", "crop_img", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN._bbox_clip": [[167, 174], ["bbox[].clamp", "bbox[].clamp", "bbox[].clamp", "bbox[].clamp"], "methods", ["None"], ["", "def", "_bbox_clip", "(", "self", ",", "bbox", ",", "img_h", ",", "img_w", ")", ":", "\n", "        ", "\"\"\"Clip the bbox with [cx, cy, w, h] format.\"\"\"", "\n", "bbox", "[", "0", "]", "=", "bbox", "[", "0", "]", ".", "clamp", "(", "0.", ",", "img_w", ")", "\n", "bbox", "[", "1", "]", "=", "bbox", "[", "1", "]", ".", "clamp", "(", "0.", ",", "img_h", ")", "\n", "bbox", "[", "2", "]", "=", "bbox", "[", "2", "]", ".", "clamp", "(", "10.", ",", "img_w", ")", "\n", "bbox", "[", "3", "]", "=", "bbox", "[", "3", "]", ".", "clamp", "(", "10.", ",", "img_h", ")", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init": [[175, 200], ["torch.round", "torch.mean", "siamrpn.SiamRPN.get_cropped_img", "siamrpn.SiamRPN.forward_template", "torch.sqrt"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.get_cropped_img", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_template"], ["", "def", "init", "(", "self", ",", "img", ",", "bbox", ")", ":", "\n", "        ", "\"\"\"Initialize the single object tracker in the first frame.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding original input\n                image.\n            bbox (Tensor): The given instance bbox of first frame that need be\n                tracked in the following frames. The shape of the box is (4, )\n                with [cx, cy, w, h] format.\n\n        Returns:\n            tuple(z_feat, avg_channel): z_feat is a tuple[Tensor] that\n            contains the multi level feature maps of exemplar image,\n            avg_channel is Tensor with shape (3, ), and denotes the padding\n            values.\n        \"\"\"", "\n", "z_width", "=", "bbox", "[", "2", "]", "+", "self", ".", "test_cfg", ".", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_height", "=", "bbox", "[", "3", "]", "+", "self", ".", "test_cfg", ".", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_size", "=", "torch", ".", "round", "(", "torch", ".", "sqrt", "(", "z_width", "*", "z_height", ")", ")", "\n", "avg_channel", "=", "torch", ".", "mean", "(", "img", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ")", "\n", "z_crop", "=", "self", ".", "get_cropped_img", "(", "img", ",", "bbox", "[", "0", ":", "2", "]", ",", "\n", "self", ".", "test_cfg", ".", "exemplar_size", ",", "z_size", ",", "\n", "avg_channel", ")", "\n", "z_feat", "=", "self", ".", "forward_template", "(", "z_crop", ")", "\n", "return", "z_feat", ",", "avg_channel", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track": [[201, 238], ["torch.sqrt", "torch.round", "siamrpn.SiamRPN.get_cropped_img", "siamrpn.SiamRPN.forward_search", "siamrpn.SiamRPN.head", "siamrpn.SiamRPN.head.get_bbox", "siamrpn.SiamRPN._bbox_clip"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.get_cropped_img", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_search", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_bbox", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN._bbox_clip"], ["", "def", "track", "(", "self", ",", "img", ",", "bbox", ",", "z_feat", ",", "avg_channel", ")", ":", "\n", "        ", "\"\"\"Track the box `bbox` of previous frame to current frame `img`.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding original input\n                image.\n            bbox (Tensor): The bbox in previous frame. The shape of the box is\n                (4, ) in [cx, cy, w, h] format.\n            z_feat (tuple[Tensor]): The multi level feature maps of exemplar\n                image in the first frame.\n            avg_channel (Tensor): of shape (3, ) denoting the padding values.\n\n        Returns:\n            tuple(best_score, best_bbox): best_score is a Tensor denoting the\n            score of best_bbox, best_bbox is a Tensor of shape (4, ) in\n            [cx, cy, w, h] format, and denotes the best tracked bbox in\n            current frame.\n        \"\"\"", "\n", "z_width", "=", "bbox", "[", "2", "]", "+", "self", ".", "test_cfg", ".", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_height", "=", "bbox", "[", "3", "]", "+", "self", ".", "test_cfg", ".", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_size", "=", "torch", ".", "sqrt", "(", "z_width", "*", "z_height", ")", "\n", "\n", "x_size", "=", "torch", ".", "round", "(", "\n", "z_size", "*", "(", "self", ".", "test_cfg", ".", "search_size", "/", "self", ".", "test_cfg", ".", "exemplar_size", ")", ")", "\n", "x_crop", "=", "self", ".", "get_cropped_img", "(", "img", ",", "bbox", "[", "0", ":", "2", "]", ",", "\n", "self", ".", "test_cfg", ".", "search_size", ",", "x_size", ",", "\n", "avg_channel", ")", "\n", "\n", "x_feat", "=", "self", ".", "forward_search", "(", "x_crop", ")", "\n", "cls_score", ",", "bbox_pred", "=", "self", ".", "head", "(", "z_feat", ",", "x_feat", ")", "\n", "scale_factor", "=", "self", ".", "test_cfg", ".", "exemplar_size", "/", "z_size", "\n", "best_score", ",", "best_bbox", "=", "self", ".", "head", ".", "get_bbox", "(", "cls_score", ",", "bbox_pred", ",", "bbox", ",", "\n", "scale_factor", ")", "\n", "\n", "# clip boundary", "\n", "best_bbox", "=", "self", ".", "_bbox_clip", "(", "best_bbox", ",", "img", ".", "shape", "[", "2", "]", ",", "img", ".", "shape", "[", "3", "]", ")", "\n", "return", "best_score", ",", "best_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test": [[239, 280], ["img_metas[].get", "mmdet.core.bbox.transforms.bbox_cxcywh_to_xyxy", "dict", "mmdet.core.bbox.transforms.bbox_cxcywh_to_xyxy.cpu().numpy", "len", "addict.Dict", "mmdet.core.bbox.transforms.bbox_xyxy_to_cxcywh", "siamrpn.SiamRPN.init", "siamrpn.SiamRPN.track", "torch.round", "best_score.cpu().numpy", "mmdet.core.bbox.transforms.bbox_cxcywh_to_xyxy.cpu", "best_score.cpu"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.track"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_metas", ",", "gt_bboxes", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Test without augmentation.\n\n        Args:\n            img (Tensor): of shape (1, C, H, W) encoding input image.\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n            gt_bboxes (list[Tensor]): list of ground truth bboxes for each\n                image with shape (1, 4) in [tl_x, tl_y, br_x, br_y] format.\n\n        Returns:\n            dict[str : ndarray]: The tracking results.\n        \"\"\"", "\n", "frame_id", "=", "img_metas", "[", "0", "]", ".", "get", "(", "'frame_id'", ",", "-", "1", ")", "\n", "assert", "frame_id", ">=", "0", "\n", "assert", "len", "(", "img", ")", "==", "1", ",", "'only support batch_size=1 when testing'", "\n", "\n", "if", "frame_id", "==", "0", ":", "\n", "            ", "gt_bboxes", "=", "gt_bboxes", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "memo", "=", "Dict", "(", ")", "\n", "self", ".", "memo", ".", "bbox", "=", "bbox_xyxy_to_cxcywh", "(", "gt_bboxes", ")", "\n", "self", ".", "memo", ".", "z_feat", ",", "self", ".", "memo", ".", "avg_channel", "=", "self", ".", "init", "(", "\n", "img", ",", "self", ".", "memo", ".", "bbox", ")", "\n", "best_score", "=", "None", "\n", "", "else", ":", "\n", "            ", "best_score", ",", "self", ".", "memo", ".", "bbox", "=", "self", ".", "track", "(", "img", ",", "self", ".", "memo", ".", "bbox", ",", "\n", "self", ".", "memo", ".", "z_feat", ",", "\n", "self", ".", "memo", ".", "avg_channel", ")", "\n", "self", ".", "memo", ".", "bbox", "=", "torch", ".", "round", "(", "self", ".", "memo", ".", "bbox", ")", "\n", "\n", "", "bbox_pred", "=", "bbox_cxcywh_to_xyxy", "(", "self", ".", "memo", ".", "bbox", ")", "\n", "results", "=", "dict", "(", ")", "\n", "if", "best_score", "is", "None", ":", "\n", "            ", "results", "[", "'score'", "]", "=", "best_score", "\n", "", "else", ":", "\n", "            ", "results", "[", "'score'", "]", "=", "best_score", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "results", "[", "'bbox'", "]", "=", "bbox_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_train": [[281, 333], ["siamrpn.SiamRPN.forward_template", "siamrpn.SiamRPN.forward_search", "siamrpn.SiamRPN.head", "dict", "siamrpn.SiamRPN.head.get_targets", "siamrpn.SiamRPN.head.loss", "dict.update"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_template", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.forward_search", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_bboxes", ",", "search_img", ",", "\n", "search_img_metas", ",", "search_gt_bboxes", ",", "is_positive_pairs", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (Tensor): of shape (N, C, H, W) encoding input exemplar images.\n                Typically H and W equal to 127.\n\n            img_metas (list[dict]): list of image information dict where each\n                dict has: 'img_shape', 'scale_factor', 'flip', and may also\n                contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            gt_bboxes (list[Tensor]): Ground truth bboxes for each exemplar\n                image with shape (1, 4) in [tl_x, tl_y, br_x, br_y] format.\n\n            search_img (Tensor): of shape (N, 1, C, H, W) encoding input search\n                images. 1 denotes there is only one search image for each\n                exemplar image. Typically H and W equal to 255.\n\n            search_img_metas (list[list[dict]]): The second list only has one\n                element. The first list contains search image information dict\n                where each dict has: 'img_shape', 'scale_factor', 'flip', and\n                may also contain 'filename', 'ori_shape', 'pad_shape', and\n                'img_norm_cfg'. For details on the values of these keys see\n                `mmtrack/datasets/pipelines/formatting.py:VideoCollect`.\n\n            search_gt_bboxes (list[Tensor]): Ground truth bboxes for each\n                search image with shape (1, 5) in [0.0, tl_x, tl_y, br_x, br_y]\n                format.\n\n            is_positive_pairs (list[bool]): list of bool denoting whether each\n                exemplar image and corresponding seach image is positive pair.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components.\n        \"\"\"", "\n", "search_img", "=", "search_img", "[", ":", ",", "0", "]", "\n", "\n", "z_feat", "=", "self", ".", "forward_template", "(", "img", ")", "\n", "x_feat", "=", "self", ".", "forward_search", "(", "search_img", ")", "\n", "cls_score", ",", "bbox_pred", "=", "self", ".", "head", "(", "z_feat", ",", "x_feat", ")", "\n", "\n", "losses", "=", "dict", "(", ")", "\n", "bbox_targets", "=", "self", ".", "head", ".", "get_targets", "(", "search_gt_bboxes", ",", "\n", "cls_score", ".", "shape", "[", "2", ":", "]", ",", "\n", "is_positive_pairs", ")", "\n", "head_losses", "=", "self", ".", "head", ".", "loss", "(", "cls_score", ",", "bbox_pred", ",", "*", "bbox_targets", ")", "\n", "losses", ".", "update", "(", "head_losses", ")", "\n", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity": [[5, 46], ["torch.mm", "torch.mm", "torch.zeros", "torch.zeros", "torch.normalize", "torch.normalize", "ref_embeds.t.t", "F.normalize.size", "ref_embeds.t.size", "NotImplementedError", "F.normalize.size", "ref_embeds.t.size", "similarity.embed_similarity"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity"], ["def", "embed_similarity", "(", "key_embeds", ",", "\n", "ref_embeds", ",", "\n", "method", "=", "'dot_product'", ",", "\n", "temperature", "=", "-", "1", ",", "\n", "transpose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Calculate feature similarity from embeddings.\n\n    Args:\n        key_embeds (Tensor): Shape (N1, C).\n        ref_embeds (Tensor): Shape (N2, C) or (C, N2).\n        method (str, optional): Method to calculate the similarity,\n            options are 'dot_product' and 'cosine'. Defaults to\n            'dot_product'.\n        temperature (int, optional): Softmax temperature. Defaults to -1.\n        transpose (bool, optional): Whether transpose `ref_embeds`.\n            Defaults to True.\n\n    Returns:\n        Tensor: Similarity matrix of shape (N1, N2).\n    \"\"\"", "\n", "assert", "method", "in", "[", "'dot_product'", ",", "'cosine'", "]", "\n", "\n", "if", "key_embeds", ".", "size", "(", "0", ")", "==", "0", "or", "ref_embeds", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "(", "key_embeds", ".", "size", "(", "0", ")", ",", "ref_embeds", ".", "size", "(", "0", ")", ")", ",", "\n", "device", "=", "key_embeds", ".", "device", ")", "\n", "\n", "", "if", "method", "==", "'cosine'", ":", "\n", "        ", "key_embeds", "=", "F", ".", "normalize", "(", "key_embeds", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "ref_embeds", "=", "F", ".", "normalize", "(", "ref_embeds", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "", "elif", "method", "==", "'dot_product'", ":", "\n", "        ", "if", "temperature", ">", "0", ":", "\n", "            ", "sims", "=", "embed_similarity", "(", "\n", "key_embeds", ",", "ref_embeds", ",", "method", "=", "'cosine'", ",", "transpose", "=", "transpose", ")", "\n", "sims", "/=", "temperature", "\n", "return", "sims", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "if", "transpose", ":", "\n", "        ", "ref_embeds", "=", "ref_embeds", ".", "t", "(", ")", "\n", "", "return", "torch", ".", "mm", "(", "key_embeds", ",", "ref_embeds", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.imrenormalize": [[6, 28], ["isinstance", "img.squeeze().cpu().numpy().transpose", "transforms._imrenormalize", "torch.from_numpy().to", "transforms._imrenormalize", "_imrenormalize.transpose", "img.squeeze().cpu().numpy", "torch.from_numpy", "img.squeeze().cpu", "img.squeeze"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms._imrenormalize", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms._imrenormalize"], ["\n", "from", "mmtrack", ".", "core", "import", "crop_image", "\n", "\n", "\n", "@", "PIPELINES", ".", "register_module", "(", ")", "\n", "class", "SeqCropLikeSiamFC", "(", "object", ")", ":", "\n", "    ", "\"\"\"Crop images as SiamFC did.\n\n    The way of cropping an image is proposed in\n    \"Fully-Convolutional Siamese Networks for Object Tracking.\"\n    `SiamFC <https://arxiv.org/abs/1606.09549>`_.\n\n    Args:\n        context_amount (float): The context amount around a bounding box.\n            Defaults to 0.5.\n        exemplar_size (int): Exemplar size. Defaults to 127.\n        crop_size (int): Crop size. Defaults to 511.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "context_amount", "=", "0.5", ",", "exemplar_size", "=", "127", ",", "crop_size", "=", "511", ")", ":", "\n", "        ", "self", ".", "context_amount", "=", "context_amount", "\n", "self", ".", "exemplar_size", "=", "exemplar_size", "\n", "self", ".", "crop_size", "=", "crop_size", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms._imrenormalize": [[30, 47], ["img_norm_cfg.copy.copy", "new_img_norm_cfg.copy.copy", "img_norm_cfg.copy.items", "new_img_norm_cfg.copy.items", "mmcv.imdenormalize", "mmcv.imnormalize", "img_norm_cfg.copy.pop", "numpy.array", "numpy.array", "isinstance", "isinstance"], "function", ["None"], ["", "def", "crop_like_SiamFC", "(", "self", ",", "\n", "image", ",", "\n", "bbox", ",", "\n", "context_amount", "=", "0.5", ",", "\n", "exemplar_size", "=", "127", ",", "\n", "crop_size", "=", "511", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result": [[49, 76], ["isinstance", "numpy.zeros", "bboxes.cpu().numpy.cpu().numpy", "labels.cpu().numpy.cpu().numpy", "ids.cpu().numpy.cpu().numpy", "numpy.concatenate", "range", "range", "bboxes.cpu().numpy.cpu", "labels.cpu().numpy.cpu", "ids.cpu().numpy.cpu"], "function", ["None"], ["padding", "=", "np", ".", "mean", "(", "image", ",", "axis", "=", "(", "0", ",", "1", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "bbox", "=", "np", ".", "array", "(", "[", "\n", "0.5", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "0", "]", ")", ",", "0.5", "*", "(", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", ")", ",", "\n", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", "\n", "]", ")", "\n", "z_width", "=", "bbox", "[", "2", "]", "+", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_height", "=", "bbox", "[", "3", "]", "+", "context_amount", "*", "(", "bbox", "[", "2", "]", "+", "bbox", "[", "3", "]", ")", "\n", "z_size", "=", "np", ".", "sqrt", "(", "z_width", "*", "z_height", ")", "\n", "\n", "z_scale", "=", "exemplar_size", "/", "z_size", "\n", "d_search", "=", "(", "crop_size", "-", "exemplar_size", ")", "/", "2", "\n", "pad", "=", "d_search", "/", "z_scale", "\n", "x_size", "=", "z_size", "+", "2", "*", "pad", "\n", "x_bbox", "=", "np", ".", "array", "(", "[", "\n", "bbox", "[", "0", "]", "-", "0.5", "*", "x_size", ",", "bbox", "[", "1", "]", "-", "0.5", "*", "x_size", ",", "\n", "bbox", "[", "0", "]", "+", "0.5", "*", "x_size", ",", "bbox", "[", "1", "]", "+", "0.5", "*", "x_size", "\n", "]", ")", "\n", "\n", "x_crop_img", "=", "crop_image", "(", "image", ",", "x_bbox", ",", "crop_size", ",", "padding", ")", "\n", "return", "x_crop_img", "\n", "\n", "", "def", "generate_box", "(", "self", ",", "image", ",", "gt_bbox", ",", "context_amount", ",", "exemplar_size", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result": [[79, 102], ["enumerate", "numpy.concatenate().astype", "numpy.array", "np.array.extend", "bboxes[].astype", "numpy.concatenate"], "function", ["None"], ["\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "w", ",", "h", "=", "gt_bbox", "[", "2", "]", "-", "gt_bbox", "[", "0", "]", ",", "gt_bbox", "[", "3", "]", "-", "gt_bbox", "[", "1", "]", "\n", "\n", "z_width", "=", "w", "+", "context_amount", "*", "(", "w", "+", "h", ")", "\n", "z_height", "=", "h", "+", "context_amount", "*", "(", "w", "+", "h", ")", "\n", "z_scale", "=", "np", ".", "sqrt", "(", "z_width", "*", "z_height", ")", "\n", "z_scale_factor", "=", "exemplar_size", "/", "z_scale", "\n", "w", "=", "w", "*", "z_scale_factor", "\n", "h", "=", "h", "*", "z_scale_factor", "\n", "cx", ",", "cy", "=", "img_w", "//", "2", ",", "img_h", "//", "2", "\n", "bbox", "=", "np", ".", "array", "(", "\n", "[", "cx", "-", "0.5", "*", "w", ",", "cy", "-", "0.5", "*", "h", ",", "cx", "+", "0.5", "*", "w", ",", "cy", "+", "0.5", "*", "h", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "bbox", "\n", "\n", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.correlation.depthwise_correlation": [[4, 24], ["kernel.view.size", "kernel.view.size", "x.view.view", "kernel.view.view", "torch.conv2d", "out.view.view", "x.view.size", "x.view.size", "kernel.view.size", "kernel.view.size", "out.view.size", "out.view.size"], "function", ["None"], ["def", "depthwise_correlation", "(", "x", ",", "kernel", ")", ":", "\n", "    ", "\"\"\"Depthwise cross correlation.\n\n    This function is proposed in\n    `SiamRPN++ <https://arxiv.org/abs/1812.11703>`_.\n\n    Args:\n        x (Tensor): of shape (N, C, H_x, W_x).\n        kernel (Tensor): of shape (N, C, H_k, W_k).\n\n    Returns:\n        Tensor: of shape (N, C, H_o, W_o). H_o = H_x - H_k + 1. So does W_o.\n    \"\"\"", "\n", "batch", "=", "kernel", ".", "size", "(", "0", ")", "\n", "channel", "=", "kernel", ".", "size", "(", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "1", ",", "batch", "*", "channel", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "kernel", "=", "kernel", ".", "view", "(", "batch", "*", "channel", ",", "1", ",", "kernel", ".", "size", "(", "2", ")", ",", "kernel", ".", "size", "(", "3", ")", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "x", ",", "kernel", ",", "groups", "=", "batch", "*", "channel", ")", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "channel", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ")", "\n", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.anchor.sot_anchor_generator.SiameseRPNAnchorGenerator.__init__": [[14, 18], ["mmdet.core.anchor.AnchorGenerator.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "strides", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "strides", ")", "==", "1", ",", "'only support one feature map level'", "\n", "super", "(", "SiameseRPNAnchorGenerator", ",", "\n", "self", ")", ".", "__init__", "(", "strides", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.anchor.sot_anchor_generator.SiameseRPNAnchorGenerator.gen_2d_hanning_windows": [[19, 40], ["range", "len", "numpy.hanning", "numpy.hanning", "numpy.outer", "numpy.tile", "multi_level_windows.append", "numpy.tile.flatten", "torch.from_numpy().to", "torch.from_numpy"], "methods", ["None"], ["", "def", "gen_2d_hanning_windows", "(", "self", ",", "featmap_sizes", ",", "device", "=", "'cuda'", ")", ":", "\n", "        ", "\"\"\"Generate 2D hanning window.\n\n        Args:\n            featmap_sizes (list[torch.size]): List of torch.size recording the\n                resolution (height, width) of the multi-level feature maps.\n            device (str): Device the tensor will be put on. Defaults to 'cuda'.\n\n        Returns:\n            list[Tensor]: List of 2D hanning window with shape\n            (num_base_anchors[i] * featmap_sizes[i][0] * featmap_sizes[i][1]).\n        \"\"\"", "\n", "assert", "self", ".", "num_levels", "==", "len", "(", "featmap_sizes", ")", "\n", "multi_level_windows", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_levels", ")", ":", "\n", "            ", "hanning_h", "=", "np", ".", "hanning", "(", "featmap_sizes", "[", "i", "]", "[", "0", "]", ")", "\n", "hanning_w", "=", "np", ".", "hanning", "(", "featmap_sizes", "[", "i", "]", "[", "1", "]", ")", "\n", "window", "=", "np", ".", "outer", "(", "hanning_h", ",", "hanning_w", ")", "\n", "window", "=", "np", ".", "tile", "(", "window", ".", "flatten", "(", ")", ",", "self", ".", "num_base_anchors", "[", "i", "]", ")", "\n", "multi_level_windows", ".", "append", "(", "torch", ".", "from_numpy", "(", "window", ")", ".", "to", "(", "device", ")", ")", "\n", "", "return", "multi_level_windows", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.anchor.sot_anchor_generator.SiameseRPNAnchorGenerator.gen_single_level_base_anchors": [[41, 84], ["torch.sqrt", "torch.stack", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "def", "gen_single_level_base_anchors", "(", "self", ",", "\n", "base_size", ",", "\n", "scales", ",", "\n", "ratios", ",", "\n", "center", "=", "None", ")", ":", "\n", "        ", "\"\"\"Generate base anchors of a single level feature map.\n\n        Args:\n            base_size (int | float): Basic size of an anchor.\n            scales (torch.Tensor): Scales of the anchor.\n            ratios (torch.Tensor): The ratio between between the height\n                and width of anchors in a single level.\n            center (tuple[float], optional): The center of the base anchor\n                related to a single feature grid. Defaults to None.\n\n        Returns:\n            torch.Tensor: Anchors of one spatial location in a single level\n            feature map in [cx, cy, w, h] format.\n        \"\"\"", "\n", "w", "=", "base_size", "\n", "h", "=", "base_size", "\n", "if", "center", "is", "None", ":", "\n", "            ", "x_center", "=", "self", ".", "center_offset", "*", "w", "\n", "y_center", "=", "self", ".", "center_offset", "*", "h", "\n", "", "else", ":", "\n", "            ", "x_center", ",", "y_center", "=", "center", "\n", "\n", "", "h_ratios", "=", "torch", ".", "sqrt", "(", "ratios", ")", "\n", "w_ratios", "=", "1", "/", "h_ratios", "\n", "if", "self", ".", "scale_major", ":", "\n", "            ", "ws", "=", "(", "(", "w", "*", "w_ratios", "[", ":", ",", "None", "]", ")", ".", "long", "(", ")", "*", "scales", "[", "None", ",", ":", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "hs", "=", "(", "(", "h", "*", "h_ratios", "[", ":", ",", "None", "]", ")", ".", "long", "(", ")", "*", "scales", "[", "None", ",", ":", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "ws", "=", "(", "w", "*", "scales", "[", ":", ",", "None", "]", "*", "w_ratios", "[", "None", ",", ":", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "hs", "=", "(", "h", "*", "scales", "[", ":", ",", "None", "]", "*", "h_ratios", "[", "None", ",", ":", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "base_anchors", "=", "[", "\n", "torch", ".", "ones_like", "(", "ws", ")", "*", "x_center", ",", "\n", "torch", ".", "ones_like", "(", "hs", ")", "*", "y_center", ",", "ws", ",", "hs", "\n", "]", "\n", "base_anchors", "=", "torch", ".", "stack", "(", "base_anchors", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "base_anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.anchor.sot_anchor_generator.SiameseRPNAnchorGenerator.single_level_grid_anchors": [[85, 131], ["int", "int", "sot_anchor_generator.SiameseRPNAnchorGenerator._meshgrid", "torch.stack", "shifts.type_as.type_as.type_as", "all_anchors.view.view.view", "torch.arange", "torch.arange", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "single_level_grid_anchors", "(", "self", ",", "\n", "base_anchors", ",", "\n", "featmap_size", ",", "\n", "stride", "=", "(", "16", ",", "16", ")", ",", "\n", "device", "=", "'cuda'", ")", ":", "\n", "        ", "\"\"\"Generate grid anchors of a single level feature map.\n\n        Note:\n            This function is usually called by method ``self.grid_anchors``.\n\n        Args:\n            base_anchors (torch.Tensor): The base anchors of a feature grid.\n            featmap_size (tuple[int]): Size of the feature maps in order\n                (h, w).\n            stride (tuple[int], optional): Stride of the feature map in order\n                (w, h). Defaults to (16, 16).\n            device (str, optional): Device the tensor will be put on.\n                Defaults to 'cuda'.\n\n        Returns:\n            torch.Tensor: Anchors of all spatial locations with [cx, cy, w, h]\n            format in the feature map.\n        \"\"\"", "\n", "feat_h", ",", "feat_w", "=", "featmap_size", "\n", "# convert Tensor to int, so that we can covert to ONNX correctlly", "\n", "feat_h", "=", "int", "(", "feat_h", ")", "\n", "feat_w", "=", "int", "(", "feat_w", ")", "\n", "shift_x", "=", "torch", ".", "arange", "(", "0", ",", "feat_w", ",", "device", "=", "device", ")", "*", "stride", "[", "0", "]", "\n", "shift_y", "=", "torch", ".", "arange", "(", "0", ",", "feat_h", ",", "device", "=", "device", ")", "*", "stride", "[", "1", "]", "\n", "\n", "shift_xx", ",", "shift_yy", "=", "self", ".", "_meshgrid", "(", "shift_x", ",", "shift_y", ")", "\n", "shifts", "=", "torch", ".", "stack", "(", "[", "\n", "shift_xx", ",", "shift_yy", ",", "\n", "torch", ".", "zeros_like", "(", "shift_xx", ")", ",", "\n", "torch", ".", "zeros_like", "(", "shift_yy", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "shifts", "=", "shifts", ".", "type_as", "(", "base_anchors", ")", "\n", "\n", "all_anchors", "=", "base_anchors", "[", ":", ",", "None", ",", ":", "]", "+", "shifts", "[", "None", ",", ":", ",", ":", "]", "\n", "all_anchors", "=", "all_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "\n", "all_anchors", "[", ":", ",", "0", "]", "+=", "-", "(", "feat_w", "//", "2", ")", "*", "stride", "[", "0", "]", "\n", "all_anchors", "[", ":", ",", "1", "]", "+=", "-", "(", "feat_h", "//", "2", ")", "*", "stride", "[", "1", "]", "\n", "\n", "return", "all_anchors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.bbox_distances": [[31, 37], ["mmdet.core.evaluation.bbox_overlaps.bbox_overlaps", "numpy.where"], "function", ["None"], ["def", "bbox_distances", "(", "bboxes1", ",", "bboxes2", ",", "iou_thr", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"Calculate the IoU distances of two sets of boxes.\"\"\"", "\n", "ious", "=", "bbox_overlaps", "(", "bboxes1", ",", "bboxes2", ",", "mode", "=", "'iou'", ")", "\n", "distances", "=", "1", "-", "ious", "\n", "distances", "=", "np", ".", "where", "(", "distances", ">", "iou_thr", ",", "np", ".", "nan", ",", "distances", ")", "\n", "return", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.acc_single_video": [[39, 80], ["len", "zip", "motmetrics.MOTAccumulator", "track.track2result", "range", "range", "mmdet.core.bbox2result", "eval_mot.bbox_distances", "[].astype", "[].astype", "numpy.ones().astype", "motmetrics.lap.linear_sum_assignment", "zip", "mmdet.core.evaluation.bbox_overlaps.bbox_overlaps", "accumulators[].update", "range", "numpy.ones", "numpy.isfinite"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.bbox_distances", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "acc_single_video", "(", "results", ",", "\n", "gts", ",", "\n", "iou_thr", "=", "0.5", ",", "\n", "ignore_iof_thr", "=", "0.5", ",", "\n", "ignore_by_classes", "=", "False", ")", ":", "\n", "    ", "\"\"\"Accumulate results in a single video.\"\"\"", "\n", "num_classes", "=", "len", "(", "results", "[", "0", "]", ")", "\n", "accumulators", "=", "[", "\n", "mm", ".", "MOTAccumulator", "(", "auto_id", "=", "True", ")", "for", "i", "in", "range", "(", "num_classes", ")", "\n", "]", "\n", "for", "result", ",", "gt", "in", "zip", "(", "results", ",", "gts", ")", ":", "\n", "        ", "if", "ignore_by_classes", ":", "\n", "            ", "gt_ignore", "=", "bbox2result", "(", "gt", "[", "'bboxes_ignore'", "]", ",", "gt", "[", "'labels_ignore'", "]", ",", "\n", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "gt_ignore", "=", "[", "gt", "[", "'bboxes_ignore'", "]", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "", "gt", "=", "track2result", "(", "gt", "[", "'bboxes'", "]", ",", "gt", "[", "'labels'", "]", ",", "gt", "[", "'instance_ids'", "]", ",", "\n", "num_classes", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "            ", "gt_ids", ",", "gt_bboxes", "=", "gt", "[", "i", "]", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", ",", "gt", "[", "i", "]", "[", ":", ",", "1", ":", "]", "\n", "pred_ids", ",", "pred_bboxes", "=", "result", "[", "i", "]", "[", ":", ",", "0", "]", ".", "astype", "(", "\n", "np", ".", "int", ")", ",", "result", "[", "i", "]", "[", ":", ",", "1", ":", "-", "1", "]", "\n", "dist", "=", "bbox_distances", "(", "gt_bboxes", ",", "pred_bboxes", ",", "iou_thr", ")", "\n", "if", "gt_ignore", "[", "i", "]", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "# 1. assign gt and preds", "\n", "                ", "fps", "=", "np", ".", "ones", "(", "pred_bboxes", ".", "shape", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "row", ",", "col", "=", "linear_sum_assignment", "(", "dist", ")", "\n", "for", "m", ",", "n", "in", "zip", "(", "row", ",", "col", ")", ":", "\n", "                    ", "if", "not", "np", ".", "isfinite", "(", "dist", "[", "m", ",", "n", "]", ")", ":", "\n", "                        ", "continue", "\n", "", "fps", "[", "n", "]", "=", "False", "\n", "# 2. ignore by iof", "\n", "", "iofs", "=", "bbox_overlaps", "(", "pred_bboxes", ",", "gt_ignore", "[", "i", "]", ",", "mode", "=", "'iof'", ")", "\n", "ignores", "=", "(", "iofs", ">", "ignore_iof_thr", ")", ".", "any", "(", "axis", "=", "1", ")", "\n", "# 3. filter preds", "\n", "valid_inds", "=", "~", "(", "fps", "&", "ignores", ")", "\n", "pred_ids", "=", "pred_ids", "[", "valid_inds", "]", "\n", "dist", "=", "dist", "[", ":", ",", "valid_inds", "]", "\n", "", "if", "dist", ".", "shape", "!=", "(", "0", ",", "0", ")", ":", "\n", "                ", "accumulators", "[", "i", "]", ".", "update", "(", "gt_ids", ",", "pred_ids", ",", "dist", ")", "\n", "", "", "", "return", "accumulators", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.aggregate_accs": [[82, 101], ["list", "enumerate", "list.append", "names.append", "accs.append", "enumerate", "names[].append", "accs[].append", "len"], "function", ["None"], ["", "def", "aggregate_accs", "(", "accumulators", ",", "classes", ")", ":", "\n", "    ", "\"\"\"Aggregate results from each class.\"\"\"", "\n", "# accs for each class", "\n", "items", "=", "list", "(", "classes", ")", "\n", "names", ",", "accs", "=", "[", "[", "]", "for", "c", "in", "classes", "]", ",", "[", "[", "]", "for", "c", "in", "classes", "]", "\n", "for", "video_ind", ",", "_accs", "in", "enumerate", "(", "accumulators", ")", ":", "\n", "        ", "for", "cls_ind", ",", "acc", "in", "enumerate", "(", "_accs", ")", ":", "\n", "            ", "if", "len", "(", "acc", ".", "_events", "[", "'Type'", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "name", "=", "f'{classes[cls_ind]}_{video_ind}'", "\n", "names", "[", "cls_ind", "]", ".", "append", "(", "name", ")", "\n", "accs", "[", "cls_ind", "]", ".", "append", "(", "acc", ")", "\n", "\n", "# overall", "\n", "", "", "items", ".", "append", "(", "'OVERALL'", ")", "\n", "names", ".", "append", "(", "[", "n", "for", "name", "in", "names", "for", "n", "in", "name", "]", ")", "\n", "accs", ".", "append", "(", "[", "a", "for", "acc", "in", "accs", "for", "a", "in", "acc", "]", ")", "\n", "\n", "return", "names", ",", "accs", ",", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.eval_single_class": [[103, 120], ["motmetrics.metrics.create", "mm.metrics.create.compute_many", "list().index", "numpy.isnan", "mm.metrics.create.compute_many", "motmetrics.math_util.quiet_divide", "float", "METRIC_MAPS.keys", "mh.compute_many.to_dict().items", "list", "mh.compute_many.to_dict"], "function", ["None"], ["", "def", "eval_single_class", "(", "names", ",", "accs", ")", ":", "\n", "    ", "\"\"\"Evaluate CLEAR MOT results for each class.\"\"\"", "\n", "mh", "=", "mm", ".", "metrics", ".", "create", "(", ")", "\n", "summary", "=", "mh", ".", "compute_many", "(", "\n", "accs", ",", "names", "=", "names", ",", "metrics", "=", "METRIC_MAPS", ".", "keys", "(", ")", ",", "generate_overall", "=", "True", ")", "\n", "results", "=", "[", "v", "[", "'OVERALL'", "]", "for", "k", ",", "v", "in", "summary", ".", "to_dict", "(", ")", ".", "items", "(", ")", "]", "\n", "motp_ind", "=", "list", "(", "METRIC_MAPS", ")", ".", "index", "(", "'motp'", ")", "\n", "if", "np", ".", "isnan", "(", "results", "[", "motp_ind", "]", ")", ":", "\n", "        ", "num_dets", "=", "mh", ".", "compute_many", "(", "\n", "accs", ",", "\n", "names", "=", "names", ",", "\n", "metrics", "=", "[", "'num_detections'", "]", ",", "\n", "generate_overall", "=", "True", ")", "\n", "sum_motp", "=", "(", "summary", "[", "'motp'", "]", "*", "num_dets", "[", "'num_detections'", "]", ")", ".", "sum", "(", ")", "\n", "motp", "=", "quiet_divide", "(", "sum_motp", ",", "num_dets", "[", "'num_detections'", "]", "[", "'OVERALL'", "]", ")", "\n", "results", "[", "motp_ind", "]", "=", "float", "(", "1", "-", "motp", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.eval_mot": [[122, 221], ["mmcv.utils.print_log", "time.time", "annotations.copy", "METRIC_MAPS.keys", "mmcv.utils.print_log", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "eval_mot.aggregate_accs", "mmcv.utils.print_log", "pandas.DataFrame", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "enumerate", "enumerate", "eval_results.to_dict.astype", "mmcv.utils.print_log", "motmetrics.io.render_summary", "mmcv.utils.print_log", "mmcv.utils.print_log", "eval_results.to_dict.to_dict", "out.items", "len", "len", "zip", "zip", "type", "numpy.array", "numpy.nan_to_num", "METRIC_MAPS.keys", "zip", "avg_results.append", "eval_results.to_dict.items", "isinstance", "float", "int", "range", "int", "avg_results.append", "TypeError", "motmetrics.metrics.create", "isinstance", "len", "range", "range", "range", "np.nan_to_num.sum", "float", "time.time", "len", "len", "len", "np.nan_to_num.mean", "len"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_mot.aggregate_accs"], ["", "def", "eval_mot", "(", "results", ",", "\n", "annotations", ",", "\n", "logger", "=", "None", ",", "\n", "classes", "=", "None", ",", "\n", "iou_thr", "=", "0.5", ",", "\n", "ignore_iof_thr", "=", "0.5", ",", "\n", "ignore_by_classes", "=", "False", ",", "\n", "nproc", "=", "4", ")", ":", "\n", "    ", "\"\"\"Evaluation CLEAR MOT metrics.\n\n    Args:\n        results (list[list[list[ndarray]]]): The first list indicates videos,\n            The second list indicates images. The third list indicates\n            categories. The ndarray indicates the tracking results.\n        annotations (list[list[dict]]): The first list indicates videos,\n            The second list indicates images. The third list indicates\n            the annotations of each video. Keys of annotations are\n\n            - `bboxes`: numpy array of shape (n, 4)\n            - `labels`: numpy array of shape (n, )\n            - `instance_ids`: numpy array of shape (n, )\n            - `bboxes_ignore` (optional): numpy array of shape (k, 4)\n            - `labels_ignore` (optional): numpy array of shape (k, )\n        logger (logging.Logger | str | None, optional): The way to print the\n            evaluation results. Defaults to None.\n        classes (list, optional): Classes in the dataset. Defaults to None.\n        iou_thr (float, optional): IoU threshold for evaluation.\n            Defaults to 0.5.\n        ignore_iof_thr (float, optional): Iof threshold to ignore results.\n            Defaults to 0.5.\n        ignore_by_classes (bool, optional): Whether ignore the results by\n            classes or not. Defaults to False.\n        nproc (int, optional): Number of the processes. Defaults to 4.\n\n    Returns:\n        dict[str, float]: Evaluation results.\n    \"\"\"", "\n", "print_log", "(", "'---CLEAR MOT Evaluation---'", ",", "logger", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "gts", "=", "annotations", ".", "copy", "(", ")", "\n", "if", "classes", "is", "None", ":", "\n", "        ", "classes", "=", "[", "i", "+", "1", "for", "i", "in", "range", "(", "len", "(", "results", "[", "0", "]", ")", ")", "]", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "gts", ")", "\n", "metrics", "=", "METRIC_MAPS", ".", "keys", "(", ")", "\n", "\n", "print_log", "(", "'Accumulating...'", ",", "logger", ")", "\n", "\n", "pool", "=", "Pool", "(", "nproc", ")", "\n", "accs", "=", "pool", ".", "starmap", "(", "\n", "acc_single_video", ",", "\n", "zip", "(", "results", ",", "gts", ",", "[", "iou_thr", "for", "_", "in", "range", "(", "len", "(", "gts", ")", ")", "]", ",", "\n", "[", "ignore_iof_thr", "for", "_", "in", "range", "(", "len", "(", "gts", ")", ")", "]", ",", "\n", "[", "ignore_by_classes", "for", "_", "in", "range", "(", "len", "(", "gts", ")", ")", "]", ")", ")", "\n", "names", ",", "accs", ",", "items", "=", "aggregate_accs", "(", "accs", ",", "classes", ")", "\n", "print_log", "(", "'Evaluating...'", ",", "logger", ")", "\n", "eval_results", "=", "pd", ".", "DataFrame", "(", "columns", "=", "metrics", ")", "\n", "summaries", "=", "pool", ".", "starmap", "(", "eval_single_class", ",", "zip", "(", "names", ",", "accs", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "\n", "# category and overall results", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "        ", "eval_results", ".", "loc", "[", "item", "]", "=", "summaries", "[", "i", "]", "\n", "\n", "", "dtypes", "=", "{", "m", ":", "type", "(", "d", ")", "for", "m", ",", "d", "in", "zip", "(", "metrics", ",", "summaries", "[", "0", "]", ")", "}", "\n", "# average results", "\n", "avg_results", "=", "[", "]", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "metrics", ")", ":", "\n", "        ", "v", "=", "np", ".", "array", "(", "[", "s", "[", "i", "]", "for", "s", "in", "summaries", "[", ":", "len", "(", "classes", ")", "]", "]", ")", "\n", "v", "=", "np", ".", "nan_to_num", "(", "v", ",", "nan", "=", "0", ")", "\n", "if", "dtypes", "[", "m", "]", "==", "int", ":", "\n", "            ", "avg_results", ".", "append", "(", "int", "(", "v", ".", "sum", "(", ")", ")", ")", "\n", "", "elif", "dtypes", "[", "m", "]", "==", "float", ":", "\n", "            ", "avg_results", ".", "append", "(", "float", "(", "v", ".", "mean", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", ")", "\n", "", "", "eval_results", ".", "loc", "[", "'AVERAGE'", "]", "=", "avg_results", "\n", "eval_results", "=", "eval_results", ".", "astype", "(", "dtypes", ")", "\n", "\n", "print_log", "(", "'Rendering...'", ",", "logger", ")", "\n", "strsummary", "=", "mm", ".", "io", ".", "render_summary", "(", "\n", "eval_results", ",", "\n", "formatters", "=", "mm", ".", "metrics", ".", "create", "(", ")", ".", "formatters", ",", "\n", "namemap", "=", "METRIC_MAPS", ")", "\n", "\n", "print_log", "(", "'\\n'", "+", "strsummary", ",", "logger", ")", "\n", "print_log", "(", "f'Evaluation finishes with {(time.time() - t):.2f} s.'", ",", "logger", ")", "\n", "\n", "eval_results", "=", "eval_results", ".", "to_dict", "(", ")", "\n", "out", "=", "{", "METRIC_MAPS", "[", "k", "]", ":", "v", "[", "'OVERALL'", "]", "for", "k", ",", "v", "in", "eval_results", ".", "items", "(", ")", "}", "\n", "for", "k", ",", "v", "in", "out", ".", "items", "(", ")", ":", "\n", "        ", "out", "[", "k", "]", "=", "float", "(", "f'{(v):.3f}'", ")", "if", "isinstance", "(", "v", ",", "float", ")", "else", "int", "(", "f'{v}'", ")", "\n", "", "for", "m", "in", "[", "'OVERALL'", ",", "'AVERAGE'", "]", ":", "\n", "        ", "out", "[", "f'track_{m}_copypaste'", "]", "=", "''", "\n", "for", "k", "in", "METRIC_MAPS", ".", "keys", "(", ")", ":", "\n", "            ", "v", "=", "eval_results", "[", "k", "]", "[", "m", "]", "\n", "v", "=", "f'{(v):.3f} '", "if", "isinstance", "(", "v", ",", "float", ")", "else", "f'{v} '", "\n", "out", "[", "f'track_{m}_copypaste'", "]", "+=", "v", "\n", "\n", "", "", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_hooks.EvalHook.after_train_epoch": [[11, 20], ["single_gpu_test", "eval_hooks.EvalHook.evaluate", "eval_hooks.EvalHook.evaluation_flag"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.single_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate"], ["def", "after_train_epoch", "(", "self", ",", "runner", ")", ":", "\n", "        ", "if", "not", "self", ".", "evaluation_flag", "(", "runner", ")", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "dataloader", ".", "dataset", ".", "load_as_video", ":", "\n", "            ", "from", "mmtrack", ".", "apis", "import", "single_gpu_test", "\n", "", "else", ":", "\n", "            ", "from", "mmdet", ".", "apis", "import", "single_gpu_test", "\n", "", "results", "=", "single_gpu_test", "(", "runner", ".", "model", ",", "self", ".", "dataloader", ",", "show", "=", "False", ")", "\n", "self", ".", "evaluate", "(", "runner", ",", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_hooks.DistEvalHook.after_train_epoch": [[26, 44], ["multi_gpu_test", "eval_hooks.DistEvalHook.evaluation_flag", "os.join", "print", "eval_hooks.DistEvalHook.evaluate"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.apis.test.multi_gpu_test", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate"], ["def", "after_train_epoch", "(", "self", ",", "runner", ")", ":", "\n", "        ", "if", "not", "self", ".", "evaluation_flag", "(", "runner", ")", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "dataloader", ".", "dataset", ".", "load_as_video", ":", "\n", "            ", "from", "mmtrack", ".", "apis", "import", "multi_gpu_test", "\n", "", "else", ":", "\n", "            ", "from", "mmdet", ".", "apis", "import", "multi_gpu_test", "\n", "", "tmpdir", "=", "self", ".", "tmpdir", "\n", "if", "tmpdir", "is", "None", ":", "\n", "            ", "tmpdir", "=", "osp", ".", "join", "(", "runner", ".", "work_dir", ",", "'.eval_hook'", ")", "\n", "", "results", "=", "multi_gpu_test", "(", "\n", "runner", ".", "model", ",", "\n", "self", ".", "dataloader", ",", "\n", "tmpdir", "=", "tmpdir", ",", "\n", "gpu_collect", "=", "self", ".", "gpu_collect", ")", "\n", "if", "runner", ".", "rank", "==", "0", ":", "\n", "            ", "print", "(", "'\\n'", ")", "\n", "self", ".", "evaluate", "(", "runner", ",", "results", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.success_overlap": [[5, 31], ["numpy.zeros", "mmdet.core.evaluation.bbox_overlaps.bbox_overlaps", "range", "len", "numpy.ones", "len", "len", "numpy.sum", "float", "numpy.arange", "numpy.arange", "len", "len"], "function", ["None"], ["def", "success_overlap", "(", "gt_bboxes", ",", "pred_bboxes", ",", "iou_th", ",", "video_length", ")", ":", "\n", "    ", "\"\"\"Evaluation based on iou.\n\n    Args:\n        gt_bboxes (ndarray): of shape (video_length, 4) in\n            [tl_x, tl_y, br_x, br_y] format.\n        pred_bboxes (ndarray): of shape (video_length, 4) in\n            [tl_x, tl_y, br_x, br_y] format.\n        iou_th (ndarray): Different threshold of iou. Typically is set to\n            `np.arange(0, 1.05, 0.05)`.\n        video_length (int): Video length.\n\n    Returns:\n        ndarray: The evaluation results at different threshold of iou.\n    \"\"\"", "\n", "success", "=", "np", ".", "zeros", "(", "len", "(", "iou_th", ")", ")", "\n", "iou", "=", "np", ".", "ones", "(", "len", "(", "gt_bboxes", ")", ")", "*", "(", "-", "1", ")", "\n", "valid", "=", "(", "gt_bboxes", "[", ":", ",", "2", "]", ">", "gt_bboxes", "[", ":", ",", "0", "]", ")", "&", "(", "\n", "gt_bboxes", "[", ":", ",", "3", "]", ">", "gt_bboxes", "[", ":", ",", "1", "]", ")", "\n", "iou_matrix", "=", "bbox_overlaps", "(", "gt_bboxes", "[", "valid", "]", ",", "pred_bboxes", "[", "valid", "]", ")", "\n", "iou", "[", "valid", "]", "=", "iou_matrix", "[", "np", ".", "arange", "(", "len", "(", "gt_bboxes", "[", "valid", "]", ")", ")", ",", "\n", "np", ".", "arange", "(", "len", "(", "gt_bboxes", "[", "valid", "]", ")", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "iou_th", ")", ")", ":", "\n", "        ", "success", "[", "i", "]", "=", "np", ".", "sum", "(", "iou", ">", "iou_th", "[", "i", "]", ")", "/", "float", "(", "video_length", ")", "\n", "", "return", "success", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.success_error": [[33, 55], ["numpy.zeros", "numpy.sqrt", "range", "len", "numpy.ones", "numpy.sum", "len", "len", "numpy.sum", "float"], "function", ["None"], ["", "def", "success_error", "(", "gt_bboxes_center", ",", "pred_bboxes_center", ",", "pixel_offset_th", ",", "\n", "video_length", ")", ":", "\n", "    ", "\"\"\"Evaluation based on pixel offset.\n\n    Args:\n        gt_bboxes (ndarray): of shape (video_length, 2) in [cx, cy] format.\n        pred_bboxes (ndarray): of shape (video_length, 2) in [cx, cy] format.\n        pixel_offset_th (ndarray): Different threshold of pixel offset.\n        video_length (int): Video length.\n\n    Returns:\n        ndarray: The evaluation results at different threshold of pixel offset.\n    \"\"\"", "\n", "success", "=", "np", ".", "zeros", "(", "len", "(", "pixel_offset_th", ")", ")", "\n", "dist", "=", "np", ".", "ones", "(", "len", "(", "gt_bboxes_center", ")", ")", "*", "(", "-", "1", ")", "\n", "valid", "=", "(", "gt_bboxes_center", "[", ":", ",", "0", "]", ">", "0", ")", "&", "(", "gt_bboxes_center", "[", ":", ",", "1", "]", ">", "0", ")", "\n", "dist", "[", "valid", "]", "=", "np", ".", "sqrt", "(", "\n", "np", ".", "sum", "(", "\n", "(", "gt_bboxes_center", "[", "valid", "]", "-", "pred_bboxes_center", "[", "valid", "]", ")", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "pixel_offset_th", ")", ")", ":", "\n", "        ", "success", "[", "i", "]", "=", "np", ".", "sum", "(", "dist", "<=", "pixel_offset_th", "[", "i", "]", ")", "/", "float", "(", "video_length", ")", "\n", "", "return", "success", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.eval_sot_ope": [[57, 120], ["zip", "dict", "numpy.stack", "numpy.stack", "len", "numpy.arange", "success_results.append", "numpy.arange", "precision_results.append", "norm_precision_results.append", "numpy.mean", "numpy.stack", "eval_sot_ope.success_overlap", "numpy.array", "numpy.array", "eval_sot_ope.success_error", "numpy.array", "eval_sot_ope.success_error", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.success_overlap", "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.success_error", "home.repos.pwc.inspect_result.goodproj13_tf-blender.evaluation.eval_sot_ope.success_error"], ["", "def", "eval_sot_ope", "(", "results", ",", "annotations", ")", ":", "\n", "    ", "\"\"\"Evaluation in OPE protocol.\n\n    Args:\n        results (list[list[ndarray]]): The first list contains the tracking\n            results of each video. The second list contains the tracking\n            results of each frame in one video. The ndarray denotes the\n            tracking box in [tl_x, tl_y, br_x, br_y] format.\n        annotations (list[list[dict]]): The first list contains the annotations\n            of each video. The second list contains the annotations of each\n            frame in one video. The dict contains the annotation information\n            of one frame.\n\n    Returns:\n        dict[str, float]: OPE style evaluation metric (i.e. success,\n        norm precision and precision).\n    \"\"\"", "\n", "success_results", "=", "[", "]", "\n", "precision_results", "=", "[", "]", "\n", "norm_precision_results", "=", "[", "]", "\n", "for", "single_video_results", ",", "single_video_anns", "in", "zip", "(", "results", ",", "annotations", ")", ":", "\n", "        ", "gt_bboxes", "=", "np", ".", "stack", "(", "[", "ann", "[", "'bboxes'", "]", "for", "ann", "in", "single_video_anns", "]", ")", "\n", "pred_bboxes", "=", "np", ".", "stack", "(", "single_video_results", ")", "\n", "video_length", "=", "len", "(", "single_video_results", ")", "\n", "\n", "if", "'ignore'", "in", "single_video_anns", "[", "0", "]", ":", "\n", "            ", "gt_ignore", "=", "np", ".", "stack", "(", "[", "ann", "[", "'ignore'", "]", "for", "ann", "in", "single_video_anns", "]", ")", "\n", "gt_bboxes", "=", "gt_bboxes", "[", "gt_ignore", "==", "0", "]", "\n", "pred_bboxes", "=", "pred_bboxes", "[", "gt_ignore", "==", "0", "]", "\n", "\n", "# eval success based on iou", "\n", "", "iou_th", "=", "np", ".", "arange", "(", "0", ",", "1.05", ",", "0.05", ")", "\n", "success_results", ".", "append", "(", "\n", "success_overlap", "(", "gt_bboxes", ",", "pred_bboxes", ",", "iou_th", ",", "video_length", ")", ")", "\n", "\n", "# eval precision", "\n", "gt_bboxes_center", "=", "np", ".", "array", "(", "\n", "(", "0.5", "*", "(", "gt_bboxes", "[", ":", ",", "2", "]", "+", "gt_bboxes", "[", ":", ",", "0", "]", ")", ",", "\n", "0.5", "*", "(", "gt_bboxes", "[", ":", ",", "3", "]", "+", "gt_bboxes", "[", ":", ",", "1", "]", ")", ")", ")", ".", "T", "\n", "pred_bboxes_center", "=", "np", ".", "array", "(", "\n", "(", "0.5", "*", "(", "pred_bboxes", "[", ":", ",", "2", "]", "+", "pred_bboxes", "[", ":", ",", "0", "]", ")", ",", "\n", "0.5", "*", "(", "pred_bboxes", "[", ":", ",", "3", "]", "+", "pred_bboxes", "[", ":", ",", "1", "]", ")", ")", ")", ".", "T", "\n", "pixel_offset_th", "=", "np", ".", "arange", "(", "0", ",", "51", ",", "1", ")", "\n", "precision_results", ".", "append", "(", "\n", "success_error", "(", "gt_bboxes_center", ",", "pred_bboxes_center", ",", "\n", "pixel_offset_th", ",", "video_length", ")", ")", "\n", "\n", "# eval normed precison", "\n", "gt_bboxes_wh", "=", "np", ".", "array", "(", "(", "gt_bboxes", "[", ":", ",", "2", "]", "-", "gt_bboxes", "[", ":", ",", "0", "]", ",", "\n", "gt_bboxes", "[", ":", ",", "3", "]", "-", "gt_bboxes", "[", ":", ",", "1", "]", ")", ")", ".", "T", "\n", "norm_gt_bboxes_center", "=", "gt_bboxes_center", "/", "(", "gt_bboxes_wh", "+", "1e-16", ")", "\n", "norm_pred_bboxes_center", "=", "pred_bboxes_center", "/", "(", "gt_bboxes_wh", "+", "1e-16", ")", "\n", "norm_pixel_offset_th", "=", "pixel_offset_th", "/", "100.", "\n", "norm_precision_results", ".", "append", "(", "\n", "success_error", "(", "norm_gt_bboxes_center", ",", "norm_pred_bboxes_center", ",", "\n", "norm_pixel_offset_th", ",", "video_length", ")", ")", "\n", "\n", "", "success", "=", "np", ".", "mean", "(", "success_results", ")", "*", "100", "\n", "precision", "=", "np", ".", "mean", "(", "precision_results", ",", "axis", "=", "0", ")", "[", "20", "]", "*", "100", "\n", "norm_precision", "=", "np", ".", "mean", "(", "norm_precision_results", ",", "axis", "=", "0", ")", "[", "20", "]", "*", "100", "\n", "eval_results", "=", "dict", "(", "\n", "success", "=", "success", ",", "norm_precision", "=", "norm_precision", ",", "precision", "=", "precision", ")", "\n", "return", "eval_results", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_optimizer_hook.SiameseRPNOptimizerHook.__init__": [[17, 22], ["mmcv.runner.hooks.OptimizerHook.__init__"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "backbone_start_train_epoch", ",", "backbone_train_layers", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SiameseRPNOptimizerHook", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "backbone_start_train_epoch", "=", "backbone_start_train_epoch", "\n", "self", ".", "backbone_train_layers", "=", "backbone_train_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_optimizer_hook.SiameseRPNOptimizerHook.before_train_epoch": [[23, 35], ["getattr().parameters", "getattr().modules", "isinstance", "getattr", "getattr", "m.train"], "methods", ["None"], ["", "def", "before_train_epoch", "(", "self", ",", "runner", ")", ":", "\n", "        ", "\"\"\"If `runner.epoch >= self.backbone_start_train_epoch`, start to train\n        the backbone.\"\"\"", "\n", "if", "runner", ".", "epoch", ">=", "self", ".", "backbone_start_train_epoch", ":", "\n", "            ", "for", "layer", "in", "self", ".", "backbone_train_layers", ":", "\n", "                ", "for", "param", "in", "getattr", "(", "runner", ".", "model", ".", "module", ".", "backbone", ",", "\n", "layer", ")", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "for", "m", "in", "getattr", "(", "runner", ".", "model", ".", "module", ".", "backbone", ",", "\n", "layer", ")", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "train", "(", ")", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__": [[62, 90], ["mmcv.runner.hooks.LrUpdaterHook.__init__", "numpy.concatenate", "dict", "dict", "lr_type", "sot_lr_updater.SiameseRPNLrUpdaterHook.lr_intervals.append", "lr_config.pop"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "lr_configs", "=", "[", "\n", "dict", "(", "\n", "type", "=", "'step'", ",", "\n", "start_lr_factor", "=", "0.2", ",", "\n", "end_lr_factor", "=", "1.0", ",", "\n", "end_epoch", "=", "5", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'log'", ",", "\n", "start_lr_factor", "=", "1.0", ",", "\n", "end_lr_factor", "=", "0.1", ",", "\n", "end_epoch", "=", "20", ")", ",", "\n", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SiameseRPNLrUpdaterHook", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "assert", "self", ".", "by_epoch", "is", "True", "\n", "self", ".", "lr_intervals", "=", "[", "]", "\n", "\n", "start_epoch", "=", "0", "\n", "for", "lr_config", "in", "lr_configs", ":", "\n", "            ", "lr_type", "=", "self", ".", "lr_types", "[", "lr_config", ".", "pop", "(", "'type'", ")", "]", "\n", "lr_config", "[", "'start_epoch'", "]", "=", "start_epoch", "\n", "\n", "lr_intervals", "=", "lr_type", "(", "**", "lr_config", ")", "\n", "\n", "self", ".", "lr_intervals", ".", "append", "(", "lr_intervals", ")", "\n", "start_epoch", "=", "lr_config", "[", "'end_epoch'", "]", "\n", "", "self", ".", "lr_intervals", "=", "np", ".", "concatenate", "(", "self", ".", "lr_intervals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.get_lr": [[91, 94], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ",", "runner", ",", "base_lr", ")", ":", "\n", "        ", "\"\"\"Get a specifical learning rate for each epoch.\"\"\"", "\n", "return", "base_lr", "*", "self", ".", "lr_intervals", "[", "runner", ".", "epoch", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.step_lr_interval": [[7, 26], ["math.pow", "numpy.arange"], "function", ["None"], ["def", "step_lr_interval", "(", "start_lr_factor", ",", "end_lr_factor", ",", "start_epoch", ",", "end_epoch", ")", ":", "\n", "    ", "\"\"\"Exponentially varying learning rate.\n\n    Generator learning rate factor exponentially varying from `start_lr_factor`\n    to `end_lr_factor` in total `end_epoch - start_epoch` epochs.\n\n    Args:\n        start_lr_factor (float): Start learning rate factor.\n        end_lr_factor (float): End learning rate factor.\n        start_epoch (int): Start epoch.\n        end_epoch (int): End epoch.\n\n    Returns:\n        ndarray: The exponentially varying learning rate.\n    \"\"\"", "\n", "epochs", "=", "end_epoch", "-", "start_epoch", "\n", "mult", "=", "math", ".", "pow", "(", "end_lr_factor", "/", "start_lr_factor", ",", "1.", "/", "(", "epochs", ")", ")", "\n", "lr_intervals", "=", "start_lr_factor", "*", "(", "mult", "**", "np", ".", "arange", "(", "epochs", ")", ")", "\n", "return", "lr_intervals", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.log_lr_interval": [[28, 48], ["numpy.logspace", "math.log10", "math.log10"], "function", ["None"], ["", "def", "log_lr_interval", "(", "start_lr_factor", ",", "end_lr_factor", ",", "start_epoch", ",", "end_epoch", ")", ":", "\n", "    ", "\"\"\"Logarithmically varying learning rate.\n\n    Generator learning rate factor logarithmically varying from\n    `start_lr_factor` to `end_lr_factor` in total `end_epoch - start_epoch`\n    epochs.\n\n    Args:\n        start_lr_factor (float): Start learning rate factor.\n        end_lr_factor (float): End learning rate factor.\n        start_epoch (int): Start epoch.\n        end_epoch (int): End epoch.\n\n    Returns:\n        ndarray: The logarithmically varying learning rate.\n    \"\"\"", "\n", "epochs", "=", "end_epoch", "-", "start_epoch", "\n", "lr_intervals", "=", "np", ".", "logspace", "(", "\n", "math", ".", "log10", "(", "start_lr_factor", ")", ",", "math", ".", "log10", "(", "end_lr_factor", ")", ",", "epochs", ")", "\n", "return", "lr_intervals", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_reid.test_load_detections": [[7, 30], ["pytest.mark.parametrize", "mmtrack.models.REID.get", "model.", "model.eval", "torch.randn", "model.simple_test", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.simple_test"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "'model'", ",", "[", "'BaseReID'", "]", ")", "\n", "def", "test_load_detections", "(", "model", ")", ":", "\n", "    ", "model", "=", "REID", ".", "get", "(", "model", ")", "\n", "model", "=", "model", "(", "\n", "backbone", "=", "dict", "(", "\n", "type", "=", "'ResNet'", ",", "\n", "depth", "=", "50", ",", "\n", "num_stages", "=", "4", ",", "\n", "out_indices", "=", "(", "3", ",", ")", ",", "\n", "style", "=", "'pytorch'", ")", ",", "\n", "neck", "=", "dict", "(", "type", "=", "'GlobalAveragePooling'", ",", "kernel_size", "=", "(", "8", ",", "4", ")", ",", "stride", "=", "1", ")", ",", "\n", "head", "=", "dict", "(", "\n", "type", "=", "'LinearReIDHead'", ",", "\n", "num_fcs", "=", "1", ",", "\n", "in_channels", "=", "2048", ",", "\n", "fc_channels", "=", "1024", ",", "\n", "out_channels", "=", "128", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN1d'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "x", "=", "torch", ".", "randn", "(", "1", ",", "3", ",", "256", ",", "128", ")", "\n", "outputs", "=", "model", ".", "simple_test", "(", "x", ")", "\n", "assert", "outputs", ".", "shape", "==", "(", "1", ",", "128", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads.test_correlation_head": [[9, 15], ["mmtrack.models.track_heads.CorrelationHead", "torch.rand", "torch.rand", "mmtrack.models.track_heads.CorrelationHead.", "test_heads..size"], "function", ["None"], ["def", "test_correlation_head", "(", ")", ":", "\n", "    ", "self", "=", "CorrelationHead", "(", "16", ",", "16", ",", "2", ")", "\n", "kernel", "=", "torch", ".", "rand", "(", "1", ",", "16", ",", "7", ",", "7", ")", "\n", "search", "=", "torch", ".", "rand", "(", "1", ",", "16", ",", "31", ",", "31", ")", "\n", "out", "=", "self", "(", "kernel", ",", "search", ")", "\n", "assert", "out", ".", "size", "(", ")", "==", "(", "1", ",", "2", ",", "25", ",", "25", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads.test_siamese_rpn_head_loss": [[17, 76], ["mmcv.Config", "mmtrack.models.track_heads.SiameseRPNHead", "tuple", "tuple", "mmtrack.models.track_heads.SiameseRPNHead.forward", "mmtrack.models.track_heads.SiameseRPNHead.get_targets", "mmtrack.models.track_heads.SiameseRPNHead.loss", "mmtrack.models.track_heads.SiameseRPNHead.get_targets", "mmtrack.models.track_heads.SiameseRPNHead.loss", "dict", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "dict", "dict", "dict", "dict", "dict", "dict", "range", "range", "len", "len", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss"], ["", "def", "test_siamese_rpn_head_loss", "(", ")", ":", "\n", "    ", "\"\"\"Tests siamese rpn head loss when truth is non-empty.\"\"\"", "\n", "cfg", "=", "mmcv", ".", "Config", "(", "\n", "dict", "(", "\n", "anchor_generator", "=", "dict", "(", "\n", "type", "=", "'SiameseRPNAnchorGenerator'", ",", "\n", "strides", "=", "[", "8", "]", ",", "\n", "ratios", "=", "[", "0.33", ",", "0.5", ",", "1", ",", "2", ",", "3", "]", ",", "\n", "scales", "=", "[", "8", "]", ")", ",", "\n", "in_channels", "=", "[", "16", ",", "16", ",", "16", "]", ",", "\n", "weighted_sum", "=", "True", ",", "\n", "bbox_coder", "=", "dict", "(", "\n", "type", "=", "'DeltaXYWHBBoxCoder'", ",", "\n", "target_means", "=", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "target_stds", "=", "[", "1.", ",", "1.", ",", "1.", ",", "1.", "]", ")", ",", "\n", "loss_cls", "=", "dict", "(", "\n", "type", "=", "'CrossEntropyLoss'", ",", "reduction", "=", "'sum'", ",", "loss_weight", "=", "1.0", ")", ",", "\n", "loss_bbox", "=", "dict", "(", "type", "=", "'L1Loss'", ",", "reduction", "=", "'sum'", ",", "loss_weight", "=", "1.2", ")", ",", "\n", "train_cfg", "=", "dict", "(", "\n", "assigner", "=", "dict", "(", "\n", "type", "=", "'MaxIoUAssigner'", ",", "\n", "pos_iou_thr", "=", "0.6", ",", "\n", "neg_iou_thr", "=", "0.3", ",", "\n", "min_pos_iou", "=", "0.6", ",", "\n", "match_low_quality", "=", "False", ")", ",", "\n", "sampler", "=", "dict", "(", "\n", "type", "=", "'RandomSampler'", ",", "\n", "num", "=", "64", ",", "\n", "pos_fraction", "=", "0.25", ",", "\n", "add_gt_as_proposals", "=", "False", ")", ",", "\n", "num_neg", "=", "16", ",", "\n", "exemplar_size", "=", "127", ",", "\n", "search_size", "=", "255", ")", ",", "\n", "test_cfg", "=", "dict", "(", "penalty_k", "=", "0.05", ",", "window_influence", "=", "0.42", ",", "lr", "=", "0.38", ")", ")", ")", "\n", "\n", "self", "=", "SiameseRPNHead", "(", "**", "cfg", ")", "\n", "\n", "z_feats", "=", "tuple", "(", "\n", "[", "torch", ".", "rand", "(", "1", ",", "16", ",", "7", ",", "7", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cls_heads", ")", ")", "]", ")", "\n", "x_feats", "=", "tuple", "(", "\n", "[", "torch", ".", "rand", "(", "1", ",", "16", ",", "31", ",", "31", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cls_heads", ")", ")", "]", ")", "\n", "cls_score", ",", "bbox_pred", "=", "self", ".", "forward", "(", "z_feats", ",", "x_feats", ")", "\n", "\n", "gt_bboxes", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "[", "0.", ",", "23.6667", ",", "23.8757", ",", "238.6326", ",", "151.8874", "]", "]", ")", ",", "\n", "]", "\n", "bbox_targets", "=", "self", ".", "get_targets", "(", "gt_bboxes", ",", "cls_score", ".", "shape", "[", "2", ":", "]", ",", "[", "True", "]", ")", "\n", "gt_losses", "=", "self", ".", "loss", "(", "cls_score", ",", "bbox_pred", ",", "*", "bbox_targets", ")", "\n", "assert", "gt_losses", "[", "'loss_rpn_cls'", "]", ">", "0", ",", "'cls loss should be non-zero'", "\n", "assert", "gt_losses", "[", "\n", "'loss_rpn_bbox'", "]", ">=", "0", ",", "'box loss should be non-zero or zero'", "\n", "\n", "gt_bboxes", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "[", "0.", ",", "23.6667", ",", "23.8757", ",", "238.6326", ",", "151.8874", "]", "]", ")", ",", "\n", "]", "\n", "bbox_targets", "=", "self", ".", "get_targets", "(", "gt_bboxes", ",", "cls_score", ".", "shape", "[", "2", ":", "]", ",", "[", "False", "]", ")", "\n", "gt_losses", "=", "self", ".", "loss", "(", "cls_score", ",", "bbox_pred", ",", "*", "bbox_targets", ")", "\n", "assert", "gt_losses", "[", "'loss_rpn_cls'", "]", ">", "0", ",", "'cls loss should be non-zero'", "\n", "assert", "gt_losses", "[", "'loss_rpn_bbox'", "]", "==", "0", ",", "'box loss should be zero'", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads.test_selsa_bbox_head_loss": [[78, 143], ["dict", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead", "mmcv.Config", "test_heads._dummy_bbox_sampling", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.get_targets", "sum", "mmdet.core.bbox2roi", "torch.rand", "torch.rand", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.forward", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.loss", "test_heads._dummy_bbox_sampling", "mmdet.core.bbox2roi", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.get_targets", "sum", "torch.rand", "torch.rand", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.forward", "mmtrack.models.roi_heads.bbox_heads.SelsaBBoxHead.loss", "torch.Tensor", "dict", "torch.empty", "torch.LongTensor", "test_heads..get", "test_heads..get", "torch.Tensor", "torch.LongTensor", "test_heads..get", "test_heads..get", "dict", "len", "len"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads._dummy_bbox_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads._dummy_bbox_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.get_targets", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track_heads.siamese_rpn_head.SiameseRPNHead.loss", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.empty", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "test_selsa_bbox_head_loss", "(", ")", ":", "\n", "    ", "\"\"\"Tests selsa_bbox_head loss when truth is empty and non-empty.\"\"\"", "\n", "selsa_bbox_head_config", "=", "dict", "(", "\n", "num_shared_fcs", "=", "2", ",", "\n", "in_channels", "=", "8", ",", "\n", "fc_out_channels", "=", "16", ",", "\n", "roi_feat_size", "=", "3", ",", "\n", "aggregator", "=", "dict", "(", "\n", "type", "=", "'SelsaAggregator'", ",", "in_channels", "=", "16", ",", "num_attention_blocks", "=", "4", ")", ")", "\n", "self", "=", "SelsaBBoxHead", "(", "**", "selsa_bbox_head_config", ")", "\n", "\n", "# Dummy proposals", "\n", "proposal_list", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "[", "23.6667", ",", "23.8757", ",", "228.6326", ",", "153.8874", "]", "]", ")", ",", "\n", "]", "\n", "\n", "target_cfg", "=", "mmcv", ".", "Config", "(", "dict", "(", "pos_weight", "=", "1", ")", ")", "\n", "\n", "# Test bbox loss when truth is empty", "\n", "gt_bboxes", "=", "[", "torch", ".", "empty", "(", "(", "0", ",", "4", ")", ")", "]", "\n", "gt_labels", "=", "[", "torch", ".", "LongTensor", "(", "[", "]", ")", "]", "\n", "\n", "sampling_results", "=", "_dummy_bbox_sampling", "(", "proposal_list", ",", "gt_bboxes", ",", "\n", "gt_labels", ")", "\n", "\n", "bbox_targets", "=", "self", ".", "get_targets", "(", "sampling_results", ",", "gt_bboxes", ",", "gt_labels", ",", "\n", "target_cfg", ")", "\n", "labels", ",", "label_weights", ",", "bbox_targets", ",", "bbox_weights", "=", "bbox_targets", "\n", "\n", "# Create dummy features \"extracted\" for each sampled bbox", "\n", "num_sampled", "=", "sum", "(", "len", "(", "res", ".", "bboxes", ")", "for", "res", "in", "sampling_results", ")", "\n", "rois", "=", "bbox2roi", "(", "[", "res", ".", "bboxes", "for", "res", "in", "sampling_results", "]", ")", "\n", "dummy_feats", "=", "torch", ".", "rand", "(", "num_sampled", ",", "8", ",", "3", ",", "3", ")", "\n", "ref_dummy_feats", "=", "torch", ".", "rand", "(", "2", "*", "num_sampled", ",", "8", ",", "3", ",", "3", ")", "\n", "cls_scores", ",", "bbox_preds", "=", "self", ".", "forward", "(", "dummy_feats", ",", "ref_dummy_feats", ")", "\n", "\n", "losses", "=", "self", ".", "loss", "(", "cls_scores", ",", "bbox_preds", ",", "rois", ",", "labels", ",", "label_weights", ",", "\n", "bbox_targets", ",", "bbox_weights", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ",", "0", ")", ">", "0", ",", "'cls-loss should be non-zero'", "\n", "assert", "losses", ".", "get", "(", "'loss_bbox'", ",", "0", ")", "==", "0", ",", "'empty gt loss should be zero'", "\n", "\n", "# Test bbox loss when truth is non-empty", "\n", "gt_bboxes", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "[", "23.6667", ",", "23.8757", ",", "238.6326", ",", "151.8874", "]", "]", ")", ",", "\n", "]", "\n", "gt_labels", "=", "[", "torch", ".", "LongTensor", "(", "[", "2", "]", ")", "]", "\n", "\n", "sampling_results", "=", "_dummy_bbox_sampling", "(", "proposal_list", ",", "gt_bboxes", ",", "\n", "gt_labels", ")", "\n", "rois", "=", "bbox2roi", "(", "[", "res", ".", "bboxes", "for", "res", "in", "sampling_results", "]", ")", "\n", "\n", "bbox_targets", "=", "self", ".", "get_targets", "(", "sampling_results", ",", "gt_bboxes", ",", "gt_labels", ",", "\n", "target_cfg", ")", "\n", "labels", ",", "label_weights", ",", "bbox_targets", ",", "bbox_weights", "=", "bbox_targets", "\n", "\n", "# Create dummy features \"extracted\" for each sampled bbox", "\n", "num_sampled", "=", "sum", "(", "len", "(", "res", ".", "bboxes", ")", "for", "res", "in", "sampling_results", ")", "\n", "dummy_feats", "=", "torch", ".", "rand", "(", "num_sampled", ",", "8", ",", "3", ",", "3", ")", "\n", "ref_dummy_feats", "=", "torch", ".", "rand", "(", "2", "*", "num_sampled", ",", "8", ",", "3", ",", "3", ")", "\n", "cls_scores", ",", "bbox_preds", "=", "self", ".", "forward", "(", "dummy_feats", ",", "ref_dummy_feats", ")", "\n", "\n", "losses", "=", "self", ".", "loss", "(", "cls_scores", ",", "bbox_preds", ",", "rois", ",", "labels", ",", "label_weights", ",", "\n", "bbox_targets", ",", "bbox_weights", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ",", "0", ")", ">", "0", ",", "'cls-loss should be non-zero'", "\n", "assert", "losses", ".", "get", "(", "'loss_bbox'", ",", "0", ")", ">", "0", ",", "'box-loss should be non-zero'", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_heads._dummy_bbox_sampling": [[145, 177], ["torch.rand", "dict", "dict", "mmdet.core.build_assigner", "mmdet.core.build_sampler", "range", "mmdet.core.build_assigner.assign", "mmdet.core.build_sampler.sample", "sampling_results.append", "range"], "function", ["None"], ["", "def", "_dummy_bbox_sampling", "(", "proposal_list", ",", "gt_bboxes", ",", "gt_labels", ")", ":", "\n", "    ", "\"\"\"Create sample results that can be passed to BBoxHead.get_targets.\"\"\"", "\n", "num_imgs", "=", "1", "\n", "feat", "=", "torch", ".", "rand", "(", "1", ",", "1", ",", "3", ",", "3", ")", "\n", "assign_config", "=", "dict", "(", "\n", "type", "=", "'MaxIoUAssigner'", ",", "\n", "pos_iou_thr", "=", "0.5", ",", "\n", "neg_iou_thr", "=", "0.5", ",", "\n", "min_pos_iou", "=", "0.5", ",", "\n", "ignore_iof_thr", "=", "-", "1", ")", "\n", "sampler_config", "=", "dict", "(", "\n", "type", "=", "'RandomSampler'", ",", "\n", "num", "=", "512", ",", "\n", "pos_fraction", "=", "0.25", ",", "\n", "neg_pos_ub", "=", "-", "1", ",", "\n", "add_gt_as_proposals", "=", "True", ")", "\n", "bbox_assigner", "=", "build_assigner", "(", "assign_config", ")", "\n", "bbox_sampler", "=", "build_sampler", "(", "sampler_config", ")", "\n", "gt_bboxes_ignore", "=", "[", "None", "for", "_", "in", "range", "(", "num_imgs", ")", "]", "\n", "sampling_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_imgs", ")", ":", "\n", "        ", "assign_result", "=", "bbox_assigner", ".", "assign", "(", "proposal_list", "[", "i", "]", ",", "gt_bboxes", "[", "i", "]", ",", "\n", "gt_bboxes_ignore", "[", "i", "]", ",", "gt_labels", "[", "i", "]", ")", "\n", "sampling_result", "=", "bbox_sampler", ".", "sample", "(", "\n", "assign_result", ",", "\n", "proposal_list", "[", "i", "]", ",", "\n", "gt_bboxes", "[", "i", "]", ",", "\n", "gt_labels", "[", "i", "]", ",", "\n", "feats", "=", "feat", ")", "\n", "sampling_results", ".", "append", "(", "sampling_result", ")", "\n", "\n", "", "return", "sampling_results", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_motion.test_flownet_simple": [[9, 24], ["mmtrack.models.motion.FlowNetSimple", "mmtrack.models.motion.FlowNetSimple.init_weights", "mmtrack.models.motion.FlowNetSimple.train", "torch.randn", "mmtrack.models.motion.FlowNetSimple.", "dict", "torch.Size", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["def", "test_flownet_simple", "(", ")", ":", "\n", "# Test flownet_simple forward", "\n", "    ", "model", "=", "FlowNetSimple", "(", "img_scale_factor", "=", "0.5", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "imgs", "=", "torch", ".", "randn", "(", "2", ",", "6", ",", "224", ",", "224", ")", "\n", "img_metas", "=", "[", "\n", "dict", "(", "\n", "img_norm_cfg", "=", "dict", "(", "\n", "mean", "=", "(", "123.675", ",", "116.28", ",", "103.53", ")", ",", "std", "=", "(", "58.395", ",", "57.12", ",", "57.375", ")", ")", ",", "\n", "img_shape", "=", "(", "224", ",", "224", ",", "3", ")", ")", "\n", "]", "\n", "flow", "=", "model", "(", "imgs", ",", "img_metas", ")", "\n", "assert", "flow", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "2", ",", "224", ",", "224", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_motion.test_cmc": [[26, 37], ["mmtrack.models.motion.CameraMotionCompensation", "numpy.random.randn().astype", "mmtrack.models.motion.CameraMotionCompensation.get_warp_matrix", "isinstance", "mmdet.core.bbox.demodata.random_boxes", "mmtrack.models.motion.CameraMotionCompensation.warp_bboxes", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.get_warp_matrix", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.camera_motion_compensation.CameraMotionCompensation.warp_bboxes"], ["", "def", "test_cmc", "(", ")", ":", "\n", "    ", "cmc", "=", "CameraMotionCompensation", "(", ")", "\n", "img", "=", "np", ".", "random", ".", "randn", "(", "256", ",", "256", ",", "3", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "ref_img", "=", "img", "\n", "\n", "warp_matrix", "=", "cmc", ".", "get_warp_matrix", "(", "img", ",", "ref_img", ")", "\n", "assert", "isinstance", "(", "warp_matrix", ",", "torch", ".", "Tensor", ")", "\n", "\n", "bboxes", "=", "random_boxes", "(", "5", ",", "256", ")", "\n", "trans_bboxes", "=", "cmc", ".", "warp_bboxes", "(", "bboxes", ",", "warp_matrix", ")", "\n", "assert", "(", "bboxes", "==", "trans_bboxes", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_motion.test_linear_motion": [[39, 63], ["mmtrack.models.motion.LinearMotion", "mmtrack.models.motion.LinearMotion.step", "mmtrack.models.motion.LinearMotion", "mmtrack.models.motion.LinearMotion.step", "mmtrack.models.motion.LinearMotion", "mmtrack.models.motion.LinearMotion.step", "mmtrack.models.motion.LinearMotion", "mmtrack.models.motion.LinearMotion.step", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.linear_motion.LinearMotion.step"], ["", "def", "test_linear_motion", "(", ")", ":", "\n", "    ", "linear_motion", "=", "LinearMotion", "(", "num_samples", "=", "2", ",", "center_motion", "=", "False", ")", "\n", "bboxes", "=", "[", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "[", "6", ",", "6", ",", "6", ",", "6", "]", "]", "\n", "bboxes", "=", "[", "torch", ".", "tensor", "(", "_", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "_", "in", "bboxes", "]", "\n", "bbox", "=", "linear_motion", ".", "step", "(", "bboxes", ")", "\n", "assert", "(", "bbox", "==", "torch", ".", "tensor", "(", "[", "9.", ",", "9.", ",", "9.", ",", "9.", "]", ")", ")", ".", "all", "(", ")", "\n", "\n", "linear_motion", "=", "LinearMotion", "(", "num_samples", "=", "3", ",", "center_motion", "=", "False", ")", "\n", "bboxes", "=", "[", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "[", "6", ",", "6", ",", "6", ",", "6", "]", "]", "\n", "bboxes", "=", "[", "torch", ".", "tensor", "(", "_", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "_", "in", "bboxes", "]", "\n", "bbox", "=", "linear_motion", ".", "step", "(", "bboxes", ")", "\n", "assert", "(", "bbox", "==", "torch", ".", "tensor", "(", "[", "8.5", ",", "8.5", ",", "8.5", ",", "8.5", "]", ")", ")", ".", "all", "(", ")", "\n", "\n", "linear_motion", "=", "LinearMotion", "(", "num_samples", "=", "4", ",", "center_motion", "=", "False", ")", "\n", "bboxes", "=", "[", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "[", "6", ",", "6", ",", "6", ",", "6", "]", "]", "\n", "bboxes", "=", "[", "torch", ".", "tensor", "(", "_", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "_", "in", "bboxes", "]", "\n", "bbox", "=", "linear_motion", ".", "step", "(", "bboxes", ")", "\n", "assert", "(", "bbox", "==", "torch", ".", "tensor", "(", "[", "8.5", ",", "8.5", ",", "8.5", ",", "8.5", "]", ")", ")", ".", "all", "(", ")", "\n", "\n", "linear_motion", "=", "LinearMotion", "(", "num_samples", "=", "4", ",", "center_motion", "=", "True", ")", "\n", "bboxes", "=", "[", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "[", "6", ",", "6", ",", "6", ",", "6", "]", "]", "\n", "bboxes", "=", "[", "torch", ".", "tensor", "(", "_", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "_", "in", "bboxes", "]", "\n", "bbox", "=", "linear_motion", ".", "step", "(", "bboxes", ")", "\n", "assert", "(", "bbox", "==", "torch", ".", "tensor", "(", "[", "8.5", ",", "8.5", ",", "8.5", ",", "8.5", "]", ")", ")", ".", "all", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_backbones.test_sot_resnet_backbone": [[7, 38], ["dict", "mmtrack.models.backbones.SOTResNet", "mmtrack.models.backbones.SOTResNet.init_weights", "mmtrack.models.backbones.SOTResNet.train", "torch.randn", "mmtrack.models.backbones.SOTResNet.", "torch.randn", "mmtrack.models.backbones.SOTResNet.", "pytest.raises", "mmtrack.models.backbones.SOTResNet", "len", "torch.Size", "torch.Size", "torch.Size", "len", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.siamrpn.SiamRPN.init_weights"], ["def", "test_sot_resnet_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test sot resnet backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# ResNet depth should be 50", "\n", "        ", "SOTResNet", "(", "20", ")", "\n", "\n", "# Test SOTResNet50 with layers 2, 3, 4 out forward", "\n", "", "cfg", "=", "dict", "(", "\n", "depth", "=", "50", ",", "\n", "out_indices", "=", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "frozen_stages", "=", "4", ",", "\n", "strides", "=", "(", "1", ",", "2", ",", "1", ",", "1", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "2", ",", "4", ")", ",", "\n", "norm_eval", "=", "True", ")", "\n", "model", "=", "SOTResNet", "(", "**", "cfg", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "imgs", "=", "torch", ".", "randn", "(", "1", ",", "3", ",", "127", ",", "127", ")", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "3", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "15", ",", "15", "]", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "1024", ",", "15", ",", "15", "]", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "15", ",", "15", "]", ")", "\n", "\n", "imgs", "=", "torch", ".", "randn", "(", "1", ",", "3", ",", "255", ",", "255", ")", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "3", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "31", ",", "31", "]", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "1024", ",", "31", ",", "31", "]", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "31", ",", "31", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_tracker.TestBaseTracker.setup_class": [[9, 30], ["dict", "mmtrack.models.TRACKERS.get", "mmtrack.models.TRACKERS.get.", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["    ", "@", "classmethod", "\n", "def", "setup_class", "(", "cls", ")", ":", "\n", "        ", "cfg", "=", "dict", "(", "\n", "obj_score_thr", "=", "0.3", ",", "\n", "regression", "=", "dict", "(", "\n", "obj_score_thr", "=", "0.5", ",", "\n", "nms", "=", "dict", "(", "type", "=", "'nms'", ",", "iou_threshold", "=", "0.6", ")", ",", "\n", "match_iou_thr", "=", "0.3", ")", ",", "\n", "reid", "=", "dict", "(", "\n", "num_samples", "=", "10", ",", "\n", "img_scale", "=", "(", "256", ",", "128", ")", ",", "\n", "img_norm_cfg", "=", "None", ",", "\n", "match_score_thr", "=", "2.0", ",", "\n", "match_iou_thr", "=", "0.2", ")", ",", "\n", "momentums", "=", "dict", "(", "embeds", "=", "0.5", ")", ",", "\n", "num_frames_retain", "=", "5", ")", "\n", "tracker", "=", "TRACKERS", ".", "get", "(", "'TracktorTracker'", ")", "\n", "cls", ".", "tracker", "=", "tracker", "(", "**", "cfg", ")", "\n", "cls", ".", "momentums", "=", "cfg", "[", "'momentums'", "]", "\n", "cls", ".", "num_frames_retain", "=", "cfg", "[", "'num_frames_retain'", "]", "\n", "cls", ".", "num_objs", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_tracker.TestBaseTracker.test_init": [[31, 48], ["mmdet.core.bbox.demodata.random_boxes", "torch.zeros", "torch.randn", "torch.arange", "test_tracker.TestBaseTracker.tracker.update", "test_tracker.TestBaseTracker.tracker.tracks[].items", "list", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "def", "test_init", "(", "self", ")", ":", "\n", "        ", "bboxes", "=", "random_boxes", "(", "self", ".", "num_objs", ",", "512", ")", "\n", "labels", "=", "torch", ".", "zeros", "(", "self", ".", "num_objs", ")", "\n", "embeds", "=", "torch", ".", "randn", "(", "self", ".", "num_objs", ",", "256", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "self", ".", "num_objs", ")", "\n", "self", ".", "tracker", ".", "update", "(", "\n", "ids", "=", "ids", ",", "bboxes", "=", "bboxes", ",", "labels", "=", "labels", ",", "embeds", "=", "embeds", ",", "frame_ids", "=", "0", ")", "\n", "\n", "assert", "self", ".", "tracker", ".", "ids", "==", "list", "(", "ids", ")", "\n", "assert", "self", ".", "tracker", ".", "memo_items", "==", "[", "\n", "'ids'", ",", "'bboxes'", ",", "'labels'", ",", "'embeds'", ",", "'frame_ids'", "\n", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "tracker", ".", "tracks", "[", "0", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "momentums", ":", "\n", "                ", "assert", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "v", ",", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_tracker.TestBaseTracker.test_update": [[49, 65], ["range", "mmdet.core.bbox.demodata.random_boxes", "torch.zeros", "torch.randn", "test_tracker.TestBaseTracker.tracker.update", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.update"], ["", "", "", "def", "test_update", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "self", ".", "num_frames_retain", "*", "2", ")", ":", "\n", "            ", "bboxes", "=", "random_boxes", "(", "self", ".", "num_objs", ",", "512", ")", "\n", "labels", "=", "torch", ".", "zeros", "(", "self", ".", "num_objs", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "embeds", "=", "torch", ".", "randn", "(", "self", ".", "num_objs", ",", "256", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "self", ".", "num_objs", ")", "+", "i", "\n", "self", ".", "tracker", ".", "update", "(", "\n", "ids", "=", "ids", ",", "\n", "bboxes", "=", "bboxes", ",", "\n", "labels", "=", "labels", ",", "\n", "embeds", "=", "embeds", ",", "\n", "frame_ids", "=", "i", ")", "\n", "if", "i", "<", "self", ".", "num_frames_retain", ":", "\n", "                ", "assert", "0", "in", "self", ".", "tracker", ".", "tracks", "\n", "", "else", ":", "\n", "                ", "assert", "0", "not", "in", "self", ".", "tracker", ".", "tracks", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_tracker.TestBaseTracker.test_memo": [[66, 72], ["torch.arange"], "methods", ["None"], ["", "", "", "def", "test_memo", "(", "self", ")", ":", "\n", "        ", "memo", "=", "self", ".", "tracker", ".", "memo", "\n", "num_tracks", "=", "self", ".", "num_frames_retain", "*", "2", "-", "1", "\n", "assert", "(", "memo", ".", "ids", "==", "torch", ".", "arange", "(", "\n", "self", ".", "num_frames_retain", ",", "self", ".", "num_frames_retain", "*", "3", "-", "1", ")", ")", ".", "all", "(", ")", "\n", "assert", "memo", ".", "bboxes", ".", "shape", "[", "0", "]", "==", "num_tracks", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_tracker.TestBaseTracker.test_get": [[73, 85], ["test_tracker.TestBaseTracker.tracker.get", "test_tracker.TestBaseTracker.tracker.get", "test_tracker.TestBaseTracker.tracker.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "test_get", "(", "self", ")", ":", "\n", "        ", "ids", "=", "[", "self", ".", "num_frames_retain", "+", "1", ",", "self", ".", "num_frames_retain", "+", "2", "]", "\n", "\n", "bboxes", "=", "self", ".", "tracker", ".", "get", "(", "'bboxes'", ",", "ids", ")", "\n", "assert", "bboxes", ".", "shape", "==", "(", "2", ",", "4", ")", "\n", "\n", "bboxes", "=", "self", ".", "tracker", ".", "get", "(", "'bboxes'", ",", "ids", ",", "num_samples", "=", "2", ")", "\n", "assert", "bboxes", ".", "shape", "==", "(", "2", ",", "2", ",", "4", ")", "\n", "\n", "bboxes", "=", "self", ".", "tracker", ".", "get", "(", "\n", "'bboxes'", ",", "ids", ",", "num_samples", "=", "2", ",", "behavior", "=", "'mean'", ")", "\n", "assert", "bboxes", ".", "shape", "==", "(", "2", ",", "4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_directory": [[10, 23], ["os.path.join", "os.path.dirname", "os.path.exists", "Exception", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["def", "_get_config_directory", "(", ")", ":", "\n", "    ", "\"\"\"Find the predefined video detector or tracker config directory.\"\"\"", "\n", "try", ":", "\n", "# Assume we are running in the source mmtracking repo", "\n", "        ", "repo_dpath", "=", "dirname", "(", "dirname", "(", "dirname", "(", "__file__", ")", ")", ")", "\n", "", "except", "NameError", ":", "\n", "# For IPython development when this __file__ is not defined", "\n", "        ", "import", "mmtrack", "\n", "repo_dpath", "=", "dirname", "(", "dirname", "(", "mmtrack", ".", "__file__", ")", ")", "\n", "", "config_dpath", "=", "join", "(", "repo_dpath", ",", "'configs'", ")", "\n", "if", "not", "exists", "(", "config_dpath", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Cannot find config path'", ")", "\n", "", "return", "config_dpath", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module": [[25, 32], ["test_forward._get_config_directory", "os.path.join", "Config.fromfile"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_directory"], ["", "def", "_get_config_module", "(", "fname", ")", ":", "\n", "    ", "\"\"\"Load a configuration as a python module.\"\"\"", "\n", "from", "mmcv", "import", "Config", "\n", "config_dpath", "=", "_get_config_directory", "(", ")", "\n", "config_fpath", "=", "join", "(", "config_dpath", ",", "fname", ")", "\n", "config_mod", "=", "Config", ".", "fromfile", "(", "config_fpath", ")", "\n", "return", "config_mod", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_model_cfg": [[34, 46], ["test_forward._get_config_module", "copy.deepcopy", "mmcv.Config", "mmcv.Config", "copy.deepcopy", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module"], ["", "def", "_get_model_cfg", "(", "fname", ")", ":", "\n", "    ", "\"\"\"Grab configs necessary to create a video detector or tracker.\n\n    These are deep copied to allow for safe modification of parameters without\n    influencing other tests.\n    \"\"\"", "\n", "import", "mmcv", "\n", "config", "=", "_get_config_module", "(", "fname", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "config", ".", "model", ")", "\n", "train_cfg", "=", "mmcv", ".", "Config", "(", "copy", ".", "deepcopy", "(", "config", ".", "train_cfg", ")", ")", "\n", "test_cfg", "=", "mmcv", ".", "Config", "(", "copy", ".", "deepcopy", "(", "config", ".", "test_cfg", ")", ")", "\n", "return", "model", ",", "train_cfg", ",", "test_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward.test_sot_forward": [[48, 120], ["pytest.mark.parametrize", "test_forward._get_config_module", "copy.deepcopy", "build_model", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "search_gt_bboxes[].new_full", "torch.cat", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "_demo_mm_inputs.pop", "float", "float", "torch.no_grad", "torch.cat", "mm_inputs.pop.extend", "range", "gt_bboxes.extend", "collections.defaultdict", "zip", "search_gt_bboxes[].size", "loss.item", "loss.item", "copy.deepcopy", "len", "copy.deepcopy", "build_model.forward", "tracktor.forward.items", "torch.cat.clone", "results[].append"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'cfg_file'", ",", "\n", "[", "'sot/siamese_rpn/siamese_rpn_r50_1x_lasot.py'", "]", ")", "\n", "def", "test_sot_forward", "(", "cfg_file", ")", ":", "\n", "    ", "config", "=", "_get_config_module", "(", "cfg_file", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "config", ".", "model", ")", "\n", "model", ".", "pretrains", "=", "None", "\n", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "tracktor", "=", "build_model", "(", "model", ")", "\n", "\n", "# Test forward train with a non-empty truth batch", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "127", ",", "127", ")", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "1", "]", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "gt_bboxes", "=", "mm_inputs", "[", "'gt_bboxes'", "]", "\n", "\n", "search_input_shape", "=", "(", "1", ",", "3", ",", "255", ",", "255", ")", "\n", "search_mm_inputs", "=", "_demo_mm_inputs", "(", "search_input_shape", ",", "num_items", "=", "[", "1", "]", ")", "\n", "search_img", "=", "search_mm_inputs", ".", "pop", "(", "'imgs'", ")", "[", "None", "]", "\n", "search_img_metas", "=", "search_mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "search_gt_bboxes", "=", "search_mm_inputs", "[", "'gt_bboxes'", "]", "\n", "img_inds", "=", "search_gt_bboxes", "[", "0", "]", ".", "new_full", "(", "(", "search_gt_bboxes", "[", "0", "]", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "0", ")", "\n", "search_gt_bboxes", "[", "0", "]", "=", "torch", ".", "cat", "(", "(", "img_inds", ",", "search_gt_bboxes", "[", "0", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "losses", "=", "tracktor", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "search_img", "=", "search_img", ",", "\n", "search_img_metas", "=", "search_img_metas", ",", "\n", "search_gt_bboxes", "=", "search_gt_bboxes", ",", "\n", "is_positive_pairs", "=", "[", "True", "]", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "tracktor", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "losses", "=", "tracktor", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "search_img", "=", "search_img", ",", "\n", "search_img_metas", "=", "search_img_metas", ",", "\n", "search_gt_bboxes", "=", "search_gt_bboxes", ",", "\n", "is_positive_pairs", "=", "[", "False", "]", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "tracktor", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "imgs", "=", "torch", ".", "cat", "(", "[", "imgs", ",", "imgs", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "img_list", "=", "[", "g", "[", "None", ",", ":", "]", "for", "g", "in", "imgs", "]", "\n", "img_metas", ".", "extend", "(", "copy", ".", "deepcopy", "(", "img_metas", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "img_metas", ")", ")", ":", "\n", "            ", "img_metas", "[", "i", "]", "[", "'frame_id'", "]", "=", "i", "\n", "", "gt_bboxes", ".", "extend", "(", "copy", ".", "deepcopy", "(", "gt_bboxes", ")", ")", "\n", "results", "=", "defaultdict", "(", "list", ")", "\n", "for", "one_img", ",", "one_meta", ",", "one_gt_bboxes", "in", "zip", "(", "img_list", ",", "img_metas", ",", "\n", "gt_bboxes", ")", ":", "\n", "            ", "result", "=", "tracktor", ".", "forward", "(", "[", "one_img", "]", ",", "[", "[", "one_meta", "]", "]", ",", "\n", "gt_bboxes", "=", "[", "one_gt_bboxes", "]", ",", "\n", "return_loss", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                ", "results", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward.test_vid_dff_style_forward": [[122, 219], ["pytest.mark.parametrize", "test_forward._get_config_module", "copy.deepcopy", "build_model", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "_demo_mm_inputs.pop", "float", "_demo_mm_inputs.pop", "float", "torch.no_grad", "torch.cat", "mm_inputs.pop.extend", "range", "collections.defaultdict", "zip", "loss.item", "loss.item", "copy.deepcopy", "len", "build_model.forward", "detector.forward.items", "torch.cat.clone", "results[].append"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward"], ["", "", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "'cfg_file'", ",", "[", "'vid/dff/dff_faster_rcnn_r101_dc5_1x_imagenetvid.py'", "]", ")", "\n", "def", "test_vid_dff_style_forward", "(", "cfg_file", ")", ":", "\n", "    ", "config", "=", "_get_config_module", "(", "cfg_file", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "config", ".", "model", ")", "\n", "model", ".", "pretrains", "=", "None", "\n", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "detector", "=", "build_model", "(", "model", ")", "\n", "\n", "# Test forward train with a non-empty truth batch", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "256", ",", "256", ")", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "10", "]", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "gt_bboxes", "=", "mm_inputs", "[", "'gt_bboxes'", "]", "\n", "gt_labels", "=", "mm_inputs", "[", "'gt_labels'", "]", "\n", "gt_masks", "=", "mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "ref_input_shape", "=", "(", "1", ",", "3", ",", "256", ",", "256", ")", "\n", "ref_mm_inputs", "=", "_demo_mm_inputs", "(", "ref_input_shape", ",", "num_items", "=", "[", "11", "]", ")", "\n", "ref_img", "=", "ref_mm_inputs", ".", "pop", "(", "'imgs'", ")", "[", "None", "]", "\n", "ref_img_metas", "=", "ref_mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "ref_img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_gt_bboxes", "=", "ref_mm_inputs", "[", "'gt_bboxes'", "]", "\n", "ref_gt_labels", "=", "ref_mm_inputs", "[", "'gt_labels'", "]", "\n", "ref_gt_masks", "=", "ref_mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "losses", "=", "detector", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "ref_img", "=", "ref_img", ",", "\n", "ref_img_metas", "=", "ref_img_metas", ",", "\n", "ref_gt_bboxes", "=", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", "=", "ref_gt_labels", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", "ref_gt_masks", "=", "ref_gt_masks", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "detector", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Test forward train with an empty truth batch", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "0", "]", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "gt_bboxes", "=", "mm_inputs", "[", "'gt_bboxes'", "]", "\n", "gt_labels", "=", "mm_inputs", "[", "'gt_labels'", "]", "\n", "gt_masks", "=", "mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "ref_input_shape", "=", "(", "1", ",", "3", ",", "256", ",", "256", ")", "\n", "ref_mm_inputs", "=", "_demo_mm_inputs", "(", "ref_input_shape", ",", "num_items", "=", "[", "0", "]", ")", "\n", "ref_img", "=", "ref_mm_inputs", ".", "pop", "(", "'imgs'", ")", "[", "None", "]", "\n", "ref_img_metas", "=", "ref_mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "ref_img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_gt_bboxes", "=", "ref_mm_inputs", "[", "'gt_bboxes'", "]", "\n", "ref_gt_labels", "=", "ref_mm_inputs", "[", "'gt_labels'", "]", "\n", "ref_gt_masks", "=", "ref_mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "losses", "=", "detector", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "ref_img", "=", "ref_img", ",", "\n", "ref_img_metas", "=", "ref_img_metas", ",", "\n", "ref_gt_bboxes", "=", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", "=", "ref_gt_labels", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", "ref_gt_masks", "=", "ref_gt_masks", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "detector", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "imgs", "=", "torch", ".", "cat", "(", "[", "imgs", ",", "imgs", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "img_list", "=", "[", "g", "[", "None", ",", ":", "]", "for", "g", "in", "imgs", "]", "\n", "img_metas", ".", "extend", "(", "copy", ".", "deepcopy", "(", "img_metas", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "img_metas", ")", ")", ":", "\n", "            ", "img_metas", "[", "i", "]", "[", "'frame_id'", "]", "=", "i", "\n", "", "results", "=", "defaultdict", "(", "list", ")", "\n", "for", "one_img", ",", "one_meta", "in", "zip", "(", "img_list", ",", "img_metas", ")", ":", "\n", "            ", "result", "=", "detector", ".", "forward", "(", "[", "one_img", "]", ",", "[", "[", "one_meta", "]", "]", ",", "\n", "return_loss", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                ", "results", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward.test_vid_fgfa_style_forward": [[221, 331], ["pytest.mark.parametrize", "test_forward._get_config_module", "copy.deepcopy", "build_model", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "build_model.forward", "isinstance", "build_model._parse_losses", "loss.requires_grad_", "loss.backward", "_demo_mm_inputs.pop", "float", "_demo_mm_inputs.pop", "float", "torch.no_grad", "torch.cat", "mm_inputs.pop.extend", "range", "collections.defaultdict", "zip", "loss.item", "loss.item", "copy.deepcopy", "len", "ref_imgs.clone", "[].clone", "copy.deepcopy", "copy.deepcopy", "build_model.forward", "detector.forward.items", "torch.cat.clone", "results[].append"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker._parse_losses", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward"], ["", "", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'cfg_file'", ",", "[", "\n", "'vid/fgfa/fgfa_faster_rcnn_r101_dc5_1x_imagenetvid.py'", ",", "\n", "'vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py'", "\n", "]", ")", "\n", "def", "test_vid_fgfa_style_forward", "(", "cfg_file", ")", ":", "\n", "    ", "config", "=", "_get_config_module", "(", "cfg_file", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "config", ".", "model", ")", "\n", "model", ".", "pretrains", "=", "None", "\n", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "detector", "=", "build_model", "(", "model", ")", "\n", "\n", "# Test forward train with a non-empty truth batch", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "256", ",", "256", ")", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "10", "]", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "gt_bboxes", "=", "mm_inputs", "[", "'gt_bboxes'", "]", "\n", "gt_labels", "=", "mm_inputs", "[", "'gt_labels'", "]", "\n", "gt_masks", "=", "mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "ref_input_shape", "=", "(", "2", ",", "3", ",", "256", ",", "256", ")", "\n", "ref_mm_inputs", "=", "_demo_mm_inputs", "(", "ref_input_shape", ",", "num_items", "=", "[", "9", ",", "11", "]", ")", "\n", "ref_img", "=", "ref_mm_inputs", ".", "pop", "(", "'imgs'", ")", "[", "None", "]", "\n", "ref_img_metas", "=", "ref_mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "ref_img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_img_metas", "[", "1", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_gt_bboxes", "=", "ref_mm_inputs", "[", "'gt_bboxes'", "]", "\n", "ref_gt_labels", "=", "ref_mm_inputs", "[", "'gt_labels'", "]", "\n", "ref_gt_masks", "=", "ref_mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "losses", "=", "detector", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "ref_img", "=", "ref_img", ",", "\n", "ref_img_metas", "=", "[", "ref_img_metas", "]", ",", "\n", "ref_gt_bboxes", "=", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", "=", "ref_gt_labels", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", "ref_gt_masks", "=", "ref_gt_masks", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "detector", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Test forward train with an empty truth batch", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "0", "]", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "gt_bboxes", "=", "mm_inputs", "[", "'gt_bboxes'", "]", "\n", "gt_labels", "=", "mm_inputs", "[", "'gt_labels'", "]", "\n", "gt_masks", "=", "mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "ref_mm_inputs", "=", "_demo_mm_inputs", "(", "ref_input_shape", ",", "num_items", "=", "[", "0", ",", "0", "]", ")", "\n", "ref_imgs", "=", "ref_mm_inputs", ".", "pop", "(", "'imgs'", ")", "[", "None", "]", "\n", "ref_img_metas", "=", "ref_mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "ref_img_metas", "[", "0", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_img_metas", "[", "1", "]", "[", "'is_video_data'", "]", "=", "True", "\n", "ref_gt_bboxes", "=", "ref_mm_inputs", "[", "'gt_bboxes'", "]", "\n", "ref_gt_labels", "=", "ref_mm_inputs", "[", "'gt_labels'", "]", "\n", "ref_gt_masks", "=", "ref_mm_inputs", "[", "'gt_masks'", "]", "\n", "\n", "losses", "=", "detector", ".", "forward", "(", "\n", "img", "=", "imgs", ",", "\n", "img_metas", "=", "img_metas", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "ref_img", "=", "ref_imgs", ",", "\n", "ref_img_metas", "=", "[", "ref_img_metas", "]", ",", "\n", "ref_gt_bboxes", "=", "ref_gt_bboxes", ",", "\n", "ref_gt_labels", "=", "ref_gt_labels", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", "ref_gt_masks", "=", "ref_gt_masks", ",", "\n", "return_loss", "=", "True", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "loss", ",", "_", "=", "detector", ".", "_parse_losses", "(", "losses", ")", "\n", "loss", ".", "requires_grad_", "(", "True", ")", "\n", "assert", "float", "(", "loss", ".", "item", "(", ")", ")", ">", "0", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Test forward test with frame_stride=1 and frame_range=[-1,0]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "imgs", "=", "torch", ".", "cat", "(", "[", "imgs", ",", "imgs", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "img_list", "=", "[", "g", "[", "None", ",", ":", "]", "for", "g", "in", "imgs", "]", "\n", "img_metas", ".", "extend", "(", "copy", ".", "deepcopy", "(", "img_metas", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "img_metas", ")", ")", ":", "\n", "            ", "img_metas", "[", "i", "]", "[", "'frame_id'", "]", "=", "i", "\n", "img_metas", "[", "i", "]", "[", "'num_left_ref_imgs'", "]", "=", "1", "\n", "img_metas", "[", "i", "]", "[", "'frame_stride'", "]", "=", "1", "\n", "", "ref_imgs", "=", "[", "ref_imgs", ".", "clone", "(", ")", ",", "imgs", "[", "[", "0", "]", "]", "[", "None", "]", ".", "clone", "(", ")", "]", "\n", "ref_img_metas", "=", "[", "\n", "copy", ".", "deepcopy", "(", "ref_img_metas", ")", ",", "\n", "copy", ".", "deepcopy", "(", "[", "img_metas", "[", "0", "]", "]", ")", "\n", "]", "\n", "results", "=", "defaultdict", "(", "list", ")", "\n", "for", "one_img", ",", "one_meta", ",", "ref_img", ",", "ref_img_meta", "in", "zip", "(", "\n", "img_list", ",", "img_metas", ",", "ref_imgs", ",", "ref_img_metas", ")", ":", "\n", "            ", "result", "=", "detector", ".", "forward", "(", "[", "one_img", "]", ",", "[", "[", "one_meta", "]", "]", ",", "\n", "ref_img", "=", "[", "ref_img", "]", ",", "\n", "ref_img_metas", "=", "[", "[", "ref_img_meta", "]", "]", ",", "\n", "return_loss", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                ", "results", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward.test_tracktor_forward": [[333, 362], ["pytest.mark.parametrize", "test_forward._get_config_module", "copy.deepcopy", "build_model", "build_model.eval", "test_forward._demo_mm_inputs", "_demo_mm_inputs.pop", "_demo_mm_inputs.pop", "torch.no_grad", "torch.cat", "copy.deepcopy", "mm_inputs.pop.extend", "collections.defaultdict", "zip", "build_model.forward", "mot.forward.items", "torch.cat.clone", "results[].append"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._get_config_module", "home.repos.pwc.inspect_result.goodproj13_tf-blender.models.builder.build_model", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs", "home.repos.pwc.inspect_result.goodproj13_tf-blender.sot.base.BaseSingleObjectTracker.forward"], ["", "", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'cfg_file'", ",", "[", "\n", "'mot/tracktor/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py'", ",", "\n", "'mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'", "\n", "]", ")", "\n", "def", "test_tracktor_forward", "(", "cfg_file", ")", ":", "\n", "    ", "config", "=", "_get_config_module", "(", "cfg_file", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "config", ".", "model", ")", "\n", "model", ".", "pretrains", "=", "None", "\n", "model", ".", "detector", ".", "pretrained", "=", "None", "\n", "\n", "from", "mmtrack", ".", "models", "import", "build_model", "\n", "mot", "=", "build_model", "(", "model", ")", "\n", "mot", ".", "eval", "(", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "256", ",", "256", ")", "\n", "mm_inputs", "=", "_demo_mm_inputs", "(", "input_shape", ",", "num_items", "=", "[", "10", "]", ",", "with_track", "=", "True", ")", "\n", "imgs", "=", "mm_inputs", ".", "pop", "(", "'imgs'", ")", "\n", "img_metas", "=", "mm_inputs", ".", "pop", "(", "'img_metas'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "imgs", "=", "torch", ".", "cat", "(", "[", "imgs", ",", "imgs", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "img_list", "=", "[", "g", "[", "None", ",", ":", "]", "for", "g", "in", "imgs", "]", "\n", "img2_metas", "=", "copy", ".", "deepcopy", "(", "img_metas", ")", "\n", "img2_metas", "[", "0", "]", "[", "'frame_id'", "]", "=", "1", "\n", "img_metas", ".", "extend", "(", "img2_metas", ")", "\n", "results", "=", "defaultdict", "(", "list", ")", "\n", "for", "one_img", ",", "one_meta", "in", "zip", "(", "img_list", ",", "img_metas", ")", ":", "\n", "            ", "result", "=", "mot", ".", "forward", "(", "[", "one_img", "]", ",", "[", "[", "one_meta", "]", "]", ",", "return_loss", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                ", "results", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_forward._demo_mm_inputs": [[364, 443], ["numpy.random.RandomState", "np.random.RandomState.rand", "range", "numpy.random.randint", "gt_masks.append", "np.random.RandomState.randint", "gt_bboxes.append", "gt_labels.append", "BitmapMasks", "torch.FloatTensor().requires_grad_", "range", "np.random.RandomState.randint", "np.random.RandomState.rand", "numpy.vstack", "torch.FloatTensor", "torch.LongTensor", "gt_match_indices.append", "len", "torch.arange", "torch.FloatTensor"], "function", ["None"], ["", "", "", "", "def", "_demo_mm_inputs", "(", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "300", ",", "300", ")", ",", "\n", "num_items", "=", "None", ",", "\n", "num_classes", "=", "10", ",", "\n", "with_track", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create a superset of inputs needed to run test or train batches.\n\n    Args:\n        input_shape (tuple):\n            input batch dimensions\n\n        num_items (None | List[int]):\n            specifies the number of boxes in each batch item\n\n        num_classes (int):\n            number of different labels a box might have\n    \"\"\"", "\n", "from", "mmdet", ".", "core", "import", "BitmapMasks", "\n", "\n", "(", "N", ",", "C", ",", "H", ",", "W", ")", "=", "input_shape", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n", "imgs", "=", "rng", ".", "rand", "(", "*", "input_shape", ")", "\n", "\n", "img_metas", "=", "[", "{", "\n", "'img_shape'", ":", "(", "H", ",", "W", ",", "C", ")", ",", "\n", "'ori_shape'", ":", "(", "H", ",", "W", ",", "C", ")", ",", "\n", "'pad_shape'", ":", "(", "H", ",", "W", ",", "C", ")", ",", "\n", "'filename'", ":", "'<demo>.png'", ",", "\n", "'scale_factor'", ":", "1.0", ",", "\n", "'flip'", ":", "False", ",", "\n", "'frame_id'", ":", "0", ",", "\n", "'img_norm_cfg'", ":", "{", "\n", "'mean'", ":", "(", "128.0", ",", "128.0", ",", "128.0", ")", ",", "\n", "'std'", ":", "(", "10.0", ",", "10.0", ",", "10.0", ")", "\n", "}", "\n", "}", "for", "i", "in", "range", "(", "N", ")", "]", "\n", "\n", "gt_bboxes", "=", "[", "]", "\n", "gt_labels", "=", "[", "]", "\n", "gt_masks", "=", "[", "]", "\n", "gt_match_indices", "=", "[", "]", "\n", "\n", "for", "batch_idx", "in", "range", "(", "N", ")", ":", "\n", "        ", "if", "num_items", "is", "None", ":", "\n", "            ", "num_boxes", "=", "rng", ".", "randint", "(", "1", ",", "10", ")", "\n", "", "else", ":", "\n", "            ", "num_boxes", "=", "num_items", "[", "batch_idx", "]", "\n", "\n", "", "cx", ",", "cy", ",", "bw", ",", "bh", "=", "rng", ".", "rand", "(", "num_boxes", ",", "4", ")", ".", "T", "\n", "\n", "tl_x", "=", "(", "(", "cx", "*", "W", ")", "-", "(", "W", "*", "bw", "/", "2", ")", ")", ".", "clip", "(", "0", ",", "W", ")", "\n", "tl_y", "=", "(", "(", "cy", "*", "H", ")", "-", "(", "H", "*", "bh", "/", "2", ")", ")", ".", "clip", "(", "0", ",", "H", ")", "\n", "br_x", "=", "(", "(", "cx", "*", "W", ")", "+", "(", "W", "*", "bw", "/", "2", ")", ")", ".", "clip", "(", "0", ",", "W", ")", "\n", "br_y", "=", "(", "(", "cy", "*", "H", ")", "+", "(", "H", "*", "bh", "/", "2", ")", ")", ".", "clip", "(", "0", ",", "H", ")", "\n", "\n", "boxes", "=", "np", ".", "vstack", "(", "[", "tl_x", ",", "tl_y", ",", "br_x", ",", "br_y", "]", ")", ".", "T", "\n", "class_idxs", "=", "rng", ".", "randint", "(", "1", ",", "num_classes", ",", "size", "=", "num_boxes", ")", "\n", "\n", "gt_bboxes", ".", "append", "(", "torch", ".", "FloatTensor", "(", "boxes", ")", ")", "\n", "gt_labels", ".", "append", "(", "torch", ".", "LongTensor", "(", "class_idxs", ")", ")", "\n", "if", "with_track", ":", "\n", "            ", "gt_match_indices", ".", "append", "(", "torch", ".", "arange", "(", "boxes", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "", "", "mask", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "(", "len", "(", "boxes", ")", ",", "H", ",", "W", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "gt_masks", ".", "append", "(", "BitmapMasks", "(", "mask", ",", "H", ",", "W", ")", ")", "\n", "\n", "mm_inputs", "=", "{", "\n", "'imgs'", ":", "torch", ".", "FloatTensor", "(", "imgs", ")", ".", "requires_grad_", "(", "True", ")", ",", "\n", "'img_metas'", ":", "img_metas", ",", "\n", "'gt_bboxes'", ":", "gt_bboxes", ",", "\n", "'gt_labels'", ":", "gt_labels", ",", "\n", "'gt_bboxes_ignore'", ":", "None", ",", "\n", "'gt_masks'", ":", "gt_masks", ",", "\n", "}", "\n", "if", "with_track", ":", "\n", "        ", "mm_inputs", "[", "'gt_match_indices'", "]", "=", "gt_match_indices", "\n", "", "return", "mm_inputs", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_aggregators.test_embed_aggregator": [[7, 30], ["mmtrack.models.aggregators.EmbedAggregator", "mmtrack.models.aggregators.EmbedAggregator.train", "torch.randn", "torch.randn", "mmtrack.models.aggregators.EmbedAggregator.", "pytest.raises", "mmtrack.models.aggregators.EmbedAggregator", "pytest.raises", "mmtrack.models.aggregators.EmbedAggregator", "mmtrack.models.aggregators.EmbedAggregator.train", "torch.randn", "torch.randn", "mmtrack.models.aggregators.EmbedAggregator."], "function", ["None"], ["def", "test_embed_aggregator", "(", ")", ":", "\n", "    ", "\"\"\"Test embed_aggregator.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The number of convs must be bigger than 1.", "\n", "        ", "model", "=", "EmbedAggregator", "(", "num_convs", "=", "0", ",", "channels", "=", "32", ",", "kernel_size", "=", "3", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# Only support 'batch_size == 1' for target_x", "\n", "        ", "model", "=", "EmbedAggregator", "(", "num_convs", "=", "3", ",", "channels", "=", "32", ",", "kernel_size", "=", "3", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "target_x", "=", "torch", ".", "randn", "(", "2", ",", "32", ",", "224", ",", "224", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "4", ",", "32", ",", "224", ",", "224", ")", "\n", "agg_x", "=", "model", "(", "target_x", ",", "ref_x", ")", "\n", "\n", "# Test embed_aggregator forward", "\n", "", "model", "=", "EmbedAggregator", "(", "num_convs", "=", "3", ",", "channels", "=", "32", ",", "kernel_size", "=", "3", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "target_x", "=", "torch", ".", "randn", "(", "1", ",", "32", ",", "224", ",", "224", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "4", ",", "32", ",", "224", ",", "224", ")", "\n", "agg_x", "=", "model", "(", "target_x", ",", "ref_x", ")", "\n", "assert", "agg_x", ".", "shape", "==", "target_x", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_models.test_aggregators.test_selsa_aggregator": [[32, 42], ["mmtrack.models.aggregators.SelsaAggregator", "mmtrack.models.aggregators.SelsaAggregator.train", "torch.randn", "torch.randn", "mmtrack.models.aggregators.SelsaAggregator."], "function", ["None"], ["", "def", "test_selsa_aggregator", "(", ")", ":", "\n", "    ", "\"\"\"Test selsa_aggregator.\"\"\"", "\n", "# Test embed_aggregator forward", "\n", "model", "=", "SelsaAggregator", "(", "in_channels", "=", "16", ",", "num_attention_blocks", "=", "4", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "target_x", "=", "torch", ".", "randn", "(", "2", ",", "16", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "4", ",", "16", ")", "\n", "agg_x", "=", "model", "(", "target_x", ",", "ref_x", ")", "\n", "assert", "agg_x", ".", "shape", "==", "target_x", ".", "shape", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.setup_class": [[14, 26], ["os.join", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "os.dirname", "dict", "dict", "dict"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "setup_class", "(", "cls", ")", ":", "\n", "        ", "cls", ".", "data_prefix", "=", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../assets'", ")", "\n", "\n", "img_names", "=", "[", "'image_1.jpg'", ",", "'image_2.jpg'", "]", "\n", "results", "=", "[", "\n", "dict", "(", "img_prefix", "=", "cls", ".", "data_prefix", ",", "img_info", "=", "dict", "(", "filename", "=", "name", ")", ")", "\n", "for", "name", "in", "img_names", "\n", "]", "\n", "load", "=", "build_from_cfg", "(", "\n", "dict", "(", "type", "=", "'LoadMultiImagesFromFile'", ",", "to_float32", "=", "True", ")", ",", "PIPELINES", ")", "\n", "cls", ".", "results", "=", "load", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_crop_like_siamfc": [[27, 43], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "mmdet.core.bbox.demodata.random_boxes"], "methods", ["None"], ["", "def", "test_seq_crop_like_siamfc", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "for", "res", "in", "results", ":", "\n", "            ", "res", "[", "'gt_bboxes'", "]", "=", "random_boxes", "(", "1", ",", "256", ")", "\n", "res", "[", "'bbox_fields'", "]", "=", "[", "'gt_bboxes'", "]", "\n", "\n", "", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqCropLikeSiamFC'", ",", "\n", "context_amount", "=", "0.5", ",", "\n", "exemplar_size", "=", "127", ",", "\n", "crop_size", "=", "511", ")", "\n", "seq_crop_like_siamfc", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "seq_crop_like_siamfc", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'img'", "]", ".", "shape", "==", "(", "511", ",", "511", ",", "3", ")", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "==", "(", "511", ",", "511", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_shift_scale_aug": [[44, 60], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "mmdet.core.bbox.demodata.random_boxes().numpy", "mmdet.core.bbox.demodata.random_boxes"], "methods", ["None"], ["", "def", "test_seq_shift_scale_aug", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "for", "res", "in", "results", ":", "\n", "            ", "res", "[", "'gt_bboxes'", "]", "=", "random_boxes", "(", "1", ",", "256", ")", ".", "numpy", "(", ")", "\n", "res", "[", "'bbox_fields'", "]", "=", "[", "'gt_bboxes'", "]", "\n", "\n", "", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqShiftScaleAug'", ",", "\n", "target_size", "=", "[", "127", ",", "255", "]", ",", "\n", "shift", "=", "[", "4", ",", "64", "]", ",", "\n", "scale", "=", "[", "0.05", ",", "0.18", "]", ")", "\n", "seq_shift_scale_aug", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "seq_shift_scale_aug", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'img'", "]", ".", "shape", "==", "(", "127", ",", "127", ",", "3", ")", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "==", "(", "255", ",", "255", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_color_aug": [[61, 76], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_color_aug", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "imgs_shape", "=", "[", "result", "[", "'img'", "]", ".", "shape", "for", "result", "in", "results", "]", "\n", "\n", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqColorAug'", ",", "\n", "prob", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "rgb_var", "=", "[", "[", "-", "0.55919361", ",", "0.98062831", ",", "-", "0.41940627", "]", ",", "\n", "[", "1.72091413", ",", "0.19879334", ",", "-", "1.82968581", "]", ",", "\n", "[", "4.64467907", ",", "4.73710203", ",", "4.88324118", "]", "]", ")", "\n", "seq_color_aug", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "seq_color_aug", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'img'", "]", ".", "shape", "==", "imgs_shape", "[", "0", "]", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "==", "imgs_shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_blur_aug": [[77, 87], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_blur_aug", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "imgs_shape", "=", "[", "result", "[", "'img'", "]", ".", "shape", "for", "result", "in", "results", "]", "\n", "\n", "transform", "=", "dict", "(", "type", "=", "'SeqBlurAug'", ",", "prob", "=", "[", "0.0", ",", "0.2", "]", ")", "\n", "seq_blur_aug", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "seq_blur_aug", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'img'", "]", ".", "shape", "==", "imgs_shape", "[", "0", "]", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "==", "imgs_shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_resize": [[88, 97], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_resize", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqResize'", ",", "img_scale", "=", "(", "512", ",", "1024", ")", ",", "keep_ratio", "=", "True", ")", "\n", "seq_resize", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "seq_resize", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'img'", "]", ".", "shape", "==", "(", "512", ",", "1024", ",", "3", ")", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "==", "(", "512", ",", "1024", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_flip": [[98, 123], ["dict", "mmcv.utils.build_from_cfg", "range", "dict", "mmcv.utils.build_from_cfg", "range", "copy.deepcopy", "mmcv.utils.build_from_cfg.", "copy.deepcopy", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_flip", "(", "self", ")", ":", "\n", "\n", "        ", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqRandomFlip'", ",", "share_params", "=", "True", ",", "flip_ratio", "=", "0.5", ")", "\n", "flip_module", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "for", "i", "in", "range", "(", "8", ")", ":", "\n", "            ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "results", "=", "flip_module", "(", "results", ")", "\n", "assert", "results", "[", "0", "]", "[", "'flip'", "]", "==", "results", "[", "1", "]", "[", "'flip'", "]", "\n", "assert", "results", "[", "0", "]", "[", "'flip_direction'", "]", "==", "results", "[", "1", "]", "[", "'flip_direction'", "]", "\n", "\n", "", "cases", "=", "[", "False", ",", "False", "]", "\n", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqRandomFlip'", ",", "share_params", "=", "False", ",", "flip_ratio", "=", "0.5", ")", "\n", "flip_module", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "for", "i", "in", "range", "(", "8", ")", ":", "\n", "            ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "results", "=", "flip_module", "(", "results", ")", "\n", "if", "results", "[", "0", "]", "[", "'flip'", "]", "==", "results", "[", "1", "]", "[", "'flip'", "]", ":", "\n", "                ", "cases", "[", "0", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "cases", "[", "1", "]", "=", "True", "\n", "", "", "assert", "cases", "[", "0", "]", "is", "True", "\n", "assert", "cases", "[", "1", "]", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_pad": [[124, 145], ["copy.deepcopy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_pad", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "\n", "transform", "=", "dict", "(", "type", "=", "'SeqPad'", ",", "size_divisor", "=", "32", ")", "\n", "transform", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "results", "=", "transform", "(", "results", ")", "\n", "\n", "for", "result", "in", "results", ":", "\n", "            ", "img_shape", "=", "result", "[", "'img'", "]", ".", "shape", "\n", "assert", "img_shape", "[", "0", "]", "%", "32", "==", "0", "\n", "assert", "img_shape", "[", "1", "]", "%", "32", "==", "0", "\n", "\n", "", "resize_transform", "=", "dict", "(", "\n", "type", "=", "'SeqResize'", ",", "img_scale", "=", "(", "1333", ",", "800", ")", ",", "keep_ratio", "=", "True", ")", "\n", "resize_module", "=", "build_from_cfg", "(", "resize_transform", ",", "PIPELINES", ")", "\n", "results", "=", "resize_module", "(", "results", ")", "\n", "results", "=", "transform", "(", "results", ")", "\n", "for", "result", "in", "results", ":", "\n", "            ", "img_shape", "=", "result", "[", "'img'", "]", ".", "shape", "\n", "assert", "img_shape", "[", "0", "]", "%", "32", "==", "0", "\n", "assert", "img_shape", "[", "1", "]", "%", "32", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_normalize": [[146, 161], ["copy.deepcopy", "dict", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "numpy.array", "numpy.array", "enumerate", "numpy.allclose"], "methods", ["None"], ["", "", "def", "test_seq_normalize", "(", "self", ")", ":", "\n", "        ", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "img_norm_cfg", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_rgb", "=", "True", ")", "\n", "transform", "=", "dict", "(", "type", "=", "'SeqNormalize'", ",", "**", "img_norm_cfg", ")", "\n", "transform", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "results", "=", "transform", "(", "results", ")", "\n", "\n", "mean", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'mean'", "]", ")", "\n", "std", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'std'", "]", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "converted_img", "=", "(", "self", ".", "results", "[", "i", "]", "[", "'img'", "]", "[", "...", ",", ":", ":", "-", "1", "]", "-", "mean", ")", "/", "std", "\n", "assert", "np", ".", "allclose", "(", "result", "[", "'img'", "]", ",", "converted_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_random_crop": [[162, 196], ["dict", "mmcv.utils.build_from_cfg", "copy.deepcopy", "mmcv.utils.build_from_cfg.", "mmcv.utils.build_from_cfg.", "pytest.raises", "dict", "mmcv.utils.build_from_cfg", "mmdet.core.bbox.demodata.random_boxes", "numpy.random.randint", "numpy.random.randint", "mmdet.core.bbox.demodata.random_boxes", "len", "len"], "methods", ["None"], ["", "", "def", "test_seq_random_crop", "(", "self", ")", ":", "\n", "# test assertion for invalid random crop", "\n", "        ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqRandomCrop'", ",", "crop_size", "=", "(", "-", "1", ",", "0", ")", ",", "share_params", "=", "False", ")", "\n", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "", "crop_size", "=", "(", "256", ",", "384", ")", "\n", "transform", "=", "dict", "(", "\n", "type", "=", "'SeqRandomCrop'", ",", "crop_size", "=", "crop_size", ",", "share_params", "=", "False", ")", "\n", "crop_module", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "results", ")", "\n", "for", "res", "in", "results", ":", "\n", "            ", "res", "[", "'gt_bboxes'", "]", "=", "random_boxes", "(", "8", ",", "256", ")", "\n", "res", "[", "'gt_labels'", "]", "=", "np", ".", "random", ".", "randint", "(", "8", ")", "\n", "res", "[", "'gt_instance_ids'", "]", "=", "np", ".", "random", ".", "randint", "(", "8", ")", "\n", "res", "[", "'gt_bboxes_ignore'", "]", "=", "random_boxes", "(", "2", ",", "256", ")", "\n", "\n", "", "outs", "=", "crop_module", "(", "results", ")", "\n", "assert", "len", "(", "outs", ")", "==", "len", "(", "results", ")", "\n", "for", "res", "in", "results", ":", "\n", "            ", "assert", "res", "[", "'img'", "]", ".", "shape", "[", ":", "2", "]", "==", "crop_size", "\n", "# All bboxes should be reserved after crop", "\n", "assert", "res", "[", "'img_shape'", "]", "[", ":", "2", "]", "==", "crop_size", "\n", "assert", "res", "[", "'gt_bboxes'", "]", ".", "shape", "[", "0", "]", "==", "8", "\n", "assert", "res", "[", "'gt_bboxes_ignore'", "]", ".", "shape", "[", "0", "]", "==", "2", "\n", "", "assert", "outs", "[", "0", "]", "[", "'img_info'", "]", "[", "'crop_offsets'", "]", "!=", "outs", "[", "1", "]", "[", "'img_info'", "]", "[", "\n", "'crop_offsets'", "]", "\n", "\n", "crop_module", ".", "share_params", "=", "True", "\n", "outs", "=", "crop_module", "(", "results", ")", "\n", "assert", "outs", "[", "0", "]", "[", "'img_info'", "]", "[", "'crop_offsets'", "]", "==", "outs", "[", "1", "]", "[", "'img_info'", "]", "[", "\n", "'crop_offsets'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_transform.TestTransforms.test_seq_color_jitter": [[197, 210], ["test_transform.TestTransforms.results.copy", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "mmcv.utils.build_from_cfg."], "methods", ["None"], ["", "def", "test_seq_color_jitter", "(", "self", ")", ":", "\n", "        ", "results", "=", "self", ".", "results", ".", "copy", "(", ")", "\n", "transform", "=", "dict", "(", "type", "=", "'SeqPhotoMetricDistortion'", ",", "share_params", "=", "False", ")", "\n", "transform", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "\n", "outs", "=", "transform", "(", "results", ")", "\n", "assert", "outs", "[", "0", "]", "[", "'img_info'", "]", "[", "'color_jitter'", "]", "!=", "outs", "[", "1", "]", "[", "'img_info'", "]", "[", "\n", "'color_jitter'", "]", "\n", "\n", "transform", ".", "share_params", "=", "True", "\n", "outs", "=", "transform", "(", "results", ")", "\n", "assert", "outs", "[", "0", "]", "[", "'img_info'", "]", "[", "'color_jitter'", "]", "==", "outs", "[", "1", "]", "[", "'img_info'", "]", "[", "\n", "'color_jitter'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_processing.test_match_instances": [[7, 30], ["dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "mmcv.utils.build_from_cfg.", "mmcv.utils.build_from_cfg.", "dict", "dict", "dict", "dict", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["def", "test_match_instances", "(", ")", ":", "\n", "    ", "process", "=", "dict", "(", "type", "=", "'MatchInstances'", ",", "skip_nomatch", "=", "True", ")", "\n", "process", "=", "build_from_cfg", "(", "process", ",", "PIPELINES", ")", "\n", "\n", "results", "=", "[", "\n", "dict", "(", "gt_instance_ids", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ")", ")", ",", "\n", "dict", "(", "gt_instance_ids", "=", "np", ".", "array", "(", "[", "2", ",", "3", ",", "4", ",", "6", "]", ")", ")", "\n", "]", "\n", "outs", "=", "process", "(", "results", ")", "\n", "assert", "(", "outs", "[", "0", "]", "[", "'gt_match_indices'", "]", "==", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "0", ",", "1", ",", "2", "]", ")", ")", ".", "all", "(", ")", "\n", "assert", "(", "outs", "[", "1", "]", "[", "'gt_match_indices'", "]", "==", "np", ".", "array", "(", "[", "2", ",", "3", ",", "4", ",", "-", "1", "]", ")", ")", ".", "all", "(", ")", "\n", "\n", "results", "=", "[", "\n", "dict", "(", "gt_instance_ids", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", "]", ")", ")", ",", "\n", "dict", "(", "gt_instance_ids", "=", "np", ".", "array", "(", "[", "3", ",", "4", ",", "6", ",", "7", "]", ")", ")", "\n", "]", "\n", "outs", "=", "process", "(", "results", ")", "\n", "assert", "outs", "is", "None", "\n", "\n", "process", ".", "skip_nomatch", "=", "False", "\n", "outs", "=", "process", "(", "results", ")", "\n", "assert", "(", "outs", "[", "0", "]", "[", "'gt_match_indices'", "]", "==", "-", "1", ")", ".", "all", "(", ")", "\n", "assert", "(", "outs", "[", "1", "]", "[", "'gt_match_indices'", "]", "==", "-", "1", ")", ".", "all", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_loading.TestLoading.setup_class": [[11, 14], ["os.join", "os.dirname"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "setup_class", "(", "cls", ")", ":", "\n", "        ", "cls", ".", "data_prefix", "=", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../assets'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_loading.TestLoading.test_load_seq_imgs": [[15, 35], ["load", "isinstance", "enumerate", "dict", "mmtrack.datasets.PIPELINES.get", "copy.deepcopy", "os.join", "repr", "dict"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "def", "test_load_seq_imgs", "(", "self", ")", ":", "\n", "        ", "img_names", "=", "[", "'image_1.jpg'", ",", "'image_2.jpg'", ",", "'image_3.jpg'", "]", "\n", "results", "=", "[", "\n", "dict", "(", "img_prefix", "=", "self", ".", "data_prefix", ",", "img_info", "=", "dict", "(", "filename", "=", "name", ")", ")", "\n", "for", "name", "in", "img_names", "\n", "]", "\n", "load", "=", "PIPELINES", ".", "get", "(", "'LoadMultiImagesFromFile'", ")", "(", ")", "\n", "all_results", "=", "load", "(", "copy", ".", "deepcopy", "(", "results", ")", ")", "\n", "assert", "isinstance", "(", "all_results", ",", "list", ")", "\n", "for", "i", ",", "results", "in", "enumerate", "(", "all_results", ")", ":", "\n", "            ", "assert", "results", "[", "'filename'", "]", "==", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "\n", "img_names", "[", "i", "]", ")", "\n", "assert", "results", "[", "'ori_filename'", "]", "==", "img_names", "[", "i", "]", "\n", "assert", "results", "[", "'img'", "]", ".", "shape", "==", "(", "256", ",", "512", ",", "3", ")", "\n", "assert", "results", "[", "'img'", "]", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "results", "[", "'img_shape'", "]", "==", "(", "256", ",", "512", ",", "3", ")", "\n", "assert", "results", "[", "'ori_shape'", "]", "==", "(", "256", ",", "512", ",", "3", ")", "\n", "assert", "repr", "(", "load", ")", "==", "load", ".", "__class__", ".", "__name__", "+", "\"(to_float32=False, color_type='color', \"", "+", "\"file_client_args={'backend': 'disk'})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_loading.TestLoading.test_load_detections": [[36, 47], ["dict", "load", "numpy.random.randn", "numpy.random.randn", "mmtrack.datasets.PIPELINES.get"], "methods", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "", "def", "test_load_detections", "(", "self", ")", ":", "\n", "        ", "results", "=", "dict", "(", ")", "\n", "results", "[", "'bbox_fields'", "]", "=", "[", "]", "\n", "results", "[", "'detections'", "]", "=", "[", "np", ".", "random", ".", "randn", "(", "4", ",", "5", ")", ",", "np", ".", "random", ".", "randn", "(", "3", ",", "5", ")", "]", "\n", "load", "=", "PIPELINES", ".", "get", "(", "'LoadDetections'", ")", "(", ")", "\n", "results", "=", "load", "(", "results", ")", "\n", "assert", "'public_bboxes'", "in", "results", "\n", "assert", "'public_labels'", "in", "results", "\n", "assert", "results", "[", "'public_bboxes'", "]", ".", "shape", "==", "(", "7", ",", "4", ")", "\n", "assert", "results", "[", "'public_labels'", "]", ".", "shape", "==", "(", "7", ",", ")", "\n", "assert", "'public_bboxes'", "in", "results", "[", "'bbox_fields'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._create_gt_results": [[28, 44], ["collections.defaultdict", "dataset.get_ann_info", "numpy.ones", "numpy.concatenate", "bbox2result", "track2result", "results[].append", "results[].append", "len", "ann[].astype", "len"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.get_ann_info", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result"], ["def", "_create_gt_results", "(", "dataset", ")", ":", "\n", "    ", "from", "mmdet", ".", "core", "import", "bbox2result", "\n", "\n", "from", "mmtrack", ".", "core", "import", "track2result", "\n", "results", "=", "defaultdict", "(", "list", ")", "\n", "for", "img_info", "in", "dataset", ".", "data_infos", ":", "\n", "        ", "ann", "=", "dataset", ".", "get_ann_info", "(", "img_info", ")", "\n", "scores", "=", "np", ".", "ones", "(", "(", "ann", "[", "'bboxes'", "]", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "bboxes", "=", "np", ".", "concatenate", "(", "(", "ann", "[", "'bboxes'", "]", ",", "scores", ")", ",", "axis", "=", "1", ")", "\n", "bbox_results", "=", "bbox2result", "(", "bboxes", ",", "ann", "[", "'labels'", "]", ",", "len", "(", "dataset", ".", "CLASSES", ")", ")", "\n", "track_results", "=", "track2result", "(", "bboxes", ",", "ann", "[", "'labels'", "]", ",", "\n", "ann", "[", "'instance_ids'", "]", ".", "astype", "(", "np", ".", "int", ")", ",", "\n", "len", "(", "dataset", ".", "CLASSES", ")", ")", "\n", "results", "[", "'bbox_results'", "]", ".", "append", "(", "bbox_results", ")", "\n", "results", "[", "'track_results'", "]", ".", "append", "(", "track_results", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_load_detections": [[46, 90], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "tempfile.TemporaryDirectory", "os.join", "test_dataset._create_gt_results", "mmcv.dump", "dataset_class.load_detections", "isinstance", "mmcv.dump", "dataset_class.load_detections", "isinstance", "numpy.random.randint", "dataset_class.prepare_results", "zip", "dict", "range", "mmcv.dump", "dataset_class.load_detections", "isinstance", "numpy.random.randint", "dataset_class.prepare_results", "zip", "tempfile.TemporaryDirectory.cleanup", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._create_gt_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.load_detections", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.load_detections", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.mot_challenge_dataset.MOTChallengeDataset.load_detections", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_results"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'MOTChallengeDataset'", "]", ")", "\n", "def", "test_load_detections", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "\n", "classes", "=", "(", "'car'", ",", "'person'", ")", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "test_mode", "=", "True", ")", "\n", "\n", "tmp_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", "\n", "det_file", "=", "osp", ".", "join", "(", "tmp_dir", ".", "name", ",", "'det.pkl'", ")", "\n", "outputs", "=", "_create_gt_results", "(", "dataset", ")", "\n", "\n", "mmcv", ".", "dump", "(", "outputs", "[", "'bbox_results'", "]", ",", "det_file", ")", "\n", "detections", "=", "dataset", ".", "load_detections", "(", "det_file", ")", "\n", "assert", "isinstance", "(", "detections", ",", "list", ")", "\n", "assert", "len", "(", "detections", ")", "==", "8", "\n", "\n", "mmcv", ".", "dump", "(", "outputs", ",", "det_file", ")", "\n", "detections", "=", "dataset", ".", "load_detections", "(", "det_file", ")", "\n", "assert", "isinstance", "(", "detections", ",", "list", ")", "\n", "assert", "len", "(", "detections", ")", "==", "8", "\n", "dataset", ".", "detections", "=", "detections", "\n", "i", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dataset", ".", "data_infos", ")", ")", "\n", "results", "=", "dataset", ".", "prepare_results", "(", "dataset", ".", "data_infos", "[", "i", "]", ")", "\n", "assert", "'detections'", "in", "results", "\n", "for", "a", ",", "b", "in", "zip", "(", "results", "[", "'detections'", "]", ",", "outputs", "[", "'bbox_results'", "]", "[", "i", "]", ")", ":", "\n", "        ", "assert", "(", "a", "==", "b", ")", ".", "all", "(", ")", "\n", "\n", "", "out", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ".", "data_infos", ")", ")", ":", "\n", "        ", "out", "[", "dataset", ".", "data_infos", "[", "i", "]", "[", "'file_name'", "]", "]", "=", "outputs", "[", "'bbox_results'", "]", "[", "i", "]", "\n", "", "mmcv", ".", "dump", "(", "out", ",", "det_file", ")", "\n", "detections", "=", "dataset", ".", "load_detections", "(", "det_file", ")", "\n", "assert", "isinstance", "(", "detections", ",", "dict", ")", "\n", "assert", "len", "(", "detections", ")", "==", "8", "\n", "dataset", ".", "detections", "=", "detections", "\n", "i", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dataset", ".", "data_infos", ")", ")", "\n", "results", "=", "dataset", ".", "prepare_results", "(", "dataset", ".", "data_infos", "[", "i", "]", ")", "\n", "assert", "'detections'", "in", "results", "\n", "for", "a", ",", "b", "in", "zip", "(", "results", "[", "'detections'", "]", ",", "outputs", "[", "'bbox_results'", "]", "[", "i", "]", ")", ":", "\n", "        ", "assert", "(", "a", "==", "b", ")", ".", "all", "(", ")", "\n", "\n", "", "tmp_dir", ".", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_parse_ann_info": [[92, 126], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dataset_class.coco.get_ann_ids", "dataset_class.coco.loadAnns", "dataset_class._parse_ann_info", "dataset_class.coco.get_ann_ids", "dataset_class.coco.loadAnns", "dataset_class._parse_ann_info", "dataset_class.coco.get_ann_ids", "dataset_class.coco.loadAnns", "dataset_class._parse_ann_info", "dataset_class.coco.load_imgs", "dataset_class.coco.load_imgs", "dataset_class.coco.load_imgs"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "\n", "[", "'CocoVideoDataset'", ",", "'MOTChallengeDataset'", "]", ")", "\n", "def", "test_parse_ann_info", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "classes", "=", "(", "'car'", ",", "'person'", ")", ",", "pipeline", "=", "[", "]", ")", "\n", "\n", "# image 1 doesn't have gt and detected objects", "\n", "img_id", "=", "1", "\n", "img_info", "=", "dataset", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "get_ann_ids", "(", "[", "img_id", "]", ")", "\n", "ann_info", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "ann", "=", "dataset", ".", "_parse_ann_info", "(", "img_info", ",", "ann_info", ")", "\n", "assert", "ann", "[", "'bboxes'", "]", ".", "shape", "==", "(", "0", ",", "4", ")", "\n", "assert", "ann", "[", "'bboxes_ignore'", "]", ".", "shape", "==", "(", "3", ",", "4", ")", "\n", "\n", "# image 5 has 2 objects", "\n", "img_id", "=", "5", "\n", "img_info", "=", "dataset", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "get_ann_ids", "(", "[", "img_id", "]", ")", "\n", "ann_info", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "ann", "=", "dataset", ".", "_parse_ann_info", "(", "img_info", ",", "ann_info", ")", "\n", "assert", "ann", "[", "'bboxes'", "]", ".", "shape", "==", "(", "2", ",", "4", ")", "\n", "assert", "ann", "[", "'bboxes_ignore'", "]", ".", "shape", "==", "(", "0", ",", "4", ")", "\n", "\n", "# image 8 doesn't have objects", "\n", "img_id", "=", "8", "\n", "img_info", "=", "dataset", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "get_ann_ids", "(", "[", "img_id", "]", ")", "\n", "ann_info", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "ann", "=", "dataset", ".", "_parse_ann_info", "(", "img_info", ",", "ann_info", ")", "\n", "assert", "ann", "[", "'bboxes'", "]", ".", "shape", "==", "(", "0", ",", "4", ")", "\n", "assert", "ann", "[", "'bboxes_ignore'", "]", ".", "shape", "==", "(", "0", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_sot_train_dataset_parse_ann_info": [[128, 142], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dataset_class.coco.get_ann_ids", "dataset_class.coco.loadAnns", "dataset_class._parse_ann_info"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'SOTTrainDataset'", "]", ")", "\n", "def", "test_sot_train_dataset_parse_ann_info", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "dataset", "=", "dataset_class", "(", "ann_file", "=", "DEMO_ANN_FILE", ",", "pipeline", "=", "[", "]", ")", "\n", "\n", "# image 5 has 2 objects, we only load the object with instance_id = 1", "\n", "img_id", "=", "5", "\n", "instance_id", "=", "1", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "get_ann_ids", "(", "[", "img_id", "]", ")", "\n", "ann_info", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "ann", "=", "dataset", ".", "_parse_ann_info", "(", "instance_id", ",", "ann_info", ")", "\n", "assert", "ann", "[", "'bboxes'", "]", ".", "shape", "==", "(", "1", ",", "4", ")", "\n", "assert", "ann", "[", "'labels'", "]", ".", "shape", "==", "(", "1", ",", ")", "and", "ann", "[", "'labels'", "]", "[", "0", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_lasot_dataset_parse_ann_info": [[144, 160], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dataset_class.coco.get_ann_ids", "dataset_class.coco.loadAnns", "dataset_class._parse_ann_info", "dataset_class.coco.load_imgs", "os.join"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset._parse_ann_info"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'LaSOTDataset'", "]", ")", "\n", "def", "test_lasot_dataset_parse_ann_info", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "osp", ".", "join", "(", "LASOT_ANN_PATH", ",", "'lasot_test_dummy.json'", ")", ",", "\n", "pipeline", "=", "[", "]", ")", "\n", "\n", "# image 5 has 1 objects", "\n", "img_id", "=", "5", "\n", "img_info", "=", "dataset", ".", "coco", ".", "load_imgs", "(", "[", "img_id", "]", ")", "[", "0", "]", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "get_ann_ids", "(", "[", "img_id", "]", ")", "\n", "ann_info", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "ann", "=", "dataset", ".", "_parse_ann_info", "(", "img_info", ",", "ann_info", ")", "\n", "assert", "ann", "[", "'bboxes'", "]", ".", "shape", "==", "(", "4", ",", ")", "\n", "assert", "ann", "[", "'labels'", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_prepare_data": [[162, 213], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dataset_class.prepare_train_img", "isinstance", "dataset_class.prepare_train_img", "isinstance", "DATASETS.get.", "dataset_class.prepare_test_img", "isinstance", "dataset_class.prepare_test_img", "isinstance", "len", "len", "results[].keys", "results[].keys", "len", "len", "results[].keys", "results[].keys", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_train_img", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_train_img", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_test_img", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_test_img"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'CocoVideoDataset'", "]", ")", "\n", "def", "test_prepare_data", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "# train", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "\n", "classes", "=", "[", "'car'", ",", "'person'", "]", ",", "\n", "ref_img_sampler", "=", "dict", "(", "\n", "num_ref_imgs", "=", "1", ",", "\n", "frame_range", "=", "1", ",", "\n", "filter_key_img", "=", "True", ",", "\n", "method", "=", "'uniform'", ")", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "test_mode", "=", "False", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "7", "\n", "\n", "results", "=", "dataset", ".", "prepare_train_img", "(", "0", ")", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", "\n", "assert", "len", "(", "results", ")", "==", "2", "\n", "assert", "'ann_info'", "in", "results", "[", "0", "]", "\n", "assert", "results", "[", "0", "]", ".", "keys", "(", ")", "==", "results", "[", "1", "]", ".", "keys", "(", ")", "\n", "\n", "dataset", ".", "ref_img_sampler", "=", "None", "\n", "results", "=", "dataset", ".", "prepare_train_img", "(", "0", ")", "\n", "assert", "isinstance", "(", "results", ",", "dict", ")", "\n", "assert", "'ann_info'", "in", "results", "\n", "\n", "# test", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "\n", "classes", "=", "[", "'car'", ",", "'person'", "]", ",", "\n", "ref_img_sampler", "=", "dict", "(", "\n", "num_ref_imgs", "=", "1", ",", "\n", "frame_range", "=", "1", ",", "\n", "filter_key_img", "=", "True", ",", "\n", "method", "=", "'uniform'", ")", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "test_mode", "=", "True", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "8", "\n", "\n", "results", "=", "dataset", ".", "prepare_test_img", "(", "0", ")", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", "\n", "assert", "len", "(", "results", ")", "==", "2", "\n", "assert", "'ann_info'", "not", "in", "results", "[", "0", "]", "\n", "assert", "results", "[", "0", "]", ".", "keys", "(", ")", "==", "results", "[", "1", "]", ".", "keys", "(", ")", "\n", "\n", "dataset", ".", "ref_img_sampler", "=", "None", "\n", "results", "=", "dataset", ".", "prepare_test_img", "(", "0", ")", "\n", "assert", "isinstance", "(", "results", ",", "dict", ")", "\n", "assert", "'ann_info'", "not", "in", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_sot_train_dataset_prepare_data": [[215, 236], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dataset_class.prepare_train_img", "isinstance", "len", "len", "results[].keys", "results[].keys", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.prepare_train_img"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'SOTTrainDataset'", "]", ")", "\n", "def", "test_sot_train_dataset_prepare_data", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "# train", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "\n", "ref_img_sampler", "=", "dict", "(", "\n", "frame_range", "=", "100", ",", "\n", "pos_prob", "=", "0.8", ",", "\n", "filter_key_img", "=", "False", ",", "\n", "return_key_img", "=", "True", ")", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "test_mode", "=", "False", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "1", "\n", "\n", "results", "=", "dataset", ".", "prepare_train_img", "(", "0", ")", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", "\n", "assert", "len", "(", "results", ")", "==", "2", "\n", "assert", "'ann_info'", "in", "results", "[", "0", "]", "\n", "assert", "results", "[", "0", "]", ".", "keys", "(", ")", "==", "results", "[", "1", "]", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_video_data_sampling": [[238, 273], ["pytest.mark.parametrize", "mmtrack.datasets.DATASETS.get", "dict", "dict", "dataset_class.ref_img_sampling", "dataset_class.ref_img_sampling", "DATASETS.get.", "dataset_class.ref_img_sampling", "abs", "len", "len", "len", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.ref_img_sampling"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'CocoVideoDataset'", "]", ")", "\n", "def", "test_video_data_sampling", "(", "dataset", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "\n", "# key image sampling", "\n", "for", "interval", "in", "[", "4", ",", "2", ",", "1", "]", ":", "\n", "        ", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "\n", "load_as_video", "=", "True", ",", "\n", "classes", "=", "[", "'car'", ",", "'person'", "]", ",", "\n", "key_img_sampler", "=", "dict", "(", "interval", "=", "interval", ")", ",", "\n", "ref_img_sampler", "=", "dict", "(", "\n", "num_ref_imgs", "=", "1", ",", "\n", "frame_range", "=", "3", ",", "\n", "filter_key_frame", "=", "True", ",", "\n", "method", "=", "'uniform'", ")", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "test_mode", "=", "True", ")", "\n", "assert", "len", "(", "dataset", ".", "data_infos", ")", "==", "8", "//", "interval", "\n", "\n", "# ref image sampling", "\n", "", "data", "=", "dataset", ".", "data_infos", "[", "3", "]", "\n", "sampler", "=", "dict", "(", "num_ref_imgs", "=", "1", ",", "frame_range", "=", "3", ",", "method", "=", "'uniform'", ")", "\n", "ref_data", "=", "dataset", ".", "ref_img_sampling", "(", "data", ",", "**", "sampler", ")", "[", "1", "]", "\n", "assert", "abs", "(", "ref_data", "[", "'frame_id'", "]", "-", "\n", "data", "[", "'frame_id'", "]", ")", "<=", "sampler", "[", "'frame_range'", "]", "\n", "sampler", "=", "dict", "(", "num_ref_imgs", "=", "2", ",", "frame_range", "=", "3", ",", "method", "=", "'bilateral_uniform'", ")", "\n", "ref_data", "=", "dataset", ".", "ref_img_sampling", "(", "data", ",", "**", "sampler", ")", "\n", "assert", "len", "(", "ref_data", ")", "==", "3", "\n", "ref_data", "=", "dataset", ".", "ref_img_sampling", "(", "data", ",", "**", "sampler", ",", "return_key_img", "=", "False", ")", "\n", "assert", "len", "(", "ref_data", ")", "==", "2", "\n", "assert", "ref_data", "[", "0", "]", "[", "'frame_id'", "]", "<", "data", "[", "'frame_id'", "]", "\n", "assert", "ref_data", "[", "1", "]", "[", "'frame_id'", "]", ">", "data", "[", "'frame_id'", "]", "\n", "assert", "data", "[", "'frame_id'", "]", "-", "ref_data", "[", "0", "]", "[", "'frame_id'", "]", "<=", "sampler", "[", "'frame_range'", "]", "\n", "assert", "ref_data", "[", "1", "]", "[", "'frame_id'", "]", "-", "data", "[", "'frame_id'", "]", "<=", "sampler", "[", "'frame_range'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_coco_video_evaluation": [[275, 306], ["mmtrack.datasets.DATASETS.get", "DATASETS.get.", "test_dataset._create_gt_results", "dataset_class.evaluate", "DATASETS.get.", "test_dataset._create_gt_results", "dataset_class.evaluate"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._create_gt_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._create_gt_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate"], ["", "def", "test_coco_video_evaluation", "(", ")", ":", "\n", "    ", "classes", "=", "(", "'car'", ",", "'person'", ")", "\n", "dataset_class", "=", "DATASETS", ".", "get", "(", "'CocoVideoDataset'", ")", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "classes", "=", "classes", ",", "pipeline", "=", "[", "]", ")", "\n", "results", "=", "_create_gt_results", "(", "dataset", ")", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "results", ",", "metric", "=", "[", "'bbox'", ",", "'track'", "]", ")", "\n", "assert", "eval_results", "[", "'bbox_mAP'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'bbox_mAP_50'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'bbox_mAP_75'", "]", "==", "1.0", "\n", "assert", "'bbox_mAP_copypaste'", "in", "eval_results", "\n", "assert", "eval_results", "[", "'MOTA'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'IDF1'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'MT'", "]", "==", "2", "\n", "assert", "'track_OVERALL_copypaste'", "in", "eval_results", "\n", "assert", "'track_AVERAGE_copypaste'", "in", "eval_results", "\n", "\n", "classes", "=", "(", "'car'", ",", ")", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "classes", "=", "classes", ",", "pipeline", "=", "[", "]", ")", "\n", "results", "=", "_create_gt_results", "(", "dataset", ")", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "results", ",", "metric", "=", "[", "'bbox'", ",", "'track'", "]", ")", "\n", "assert", "eval_results", "[", "'bbox_mAP'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'bbox_mAP_50'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'bbox_mAP_75'", "]", "==", "1.0", "\n", "assert", "'bbox_mAP_copypaste'", "in", "eval_results", "\n", "assert", "eval_results", "[", "'MOTA'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'IDF1'", "]", "==", "1.0", "\n", "assert", "eval_results", "[", "'MT'", "]", "==", "1", "\n", "assert", "'track_OVERALL_copypaste'", "in", "eval_results", "\n", "assert", "'track_AVERAGE_copypaste'", "in", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_mot17_bbox_evaluation": [[308, 319], ["mmtrack.datasets.DATASETS.get", "DATASETS.get.", "test_dataset._create_gt_results", "dataset_class.evaluate", "dataset_class.evaluate"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._create_gt_results", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate"], ["", "def", "test_mot17_bbox_evaluation", "(", ")", ":", "\n", "    ", "classes", "=", "(", "'car'", ",", "'person'", ")", "\n", "dataset_class", "=", "DATASETS", ".", "get", "(", "'MOTChallengeDataset'", ")", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "DEMO_ANN_FILE", ",", "classes", "=", "classes", ",", "pipeline", "=", "[", "]", ")", "\n", "results", "=", "_create_gt_results", "(", "dataset", ")", "\n", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "results", ",", "metric", "=", "'bbox'", ")", "\n", "assert", "eval_results", "[", "'mAP'", "]", "==", "1.0", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "results", "[", "'bbox_results'", "]", ",", "metric", "=", "'bbox'", ")", "\n", "assert", "eval_results", "[", "'mAP'", "]", "==", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_mot17_track_evaluation": [[321, 377], ["unittest.mock.patch", "unittest.mock.patch", "pytest.mark.parametrize", "tempfile.TemporaryDirectory", "mmtrack.datasets.DATASETS.get", "unittest.mock.MagicMock", "unittest.mock.MagicMock", "DATASETS.get.", "unittest.mock.MagicMock", "test_dataset.test_mot17_track_evaluation._load_results"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get"], ["", "@", "patch", "(", "'mmtrack.datasets.MOTChallengeDataset.load_annotations'", ",", "MagicMock", ")", "\n", "@", "patch", "(", "'mmtrack.datasets.MOTChallengeDataset._filter_imgs'", ",", "MagicMock", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dataset'", ",", "[", "'MOTChallengeDataset'", "]", ")", "\n", "def", "test_mot17_track_evaluation", "(", "dataset", ")", ":", "\n", "    ", "tmp_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", "\n", "videos", "=", "[", "'TUD-Campus'", ",", "'TUD-Stadtmitte'", "]", "\n", "\n", "dataset_class", "=", "DATASETS", ".", "get", "(", "dataset", ")", "\n", "dataset_class", ".", "cat_ids", "=", "MagicMock", "(", ")", "\n", "dataset_class", ".", "coco", "=", "MagicMock", "(", ")", "\n", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "MagicMock", "(", ")", ",", "visibility_thr", "=", "-", "1", ",", "pipeline", "=", "[", "]", ")", "\n", "dataset", ".", "img_prefix", "=", "MOT_ANN_PATH", "\n", "dataset", ".", "vid_ids", "=", "[", "1", ",", "2", "]", "\n", "vid_infos", "=", "[", "dict", "(", "name", "=", "_", ")", "for", "_", "in", "videos", "]", "\n", "dataset", ".", "coco", ".", "load_vids", "=", "MagicMock", "(", "return_value", "=", "vid_infos", ")", "\n", "dataset", ".", "data_infos", "=", "[", "]", "\n", "\n", "def", "_load_results", "(", "videos", ")", ":", "\n", "        ", "track_results", ",", "data_infos", "=", "[", "]", ",", "[", "]", "\n", "for", "video", "in", "videos", ":", "\n", "            ", "dets", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "MOT_ANN_PATH", ",", "'results'", ",", "f'{video}.txt'", ")", ")", "\n", "track_result", "=", "defaultdict", "(", "list", ")", "\n", "for", "det", "in", "dets", ":", "\n", "                ", "det", "=", "det", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "frame_id", ",", "ins_id", "=", "map", "(", "int", ",", "det", "[", ":", "2", "]", ")", "\n", "bbox", "=", "list", "(", "map", "(", "float", ",", "det", "[", "2", ":", "7", "]", ")", ")", "\n", "track", "=", "[", "\n", "ins_id", ",", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", ",", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ",", "\n", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ",", "bbox", "[", "4", "]", "\n", "]", "\n", "track_result", "[", "frame_id", "]", ".", "append", "(", "track", ")", "\n", "", "max_frame", "=", "max", "(", "track_result", ".", "keys", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "max_frame", "+", "1", ")", ":", "\n", "                ", "track_results", ".", "append", "(", "\n", "[", "np", ".", "array", "(", "track_result", "[", "i", "]", ",", "dtype", "=", "np", ".", "float32", ")", "]", ")", "\n", "data_infos", ".", "append", "(", "dict", "(", "frame_id", "=", "i", "-", "1", ")", ")", "\n", "", "", "return", "track_results", ",", "data_infos", "\n", "\n", "", "track_results", ",", "data_infos", "=", "_load_results", "(", "videos", ")", "\n", "dataset", ".", "data_infos", "=", "data_infos", "\n", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "\n", "dict", "(", "track_results", "=", "track_results", ")", ",", "\n", "metric", "=", "'track'", ",", "\n", "logger", "=", "None", ",", "\n", "resfile_path", "=", "None", ",", "\n", "track_iou_thr", "=", "0.5", ")", "\n", "assert", "eval_results", "[", "'IDF1'", "]", "==", "0.624", "\n", "assert", "eval_results", "[", "'IDP'", "]", "==", "0.799", "\n", "assert", "eval_results", "[", "'MOTA'", "]", "==", "0.555", "\n", "assert", "eval_results", "[", "'IDs'", "]", "==", "14", "\n", "\n", "tmp_dir", ".", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_lasot_evaluation": [[379, 400], ["mmtrack.datasets.DATASETS.get", "DATASETS.get.", "dict", "dataset_class.evaluate", "results.extend", "result.split", "dict.append", "os.join", "mmcv.list_from_file", "numpy.array", "os.join", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.trackers.base_tracker.BaseTracker.get", "home.repos.pwc.inspect_result.goodproj13_tf-blender.datasets.coco_video_dataset.CocoVideoDataset.evaluate"], ["", "def", "test_lasot_evaluation", "(", ")", ":", "\n", "    ", "dataset_class", "=", "DATASETS", ".", "get", "(", "'LaSOTDataset'", ")", "\n", "dataset", "=", "dataset_class", "(", "\n", "ann_file", "=", "osp", ".", "join", "(", "LASOT_ANN_PATH", ",", "'lasot_test_dummy.json'", ")", ",", "\n", "pipeline", "=", "[", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "video_name", "in", "[", "'airplane-1'", ",", "'airplane-2'", "]", ":", "\n", "        ", "results", ".", "extend", "(", "\n", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "LASOT_ANN_PATH", ",", "video_name", ",", "'track_results.txt'", ")", ")", ")", "\n", "", "track_results", "=", "[", "]", "\n", "for", "result", "in", "results", ":", "\n", "        ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "result", ".", "split", "(", "','", ")", "\n", "track_results", ".", "append", "(", "np", ".", "array", "(", "[", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", ",", "int", "(", "x2", ")", ",", "int", "(", "y2", ")", "]", ")", ")", "\n", "\n", "", "track_results", "=", "dict", "(", "bbox", "=", "track_results", ")", "\n", "eval_results", "=", "dataset", ".", "evaluate", "(", "track_results", ",", "metric", "=", "[", "'track'", "]", ")", "\n", "assert", "eval_results", "[", "'success'", "]", "==", "67.524", "\n", "assert", "eval_results", "[", "'norm_precision'", "]", "==", "70.0", "\n", "assert", "eval_results", "[", "'precision'", "]", "==", "50.0", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset.test_evaluation_hook": [[402, 487], ["unittest.mock.patch", "unittest.mock.patch", "pytest.mark.parametrize", "torch.utils.data.DataLoader", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "test_dataset._build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "torch.ones", "torch.ones", "pytest.raises", "EvalHookParam", "pytest.raises", "EvalHookParam", "pytest.warns", "EvalHookParam", "unittest.mock.MagicMock"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner", "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner"], ["", "@", "patch", "(", "'mmtrack.apis.single_gpu_test'", ",", "MagicMock", ")", "\n", "@", "patch", "(", "'mmtrack.apis.multi_gpu_test'", ",", "MagicMock", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'EvalHookParam'", ",", "(", "EvalHook", ",", "DistEvalHook", ")", ")", "\n", "def", "test_evaluation_hook", "(", "EvalHookParam", ")", ":", "\n", "# create dummy data", "\n", "    ", "dataloader", "=", "DataLoader", "(", "torch", ".", "ones", "(", "(", "5", ",", "2", ")", ")", ")", "\n", "dataloader", ".", "dataset", ".", "load_as_video", "=", "True", "\n", "\n", "# 0.1. dataloader is not a DataLoader object", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "EvalHookParam", "(", "dataloader", "=", "MagicMock", "(", ")", ",", "interval", "=", "-", "1", ")", "\n", "\n", "# 0.2. negative interval", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "EvalHookParam", "(", "dataloader", ",", "interval", "=", "-", "1", ")", "\n", "\n", "# 1. start=None, interval=1: perform evaluation after each epoch.", "\n", "", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "interval", "=", "1", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 2", "\n", "\n", "# 2. start=1, interval=1: perform evaluation after each epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "1", ",", "interval", "=", "1", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 2", "\n", "\n", "# 3. start=None, interval=2: perform evaluation after epoch 2, 4, 6, etc", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "interval", "=", "2", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "1", "# after epoch 2", "\n", "\n", "# 4. start=1, interval=2: perform evaluation after epoch 1, 3, 5, etc", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "1", ",", "interval", "=", "2", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 3", "\n", "\n", "# 5. start=0/negative, interval=1: perform evaluation after each epoch and", "\n", "#    before epoch 1.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "0", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "3", "# before epoch1 and after e1 & e2", "\n", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "        ", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "-", "2", ")", "\n", "", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "3", "# before epoch1 and after e1 & e2", "\n", "\n", "# 6. resuming from epoch i, start = x (x<=i), interval =1: perform", "\n", "#    evaluation after each epoch and before the first epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "1", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "_epoch", "=", "2", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# before & after epoch 3", "\n", "\n", "# 7. resuming from epoch i, start = i+1/None, interval =1: perform", "\n", "#    evaluation after each epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "dataloader", ",", "start", "=", "2", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "_epoch", "=", "1", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 2 & 3", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_dataset._build_demo_runner": [[489, 512], ["Model", "tempfile.mkdtemp", "mmcv.runner.EpochBasedRunner", "super().__init__", "torch.Linear", "test_dataset..linear", "dict", "dict", "logging.getLogger", "test_dataset..", "test_dataset.."], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.optimizer.sot_lr_updater.SiameseRPNLrUpdaterHook.__init__"], ["", "def", "_build_demo_runner", "(", ")", ":", "\n", "\n", "    ", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", ",", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "            ", "return", "self", ".", "linear", "(", "x", ")", "\n", "\n", "", "def", "train_step", "(", "self", ",", "x", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "dict", "(", "loss", "=", "self", "(", "x", ")", ")", "\n", "\n", "", "def", "val_step", "(", "self", ",", "x", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "dict", "(", "loss", "=", "self", "(", "x", ")", ")", "\n", "\n", "", "", "model", "=", "Model", "(", ")", "\n", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "work_dir", "=", "tmp_dir", ",", "logger", "=", "logging", ".", "getLogger", "(", ")", ")", "\n", "return", "runner", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_formatting.TestFormatting.setup_class": [[11, 14], ["os.join", "os.dirname"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "setup_class", "(", "cls", ")", ":", "\n", "        ", "cls", ".", "data_prefix", "=", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../assets'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_data.test_formatting.TestFormatting.test_formatting": [[15, 66], ["dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "dict", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg.", "len", "dict", "len", "len", "numpy.random.randn", "len", "len", "len", "len", "dict"], "methods", ["None"], ["", "def", "test_formatting", "(", "self", ")", ":", "\n", "        ", "img_names", "=", "[", "'image_1.jpg'", ",", "'image_2.jpg'", ",", "'image_3.jpg'", "]", "\n", "collect_keys", "=", "[", "'img'", ",", "'gt_bboxes'", "]", "\n", "num_objects", "=", "4", "\n", "num_ref_imgs", "=", "len", "(", "img_names", ")", "-", "1", "\n", "\n", "results", "=", "[", "\n", "dict", "(", "img_prefix", "=", "self", ".", "data_prefix", ",", "img_info", "=", "dict", "(", "filename", "=", "name", ")", ")", "\n", "for", "name", "in", "img_names", "\n", "]", "\n", "\n", "load", "=", "dict", "(", "type", "=", "'LoadMultiImagesFromFile'", ")", "\n", "load", "=", "build_from_cfg", "(", "load", ",", "PIPELINES", ")", "\n", "results", "=", "load", "(", "results", ")", "\n", "assert", "len", "(", "results", ")", "==", "len", "(", "img_names", ")", "\n", "\n", "for", "result", "in", "results", ":", "\n", "            ", "result", "[", "'gt_bboxes'", "]", "=", "np", ".", "random", ".", "randn", "(", "num_objects", ",", "4", ")", "\n", "\n", "", "collect", "=", "dict", "(", "type", "=", "'VideoCollect'", ",", "keys", "=", "collect_keys", ")", "\n", "collect", "=", "build_from_cfg", "(", "collect", ",", "PIPELINES", ")", "\n", "results", "=", "collect", "(", "results", ")", "\n", "assert", "len", "(", "results", ")", "==", "len", "(", "img_names", ")", "\n", "for", "key", "in", "collect_keys", ":", "\n", "            ", "assert", "key", "in", "results", "[", "0", "]", "\n", "assert", "key", "in", "results", "[", "1", "]", "\n", "assert", "key", "in", "results", "[", "2", "]", "\n", "", "assert", "'img_metas'", "in", "results", "[", "0", "]", "\n", "assert", "'img_metas'", "in", "results", "[", "1", "]", "\n", "assert", "'img_metas'", "in", "results", "[", "2", "]", "\n", "key_results", "=", "results", "[", "0", "]", "\n", "\n", "concat_ref", "=", "dict", "(", "type", "=", "'ConcatVideoReferences'", ")", "\n", "concat_ref", "=", "build_from_cfg", "(", "concat_ref", ",", "PIPELINES", ")", "\n", "results", "=", "concat_ref", "(", "results", ")", "\n", "assert", "len", "(", "results", ")", "==", "2", "\n", "assert", "results", "[", "0", "]", "==", "key_results", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "ndim", "==", "4", "\n", "assert", "results", "[", "1", "]", "[", "'img'", "]", ".", "shape", "[", "3", "]", "==", "2", "\n", "assert", "len", "(", "results", "[", "1", "]", "[", "'img_metas'", "]", ")", "==", "2", "\n", "assert", "results", "[", "1", "]", "[", "'gt_bboxes'", "]", ".", "ndim", "==", "2", "\n", "assert", "results", "[", "1", "]", "[", "'gt_bboxes'", "]", ".", "shape", "[", "1", "]", "==", "5", "\n", "assert", "results", "[", "1", "]", "[", "'gt_bboxes'", "]", ".", "shape", "[", "0", "]", "==", "(", "num_ref_imgs", "*", "num_objects", ")", "\n", "\n", "ref_prefix", "=", "'ref'", "\n", "bundle", "=", "dict", "(", "type", "=", "'SeqDefaultFormatBundle'", ",", "ref_prefix", "=", "ref_prefix", ")", "\n", "bundle", "=", "build_from_cfg", "(", "bundle", ",", "PIPELINES", ")", "\n", "results", "=", "bundle", "(", "results", ")", "\n", "for", "key", "in", "results", ":", "\n", "            ", "if", "ref_prefix", "not", "in", "key", ":", "\n", "                ", "assert", "f'{ref_prefix}_{key}'", "in", "results", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_core.test_motion_utils.test_flow_warp_feats": [[7, 30], ["torch.randn", "torch.randn", "mmtrack.core.flow_warp_feats", "pytest.raises", "torch.randn", "torch.randn", "mmtrack.core.flow_warp_feats", "pytest.raises", "torch.randn", "torch.randn", "mmtrack.core.flow_warp_feats", "pytest.raises", "torch.randn", "torch.randn", "mmtrack.core.flow_warp_feats"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats", "home.repos.pwc.inspect_result.goodproj13_tf-blender.motion.flow.flow_warp_feats"], ["def", "test_flow_warp_feats", "(", ")", ":", "\n", "    ", "flow", "=", "torch", ".", "randn", "(", "2", ",", "2", ",", "10", ",", "10", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "2", ",", "8", ",", "32", ",", "32", ")", "\n", "x", "=", "flow_warp_feats", "(", "ref_x", ",", "flow", ")", "\n", "assert", "x", ".", "shape", "==", "ref_x", ".", "shape", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# the length of ref_x.shape must be 4", "\n", "        ", "flow", "=", "torch", ".", "randn", "(", "2", ",", "2", ",", "10", ",", "10", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "2", ",", "8", ",", "32", ",", "32", ",", "32", ")", "\n", "x", "=", "flow_warp_feats", "(", "ref_x", ",", "flow", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# the length of flow.shape must be 4", "\n", "        ", "flow", "=", "torch", ".", "randn", "(", "2", ",", "2", ",", "10", ",", "10", ",", "10", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "2", ",", "8", ",", "32", ",", "32", ")", "\n", "x", "=", "flow_warp_feats", "(", "ref_x", ",", "flow", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# flow.shape[1] == 2", "\n", "        ", "flow", "=", "torch", ".", "randn", "(", "2", ",", "3", ",", "10", ",", "10", ")", "\n", "ref_x", "=", "torch", ".", "randn", "(", "2", ",", "8", ",", "32", ",", "32", ")", "\n", "x", "=", "flow_warp_feats", "(", "ref_x", ",", "flow", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_core.test_track.test_imrenormalize": [[6, 28], ["dict", "dict", "numpy.random.randn().astype", "imrenormalize", "isinstance", "numpy.allclose", "torch.randn", "imrenormalize", "isinstance", "numpy.allclose", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.imrenormalize", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.imrenormalize"], ["def", "test_imrenormalize", "(", ")", ":", "\n", "    ", "from", "mmtrack", ".", "core", "import", "imrenormalize", "\n", "img_norm_cfg", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_rgb", "=", "True", ")", "\n", "new_img_norm_cfg", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_rgb", "=", "True", ")", "\n", "\n", "img", "=", "np", ".", "random", ".", "randn", "(", "128", ",", "256", ",", "3", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "new_img", "=", "imrenormalize", "(", "img", ",", "img_norm_cfg", ",", "new_img_norm_cfg", ")", "\n", "assert", "isinstance", "(", "new_img", ",", "np", ".", "ndarray", ")", "\n", "assert", "new_img", ".", "shape", "==", "(", "128", ",", "256", ",", "3", ")", "\n", "assert", "np", ".", "allclose", "(", "img", ",", "new_img", ",", "atol", "=", "1e-6", ")", "\n", "\n", "img", "=", "torch", ".", "randn", "(", "1", ",", "3", ",", "128", ",", "256", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "new_img", "=", "imrenormalize", "(", "img", ",", "img_norm_cfg", ",", "new_img_norm_cfg", ")", "\n", "assert", "isinstance", "(", "new_img", ",", "torch", ".", "Tensor", ")", "\n", "assert", "new_img", ".", "shape", "==", "(", "1", ",", "3", ",", "128", ",", "256", ")", "\n", "assert", "np", ".", "allclose", "(", "img", ",", "new_img", ",", "atol", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_core.test_track.test_track2result": [[30, 52], ["mmdet.core.bbox.demodata.random_boxes", "torch.FloatTensor().uniform_", "torch.cat", "torch.randint", "torch.arange", "track2result", "isinstance", "range", "len", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.track2result"], ["", "def", "test_track2result", "(", ")", ":", "\n", "    ", "from", "mmtrack", ".", "core", "import", "track2result", "\n", "\n", "# pseudo data", "\n", "num_objects", ",", "num_classes", "=", "8", ",", "4", "\n", "bboxes", "=", "random_boxes", "(", "num_objects", ",", "640", ")", "\n", "scores", "=", "torch", ".", "FloatTensor", "(", "num_objects", ",", "1", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "bboxes", "=", "torch", ".", "cat", "(", "[", "bboxes", ",", "scores", "]", ",", "dim", "=", "1", ")", "\n", "# leave the results of the last class as empty", "\n", "labels", "=", "torch", ".", "randint", "(", "0", ",", "num_classes", "-", "1", ",", "(", "num_objects", ",", ")", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "num_objects", ")", "\n", "\n", "# run", "\n", "result", "=", "track2result", "(", "bboxes", ",", "labels", ",", "ids", ",", "num_classes", ")", "\n", "\n", "# test", "\n", "assert", "len", "(", "result", ")", "==", "num_classes", "\n", "assert", "result", "[", "-", "1", "]", ".", "shape", "==", "(", "0", ",", "6", ")", "\n", "assert", "isinstance", "(", "result", "[", "0", "]", ",", "np", ".", "ndarray", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "        ", "assert", "result", "[", "i", "]", ".", "shape", "[", "0", "]", "==", "(", "labels", "==", "i", ")", ".", "sum", "(", ")", "\n", "assert", "result", "[", "i", "]", ".", "shape", "[", "1", "]", "==", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_core.test_track.test_restore_result": [[54, 69], ["restore_result", "restore_result", "numpy.random.randn", "numpy.random.randn", "len", "range", "range", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.transforms.restore_result"], ["", "", "def", "test_restore_result", "(", ")", ":", "\n", "    ", "from", "mmtrack", ".", "core", "import", "restore_result", "\n", "num_classes", "=", "3", "\n", "num_objects", "=", "[", "2", ",", "0", ",", "2", "]", "\n", "\n", "result", "=", "[", "np", ".", "random", ".", "randn", "(", "num_objects", "[", "i", "]", ",", "5", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "bboxes", ",", "labels", "=", "restore_result", "(", "result", ",", "return_ids", "=", "False", ")", "\n", "assert", "bboxes", ".", "shape", "==", "(", "4", ",", "5", ")", "\n", "assert", "(", "labels", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "2", ",", "2", "]", ")", ")", ".", "all", "(", ")", "\n", "\n", "result", "=", "[", "np", ".", "random", ".", "randn", "(", "num_objects", "[", "i", "]", ",", "6", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "bboxes", ",", "labels", ",", "ids", "=", "restore_result", "(", "result", ",", "return_ids", "=", "True", ")", "\n", "assert", "bboxes", ".", "shape", "==", "(", "4", ",", "5", ")", "\n", "assert", "(", "labels", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "2", ",", "2", "]", ")", ")", ".", "all", "(", ")", "\n", "assert", "len", "(", "ids", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.test_core.test_track.test_embed_similarity": [[71, 108], ["torch.randn", "torch.randn", "embed_similarity", "embed_similarity", "embed_similarity", "embed_similarity", "embed_similarity.size", "torch.randn.t", "embed_similarity.size", "embed_similarity.size", "embed_similarity.size", "embed_similarity.max"], "function", ["home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity", "home.repos.pwc.inspect_result.goodproj13_tf-blender.track.similarity.embed_similarity"], ["", "def", "test_embed_similarity", "(", ")", ":", "\n", "    ", "from", "mmtrack", ".", "core", "import", "embed_similarity", "\n", "key_embeds", "=", "torch", ".", "randn", "(", "20", ",", "256", ")", "\n", "ref_embeds", "=", "torch", ".", "randn", "(", "10", ",", "256", ")", "\n", "\n", "sims", "=", "embed_similarity", "(", "\n", "key_embeds", ",", "\n", "ref_embeds", ",", "\n", "method", "=", "'dot_product'", ",", "\n", "temperature", "=", "-", "1", ",", "\n", "transpose", "=", "True", ")", "\n", "assert", "sims", ".", "size", "(", ")", "==", "(", "20", ",", "10", ")", "\n", "\n", "sims", "=", "embed_similarity", "(", "\n", "key_embeds", ",", "\n", "ref_embeds", ".", "t", "(", ")", ",", "\n", "method", "=", "'dot_product'", ",", "\n", "temperature", "=", "-", "1", ",", "\n", "transpose", "=", "False", ")", "\n", "assert", "sims", ".", "size", "(", ")", "==", "(", "20", ",", "10", ")", "\n", "\n", "sims", "=", "embed_similarity", "(", "\n", "key_embeds", ",", "\n", "ref_embeds", ",", "\n", "method", "=", "'dot_product'", ",", "\n", "temperature", "=", "0.07", ",", "\n", "transpose", "=", "True", ")", "\n", "assert", "sims", ".", "size", "(", ")", "==", "(", "20", ",", "10", ")", "\n", "\n", "sims", "=", "embed_similarity", "(", "\n", "key_embeds", ",", "\n", "ref_embeds", ",", "\n", "method", "=", "'cosine'", ",", "\n", "temperature", "=", "-", "1", ",", "\n", "transpose", "=", "True", ")", "\n", "assert", "sims", ".", "size", "(", ")", "==", "(", "20", ",", "10", ")", "\n", "assert", "sims", ".", "max", "(", ")", "<=", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.lasot.create_assets.create_dummy_data": [[7, 54], ["collections.defaultdict", "dict", "mmcv.dump", "dict", "dict", "lasot_test[].append", "mmcv.list_from_file", "enumerate", "os.join", "os.join", "dict", "lasot_test[].append", "gt_bbox.split", "dict", "lasot_test[].append", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["def", "create_dummy_data", "(", ")", ":", "\n", "    ", "lasot_test", "=", "defaultdict", "(", "list", ")", "\n", "records", "=", "dict", "(", "vid_id", "=", "1", ",", "img_id", "=", "1", ",", "ann_id", "=", "1", ",", "global_instance_id", "=", "1", ")", "\n", "videos_list", "=", "[", "'airplane-1'", ",", "'airplane-2'", "]", "\n", "\n", "lasot_test", "[", "'categories'", "]", "=", "[", "dict", "(", "id", "=", "0", ",", "name", "=", "0", ")", "]", "\n", "\n", "for", "video_name", "in", "videos_list", ":", "\n", "        ", "video_path", "=", "video_name", "\n", "video", "=", "dict", "(", "id", "=", "records", "[", "'vid_id'", "]", ",", "name", "=", "video_name", ")", "\n", "lasot_test", "[", "'videos'", "]", ".", "append", "(", "video", ")", "\n", "\n", "gt_bboxes", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "video_path", ",", "'groundtruth.txt'", ")", ")", "\n", "\n", "height", ",", "width", ",", "_", "=", "(", "360", ",", "640", ",", "3", ")", "\n", "for", "frame_id", ",", "gt_bbox", "in", "enumerate", "(", "gt_bboxes", ")", ":", "\n", "            ", "file_name", "=", "'%08d'", "%", "(", "frame_id", "+", "1", ")", "+", "'.jpg'", "\n", "file_name", "=", "osp", ".", "join", "(", "video_name", ",", "'img'", ",", "file_name", ")", "\n", "image", "=", "dict", "(", "\n", "file_name", "=", "file_name", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "id", "=", "records", "[", "'img_id'", "]", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "video_id", "=", "records", "[", "'vid_id'", "]", ")", "\n", "lasot_test", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "\n", "x1", ",", "y1", ",", "w", ",", "h", "=", "gt_bbox", ".", "split", "(", "','", ")", "\n", "ann", "=", "dict", "(", "\n", "id", "=", "records", "[", "'ann_id'", "]", ",", "\n", "image_id", "=", "records", "[", "'img_id'", "]", ",", "\n", "instance_id", "=", "records", "[", "'global_instance_id'", "]", ",", "\n", "category_id", "=", "0", ",", "\n", "bbox", "=", "[", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", ",", "int", "(", "w", ")", ",", "\n", "int", "(", "h", ")", "]", ",", "\n", "area", "=", "int", "(", "w", ")", "*", "int", "(", "h", ")", ",", "\n", "full_occlusion", "=", "False", ",", "\n", "out_of_view", "=", "False", ")", "\n", "lasot_test", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "\n", "records", "[", "'ann_id'", "]", "+=", "1", "\n", "records", "[", "'img_id'", "]", "+=", "1", "\n", "", "records", "[", "'global_instance_id'", "]", "+=", "1", "\n", "records", "[", "'vid_id'", "]", "+=", "1", "\n", "\n", "", "mmcv", ".", "dump", "(", "lasot_test", ",", "'lasot_test_dummy.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.goodproj13_tf-blender.demo_cocovid_data.create_assets.create_dummy_data": [[7, 112], ["dict", "dict", "collections.defaultdict", "enumerate", "enumerate", "dict.items", "mmcv.dump", "dict", "ann[].append", "ann[].append", "dict", "range", "enumerate", "mmdet.core.bbox.demodata.random_boxes().numpy", "range", "dict", "dict", "ann[].append", "mmdet.core.bbox.demodata.random_boxes().numpy", "enumerate", "float", "float", "float", "float", "float", "dict.copy", "ann[].append", "dict", "dict", "float", "float", "float", "float", "float", "ann[].append", "mmdet.core.bbox.demodata.random_boxes", "dict", "dict", "dict", "mmdet.core.bbox.demodata.random_boxes", "dict", "len", "min", "min", "KeyError", "classes.index"], "function", ["None"], ["def", "create_dummy_data", "(", ")", ":", "\n", "    ", "lasot_test", "=", "defaultdict", "(", "list", ")", "\n", "records", "=", "dict", "(", "vid_id", "=", "1", ",", "img_id", "=", "1", ",", "ann_id", "=", "1", ",", "global_instance_id", "=", "1", ")", "\n", "videos_list", "=", "[", "'airplane-1'", ",", "'airplane-2'", "]", "\n", "\n", "lasot_test", "[", "'categories'", "]", "=", "[", "dict", "(", "id", "=", "0", ",", "name", "=", "0", ")", "]", "\n", "\n", "for", "video_name", "in", "videos_list", ":", "\n", "        ", "video_path", "=", "video_name", "\n", "video", "=", "dict", "(", "id", "=", "records", "[", "'vid_id'", "]", ",", "name", "=", "video_name", ")", "\n", "lasot_test", "[", "'videos'", "]", ".", "append", "(", "video", ")", "\n", "\n", "gt_bboxes", "=", "mmcv", ".", "list_from_file", "(", "\n", "osp", ".", "join", "(", "video_path", ",", "'groundtruth.txt'", ")", ")", "\n", "\n", "height", ",", "width", ",", "_", "=", "(", "360", ",", "640", ",", "3", ")", "\n", "for", "frame_id", ",", "gt_bbox", "in", "enumerate", "(", "gt_bboxes", ")", ":", "\n", "            ", "file_name", "=", "'%08d'", "%", "(", "frame_id", "+", "1", ")", "+", "'.jpg'", "\n", "file_name", "=", "osp", ".", "join", "(", "video_name", ",", "'img'", ",", "file_name", ")", "\n", "image", "=", "dict", "(", "\n", "file_name", "=", "file_name", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "id", "=", "records", "[", "'img_id'", "]", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", "video_id", "=", "records", "[", "'vid_id'", "]", ")", "\n", "lasot_test", "[", "'images'", "]", ".", "append", "(", "image", ")", "\n", "\n", "x1", ",", "y1", ",", "w", ",", "h", "=", "gt_bbox", ".", "split", "(", "','", ")", "\n", "ann", "=", "dict", "(", "\n", "id", "=", "records", "[", "'ann_id'", "]", ",", "\n", "image_id", "=", "records", "[", "'img_id'", "]", ",", "\n", "instance_id", "=", "records", "[", "'global_instance_id'", "]", ",", "\n", "category_id", "=", "0", ",", "\n", "bbox", "=", "[", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", ",", "int", "(", "w", ")", ",", "\n", "int", "(", "h", ")", "]", ",", "\n", "area", "=", "int", "(", "w", ")", "*", "int", "(", "h", ")", ",", "\n", "full_occlusion", "=", "False", ",", "\n", "out_of_view", "=", "False", ")", "\n", "lasot_test", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "\n", "records", "[", "'ann_id'", "]", "+=", "1", "\n", "records", "[", "'img_id'", "]", "+=", "1", "\n", "", "records", "[", "'global_instance_id'", "]", "+=", "1", "\n", "records", "[", "'vid_id'", "]", "+=", "1", "\n", "\n", "", "mmcv", ".", "dump", "(", "lasot_test", ",", "'lasot_test_dummy.json'", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "create_dummy_data", "(", ")", "\n", "", ""]]}