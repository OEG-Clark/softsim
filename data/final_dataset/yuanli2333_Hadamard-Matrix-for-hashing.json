{"home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.Model.__init__": [[5, 33], ["torch.Module.__init__", "torch.Sequential", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.Tanh", "torch.Dropout", "torch.Sequential", "getattr"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hash_bit", "=", "args", ".", "hash_bit", "\n", "self", ".", "base_model", "=", "getattr", "(", "torchvision", ".", "models", ",", "args", ".", "model_type", ")", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "conv1", "=", "self", ".", "base_model", ".", "conv1", "\n", "self", ".", "bn1", "=", "self", ".", "base_model", ".", "bn1", "\n", "self", ".", "relu", "=", "self", ".", "base_model", ".", "relu", "\n", "self", ".", "maxpool", "=", "self", ".", "base_model", ".", "maxpool", "\n", "self", ".", "layer1", "=", "self", ".", "base_model", ".", "layer1", "\n", "self", ".", "layer2", "=", "self", ".", "base_model", ".", "layer2", "\n", "self", ".", "layer3", "=", "self", ".", "base_model", ".", "layer3", "\n", "self", ".", "layer4", "=", "self", ".", "base_model", ".", "layer4", "\n", "self", ".", "avgpool", "=", "self", ".", "base_model", ".", "avgpool", "\n", "self", ".", "feature_layers", "=", "nn", ".", "Sequential", "(", "self", ".", "conv1", ",", "self", ".", "bn1", ",", "self", ".", "relu", ",", "self", ".", "maxpool", ",", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", ",", "self", ".", "avgpool", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "base_model", ".", "fc", ".", "in_features", ",", "self", ".", "base_model", ".", "fc", ".", "in_features", ")", "\n", "self", ".", "activation1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "base_model", ".", "fc", ".", "in_features", ",", "self", ".", "base_model", ".", "fc", ".", "in_features", ")", "\n", "self", ".", "activation2", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "self", ".", "base_model", ".", "fc", ".", "in_features", ",", "self", ".", "hash_bit", ")", "\n", "self", ".", "last_layer", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "hash_layer", "=", "nn", ".", "Sequential", "(", "self", ".", "fc1", ",", "self", ".", "activation1", ",", "self", ".", "dropout", ",", "self", ".", "fc2", ",", "self", ".", "activation2", ",", "self", ".", "fc3", ",", "\n", "self", ".", "last_layer", ")", "\n", "\n", "self", ".", "iter_num", "=", "0", "\n", "self", ".", "scale", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.Model.forward": [[34, 42], ["network.Model.feature_layers", "x.view.view.view", "network.Model.hash_layer", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature_layers", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "y", "=", "self", ".", "hash_layer", "(", "x", ")", "\n", "\n", "#y = self.last_layer(5*y)", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.AlexNetFc.__init__": [[44, 64], ["torch.Module.__init__", "torchvision.models.alexnet", "torch.Sequential", "range", "torch.Sequential", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.Tanh", "torch.Dropout", "torch.Sequential", "network.AlexNetFc.classifier.add_module", "str"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "AlexNetFc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_model", "=", "torchvision", ".", "models", ".", "alexnet", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "features", "=", "self", ".", "base_model", ".", "features", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "            ", "self", ".", "classifier", ".", "add_module", "(", "\"classifier\"", "+", "str", "(", "i", ")", ",", "self", ".", "base_model", ".", "classifier", "[", "i", "]", ")", "\n", "", "self", ".", "feature_layers", "=", "nn", ".", "Sequential", "(", "self", ".", "features", ",", "self", ".", "classifier", ")", "\n", "\n", "self", ".", "hash_bit", "=", "args", ".", "hash_bit", "\n", "feature_dim", "=", "self", ".", "base_model", ".", "classifier", "[", "6", "]", ".", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "feature_dim", ",", "feature_dim", ")", "\n", "self", ".", "activation1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "feature_dim", ",", "feature_dim", ")", "\n", "self", ".", "activation2", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "feature_dim", ",", "self", ".", "hash_bit", ")", "\n", "self", ".", "last_layer", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "hash_layer", "=", "nn", ".", "Sequential", "(", "self", ".", "fc1", ",", "self", ".", "activation1", ",", "self", ".", "fc2", ",", "self", ".", "activation2", ",", "self", ".", "fc3", ",", "\n", "self", ".", "last_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.AlexNetFc.forward": [[65, 72], ["network.AlexNetFc.features", "network.AlexNetFc.view", "network.AlexNetFc.classifier", "network.AlexNetFc.hash_layer", "network.AlexNetFc.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "256", "*", "6", "*", "6", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "y", "=", "self", ".", "hash_layer", "(", "x", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.freeze_mulit_layers": [[75, 78], ["network.freeze_layer"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.freeze_layer"], ["", "", "def", "freeze_mulit_layers", "(", "multi_layers", ")", ":", "\n", "    ", "for", "layer", "in", "multi_layers", ":", "\n", "        ", "freeze_layer", "(", "layer", ")", "\n", "", "", "def", "freeze_layer", "(", "layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.network.freeze_layer": [[78, 81], ["layer.parameters"], "function", ["None"], ["", "", "def", "freeze_layer", "(", "layer", ")", ":", "\n", "    ", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.main": [[15, 101], ["vars().items", "data_list.ImageList", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_list.ImageList", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.cuda.is_available", "torch.cuda.is_available", "print", "torch.load", "torch.load", "torch.randint_like", "torch.randint_like", "data_list.ImageList", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.BCELoss().cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "print", "range", "print", "open().readlines", "open().readlines", "open().readlines", "network.Model().cuda", "train.train", "vars", "pre_process.image_test", "pre_process.image_test", "pre_process.image_train", "network.AlexNetFc().cuda", "torch.BCELoss", "AlexNetFc().cuda.feature_layers.parameters", "AlexNetFc().cuda.hash_layer.parameters", "torch.nn.DataParallel", "torch.nn.DataParallel", "print", "train.test_MAP", "print", "str", "open", "open", "open", "network.Model", "torch.save", "torch.save", "print", "str", "network.AlexNetFc", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.train", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_test", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_test", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_train", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.test.test_MAP", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "global", "data_imbalance", "\n", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'\\t{}: {}'", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "", "if", "args", ".", "data_name", "==", "'imagenet'", ":", "\n", "        ", "train_list", "=", "'data/imagenet/train.txt'", "\n", "test_list", "=", "'data/imagenet/test.txt'", "\n", "#true_hash = 'data/imagenet/imagenet_100_class.pkl'", "\n", "true_hash", "=", "'data/imagenet/hash_centers/'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_imagenet_100_class.pkl'", "\n", "#true_hash = 'data/imagenet/32_imagenet_100_class.pkl'", "\n", "data_imbalance", "=", "100", "\n", "two_loss_epoch", "=", "-", "1", "\n", "total_epoch", "=", "90", "\n", "\n", "", "elif", "args", ".", "data_name", "==", "'coco'", ":", "\n", "        ", "train_list", "=", "'data/coco/train.txt'", "\n", "test_list", "=", "'data/coco/test.txt'", "\n", "#true_hash = 'data/coco/coco_ha80_class.pkl'", "\n", "true_hash", "=", "'data/coco/hash_centers/'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_coco_80_class.pkl'", "\n", "data_imbalance", "=", "1", "\n", "two_loss_epoch", "=", "-", "1", "\n", "total_epoch", "=", "90", "\n", "\n", "", "elif", "args", ".", "data_name", "==", "'nus_wide'", ":", "\n", "        ", "train_list", "=", "'data/nus_wide/train.txt'", "\n", "#true_hash = 'data/nus_wide/nus_wide_ha21_class.pkl'", "\n", "true_hash", "=", "'data/nus_wide/hash_centers/'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_nus_wide_21_class.pkl'", "\n", "data_imbalance", "=", "5", "\n", "two_loss_epoch", "=", "-", "1", "\n", "total_epoch", "=", "90", "\n", "\n", "", "database_list", "=", "'data/'", "+", "args", ".", "data_name", "+", "'/database.txt'", "\n", "test_list", "=", "'data/'", "+", "args", ".", "data_name", "+", "'/test.txt'", "\n", "database", "=", "ImageList", "(", "open", "(", "database_list", ")", ".", "readlines", "(", ")", ",", "\n", "transform", "=", "prep", ".", "image_test", "(", "resize_size", "=", "255", ",", "crop_size", "=", "224", ")", ")", "\n", "database_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "database", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ")", "\n", "\n", "test_dataset", "=", "ImageList", "(", "open", "(", "test_list", ")", ".", "readlines", "(", ")", ",", "transform", "=", "prep", ".", "image_test", "(", "resize_size", "=", "255", ",", "crop_size", "=", "224", ")", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ")", "\n", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "gpus", "# before using torch", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"CUDA is not available\"", "\n", "\n", "print", "(", "true_hash", ")", "\n", "Hash_center", "=", "torch", ".", "load", "(", "true_hash", ")", "\n", "global", "random_center", "\n", "random_center", "=", "torch", ".", "randint_like", "(", "Hash_center", "[", "0", "]", ",", "2", ")", "\n", "#Hash_center[Hash_center < 0] = 0  # Hash centers are {0,1}, no this line Hash center are {-1,1}", "\n", "\n", "train_data", "=", "ImageList", "(", "open", "(", "train_list", ")", ".", "readlines", "(", ")", ",", "\n", "transform", "=", "prep", ".", "image_train", "(", "resize_size", "=", "255", ",", "crop_size", "=", "224", ")", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "10", ")", "\n", "if", "args", ".", "model_type", "==", "'resnet50'", "or", "args", ".", "model_type", "==", "'resnet152'", ":", "\n", "        ", "model", "=", "Model", "(", "args", ")", ".", "cuda", "(", ")", "\n", "", "elif", "args", ".", "model_type", "==", "'Alexnet'", ":", "\n", "        ", "model", "=", "AlexNetFc", "(", "args", ")", ".", "cuda", "(", ")", "\n", "\n", "", "criterion", "=", "nn", ".", "BCELoss", "(", ")", ".", "cuda", "(", ")", "\n", "#criterion = nn.MSELoss().cuda()", "\n", "params_list", "=", "[", "{", "'params'", ":", "model", ".", "feature_layers", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "multi_lr", "*", "args", ".", "lr", "}", ",", "# 0.05*(args.lr)", "\n", "{", "'params'", ":", "model", ".", "hash_layer", ".", "parameters", "(", ")", "}", "]", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params_list", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "\n", "#if len(args.gpu_ids)>1:", "\n", "#model =  torch.nn.DataParallel(model, device_ids=args.gpu_ids)", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", ".", "cuda", "(", ")", "\n", "\n", "print", "(", "'>>>>>>>>>>>>>>>>>>>>>>>>>>Start Train>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>'", ")", "\n", "best_MAP", "=", "0", "\n", "for", "epoch", "in", "range", "(", "total_epoch", ")", ":", "\n", "        ", "train", "(", "model", ",", "args", ",", "train_loader", ",", "criterion", ",", "Hash_center", ",", "optimizer", ",", "epoch", ",", "two_loss_epoch", ")", "\n", "\n", "if", "epoch", "%", "5", "==", "0", ":", "\n", "            ", "print", "(", "'Testing, epoch: %d'", "%", "epoch", ")", "\n", "MAP", "=", "test_MAP", "(", "model", ",", "database_loader", ",", "test_loader", ",", "args", ")", "\n", "if", "MAP", ">", "best_MAP", ":", "\n", "                ", "best_MAP", "=", "MAP", "\n", "file_dir", "=", "args", ".", "data_name", "\n", "dir_name", "=", "'data/'", "+", "file_dir", "+", "'/'", "+", "'models/'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'bit_'", "+", "str", "(", "epoch", ")", "+", "'e_'", "+", "str", "(", "\"{:.4g}\"", ".", "format", "(", "MAP", ")", ")", "+", "'_'", "+", "args", ".", "model_type", "+", "'.pkl'", "\n", "torch", ".", "save", "(", "model", ",", "dir_name", ")", "\n", "print", "(", "'save model in: %s'", "%", "dir_name", ")", "\n", "", "print", "(", "'MAP:%.3f'", "%", "MAP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.train": [[102, 161], ["train.adjust_learning_rate", "model.train", "time.time", "enumerate", "time.time", "numpy.mean", "print", "optimizer.zero_grad", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "model", "criterion", "torch.mean", "torch.mean", "loss.backward", "optimizer.step", "total_loss.append", "loss.data.cpu().numpy", "time.time", "print", "train.Hash_center_multilables", "torch.autograd.Variable", "torch.autograd.Variable", "len", "model.narrow", "model.narrow", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "my_pairwise_loss.pairwise_loss", "torch.abs", "torch.abs", "int", "int", "int", "loss.data.cpu", "int", "int", "int", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.adjust_learning_rate", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.train", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.Hash_center_multilables", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.my_pairwise_loss.pairwise_loss"], ["", "", "", "def", "train", "(", "model", ",", "args", ",", "train_loader", ",", "criterion", ",", "Hash_center", ",", "optimizer", ",", "epoch", ",", "two_loss_epoch", ")", ":", "\n", "    ", "lr", "=", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "model", ".", "train", "(", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "iter_num", "=", "0", "\n", "total_loss", "=", "[", "]", "\n", "for", "i", ",", "(", "input", ",", "label", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "data_name", "==", "'imagenet'", ":", "\n", "            ", "hash_label", "=", "(", "label", "==", "1", ")", ".", "nonzero", "(", ")", "[", ":", ",", "1", "]", "\n", "hash_center", "=", "Hash_center", "[", "hash_label", "]", "\n", "", "elif", "args", ".", "data_name", "==", "'nus_wide'", "or", "args", ".", "data_name", "==", "'coco'", ":", "\n", "            ", "hash_center", "=", "Hash_center_multilables", "(", "label", ",", "Hash_center", ")", "\n", "#hash_label = (torch.cumsum(torch.cumsum(label, dim=1), dim=1) == 1).nonzero()[:, 1] # obtain the index of first 1 element in every row", "\n", "#hash_center = Hash_center[hash_label]", "\n", "\n", "", "hash_center", "=", "Variable", "(", "hash_center", ")", ".", "cuda", "(", ")", "\n", "\n", "input", "=", "Variable", "(", "input", ")", ".", "cuda", "(", ")", "\n", "y", "=", "model", "(", "input", ")", "\n", "\n", "#y = y[torch.mean(label.float(), dim=1)!=0]  # ignore some training image whose label is all zeros, this is for nus_wide", "\n", "#hash_center = hash_center[torch.mean(label.float(), dim=1)!=0]", "\n", "\n", "center_loss", "=", "criterion", "(", "0.5", "*", "(", "y", "+", "1", ")", ",", "0.5", "*", "(", "hash_center", "+", "1", ")", ")", "\n", "Q_loss", "=", "torch", ".", "mean", "(", "(", "torch", ".", "abs", "(", "y", ")", "-", "1.0", ")", "**", "2", ")", "\n", "\n", "if", "epoch", "<=", "two_loss_epoch", ":", "\n", "            ", "loss", "=", "args", ".", "lambda0", "*", "center_loss", "+", "args", ".", "lambda2", "*", "Q_loss", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "label", ")", "<", "args", ".", "batch_size", ":", "# if the last batch is not a complete batch, just set similarity_loss=0", "\n", "                ", "similarity_loss", "=", "0", "\n", "# loss = center_loss #+ loss_mean", "\n", "", "else", ":", "\n", "                ", "output1", "=", "y", ".", "narrow", "(", "0", ",", "0", ",", "int", "(", "0.5", "*", "len", "(", "y", ")", ")", ")", "\n", "output2", "=", "y", ".", "narrow", "(", "0", ",", "int", "(", "0.5", "*", "len", "(", "y", ")", ")", ",", "int", "(", "0.5", "*", "len", "(", "y", ")", ")", ")", "\n", "label1", "=", "label", "[", "0", ":", "int", "(", "0.5", "*", "len", "(", "label", ")", ")", "]", "# shape: [1/2*batch_size, num_class]", "\n", "label2", "=", "label", "[", "int", "(", "0.5", "*", "len", "(", "label", ")", ")", ":", "int", "(", "len", "(", "label", ")", ")", "]", "# shape: [1/2*batch_size, num_class]", "\n", "label1", "=", "torch", ".", "autograd", ".", "Variable", "(", "label1", ")", ".", "cuda", "(", ")", "\n", "label2", "=", "torch", ".", "autograd", ".", "Variable", "(", "label2", ")", ".", "cuda", "(", ")", "\n", "similarity_loss", "=", "pairwise_loss", "(", "output1", ",", "output2", ",", "label1", ",", "label2", ",", "\n", "sigmoid_param", "=", "10.", "/", "args", ".", "hash_bit", ",", "\n", "#l_threshold=15,  # \"l_threshold\":15.0,", "\n", "data_imbalance", "=", "data_imbalance", ")", "# for imagenet, is 100", "\n", "", "loss", "=", "args", ".", "lambda0", "*", "center_loss", "+", "args", ".", "lambda1", "*", "similarity_loss", "+", "args", ".", "lambda2", "*", "Q_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "iter_num", "+=", "1", "\n", "total_loss", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "end_time1", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'epoch: %d, lr: %.5f iter_num: %d, time: %.3f, loss: %.3f'", "%", "(", "epoch", ",", "lr", ",", "iter_num", ",", "(", "end_time1", "-", "start_time", ")", ",", "loss", ")", ")", "\n", "\n", "\n", "", "", "end_epoch_time", "=", "time", ".", "time", "(", ")", "\n", "epoch_loss", "=", "np", ".", "mean", "(", "total_loss", ")", "\n", "print", "(", "'Epoch: %d, time: %.3f, epoch loss: %.3f'", "%", "(", "epoch", ",", "end_epoch_time", "-", "start_time", ",", "epoch_loss", ")", ")", "\n", "#if epoch_loss <= 0.2:", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.test_MAP": [[168, 181], ["print", "test.predict_hash_code", "print", "print", "print", "test.predict_hash_code", "print", "print", "print", "test.mean_average_precision"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.predict_hash_code", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.predict_hash_code", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.mean_average_precision"], ["", "def", "test_MAP", "(", "model", ",", "database_loader", ",", "test_loader", ",", "args", ")", ":", "\n", "    ", "print", "(", "'Waiting for generate the hash code from database'", ")", "\n", "database_hash", ",", "database_labels", "=", "predict_hash_code", "(", "model", ",", "database_loader", ")", "\n", "print", "(", "database_hash", ".", "shape", ")", "\n", "print", "(", "database_labels", ".", "shape", ")", "\n", "print", "(", "'Waiting for generate the hash code from test set'", ")", "\n", "test_hash", ",", "test_labels", "=", "predict_hash_code", "(", "model", ",", "test_loader", ")", "\n", "print", "(", "test_hash", ".", "shape", ")", "\n", "print", "(", "test_labels", ".", "shape", ")", "\n", "print", "(", "'Calculate MAP.....'", ")", "\n", "MAP", ",", "R", ",", "APx", "=", "mean_average_precision", "(", "database_hash", ",", "test_hash", ",", "database_labels", ",", "test_labels", ",", "args", ")", "\n", "\n", "return", "MAP", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.adjust_learning_rate": [[182, 191], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "args", ".", "lr", "*", "(", "0.7", "**", "(", "epoch", "//", "10", ")", ")", "\n", "#for param_group in optimizer.param_groups:", "\n", "#param_group['lr'] = lr", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "args", ".", "multi_lr", "*", "lr", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr", "\n", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.Hash_center_multilables": [[192, 216], ["one_labels.squeeze.squeeze", "torch.mean", "torch.mean", "Center_mean.view.view", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "Hash_center_multilables", "(", "labels", ",", "Hash_center", ")", ":", "# label.shape: [batch_size, num_class], Hash_center.shape: [num_class, hash_bits]", "\n", "    ", "is_start", "=", "True", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "one_labels", "=", "(", "label", "==", "1", ")", ".", "nonzero", "(", ")", "# find the position of 1 in label", "\n", "#if len(one_labels) == 0:    # In nus_wide dataset, some image's labels  are all zero, we ignore these images", "\n", "#Center_mean = torch.zeros((1, Hash_center.size(1))) # let it's hash center be zero", "\n", "#else:", "\n", "one_labels", "=", "one_labels", ".", "squeeze", "(", "1", ")", "\n", "Center_mean", "=", "torch", ".", "mean", "(", "Hash_center", "[", "one_labels", "]", ",", "dim", "=", "0", ")", "\n", "Center_mean", "[", "Center_mean", "<", "0", "]", "=", "-", "1", "\n", "Center_mean", "[", "Center_mean", ">", "0", "]", "=", "1", "\n", "#random_center = torch.randint_like(Hash_center[0], 2) # the random binary vector {0, 1}, has the same shape with label", "\n", "random_center", "[", "random_center", "==", "0", "]", "=", "-", "1", "# the random binary vector become {-1, 1}", "\n", "Center_mean", "[", "Center_mean", "==", "0", "]", "=", "random_center", "[", "Center_mean", "==", "0", "]", "# shape: [hash_bit]", "\n", "Center_mean", "=", "Center_mean", ".", "view", "(", "1", ",", "-", "1", ")", "# shape:[1,hash_bit]", "\n", "\n", "if", "is_start", ":", "# the first time", "\n", "            ", "hash_center", "=", "Center_mean", "\n", "is_start", "=", "False", "\n", "", "else", ":", "\n", "            ", "hash_center", "=", "torch", ".", "cat", "(", "(", "hash_center", ",", "Center_mean", ")", ",", "0", ")", "\n", "#hash_center = torch.stack((hash_center, Center_mean), dim=0)", "\n", "\n", "", "", "return", "hash_center", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.test.mean_average_precision": [[10, 51], ["numpy.dot", "numpy.argsort", "range", "numpy.sum", "numpy.cumsum", "numpy.sum", "Recall.append", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.sum", "np.cumsum.astype", "numpy.arange", "APx.append", "APx.append", "numpy.sum", "numpy.float", "numpy.array", "numpy.array", "numpy.sum"], "function", ["None"], ["def", "mean_average_precision", "(", "database_hash", ",", "test_hash", ",", "database_labels", ",", "test_labels", ",", "args", ")", ":", "# R = 1000", "\n", "# binary the hash code", "\n", "    ", "R", "=", "args", ".", "R", "\n", "T", "=", "args", ".", "T", "\n", "database_hash", "[", "database_hash", "<", "T", "]", "=", "-", "1", "\n", "database_hash", "[", "database_hash", ">=", "T", "]", "=", "1", "\n", "test_hash", "[", "test_hash", "<", "T", "]", "=", "-", "1", "\n", "test_hash", "[", "test_hash", ">=", "T", "]", "=", "1", "\n", "\n", "query_num", "=", "test_hash", ".", "shape", "[", "0", "]", "# total number for testing", "\n", "sim", "=", "np", ".", "dot", "(", "database_hash", ",", "test_hash", ".", "T", ")", "\n", "ids", "=", "np", ".", "argsort", "(", "-", "sim", ",", "axis", "=", "0", ")", "\n", "#data_dir = 'data/' + args.data_name", "\n", "#ids_10 = ids[:10, :]", "\n", "\n", "#np.save(data_dir + '/ids.npy', ids_10)", "\n", "APx", "=", "[", "]", "\n", "Recall", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "query_num", ")", ":", "# for i=0", "\n", "        ", "label", "=", "test_labels", "[", "i", ",", ":", "]", "# the first test labels", "\n", "if", "np", ".", "sum", "(", "label", ")", "==", "0", ":", "# ignore images with meaningless label in nus wide", "\n", "            ", "continue", "\n", "", "label", "[", "label", "==", "0", "]", "=", "-", "1", "\n", "idx", "=", "ids", "[", ":", ",", "i", "]", "\n", "imatch", "=", "np", ".", "sum", "(", "database_labels", "[", "idx", "[", "0", ":", "R", "]", ",", ":", "]", "==", "label", ",", "axis", "=", "1", ")", ">", "0", "\n", "relevant_num", "=", "np", ".", "sum", "(", "imatch", ")", "\n", "Lx", "=", "np", ".", "cumsum", "(", "imatch", ")", "\n", "Px", "=", "Lx", ".", "astype", "(", "float", ")", "/", "np", ".", "arange", "(", "1", ",", "R", "+", "1", ",", "1", ")", "#", "\n", "\n", "if", "relevant_num", "!=", "0", ":", "\n", "            ", "APx", ".", "append", "(", "np", ".", "sum", "(", "Px", "*", "imatch", ")", "/", "relevant_num", ")", "\n", "", "if", "relevant_num", "==", "0", ":", "# even no relevant image, still need add in APx for calculating the mean", "\n", "            ", "APx", ".", "append", "(", "0", ")", "\n", "\n", "", "all_relevant", "=", "np", ".", "sum", "(", "database_labels", "==", "label", ",", "axis", "=", "1", ")", ">", "0", "\n", "all_num", "=", "np", ".", "sum", "(", "all_relevant", ")", "\n", "r", "=", "relevant_num", "/", "np", ".", "float", "(", "all_num", ")", "\n", "Recall", ".", "append", "(", "r", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "APx", ")", ")", ",", "np", ".", "mean", "(", "np", ".", "array", "(", "Recall", ")", ")", ",", "APx", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.test.predict_hash_code": [[52, 69], ["model.eval", "enumerate", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "model", "torch.cat.cpu().numpy", "torch.cat.cpu().numpy", "model.data.cpu().float", "Variable().cuda.float", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat.cpu", "torch.cat.cpu", "model.data.cpu", "model.data.cpu().float", "Variable().cuda.float", "model.data.cpu"], "function", ["None"], ["", "def", "predict_hash_code", "(", "model", ",", "data_loader", ")", ":", "# data_loader is database_loader or test_loader", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "is_start", "=", "True", "\n", "for", "i", ",", "(", "input", ",", "label", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "input", "=", "Variable", "(", "input", ")", ".", "cuda", "(", ")", "\n", "label", "=", "Variable", "(", "label", ")", ".", "cuda", "(", ")", "\n", "y", "=", "model", "(", "input", ")", "\n", "\n", "if", "is_start", ":", "\n", "            ", "all_output", "=", "y", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "all_label", "=", "label", ".", "float", "(", ")", "\n", "is_start", "=", "False", "\n", "", "else", ":", "\n", "            ", "all_output", "=", "torch", ".", "cat", "(", "(", "all_output", ",", "y", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ")", ",", "0", ")", "\n", "all_label", "=", "torch", ".", "cat", "(", "(", "all_label", ",", "label", ".", "float", "(", ")", ")", ",", "0", ")", "\n", "\n", "", "", "return", "all_output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "all_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.test.test_MAP": [[71, 93], ["print", "test.predict_hash_code", "numpy.save", "numpy.save", "print", "print", "print", "test.predict_hash_code", "numpy.save", "numpy.save", "print", "print", "print", "test.mean_average_precision", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.predict_hash_code", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.predict_hash_code", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.mean_average_precision"], ["", "def", "test_MAP", "(", "model", ",", "database_loader", ",", "test_loader", ",", "args", ")", ":", "\n", "    ", "print", "(", "'Waiting for generate the hash code from database'", ")", "\n", "database_hash", ",", "database_labels", "=", "predict_hash_code", "(", "model", ",", "database_loader", ")", "\n", "file_dir", "=", "'data/'", "+", "args", ".", "data_name", "\n", "da_ha_name", "=", "args", ".", "data_name", "+", "'_'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_database_hash.npy'", "\n", "da_la_name", "=", "args", ".", "data_name", "+", "'_'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_database_label.npy'", "\n", "np", ".", "save", "(", "file_dir", "+", "'/'", "+", "da_ha_name", ",", "database_hash", ")", "\n", "np", ".", "save", "(", "file_dir", "+", "'/'", "+", "da_la_name", ",", "database_labels", ")", "\n", "print", "(", "database_hash", ".", "shape", ")", "\n", "print", "(", "database_labels", ".", "shape", ")", "\n", "print", "(", "'Waiting for generate the hash code from test set'", ")", "\n", "test_hash", ",", "test_labels", "=", "predict_hash_code", "(", "model", ",", "test_loader", ")", "\n", "te_ha_name", "=", "args", ".", "data_name", "+", "'_'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_test_hash.npy'", "\n", "te_la_name", "=", "args", ".", "data_name", "+", "'_'", "+", "str", "(", "args", ".", "hash_bit", ")", "+", "'_test_label.npy'", "\n", "np", ".", "save", "(", "file_dir", "+", "'/'", "+", "te_ha_name", ",", "test_hash", ")", "\n", "np", ".", "save", "(", "file_dir", "+", "'/'", "+", "te_la_name", ",", "test_labels", ")", "\n", "print", "(", "test_hash", ".", "shape", ")", "\n", "print", "(", "test_labels", ".", "shape", ")", "\n", "print", "(", "'Calculate MAP.....'", ")", "\n", "MAP", ",", "R", ",", "APx", "=", "mean_average_precision", "(", "database_hash", ",", "test_hash", ",", "database_labels", ",", "test_labels", ",", "args", ")", "\n", "\n", "return", "MAP", ",", "R", ",", "APx", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.ImageList.__init__": [[69, 80], ["data_list.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.make_dataset"], ["def", "__init__", "(", "self", ",", "image_list", ",", "labels", "=", "None", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ")", ":", "# ImageList(image_list = '../data/imagenet/train.txt')", "\n", "        ", "imgs", "=", "make_dataset", "(", "image_list", ",", "labels", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.ImageList.__getitem__": [[81, 96], ["data_list.ImageList.loader", "data_list.ImageList.transform", "data_list.ImageList.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.ImageList.__len__": [[97, 99], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.make_dataset": [[12, 22], ["len", "len", "image_list[].strip", "range", "image_list[].split", "numpy.array", "int", "val.split", "val.split", "int", "val.split", "val.split"], "function", ["None"], ["def", "make_dataset", "(", "image_list", ",", "labels", ")", ":", "\n", "    ", "if", "labels", ":", "# labels=None for imagenet", "\n", "      ", "len_", "=", "len", "(", "image_list", ")", "\n", "images", "=", "[", "(", "image_list", "[", "i", "]", ".", "strip", "(", ")", ",", "labels", "[", "i", ",", ":", "]", ")", "for", "i", "in", "range", "(", "len_", ")", "]", "\n", "", "else", ":", "# split and get the labels", "\n", "      ", "if", "len", "(", "image_list", "[", "0", "]", ".", "split", "(", ")", ")", ">", "2", ":", "\n", "        ", "images", "=", "[", "(", "val", ".", "split", "(", ")", "[", "0", "]", ",", "np", ".", "array", "(", "[", "int", "(", "la", ")", "for", "la", "in", "val", ".", "split", "(", ")", "[", "1", ":", "]", "]", ")", ")", "for", "val", "in", "image_list", "]", "\n", "", "else", ":", "\n", "        ", "images", "=", "[", "(", "val", ".", "split", "(", ")", "[", "0", "]", ",", "int", "(", "val", ".", "split", "(", ")", "[", "1", "]", ")", ")", "for", "val", "in", "image_list", "]", "\n", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.pil_loader": [[24, 29], ["open", "PIL.Image.open", "img.convert"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["", "def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "            ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.accimage_loader": [[31, 38], ["accimage.Image", "data_list.pil_loader"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.pil_loader"], ["", "", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "import", "accimage", "\n", "try", ":", "\n", "        ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.default_loader": [[40, 46], ["data_list.pil_loader"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.data_list.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "#from torchvision import get_image_backend", "\n", "#if get_image_backend() == 'accimage':", "\n", "#    return accimage_loader(path)", "\n", "#else:", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.my_pairwise_loss.pairwise_loss": [[6, 15], ["torch.autograd.Variable().float", "torch.exp", "torch.exp", "torch.mean", "torch.mean", "torch.mm", "torch.mm", "torch.log", "torch.log", "torch.autograd.Variable", "outputs2.t", "torch.mm", "torch.mm", "label1.data.float", "label2.data.float().t", "label2.data.float"], "function", ["None"], ["def", "pairwise_loss", "(", "outputs1", ",", "outputs2", ",", "label1", ",", "label2", ",", "sigmoid_param", "=", "1", ",", "data_imbalance", "=", "1", ")", ":", "\n", "    ", "similarity", "=", "Variable", "(", "torch", ".", "mm", "(", "label1", ".", "data", ".", "float", "(", ")", ",", "label2", ".", "data", ".", "float", "(", ")", ".", "t", "(", ")", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "dot_product", "=", "sigmoid_param", "*", "torch", ".", "mm", "(", "outputs1", ",", "outputs2", ".", "t", "(", ")", ")", "\n", "exp_product", "=", "torch", ".", "exp", "(", "dot_product", ")", "\n", "\n", "exp_loss", "=", "(", "torch", ".", "log", "(", "1", "+", "exp_product", ")", "-", "similarity", "*", "dot_product", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "exp_loss", ")", "\n", "\n", "return", "loss", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.ResizeImage.__init__": [[9, 14], ["isinstance", "int", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "      ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "        ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "", "", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.ResizeImage.__call__": [[14, 17], ["img.resize"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "      ", "th", ",", "tw", "=", "self", ".", "size", "\n", "return", "img", ".", "resize", "(", "(", "th", ",", "tw", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.PlaceCrop.__init__": [[27, 34], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "start_x", ",", "start_y", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "self", ".", "start_x", "=", "start_x", "\n", "self", ".", "start_y", "=", "start_y", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.PlaceCrop.__call__": [[35, 44], ["img.crop"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL.Image): Image to be cropped.\n        Returns:\n            PIL.Image: Cropped image.\n        \"\"\"", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "return", "img", ".", "crop", "(", "(", "self", ".", "start_x", ",", "self", ".", "start_y", ",", "self", ".", "start_x", "+", "tw", ",", "self", ".", "start_y", "+", "th", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.ForceFlip.__call__": [[49, 57], ["img.transpose"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL.Image): Image to be flipped.\n        Returns:\n            PIL.Image: Randomly flipped image.\n        \"\"\"", "\n", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_train": [[58, 67], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "pre_process.ResizeImage", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "", "def", "image_train", "(", "resize_size", "=", "256", ",", "crop_size", "=", "224", ")", ":", "\n", "  ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "transforms", ".", "RandomResizedCrop", "(", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_test": [[69, 82], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "image_test", "(", "resize_size", "=", "256", ",", "crop_size", "=", "224", ")", ":", "\n", "  ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "#ten crops for image when validation, input the data_transforms dictionary", "\n", "start_first", "=", "0", "\n", "start_center", "=", "(", "resize_size", "-", "crop_size", "-", "1", ")", "/", "2", "\n", "start_last", "=", "resize_size", "-", "crop_size", "-", "1", "\n", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_center", ",", "start_center", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_test_10crop": [[84, 153], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "pre_process.ResizeImage", "pre_process.ForceFlip", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.ForceFlip", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.ForceFlip", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.ForceFlip", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.ForceFlip", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor", "pre_process.ResizeImage", "pre_process.PlaceCrop", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "image_test_10crop", "(", "resize_size", "=", "256", ",", "crop_size", "=", "224", ")", ":", "\n", "  ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "#ten crops for image when validation, input the data_transforms dictionary", "\n", "start_first", "=", "0", "\n", "start_center", "=", "(", "resize_size", "-", "crop_size", "-", "1", ")", "/", "2", "\n", "start_last", "=", "resize_size", "-", "crop_size", "-", "1", "\n", "data_transforms", "=", "{", "}", "\n", "data_transforms", "[", "'val0'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "ForceFlip", "(", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_first", ",", "start_first", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val1'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "ForceFlip", "(", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_last", ",", "start_last", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val2'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "ForceFlip", "(", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_last", ",", "start_first", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val3'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "ForceFlip", "(", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_first", ",", "start_last", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val4'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "ForceFlip", "(", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_center", ",", "start_center", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val5'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_first", ",", "start_first", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val6'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_last", ",", "start_last", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val7'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_last", ",", "start_first", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val8'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_first", ",", "start_last", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "data_transforms", "[", "'val9'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "ResizeImage", "(", "resize_size", ")", ",", "\n", "PlaceCrop", "(", "crop_size", ",", "start_center", ",", "start_center", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "return", "data_transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_train_cifar": [[154, 162], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "image_train_cifar", "(", "resize_size", "=", "256", ",", "crop_size", "=", "224", ")", ":", "\n", "  ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", ",", "\n", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", ")", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.pre_process.image_test_cifar": [[164, 170], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "image_test_cifar", "(", "resize_size", "=", "256", ",", "crop_size", "=", "224", ")", ":", "\n", "  ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", ",", "\n", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", ")", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.train_ucf101.autofill": [[85, 97], ["os.path.join", "os.path.basename", "os.path.exists", "os.getcwd", "socket.gethostname", "socket.gethostname"], "function", ["None"], ["def", "autofill", "(", "args", ")", ":", "\n", "# customized", "\n", "    ", "if", "not", "args", ".", "task_name", ":", "\n", "        ", "args", ".", "task_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "getcwd", "(", ")", ")", "\n", "", "if", "not", "args", ".", "log_file", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "\"./exps/logs\"", ")", ":", "\n", "            ", "args", ".", "log_file", "=", "\"./exps/logs/{}_at-{}.log\"", ".", "format", "(", "args", ".", "task_name", ",", "socket", ".", "gethostname", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "log_file", "=", "\".{}_at-{}.log\"", ".", "format", "(", "args", ".", "task_name", ",", "socket", ".", "gethostname", "(", ")", ")", "\n", "# fixed", "\n", "", "", "args", ".", "model_prefix", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "args", ".", "task_name", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.train_ucf101.set_logger": [[98, 111], ["logging.basicConfig", "os.path.exists", "os.makedirs", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["", "def", "set_logger", "(", "log_file", "=", "''", ",", "debug_mode", "=", "False", ")", ":", "\n", "    ", "if", "log_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "", "handlers", "=", "[", "logging", ".", "FileHandler", "(", "log_file", ")", ",", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "", "\"\"\" add '%(filename)s:%(lineno)d %(levelname)s:' to format show source file \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", "if", "debug_mode", "else", "logging", ".", "INFO", ",", "\n", "format", "=", "'%(asctime)s: %(message)s'", ",", "\n", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ",", "\n", "handlers", "=", "handlers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.train_hmdb51.autofill": [[85, 97], ["os.path.join", "os.path.basename", "os.path.exists", "os.getcwd", "socket.gethostname", "socket.gethostname"], "function", ["None"], ["def", "autofill", "(", "args", ")", ":", "\n", "# customized", "\n", "    ", "if", "not", "args", ".", "task_name", ":", "\n", "        ", "args", ".", "task_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "getcwd", "(", ")", ")", "\n", "", "if", "not", "args", ".", "log_file", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "\"./exps/logs\"", ")", ":", "\n", "            ", "args", ".", "log_file", "=", "\"./exps/logs/{}_at-{}.log\"", ".", "format", "(", "args", ".", "task_name", ",", "socket", ".", "gethostname", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "log_file", "=", "\".{}_at-{}.log\"", ".", "format", "(", "args", ".", "task_name", ",", "socket", ".", "gethostname", "(", ")", ")", "\n", "# fixed", "\n", "", "", "args", ".", "model_prefix", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "args", ".", "task_name", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.train_hmdb51.set_logger": [[98, 111], ["logging.basicConfig", "os.path.exists", "os.makedirs", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["", "def", "set_logger", "(", "log_file", "=", "''", ",", "debug_mode", "=", "False", ")", ":", "\n", "    ", "if", "log_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "", "handlers", "=", "[", "logging", ".", "FileHandler", "(", "log_file", ")", ",", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "", "\"\"\" add '%(filename)s:%(lineno)d %(levelname)s:' to format show source file \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", "if", "debug_mode", "else", "logging", ".", "INFO", ",", "\n", "format", "=", "'%(asctime)s: %(message)s'", ",", "\n", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ",", "\n", "handlers", "=", "handlers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.train_model.train_model": [[15, 123], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "data.iterator_factory.creat", "print", "print", "train.model.model", "train.model.model.net.cuda", "train.model.model.net.named_parameters", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "train.lr_scheduler.MultiFactorScheduler", "train.metric.MetricList", "train.model.model.fit", "len", "len", "logging.info", "torch.nn.parallel.DistributedDataParallel().cuda", "torch.nn.parallel.DistributedDataParallel().cuda", "torch.nn.parallel.DistributedDataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "train.model.model.load_checkpoint", "torch.get_world_size", "train.metric.Loss", "torch.initial_seed", "torch.initial_seed", "torch.initial_seed", "max", "torch.nn.BCELoss().cuda", "torch.nn.BCELoss().cuda", "torch.nn.BCELoss().cuda", "name.startswith", "param_new_layers.append", "os.path.exists", "logging.info", "torch.load", "torch.load", "torch.load", "train.model.model.load_state", "logging.info", "train_iter.__len__", "param_new_layers.append", "param_base_layers.append", "name_base_layers.append", "len", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "int", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "len"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.creat", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.fit", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.load_checkpoint", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.load_state", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__len__"], ["def", "train_model", "(", "Hash_center", ",", "sym_net", ",", "model_prefix", ",", "dataset", ",", "input_conf", ",", "hash_bit", ",", "\n", "clip_length", "=", "16", ",", "train_frame_interval", "=", "2", ",", "val_frame_interval", "=", "2", ",", "\n", "resume_epoch", "=", "-", "1", ",", "batch_size", "=", "4", ",", "save_frequency", "=", "1", ",", "\n", "lr_base", "=", "0.01", ",", "lr_factor", "=", "0.1", ",", "lr_steps", "=", "[", "400000", ",", "800000", "]", ",", "\n", "end_epoch", "=", "1000", ",", "distributed", "=", "False", ",", "\n", "pretrained_3d", "=", "None", ",", "fine_tune", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"Currently, we only support CUDA version\"", "\n", "\n", "# data iterator", "\n", "iter_seed", "=", "torch", ".", "initial_seed", "(", ")", "+", "(", "torch", ".", "distributed", ".", "get_rank", "(", ")", "*", "10", "if", "distributed", "else", "100", ")", "+", "max", "(", "0", ",", "resume_epoch", ")", "*", "100", "\n", "train_iter", ",", "eval_iter", "=", "iterator_factory", ".", "creat", "(", "name", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "clip_length", "=", "clip_length", ",", "\n", "train_interval", "=", "train_frame_interval", ",", "\n", "val_interval", "=", "val_frame_interval", ",", "\n", "mean", "=", "input_conf", "[", "'mean'", "]", ",", "\n", "std", "=", "input_conf", "[", "'std'", "]", ",", "\n", "seed", "=", "iter_seed", ")", "\n", "print", "(", "len", "(", "train_iter", ")", ")", "\n", "print", "(", "len", "(", "eval_iter", ")", ")", "\n", "# wapper (dynamic model)", "\n", "net", "=", "model", "(", "net", "=", "sym_net", ",", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", ".", "cuda", "(", ")", ",", "\n", "model_prefix", "=", "model_prefix", ",", "\n", "step_callback_freq", "=", "50", ",", "\n", "save_checkpoint_freq", "=", "save_frequency", ",", "\n", "opt_batch_size", "=", "batch_size", ",", "# optional", "\n", "dataset", "=", "dataset", ",", "# dataset name", "\n", "hash_bit", "=", "hash_bit", ",", "\n", ")", "\n", "net", ".", "net", ".", "cuda", "(", ")", "\n", "\n", "# config optimization", "\n", "param_base_layers", "=", "[", "]", "\n", "param_new_layers", "=", "[", "]", "\n", "name_base_layers", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "net", ".", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "fine_tune", ":", "\n", "#print(f'fine tune {fine_tune}')", "\n", "            ", "if", "name", ".", "startswith", "(", "'hash'", ")", ":", "\n", "                ", "param_new_layers", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "                ", "param_base_layers", ".", "append", "(", "param", ")", "\n", "name_base_layers", ".", "append", "(", "name", ")", "\n", "", "", "else", ":", "\n", "            ", "param_new_layers", ".", "append", "(", "param", ")", "\n", "\n", "", "", "if", "name_base_layers", ":", "\n", "        ", "out", "=", "\"[\\'\"", "+", "'\\', \\''", ".", "join", "(", "name_base_layers", ")", "+", "\"\\']\"", "\n", "logging", ".", "info", "(", "\"Optimizer:: >> recuding the learning rate of {} params: {}\"", ".", "format", "(", "len", "(", "name_base_layers", ")", ",", "\n", "out", "if", "len", "(", "out", ")", "<", "300", "else", "out", "[", "0", ":", "150", "]", "+", "\" ... \"", "+", "out", "[", "-", "150", ":", "]", ")", ")", "\n", "\n", "", "if", "distributed", ":", "\n", "        ", "net", ".", "net", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "net", ".", "net", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "net", ".", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "net", ".", "net", ")", ".", "cuda", "(", ")", "\n", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "param_base_layers", ",", "'lr_mult'", ":", "0.2", "}", ",", "\n", "{", "'params'", ":", "param_new_layers", ",", "'lr_mult'", ":", "1.0", "}", "]", ",", "\n", "lr", "=", "lr_base", ",", "\n", "momentum", "=", "0.9", ",", "\n", "weight_decay", "=", "0.0001", ",", "\n", "nesterov", "=", "True", ")", "\n", "\n", "# load params from pretrained 3d network", "\n", "if", "pretrained_3d", ":", "\n", "        ", "if", "resume_epoch", "<", "0", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "pretrained_3d", ")", ",", "\"cannot locate: `{}'\"", ".", "format", "(", "pretrained_3d", ")", "\n", "logging", ".", "info", "(", "\"Initializer:: loading model states from: `{}'\"", ".", "format", "(", "pretrained_3d", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "pretrained_3d", ")", "\n", "net", ".", "load_state", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"Initializer:: skip loading model states from: `{}'\"", "\n", "+", "\", since it's going to be overwrited by the resumed model\"", ".", "format", "(", "pretrained_3d", ")", ")", "\n", "\n", "# resume training: model and optimizer", "\n", "", "", "if", "resume_epoch", "<", "0", ":", "\n", "        ", "epoch_start", "=", "0", "\n", "step_counter", "=", "0", "\n", "", "else", ":", "\n", "        ", "net", ".", "load_checkpoint", "(", "epoch", "=", "resume_epoch", ",", "optimizer", "=", "optimizer", ")", "\n", "epoch_start", "=", "resume_epoch", "\n", "step_counter", "=", "epoch_start", "*", "train_iter", ".", "__len__", "(", ")", "\n", "\n", "# set learning rate scheduler", "\n", "", "num_worker", "=", "dist", ".", "get_world_size", "(", ")", "if", "torch", ".", "distributed", ".", "_initialized", "else", "1", "\n", "lr_scheduler", "=", "MultiFactorScheduler", "(", "base_lr", "=", "lr_base", ",", "\n", "steps", "=", "[", "int", "(", "x", "/", "(", "batch_size", "*", "num_worker", ")", ")", "for", "x", "in", "lr_steps", "]", ",", "\n", "factor", "=", "lr_factor", ",", "\n", "step_counter", "=", "step_counter", ")", "\n", "# define evaluation metric", "\n", "metrics", "=", "metric", ".", "MetricList", "(", "metric", ".", "Loss", "(", "name", "=", "\"loss-ce\"", ")", ")", "\n", "\n", "# enable cudnn tune", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "net", ".", "fit", "(", "train_iter", "=", "train_iter", ",", "\n", "eval_iter", "=", "eval_iter", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "metrics", "=", "metrics", ",", "\n", "epoch_start", "=", "epoch_start", ",", "\n", "epoch_end", "=", "end_epoch", ",", "\n", "Hash_center", "=", "Hash_center", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.mean_average_precision": [[20, 57], ["numpy.dot", "numpy.argsort", "numpy.save", "range", "numpy.sum", "numpy.cumsum", "numpy.mean", "np.cumsum.astype", "numpy.arange", "APx.append", "APx.append", "numpy.array", "numpy.sum"], "function", ["None"], ["def", "mean_average_precision", "(", "database_hash", ",", "test_hash", ",", "database_labels", ",", "test_labels", ",", "args", ")", ":", "# R = 1000", "\n", "# binary the hash code", "\n", "    ", "R", "=", "args", ".", "R", "\n", "T", "=", "args", ".", "T", "\n", "database_hash", "[", "database_hash", "<", "T", "]", "=", "-", "1", "\n", "database_hash", "[", "database_hash", ">=", "T", "]", "=", "1", "\n", "test_hash", "[", "test_hash", "<", "T", "]", "=", "-", "1", "\n", "test_hash", "[", "test_hash", ">=", "T", "]", "=", "1", "\n", "\n", "query_num", "=", "test_hash", ".", "shape", "[", "0", "]", "# total number for testing", "\n", "sim", "=", "np", ".", "dot", "(", "database_hash", ",", "test_hash", ".", "T", ")", "\n", "ids", "=", "np", ".", "argsort", "(", "-", "sim", ",", "axis", "=", "0", ")", "\n", "ids_100", "=", "ids", "[", ":", "100", ",", ":", "]", "\n", "file_dir", "=", "'dataset/'", "+", "args", ".", "dataset", "\n", "np", ".", "save", "(", "file_dir", "+", "'/ids.npy'", ",", "ids_100", ")", "\n", "APx", "=", "[", "]", "\n", "Recall", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "query_num", ")", ":", "# for i=0", "\n", "        ", "label", "=", "test_labels", "[", "i", "]", "# the first test labels", "\n", "idx", "=", "ids", "[", ":", ",", "i", "]", "\n", "imatch", "=", "(", "database_labels", "[", "idx", "[", "0", ":", "R", "]", "]", "==", "label", ")", ">", "0", "\n", "relevant_num", "=", "np", ".", "sum", "(", "imatch", ")", "\n", "Lx", "=", "np", ".", "cumsum", "(", "imatch", ")", "\n", "Px", "=", "Lx", ".", "astype", "(", "float", ")", "/", "np", ".", "arange", "(", "1", ",", "R", "+", "1", ",", "1", ")", "#", "\n", "\n", "if", "relevant_num", "!=", "0", ":", "\n", "            ", "APx", ".", "append", "(", "np", ".", "sum", "(", "Px", "*", "imatch", ")", "/", "relevant_num", ")", "\n", "", "if", "relevant_num", "==", "0", ":", "# even no relevant image, still need add in APx for calculating the mean", "\n", "            ", "APx", ".", "append", "(", "0", ")", "\n", "\n", "#all_relevant = np.sum(database_labels == label, axis=1) > 0", "\n", "#all_num = np.sum(all_relevant)", "\n", "#r = relevant_num / np.float(all_num)", "\n", "#Recall.append(r)", "\n", "\n", "", "", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "APx", ")", ")", ",", "APx", "#np.mean(np.array(Recall)), APx", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.video.hash_test.predict_hash_code": [[59, 81], ["model.eval", "enumerate", "input.float().cuda.float().cuda", "target.cuda.cuda", "model", "torch.cat.cpu().numpy", "torch.cat.cpu().numpy", "video_path.append", "model.data.cpu().float", "target.cuda.float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "input.float().cuda.float", "torch.cat.cpu", "torch.cat.cpu", "model.data.cpu", "model.data.cpu().float", "target.cuda.float", "model.data.cpu"], "function", ["None"], ["", "def", "predict_hash_code", "(", "model", ",", "data_loader", ")", ":", "# data_loader is database_loader or test_loader", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "is_start", "=", "True", "\n", "video_path", "=", "[", "]", "\n", "for", "i", ",", "(", "input", ",", "target", ",", "video_subpath", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "input", "=", "input", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "y", "=", "model", "(", "input", ")", "\n", "for", "subpath", "in", "video_subpath", ":", "\n", "            ", "video_path", ".", "append", "(", "subpath", ")", "\n", "", "if", "is_start", ":", "\n", "            ", "all_output", "=", "y", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "all_label", "=", "target", ".", "float", "(", ")", "\n", "is_start", "=", "False", "\n", "", "else", ":", "\n", "            ", "all_output", "=", "torch", ".", "cat", "(", "(", "all_output", ",", "y", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ")", ",", "0", ")", "\n", "all_label", "=", "torch", ".", "cat", "(", "(", "all_label", ",", "target", ".", "float", "(", ")", ")", ",", "0", ")", "\n", "\n", "", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "'Generating, batch: %d'", "%", "i", ")", "\n", "\n", "", "", "return", "all_output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "all_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "video_path", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.test.evaluate_video_ucf101_split1.autofill": [[53, 60], ["os.path.join", "os.path.basename", "os.getcwd"], "function", ["None"], ["def", "autofill", "(", "args", ")", ":", "\n", "# customized", "\n", "    ", "if", "not", "args", ".", "task_name", ":", "\n", "        ", "args", ".", "task_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "getcwd", "(", ")", ")", "\n", "# fixed", "\n", "", "args", ".", "model_prefix", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "args", ".", "task_name", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.test.evaluate_video_ucf101_split1.set_logger": [[61, 74], ["logging.basicConfig", "os.path.exists", "os.makedirs", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["", "def", "set_logger", "(", "log_file", "=", "''", ",", "debug_mode", "=", "False", ")", ":", "\n", "    ", "if", "log_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "", "handlers", "=", "[", "logging", ".", "FileHandler", "(", "log_file", ")", ",", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "", "\"\"\" add '%(filename)s' to format show source file \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", "if", "debug_mode", "else", "logging", ".", "INFO", ",", "\n", "format", "=", "'%(asctime)s %(levelname)s: %(message)s'", ",", "\n", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ",", "\n", "handlers", "=", "handlers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.test.evaluate_speed.set_logger": [[42, 55], ["logging.basicConfig", "os.path.exists", "os.makedirs", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["def", "set_logger", "(", "log_file", "=", "''", ",", "debug_mode", "=", "False", ")", ":", "\n", "    ", "if", "log_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "\"./\"", "+", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "", "handlers", "=", "[", "logging", ".", "FileHandler", "(", "log_file", ")", ",", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "", "\"\"\" add '%(filename)s' to format show source file \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", "if", "debug_mode", "else", "logging", ".", "INFO", ",", "\n", "format", "=", "'%(asctime)s %(levelname)s: %(message)s'", ",", "\n", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ",", "\n", "handlers", "=", "handlers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.config.get_config": [[3, 21], ["logging.debug", "logging.info", "name.upper", "logging.info", "name.upper"], "function", ["None"], ["def", "get_config", "(", "name", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "logging", ".", "debug", "(", "\"loading network configs of: {}\"", ".", "format", "(", "name", ".", "upper", "(", ")", ")", ")", "\n", "\n", "config", "=", "{", "}", "\n", "\n", "if", "\"3D\"", "in", "name", ".", "upper", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Preprocessing:: using MXNet default mean & std.\"", ")", "\n", "config", "[", "'mean'", "]", "=", "[", "124", "/", "255", ",", "117", "/", "255", ",", "104", "/", "255", "]", "\n", "config", "[", "'std'", "]", "=", "[", "1", "/", "(", ".0167", "*", "255", ")", "]", "*", "3", "\n", "", "else", ":", "\n", "        ", "config", "[", "'mean'", "]", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "config", "[", "'std'", "]", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "# else:", "\n", "#    raise NotImplemented(\"Configs for {} not implemented\".format(name))", "\n", "\n", "", "logging", ".", "info", "(", "\"data:: {}\"", ".", "format", "(", "config", ")", ")", "\n", "return", "config", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.initializer.xavier": [[8, 31], ["net.apply", "hasattr", "torch.nn.init.xavier_uniform", "classname.find", "m.bias.data.zero_", "classname.find", "m.weight.data.fill_", "m.bias.data.zero_", "classname.find", "torch.nn.init.xavier_uniform", "m.bias.data.zero_", "classname.upper", "logging.warning"], "function", ["None"], ["def", "xavier", "(", "net", ")", ":", "\n", "    ", "def", "weights_init", "(", "m", ")", ":", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "and", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "1.", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "1.", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "classname", "in", "[", "'Sequential'", ",", "'AvgPool3d'", ",", "'MaxPool3d'", ",", "'Dropout'", ",", "'ReLU'", ",", "'Softmax'", ",", "'BnActConv3d'", "]", "or", "'Block'", "in", "classname", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "classname", "!=", "classname", ".", "upper", "(", ")", ":", "\n", "                ", "logging", ".", "warning", "(", "\"Initializer:: '{}' is uninitialized.\"", ".", "format", "(", "classname", ")", ")", "\n", "", "", "", "net", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.initializer.init_from_dict": [[34, 52], ["logging.debug", "net.load_state_dict", "list", "state_dict.items", "net.state_dict().keys", "logging.info", "[].copy_", "list.remove", "net.state_dict", "param.view", "json.dumps", "net.state_dict", "net.state_dict"], "function", ["None"], ["", "def", "init_from_dict", "(", "net", ",", "state_dict", ",", "strict", "=", "False", ")", ":", "\n", "    ", "logging", ".", "debug", "(", "\"Initializer:: loading from `state_dic', strict = {} ...\"", ".", "format", "(", "strict", ")", ")", "\n", "\n", "if", "strict", ":", "\n", "        ", "net", ".", "load_state_dict", "(", "state_dict", "=", "state_dict", ")", "\n", "", "else", ":", "\n", "# customized partialy load function", "\n", "        ", "net_state_keys", "=", "list", "(", "net", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "\n", "for", "name", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "in", "net_state_keys", ":", "\n", "                ", "dst_param_shape", "=", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "shape", "\n", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "copy_", "(", "param", ".", "view", "(", "dst_param_shape", ")", ")", "\n", "net_state_keys", ".", "remove", "(", "name", ")", "\n", "\n", "# indicating missed keys", "\n", "", "", "if", "net_state_keys", ":", "\n", "            ", "logging", ".", "info", "(", "\"Initializer:: failed to load: \\n{}\"", ".", "format", "(", "\n", "json", ".", "dumps", "(", "net_state_keys", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.initializer.init_3d_from_2d_dict": [[54, 136], ["logging.debug", "list", "list", "state_dict.items", "src.view.numpy", "state_dict.keys", "net.state_dict().keys", "logging.info", "logging.info", "torch.FloatTensor", "src.view.view", "torch.from_numpy.copy_", "[].copy_", "list.remove", "list.remove", "float", "torch.FloatTensor", "torch.FloatTensor", "src.view.abs().mean", "dst[].copy_", "torch.from_numpy.numpy().swapaxes", "numpy.ndindex", "torch.from_numpy", "net.state_dict", "name.startswith", "len", "json.dumps", "float", "numpy.random.shuffle", "net.state_dict", "list", "src.view.abs", "torch.nn.init.uniform", "dst[].copy_", "dst[].copy_", "dst[].copy_", "torch.from_numpy.numpy", "len", "len", "initializer.init_3d_from_2d_dict.filling_kernel"], "function", ["None"], ["", "", "", "def", "init_3d_from_2d_dict", "(", "net", ",", "state_dict", ",", "method", "=", "'inflation'", ")", ":", "\n", "    ", "logging", ".", "debug", "(", "\"Initializer:: loading from 2D neural network, filling method: `{}' ...\"", ".", "format", "(", "method", ")", ")", "\n", "\n", "# filling method", "\n", "def", "filling_kernel", "(", "src", ",", "dshape", ",", "method", ")", ":", "\n", "        ", "assert", "method", "in", "[", "'inflation'", ",", "'random'", "]", ",", "\"filling method: {} is unknown!\"", ".", "format", "(", "method", ")", "\n", "src_np", "=", "src", ".", "numpy", "(", ")", "\n", "\n", "if", "method", "==", "'inflation'", ":", "\n", "            ", "dst", "=", "torch", ".", "FloatTensor", "(", "dshape", ")", "\n", "# normalize", "\n", "src", "=", "src", "/", "float", "(", "dshape", "[", "2", "]", ")", "\n", "src", "=", "src", ".", "view", "(", "dshape", "[", "0", "]", ",", "dshape", "[", "1", "]", ",", "1", ",", "dshape", "[", "3", "]", ",", "dshape", "[", "4", "]", ")", "\n", "dst", ".", "copy_", "(", "src", ")", "\n", "", "elif", "method", "==", "'random'", ":", "\n", "            ", "dst", "=", "torch", ".", "FloatTensor", "(", "dshape", ")", "\n", "tmp", "=", "torch", ".", "FloatTensor", "(", "src", ".", "shape", ")", "\n", "# normalize", "\n", "src", "=", "src", "/", "float", "(", "dshape", "[", "2", "]", ")", "\n", "# random range", "\n", "scale", "=", "src", ".", "abs", "(", ")", ".", "mean", "(", ")", "\n", "# filling", "\n", "dst", "[", ":", ",", ":", ",", "0", ",", ":", ",", ":", "]", ".", "copy_", "(", "src", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "dshape", "[", "2", "]", ":", "\n", "                ", "if", "i", "+", "2", "<", "dshape", "[", "2", "]", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "uniform", "(", "tmp", ",", "a", "=", "-", "scale", ",", "b", "=", "scale", ")", "\n", "dst", "[", ":", ",", ":", ",", "i", ",", ":", ",", ":", "]", ".", "copy_", "(", "tmp", ")", "\n", "dst", "[", ":", ",", ":", ",", "i", "+", "1", ",", ":", ",", ":", "]", ".", "copy_", "(", "src", ")", "\n", "dst", "[", ":", ",", ":", ",", "i", "+", "2", ",", ":", ",", ":", "]", ".", "copy_", "(", "-", "tmp", ")", "\n", "i", "+=", "3", "\n", "", "elif", "i", "+", "1", "<", "dshape", "[", "2", "]", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "uniform", "(", "tmp", ",", "a", "=", "-", "scale", ",", "b", "=", "scale", ")", "\n", "dst", "[", ":", ",", ":", ",", "i", ",", ":", ",", ":", "]", ".", "copy_", "(", "tmp", ")", "\n", "dst", "[", ":", ",", ":", ",", "i", "+", "1", ",", ":", ",", ":", "]", ".", "copy_", "(", "-", "tmp", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "dst", "[", ":", ",", ":", ",", "i", ",", ":", ",", ":", "]", ".", "copy_", "(", "src", ")", "\n", "i", "+=", "1", "\n", "# shuffle", "\n", "", "", "tmp", "=", "dst", ".", "numpy", "(", ")", ".", "swapaxes", "(", "2", ",", "-", "1", ")", "\n", "shp", "=", "tmp", ".", "shape", "[", ":", "-", "1", "]", "\n", "for", "ndx", "in", "np", ".", "ndindex", "(", "shp", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "tmp", "[", "ndx", "]", ")", "\n", "", "dst", "=", "torch", ".", "from_numpy", "(", "tmp", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "dst", "\n", "\n", "\n", "# customized partialy loading function", "\n", "", "src_state_keys", "=", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "dst_state_keys", "=", "list", "(", "net", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "\n", "for", "name", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "name", "in", "dst_state_keys", ":", "\n", "            ", "src_param_shape", "=", "param", ".", "shape", "\n", "dst_param_shape", "=", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "shape", "\n", "if", "src_param_shape", "!=", "dst_param_shape", ":", "\n", "                ", "if", "name", ".", "startswith", "(", "'classifier'", ")", ":", "\n", "                    ", "continue", "\n", "", "assert", "len", "(", "src_param_shape", ")", "==", "4", "and", "len", "(", "dst_param_shape", ")", "==", "5", ",", "\"{} mismatch\"", ".", "format", "(", "name", ")", "\n", "if", "list", "(", "src_param_shape", ")", "==", "[", "dst_param_shape", "[", "i", "]", "for", "i", "in", "[", "0", ",", "1", ",", "3", ",", "4", "]", "]", ":", "\n", "                    ", "if", "dst_param_shape", "[", "2", "]", "!=", "1", ":", "\n", "                        ", "param", "=", "filling_kernel", "(", "src", "=", "param", ",", "dshape", "=", "dst_param_shape", ",", "method", "=", "method", ")", "\n", "", "else", ":", "\n", "                        ", "param", "=", "param", ".", "view", "(", "dst_param_shape", ")", "\n", "", "", "assert", "dst_param_shape", "==", "param", ".", "shape", ",", "\"Initilizer:: error({}): {} != {}\"", ".", "format", "(", "name", ",", "dst_param_shape", ",", "param", ".", "shape", ")", "\n", "", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "copy_", "(", "param", ")", "#, broadcast=False)", "\n", "src_state_keys", ".", "remove", "(", "name", ")", "\n", "dst_state_keys", ".", "remove", "(", "name", ")", "\n", "\n", "# indicat missing / ignored keys", "\n", "", "", "if", "src_state_keys", ":", "\n", "        ", "out", "=", "\"[\\'\"", "+", "'\\', \\''", ".", "join", "(", "src_state_keys", ")", "+", "\"\\']\"", "\n", "logging", ".", "info", "(", "\"Initializer:: >> {} params are unused: {}\"", ".", "format", "(", "len", "(", "src_state_keys", ")", ",", "\n", "out", "if", "len", "(", "out", ")", "<", "300", "else", "out", "[", "0", ":", "150", "]", "+", "\" ... \"", "+", "out", "[", "-", "150", ":", "]", ")", ")", "\n", "", "if", "dst_state_keys", ":", "\n", "        ", "logging", ".", "info", "(", "\"Initializer:: >> failed to load: \\n{}\"", ".", "format", "(", "\n", "json", ".", "dumps", "(", "dst_state_keys", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.BN_AC_CONV3D.__init__": [[18, 25], ["torch.Module.__init__", "torch.BatchNorm3d", "torch.ReLU", "torch.Conv3d"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_in", ",", "num_filter", ",", "\n", "kernel", "=", "(", "1", ",", "1", ",", "1", ")", ",", "pad", "=", "(", "0", ",", "0", ",", "0", ")", ",", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "g", "=", "1", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "BN_AC_CONV3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm3d", "(", "num_in", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv3d", "(", "num_in", ",", "num_filter", ",", "kernel_size", "=", "kernel", ",", "padding", "=", "pad", ",", "\n", "stride", "=", "stride", ",", "groups", "=", "g", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.BN_AC_CONV3D.forward": [[26, 30], ["mfnet_3d.BN_AC_CONV3D.relu", "mfnet_3d.BN_AC_CONV3D.conv", "mfnet_3d.BN_AC_CONV3D.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "relu", "(", "self", ".", "bn", "(", "x", ")", ")", "\n", "h", "=", "self", ".", "conv", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.MF_UNIT.__init__": [[34, 50], ["torch.Module.__init__", "int", "mfnet_3d.BN_AC_CONV3D", "mfnet_3d.BN_AC_CONV3D", "mfnet_3d.BN_AC_CONV3D", "mfnet_3d.BN_AC_CONV3D", "mfnet_3d.BN_AC_CONV3D", "mfnet_3d.BN_AC_CONV3D"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_in", ",", "num_mid", ",", "num_out", ",", "g", "=", "1", ",", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "first_block", "=", "False", ",", "use_3d", "=", "True", ")", ":", "\n", "        ", "super", "(", "MF_UNIT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "num_ix", "=", "int", "(", "num_mid", "/", "4", ")", "\n", "kt", ",", "pt", "=", "(", "3", ",", "1", ")", "if", "use_3d", "else", "(", "1", ",", "0", ")", "\n", "# prepare input", "\n", "self", ".", "conv_i1", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_in", ",", "num_filter", "=", "num_ix", ",", "kernel", "=", "(", "1", ",", "1", ",", "1", ")", ",", "pad", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "self", ".", "conv_i2", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_ix", ",", "num_filter", "=", "num_in", ",", "kernel", "=", "(", "1", ",", "1", ",", "1", ")", ",", "pad", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "# main part", "\n", "self", ".", "conv_m1", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_in", ",", "num_filter", "=", "num_mid", ",", "kernel", "=", "(", "kt", ",", "3", ",", "3", ")", ",", "pad", "=", "(", "pt", ",", "1", ",", "1", ")", ",", "stride", "=", "stride", ",", "g", "=", "g", ")", "\n", "if", "first_block", ":", "\n", "            ", "self", ".", "conv_m2", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_mid", ",", "num_filter", "=", "num_out", ",", "kernel", "=", "(", "1", ",", "1", ",", "1", ")", ",", "pad", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_m2", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_mid", ",", "num_filter", "=", "num_out", ",", "kernel", "=", "(", "1", ",", "3", ",", "3", ")", ",", "pad", "=", "(", "0", ",", "1", ",", "1", ")", ",", "g", "=", "g", ")", "\n", "# adapter", "\n", "", "if", "first_block", ":", "\n", "            ", "self", ".", "conv_w1", "=", "BN_AC_CONV3D", "(", "num_in", "=", "num_in", ",", "num_filter", "=", "num_out", ",", "kernel", "=", "(", "1", ",", "1", ",", "1", ")", ",", "pad", "=", "(", "0", ",", "0", ",", "0", ")", ",", "stride", "=", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.MF_UNIT.forward": [[51, 63], ["mfnet_3d.MF_UNIT.conv_i1", "mfnet_3d.MF_UNIT.conv_m1", "mfnet_3d.MF_UNIT.conv_m2", "hasattr", "mfnet_3d.MF_UNIT.conv_i2", "mfnet_3d.MF_UNIT.conv_w1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "h", "=", "self", ".", "conv_i1", "(", "x", ")", "\n", "x_in", "=", "x", "+", "self", ".", "conv_i2", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "conv_m1", "(", "x_in", ")", "\n", "h", "=", "self", ".", "conv_m2", "(", "h", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'conv_w1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "conv_w1", "(", "x", ")", "\n", "\n", "", "return", "h", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.MFNET_3D.__init__": [[67, 168], ["torch.Module.__init__", "torch.Sequential", "torch.MaxPool3d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.Tanh", "torch.Sequential", "initializer.xavier", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "os.path.join", "logging.info", "os.path.exists", "torch.load", "initializer.init_3d_from_2d_dict", "logging.info", "os.path.dirname", "os.path.realpath", "torch.Conv3d", "torch.BatchNorm3d", "torch.ReLU", "mfnet_3d.MF_UNIT", "range", "mfnet_3d.MF_UNIT", "range", "mfnet_3d.MF_UNIT", "range", "mfnet_3d.MF_UNIT", "range", "torch.BatchNorm3d", "torch.ReLU", "torch.AvgPool3d"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.initializer.xavier", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.initializer.init_3d_from_2d_dict"], ["    ", "def", "__init__", "(", "self", ",", "hash_bit", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MFNET_3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hash_bit", "=", "hash_bit", "\n", "\n", "groups", "=", "16", "\n", "k_sec", "=", "{", "2", ":", "3", ",", "3", ":", "4", ",", "4", ":", "6", ",", "5", ":", "3", "}", "\n", "\n", "# conv1 - x224 (x16)", "\n", "conv1_num_out", "=", "16", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv'", ",", "nn", ".", "Conv3d", "(", "3", ",", "conv1_num_out", ",", "kernel_size", "=", "(", "3", ",", "5", ",", "5", ")", ",", "padding", "=", "(", "1", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'bn'", ",", "nn", ".", "BatchNorm3d", "(", "conv1_num_out", ")", ")", ",", "\n", "(", "'relu'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "\n", "# conv2 - x56 (x8)", "\n", "num_mid", "=", "96", "\n", "conv2_num_out", "=", "96", "\n", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"B%02d\"", "%", "i", ",", "MF_UNIT", "(", "num_in", "=", "conv1_num_out", "if", "i", "==", "1", "else", "conv2_num_out", ",", "\n", "num_mid", "=", "num_mid", ",", "\n", "num_out", "=", "conv2_num_out", ",", "\n", "stride", "=", "(", "2", ",", "1", ",", "1", ")", "if", "i", "==", "1", "else", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "g", "=", "groups", ",", "\n", "first_block", "=", "(", "i", "==", "1", ")", ")", ")", "for", "i", "in", "range", "(", "1", ",", "k_sec", "[", "2", "]", "+", "1", ")", "\n", "]", ")", ")", "\n", "\n", "# conv3 - x28 (x8)", "\n", "num_mid", "*=", "2", "\n", "conv3_num_out", "=", "2", "*", "conv2_num_out", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"B%02d\"", "%", "i", ",", "MF_UNIT", "(", "num_in", "=", "conv2_num_out", "if", "i", "==", "1", "else", "conv3_num_out", ",", "\n", "num_mid", "=", "num_mid", ",", "\n", "num_out", "=", "conv3_num_out", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", "if", "i", "==", "1", "else", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "g", "=", "groups", ",", "\n", "first_block", "=", "(", "i", "==", "1", ")", ")", ")", "for", "i", "in", "range", "(", "1", ",", "k_sec", "[", "3", "]", "+", "1", ")", "\n", "]", ")", ")", "\n", "\n", "# conv4 - x14 (x8)", "\n", "num_mid", "*=", "2", "\n", "conv4_num_out", "=", "2", "*", "conv3_num_out", "\n", "self", ".", "conv4", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"B%02d\"", "%", "i", ",", "MF_UNIT", "(", "num_in", "=", "conv3_num_out", "if", "i", "==", "1", "else", "conv4_num_out", ",", "\n", "num_mid", "=", "num_mid", ",", "\n", "num_out", "=", "conv4_num_out", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", "if", "i", "==", "1", "else", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "g", "=", "groups", ",", "\n", "first_block", "=", "(", "i", "==", "1", ")", ")", ")", "for", "i", "in", "range", "(", "1", ",", "k_sec", "[", "4", "]", "+", "1", ")", "\n", "]", ")", ")", "\n", "\n", "# conv5 - x7 (x8)", "\n", "num_mid", "*=", "2", "\n", "conv5_num_out", "=", "2", "*", "conv4_num_out", "\n", "self", ".", "conv5", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"B%02d\"", "%", "i", ",", "MF_UNIT", "(", "num_in", "=", "conv4_num_out", "if", "i", "==", "1", "else", "conv5_num_out", ",", "\n", "num_mid", "=", "num_mid", ",", "\n", "num_out", "=", "conv5_num_out", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", "if", "i", "==", "1", "else", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "g", "=", "groups", ",", "\n", "first_block", "=", "(", "i", "==", "1", ")", ")", ")", "for", "i", "in", "range", "(", "1", ",", "k_sec", "[", "5", "]", "+", "1", ")", "\n", "]", ")", ")", "\n", "\n", "# final", "\n", "self", ".", "tail", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'bn'", ",", "nn", ".", "BatchNorm3d", "(", "conv5_num_out", ")", ")", ",", "\n", "(", "'relu'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "]", ")", ")", "\n", "\n", "self", ".", "globalpool", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'avg'", ",", "nn", ".", "AvgPool3d", "(", "kernel_size", "=", "(", "8", ",", "7", ",", "7", ")", ",", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ")", ")", ",", "\n", "#('dropout', nn.Dropout(p=0.5)), #only for fine-tuning", "\n", "]", ")", ")", "\n", "#self.classifier = nn.Linear(conv5_num_out, num_classes) # 2048", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "conv5_num_out", ",", "conv5_num_out", ")", "\n", "self", ".", "activation1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "conv5_num_out", ",", "conv5_num_out", ")", "\n", "self", ".", "activation2", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "conv5_num_out", ",", "self", ".", "hash_bit", ")", "\n", "self", ".", "last_layer", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "hash_layer", "=", "nn", ".", "Sequential", "(", "self", ".", "fc1", ",", "self", ".", "activation1", ",", "self", ".", "fc2", ",", "self", ".", "activation2", ",", "\n", "self", ".", "fc3", ",", "self", ".", "last_layer", ")", "\n", "\n", "#############", "\n", "# Initialization", "\n", "initializer", ".", "xavier", "(", "net", "=", "self", ")", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "import", "torch", "\n", "load_method", "=", "'inflation'", "# 'random', 'inflation'", "\n", "pretrained_model", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'pretrained/MFNet2D_ImageNet1k-0000.pth'", ")", "\n", "logging", ".", "info", "(", "\"Network:: graph initialized, loading pretrained model: `{}'\"", ".", "format", "(", "pretrained_model", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "pretrained_model", ")", ",", "\"cannot locate: `{}'\"", ".", "format", "(", "pretrained_model", ")", "\n", "state_dict_2d", "=", "torch", ".", "load", "(", "pretrained_model", ")", "\n", "initializer", ".", "init_3d_from_2d_dict", "(", "net", "=", "self", ",", "state_dict", "=", "state_dict_2d", ",", "method", "=", "load_method", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"Network:: graph initialized, use random inilization!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.mfnet_3d.MFNET_3D.forward": [[169, 187], ["mfnet_3d.MFNET_3D.conv1", "mfnet_3d.MFNET_3D.maxpool", "mfnet_3d.MFNET_3D.conv2", "mfnet_3d.MFNET_3D.conv3", "mfnet_3d.MFNET_3D.conv4", "mfnet_3d.MFNET_3D.conv5", "mfnet_3d.MFNET_3D.tail", "mfnet_3d.MFNET_3D.globalpool", "mfnet_3d.MFNET_3D.view", "mfnet_3d.MFNET_3D.hash_layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "shape", "[", "2", "]", "==", "16", "\n", "\n", "h", "=", "self", ".", "conv1", "(", "x", ")", "# x224 -> x112", "\n", "h", "=", "self", ".", "maxpool", "(", "h", ")", "# x112 ->  x56", "\n", "\n", "h", "=", "self", ".", "conv2", "(", "h", ")", "#  x56 ->  x56", "\n", "h", "=", "self", ".", "conv3", "(", "h", ")", "#  x56 ->  x28", "\n", "h", "=", "self", ".", "conv4", "(", "h", ")", "#  x28 ->  x14", "\n", "h", "=", "self", ".", "conv5", "(", "h", ")", "#  x14 ->   x7", "\n", "\n", "h", "=", "self", ".", "tail", "(", "h", ")", "\n", "h", "=", "self", ".", "globalpool", "(", "h", ")", "\n", "\n", "h", "=", "h", ".", "view", "(", "h", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "hash_layer", "(", "h", ")", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.network.symbol_builder.get_symbol": [[6, 20], ["config.get_config", "name.upper", "mfnet_3d.MFNET_3D", "logging.error", "NotImplementedError", "logging.debug", "logging.debug"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.dataset.config.get_config"], ["def", "get_symbol", "(", "name", ",", "print_net", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "name", ".", "upper", "(", ")", "==", "\"MFNET_3D\"", ":", "\n", "        ", "net", "=", "MFNET_3D", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "error", "(", "\"network '{}'' not implemented\"", ".", "format", "(", "name", ")", ")", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "if", "print_net", ":", "\n", "        ", "logging", ".", "debug", "(", "\"Symbol:: Network Architecture:\"", ")", "\n", "logging", ".", "debug", "(", "net", ")", "\n", "\n", "", "input_conf", "=", "get_config", "(", "name", ",", "**", "kwargs", ")", "\n", "return", "net", ",", "input_conf", "\n", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.dataset.config.get_config": [[3, 20], ["logging.debug", "name.upper", "name.upper", "name.upper", "name.upper", "logging.error"], "function", ["None"], ["def", "get_config", "(", "name", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "logging", ".", "debug", "(", "\"loading network configs of: {}\"", ".", "format", "(", "name", ".", "upper", "(", ")", ")", ")", "\n", "\n", "config", "=", "{", "}", "\n", "\n", "if", "\"3D\"", "in", "name", ".", "upper", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Preprocessing:: using MXNet default mean & std.\"", ")", "\n", "config", "[", "'mean'", "]", "=", "[", "124", "/", "255", ",", "117", "/", "255", ",", "104", "/", "255", "]", "\n", "config", "[", "'std'", "]", "=", "[", "1", "/", "(", ".0167", "*", "255", ")", "]", "*", "3", "\n", "", "else", ":", "\n", "        ", "config", "[", "'mean'", "]", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "config", "[", "'std'", "]", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "# else:", "\n", "#    raise NotImplemented(\"Configs for {} not implemented\".format(name))", "\n", "\n", "", "logging", ".", "info", "(", "\"data:: {}\"", ".", "format", "(", "config", ")", ")", "\n", "return", "config", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.scripts.convert_videos.exe_cmd": [[8, 21], ["os.path.exists", "cmd.replace().replace().replace.replace().replace().replace", "subprocess.check_output", "cmd.replace().replace().replace.split", "logging.warning", "cmd.replace().replace().replace.replace().replace", "cmd.replace().replace().replace.replace"], "function", ["None"], ["def", "exe_cmd", "(", "cmd", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "dst_file", "=", "cmd", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "dst_file", ")", ":", "\n", "            ", "return", "\"exist\"", "\n", "", "cmd", "=", "cmd", ".", "replace", "(", "'('", ",", "'\\('", ")", ".", "replace", "(", "')'", ",", "'\\)'", ")", ".", "replace", "(", "'\\''", ",", "'\\\\\\''", ")", "\n", "output", "=", "subprocess", ".", "check_output", "(", "cmd", ",", "shell", "=", "True", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "err", ":", "\n", "        ", "logging", ".", "warning", "(", "\"failed: {}\"", ".", "format", "(", "cmd", ")", ")", "\n", "# logging.warning(\"failed: {}: {}\".format(cmd, err.output.decode(\"utf-8\"))) # more details", "\n", "return", "False", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.scripts.convert_videos.convert_video_wapper": [[22, 42], ["zip", "logging.info", "cmd_format.format", "commands.append", "enumerate", "logging.info", "len", "convert_videos.exe_cmd", "joblib.Parallel", "joblib.delayed"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.raw.video_processing_nvvl.exe_cmd"], ["", "def", "convert_video_wapper", "(", "src_videos", ",", "\n", "dst_videos", ",", "\n", "cmd_format", ",", "\n", "in_parallel", "=", "True", ")", ":", "\n", "    ", "commands", "=", "[", "]", "\n", "for", "src", ",", "dst", "in", "zip", "(", "src_videos", ",", "dst_videos", ")", ":", "\n", "        ", "cmd", "=", "cmd_format", ".", "format", "(", "src", ",", "dst", ")", "\n", "commands", ".", "append", "(", "cmd", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"- {} commonds to excute\"", ".", "format", "(", "len", "(", "commands", ")", ")", ")", "\n", "\n", "if", "not", "in_parallel", ":", "\n", "        ", "for", "i", ",", "cmd", "in", "enumerate", "(", "commands", ")", ":", "\n", "# if i % 100 == 0:", "\n", "#     logging.info(\"{} / {}: '{}'\".format(i, len(commands), cmd))", "\n", "            ", "exe_cmd", "(", "cmd", "=", "cmd", ")", "\n", "", "", "else", ":", "\n", "        ", "num_jobs", "=", "24", "\n", "logging", ".", "info", "(", "\"processing videos in parallel, num_jobs={}\"", ".", "format", "(", "num_jobs", ")", ")", "\n", "Parallel", "(", "n_jobs", "=", "num_jobs", ")", "(", "delayed", "(", "exe_cmd", ")", "(", "cmd", ")", "for", "cmd", "in", "commands", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.raw.video_processing_nvvl.exe_cmd": [[10, 23], ["os.path.exists", "cmd.replace().replace().replace.replace().replace().replace", "subprocess.check_output", "cmd.replace().replace().replace.split", "logging.warning", "cmd.replace().replace().replace.replace().replace", "cmd.replace().replace().replace.replace"], "function", ["None"], ["def", "exe_cmd", "(", "cmd", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "dst_file", "=", "cmd", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "dst_file", ")", ":", "\n", "            ", "return", "\"exist\"", "\n", "", "cmd", "=", "cmd", ".", "replace", "(", "'('", ",", "'\\('", ")", ".", "replace", "(", "')'", ",", "'\\)'", ")", ".", "replace", "(", "'\\''", ",", "'\\\\\\''", ")", "\n", "output", "=", "subprocess", ".", "check_output", "(", "cmd", ",", "shell", "=", "True", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "err", ":", "\n", "        ", "logging", ".", "warning", "(", "\"failed: {}\"", ".", "format", "(", "cmd", ")", ")", "\n", "# logging.warning(\"failed: {}: {}\".format(cmd, err.output.decode(\"utf-8\"))) # detailed error", "\n", "return", "False", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.__init__": [[19, 34], ["logging.warning"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "net", ",", "\n", "criterion", "=", "None", ",", "\n", "model_prefix", "=", "''", ",", "\n", "dataset", "=", "None", ",", "\n", "hash_bit", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Unknown kwargs: {}\"", ".", "format", "(", "kwargs", ")", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "hash_bit", "=", "hash_bit", "\n", "# init params", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "model_prefix", "=", "model_prefix", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.load_state": [[35, 52], ["model.static_model.net.load_state_dict", "list", "state_dict.items", "model.static_model.net.state_dict().keys", "logging.warning", "model.static_model.net.state_dict().keys", "model.static_model.net.state_dict", "[].copy_", "list.remove", "model.static_model.net.state_dict", "model.static_model.net.state_dict", "param.view", "model.static_model.net.state_dict"], "methods", ["None"], ["", "def", "load_state", "(", "self", ",", "state_dict", ",", "strict", "=", "False", ")", ":", "\n", "        ", "if", "strict", ":", "\n", "            ", "self", ".", "net", ".", "load_state_dict", "(", "state_dict", "=", "state_dict", ")", "\n", "", "else", ":", "\n", "# customized partialy load function", "\n", "            ", "net_state_keys", "=", "list", "(", "self", ".", "net", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "\n", "for", "name", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "name", "in", "self", ".", "net", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ":", "\n", "                    ", "dst_param_shape", "=", "self", ".", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "shape", "\n", "if", "param", ".", "shape", "==", "dst_param_shape", ":", "\n", "                        ", "self", ".", "net", ".", "state_dict", "(", ")", "[", "name", "]", ".", "copy_", "(", "param", ".", "view", "(", "dst_param_shape", ")", ")", "\n", "net_state_keys", ".", "remove", "(", "name", ")", "\n", "# indicating missed keys", "\n", "", "", "", "if", "net_state_keys", ":", "\n", "                ", "logging", ".", "warning", "(", "\">> Failed to load: {}\"", ".", "format", "(", "net_state_keys", ")", ")", "\n", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.get_checkpoint_path": [[53, 61], ["socket.gethostname"], "methods", ["None"], ["", "def", "get_checkpoint_path", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "assert", "self", ".", "model_prefix", ",", "\"model_prefix undefined!\"", "\n", "if", "torch", ".", "distributed", ".", "_initialized", ":", "\n", "            ", "hostname", "=", "socket", ".", "gethostname", "(", ")", "\n", "checkpoint_path", "=", "\"{}_at-{}_ep-{:04d}_{}_{}bits.pth\"", ".", "format", "(", "self", ".", "model_prefix", ",", "hostname", ",", "epoch", ",", "self", ".", "dataset", ",", "self", ".", "hash_bit", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint_path", "=", "\"{}_ep-{:04d}_{}_{}bits.pth\"", ".", "format", "(", "self", ".", "model_prefix", ",", "epoch", ",", "self", ".", "dataset", ",", "self", ".", "hash_bit", ")", "\n", "", "return", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.load_checkpoint": [[62, 83], ["model.static_model.get_checkpoint_path", "os.path.exists", "torch.load", "model.static_model.load_state", "logging.info", "torch.load.keys", "optimizer.load_state_dict", "logging.info", "logging.warning", "logging.warning", "torch.load.keys"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.get_checkpoint_path", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.load_state"], ["", "def", "load_checkpoint", "(", "self", ",", "epoch", ",", "optimizer", "=", "None", ")", ":", "\n", "\n", "        ", "load_path", "=", "self", ".", "get_checkpoint_path", "(", "epoch", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "load_path", ")", ",", "\"Failed to load: {} (file not exist)\"", ".", "format", "(", "load_path", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "\n", "all_params_matched", "=", "self", ".", "load_state", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "\n", "if", "optimizer", ":", "\n", "            ", "if", "'optimizer'", "in", "checkpoint", ".", "keys", "(", ")", "and", "all_params_matched", ":", "\n", "                ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "logging", ".", "info", "(", "\"Model & Optimizer states are resumed from: `{}'\"", ".", "format", "(", "load_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logging", ".", "warning", "(", "\">> Failed to load optimizer state from: `{}'\"", ".", "format", "(", "load_path", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"Only model state resumed from: `{}'\"", ".", "format", "(", "load_path", ")", ")", "\n", "\n", "", "if", "'epoch'", "in", "checkpoint", ".", "keys", "(", ")", ":", "\n", "            ", "if", "checkpoint", "[", "'epoch'", "]", "!=", "epoch", ":", "\n", "                ", "logging", ".", "warning", "(", "\">> Epoch information inconsistant: {} vs {}\"", ".", "format", "(", "checkpoint", "[", "'epoch'", "]", ",", "epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.save_checkpoint": [[84, 104], ["model.static_model.get_checkpoint_path", "os.path.dirname", "os.path.exists", "logging.debug", "os.makedirs", "torch.save", "logging.info", "torch.save", "logging.info", "model.static_model.net.state_dict", "model.static_model.net.state_dict"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.get_checkpoint_path"], ["", "", "", "def", "save_checkpoint", "(", "self", ",", "epoch", ",", "optimizer_state", "=", "None", ")", ":", "\n", "\n", "        ", "save_path", "=", "self", ".", "get_checkpoint_path", "(", "epoch", ")", "\n", "save_folder", "=", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_folder", ")", ":", "\n", "            ", "logging", ".", "debug", "(", "\"mkdir {}\"", ".", "format", "(", "save_folder", ")", ")", "\n", "os", ".", "makedirs", "(", "save_folder", ")", "\n", "\n", "", "if", "not", "optimizer_state", ":", "\n", "            ", "torch", ".", "save", "(", "{", "'epoch'", ":", "epoch", ",", "\n", "'state_dict'", ":", "self", ".", "net", ".", "state_dict", "(", ")", "}", ",", "\n", "save_path", ")", "\n", "logging", ".", "info", "(", "\"Checkpoint (only model) saved to: {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "save", "(", "{", "'epoch'", ":", "epoch", ",", "\n", "'state_dict'", ":", "self", ".", "net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer_state", "}", ",", "\n", "save_path", ")", "\n", "logging", ".", "info", "(", "\"Checkpoint (model & optimizer) saved to: {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.forward": [[106, 128], ["data.float().cuda.float().cuda.float().cuda", "target.cuda.cuda.cuda", "model.static_model.net", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "hasattr", "model.static_model.criterion", "data.float().cuda.float().cuda.float"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "data", ",", "target", ")", ":", "\n", "        ", "\"\"\" typical forward function with:\n            single output and single loss\n        \"\"\"", "\n", "# data = data.float().cuda(async=True)", "\n", "# target = target.cuda(async=True)", "\n", "data", "=", "data", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "if", "self", ".", "net", ".", "training", ":", "\n", "            ", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "data", ",", "requires_grad", "=", "False", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "target", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "data", ",", "volatile", "=", "True", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "target", ",", "volatile", "=", "True", ")", "\n", "\n", "", "output", "=", "self", ".", "net", "(", "input_var", ")", "\n", "if", "hasattr", "(", "self", ",", "'criterion'", ")", "and", "self", ".", "criterion", "is", "not", "None", "and", "target", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "criterion", "(", "0.5", "*", "(", "output", "+", "1", ")", ",", "0.5", "*", "(", "target_var", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "None", "\n", "", "return", "[", "output", "]", ",", "[", "loss", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.__init__": [[135, 176], ["model.static_model.__init__", "logging.warning", "callback.CallbackList", "callback.SpeedMonitor", "callback.MetricPrinter"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "net", ",", "\n", "criterion", ",", "\n", "model_prefix", "=", "''", ",", "\n", "step_callback", "=", "None", ",", "\n", "step_callback_freq", "=", "50", ",", "\n", "epoch_callback", "=", "None", ",", "\n", "save_checkpoint_freq", "=", "1", ",", "\n", "opt_batch_size", "=", "None", ",", "\n", "dataset", "=", "None", ",", "\n", "hash_bit", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# load parameters", "\n", "        ", "if", "kwargs", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Unknown kwargs: {}\"", ".", "format", "(", "kwargs", ")", ")", "\n", "\n", "", "super", "(", "model", ",", "self", ")", ".", "__init__", "(", "net", ",", "criterion", "=", "criterion", ",", "model_prefix", "=", "model_prefix", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "hash_bit", "=", "hash_bit", "\n", "# load optional arguments", "\n", "# - callbacks", "\n", "self", ".", "callback_kwargs", "=", "{", "'epoch'", ":", "None", ",", "\n", "'batch'", ":", "None", ",", "\n", "'sample_elapse'", ":", "None", ",", "\n", "'update_elapse'", ":", "None", ",", "\n", "'epoch_elapse'", ":", "None", ",", "\n", "'namevals'", ":", "None", ",", "\n", "'optimizer_dict'", ":", "None", ",", "}", "\n", "\n", "if", "not", "step_callback", ":", "\n", "            ", "step_callback", "=", "callback", ".", "CallbackList", "(", "callback", ".", "SpeedMonitor", "(", ")", ",", "\n", "callback", ".", "MetricPrinter", "(", ")", ")", "\n", "", "if", "not", "epoch_callback", ":", "\n", "            ", "epoch_callback", "=", "(", "lambda", "**", "kwargs", ":", "None", ")", "\n", "\n", "", "self", ".", "step_callback", "=", "step_callback", "\n", "self", ".", "step_callback_freq", "=", "step_callback_freq", "\n", "self", ".", "epoch_callback", "=", "epoch_callback", "\n", "self", ".", "save_checkpoint_freq", "=", "save_checkpoint_freq", "\n", "self", ".", "batch_size", "=", "opt_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.step_end_callback": [[182, 185], ["model.model.step_callback"], "methods", ["None"], ["def", "step_end_callback", "(", "self", ")", ":", "\n", "# logging.debug(\"Step {} finished!\".format(self.i_step))", "\n", "        ", "self", ".", "step_callback", "(", "**", "(", "self", ".", "callback_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.epoch_end_callback": [[186, 197], ["model.model.epoch_callback", "logging.info", "model.model.save_checkpoint"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.save_checkpoint"], ["", "def", "epoch_end_callback", "(", "self", ")", ":", "\n", "        ", "self", ".", "epoch_callback", "(", "**", "(", "self", ".", "callback_kwargs", ")", ")", "\n", "if", "self", ".", "callback_kwargs", "[", "'epoch_elapse'", "]", "is", "not", "None", ":", "\n", "            ", "logging", ".", "info", "(", "\"Epoch [{:d}]   time cost: {:.2f} sec ({:.2f} h)\"", ".", "format", "(", "\n", "self", ".", "callback_kwargs", "[", "'epoch'", "]", ",", "\n", "self", ".", "callback_kwargs", "[", "'epoch_elapse'", "]", ",", "\n", "self", ".", "callback_kwargs", "[", "'epoch_elapse'", "]", "/", "3600.", ")", ")", "\n", "", "if", "self", ".", "callback_kwargs", "[", "'epoch'", "]", "==", "0", "or", "(", "(", "self", ".", "callback_kwargs", "[", "'epoch'", "]", "+", "1", ")", "%", "self", ".", "save_checkpoint_freq", ")", "==", "0", ":", "\n", "            ", "self", ".", "save_checkpoint", "(", "epoch", "=", "self", ".", "callback_kwargs", "[", "'epoch'", "]", "+", "1", ",", "\n", "optimizer_state", "=", "self", ".", "callback_kwargs", "[", "'optimizer_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.adjust_learning_rate": [[201, 208], ["None"], "methods", ["None"], ["def", "adjust_learning_rate", "(", "self", ",", "lr", ",", "optimizer", ")", ":", "\n", "        ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "if", "'lr_mult'", "in", "param_group", ":", "\n", "                ", "lr_mult", "=", "param_group", "[", "'lr_mult'", "]", "\n", "", "else", ":", "\n", "                ", "lr_mult", "=", "1.0", "\n", "", "param_group", "[", "'lr'", "]", "=", "lr", "*", "lr_mult", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.fit": [[212, 332], ["metric.Accuracy", "torch.cuda.is_available", "range", "logging.info", "logging.warning", "time.time", "metrics.reset", "model.model.net.train", "time.time", "logging.info", "enumerate", "optimizer.state_dict", "model.model.epoch_end_callback", "time.time", "model.model.forward", "optimizer.zero_grad", "model.model.adjust_learning_rate", "optimizer.step", "metrics.update", "time.time", "time.time", "loss.backward", "target.cpu", "time.time", "time.time", "metrics.get_name_value", "metrics.reset", "model.model.step_end_callback", "lr_scheduler.update", "output.data.cpu", "loss.data.cpu"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.None.train.train", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.epoch_end_callback", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.static_model.forward", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.adjust_learning_rate", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get_name_value", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.model.model.step_end_callback", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update"], ["def", "fit", "(", "self", ",", "train_iter", ",", "optimizer", ",", "lr_scheduler", ",", "\n", "eval_iter", "=", "None", ",", "\n", "metrics", "=", "metric", ".", "Accuracy", "(", "topk", "=", "1", ")", ",", "\n", "epoch_start", "=", "0", ",", "\n", "epoch_end", "=", "10000", ",", "\n", "Hash_center", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "\"\"\"\n        checking\n        \"\"\"", "\n", "if", "kwargs", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Unknown kwargs: {}\"", ".", "format", "(", "kwargs", ")", ")", "\n", "\n", "", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"only support GPU version\"", "\n", "\n", "\"\"\"\n        start the main loop\n        \"\"\"", "\n", "pause_sec", "=", "0.", "\n", "for", "i_epoch", "in", "range", "(", "epoch_start", ",", "epoch_end", ")", ":", "\n", "            ", "self", ".", "callback_kwargs", "[", "'epoch'", "]", "=", "i_epoch", "\n", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "###########", "\n", "# 1] TRAINING", "\n", "###########", "\n", "metrics", ".", "reset", "(", ")", "\n", "self", ".", "net", ".", "train", "(", ")", "\n", "sum_sample_inst", "=", "0", "\n", "sum_sample_elapse", "=", "0.", "\n", "sum_update_elapse", "=", "0", "\n", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\"Start epoch {:d}:\"", ".", "format", "(", "i_epoch", ")", ")", "\n", "for", "i_batch", ",", "(", "data", ",", "target", ",", "_", ")", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "                ", "self", ".", "callback_kwargs", "[", "'batch'", "]", "=", "i_batch", "\n", "\n", "update_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "hash_center", "=", "Hash_center", "[", "target", "]", "\n", "# [forward] making next step", "\n", "outputs", ",", "losses", "=", "self", ".", "forward", "(", "data", ",", "hash_center", ")", "# output: [batch_size, 64]", "\n", "\n", "# [backward]", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "loss", "in", "losses", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "", "self", ".", "adjust_learning_rate", "(", "optimizer", "=", "optimizer", ",", "lr", "=", "lr_scheduler", ".", "update", "(", ")", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# [evaluation] update train metric", "\n", "metrics", ".", "update", "(", "[", "output", ".", "data", ".", "cpu", "(", ")", "for", "output", "in", "outputs", "]", ",", "\n", "target", ".", "cpu", "(", ")", ",", "\n", "[", "loss", ".", "data", ".", "cpu", "(", ")", "for", "loss", "in", "losses", "]", ")", "\n", "\n", "# timing each batch", "\n", "sum_sample_elapse", "+=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "sum_update_elapse", "+=", "time", ".", "time", "(", ")", "-", "update_start_time", "\n", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "sum_sample_inst", "+=", "data", ".", "shape", "[", "0", "]", "\n", "\n", "\n", "if", "(", "i_batch", "%", "self", ".", "step_callback_freq", ")", "==", "0", ":", "\n", "# retrive eval results and reset metic", "\n", "                    ", "self", ".", "callback_kwargs", "[", "'namevals'", "]", "=", "metrics", ".", "get_name_value", "(", ")", "\n", "metrics", ".", "reset", "(", ")", "\n", "# speed monitor", "\n", "self", ".", "callback_kwargs", "[", "'sample_elapse'", "]", "=", "sum_sample_elapse", "/", "sum_sample_inst", "\n", "self", ".", "callback_kwargs", "[", "'update_elapse'", "]", "=", "sum_update_elapse", "/", "sum_sample_inst", "\n", "sum_update_elapse", "=", "0", "\n", "sum_sample_elapse", "=", "0", "\n", "sum_sample_inst", "=", "0", "\n", "# callbacks", "\n", "self", ".", "step_end_callback", "(", ")", "\n", "\n", "###########", "\n", "# 2] END OF EPOCH", "\n", "###########", "\n", "", "", "self", ".", "callback_kwargs", "[", "'epoch_elapse'", "]", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "self", ".", "callback_kwargs", "[", "'optimizer_dict'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "self", ".", "epoch_end_callback", "(", ")", "\n", "\n", "###########", "\n", "# 3] Evaluation", "\n", "###########", "\n", "\"\"\"\n            if (eval_iter is not None) \\\n                and ((i_epoch+1) % max(1, int(self.save_checkpoint_freq/2))) == 0:\n                logging.info(\"Start evaluating epoch {:d}:\".format(i_epoch))\n\n                metrics.reset()\n                self.net.eval()\n                sum_sample_elapse = 0.\n                sum_sample_inst = 0\n                sum_forward_elapse = 0.\n                batch_start_time = time.time()\n                for i_batch, (data, target) in enumerate(eval_iter):\n                    self.callback_kwargs['batch'] = i_batch\n\n                    forward_start_time = time.time()\n\n                    outputs, losses = self.forward(data, target)\n\n                    metrics.update([output.data.cpu() for output in outputs],\n                                    target.cpu(),\n                                   [loss.data.cpu() for loss in losses])\n\n                    sum_forward_elapse += time.time() - forward_start_time\n                    sum_sample_elapse += time.time() - batch_start_time\n                    batch_start_time = time.time()\n                    sum_sample_inst += data.shape[0]\n\n                # evaluation callbacks\n                self.callback_kwargs['sample_elapse'] = sum_sample_elapse / sum_sample_inst\n                self.callback_kwargs['update_elapse'] = sum_forward_elapse / sum_sample_inst\n                self.callback_kwargs['namevals'] = metrics.get_name_value()\n                self.step_end_callback()\n            \"\"\"", "\n", "\n", "", "logging", ".", "info", "(", "\"Optimization done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.lr_scheduler.LRScheduler.__init__": [[10, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "step_counter", "=", "0", ",", "base_lr", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "step_counter", "=", "step_counter", "\n", "self", ".", "base_lr", "=", "base_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.lr_scheduler.LRScheduler.update": [[14, 16], ["NotImplementedError"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"must override this\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.lr_scheduler.LRScheduler.get_lr": [[17, 19], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.lr_scheduler.MultiFactorScheduler.__init__": [[22, 39], ["lr_scheduler.LRScheduler.__init__", "enumerate", "logging.info", "isinstance", "ValueError", "len", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "steps", ",", "base_lr", "=", "0.01", ",", "factor", "=", "0.1", ",", "step_counter", "=", "0", ")", ":", "\n", "        ", "super", "(", "MultiFactorScheduler", ",", "self", ")", ".", "__init__", "(", "step_counter", ",", "base_lr", ")", "\n", "assert", "isinstance", "(", "steps", ",", "list", ")", "and", "len", "(", "steps", ")", ">", "0", "\n", "for", "i", ",", "_step", "in", "enumerate", "(", "steps", ")", ":", "\n", "            ", "if", "i", "!=", "0", "and", "steps", "[", "i", "]", "<=", "steps", "[", "i", "-", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"Schedule step must be an increasing integer list\"", ")", "\n", "", "if", "_step", "<", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"Schedule step must be greater or equal than 1 round\"", ")", "\n", "", "", "if", "factor", ">", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Factor must be no more than 1 to make lr reduce\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Iter %d: start with learning rate: %0.5e (next lr step: %d)\"", "%", "(", "self", ".", "step_counter", ",", "self", ".", "base_lr", ",", "steps", "[", "0", "]", ")", ")", "\n", "self", ".", "steps", "=", "steps", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "lr", "=", "self", ".", "base_lr", "\n", "self", ".", "cursor", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.lr_scheduler.MultiFactorScheduler.update": [[40, 60], ["len", "len", "logging.info", "logging.info"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "self", ".", "step_counter", "+=", "1", "\n", "\n", "if", "self", ".", "cursor", ">=", "len", "(", "self", ".", "steps", ")", ":", "\n", "            ", "return", "self", ".", "lr", "\n", "", "while", "self", ".", "steps", "[", "self", ".", "cursor", "]", "<", "self", ".", "step_counter", ":", "\n", "            ", "self", ".", "lr", "*=", "self", ".", "factor", "\n", "self", ".", "cursor", "+=", "1", "\n", "# message", "\n", "if", "self", ".", "cursor", ">=", "len", "(", "self", ".", "steps", ")", ":", "\n", "                ", "logging", ".", "info", "(", "\"Iter: %d, change learning rate to %0.5e for step [%d:Inf)\"", "%", "(", "self", ".", "step_counter", "-", "1", ",", "self", ".", "lr", ",", "self", ".", "step_counter", "-", "1", ")", ")", "\n", "return", "self", ".", "lr", "\n", "", "else", ":", "\n", "                ", "logging", ".", "info", "(", "\"Iter: %d, change learning rate to %0.5e for step [%d:%d)\"", "%", "(", "self", ".", "step_counter", "-", "1", ",", "self", ".", "lr", ",", "self", ".", "step_counter", "-", "1", ",", "self", ".", "steps", "[", "self", ".", "cursor", "]", ")", ")", "\n", "", "", "if", "self", ".", "step_counter", "<", "100", ":", "\n", "            ", "return", "self", ".", "lr", "/", "2.0", "\n", "", "return", "self", ".", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.__init__": [[11, 14], ["str", "metric.EvalMetric.reset"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "name", "=", "str", "(", "name", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.update": [[15, 17], ["NotImplementedError"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "preds", ",", "labels", ",", "losses", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.reset": [[18, 21], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_inst", "=", "0", "\n", "self", ".", "sum_metric", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.get": [[22, 27], ["float"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_inst", "==", "0", ":", "\n", "            ", "return", "(", "self", ".", "name", ",", "float", "(", "'nan'", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "name", ",", "self", ".", "sum_metric", "/", "self", ".", "num_inst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.get_name_value": [[28, 35], ["metric.EvalMetric.get", "list", "isinstance", "isinstance", "zip"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get"], ["", "", "def", "get_name_value", "(", "self", ")", ":", "\n", "        ", "name", ",", "value", "=", "self", ".", "get", "(", ")", "\n", "if", "not", "isinstance", "(", "name", ",", "list", ")", ":", "\n", "            ", "name", "=", "[", "name", "]", "\n", "", "if", "not", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "            ", "value", "=", "[", "value", "]", "\n", "", "return", "list", "(", "zip", "(", "name", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.check_label_shapes": [[36, 45], ["NotImplementedError", "type", "type", "len", "len"], "methods", ["None"], ["", "def", "check_label_shapes", "(", "self", ",", "preds", ",", "labels", ")", ":", "\n", "# raise if the shape is inconsistent", "\n", "        ", "if", "(", "type", "(", "labels", ")", "is", "list", ")", "and", "(", "type", "(", "preds", ")", "is", "list", ")", ":", "\n", "            ", "label_shape", ",", "pred_shape", "=", "len", "(", "labels", ")", ",", "len", "(", "preds", ")", "\n", "", "else", ":", "\n", "            ", "label_shape", ",", "pred_shape", "=", "labels", ".", "shape", "[", "0", "]", ",", "preds", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "label_shape", "!=", "pred_shape", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.__init__": [[50, 55], ["all", "metric.EvalMetric.__init__", "issubclass", "type"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "name", "=", "\"metric_list\"", ")", ":", "\n", "        ", "assert", "all", "(", "[", "issubclass", "(", "type", "(", "x", ")", ",", "EvalMetric", ")", "for", "x", "in", "args", "]", ")", ",", "\"MetricList input is illegal: {}\"", ".", "format", "(", "args", ")", "\n", "self", ".", "metrics", "=", "[", "metric", "for", "metric", "in", "args", "]", "\n", "super", "(", "MetricList", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.update": [[56, 63], ["metric.update", "type", "type", "type"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update"], ["", "def", "update", "(", "self", ",", "preds", ",", "labels", ",", "losses", "=", "None", ")", ":", "\n", "        ", "preds", "=", "[", "preds", "]", "if", "type", "(", "preds", ")", "is", "not", "list", "else", "preds", "\n", "labels", "=", "[", "labels", "]", "if", "type", "(", "labels", ")", "is", "not", "list", "else", "labels", "\n", "losses", "=", "[", "losses", "]", "if", "type", "(", "losses", ")", "is", "not", "list", "else", "losses", "\n", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "metric", ".", "update", "(", "preds", ",", "labels", ",", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.reset": [[64, 70], ["hasattr", "logging.warning", "metric.reset"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'metrics'", ")", ":", "\n", "            ", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "                ", "metric", ".", "reset", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "warning", "(", "\"No metric defined.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get": [[71, 76], ["ouputs.append", "metric.get"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "ouputs", "=", "[", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "ouputs", ".", "append", "(", "metric", ".", "get", "(", ")", ")", "\n", "", "return", "ouputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get_name_value": [[77, 82], ["ouputs.append", "metric.get_name_value"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get_name_value"], ["", "def", "get_name_value", "(", "self", ")", ":", "\n", "        ", "ouputs", "=", "[", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "ouputs", ".", "append", "(", "metric", ".", "get_name_value", "(", ")", ")", "\n", "", "return", "ouputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Accuracy.__init__": [[91, 94], ["metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'accuracy'", ",", "topk", "=", "1", ")", ":", "\n", "        ", "super", "(", "Accuracy", ",", "self", ")", ".", "__init__", "(", "name", ")", "\n", "self", ".", "topk", "=", "topk", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Accuracy.update": [[95, 110], ["metric.Accuracy.check_label_shapes", "zip", "pred.topk", "pred_topk.t.t.t", "pred_topk.t.t.eq", "float", "type", "type", "label.view().expand_as", "pred_topk.t.eq.view().float().sum().numpy", "label.view", "pred_topk.t.eq.view().float().sum", "pred_topk.t.eq.view().float", "pred_topk.t.eq.view"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.EvalMetric.check_label_shapes"], ["", "def", "update", "(", "self", ",", "preds", ",", "labels", ",", "losses", ")", ":", "\n", "        ", "preds", "=", "[", "preds", "]", "if", "type", "(", "preds", ")", "is", "not", "list", "else", "preds", "\n", "labels", "=", "[", "labels", "]", "if", "type", "(", "labels", ")", "is", "not", "list", "else", "labels", "\n", "\n", "self", ".", "check_label_shapes", "(", "preds", ",", "labels", ")", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "            ", "assert", "self", ".", "topk", "<=", "pred", ".", "shape", "[", "1", "]", ",", "\"topk({}) should no larger than the pred dim({})\"", ".", "format", "(", "self", ".", "topk", ",", "pred", ".", "shape", "[", "1", "]", ")", "\n", "_", ",", "pred_topk", "=", "pred", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "\n", "pred_topk", "=", "pred_topk", ".", "t", "(", ")", "\n", "correct", "=", "pred_topk", ".", "eq", "(", "label", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred_topk", ")", ")", "\n", "\n", "self", ".", "sum_metric", "+=", "float", "(", "correct", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "label", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.__init__": [[115, 117], ["metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'loss'", ")", ":", "\n", "        ", "super", "(", "Loss", ",", "self", ")", ".", "__init__", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update": [[118, 123], ["float", "loss.numpy().sum", "loss.numpy", "loss.numpy"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "preds", ",", "labels", ",", "losses", ")", ":", "\n", "        ", "assert", "losses", "is", "not", "None", ",", "\"Loss undefined.\"", "\n", "for", "loss", "in", "losses", ":", "\n", "            ", "self", ".", "sum_metric", "+=", "float", "(", "loss", ".", "numpy", "(", ")", ".", "sum", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "loss", ".", "numpy", "(", ")", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "with_header", "=", "False", ")", ":", "\n", "        ", "self", ".", "with_header", "=", "with_header", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.__call__": [[13, 15], ["NotImplementedError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"To be implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.header": [[16, 24], ["None"], "methods", ["None"], ["", "def", "header", "(", "self", ",", "epoch", "=", "None", ",", "batch", "=", "None", ")", ":", "\n", "        ", "str_out", "=", "\"\"", "\n", "if", "self", ".", "with_header", ":", "\n", "            ", "if", "epoch", "is", "not", "None", ":", "\n", "                ", "str_out", "+=", "\"Epoch {:s} \"", ".", "format", "(", "(", "\"[%d]\"", "%", "epoch", ")", ".", "ljust", "(", "5", ",", "' '", ")", ")", "\n", "", "if", "batch", "is", "not", "None", ":", "\n", "                ", "str_out", "+=", "\"Batch {:s} \"", ".", "format", "(", "(", "\"[%d]\"", "%", "batch", ")", ".", "ljust", "(", "6", ",", "' '", ")", ")", "\n", "", "", "return", "str_out", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.CallbackList.__init__": [[27, 32], ["callback.Callback.__init__", "all", "issubclass", "type"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "with_header", "=", "True", ")", ":", "\n", "        ", "super", "(", "CallbackList", ",", "self", ")", ".", "__init__", "(", "with_header", "=", "with_header", ")", "\n", "assert", "all", "(", "[", "issubclass", "(", "type", "(", "x", ")", ",", "Callback", ")", "for", "x", "in", "args", "]", ")", ",", "\"Callback inputs illegal: {}\"", ".", "format", "(", "args", ")", "\n", "self", ".", "callbacks", "=", "[", "callback", "for", "callback", "in", "args", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.CallbackList.__call__": [[33, 42], ["callback.CallbackList.header", "logging.info", "callback"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.header"], ["", "def", "__call__", "(", "self", ",", "epoch", "=", "None", ",", "batch", "=", "None", ",", "silent", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "str_out", "=", "self", ".", "header", "(", "epoch", ",", "batch", ")", "\n", "\n", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "str_out", "+=", "callback", "(", "**", "kwargs", ",", "silent", "=", "True", ")", "+", "\" \"", "\n", "\n", "", "if", "not", "silent", ":", "\n", "            ", "logging", ".", "info", "(", "str_out", ")", "\n", "", "return", "str_out", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.SpeedMonitor.__init__": [[50, 52], ["callback.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "with_header", "=", "False", ")", ":", "\n", "        ", "super", "(", "SpeedMonitor", ",", "self", ")", ".", "__init__", "(", "with_header", "=", "with_header", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.SpeedMonitor.__call__": [[53, 67], ["callback.SpeedMonitor.header", "logging.info"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.header"], ["", "def", "__call__", "(", "self", ",", "sample_elapse", ",", "update_elapse", "=", "None", ",", "epoch", "=", "None", ",", "batch", "=", "None", ",", "silent", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "str_out", "=", "self", ".", "header", "(", "epoch", ",", "batch", ")", "\n", "\n", "if", "sample_elapse", "is", "not", "None", ":", "\n", "            ", "sample_freq", "=", "1.", "/", "sample_elapse", "\n", "if", "update_elapse", "is", "not", "None", ":", "\n", "                ", "update_freq", "=", "1.", "/", "update_elapse", "\n", "str_out", "+=", "\"Speed {: >5.1f} (+{: >2.0f}) sample/sec \"", ".", "format", "(", "sample_freq", ",", "update_freq", "-", "sample_freq", ")", "\n", "", "else", ":", "\n", "                ", "str_out", "+=", "\"Speed {:.2f} sample/sec \"", ".", "format", "(", "sample_freq", ")", "\n", "\n", "", "", "if", "not", "silent", ":", "\n", "            ", "logging", ".", "info", "(", "str_out", ")", "\n", "", "return", "str_out", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.MetricPrinter.__init__": [[70, 72], ["callback.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "with_header", "=", "False", ")", ":", "\n", "        ", "super", "(", "MetricPrinter", ",", "self", ")", ".", "__init__", "(", "with_header", "=", "with_header", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.MetricPrinter.__call__": [[73, 85], ["callback.MetricPrinter.header", "enumerate", "logging.info", "len"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.callback.Callback.header"], ["", "def", "__call__", "(", "self", ",", "namevals", ",", "epoch", "=", "None", ",", "batch", "=", "None", ",", "silent", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "str_out", "=", "self", ".", "header", "(", "epoch", ",", "batch", ")", "\n", "\n", "if", "namevals", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "nameval", "in", "enumerate", "(", "namevals", ")", ":", "\n", "                ", "name", ",", "value", "=", "nameval", "[", "0", "]", "\n", "str_out", "+=", "\"{} = {:.5f}\"", ".", "format", "(", "name", ",", "value", ")", "\n", "str_out", "+=", "\", \"", "if", "i", "!=", "(", "len", "(", "namevals", ")", "-", "1", ")", "else", "\" \"", "\n", "\n", "", "", "if", "not", "silent", ":", "\n", "            ", "logging", ".", "info", "(", "str_out", ")", "\n", "", "return", "str_out", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_hmdb51": [[10, 66], ["logging.debug", "video_transforms.Normalize", "video_sampler.RandomSampling", "video_iterator.VideoIter", "video_sampler.SequentialSampling", "video_iterator.VideoIter", "torch.distributed.get_rank", "os.path.join", "os.path.join", "video_transforms.Compose", "os.path.join", "os.path.join", "video_transforms.Compose", "video_transforms.RandomScale", "video_transforms.RandomCrop", "video_transforms.RandomHorizontalFlip", "video_transforms.RandomHLS", "video_transforms.ToTensor", "video_transforms.Resize", "video_transforms.CenterCrop", "video_transforms.ToTensor"], "function", ["None"], ["def", "get_hmdb51", "(", "data_root", "=", "'./dataset/HMDB51'", ",", "\n", "clip_length", "=", "8", ",", "\n", "train_interval", "=", "2", ",", "\n", "val_interval", "=", "2", ",", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "\n", "seed", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "if", "torch", ".", "distributed", ".", "_initialized", "else", "0", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" data iter for ucf-101\n    \"\"\"", "\n", "logging", ".", "debug", "(", "\"VideoIter:: clip_length = {}, interval = [train: {}, val: {}], seed = {}\"", ".", "format", "(", "clip_length", ",", "train_interval", ",", "val_interval", ",", "seed", ")", ")", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "\n", "train_sampler", "=", "sampler", ".", "RandomSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "train_interval", ",", "\n", "speed", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "seed", "=", "(", "seed", "+", "0", ")", ")", "\n", "train", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'hmdb51_split1_train.txt'", ")", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomScale", "(", "make_square", "=", "True", ",", "\n", "aspect_ratio", "=", "[", "0.8", ",", "1.", "/", "0.8", "]", ",", "\n", "slen", "=", "[", "224", ",", "288", "]", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "(", "224", ",", "224", ")", ")", ",", "# insert a resize if needed", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomHLS", "(", "vars", "=", "[", "15", ",", "35", ",", "25", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ",", "\n", "aug_seed", "=", "(", "seed", "+", "1", ")", ")", ",", "\n", "name", "=", "'train'", ",", "\n", "shuffle_list_seed", "=", "(", "seed", "+", "2", ")", ",", "\n", ")", "\n", "\n", "val_sampler", "=", "sampler", ".", "SequentialSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "val_interval", ",", "\n", "fix_cursor", "=", "True", ",", "\n", "shuffle", "=", "True", ")", "\n", "val", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'hmdb51_split1_test.txt'", ")", ",", "\n", "sampler", "=", "val_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "256", ",", "256", ")", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ",", "\n", "name", "=", "'test'", ",", "\n", ")", "\n", "\n", "return", "(", "train", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_ucf101": [[67, 123], ["logging.debug", "video_transforms.Normalize", "video_sampler.RandomSampling", "video_iterator.VideoIter", "video_sampler.SequentialSampling", "video_iterator.VideoIter", "torch.distributed.get_rank", "os.path.join", "os.path.join", "video_transforms.Compose", "os.path.join", "os.path.join", "video_transforms.Compose", "video_transforms.RandomScale", "video_transforms.RandomCrop", "video_transforms.RandomHorizontalFlip", "video_transforms.RandomHLS", "video_transforms.ToTensor", "video_transforms.Resize", "video_transforms.CenterCrop", "video_transforms.ToTensor"], "function", ["None"], ["", "def", "get_ucf101", "(", "data_root", "=", "'./dataset/UCF101'", ",", "\n", "clip_length", "=", "8", ",", "\n", "train_interval", "=", "2", ",", "\n", "val_interval", "=", "2", ",", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "\n", "seed", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "if", "torch", ".", "distributed", ".", "_initialized", "else", "0", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" data iter for ucf-101\n    \"\"\"", "\n", "logging", ".", "debug", "(", "\"VideoIter:: clip_length = {}, interval = [train: {}, val: {}], seed = {}\"", ".", "format", "(", "clip_length", ",", "train_interval", ",", "val_interval", ",", "seed", ")", ")", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "\n", "train_sampler", "=", "sampler", ".", "RandomSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "train_interval", ",", "\n", "speed", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "seed", "=", "(", "seed", "+", "0", ")", ")", "\n", "train", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'trainlist01.txt'", ")", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomScale", "(", "make_square", "=", "True", ",", "\n", "aspect_ratio", "=", "[", "0.8", ",", "1.", "/", "0.8", "]", ",", "\n", "slen", "=", "[", "224", ",", "288", "]", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "(", "224", ",", "224", ")", ")", ",", "# insert a resize if needed", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomHLS", "(", "vars", "=", "[", "15", ",", "35", ",", "25", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ",", "\n", "aug_seed", "=", "(", "seed", "+", "1", ")", ")", ",", "\n", "name", "=", "'train'", ",", "\n", "shuffle_list_seed", "=", "(", "seed", "+", "2", ")", ",", "\n", ")", "\n", "\n", "val_sampler", "=", "sampler", ".", "SequentialSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "val_interval", ",", "\n", "fix_cursor", "=", "True", ",", "\n", "shuffle", "=", "True", ")", "\n", "val", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'testlist01.txt'", ")", ",", "\n", "sampler", "=", "val_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "256", ",", "256", ")", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ",", "\n", "name", "=", "'test'", ",", "\n", ")", "\n", "\n", "return", "(", "train", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_kinetics": [[125, 180], ["logging.debug", "video_transforms.Normalize", "video_sampler.RandomSampling", "video_iterator.VideoIter", "video_sampler.SequentialSampling", "video_iterator.VideoIter", "torch.distributed.get_rank", "os.path.join", "os.path.join", "video_transforms.Compose", "os.path.join", "os.path.join", "video_transforms.Compose", "video_transforms.RandomScale", "video_transforms.RandomCrop", "video_transforms.RandomHorizontalFlip", "video_transforms.RandomHLS", "video_transforms.ToTensor", "video_transforms.Resize", "video_transforms.CenterCrop", "video_transforms.ToTensor"], "function", ["None"], ["", "def", "get_kinetics", "(", "data_root", "=", "'./dataset/Kinetics'", ",", "\n", "clip_length", "=", "8", ",", "\n", "train_interval", "=", "2", ",", "\n", "val_interval", "=", "2", ",", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "\n", "seed", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "if", "torch", ".", "distributed", ".", "_initialized", "else", "0", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" data iter for kinetics\n    \"\"\"", "\n", "logging", ".", "debug", "(", "\"VideoIter:: clip_length = {}, interval = [train: {}, val: {}], seed = {}\"", ".", "format", "(", "clip_length", ",", "train_interval", ",", "val_interval", ",", "seed", ")", ")", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "\n", "train_sampler", "=", "sampler", ".", "RandomSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "train_interval", ",", "\n", "speed", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "seed", "=", "(", "seed", "+", "0", ")", ")", "\n", "train", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ",", "'train_avi-x256'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'kinetics_train_w-missed-v1_avi.txt'", ")", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomScale", "(", "make_square", "=", "True", ",", "\n", "aspect_ratio", "=", "[", "0.8", ",", "1.", "/", "0.8", "]", ",", "\n", "slen", "=", "[", "224", ",", "288", "]", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "(", "224", ",", "224", ")", ")", ",", "# insert a resize if needed", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomHLS", "(", "vars", "=", "[", "15", ",", "35", ",", "25", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ",", "\n", "aug_seed", "=", "(", "seed", "+", "1", ")", ")", ",", "\n", "name", "=", "'train'", ",", "\n", "shuffle_list_seed", "=", "(", "seed", "+", "2", ")", ",", "\n", ")", "\n", "\n", "val_sampler", "=", "sampler", ".", "SequentialSampling", "(", "num", "=", "clip_length", ",", "\n", "interval", "=", "val_interval", ",", "\n", "fix_cursor", "=", "True", ",", "\n", "shuffle", "=", "True", ")", "\n", "val", "=", "VideoIter", "(", "video_prefix", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'data'", ",", "'val_avi-x256'", ")", ",", "\n", "txt_list", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'raw'", ",", "'list_cvt'", ",", "'kinetics_val_w-missed-v1_avi.txt'", ")", ",", "\n", "sampler", "=", "val_sampler", ",", "\n", "force_color", "=", "True", ",", "\n", "video_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "256", ",", "256", ")", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ",", "\n", "name", "=", "'test'", ",", "\n", ")", "\n", "return", "(", "train", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.creat": [[183, 204], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "name.upper", "iterator_factory.get_ucf101", "name.upper", "iterator_factory.get_hmdb51", "name.upper", "iterator_factory.get_kinetics", "NotImplementedError", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_ucf101", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_hmdb51", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.iterator_factory.get_kinetics"], ["", "def", "creat", "(", "name", ",", "batch_size", ",", "num_workers", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "name", ".", "upper", "(", ")", "==", "'UCF101'", ":", "\n", "        ", "train", ",", "val", "=", "get_ucf101", "(", "**", "kwargs", ")", "\n", "", "elif", "name", ".", "upper", "(", ")", "==", "'HMDB51'", ":", "\n", "        ", "train", ",", "val", "=", "get_hmdb51", "(", "**", "kwargs", ")", "\n", "", "elif", "name", ".", "upper", "(", ")", "==", "'KINETICS'", ":", "\n", "        ", "train", ",", "val", "=", "get_kinetics", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "assert", "NotImplementedError", "(", "\"iter {} not found\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val", ",", "\n", "batch_size", "=", "2", "*", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "return", "(", "train_loader", ",", "val_loader", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset.__init__": [[13, 44], ["torch.Dataset.__init__", "torchvision.transforms.Compose", "new_nvvl_dataset.Video_dataset._get_video_list", "torchvision.transforms.ToTensor"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter._get_video_list"], ["    ", "def", "__init__", "(", "self", ",", "\n", "video_prefix", ",", "# video root", "\n", "txt_list", ",", "# video list", "\n", "clip_length", ",", "\n", "device_id", ",", "# gpu id for load video", "\n", "video_transform", "=", "None", ",", "\n", "return_item_subpath", "=", "False", ",", "\n", "transform", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", "Video_dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "video_prefix", "=", "video_prefix", "\n", "self", ".", "clip_length", "=", "clip_length", "\n", "self", ".", "video_transform", "=", "video_transform", "\n", "self", ".", "return_item_subpath", "=", "return_item_subpath", "\n", "self", ".", "device_id", "=", "device_id", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", "]", ")", "# you can add to the list all the transformations you need.", "\n", "\n", "self", ".", "video_list", "=", "self", ".", "_get_video_list", "(", "video_prefix", "=", "self", ".", "video_prefix", ",", "txt_list", "=", "txt_list", ",", ")", "# [vid, label, video_subpath]", "\n", "#self.loader = pynvvl.NVVLVideoLoader(device_id=self.device_id)", "\n", "#self.loader = pynvvl.NVVLVideoLoader(device_id=self.device_id, log_level='error')", "\n", "\"\"\"\n        self.processing = {\"input\": nvvl.ProcessDesc(\n            type = 'half',\n            height = 224,\n            width = 224,\n            random_crop = False,\n            random_flip = False,\n            color_space = \"RGB\",\n            dimension_order = \"cfhw\",\n            normalized = True\n        )}\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset.__getitem__": [[45, 59], ["new_nvvl_dataset.Video_dataset._video_load", "print", "new_nvvl_dataset.Video_dataset.__getitem__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset._video_load", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "clip_input", ",", "label", ",", "vid_subpath", "=", "self", ".", "_video_load", "(", "index", ")", "\n", "\n", "if", "self", ".", "return_item_subpath", ":", "\n", "                ", "return", "clip_input", ",", "label", ",", "vid_subpath", "\n", "", "else", ":", "\n", "                ", "return", "clip_input", ",", "label", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "index", "=", "index", "-", "1", "if", "index", ">", "0", "else", "index", "+", "1", "\n", "print", "(", "\"Video_dataset: %s, skip it\"", "%", "e", ")", "\n", "return", "self", ".", "__getitem__", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset.__len__": [[61, 63], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset._video_load": [[65, 101], ["os.path.join", "pynvvl.NVVLVideoLoader", "os.path.getsize", "print", "new_nvvl_dataset.Video_dataset.__getitem__", "pynvvl.NVVLVideoLoader.frame_count", "int", "pynvvl.NVVLVideoLoader.read_sequence", "cupy.asnumpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "new_nvvl_dataset.Video_dataset.__getitem__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__getitem__", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__getitem__"], ["", "def", "_video_load", "(", "self", ",", "index", ")", ":", "\n", "# get current video info", "\n", "        ", "v_id", ",", "label", ",", "vid_subpath", "=", "self", ".", "video_list", "[", "index", "]", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "video_prefix", ",", "vid_subpath", ")", "\n", "#video = nvvl.VideoDataset(video_path,", "\n", "#sequence_length=self.clip_length,", "\n", "#device_id=self.device_id,", "\n", "#processing = self.processing)", "\n", "loader", "=", "pynvvl", ".", "NVVLVideoLoader", "(", "device_id", "=", "self", ".", "device_id", ")", "\n", "if", "os", ".", "path", ".", "getsize", "(", "video_path", ")", "<", "300", ":", "\n", "            ", "print", "(", "\"Null video: {}, skip it\"", ".", "format", "(", "video_path", ")", ")", "\n", "index", "=", "index", "-", "1", "if", "index", ">", "0", "else", "index", "+", "1", "\n", "return", "self", ".", "__getitem__", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "n_frames", "=", "loader", ".", "frame_count", "(", "video_path", ")", "\n", "if", "n_frames", "==", "0", ":", "\n", "                ", "index", "=", "index", "-", "1", "if", "index", ">", "0", "else", "index", "+", "1", "\n", "return", "self", ".", "__getitem__", "(", "index", ")", "\n", "", "random_start_frame", "=", "int", "(", "2", ")", "\n", "\n", "video", "=", "loader", ".", "read_sequence", "(", "\n", "filename", "=", "video_path", ",", "\n", "frame", "=", "random_start_frame", ",", "\n", "count", "=", "self", ".", "clip_length", ",", "\n", "scale_height", "=", "224", ",", "\n", "scale_width", "=", "224", ",", "\n", "crop_height", "=", "224", ",", "\n", "crop_width", "=", "224", ",", "\n", "horiz_flip", "=", "True", ",", "\n", "scale_method", "=", "'Linear'", ",", "\n", "normalized", "=", "True", "\n", ")", "\n", "video", "=", "cupy", ".", "asnumpy", "(", "video", ")", "\n", "video", "=", "torch", ".", "from_numpy", "(", "video", ")", "\n", "\n", "", "return", "video", ",", "label", ",", "vid_subpath", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.new_nvvl_dataset.Video_dataset._get_video_list": [[103, 130], ["os.path.exists", "os.path.exists", "open", "f.read().splitlines", "logging.info", "enumerate", "line.split", "video_subpath.replace.replace.replace", "os.path.join", "video_list.append", "f.read", "len", "os.path.exists", "logging.warning", "int", "int"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["", "def", "_get_video_list", "(", "self", ",", "\n", "video_prefix", ",", "\n", "txt_list", ",", "\n", "check_video", "=", "False", ",", "\n", "cached_info_path", "=", "None", ")", ":", "\n", "# formate:", "\n", "# [v_id, label, video_subpath]", "\n", "        ", "assert", "os", ".", "path", ".", "exists", "(", "video_prefix", ")", ",", "\"VideoIter:: failed to locate: `{}'\"", ".", "format", "(", "video_prefix", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "txt_list", ")", ",", "\"VideoIter:: failed to locate: `{}'\"", ".", "format", "(", "txt_list", ")", "\n", "\n", "# building dataset", "\n", "video_list", "=", "[", "]", "# [v_id, label, video_subpath]", "\n", "with", "open", "(", "txt_list", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "logging", ".", "info", "(", "\"VideoIter:: found {} videos in `{}'\"", ".", "format", "(", "len", "(", "lines", ")", ",", "txt_list", ")", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "v_id", ",", "label", ",", "video_subpath", "=", "line", ".", "split", "(", ")", "\n", "video_subpath", "=", "video_subpath", ".", "replace", "(", "'.avi'", ",", "'.mp4'", ")", "# format should be '.mp4' for nvvl", "\n", "#print(video_subpath)", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "video_prefix", ",", "video_subpath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "                    ", "logging", ".", "warning", "(", "\"VideoIter:: >> cannot locate `{}'\"", ".", "format", "(", "video_path", ")", ")", "\n", "continue", "\n", "", "info", "=", "[", "int", "(", "v_id", ")", ",", "int", "(", "label", ")", ",", "video_subpath", "]", "\n", "video_list", ".", "append", "(", "info", ")", "\n", "\n", "", "", "return", "video_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.__init__": [[15, 17], ["video_iterator.Video.open"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["def", "__init__", "(", "self", ",", "vid_path", ")", ":", "\n", "        ", "self", ".", "open", "(", "vid_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.__del__": [[18, 20], ["video_iterator.Video.close"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.__enter__": [[21, 23], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.__exit__": [[24, 26], ["video_iterator.Video.__del__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.__del__"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "        ", "self", ".", "__del__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset": [[27, 33], ["video_iterator.Video.close"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.close"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "self", ".", "vid_path", "=", "None", "\n", "self", ".", "frame_count", "=", "-", "1", "\n", "self", ".", "faulty_frame", "=", "None", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open": [[34, 49], ["os.path.exists", "video_iterator.Video.reset", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "IOError"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.reset"], ["", "def", "open", "(", "self", ",", "vid_path", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "exists", "(", "vid_path", ")", ",", "\"VideoIter:: cannot locate: `{}'\"", ".", "format", "(", "vid_path", ")", "\n", "\n", "# close previous video & reset variables", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "# try to open video", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "vid_path", ")", "\n", "if", "cap", ".", "isOpened", "(", ")", ":", "\n", "            ", "self", ".", "cap", "=", "cap", "\n", "self", ".", "vid_path", "=", "vid_path", "\n", "", "else", ":", "\n", "            ", "raise", "IOError", "(", "\"VideoIter:: failed to open video: `{}'\"", ".", "format", "(", "vid_path", ")", ")", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.count_frames": [[50, 68], ["video_iterator.Video.vid_path.endswith", "int", "range", "video_iterator.Video.cap.get", "video_iterator.Video.cap.set", "video_iterator.Video.cap.grab", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.MetricList.get"], ["", "def", "count_frames", "(", "self", ",", "check_validity", "=", "False", ")", ":", "\n", "        ", "offset", "=", "0", "\n", "if", "self", ".", "vid_path", ".", "endswith", "(", "'.flv'", ")", ":", "\n", "            ", "offset", "=", "-", "1", "\n", "", "unverified_frame_count", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "+", "offset", "\n", "if", "check_validity", ":", "\n", "            ", "verified_frame_count", "=", "0", "\n", "for", "i", "in", "range", "(", "unverified_frame_count", ")", ":", "\n", "                ", "self", ".", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "i", ")", "\n", "if", "not", "self", ".", "cap", ".", "grab", "(", ")", ":", "\n", "                    ", "logging", ".", "warning", "(", "\"VideoIter:: >> frame (start from 0) {} corrupted in {}\"", ".", "format", "(", "i", ",", "self", ".", "vid_path", ")", ")", "\n", "break", "\n", "", "verified_frame_count", "=", "i", "+", "1", "\n", "", "self", ".", "frame_count", "=", "verified_frame_count", "\n", "", "else", ":", "\n", "            ", "self", ".", "frame_count", "=", "unverified_frame_count", "\n", "", "assert", "self", ".", "frame_count", ">", "0", ",", "\"VideoIter:: Video: `{}' has no frames\"", ".", "format", "(", "self", ".", "vid_path", ")", "\n", "return", "self", ".", "frame_count", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames": [[69, 75], ["video_iterator.Video.extract_frames_fast", "video_iterator.Video.extract_frames_slow"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames_fast", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames_slow"], ["", "def", "extract_frames", "(", "self", ",", "idxs", ",", "force_color", "=", "True", ")", ":", "\n", "        ", "frames", "=", "self", ".", "extract_frames_fast", "(", "idxs", ",", "force_color", ")", "\n", "if", "frames", "is", "None", ":", "\n", "# try slow method:", "\n", "            ", "frames", "=", "self", ".", "extract_frames_slow", "(", "idxs", ",", "force_color", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames_fast": [[76, 102], ["max", "len", "video_iterator.Video.cap.read", "frames.append", "video_iterator.Video.cap.set", "len", "cv2.cvtColor", "cv2.cvtColor"], "methods", ["None"], ["", "def", "extract_frames_fast", "(", "self", ",", "idxs", ",", "force_color", "=", "True", ")", ":", "\n", "        ", "assert", "self", ".", "cap", "is", "not", "None", ",", "\"No opened video.\"", "\n", "if", "len", "(", "idxs", ")", "<", "1", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "frames", "=", "[", "]", "\n", "pre_idx", "=", "max", "(", "idxs", ")", "\n", "for", "idx", "in", "idxs", ":", "\n", "            ", "assert", "(", "self", ".", "frame_count", "<", "0", ")", "or", "(", "idx", "<", "self", ".", "frame_count", ")", ",", "\"idxs: {} > total valid frames({})\"", ".", "format", "(", "idxs", ",", "self", ".", "frame_count", ")", "\n", "if", "pre_idx", "!=", "(", "idx", "-", "1", ")", ":", "\n", "                ", "self", ".", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "idx", ")", "\n", "", "res", ",", "frame", "=", "self", ".", "cap", ".", "read", "(", ")", "# in BGR/GRAY format", "\n", "pre_idx", "=", "idx", "\n", "if", "not", "res", ":", "\n", "                ", "self", ".", "faulty_frame", "=", "idx", "\n", "return", "None", "\n", "", "if", "len", "(", "frame", ".", "shape", ")", "<", "3", ":", "\n", "                ", "if", "force_color", ":", "\n", "# Convert Gray to RGB", "\n", "                    ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_GRAY2RGB", ")", "\n", "", "", "else", ":", "\n", "# Convert BGR to RGB", "\n", "                ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "", "frames", ".", "append", "(", "frame", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames_slow": [[103, 131], ["min", "video_iterator.Video.cap.set", "len", "len", "max", "video_iterator.Video.cap.read", "len", "cv2.cvtColor", "cv2.cvtColor", "enumerate"], "methods", ["None"], ["", "def", "extract_frames_slow", "(", "self", ",", "idxs", ",", "force_color", "=", "True", ")", ":", "\n", "        ", "assert", "self", ".", "cap", "is", "not", "None", ",", "\"No opened video.\"", "\n", "if", "len", "(", "idxs", ")", "<", "1", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "frames", "=", "[", "None", "]", "*", "len", "(", "idxs", ")", "\n", "idx", "=", "min", "(", "idxs", ")", "\n", "self", ".", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "idx", ")", "\n", "while", "idx", "<=", "max", "(", "idxs", ")", ":", "\n", "            ", "res", ",", "frame", "=", "self", ".", "cap", ".", "read", "(", ")", "# in BGR/GRAY format", "\n", "if", "not", "res", ":", "\n", "# end of the video", "\n", "                ", "self", ".", "faulty_frame", "=", "idx", "\n", "return", "None", "\n", "", "if", "idx", "in", "idxs", ":", "\n", "# fond a frame", "\n", "                ", "if", "len", "(", "frame", ".", "shape", ")", "<", "3", ":", "\n", "                    ", "if", "force_color", ":", "\n", "# Convert Gray to RGB", "\n", "                        ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_GRAY2RGB", ")", "\n", "", "", "else", ":", "\n", "# Convert BGR to RGB", "\n", "                    ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "", "pos", "=", "[", "k", "for", "k", ",", "i", "in", "enumerate", "(", "idxs", ")", "if", "i", "==", "idx", "]", "\n", "for", "k", "in", "pos", ":", "\n", "                    ", "frames", "[", "k", "]", "=", "frame", "\n", "", "", "idx", "+=", "1", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.close": [[132, 137], ["hasattr", "video_iterator.Video.cap.release"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'cap'", ")", "and", "self", ".", "cap", "is", "not", "None", ":", "\n", "            ", "self", ".", "cap", ".", "release", "(", ")", "\n", "self", ".", "cap", "=", "None", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter.__init__": [[141, 175], ["torch.Dataset.__init__", "numpy.random.RandomState", "video_iterator.VideoIter._get_video_list", "logging.info", "logging.warning", "video_iterator.VideoIter.rng.shuffle", "len"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter._get_video_list"], ["    ", "def", "__init__", "(", "self", ",", "\n", "video_prefix", ",", "\n", "txt_list", ",", "\n", "sampler", ",", "\n", "video_transform", "=", "None", ",", "\n", "name", "=", "\"<NO_NAME>\"", ",", "\n", "force_color", "=", "True", ",", "\n", "cached_info_path", "=", "None", ",", "\n", "#return_item_subpath=False,", "\n", "return_item_subpath", "=", "True", ",", "\n", "shuffle_list_seed", "=", "None", ",", "\n", "check_video", "=", "False", ",", "\n", "tolerant_corrupted_video", "=", "None", ")", ":", "\n", "        ", "super", "(", "VideoIter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# load params", "\n", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "force_color", "=", "force_color", "\n", "self", ".", "video_prefix", "=", "video_prefix", "\n", "self", ".", "video_transform", "=", "video_transform", "\n", "self", ".", "return_item_subpath", "=", "return_item_subpath", "\n", "self", ".", "backup_item", "=", "None", "\n", "if", "(", "not", "check_video", ")", "and", "(", "tolerant_corrupted_video", "is", "None", ")", ":", "\n", "            ", "logging", ".", "warning", "(", "\"VideoIter:: >> `check_video' is off, `tolerant_corrupted_video' is automatically activated.\"", ")", "\n", "tolerant_corrupted_video", "=", "True", "\n", "", "self", ".", "tolerant_corrupted_video", "=", "tolerant_corrupted_video", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "shuffle_list_seed", "if", "shuffle_list_seed", "else", "0", ")", "\n", "# load video list", "\n", "self", ".", "video_list", "=", "self", ".", "_get_video_list", "(", "video_prefix", "=", "video_prefix", ",", "\n", "txt_list", "=", "txt_list", ",", "\n", "check_video", "=", "check_video", ",", "\n", "cached_info_path", "=", "cached_info_path", ")", "\n", "if", "shuffle_list_seed", "is", "not", "None", ":", "\n", "            ", "self", ".", "rng", ".", "shuffle", "(", "self", ".", "video_list", ")", "\n", "", "logging", ".", "info", "(", "\"VideoIter:: iterator initialized (phase: '{:s}', num: {:d})\"", ".", "format", "(", "name", ",", "len", "(", "self", ".", "video_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter.getitem_from_raw_video": [[176, 219], ["os.path.join", "numpy.concatenate", "logging.warning", "video_iterator.VideoIter.video_transform", "video_iterator.Video", "range", "logging.warning", "video_iterator.Video", "video.extract_frames", "video.count_frames", "video_iterator.VideoIter.sampler.sampling", "set().intersection", "list", "video.extract_frames", "faulty_frames.append", "video_iterator.VideoIter.rng.rand", "set", "list"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.count_frames", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_sampler.SequentialSampling.sampling", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.extract_frames"], ["", "def", "getitem_from_raw_video", "(", "self", ",", "index", ")", ":", "\n", "# get current video info", "\n", "        ", "v_id", ",", "label", ",", "vid_subpath", ",", "frame_count", "=", "self", ".", "video_list", "[", "index", "]", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "video_prefix", ",", "vid_subpath", ")", "\n", "\n", "faulty_frames", "=", "[", "]", "\n", "successfule_trial", "=", "False", "\n", "try", ":", "\n", "            ", "with", "Video", "(", "vid_path", "=", "video_path", ")", "as", "video", ":", "\n", "                ", "if", "frame_count", "<", "0", ":", "\n", "                    ", "frame_count", "=", "video", ".", "count_frames", "(", "check_validity", "=", "False", ")", "\n", "", "for", "i_trial", "in", "range", "(", "20", ")", ":", "\n", "# dynamic sampling", "\n", "                    ", "sampled_idxs", "=", "self", ".", "sampler", ".", "sampling", "(", "range_max", "=", "frame_count", ",", "v_id", "=", "v_id", ",", "prev_failed", "=", "(", "i_trial", ">", "0", ")", ")", "\n", "if", "set", "(", "list", "(", "sampled_idxs", ")", ")", ".", "intersection", "(", "faulty_frames", ")", ":", "\n", "                        ", "continue", "\n", "", "prev_sampled_idxs", "=", "list", "(", "sampled_idxs", ")", "\n", "# extracting frames", "\n", "sampled_frames", "=", "video", ".", "extract_frames", "(", "idxs", "=", "sampled_idxs", ",", "force_color", "=", "self", ".", "force_color", ")", "\n", "if", "sampled_frames", "is", "None", ":", "\n", "                        ", "faulty_frames", ".", "append", "(", "video", ".", "faulty_frame", ")", "\n", "", "else", ":", "\n", "                        ", "successfule_trial", "=", "True", "\n", "break", "\n", "", "", "", "", "except", "IOError", "as", "e", ":", "\n", "            ", "logging", ".", "warning", "(", "\">> I/O error({0}): {1}\"", ".", "format", "(", "e", ".", "errno", ",", "e", ".", "strerror", ")", ")", "\n", "\n", "", "if", "not", "successfule_trial", ":", "\n", "            ", "assert", "(", "self", ".", "backup_item", "is", "not", "None", ")", ",", "\"VideoIter:: >> frame {} is error & backup is inavailable. [{}]'\"", ".", "format", "(", "faulty_frames", ",", "video_path", ")", "\n", "logging", ".", "warning", "(", "\">> frame {} is error, use backup item! [{}]\"", ".", "format", "(", "faulty_frames", ",", "video_path", ")", ")", "\n", "with", "Video", "(", "vid_path", "=", "self", ".", "backup_item", "[", "'video_path'", "]", ")", "as", "video", ":", "\n", "                ", "sampled_frames", "=", "video", ".", "extract_frames", "(", "idxs", "=", "self", ".", "backup_item", "[", "'sampled_idxs'", "]", ",", "force_color", "=", "self", ".", "force_color", ")", "\n", "", "", "elif", "self", ".", "tolerant_corrupted_video", ":", "\n", "# assume the error rate less than 10%", "\n", "            ", "if", "(", "self", ".", "backup_item", "is", "None", ")", "or", "(", "self", ".", "rng", ".", "rand", "(", ")", "<", "0.1", ")", ":", "\n", "                ", "self", ".", "backup_item", "=", "{", "'video_path'", ":", "video_path", ",", "'sampled_idxs'", ":", "sampled_idxs", "}", "\n", "\n", "", "", "clip_input", "=", "np", ".", "concatenate", "(", "sampled_frames", ",", "axis", "=", "2", ")", "\n", "# apply video augmentation", "\n", "if", "self", ".", "video_transform", "is", "not", "None", ":", "\n", "            ", "clip_input", "=", "self", ".", "video_transform", "(", "clip_input", ")", "\n", "", "return", "clip_input", ",", "label", ",", "vid_subpath", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter.__getitem__": [[221, 235], ["video_iterator.VideoIter.getitem_from_raw_video", "video_iterator.VideoIter.rng.choice", "logging.warning", "range", "video_iterator.VideoIter.__len__"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter.getitem_from_raw_video", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "succ", "=", "False", "\n", "while", "not", "succ", ":", "\n", "            ", "try", ":", "\n", "                ", "clip_input", ",", "label", ",", "vid_subpath", "=", "self", ".", "getitem_from_raw_video", "(", "index", ")", "\n", "succ", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "index", "=", "self", ".", "rng", ".", "choice", "(", "range", "(", "0", ",", "self", ".", "__len__", "(", ")", ")", ")", "\n", "logging", ".", "warning", "(", "\"VideoIter:: ERROR!! (Force using another index:\\n{})\\n{}\"", ".", "format", "(", "index", ",", "e", ")", ")", "\n", "\n", "", "", "if", "self", ".", "return_item_subpath", ":", "\n", "            ", "return", "clip_input", ",", "label", ",", "vid_subpath", "\n", "", "else", ":", "\n", "            ", "return", "clip_input", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter.__len__": [[237, 239], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.VideoIter._get_video_list": [[241, 317], ["os.path.exists", "os.path.exists", "os.path.exists", "open", "open.read().splitlines", "logging.info", "enumerate", "logging.info", "cached_video_info.update", "open", "open.close", "line.split", "os.path.join", "video_list.append", "len", "open", "open.write", "open.write", "enumerate", "open.readline().split", "open.readline().split", "logging.info", "open.readlines", "logging.warning", "os.path.exists", "os.makedirs", "open.read", "len", "os.path.exists", "logging.warning", "int", "int", "logging.info", "len", "cached_video_info.items", "open.write", "video_prefix.replace", "txt_list.replace", "line.split", "cached_video_info.update", "os.path.dirname", "os.path.dirname", "video_prefix.replace", "txt_list.replace", "open.write", "open.readline", "open.readline", "video_iterator.VideoIter.video.open().count_frames", "new_video_info.update", "len", "int", "video_iterator.VideoIter.video.open"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.close", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.count_frames", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.train.metric.Loss.update", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["", "def", "_get_video_list", "(", "self", ",", "\n", "video_prefix", ",", "\n", "txt_list", ",", "\n", "check_video", "=", "False", ",", "\n", "cached_info_path", "=", "None", ")", ":", "\n", "# formate:", "\n", "# [vid, label, video_subpath, frame_count]", "\n", "        ", "assert", "os", ".", "path", ".", "exists", "(", "video_prefix", ")", ",", "\"VideoIter:: failed to locate: `{}'\"", ".", "format", "(", "video_prefix", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "txt_list", ")", ",", "\"VideoIter:: failed to locate: `{}'\"", ".", "format", "(", "txt_list", ")", "\n", "\n", "# try to load cached list", "\n", "cached_video_info", "=", "{", "}", "\n", "if", "cached_info_path", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "cached_info_path", ")", ":", "\n", "                ", "f", "=", "open", "(", "cached_info_path", ",", "'r'", ")", "\n", "cached_video_prefix", "=", "f", ".", "readline", "(", ")", ".", "split", "(", ")", "[", "1", "]", "\n", "cached_txt_list", "=", "f", ".", "readline", "(", ")", ".", "split", "(", ")", "[", "1", "]", "\n", "if", "(", "cached_video_prefix", "==", "video_prefix", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "and", "(", "cached_txt_list", "==", "txt_list", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", ":", "\n", "                    ", "logging", ".", "info", "(", "\"VideoIter:: loading cached video info from: `{}'\"", ".", "format", "(", "cached_info_path", ")", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                        ", "video_subpath", ",", "frame_count", "=", "line", ".", "split", "(", ")", "\n", "cached_video_info", ".", "update", "(", "{", "video_subpath", ":", "int", "(", "frame_count", ")", "}", ")", "\n", "", "", "else", ":", "\n", "                    ", "logging", ".", "warning", "(", "\">> Cached video list mismatched: \"", "+", "\n", "\"(prefix:{}, list:{}) != expected (prefix:{}, list:{})\"", ".", "format", "(", "cached_video_prefix", ",", "cached_txt_list", ",", "video_prefix", ",", "txt_list", ")", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "cached_info_path", ")", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "cached_info_path", ")", ")", "\n", "\n", "# building dataset", "\n", "", "", "", "video_list", "=", "[", "]", "\n", "new_video_info", "=", "{", "}", "\n", "logging_interval", "=", "100", "\n", "with", "open", "(", "txt_list", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "logging", ".", "info", "(", "\"VideoIter:: found {} videos in `{}'\"", ".", "format", "(", "len", "(", "lines", ")", ",", "txt_list", ")", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "v_id", ",", "label", ",", "video_subpath", "=", "line", ".", "split", "(", ")", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "video_prefix", ",", "video_subpath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "                    ", "logging", ".", "warning", "(", "\"VideoIter:: >> cannot locate `{}'\"", ".", "format", "(", "video_path", ")", ")", "\n", "continue", "\n", "", "if", "check_video", ":", "\n", "                    ", "if", "video_subpath", "in", "cached_video_info", ":", "\n", "                        ", "frame_count", "=", "cached_video_info", "[", "video_subpath", "]", "\n", "", "elif", "video_subpath", "in", "new_video_info", ":", "\n", "                        ", "frame_count", "=", "cached_video_info", "[", "video_subpath", "]", "\n", "", "else", ":", "\n", "                        ", "frame_count", "=", "self", ".", "video", ".", "open", "(", "video_path", ")", ".", "count_frames", "(", "check_validity", "=", "True", ")", "\n", "new_video_info", ".", "update", "(", "{", "video_subpath", ":", "frame_count", "}", ")", "\n", "", "", "else", ":", "\n", "                    ", "frame_count", "=", "-", "1", "\n", "", "info", "=", "[", "int", "(", "v_id", ")", ",", "int", "(", "label", ")", ",", "video_subpath", ",", "frame_count", "]", "\n", "video_list", ".", "append", "(", "info", ")", "\n", "if", "check_video", "and", "(", "i", "%", "logging_interval", ")", "==", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "\"VideoIter:: - Checking: {:d}/{:d}, \\tinfo: {}\"", ".", "format", "(", "i", ",", "len", "(", "lines", ")", ",", "info", ")", ")", "\n", "\n", "# caching video list", "\n", "", "", "", "if", "cached_info_path", "and", "len", "(", "new_video_info", ")", ">", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"VideoIter:: adding {} lines new video info to: {}\"", ".", "format", "(", "len", "(", "new_video_info", ")", ",", "cached_info_path", ")", ")", "\n", "cached_video_info", ".", "update", "(", "new_video_info", ")", "\n", "with", "open", "(", "cached_info_path", ",", "'w'", ")", "as", "f", ":", "\n", "# head", "\n", "                ", "f", ".", "write", "(", "\"video_prefix: {:s}\\n\"", ".", "format", "(", "video_prefix", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", ")", "\n", "f", ".", "write", "(", "\"txt_list: {:s}\\n\"", ".", "format", "(", "txt_list", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", ")", "\n", "# content", "\n", "for", "i", ",", "(", "video_subpath", ",", "frame_count", ")", "in", "enumerate", "(", "cached_video_info", ".", "items", "(", ")", ")", ":", "\n", "                    ", "if", "i", ">", "0", ":", "\n", "                        ", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"{:s}\\t{:d}\"", ".", "format", "(", "video_subpath", ",", "frame_count", ")", ")", "\n", "\n", "", "", "", "return", "video_list", "", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Compose.__init__": [[20, 24], ["enumerate", "t.set_random_state"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Transform.set_random_state"], ["def", "__init__", "(", "self", ",", "transforms", ",", "aug_seed", "=", "0", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "transforms", ")", ":", "\n", "            ", "t", ".", "set_random_state", "(", "seed", "=", "(", "aug_seed", "+", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Compose.__call__": [[25, 29], ["t"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "data", "=", "t", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Transform.set_random_state": [[32, 34], ["numpy.random.RandomState"], "methods", ["None"], ["def", "set_random_state", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Normalize.__init__": [[45, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Normalize.__call__": [[49, 53], ["zip", "t.sub_().div_", "t.sub_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ":", "\n", "            ", "t", ".", "sub_", "(", "m", ")", ".", "div_", "(", "s", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Resize.__init__": [[63, 66], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "cv2", ".", "INTER_LINEAR", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "# [w, h]", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.Resize.__call__": [[67, 90], ["isinstance", "cv2.resize", "min", "int", "int"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "\n", "if", "isinstance", "(", "self", ".", "size", ",", "int", ")", ":", "\n", "            ", "slen", "=", "self", ".", "size", "\n", "if", "min", "(", "w", ",", "h", ")", "==", "slen", ":", "\n", "                ", "return", "data", "\n", "", "if", "w", "<", "h", ":", "\n", "                ", "new_w", "=", "self", ".", "size", "\n", "new_h", "=", "int", "(", "self", ".", "size", "*", "h", "/", "w", ")", "\n", "", "else", ":", "\n", "                ", "new_w", "=", "int", "(", "self", ".", "size", "*", "w", "/", "h", ")", "\n", "new_h", "=", "self", ".", "size", "\n", "", "", "else", ":", "\n", "            ", "new_w", "=", "self", ".", "size", "[", "0", "]", "\n", "new_h", "=", "self", ".", "size", "[", "1", "]", "\n", "\n", "", "if", "(", "h", "!=", "new_h", ")", "or", "(", "w", "!=", "new_w", ")", ":", "\n", "            ", "scaled_data", "=", "cv2", ".", "resize", "(", "data", ",", "(", "new_w", ",", "new_h", ")", ",", "self", ".", "interpolation", ")", "\n", "", "else", ":", "\n", "            ", "scaled_data", "=", "data", "\n", "\n", "", "return", "scaled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomScale.__init__": [[100, 113], ["numpy.random.RandomState"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "make_square", "=", "False", ",", "\n", "aspect_ratio", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "slen", "=", "[", "224", ",", "288", "]", ",", "\n", "interpolation", "=", "cv2", ".", "INTER_LINEAR", ")", ":", "\n", "        ", "assert", "slen", "[", "1", "]", ">=", "slen", "[", "0", "]", ",", "\"slen ({}) should be in increase order\"", ".", "format", "(", "scale", ")", "\n", "assert", "aspect_ratio", "[", "1", "]", ">=", "aspect_ratio", "[", "0", "]", ",", "\"aspect_ratio ({}) should be in increase order\"", ".", "format", "(", "aspect_ratio", ")", "\n", "self", ".", "slen", "=", "slen", "# [min factor, max factor]", "\n", "self", ".", "aspect_ratio", "=", "aspect_ratio", "\n", "self", ".", "make_square", "=", "make_square", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomScale.__call__": [[114, 129], ["cv2.resize", "image_transforms.RandomScale.rng.uniform", "image_transforms.RandomScale.rng.uniform", "min", "image_transforms.RandomScale.rng.rand", "int", "int"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "new_w", "=", "w", "\n", "new_h", "=", "h", "if", "not", "self", ".", "make_square", "else", "w", "\n", "if", "self", ".", "aspect_ratio", ":", "\n", "            ", "random_aspect_ratio", "=", "self", ".", "rng", ".", "uniform", "(", "self", ".", "aspect_ratio", "[", "0", "]", ",", "self", ".", "aspect_ratio", "[", "1", "]", ")", "\n", "if", "self", ".", "rng", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "                ", "random_aspect_ratio", "=", "1.0", "/", "random_aspect_ratio", "\n", "", "new_w", "*=", "random_aspect_ratio", "\n", "new_h", "/=", "random_aspect_ratio", "\n", "", "resize_factor", "=", "self", ".", "rng", ".", "uniform", "(", "self", ".", "slen", "[", "0", "]", ",", "self", ".", "slen", "[", "1", "]", ")", "/", "min", "(", "new_w", ",", "new_h", ")", "\n", "new_w", "*=", "resize_factor", "\n", "new_h", "*=", "resize_factor", "\n", "scaled_data", "=", "cv2", ".", "resize", "(", "data", ",", "(", "int", "(", "new_w", "+", "1", ")", ",", "int", "(", "new_h", "+", "1", ")", ")", ",", "self", ".", "interpolation", ")", "\n", "return", "scaled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.CenterCrop.__init__": [[136, 141], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "size", ",", "size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.CenterCrop.__call__": [[142, 149], ["int", "int", "round", "round"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "x1", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.", ")", ")", "\n", "cropped_data", "=", "data", "[", "y1", ":", "(", "y1", "+", "th", ")", ",", "x1", ":", "(", "x1", "+", "tw", ")", ",", ":", "]", "\n", "return", "cropped_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomCrop.__init__": [[155, 161], ["isinstance", "numpy.random.RandomState"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "size", ",", "size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomCrop.__call__": [[162, 169], ["image_transforms.RandomCrop.rng.choice", "image_transforms.RandomCrop.rng.choice", "range", "range"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "x1", "=", "self", ".", "rng", ".", "choice", "(", "range", "(", "w", "-", "tw", ")", ")", "\n", "y1", "=", "self", ".", "rng", ".", "choice", "(", "range", "(", "h", "-", "th", ")", ")", "\n", "cropped_data", "=", "data", "[", "y1", ":", "(", "y1", "+", "th", ")", ",", "x1", ":", "(", "x1", "+", "tw", ")", ",", ":", "]", "\n", "return", "cropped_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomHorizontalFlip.__init__": [[173, 175], ["numpy.random.RandomState"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomHorizontalFlip.__call__": [[176, 181], ["image_transforms.RandomHorizontalFlip.rng.rand", "numpy.fliplr", "numpy.ascontiguousarray"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "rng", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "            ", "data", "=", "np", ".", "fliplr", "(", "data", ")", "\n", "data", "=", "np", ".", "ascontiguousarray", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomVerticalFlip.__init__": [[185, 187], ["numpy.random.RandomState"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomVerticalFlip.__call__": [[188, 193], ["image_transforms.RandomVerticalFlip.rng.rand", "numpy.flipud", "numpy.ascontiguousarray"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "rng", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "            ", "data", "=", "np", ".", "flipud", "(", "data", ")", "\n", "data", "=", "np", ".", "ascontiguousarray", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomRGB.__init__": [[195, 198], ["numpy.random.RandomState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vars", "=", "[", "10", ",", "10", ",", "10", "]", ")", ":", "\n", "        ", "self", ".", "vars", "=", "vars", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomRGB.__call__": [[199, 210], ["len", "numpy.zeros", "range", "int", "numpy.minimum", "round", "numpy.maximum", "image_transforms.RandomRGB.rng.uniform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "\n", "random_vars", "=", "[", "int", "(", "round", "(", "self", ".", "rng", ".", "uniform", "(", "-", "x", ",", "x", ")", ")", ")", "for", "x", "in", "self", ".", "vars", "]", "\n", "\n", "base", "=", "len", "(", "random_vars", ")", "\n", "augmented_data", "=", "np", ".", "zeros", "(", "data", ".", "shape", ")", "\n", "for", "ic", "in", "range", "(", "0", ",", "c", ")", ":", "\n", "            ", "var", "=", "random_vars", "[", "ic", "%", "base", "]", "\n", "augmented_data", "[", ":", ",", ":", ",", "ic", "]", "=", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "data", "[", ":", ",", ":", ",", "ic", "]", "+", "var", ",", "0", ")", ",", "255", ")", "\n", "", "return", "augmented_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomHLS.__init__": [[212, 215], ["numpy.random.RandomState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vars", "=", "[", "15", ",", "35", ",", "25", "]", ")", ":", "\n", "        ", "self", ".", "vars", "=", "vars", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.RandomHLS.__call__": [[216, 241], ["len", "numpy.zeros", "range", "range", "range", "int", "int", "cv2.cvtColor", "numpy.minimum", "int", "cv2.cvtColor", "round", "numpy.maximum", "augmented_data[].astype", "image_transforms.RandomHLS.rng.uniform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "data", ".", "shape", "\n", "assert", "c", "%", "3", "==", "0", ",", "\"input channel = %d, illegal\"", "%", "c", "\n", "\n", "random_vars", "=", "[", "int", "(", "round", "(", "self", ".", "rng", ".", "uniform", "(", "-", "x", ",", "x", ")", ")", ")", "for", "x", "in", "self", ".", "vars", "]", "\n", "\n", "base", "=", "len", "(", "random_vars", ")", "\n", "augmented_data", "=", "np", ".", "zeros", "(", "data", ".", "shape", ",", ")", "\n", "\n", "for", "i_im", "in", "range", "(", "0", ",", "int", "(", "c", "/", "3", ")", ")", ":", "\n", "            ", "augmented_data", "[", ":", ",", ":", ",", "3", "*", "i_im", ":", "(", "3", "*", "i_im", "+", "3", ")", "]", "=", "cv2", ".", "cvtColor", "(", "data", "[", ":", ",", ":", ",", "3", "*", "i_im", ":", "(", "3", "*", "i_im", "+", "3", ")", "]", ",", "cv2", ".", "COLOR_RGB2HLS", ")", "\n", "\n", "", "hls_limits", "=", "[", "180", ",", "255", ",", "255", "]", "\n", "for", "ic", "in", "range", "(", "0", ",", "c", ")", ":", "\n", "            ", "var", "=", "random_vars", "[", "ic", "%", "base", "]", "\n", "limit", "=", "hls_limits", "[", "ic", "%", "base", "]", "\n", "augmented_data", "[", ":", ",", ":", ",", "ic", "]", "=", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "augmented_data", "[", ":", ",", ":", ",", "ic", "]", "+", "var", ",", "0", ")", ",", "limit", ")", "\n", "\n", "", "for", "i_im", "in", "range", "(", "0", ",", "int", "(", "c", "/", "3", ")", ")", ":", "\n", "            ", "augmented_data", "[", ":", ",", ":", ",", "3", "*", "i_im", ":", "(", "3", "*", "i_im", "+", "3", ")", "]", "=", "cv2", ".", "cvtColor", "(", "augmented_data", "[", ":", ",", ":", ",", "3", "*", "i_im", ":", "(", "3", "*", "i_im", "+", "3", ")", "]", ".", "astype", "(", "np", ".", "uint8", ")", ",", "cv2", ".", "COLOR_HLS2RGB", ")", "\n", "\n", "", "return", "augmented_data", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.ToTensor.__init__": [[247, 249], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dim", "=", "3", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_transforms.ToTensor.__call__": [[250, 257], ["isinstance", "torch.from_numpy", "torch.from_numpy.transpose", "torch.from_numpy.float"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "np", ".", "ndarray", ")", ":", "\n", "# H, W, C = image.shape", "\n", "# handle numpy array", "\n", "            ", "image", "=", "torch", ".", "from_numpy", "(", "image", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "# backward compatibility", "\n", "return", "image", ".", "float", "(", ")", "/", "255.0", "", "", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_sampler.RandomSampling.__init__": [[9, 15], ["numpy.random.RandomState", "type"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num", ",", "interval", "=", "1", ",", "speed", "=", "[", "1.0", ",", "1.0", "]", ",", "seed", "=", "0", ")", ":", "\n", "        ", "assert", "num", ">", "0", ",", "\"at least sampling 1 frame\"", "\n", "self", ".", "num", "=", "num", "\n", "self", ".", "interval", "=", "interval", "if", "type", "(", "interval", ")", "==", "list", "else", "[", "interval", "]", "\n", "self", ".", "speed", "=", "speed", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_sampler.RandomSampling.sampling": [[16, 32], ["ValueError", "video_sampler.RandomSampling.rng.choice", "min", "video_sampler.RandomSampling.rng.uniform", "numpy.linspace().astype().tolist", "video_sampler.RandomSampling.rng.uniform", "video_sampler.RandomSampling.rng.choice", "numpy.linspace().astype", "range", "video_sampler.RandomSampling.rng.choice", "range", "numpy.linspace"], "methods", ["None"], ["", "def", "sampling", "(", "self", ",", "range_max", ",", "v_id", "=", "None", ",", "prev_failed", "=", "False", ")", ":", "\n", "        ", "assert", "range_max", ">", "0", ",", "ValueError", "(", "\"range_max = {}\"", ".", "format", "(", "range_max", ")", ")", "\n", "interval", "=", "self", ".", "rng", ".", "choice", "(", "self", ".", "interval", ")", "\n", "if", "self", ".", "num", "==", "1", ":", "\n", "            ", "return", "[", "self", ".", "rng", ".", "choice", "(", "range", "(", "0", ",", "range_max", ")", ")", "]", "\n", "# sampling", "\n", "", "speed_min", "=", "self", ".", "speed", "[", "0", "]", "\n", "speed_max", "=", "min", "(", "self", ".", "speed", "[", "1", "]", ",", "(", "range_max", "-", "1", ")", "/", "(", "(", "self", ".", "num", "-", "1", ")", "*", "interval", ")", ")", "\n", "if", "speed_max", "<", "speed_min", ":", "\n", "            ", "return", "[", "self", ".", "rng", ".", "choice", "(", "range", "(", "0", ",", "range_max", ")", ")", "]", "*", "self", ".", "num", "\n", "", "random_interval", "=", "self", ".", "rng", ".", "uniform", "(", "speed_min", ",", "speed_max", ")", "*", "interval", "\n", "frame_range", "=", "(", "self", ".", "num", "-", "1", ")", "*", "random_interval", "\n", "clip_start", "=", "self", ".", "rng", ".", "uniform", "(", "0", ",", "(", "range_max", "-", "1", ")", "-", "frame_range", ")", "\n", "clip_end", "=", "clip_start", "+", "frame_range", "\n", "return", "np", ".", "linspace", "(", "clip_start", ",", "clip_end", ",", "self", ".", "num", ")", ".", "astype", "(", "dtype", "=", "np", ".", "int", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_sampler.SequentialSampling.__init__": [[35, 42], ["numpy.random.RandomState", "type"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num", ",", "interval", "=", "1", ",", "shuffle", "=", "False", ",", "fix_cursor", "=", "False", ",", "seed", "=", "0", ")", ":", "\n", "        ", "self", ".", "memory", "=", "{", "}", "\n", "self", ".", "num", "=", "num", "\n", "self", ".", "interval", "=", "interval", "if", "type", "(", "interval", ")", "==", "list", "else", "[", "interval", "]", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "fix_cursor", "=", "fix_cursor", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_sampler.SequentialSampling.sampling": [[43, 65], ["ValueError", "video_sampler.SequentialSampling.rng.choice", "range", "list", "len", "range", "video_sampler.SequentialSampling.rng.shuffle", "video_sampler.SequentialSampling.rng.choice", "range"], "methods", ["None"], ["", "def", "sampling", "(", "self", ",", "range_max", ",", "v_id", ",", "prev_failed", "=", "False", ")", ":", "\n", "        ", "assert", "range_max", ">", "0", ",", "ValueError", "(", "\"range_max = {}\"", ".", "format", "(", "range_max", ")", ")", "\n", "num", "=", "self", ".", "num", "\n", "interval", "=", "self", ".", "rng", ".", "choice", "(", "self", ".", "interval", ")", "\n", "frame_range", "=", "(", "num", "-", "1", ")", "*", "interval", "+", "1", "\n", "# sampling clips", "\n", "if", "v_id", "not", "in", "self", ".", "memory", ":", "\n", "            ", "clips", "=", "list", "(", "range", "(", "0", ",", "range_max", "-", "(", "frame_range", "-", "1", ")", ",", "frame_range", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "                ", "self", ".", "rng", ".", "shuffle", "(", "clips", ")", "\n", "", "self", ".", "memory", "[", "v_id", "]", "=", "[", "-", "1", ",", "clips", "]", "\n", "# pickup a clip", "\n", "", "cursor", ",", "clips", "=", "self", ".", "memory", "[", "v_id", "]", "\n", "if", "not", "clips", ":", "\n", "            ", "return", "[", "self", ".", "rng", ".", "choice", "(", "range", "(", "0", ",", "range_max", ")", ")", "]", "*", "num", "\n", "", "cursor", "=", "(", "cursor", "+", "1", ")", "%", "len", "(", "clips", ")", "\n", "if", "prev_failed", "or", "not", "self", ".", "fix_cursor", ":", "\n", "            ", "self", ".", "memory", "[", "v_id", "]", "[", "0", "]", "=", "cursor", "\n", "# sampling within clip", "\n", "", "idxs", "=", "range", "(", "clips", "[", "cursor", "]", ",", "clips", "[", "cursor", "]", "+", "frame_range", ",", "interval", ")", "\n", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_transforms.ToTensor.__init__": [[23, 25], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dim", "=", "3", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_transforms.ToTensor.__call__": [[26, 33], ["isinstance", "torch.from_numpy", "torch.from_numpy.reshape().transpose", "torch.from_numpy.float", "torch.from_numpy.reshape"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clips", ")", ":", "\n", "        ", "if", "isinstance", "(", "clips", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "H", ",", "W", ",", "_", "=", "clips", ".", "shape", "\n", "# handle numpy array", "\n", "clips", "=", "torch", ".", "from_numpy", "(", "clips", ".", "reshape", "(", "(", "H", ",", "W", ",", "-", "1", ",", "self", ".", "dim", ")", ")", ".", "transpose", "(", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "# backward compatibility", "\n", "return", "clips", ".", "float", "(", ")", "/", "255.0", "", "", "", "", ""]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__": [[14, 31], ["torch.Dataset.__init__", "image_iterator.ImageListIter._get_video_list", "logging.info", "len"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__init__", "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter._get_video_list"], ["    ", "def", "__init__", "(", "self", ",", "\n", "image_prefix", ",", "\n", "txt_list", ",", "\n", "image_transform", ",", "\n", "name", "=", "\"\"", ",", "\n", "force_color", "=", "True", ")", ":", "\n", "        ", "super", "(", "ImageListIter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# load image list", "\n", "self", ".", "image_list", "=", "self", ".", "_get_video_list", "(", "txt_list", "=", "txt_list", ")", "\n", "\n", "# load params", "\n", "self", ".", "force_color", "=", "force_color", "\n", "self", ".", "image_prefix", "=", "image_prefix", "\n", "self", ".", "image_transform", "=", "image_transform", "\n", "logging", ".", "info", "(", "\"ImageListIter ({:s}) initialized, num: {:d})\"", ".", "format", "(", "name", ",", "\n", "len", "(", "self", ".", "image_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.get_image": [[32, 49], ["os.path.join", "cv2.imread", "cv2.cvtColor", "image_iterator.ImageListIter.image_transform"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "index", ")", ":", "\n", "# get current video info", "\n", "        ", "im_id", ",", "label", ",", "img_subpath", "=", "self", ".", "image_list", "[", "index", "]", "\n", "\n", "# load image", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_prefix", ",", "img_subpath", ")", "\n", "if", "self", ".", "force_color", ":", "\n", "            ", "cv_read_flag", "=", "cv2", ".", "IMREAD_COLOR", "\n", "", "else", ":", "\n", "            ", "cv_read_flag", "=", "cv2", ".", "IMREAD_GRAYSCALE", "\n", "", "cv_img", "=", "cv2", ".", "imread", "(", "image_path", ",", "cv_read_flag", ")", "\n", "image_input", "=", "cv2", ".", "cvtColor", "(", "cv_img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "# apply image augmentation", "\n", "if", "self", ".", "image_transform", "is", "not", "None", ":", "\n", "            ", "image_input", "=", "self", ".", "image_transform", "(", "image_input", ")", "\n", "", "return", "image_input", ",", "label", ",", "img_subpath", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__getitem__": [[51, 54], ["image_iterator.ImageListIter.get_image"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.get_image"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_input", ",", "label", ",", "img_subpath", "=", "self", ".", "get_image", "(", "index", ")", "\n", "return", "image_input", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter.__len__": [[56, 58], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.image_iterator.ImageListIter._get_video_list": [[60, 77], ["os.path.exists", "logging.info", "open", "f.read().splitlines", "logging.info", "enumerate", "line.split", "image_list.append", "f.read", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.yuanli2333_Hadamard-Matrix-for-hashing.data.video_iterator.Video.open"], ["", "def", "_get_video_list", "(", "self", ",", "txt_list", ")", ":", "\n", "# formate:", "\n", "# [im_id, label, image_subpath]", "\n", "        ", "assert", "os", ".", "path", ".", "exists", "(", "txt_list", ")", ",", "\"Failed to locate: {}\"", ".", "format", "(", "txt_list", ")", "\n", "\n", "# building dataset", "\n", "logging", ".", "info", "(", "\"Building dataset ...\"", ")", "\n", "image_list", "=", "[", "]", "\n", "with", "open", "(", "txt_list", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "logging", ".", "info", "(", "\"Found {} images in '{}'\"", ".", "format", "(", "len", "(", "lines", ")", ",", "txt_list", ")", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "im_id", ",", "label", ",", "image_subpath", "=", "line", ".", "split", "(", ")", "\n", "info", "=", "[", "int", "(", "im_id", ")", ",", "int", "(", "label", ")", ",", "image_subpath", "]", "\n", "image_list", ".", "append", "(", "info", ")", "\n", "\n", "", "", "return", "image_list", "", "", "", ""]]}