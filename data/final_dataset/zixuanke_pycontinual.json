{"home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.__init__": [[186, 216], ["kwargs.pop", "collections.OrderedDict", "collections.defaultdict", "collections.defaultdict", "warnings.warn", "kwargs.pop", "TypeError", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_words", "=", "None", ",", "\n", "filters", "=", "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'", ",", "\n", "lower", "=", "True", ",", "\n", "split", "=", "' '", ",", "\n", "char_level", "=", "False", ",", "\n", "oov_token", "=", "None", ",", "\n", "analyzer", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "# Legacy support", "\n", "        ", "if", "'nb_words'", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "'The `nb_words` argument in `Tokenizer` '", "\n", "'has been renamed `num_words`.'", ")", "\n", "num_words", "=", "kwargs", ".", "pop", "(", "'nb_words'", ")", "\n", "", "document_count", "=", "kwargs", ".", "pop", "(", "'document_count'", ",", "0", ")", "\n", "if", "kwargs", ":", "\n", "            ", "raise", "TypeError", "(", "'Unrecognized keyword arguments: '", "+", "str", "(", "kwargs", ")", ")", "\n", "\n", "", "self", ".", "word_counts", "=", "OrderedDict", "(", ")", "\n", "self", ".", "word_docs", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "filters", "=", "filters", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "lower", "=", "lower", "\n", "self", ".", "num_words", "=", "num_words", "\n", "self", ".", "document_count", "=", "document_count", "\n", "self", ".", "char_level", "=", "char_level", "\n", "self", ".", "oov_token", "=", "oov_token", "\n", "self", ".", "index_docs", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "word_index", "=", "{", "}", "\n", "self", ".", "index_word", "=", "{", "}", "\n", "self", ".", "analyzer", "=", "analyzer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts": [[217, 273], ["list", "list.sort", "sorted_voc.extend", "dict", "list", "set", "w2v_util.Tokenizer.word_counts.items", "six.moves.zip", "w2v_util.Tokenizer.word_docs.items", "isinstance", "list", "w2v_util.Tokenizer.word_index.items", "isinstance", "w2v_util.text_to_word_sequence", "w2v_util.Tokenizer.analyzer", "six.moves.range", "text.lower.lower.lower", "text_elem.lower", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.text_to_word_sequence"], ["", "def", "fit_on_texts", "(", "self", ",", "texts", ")", ":", "\n", "        ", "\"\"\"Updates internal vocabulary based on a list of texts.\n\n        In the case where texts contains lists,\n        we assume each entry of the lists to be a token.\n\n        Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n        # Arguments\n            texts: can be a list of strings,\n                a generator of strings (for memory-efficiency),\n                or a list of list of strings.\n        \"\"\"", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "self", ".", "document_count", "+=", "1", "\n", "if", "self", ".", "char_level", "or", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                ", "if", "self", ".", "lower", ":", "\n", "                    ", "if", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                        ", "text", "=", "[", "text_elem", ".", "lower", "(", ")", "for", "text_elem", "in", "text", "]", "\n", "", "else", ":", "\n", "                        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "", "seq", "=", "text", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "analyzer", "is", "None", ":", "\n", "                    ", "seq", "=", "text_to_word_sequence", "(", "text", ",", "\n", "filters", "=", "self", ".", "filters", ",", "\n", "lower", "=", "self", ".", "lower", ",", "\n", "split", "=", "self", ".", "split", ")", "\n", "", "else", ":", "\n", "                    ", "seq", "=", "self", ".", "analyzer", "(", "text", ")", "\n", "", "", "for", "w", "in", "seq", ":", "\n", "                ", "if", "w", "in", "self", ".", "word_counts", ":", "\n", "                    ", "self", ".", "word_counts", "[", "w", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "self", ".", "word_counts", "[", "w", "]", "=", "1", "\n", "", "", "for", "w", "in", "set", "(", "seq", ")", ":", "\n", "# In how many documents each word occurs", "\n", "                ", "self", ".", "word_docs", "[", "w", "]", "+=", "1", "\n", "\n", "", "", "wcounts", "=", "list", "(", "self", ".", "word_counts", ".", "items", "(", ")", ")", "\n", "wcounts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "# forcing the oov_token to index 1 if it exists", "\n", "if", "self", ".", "oov_token", "is", "None", ":", "\n", "            ", "sorted_voc", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "sorted_voc", "=", "[", "self", ".", "oov_token", "]", "\n", "", "sorted_voc", ".", "extend", "(", "wc", "[", "0", "]", "for", "wc", "in", "wcounts", ")", "\n", "\n", "# note that index 0 is reserved, never assigned to an existing word", "\n", "self", ".", "word_index", "=", "dict", "(", "\n", "zip", "(", "sorted_voc", ",", "list", "(", "range", "(", "1", ",", "len", "(", "sorted_voc", ")", "+", "1", ")", ")", ")", ")", "\n", "\n", "self", ".", "index_word", "=", "{", "c", ":", "w", "for", "w", ",", "c", "in", "self", ".", "word_index", ".", "items", "(", ")", "}", "\n", "\n", "for", "w", ",", "c", "in", "list", "(", "self", ".", "word_docs", ".", "items", "(", ")", ")", ":", "\n", "            ", "self", ".", "index_docs", "[", "self", ".", "word_index", "[", "w", "]", "]", "=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_sequences": [[274, 289], ["len", "set"], "methods", ["None"], ["", "", "def", "fit_on_sequences", "(", "self", ",", "sequences", ")", ":", "\n", "        ", "\"\"\"Updates internal vocabulary based on a list of sequences.\n\n        Required before using `sequences_to_matrix`\n        (if `fit_on_texts` was never called).\n\n        # Arguments\n            sequences: A list of sequence.\n                A \"sequence\" is a list of integer word indices.\n        \"\"\"", "\n", "self", ".", "document_count", "+=", "len", "(", "sequences", ")", "\n", "for", "seq", "in", "sequences", ":", "\n", "            ", "seq", "=", "set", "(", "seq", ")", "\n", "for", "i", "in", "seq", ":", "\n", "                ", "self", ".", "index_docs", "[", "i", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences": [[290, 303], ["list", "w2v_util.Tokenizer.texts_to_sequences_generator"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences_generator"], ["", "", "", "def", "texts_to_sequences", "(", "self", ",", "texts", ")", ":", "\n", "        ", "\"\"\"Transforms each text in texts to a sequence of integers.\n\n        Only top `num_words-1` most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Returns\n            A list of sequences.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "texts_to_sequences_generator", "(", "texts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences_generator": [[304, 349], ["w2v_util.Tokenizer.word_index.get", "isinstance", "w2v_util.Tokenizer.word_index.get", "isinstance", "w2v_util.text_to_word_sequence", "w2v_util.Tokenizer.analyzer", "text.lower.lower.lower", "vect.append", "vect.append", "text_elem.lower", "vect.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.text_to_word_sequence"], ["", "def", "texts_to_sequences_generator", "(", "self", ",", "texts", ")", ":", "\n", "        ", "\"\"\"Transforms each text in `texts` to a sequence of integers.\n\n        Each item in texts can also be a list,\n        in which case we assume each item of that list to be a token.\n\n        Only top `num_words-1` most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Yields\n            Yields individual sequences.\n        \"\"\"", "\n", "num_words", "=", "self", ".", "num_words", "\n", "oov_token_index", "=", "self", ".", "word_index", ".", "get", "(", "self", ".", "oov_token", ")", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "if", "self", ".", "char_level", "or", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                ", "if", "self", ".", "lower", ":", "\n", "                    ", "if", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                        ", "text", "=", "[", "text_elem", ".", "lower", "(", ")", "for", "text_elem", "in", "text", "]", "\n", "", "else", ":", "\n", "                        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "", "seq", "=", "text", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "analyzer", "is", "None", ":", "\n", "                    ", "seq", "=", "text_to_word_sequence", "(", "text", ",", "\n", "filters", "=", "self", ".", "filters", ",", "\n", "lower", "=", "self", ".", "lower", ",", "\n", "split", "=", "self", ".", "split", ")", "\n", "", "else", ":", "\n", "                    ", "seq", "=", "self", ".", "analyzer", "(", "text", ")", "\n", "", "", "vect", "=", "[", "]", "\n", "for", "w", "in", "seq", ":", "\n", "                ", "i", "=", "self", ".", "word_index", ".", "get", "(", "w", ")", "\n", "if", "i", "is", "not", "None", ":", "\n", "                    ", "if", "num_words", "and", "i", ">=", "num_words", ":", "\n", "                        ", "if", "oov_token_index", "is", "not", "None", ":", "\n", "                            ", "vect", ".", "append", "(", "oov_token_index", ")", "\n", "", "", "else", ":", "\n", "                        ", "vect", ".", "append", "(", "i", ")", "\n", "", "", "elif", "self", ".", "oov_token", "is", "not", "None", ":", "\n", "                    ", "vect", ".", "append", "(", "oov_token_index", ")", "\n", "", "", "yield", "vect", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.sequences_to_texts": [[350, 363], ["list", "w2v_util.Tokenizer.sequences_to_texts_generator"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.sequences_to_texts_generator"], ["", "", "def", "sequences_to_texts", "(", "self", ",", "sequences", ")", ":", "\n", "        ", "\"\"\"Transforms each sequence into a list of text.\n\n        Only top `num_words-1` most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            sequences: A list of sequences (list of integers).\n\n        # Returns\n            A list of texts (strings)\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "sequences_to_texts_generator", "(", "sequences", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.sequences_to_texts_generator": [[364, 395], ["w2v_util.Tokenizer.word_index.get", "w2v_util.Tokenizer.index_word.get", "vect.append", "vect.append", "vect.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get"], ["", "def", "sequences_to_texts_generator", "(", "self", ",", "sequences", ")", ":", "\n", "        ", "\"\"\"Transforms each sequence in `sequences` to a list of texts(strings).\n\n        Each sequence has to a list of integers.\n        In other words, sequences should be a list of sequences\n\n        Only top `num_words-1` most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            sequences: A list of sequences.\n\n        # Yields\n            Yields individual texts.\n        \"\"\"", "\n", "num_words", "=", "self", ".", "num_words", "\n", "oov_token_index", "=", "self", ".", "word_index", ".", "get", "(", "self", ".", "oov_token", ")", "\n", "for", "seq", "in", "sequences", ":", "\n", "            ", "vect", "=", "[", "]", "\n", "for", "num", "in", "seq", ":", "\n", "                ", "word", "=", "self", ".", "index_word", ".", "get", "(", "num", ")", "\n", "if", "word", "is", "not", "None", ":", "\n", "                    ", "if", "num_words", "and", "num", ">=", "num_words", ":", "\n", "                        ", "if", "oov_token_index", "is", "not", "None", ":", "\n", "                            ", "vect", ".", "append", "(", "self", ".", "index_word", "[", "oov_token_index", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "vect", ".", "append", "(", "word", ")", "\n", "", "", "elif", "self", ".", "oov_token", "is", "not", "None", ":", "\n", "                    ", "vect", ".", "append", "(", "self", ".", "index_word", "[", "oov_token_index", "]", ")", "\n", "", "", "vect", "=", "' '", ".", "join", "(", "vect", ")", "\n", "yield", "vect", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_matrix": [[396, 408], ["w2v_util.Tokenizer.texts_to_sequences", "w2v_util.Tokenizer.sequences_to_matrix"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.sequences_to_matrix"], ["", "", "def", "texts_to_matrix", "(", "self", ",", "texts", ",", "mode", "=", "'binary'", ")", ":", "\n", "        ", "\"\"\"Convert a list of texts to a Numpy matrix.\n\n        # Arguments\n            texts: list of strings.\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n\n        # Returns\n            A Numpy matrix.\n        \"\"\"", "\n", "sequences", "=", "self", ".", "texts_to_sequences", "(", "texts", ")", "\n", "return", "self", ".", "sequences_to_matrix", "(", "sequences", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.sequences_to_matrix": [[409, 463], ["numpy.zeros", "numpy.zeros", "enumerate", "ValueError", "collections.defaultdict", "list", "ValueError", "len", "collections.defaultdict.items", "len", "len", "numpy.log", "numpy.log", "ValueError", "numpy.log", "numpy.log", "w2v_util.Tokenizer.index_docs.get"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get"], ["", "def", "sequences_to_matrix", "(", "self", ",", "sequences", ",", "mode", "=", "'binary'", ")", ":", "\n", "        ", "\"\"\"Converts a list of sequences into a Numpy matrix.\n\n        # Arguments\n            sequences: list of sequences\n                (a sequence is a list of integer word indices).\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n\n        # Returns\n            A Numpy matrix.\n\n        # Raises\n            ValueError: In case of invalid `mode` argument,\n                or if the Tokenizer requires to be fit to sample data.\n        \"\"\"", "\n", "if", "not", "self", ".", "num_words", ":", "\n", "            ", "if", "self", ".", "word_index", ":", "\n", "                ", "num_words", "=", "len", "(", "self", ".", "word_index", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Specify a dimension (`num_words` argument), '", "\n", "'or fit on some text data first.'", ")", "\n", "", "", "else", ":", "\n", "            ", "num_words", "=", "self", ".", "num_words", "\n", "\n", "", "if", "mode", "==", "'tfidf'", "and", "not", "self", ".", "document_count", ":", "\n", "            ", "raise", "ValueError", "(", "'Fit the Tokenizer on some data '", "\n", "'before using tfidf mode.'", ")", "\n", "\n", "", "x", "=", "np", ".", "zeros", "(", "(", "len", "(", "sequences", ")", ",", "num_words", ")", ")", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "            ", "if", "not", "seq", ":", "\n", "                ", "continue", "\n", "", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "j", "in", "seq", ":", "\n", "                ", "if", "j", ">=", "num_words", ":", "\n", "                    ", "continue", "\n", "", "counts", "[", "j", "]", "+=", "1", "\n", "", "for", "j", ",", "c", "in", "list", "(", "counts", ".", "items", "(", ")", ")", ":", "\n", "                ", "if", "mode", "==", "'count'", ":", "\n", "                    ", "x", "[", "i", "]", "[", "j", "]", "=", "c", "\n", "", "elif", "mode", "==", "'freq'", ":", "\n", "                    ", "x", "[", "i", "]", "[", "j", "]", "=", "c", "/", "len", "(", "seq", ")", "\n", "", "elif", "mode", "==", "'binary'", ":", "\n", "                    ", "x", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "", "elif", "mode", "==", "'tfidf'", ":", "\n", "# Use weighting scheme 2 in", "\n", "# https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "\n", "                    ", "tf", "=", "1", "+", "np", ".", "log", "(", "c", ")", "\n", "idf", "=", "np", ".", "log", "(", "1", "+", "self", ".", "document_count", "/", "\n", "(", "1", "+", "self", ".", "index_docs", ".", "get", "(", "j", ",", "0", ")", ")", ")", "\n", "x", "[", "i", "]", "[", "j", "]", "=", "tf", "*", "idf", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "'Unknown vectorization mode:'", ",", "mode", ")", "\n", "", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.get_config": [[464, 492], ["json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "'''Returns the tokenizer configuration as Python dictionary.\n        The word count dictionaries used by the tokenizer get serialized\n        into plain JSON, so that the configuration can be read by other\n        projects.\n\n        # Returns\n            A Python dictionary with the tokenizer configuration.\n        '''", "\n", "json_word_counts", "=", "json", ".", "dumps", "(", "self", ".", "word_counts", ")", "\n", "json_word_docs", "=", "json", ".", "dumps", "(", "self", ".", "word_docs", ")", "\n", "json_index_docs", "=", "json", ".", "dumps", "(", "self", ".", "index_docs", ")", "\n", "json_word_index", "=", "json", ".", "dumps", "(", "self", ".", "word_index", ")", "\n", "json_index_word", "=", "json", ".", "dumps", "(", "self", ".", "index_word", ")", "\n", "\n", "return", "{", "\n", "'num_words'", ":", "self", ".", "num_words", ",", "\n", "'filters'", ":", "self", ".", "filters", ",", "\n", "'lower'", ":", "self", ".", "lower", ",", "\n", "'split'", ":", "self", ".", "split", ",", "\n", "'char_level'", ":", "self", ".", "char_level", ",", "\n", "'oov_token'", ":", "self", ".", "oov_token", ",", "\n", "'document_count'", ":", "self", ".", "document_count", ",", "\n", "'word_counts'", ":", "json_word_counts", ",", "\n", "'word_docs'", ":", "json_word_docs", ",", "\n", "'index_docs'", ":", "json_index_docs", ",", "\n", "'index_word'", ":", "json_index_word", ",", "\n", "'word_index'", ":", "json_word_index", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.to_json": [[494, 512], ["w2v_util.Tokenizer.get_config", "json.dumps", "json.dumps", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.get_config"], ["", "def", "to_json", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Returns a JSON string containing the tokenizer configuration.\n        To load a tokenizer from a JSON string, use\n        `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `json.dumps()`.\n\n        # Returns\n            A JSON string containing the tokenizer configuration.\n        \"\"\"", "\n", "config", "=", "self", ".", "get_config", "(", ")", "\n", "tokenizer_config", "=", "{", "\n", "'class_name'", ":", "self", ".", "__class__", ".", "__name__", ",", "\n", "'config'", ":", "config", "\n", "}", "\n", "return", "json", ".", "dumps", "(", "tokenizer_config", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.text_to_word_sequence": [[31, 69], ["text.replace.split", "text.replace.lower", "isinstance", "maketrans", "text.replace.translate", "text.replace.translate", "ord", "unicode", "len", "maketrans", "text.replace.translate", "text.replace.replace", "len"], "function", ["None"], ["", "def", "text_to_word_sequence", "(", "text", ",", "\n", "filters", "=", "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'", ",", "\n", "lower", "=", "True", ",", "split", "=", "\" \"", ")", ":", "\n", "    ", "\"\"\"Converts a text to a sequence of words (or tokens).\n\n    # Arguments\n        text: Input text (string).\n        filters: list (or concatenation) of characters to filter out, such as\n            punctuation. Default: ``!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n``,\n            includes basic punctuation, tabs, and newlines.\n        lower: boolean. Whether to convert the input to lowercase.\n        split: str. Separator for word splitting.\n\n    # Returns\n        A list of words (or tokens).\n    \"\"\"", "\n", "if", "lower", ":", "\n", "        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "", "if", "sys", ".", "version_info", "<", "(", "3", ",", ")", ":", "\n", "        ", "if", "isinstance", "(", "text", ",", "unicode", ")", ":", "# noqa: F821", "\n", "            ", "translate_map", "=", "{", "\n", "ord", "(", "c", ")", ":", "unicode", "(", "split", ")", "for", "c", "in", "filters", "# noqa: F821", "\n", "}", "\n", "text", "=", "text", ".", "translate", "(", "translate_map", ")", "\n", "", "elif", "len", "(", "split", ")", "==", "1", ":", "\n", "            ", "translate_map", "=", "maketrans", "(", "filters", ",", "split", "*", "len", "(", "filters", ")", ")", "\n", "text", "=", "text", ".", "translate", "(", "translate_map", ")", "\n", "", "else", ":", "\n", "            ", "for", "c", "in", "filters", ":", "\n", "                ", "text", "=", "text", ".", "replace", "(", "c", ",", "split", ")", "\n", "", "", "", "else", ":", "\n", "        ", "translate_dict", "=", "{", "c", ":", "split", "for", "c", "in", "filters", "}", "\n", "translate_map", "=", "maketrans", "(", "translate_dict", ")", "\n", "text", "=", "text", ".", "translate", "(", "translate_map", ")", "\n", "\n", "", "seq", "=", "text", ".", "split", "(", "split", ")", "\n", "return", "[", "i", "for", "i", "in", "seq", "if", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.one_hot": [[71, 101], ["w2v_util.hashing_trick"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.hashing_trick"], ["", "def", "one_hot", "(", "text", ",", "n", ",", "\n", "filters", "=", "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'", ",", "\n", "lower", "=", "True", ",", "\n", "split", "=", "' '", ",", "\n", "analyzer", "=", "None", ")", ":", "\n", "    ", "\"\"\"One-hot encodes a text into a list of word indexes of size n.\n\n    This is a wrapper to the `hashing_trick` function using `hash` as the\n    hashing function; unicity of word to index mapping non-guaranteed.\n\n    # Arguments\n        text: Input text (string).\n        n: int. Size of vocabulary.\n        filters: list (or concatenation) of characters to filter out, such as\n            punctuation. Default: ``!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n``,\n            includes basic punctuation, tabs, and newlines.\n        lower: boolean. Whether to set the text to lowercase.\n        split: str. Separator for word splitting.\n        analyzer: function. Custom analyzer to split the text\n\n    # Returns\n        List of integers in [1, n]. Each integer encodes a word\n        (unicity non-guaranteed).\n    \"\"\"", "\n", "return", "hashing_trick", "(", "text", ",", "n", ",", "\n", "hash_function", "=", "hash", ",", "\n", "filters", "=", "filters", ",", "\n", "lower", "=", "lower", ",", "\n", "split", "=", "split", ",", "\n", "analyzer", "=", "analyzer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.hashing_trick": [[103, 153], ["w2v_util.text_to_word_sequence", "analyzer", "int", "w2v_util.hashing_trick.hash_function"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.text_to_word_sequence"], ["", "def", "hashing_trick", "(", "text", ",", "n", ",", "\n", "hash_function", "=", "None", ",", "\n", "filters", "=", "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'", ",", "\n", "lower", "=", "True", ",", "\n", "split", "=", "' '", ",", "\n", "analyzer", "=", "None", ")", ":", "\n", "    ", "\"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        hash_function: defaults to python `hash` function, can be 'md5' or\n            any function that takes in input a string and returns a int.\n            Note that 'hash' is not a stable hashing function, so\n            it is not consistent across different runs, while 'md5'\n            is a stable hashing function.\n        filters: list (or concatenation) of characters to filter out, such as\n            punctuation. Default: ``!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n``,\n            includes basic punctuation, tabs, and newlines.\n        lower: boolean. Whether to set the text to lowercase.\n        split: str. Separator for word splitting.\n        analyzer: function. Custom analyzer to split the text\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n\n    `0` is a reserved index that won't be assigned to any word.\n\n    Two or more words may be assigned to the same index, due to possible\n    collisions by the hashing function.\n    The [probability](\n        https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)\n    of a collision is in relation to the dimension of the hashing space and\n    the number of distinct objects.\n    \"\"\"", "\n", "if", "hash_function", "is", "None", ":", "\n", "        ", "hash_function", "=", "hash", "\n", "", "elif", "hash_function", "==", "'md5'", ":", "\n", "        ", "def", "hash_function", "(", "w", ")", ":", "\n", "            ", "return", "int", "(", "md5", "(", "w", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", ",", "16", ")", "\n", "\n", "", "", "if", "analyzer", "is", "None", ":", "\n", "        ", "seq", "=", "text_to_word_sequence", "(", "text", ",", "\n", "filters", "=", "filters", ",", "\n", "lower", "=", "lower", ",", "\n", "split", "=", "split", ")", "\n", "", "else", ":", "\n", "        ", "seq", "=", "analyzer", "(", "text", ")", "\n", "\n", "", "return", "[", "(", "hash_function", "(", "w", ")", "%", "(", "n", "-", "1", ")", "+", "1", ")", "for", "w", "in", "seq", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.tokenizer_from_json": [[514, 544], ["json.loads", "json.loads", "json.loads.get", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "json.loads", "w2v_util.Tokenizer", "tokenizer_config.get.pop", "tokenizer_config.get.pop", "tokenizer_config.get.pop", "int", "tokenizer_config.get.pop", "int", "tokenizer_config.get.pop", "json.loads.items", "json.loads.items"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get"], ["", "", "def", "tokenizer_from_json", "(", "json_string", ")", ":", "\n", "    ", "\"\"\"Parses a JSON tokenizer configuration file and returns a\n    tokenizer instance.\n\n    # Arguments\n        json_string: JSON string encoding a tokenizer configuration.\n\n    # Returns\n        A Keras Tokenizer instance\n    \"\"\"", "\n", "tokenizer_config", "=", "json", ".", "loads", "(", "json_string", ")", "\n", "config", "=", "tokenizer_config", ".", "get", "(", "'config'", ")", "\n", "\n", "word_counts", "=", "json", ".", "loads", "(", "config", ".", "pop", "(", "'word_counts'", ")", ")", "\n", "word_docs", "=", "json", ".", "loads", "(", "config", ".", "pop", "(", "'word_docs'", ")", ")", "\n", "index_docs", "=", "json", ".", "loads", "(", "config", ".", "pop", "(", "'index_docs'", ")", ")", "\n", "# Integer indexing gets converted to strings with json.dumps()", "\n", "index_docs", "=", "{", "int", "(", "k", ")", ":", "v", "for", "k", ",", "v", "in", "index_docs", ".", "items", "(", ")", "}", "\n", "index_word", "=", "json", ".", "loads", "(", "config", ".", "pop", "(", "'index_word'", ")", ")", "\n", "index_word", "=", "{", "int", "(", "k", ")", ":", "v", "for", "k", ",", "v", "in", "index_word", ".", "items", "(", ")", "}", "\n", "word_index", "=", "json", ".", "loads", "(", "config", ".", "pop", "(", "'word_index'", ")", ")", "\n", "\n", "tokenizer", "=", "Tokenizer", "(", "**", "config", ")", "\n", "tokenizer", ".", "word_counts", "=", "word_counts", "\n", "tokenizer", ".", "word_docs", "=", "word_docs", "\n", "tokenizer", ".", "index_docs", "=", "index_docs", "\n", "tokenizer", ".", "word_index", "=", "word_index", "\n", "tokenizer", ".", "index_word", "=", "index_word", "\n", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences": [[545, 634], ["len", "numpy.full", "enumerate", "hasattr", "ValueError", "numpy.max", "numpy.issubdtype", "numpy.issubdtype", "isinstance", "ValueError", "numpy.asarray", "lengths.append", "len", "ValueError", "len", "len", "ValueError", "type", "ValueError", "ValueError", "numpy.asarray", "str", "len", "len"], "function", ["None"], ["", "def", "pad_sequences", "(", "sequences", ",", "maxlen", "=", "None", ",", "dtype", "=", "'int32'", ",", "\n", "padding", "=", "'pre'", ",", "truncating", "=", "'pre'", ",", "value", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Pads sequences to the same length.\n    This function transforms a list of\n    `num_samples` sequences (lists of integers)\n    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n    `num_timesteps` is either the `maxlen` argument if provided,\n    or the length of the longest sequence otherwise.\n    Sequences that are shorter than `num_timesteps`\n    are padded with `value` at the beginning or the end\n    if padding='post.\n    Sequences longer than `num_timesteps` are truncated\n    so that they fit the desired length.\n    The position where padding or truncation happens is determined by\n    the arguments `padding` and `truncating`, respectively.\n    Pre-padding is the default.\n    # Arguments\n        sequences: List of lists, where each element is a sequence.\n        maxlen: Int, maximum length of all sequences.\n        dtype: Type of the output sequences.\n            To pad sequences with variable length strings, you can use `object`.\n        padding: String, 'pre' or 'post':\n            pad either before or after each sequence.\n        truncating: String, 'pre' or 'post':\n            remove values from sequences larger than\n            `maxlen`, either at the beginning or at the end of the sequences.\n        value: Float or String, padding value.\n    # Returns\n        x: Numpy array with shape `(len(sequences), maxlen)`\n    # Raises\n        ValueError: In case of invalid values for `truncating` or `padding`,\n            or in case of invalid shape for a `sequences` entry.\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "sequences", ",", "'__len__'", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'`sequences` must be iterable.'", ")", "\n", "", "num_samples", "=", "len", "(", "sequences", ")", "\n", "\n", "lengths", "=", "[", "]", "\n", "sample_shape", "=", "(", ")", "\n", "flag", "=", "True", "\n", "\n", "# take the sample shape from the first non empty sequence", "\n", "# checking for consistency in the main loop below.", "\n", "\n", "for", "x", "in", "sequences", ":", "\n", "        ", "try", ":", "\n", "            ", "lengths", ".", "append", "(", "len", "(", "x", ")", ")", "\n", "if", "flag", "and", "len", "(", "x", ")", ":", "\n", "                ", "sample_shape", "=", "np", ".", "asarray", "(", "x", ")", ".", "shape", "[", "1", ":", "]", "\n", "flag", "=", "False", "\n", "", "", "except", "TypeError", ":", "\n", "            ", "raise", "ValueError", "(", "'`sequences` must be a list of iterables. '", "\n", "'Found non-iterable: '", "+", "str", "(", "x", ")", ")", "\n", "\n", "", "", "if", "maxlen", "is", "None", ":", "\n", "        ", "maxlen", "=", "np", ".", "max", "(", "lengths", ")", "\n", "\n", "", "is_dtype_str", "=", "np", ".", "issubdtype", "(", "dtype", ",", "np", ".", "str_", ")", "or", "np", ".", "issubdtype", "(", "dtype", ",", "np", ".", "unicode_", ")", "\n", "if", "isinstance", "(", "value", ",", "six", ".", "string_types", ")", "and", "dtype", "!=", "object", "and", "not", "is_dtype_str", ":", "\n", "        ", "raise", "ValueError", "(", "\"`dtype` {} is not compatible with `value`'s type: {}\\n\"", "\n", "\"You should set `dtype=object` for variable length strings.\"", "\n", ".", "format", "(", "dtype", ",", "type", "(", "value", ")", ")", ")", "\n", "\n", "", "x", "=", "np", ".", "full", "(", "(", "num_samples", ",", "maxlen", ")", "+", "sample_shape", ",", "value", ",", "dtype", "=", "dtype", ")", "\n", "for", "idx", ",", "s", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "if", "not", "len", "(", "s", ")", ":", "\n", "            ", "continue", "# empty list/array was found", "\n", "", "if", "truncating", "==", "'pre'", ":", "\n", "            ", "trunc", "=", "s", "[", "-", "maxlen", ":", "]", "\n", "", "elif", "truncating", "==", "'post'", ":", "\n", "            ", "trunc", "=", "s", "[", ":", "maxlen", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Truncating type \"%s\" '", "\n", "'not understood'", "%", "truncating", ")", "\n", "\n", "# check `trunc` has expected shape", "\n", "", "trunc", "=", "np", ".", "asarray", "(", "trunc", ",", "dtype", "=", "dtype", ")", "\n", "if", "trunc", ".", "shape", "[", "1", ":", "]", "!=", "sample_shape", ":", "\n", "            ", "raise", "ValueError", "(", "'Shape of sample %s of sequence at position %s '", "\n", "'is different from expected shape %s'", "%", "\n", "(", "trunc", ".", "shape", "[", "1", ":", "]", ",", "idx", ",", "sample_shape", ")", ")", "\n", "\n", "", "if", "padding", "==", "'post'", ":", "\n", "            ", "x", "[", "idx", ",", ":", "len", "(", "trunc", ")", "]", "=", "trunc", "\n", "", "elif", "padding", "==", "'pre'", ":", "\n", "            ", "x", "[", "idx", ",", "-", "len", "(", "trunc", ")", ":", "]", "=", "trunc", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Padding type \"%s\" not understood'", "%", "padding", ")", "\n", "", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.preparation.resume_checkpoint": [[86, 105], ["torch.load", "net.load_state_dict", "logger.info", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "resume_checkpoint", "(", "appr", ",", "net", ")", ":", "\n", "    ", "if", "args", ".", "resume_model", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", ")", "\n", "net", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "logger", ".", "info", "(", "'resume_from_file: '", "+", "str", "(", "args", ".", "resume_from_file", ")", ")", "\n", "\n", "\n", "", "if", "args", ".", "resume_model", ":", "\n", "        ", "if", "hasattr", "(", "appr", ",", "'mask_pre'", ")", ":", "appr", ".", "mask_pre", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_mask_pre'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'mask_back'", ")", ":", "appr", ".", "mask_back", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_mask_back'", ")", "\n", "\n", "#for GEM", "\n", "if", "hasattr", "(", "appr", ",", "'buffer'", ")", ":", "appr", ".", "buffer", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_buffer'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'grad_dims'", ")", ":", "appr", ".", "grad_dims", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_grad_dims'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'grads_cs'", ")", ":", "appr", ".", "grads_cs", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_grads_cs'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'grads_da'", ")", ":", "appr", ".", "grads_da", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_grads_da'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'history_mask_pre'", ")", ":", "appr", ".", "history_mask_pre", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_history_mask_pre'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'similarities'", ")", ":", "appr", ".", "similarities", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_similarities'", ")", "# not in state_dict", "\n", "if", "hasattr", "(", "appr", ",", "'check_federated'", ")", ":", "appr", ".", "check_federated", "=", "torch", ".", "load", "(", "args", ".", "resume_from_file", "+", "'_check_federated'", ")", "# not in state_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.asc_config": [[15, 196], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "asc_config", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'--backbone'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'chose the backbone model'", ",", "\n", "choices", "=", "[", "'bert'", ",", "'bert_frozen'", ",", "'bert_adapter'", ",", "'w2v_as'", ",", "'w2v'", ",", "'cnn'", ",", "'mlp'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--baseline'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'chose the baseline model'", ",", "\n", "choices", "=", "[", "'ncl'", ",", "'one'", ",", "'mtl'", ",", "'l2'", ",", "'a-gem'", ",", "'derpp'", ",", "'kan'", ",", "'srk'", ",", "'ewc'", ",", "'hal'", ",", "'ucl'", ",", "'owm'", ",", "'acl'", ",", "'hat'", ",", "'cat'", ",", "'b-cl'", ",", "'classic'", ",", "'ctr'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "'what datasets'", ",", "\n", "choices", "=", "[", "'asc'", ",", "'dsc'", ",", "'ssc'", ",", "'nli'", ",", "'newsgroup'", ",", "'celeba'", ",", "'femnist'", ",", "'vlcs'", ",", "'cifar10'", ",", "'mnist'", ",", "'fashionmnist'", ",", "'cifar100'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--scenario'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "'what senario it will be'", ",", "\n", "choices", "=", "[", "'til_classification '", ",", "'dil_classification'", "]", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--note'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nclasses'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ntasks'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ntasks_unseen'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--idrandom'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_patience'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "0.05", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_factor'", ",", "default", "=", "3", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_gap'", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_min'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--thres_cosh'", ",", "default", "=", "50", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--thres_emb'", ",", "default", "=", "6", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--clipgrad'", ",", "default", "=", "10000", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lamb'", ",", "default", "=", "5000", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--sbatch'", ",", "default", "=", "64", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_mask_adapter_size'", ",", "default", "=", "2000", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_adapter_size'", ",", "default", "=", "2000", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--mlp_adapter_size'", ",", "default", "=", "2000", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--semantic_cap_size'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_semantic_cap'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--mid_size'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--experiment_id'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--use_predefine_args'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--temp'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'temperature for loss function'", ")", "\n", "parser", ".", "add_argument", "(", "'--base_temp'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'temperature for loss function'", ")", "\n", "parser", ".", "add_argument", "(", "'--buffer_percent'", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'The size of the memory buffer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--buffer_size'", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'The size of the memory buffer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi_gpu'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup_loss'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--distill_loss'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--my_contrast'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--trans_loss'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--true_id'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--larger_as_list'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_model'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--head_ewc'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--head_robust'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_twice'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--augment_current'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--augment_distill'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--augment_trans'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--ngpus'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_from_task'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_from_file'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_gate_in_ouput'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--two_stage'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_pooled_rep'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--pooled_rep_contrast'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--task_gate_in_ouput'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtl'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--overlap_only'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_model'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_each_step'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_each_step'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--known_id'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--first_id'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--last_id'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use last ID as the ID for testing, useful in DIL setting'", ")", "\n", "parser", ".", "add_argument", "(", "'--ent_id'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use entropy to decide ID, useful in DIL setting'", ")", "\n", "parser", ".", "add_argument", "(", "'--entropy_loss'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--share_conv'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--distributed'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter_ucl'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter_owm'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter_mask'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter_capsule_mask'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--build_adapter_capsule'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_bert_output'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_bert_attention_output'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_one_layer_shared'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_two_layer_shared'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--transfer_layer_incremental'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--transfer_layer_all'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--task_mask'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_tsv_mask'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--tsv_mask_type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation'", ",", "type", "=", "float", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_steps'", ",", "type", "=", "float", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "float", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'--xusemeval_num_train_epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--bingdomains_num_train_epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--bingdomains_num_train_epochs_multiplier'", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--w2v_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--capsule_nhid'", ",", "type", "=", "int", ",", "default", "=", "2000", ")", "\n", "parser", ".", "add_argument", "(", "'--capsule_nhid_output'", ",", "type", "=", "int", ",", "default", "=", "768", ")", "\n", "parser", ".", "add_argument", "(", "'--cut_partition'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--exp'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "'sgd'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_checkpoint'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--l2_norm'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--larger_as_share'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_head'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup_head'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--distill_head'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--amix_head'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--current_head'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--transfer_route'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_capsule'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--srk_train_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--class_per_task'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--use_imp'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_gelu'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_only'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_size'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--image_size'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--image_channel'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data_size'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data_size_ontonote'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data_size'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data_size'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_kernel_size'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--skipgram_prb'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'prob of ngram mask'", ")", "\n", "parser", ".", "add_argument", "(", "'--skipgram_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'the max size of ngram mask'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_source_words'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to mask source words for training\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_whole_word'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether masking a whole word.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_pred'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"Max tokens of prediction.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_prob\"", ",", "default", "=", "0.15", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Number of prediction is sometimes less than max_pred when sequence is short.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ffn_type'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"0: default mlp; 1: W((Wx+b) elem_prod x);\"", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Beam size for searching\"", ")", "\n", "parser", ".", "add_argument", "(", "'--length_penalty'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Length penalty for beam search\"", ")", "\n", "parser", ".", "add_argument", "(", "'--not_predict_token'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Do not predict the tokens during decoding.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--forbid_ignore_word'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Ignore the word during forbid_duplicate_ngrams\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ngram_size'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--forbid_duplicate_ngrams'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_len\"", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--seg_emb'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Using segment embedding for self-attention.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_shift'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Using position shift for fine-tuning.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warm_train\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.train_config": [[197, 281], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "train_config", "(", "parser", ")", ":", "\n", "## Other parameters", "\n", "\n", "    ", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "default", "=", "'bert-base-uncased'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_hidden_size\"", ",", "default", "=", "768", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_num_hidden_layers\"", ",", "default", "=", "12", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dropout_prob\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Dropout rate for hidden states.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_term_length\"", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sentence_length\"", ",", "\n", "default", "=", "123", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for eval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "\n", "default", "=", "6", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10%% of training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "# attention", "\n", "parser", ".", "add_argument", "(", "'--deep_att_lexicon_input_on'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "64", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_sim_func'", ",", "type", "=", "str", ",", "default", "=", "'dotproductproject'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_activation'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_norm_on'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_proj_on'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_residual_on'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_share'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--deep_att_opt'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "# self attn", "\n", "parser", ".", "add_argument", "(", "'--self_attention_on'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "64", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_sim_func'", ",", "type", "=", "str", ",", "default", "=", "'dotproductproject'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_activation'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_norm_on'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_proj_on'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_residual_on'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_drop_diagonal'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_att_share'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--vb_dropout'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout_p'", ",", "type", "=", "float", ",", "default", "=", "0.4", ")", "\n", "# query summary", "\n", "parser", ".", "add_argument", "(", "'--unseen'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--down_sample_ratio'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.ucl_config": [[285, 308], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "ucl_config", "(", "parser", ")", ":", "\n", "# Arguments", "\n", "    ", "parser", ".", "add_argument", "(", "'--ablation'", ",", "default", "=", "'None'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "choices", "=", "[", "'no_L1'", ",", "\n", "'no_upper'", ",", "\n", "'no_lower'", ",", "\n", "'no_sigma_normal'", ",", "\n", "'None'", "]", ",", "\n", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--unitN'", ",", "default", "=", "400", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "256", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_rho'", ",", "default", "=", "0.001", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ratio'", ",", "default", "=", "'0.5'", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta'", ",", "default", "=", "'0.03'", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--smax'", ",", "default", "=", "400", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--c'", ",", "default", "=", "'0.9'", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--date'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--tasknum'", ",", "default", "=", "50", ",", "type", "=", "int", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Using sigma max to support coefficient'", ")", "\n", "parser", ".", "add_argument", "(", "'--rho'", ",", "type", "=", "float", ",", "default", "=", "-", "2.783", ",", "help", "=", "'initial rho'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.augment_config": [[311, 340], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "augment_config", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'--co'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'set a random choice between mix and unmix during training'", ")", "\n", "parser", ".", "add_argument", "(", "'--mix-method'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'mix method, set different mix method'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-u'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'weight for consistency loss term of unlabeled data'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-u-hinge'", ",", "default", "=", "0", ",", "type", "=", "float", ",", "\n", "help", "=", "'weight for hinge loss term of unlabeled data'", ")", "\n", "parser", ".", "add_argument", "(", "'--amix'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--mix-layers-set'", ",", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "type", "=", "int", ",", "help", "=", "'define mix layer set'", ")", "\n", "parser", ".", "add_argument", "(", "'--distill_type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--use_soft_ce'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--nsamples'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--hat_as_aug'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_ratio'", ",", "default", "=", "'1'", ",", "type", "=", "float", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--share_gate'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup_head_norm'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--amix_head_norm'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_head_loss'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--distill_head_norm'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--amix_ratio'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--sup_ratio'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--ce_ratio'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--hetero'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_align'", ",", "action", "=", "'store_true'", ")", "\n", "# parser.add_argument('--kd_T', type=float, default=4, help='temperature for KD distillation')", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.acl_config": [[341, 357], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "acl_config", "(", "parser", ")", ":", "\n", "\n", "    ", "parser", ".", "add_argument", "(", "'--diff'", ",", "type", "=", "str", ",", "default", "=", "'yes'", ")", "\n", "parser", ".", "add_argument", "(", "'--lam'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--s_step'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--d_step'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--d_lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ")", "\n", "parser", ".", "add_argument", "(", "'--d_wd'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--adv'", ",", "type", "=", "float", ",", "default", "=", "0.05", ")", "\n", "parser", ".", "add_argument", "(", "'--orth'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--e_lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--e_wd'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--mom'", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "parser", ".", "add_argument", "(", "'--hal_lambda'", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.cat_config": [[358, 369], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "cat_config", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'--loss_type'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_kt'", ",", "default", "=", "0.025", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs_kt'", ",", "default", "=", "300", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_patience_kt'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)f)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_head\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_weights'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)d)'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_report'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--exit_after_first_task'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--similarity_detection'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'(default=%(default)s)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.contrastive_config": [[370, 388], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "contrastive_config", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'--s_dim'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"the dimension of student's feature\"", ")", "\n", "parser", ".", "add_argument", "(", "'--t_dim'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"the dimension of teacher's feature\"", ")", "\n", "parser", ".", "add_argument", "(", "'--feat_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'the dimension of the projection space'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_k'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'number of negatives paired with each positive'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_t'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "' the temperature'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_m'", ",", "type", "=", "int", ",", "default", "=", "0.5", ",", "help", "=", "' the momentum for updating the memory buffer'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_data'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "' the number of samples in the training set, therefor the memory buffer is: opt.n_data x opt.feat_dim'", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive_by_confident'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_defer'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive_defer_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive_with_mlp'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--each_class_remain_sample'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "' the temperature'", ")", "\n", "parser", ".", "add_argument", "(", "'--vote'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.set_args": [[389, 400], ["argparse.ArgumentParser", "config.asc_config", "config.train_config", "config.ucl_config", "config.contrastive_config", "config.augment_config", "config.acl_config", "config.cat_config", "cat_config.parse_args"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.asc_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.train_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.ucl_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.contrastive_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.augment_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.acl_config", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.config.cat_config"], ["", "def", "set_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "asc_config", "(", "parser", ")", "\n", "parser", "=", "train_config", "(", "parser", ")", "\n", "parser", "=", "ucl_config", "(", "parser", ")", "\n", "parser", "=", "contrastive_config", "(", "parser", ")", "\n", "parser", "=", "augment_config", "(", "parser", ")", "\n", "parser", "=", "acl_config", "(", "parser", ")", "\n", "parser", "=", "cat_config", "(", "parser", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.ABSATokenizer.subword_tokenize": [[33, 46], ["enumerate", "nlp_data_utils.ABSATokenizer.wordpiece_tokenizer.tokenize", "enumerate", "split_tokens.append", "idx_map.append", "split_labels.append", "split_labels.append"], "methods", ["None"], ["    ", "def", "subword_tokenize", "(", "self", ",", "tokens", ",", "labels", ")", ":", "# for AE", "\n", "        ", "split_tokens", ",", "split_labels", "=", "[", "]", ",", "[", "]", "\n", "idx_map", "=", "[", "]", "\n", "for", "ix", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "jx", ",", "sub_token", "in", "enumerate", "(", "sub_tokens", ")", ":", "\n", "                ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "if", "labels", "[", "ix", "]", "==", "\"B\"", "and", "jx", ">", "0", ":", "\n", "                    ", "split_labels", ".", "append", "(", "\"I\"", ")", "\n", "", "else", ":", "\n", "                    ", "split_labels", ".", "append", "(", "labels", "[", "ix", "]", ")", "\n", "", "idx_map", ".", "append", "(", "ix", ")", "\n", "", "", "return", "split_tokens", ",", "split_labels", ",", "idx_map", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.InputExample.__init__": [[54, 70], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", "=", "None", ",", "text_a", "=", "None", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.InputFeatures.__init__": [[75, 131], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "segment_ids", "=", "None", ",", "\n", "\n", "tokens_term_ids", "=", "None", ",", "\n", "tokens_sentence_ids", "=", "None", ",", "\n", "\n", "term_input_ids", "=", "None", ",", "\n", "term_input_mask", "=", "None", ",", "\n", "term_segment_ids", "=", "None", ",", "\n", "\n", "sentence_input_ids", "=", "None", ",", "\n", "sentence_input_mask", "=", "None", ",", "\n", "sentence_segment_ids", "=", "None", ",", "\n", "\n", "tokens_term_sentence_ids", "=", "None", ",", "\n", "label_id", "=", "None", ",", "\n", "\n", "masked_lm_labels", "=", "None", ",", "\n", "masked_pos", "=", "None", ",", "\n", "masked_weights", "=", "None", ",", "\n", "\n", "position_ids", "=", "None", ",", "\n", "\n", "valid_ids", "=", "None", ",", "\n", "label_mask", "=", "None", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n", "self", ".", "masked_lm_labels", "=", "masked_lm_labels", ",", "\n", "self", ".", "masked_pos", "=", "masked_pos", ",", "\n", "self", ".", "masked_weights", "=", "masked_weights", "\n", "\n", "self", ".", "tokens_term_ids", "=", "tokens_term_ids", "\n", "self", ".", "tokens_sentence_ids", "=", "tokens_sentence_ids", "\n", "\n", "self", ".", "term_input_ids", "=", "term_input_ids", "\n", "self", ".", "term_input_mask", "=", "term_input_mask", "\n", "self", ".", "term_segment_ids", "=", "term_segment_ids", "\n", "\n", "self", ".", "sentence_input_ids", "=", "sentence_input_ids", "\n", "self", ".", "sentence_input_mask", "=", "sentence_input_mask", "\n", "self", ".", "sentence_segment_ids", "=", "sentence_segment_ids", "\n", "\n", "self", ".", "tokens_term_sentence_ids", "=", "tokens_term_sentence_ids", "\n", "\n", "self", ".", "position_ids", "=", "position_ids", "\n", "\n", "self", ".", "valid_ids", "=", "valid_ids", "\n", "self", ".", "label_mask", "=", "label_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor.get_train_examples": [[137, 140], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor.get_dev_examples": [[141, 144], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor.get_test_examples": [[145, 148], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor.get_labels": [[149, 152], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json": [[153, 158], ["open", "json.load"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "@", "classmethod", "\n", "def", "_read_json", "(", "cls", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"Reads a json file for tasks in sentiment analysis.\"\"\"", "\n", "with", "open", "(", "input_file", ")", "as", "f", ":", "\n", "            ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_tsv": [[159, 163], ["readfile"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "return", "readfile", "(", "input_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DtcProcessor.get_labels": [[169, 171], ["range"], "methods", ["None"], ["def", "get_labels", "(", "self", ",", "ntasks", ")", ":", "\n", "        ", "return", "[", "t", "for", "t", "in", "range", "(", "ntasks", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DtcProcessor._create_examples": [[172, 181], ["enumerate", "examples.append", "nlp_data_utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "i", ",", "(", "sentence", ",", "label", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "sentence", "#no need to split for us", "\n", "text_b", "=", "None", "\n", "label", "=", "label", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DscProcessor.get_train_examples": [[185, 189], ["nlp_data_utils.DscProcessor._create_examples", "nlp_data_utils.DscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"train.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DscProcessor.get_dev_examples": [[190, 194], ["nlp_data_utils.DscProcessor._create_examples", "nlp_data_utils.DscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"dev.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DscProcessor.get_test_examples": [[195, 199], ["nlp_data_utils.DscProcessor._create_examples", "nlp_data_utils.DscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"test.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DscProcessor.get_labels": [[200, 202], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "'-1'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DscProcessor._create_examples": [[204, 215], ["enumerate", "examples.append", "nlp_data_utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "ids", ")", "\n", "text_a", "=", "lines", "[", "ids", "]", "[", "'sentence'", "]", "\n", "text_b", "=", "None", "\n", "label", "=", "lines", "[", "ids", "]", "[", "'polarity'", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples": [[221, 225], ["nlp_data_utils.AscProcessor._create_examples", "nlp_data_utils.AscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"train.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples": [[226, 230], ["nlp_data_utils.AscProcessor._create_examples", "nlp_data_utils.AscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"dev.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples": [[231, 235], ["nlp_data_utils.AscProcessor._create_examples", "nlp_data_utils.AscProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.DataProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "fn", "=", "\"test.json\"", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fn", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels": [[236, 239], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"positive\"", ",", "\"negative\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor._create_examples": [[240, 251], ["enumerate", "examples.append", "nlp_data_utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "ids", ")", "\n", "text_a", "=", "lines", "[", "ids", "]", "[", "'term'", "]", "\n", "text_b", "=", "lines", "[", "ids", "]", "[", "'sentence'", "]", "\n", "label", "=", "lines", "[", "ids", "]", "[", "'polarity'", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor.get_examples": [[259, 262], ["nlp_data_utils.StringProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples"], ["def", "get_examples", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples": [[263, 271], ["examples.append", "nlp_data_utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "text_a", "=", "line", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "text_a", "=", "text_a", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features": [[272, 372], ["enumerate", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "tokenizer.convert_tokens_to_ids", "features.append", "tokenizer.tokenize", "tokenizer.subword_tokenize", "tokenizer.tokenize", "nlp_data_utils._truncate_seq_pair", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "len", "len", "len", "nlp_data_utils.InputFeatures", "len", "tokens.append", "segment_ids.append", "tokens.index", "tokenizer.convert_tokens_to_ids.insert", "input_mask.insert", "segment_ids.insert", "len", "len", "token.lower", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.ABSATokenizer.subword_tokenize", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils._truncate_seq_pair"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "#check later if we can merge this function with the SQuAD preprocessing", "\n", "# label_map = {}", "\n", "# for (i, label) in enumerate(label_list):", "\n", "#     label_map[label] = i", "\n", "\n", "#text_b for sentence (segment 1); text_a for aspect (segment 0)", "\n", "# text_a = lines[ids]['term']", "\n", "# text_b = lines[ids]['sentence']", "\n", "# label = lines[ids]['polarity']", "\n", "\n", "if", "transformer_args", ".", "task", "==", "'asc'", ":", "# for pair", "\n", "        ", "label_map", "=", "{", "'+'", ":", "0", ",", "'positive'", ":", "0", ",", "'-'", ":", "1", ",", "'negative'", ":", "1", ",", "'neutral'", ":", "2", "}", "\n", "", "elif", "transformer_args", ".", "task", "==", "'nli'", ":", "\n", "        ", "label_map", "=", "{", "'neutral'", ":", "0", ",", "'entailment'", ":", "1", ",", "'contradiction'", ":", "2", "}", "\n", "", "elif", "transformer_args", ".", "task", "==", "'ae'", ":", "\n", "        ", "label_map", "=", "{", "'B'", ":", "0", ",", "'I'", ":", "1", ",", "'O'", ":", "2", "}", "\n", "\n", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "mode", "!=", "\"ae\"", ":", "\n", "            ", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "", "else", ":", "#only do subword tokenization.", "\n", "            ", "tokens_a", ",", "labels_a", ",", "example", ".", "idx_map", "=", "tokenizer", ".", "subword_tokenize", "(", "[", "token", ".", "lower", "(", ")", "for", "token", "in", "example", ".", "text_a", "]", ",", "example", ".", "label", ")", "\n", "\n", "", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "\n", "", "if", "tokens_b", ":", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "            ", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", "0", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "for", "token", "in", "tokens_b", ":", "\n", "                ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# token_a has a max_length", "\n", "if", "transformer_args", ".", "exp", "in", "[", "'3layer_aspect'", ",", "'2layer_aspect_transfer'", ",", "'2layer_aspect_dynamic'", "]", ":", "\n", "            ", "term_position", "=", "tokens", ".", "index", "(", "'[SEP]'", ")", "-", "1", "\n", "while", "term_position", "<", "transformer_args", ".", "max_term_length", ":", "#[CLS],t,[SEP]", "\n", "                ", "input_ids", ".", "insert", "(", "term_position", ",", "0", ")", "\n", "input_mask", ".", "insert", "(", "term_position", ",", "0", ")", "\n", "segment_ids", ".", "insert", "(", "term_position", ",", "0", ")", "\n", "term_position", "+=", "1", "\n", "\n", "", "max_seq_length", "=", "max_seq_length", "\n", "# Zero-pad up to the sequence length.", "\n", "", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "            ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "mode", "!=", "\"ae\"", ":", "\n", "            ", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "else", ":", "\n", "            ", "label_id", "=", "[", "-", "1", "]", "*", "len", "(", "input_ids", ")", "#-1 is the index to ignore", "\n", "#truncate the label length if it exceeds the limit.", "\n", "lb", "=", "[", "label_map", "[", "label", "]", "for", "label", "in", "labels_a", "]", "\n", "if", "len", "(", "lb", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "lb", "=", "lb", "[", "0", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "", "label_id", "[", "1", ":", "len", "(", "lb", ")", "+", "1", "]", "=", "lb", "\n", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils._truncate_seq_pair": [[374, 389], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc": [[391, 423], ["enumerate", "tokenizer.texts_to_sequences", "features.append", "w2v_util.pad_sequences", "nlp_data_utils.InputFeatures", "example.text_a.translate().lower", "example.text_a.translate", "str.maketrans"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences"], ["", "", "", "def", "convert_examples_to_features_w2v_dsc", "(", "examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "# prepare for word2vector experiments", "\n", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "#check later if we can merge this function with the SQuAD preprocessing", "\n", "# label_map = {}", "\n", "# for (i, label) in enumerate(label_list):", "\n", "#     label_map[label] = i", "\n", "\n", "label_map", "=", "{", "'-1'", ":", "0", ",", "'1'", ":", "1", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens_a_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "[", "example", ".", "text_a", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "tokens_a_ids", "=", "pad_sequences", "(", "tokens_a_ids", ",", "maxlen", "=", "args", ".", "max_seq_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "\n", "# print('example.text_a: ',example.text_a.translate(str.maketrans('', '', string.punctuation)).lower())", "\n", "# print('tokens_a_ids: ',tokens_a_ids)", "\n", "# print('tokens_a_ids: ',len(tokens_a_ids))", "\n", "\n", "# exit()", "\n", "if", "'newsgroup'", "in", "args", ".", "task", ":", "\n", "            ", "label_id", "=", "example", ".", "label", "\n", "", "else", ":", "\n", "            ", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "tokens_term_ids", "=", "tokens_a_ids", ",", "\n", "tokens_sentence_ids", "=", "tokens_a_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v": [[424, 458], ["enumerate", "tokenizer.texts_to_sequences", "tokenizer.texts_to_sequences", "features.append", "w2v_util.pad_sequences", "w2v_util.pad_sequences", "nlp_data_utils.InputFeatures", "example.text_a.translate().lower", "example.text_b.translate().lower", "example.text_a.translate", "example.text_b.translate", "str.maketrans", "str.maketrans"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences"], ["", "def", "convert_examples_to_features_w2v", "(", "examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "# prepare for word2vector experiments", "\n", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "#check later if we can merge this function with the SQuAD preprocessing", "\n", "# label_map = {}", "\n", "# for (i, label) in enumerate(label_list):", "\n", "#     label_map[label] = i", "\n", "\n", "label_map", "=", "{", "'+'", ":", "0", ",", "'positive'", ":", "0", ",", "'-'", ":", "1", ",", "'negative'", ":", "1", ",", "'neutral'", ":", "2", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens_a_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "[", "example", ".", "text_a", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "tokens_b_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "[", "example", ".", "text_b", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "\n", "# if len(tokens_a_ids[0])<= 0 or len(tokens_b_ids[0])<= 0:", "\n", "#     print('empty')", "\n", "#     continue", "\n", "# assert len(tokens_a_ids[0]) > 0", "\n", "# assert len(tokens_b_ids[0]) > 0", "\n", "\n", "tokens_a_ids", "=", "pad_sequences", "(", "tokens_a_ids", ",", "maxlen", "=", "args", ".", "max_term_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "tokens_b_ids", "=", "pad_sequences", "(", "tokens_b_ids", ",", "maxlen", "=", "args", ".", "max_sentence_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "\n", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "tokens_term_ids", "=", "tokens_a_ids", ",", "\n", "tokens_sentence_ids", "=", "tokens_b_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as": [[460, 509], ["enumerate", "tokenizer.texts_to_sequences", "tokenizer.texts_to_sequences", "tokenizer.texts_to_sequences", "features.append", "w2v_util.pad_sequences", "w2v_util.pad_sequences", "w2v_util.pad_sequences", "nlp_data_utils.InputFeatures", "example.text_a.translate().lower", "example.text_b.translate().lower", "example.text_b.translate().lower", "example.text_a.translate", "example.text_b.translate", "example.text_a.translate().lower", "str.maketrans", "str.maketrans", "example.text_b.translate", "example.text_a.translate", "str.maketrans", "str.maketrans"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.pad_sequences"], ["", "def", "convert_examples_to_features_w2v_as", "(", "examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", ":", "\n", "# w2v also considers aspect (by adding aspect at the beginning)", "\n", "# prepare for word2vector experiments", "\n", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "#check later if we can merge this function with the SQuAD preprocessing", "\n", "# label_map = {}", "\n", "# for (i, label) in enumerate(label_list):", "\n", "#     label_map[label] = i", "\n", "\n", "if", "transformer_args", ".", "task", "==", "'asc'", ":", "\n", "        ", "label_map", "=", "{", "'+'", ":", "0", ",", "'positive'", ":", "0", ",", "'-'", ":", "1", ",", "'negative'", ":", "1", ",", "'neutral'", ":", "2", "}", "\n", "", "elif", "transformer_args", ".", "task", "==", "'nli'", ":", "\n", "        ", "label_map", "=", "{", "'neutral'", ":", "0", ",", "'entailment'", ":", "1", ",", "'contradiction'", ":", "2", "}", "\n", "\n", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens_a_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "[", "example", ".", "text_a", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "tokens_b_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "[", "example", ".", "text_b", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "\n", "tokens_ids", "=", "tokenizer", ".", "texts_to_sequences", "(", "\n", "[", "example", ".", "text_a", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "+", "' '", "+", "\n", "example", ".", "text_b", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "lower", "(", ")", "]", ")", "\n", "\n", "# print([example.text_a.translate(str.maketrans('', '', string.punctuation)).lower()])", "\n", "# print([example.text_a.translate(str.maketrans('', '', string.punctuation)).lower() + ' ' +", "\n", "#        example.text_b.translate(str.maketrans('', '', string.punctuation)).lower()])", "\n", "# print('tokens_ids: ',tokens_ids)", "\n", "# print('tokens_a_ids: ',tokens_a_ids)", "\n", "\n", "# if len(tokens_a_ids[0])<= 0 or len(tokens_b_ids[0])<= 0:", "\n", "#     print('empty')", "\n", "#     continue", "\n", "# assert len(tokens_a_ids[0]) > 0", "\n", "# assert len(tokens_b_ids[0]) > 0", "\n", "\n", "tokens_ids", "=", "pad_sequences", "(", "tokens_ids", ",", "maxlen", "=", "args", ".", "max_seq_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "tokens_a_ids", "=", "pad_sequences", "(", "tokens_a_ids", ",", "maxlen", "=", "args", ".", "max_term_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "tokens_b_ids", "=", "pad_sequences", "(", "tokens_b_ids", ",", "maxlen", "=", "args", ".", "max_sentence_length", ",", "padding", "=", "'post'", ",", "value", "=", "0", ")", "[", "0", "]", "\n", "\n", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "tokens_term_sentence_ids", "=", "tokens_ids", ",", "\n", "tokens_term_ids", "=", "tokens_a_ids", ",", "\n", "tokens_sentence_ids", "=", "tokens_b_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dtc": [[514, 566], ["enumerate", "tokenizer.tokenize", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "tokenizer.convert_tokens_to_ids", "features.append", "len", "tokens.append", "segment_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "len", "len", "len", "nlp_data_utils.InputFeatures"], "function", ["None"], ["", "def", "convert_examples_to_features_dtc", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "#TODO: input document only", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "labels_a", "=", "example", ".", "label", "\n", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "# print('labels_a: ',labels_a)", "\n", "# print('example.text_a: ',example.text_a)", "\n", "# print('tokens_a: ',tokens_a)", "\n", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", "0", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "            ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "labels_a", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc": [[570, 627], ["enumerate", "tokenizer.tokenize", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "tokenizer.convert_tokens_to_ids", "features.append", "len", "tokens.append", "segment_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "len", "len", "len", "nlp_data_utils.InputFeatures"], "function", ["None"], ["", "def", "convert_examples_to_features_dsc", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "#TODO: input document only", "\n", "label_map", "=", "{", "'-1'", ":", "0", ",", "'1'", ":", "1", "}", "\n", "if", "transformer_args", ".", "task", "==", "'dsc'", ":", "\n", "        ", "label_map", "=", "{", "'-1'", ":", "0", ",", "'1'", ":", "1", "}", "\n", "", "elif", "transformer_args", ".", "task", "==", "'ssc'", ":", "\n", "        ", "label_map", "=", "{", "'0'", ":", "0", ",", "'1'", ":", "1", ",", "'2'", ":", "2", "}", "\n", "\n", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "labels_a", "=", "label_map", "[", "example", ".", "label", "]", "\n", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "# print('labels_a: ',labels_a)", "\n", "# print('example.text_a: ',example.text_a)", "\n", "# print('tokens_a: ',tokens_a)", "\n", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", "0", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "            ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "labels_a", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.whitespace_tokenize": [[629, 636], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.get_random_word": [[639, 642], ["random.randint", "len"], "function", ["None"], ["", "def", "get_random_word", "(", "vocab_words", ")", ":", "\n", "    ", "i", "=", "randint", "(", "0", ",", "len", "(", "vocab_words", ")", "-", "1", ")", "\n", "return", "vocab_words", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load": [[6, 203], ["None"], "function", ["None"], ["def", "load", "(", ")", ":", "\n", "# ============= dataset base ==================", "\n", "    ", "if", "args", ".", "task", "==", "'asc'", ":", "#aspect sentiment classication", "\n", "        ", "args", ".", "ntasks", "=", "19", "\n", "args", ".", "num_train_epochs", "=", "10", "\n", "args", ".", "xusemeval_num_train_epochs", "=", "10", "\n", "args", ".", "bingdomains_num_train_epochs", "=", "30", "\n", "args", ".", "bingdomains_num_train_epochs_multiplier", "=", "3", "\n", "args", ".", "nepochs", "=", "100", "\n", "args", ".", "nclasses", "=", "3", "\n", "\n", "\n", "", "if", "args", ".", "task", "==", "'dsc'", ":", "#document sentiment classication", "\n", "        ", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "num_train_epochs", "=", "20", "\n", "args", ".", "nepochs", "=", "100", "\n", "args", ".", "nclasses", "=", "2", "\n", "\n", "\n", "", "if", "args", ".", "task", "==", "'newsgroup'", ":", "#aspect sentiment classication", "\n", "        ", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "class_per_task", "=", "2", "\n", "args", ".", "num_train_epochs", "=", "10", "\n", "args", ".", "nepochs", "=", "100", "\n", "args", ".", "nclasses", "=", "2", "\n", "\n", "\n", "\n", "", "if", "args", ".", "task", "==", "'celeba'", ":", "\n", "        ", "if", "args", ".", "ntasks", "!=", "20", ":", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "nclasses", "=", "2", "\n", "args", ".", "train_data_size", "=", "100", "\n", "args", ".", "data_size", "=", "'full'", "\n", "args", ".", "image_size", "=", "32", "\n", "args", ".", "image_channel", "=", "3", "\n", "args", ".", "nepochs", "=", "1000", "\n", "\n", "", "if", "args", ".", "task", "==", "'cifar10'", ":", "\n", "        ", "if", "args", ".", "ntasks", "!=", "20", ":", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "nclasses", "=", "10", "\n", "args", ".", "image_size", "=", "32", "\n", "args", ".", "image_channel", "=", "3", "\n", "args", ".", "nepochs", "=", "1000", "\n", "\n", "\n", "", "if", "args", ".", "task", "==", "'cifar100'", ":", "\n", "        ", "if", "args", ".", "ntasks", "!=", "20", ":", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "nclasses", "=", "100", "\n", "args", ".", "image_size", "=", "32", "\n", "args", ".", "image_channel", "=", "3", "\n", "args", ".", "nepochs", "=", "1000", "\n", "\n", "\n", "", "if", "args", ".", "task", "==", "'mnist'", ":", "\n", "        ", "if", "args", ".", "ntasks", "!=", "20", ":", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "nclasses", "=", "10", "\n", "args", ".", "image_size", "=", "28", "\n", "args", ".", "image_channel", "=", "1", "\n", "args", ".", "nepochs", "=", "1000", "\n", "\n", "", "if", "args", ".", "task", "==", "'femnist'", ":", "\n", "        ", "if", "args", ".", "ntasks", "!=", "20", ":", "args", ".", "ntasks", "=", "10", "\n", "args", ".", "nclasses", "=", "62", "\n", "args", ".", "data_size", "=", "'full'", "\n", "args", ".", "image_size", "=", "28", "\n", "args", ".", "image_channel", "=", "1", "\n", "args", ".", "train_data_size", "=", "6200", "\n", "args", ".", "nepochs", "=", "1000", "\n", "\n", "\n", "# ============= backbone base ==================", "\n", "", "if", "'bert_adapter'", "in", "args", ".", "backbone", ":", "\n", "        ", "args", ".", "apply_bert_output", "=", "True", "\n", "args", ".", "apply_bert_attention_output", "=", "True", "\n", "\n", "", "if", "'cnn'", "in", "args", ".", "backbone", ":", "\n", "        ", "pass", "\n", "\n", "# ============= approach base ==================", "\n", "\n", "# Some are in the \"base\" folder", "\n", "", "if", "args", ".", "baseline", "==", "'kan'", ":", "\n", "        ", "pass", "\n", "", "if", "args", ".", "baseline", "==", "'srk'", ":", "\n", "        ", "pass", "\n", "", "if", "args", ".", "baseline", "==", "'ewc'", ":", "\n", "        ", "pass", "\n", "", "if", "args", ".", "baseline", "==", "'owm'", ":", "\n", "        ", "pass", "\n", "", "if", "args", ".", "baseline", "==", "'hat'", ":", "\n", "        ", "pass", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'l2'", ":", "\n", "        ", "args", ".", "lamb", "=", "0.5", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'a-gem'", ":", "\n", "        ", "args", ".", "buffer_size", "=", "128", "\n", "args", ".", "buffer_percent", "=", "0.02", "\n", "args", ".", "gamma", "=", "0.5", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'derpp'", ":", "\n", "        ", "args", ".", "buffer_size", "=", "128", "\n", "args", ".", "buffer_percent", "=", "0.02", "\n", "args", ".", "alpha", "=", "0.5", "\n", "args", ".", "beta", "=", "0.5", "\n", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'hal'", ":", "\n", "        ", "args", ".", "buffer_size", "=", "128", "\n", "args", ".", "buffer_percent", "=", "0.02", "\n", "args", ".", "gamma", "=", "0.1", "\n", "args", ".", "beta", "=", "0.5", "\n", "args", ".", "hal_lambda", "=", "0.1", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ucl'", ":", "\n", "        ", "args", ".", "ratio", "=", "0.125", "\n", "args", ".", "beta", "=", "0.002", "\n", "args", ".", "lr_rho", "=", "0.01", "\n", "args", ".", "alpha", "=", "5", "\n", "args", ".", "optimizer", "=", "'SGD'", "\n", "args", ".", "clipgrad", "=", "100", "\n", "args", ".", "lr_min", "=", "2e-6", "\n", "args", ".", "lr_factor", "=", "3", "\n", "args", ".", "lr_patience", "=", "5", "\n", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'cat'", ":", "\n", "        ", "args", ".", "n_head", "=", "5", "\n", "args", ".", "similarity_detection", "=", "'auto'", "\n", "args", ".", "loss_type", "=", "'multi-loss-joint-Tsim'", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'acl'", ":", "\n", "        ", "args", ".", "buffer_size", "=", "128", "\n", "args", ".", "buffer_percent", "=", "0.02", "\n", "args", ".", "alpha", "=", "0.5", "\n", "args", ".", "beta", "=", "0.5", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'b-cl'", ":", "\n", "        ", "args", ".", "apply_bert_output", "=", "True", "\n", "args", ".", "apply_bert_attention_output", "=", "True", "\n", "args", ".", "build_adapter_capsule_mask", "=", "True", "\n", "args", ".", "apply_one_layer_shared", "=", "True", "\n", "args", ".", "semantic_cap_size", "=", "3", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'classic'", ":", "\n", "        ", "args", ".", "apply_bert_output", "=", "True", "\n", "args", ".", "apply_bert_attention_output", "=", "True", "\n", "args", ".", "sup_loss", "=", "True", "\n", "args", ".", "amix", "=", "True", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ctr'", ":", "\n", "        ", "args", ".", "apply_bert_output", "=", "True", "\n", "args", ".", "apply_bert_attention_output", "=", "True", "\n", "args", ".", "build_adapter_capsule_mask", "=", "True", "\n", "args", ".", "apply_one_layer_shared", "=", "True", "\n", "args", ".", "use_imp", "=", "True", "\n", "args", ".", "transfer_route", "=", "True", "\n", "args", ".", "share_conv", "=", "True", "\n", "args", ".", "larger_as_share", "=", "True", "\n", "args", ".", "adapter_size", "=", "True", "\n", "\n", "# ============= additional for DIL ==================", "\n", "\n", "", "if", "not", "args", ".", "ent_id", "and", "not", "args", ".", "last_id", "and", "'dil'", "in", "args", ".", "scenario", ":", "\n", "        ", "args", ".", "last_id", "=", "True", "# you have to chose one way to decide the ID", "\n", "\n", "\n", "", "if", "args", ".", "ent_id", ":", "\n", "        ", "args", ".", "resume_model", "=", "True", "\n", "args", ".", "eval_only", "=", "True", "\n", "args", ".", "eval_batch_size", "=", "1", "\n", "\n", "", "if", "args", ".", "eval_only", ":", "\n", "        ", "args", ".", "resume_model", "=", "True", "\n", "if", "args", ".", "ntasks", "==", "10", "and", "not", "args", ".", "eval_each_step", ":", "\n", "            ", "args", ".", "resume_from_task", "=", "9", "\n", "", "elif", "args", ".", "ntasks", "==", "20", "and", "not", "args", ".", "eval_each_step", ":", "\n", "            ", "args", ".", "resume_from_task", "=", "19", "\n", "\n", "", "", "if", "args", ".", "unseen", ":", "\n", "        ", "args", ".", "ntasks_unseen", "=", "10", "\n", "\n", "\n", "#================ analysis base ================", "\n", "\n", "", "if", "args", ".", "exit_after_first_task", ":", "\n", "        ", "args", ".", "nepochs", "=", "1", "\n", "args", ".", "num_train_epochs", "=", "1", "\n", "args", ".", "xusemeval_num_train_epochs", "=", "1", "\n", "args", ".", "bingdomains_num_train_epochs", "=", "1", "\n", "args", ".", "bingdomains_num_train_epochs_multiplier", "=", "1", "\n", "args", ".", "eval_only", "=", "False", "\n", "\n", "", "return", "args", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.print_model_report": [[10, 22], ["print", "print", "print", "model.parameters", "print", "print", "print", "print", "numpy.prod", "p.size", "p.size", "utils.human_format"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.human_format"], ["def", "print_model_report", "(", "model", ")", ":", "\n", "    ", "print", "(", "'-'", "*", "100", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "'Dimensions ='", ",", "end", "=", "' '", ")", "\n", "count", "=", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "print", "(", "p", ".", "size", "(", ")", ",", "end", "=", "' '", ")", "\n", "count", "+=", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "'Num parameters = %s'", "%", "(", "human_format", "(", "count", ")", ")", ")", "\n", "print", "(", "'-'", "*", "100", ")", "\n", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.human_format": [[23, 29], ["abs"], "function", ["None"], ["", "def", "human_format", "(", "num", ")", ":", "\n", "    ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "        ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.print_optimizer_config": [[30, 41], ["print", "print", "opt.keys", "print", "n.startswith", "print"], "function", ["None"], ["", "def", "print_optimizer_config", "(", "optim", ")", ":", "\n", "    ", "if", "optim", "is", "None", ":", "\n", "        ", "print", "(", "optim", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "optim", ",", "'='", ",", "end", "=", "' '", ")", "\n", "opt", "=", "optim", ".", "param_groups", "[", "0", "]", "\n", "for", "n", "in", "opt", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "n", ".", "startswith", "(", "'param'", ")", ":", "\n", "                ", "print", "(", "n", "+", "':'", ",", "opt", "[", "n", "]", ",", "end", "=", "', '", ")", "\n", "", "", "print", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model": [[44, 46], ["copy.deepcopy", "model.state_dict"], "function", ["None"], ["", "def", "get_model", "(", "model", ")", ":", "\n", "    ", "return", "deepcopy", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_": [[47, 50], ["model.load_state_dict", "copy.deepcopy"], "function", ["None"], ["", "def", "set_model_", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "model", ".", "load_state_dict", "(", "deepcopy", "(", "state_dict", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model": [[51, 55], ["model.parameters"], "function", ["None"], ["", "def", "freeze_model", "(", "model", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size": [[58, 60], ["int", "numpy.floor", "float"], "function", ["None"], ["", "def", "compute_conv_output_size", "(", "Lin", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "return", "int", "(", "np", ".", "floor", "(", "(", "Lin", "+", "2", "*", "padding", "-", "dilation", "*", "(", "kernel_size", "-", "1", ")", "-", "1", ")", "/", "float", "(", "stride", ")", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_mean_std_dataset": [[63, 79], ["torch.utils.data.DataLoader", "len", "mean.view().expand_as", "image.mean().mean", "mean.view", "image.mean", "mean.size", "mean.size", "image.size", "len", "image.size"], "function", ["None"], ["", "def", "compute_mean_std_dataset", "(", "dataset", ")", ":", "\n", "# dataset already put ToTensor", "\n", "    ", "mean", "=", "0", "\n", "std", "=", "0", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "for", "image", ",", "_", "in", "loader", ":", "\n", "        ", "mean", "+=", "image", ".", "mean", "(", "3", ")", ".", "mean", "(", "2", ")", "\n", "", "mean", "/=", "len", "(", "dataset", ")", "\n", "\n", "mean_expanded", "=", "mean", ".", "view", "(", "mean", ".", "size", "(", "0", ")", ",", "mean", ".", "size", "(", "1", ")", ",", "1", ",", "1", ")", ".", "expand_as", "(", "image", ")", "\n", "for", "image", ",", "_", "in", "loader", ":", "\n", "        ", "std", "+=", "(", "image", "-", "mean_expanded", ")", ".", "pow", "(", "2", ")", ".", "sum", "(", "3", ")", ".", "sum", "(", "2", ")", "\n", "\n", "", "std", "=", "(", "std", "/", "(", "len", "(", "dataset", ")", "*", "image", ".", "size", "(", "2", ")", "*", "image", ".", "size", "(", "3", ")", "-", "1", ")", ")", ".", "sqrt", "(", ")", "\n", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.report_tr": [[83, 92], ["print", "time.time"], "function", ["None"], ["", "def", "report_tr", "(", "res", ",", "e", ",", "sbatch", ",", "clock0", ",", "clock1", ")", ":", "\n", "# Training performance", "\n", "    ", "print", "(", "\n", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train losses={:.3f} | T: loss={:.3f}, acc={:5.2f}% | D: loss={:.3f}, acc={:5.1f}%, '", "\n", "'Diff loss:{:.3f} |'", ".", "format", "(", "\n", "e", "+", "1", ",", "\n", "1000", "*", "sbatch", "*", "(", "clock1", "-", "clock0", ")", "/", "res", "[", "'size'", "]", ",", "\n", "1000", "*", "sbatch", "*", "(", "time", ".", "time", "(", ")", "-", "clock1", ")", "/", "res", "[", "'size'", "]", ",", "res", "[", "'loss_tot'", "]", ",", "\n", "res", "[", "'loss_t'", "]", ",", "res", "[", "'acc_t'", "]", ",", "res", "[", "'loss_a'", "]", ",", "res", "[", "'acc_d'", "]", ",", "res", "[", "'loss_d'", "]", ")", ",", "end", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.report_val": [[93, 97], ["print"], "function", ["None"], ["", "def", "report_val", "(", "res", ")", ":", "\n", "# Validation performance", "\n", "    ", "print", "(", "' Valid losses={:.3f} | T: loss={:.6f}, acc={:5.2f}%, | D: loss={:.3f}, acc={:5.2f}%, Diff loss={:.3f} |'", ".", "format", "(", "\n", "res", "[", "'loss_tot'", "]", ",", "res", "[", "'loss_t'", "]", ",", "res", "[", "'acc_t'", "]", ",", "res", "[", "'loss_a'", "]", ",", "res", "[", "'acc_d'", "]", ",", "res", "[", "'loss_d'", "]", ")", ",", "end", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert_ner": [[102, 132], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_bert_ner", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "valid_ids", ",", "label_mask", ",", "_", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "valid_ids", ",", "label_mask", ")", "\n", "\n", "loss", "=", "criterion", "(", "t", ",", "outputs", "[", "t", "]", ",", "targets", ",", "label_mask", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_ner_w2v": [[134, 164], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_ner_w2v", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_sentence_ids", ",", "targets", ",", "label_mask", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", ".", "forward", "(", "tokens_sentence_ids", ",", "label_mask", ")", "\n", "\n", "loss", "=", "criterion", "(", "t", ",", "outputs", "[", "t", "]", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert": [[167, 198], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_bert", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "loss", "=", "criterion", "(", "t", ",", "outputs", "[", "t", "]", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert_dil": [[201, 232], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_bert_dil", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "loss", "=", "criterion", "(", "t", ",", "output", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_cnn": [[233, 268], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_cnn", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "args", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "criterion", "(", "t", ",", "output", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_adapter_head": [[270, 305], ["model.last.named_parameters", "model.train", "tqdm.tqdm", "model.last.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "loss.backward", "model.last.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_adapter_head", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ",", "\n", "ce", "=", "None", ",", "lamb", "=", "None", ",", "mask_pre", "=", "None", ",", "args", "=", "None", ",", "ewc_lamb", "=", "None", ",", "model_old", "=", "None", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "args", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "loss", ",", "reg", "=", "criterion", "(", "ce", ",", "lamb", ",", "mask_pre", ",", "output", ",", "targets", ",", "masks", ",", "\n", "t", "=", "t", ",", "args", "=", "args", ",", "ewc_lamb", "=", "ewc_lamb", ",", "fisher", "=", "fisher", ",", "\n", "model", "=", "model", ",", "model_old", "=", "model_old", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_cnn_head": [[307, 343], ["model.last.named_parameters", "model.train", "tqdm.tqdm", "model.last.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "torch.LongTensor().cuda", "model.forward", "criterion", "loss.backward", "model.last.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "torch.LongTensor", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_cnn_head", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ",", "\n", "ce", "=", "None", ",", "lamb", "=", "None", ",", "mask_pre", "=", "None", ",", "args", "=", "None", ",", "ewc_lamb", "=", "None", ",", "model_old", "=", "None", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "task", "=", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "task", ",", "images", ",", "s", "=", "args", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "loss", ",", "reg", "=", "criterion", "(", "ce", ",", "lamb", ",", "mask_pre", ",", "output", ",", "targets", ",", "masks", ",", "\n", "t", "=", "t", ",", "args", "=", "args", ",", "ewc_lamb", "=", "ewc_lamb", ",", "fisher", "=", "fisher", ",", "\n", "model", "=", "model", ",", "model_old", "=", "model_old", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "last", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_w2v": [[344, 379], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "len", "len", "torch.LongTensor", "bat.to", "numpy.arange", "p.grad.data.pow", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag_w2v", "(", "t", ",", "train", ",", "device", ",", "model", ",", "criterion", ",", "args", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "train", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "len", "(", "train", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "batch", "=", "train", "[", "b", "]", "\n", "batch", "=", "[", "\n", "bat", ".", "to", "(", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "criterion", "(", "t", ",", "output", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "len", "(", "train", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag": [[380, 405], ["model.named_parameters", "model.train", "tqdm.tqdm", "model.named_parameters", "range", "torch.LongTensor().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "model.zero_grad", "model.forward", "criterion", "criterion.backward", "model.named_parameters", "torch.autograd.Variable", "x.size", "x.size", "torch.LongTensor", "numpy.arange", "p.grad.data.pow", "numpy.min", "x.size"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward"], ["", "def", "fisher_matrix_diag", "(", "t", ",", "x", ",", "y", ",", "model", ",", "criterion", ",", "sbatch", "=", "20", ")", ":", "\n", "# Init", "\n", "    ", "fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "0", "*", "p", ".", "data", "\n", "# Compute", "\n", "", "model", ".", "train", "(", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "x", ".", "size", "(", "0", ")", ",", "sbatch", ")", ",", "desc", "=", "'Fisher diagonal'", ",", "ncols", "=", "100", ",", "ascii", "=", "True", ")", ":", "\n", "        ", "b", "=", "torch", ".", "LongTensor", "(", "np", ".", "arange", "(", "i", ",", "np", ".", "min", "(", "[", "i", "+", "sbatch", ",", "x", ".", "size", "(", "0", ")", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "images", "=", "torch", ".", "autograd", ".", "Variable", "(", "x", "[", "b", "]", ",", "volatile", "=", "False", ")", "\n", "target", "=", "torch", ".", "autograd", ".", "Variable", "(", "y", "[", "b", "]", ",", "volatile", "=", "False", ")", "\n", "# Forward and backward", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", ".", "forward", "(", "images", ")", "\n", "loss", "=", "criterion", "(", "t", ",", "outputs", "[", "t", "]", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Get gradients", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "fisher", "[", "n", "]", "+=", "sbatch", "*", "p", ".", "grad", ".", "data", ".", "pow", "(", "2", ")", "\n", "# Mean", "\n", "", "", "", "for", "n", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "fisher", "[", "n", "]", "=", "fisher", "[", "n", "]", "/", "x", ".", "size", "(", "0", ")", "\n", "fisher", "[", "n", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "fisher", "[", "n", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "return", "fisher", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.cross_entropy": [[408, 422], ["torch.nn.functional.softmax", "torch.nn.functional.softmax", "out.pow.pow", "tar.pow.pow", "out.pow.sum().view().expand_as", "ce.mean.mean", "out.pow.sum().view().expand_as", "tar.pow.sum().view().expand_as", "out.pow.size", "out.pow.sum().view", "out.pow.sum().view", "tar.pow.sum().view", "out.pow.log", "out.pow.sum", "out.pow.sum", "tar.pow.sum"], "function", ["None"], ["", "def", "cross_entropy", "(", "outputs", ",", "targets", ",", "exp", "=", "1", ",", "size_average", "=", "True", ",", "eps", "=", "1e-5", ")", ":", "\n", "    ", "out", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "outputs", ")", "\n", "tar", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "targets", ")", "\n", "if", "exp", "!=", "1", ":", "\n", "        ", "out", "=", "out", ".", "pow", "(", "exp", ")", "\n", "out", "=", "out", "/", "out", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "out", ")", "\n", "tar", "=", "tar", ".", "pow", "(", "exp", ")", "\n", "tar", "=", "tar", "/", "tar", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "tar", ")", "\n", "", "out", "=", "out", "+", "eps", "/", "out", ".", "size", "(", "1", ")", "\n", "out", "=", "out", "/", "out", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "out", ")", "\n", "ce", "=", "-", "(", "tar", "*", "out", ".", "log", "(", ")", ")", ".", "sum", "(", "1", ")", "\n", "if", "size_average", ":", "\n", "        ", "ce", "=", "ce", ".", "mean", "(", ")", "\n", "", "return", "ce", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_req_grad": [[425, 431], ["hasattr", "hasattr"], "function", ["None"], ["", "def", "set_req_grad", "(", "layer", ",", "req_grad", ")", ":", "\n", "    ", "if", "hasattr", "(", "layer", ",", "'weight'", ")", ":", "\n", "        ", "layer", ".", "weight", ".", "requires_grad", "=", "req_grad", "\n", "", "if", "hasattr", "(", "layer", ",", "'bias'", ")", ":", "\n", "        ", "layer", ".", "bias", ".", "requires_grad", "=", "req_grad", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.is_number": [[434, 449], ["float", "unicodedata.numeric"], "function", ["None"], ["", "def", "is_number", "(", "s", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "float", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "pass", "\n", "\n", "", "try", ":", "\n", "        ", "import", "unicodedata", "\n", "unicodedata", ".", "numeric", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "False", "\n", "########################################################################################################################", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.sequece_generate.get": [[19, 160], ["open", "range", "str", "range", "random.shuffle", "f_random_seq.writelines"], "function", ["None"], ["def", "get", "(", "seed", "=", "0", ")", ":", "\n", "\n", "    ", "ninteen_domains", "=", "[", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "'Bing3domains_Computer'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'Bing5domains_CanonG3'", ",", "\n", "'Bing5domains_ApexAD2600Progressive'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "'Bing9domains_HitachiRouter'", ",", "\n", "'Bing9domains_ipod'", ",", "\n", "'Bing9domains_LinksysRouter'", ",", "\n", "'Bing9domains_MicroMP3'", ",", "\n", "'Bing9domains_Nokia6600'", ",", "\n", "'Bing9domains_Norton'", ",", "\n", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "]", "\n", "\n", "\n", "\n", "ten_domains", "=", "[", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "]", "\n", "\n", "# ner_domains_oldseq = ['ieer','btc','gum','ritter','re3d', 'wnut2017','wikigold','conll2003']", "\n", "# ner_domains_8 = ['ieer','btc','gum','ritter','ontonote', 'wnut2017','wikigold','conll2003']", "\n", "# ner_domains_7 = ['ieer','btc','ritter','ontonote', 'wnut2017','wikigold','conll2003']", "\n", "# ner_domains_6 = ['ieer','btc','ontonote', 'wnut2017','wikigold','conll2003']", "\n", "ner_domains_full", "=", "[", "'ieer'", ",", "'btc'", ",", "'gum'", ",", "'ritter'", ",", "'re3d'", ",", "'wnut2017'", ",", "'wikigold'", ",", "'conll2003'", ",", "'ontonote'", "]", "\n", "ner_domains_overlap", "=", "[", "'ieer'", ",", "'btc'", ",", "'gum'", ",", "'re3d'", ",", "'wikigold'", ",", "'conll2003'", ",", "'ontonote'", "]", "\n", "\n", "# nli_domains = ['travel','telephone','slate','government','fiction']", "\n", "\n", "# dsc_domains = ['Video_Games','Toys_and_Games','Tools_and_Home_Improvement','Sports_and_Outdoors','Pet_Supplies',", "\n", "#        'Patio_Lawn_and_Garden','Office_Products','Musical_Instruments','Movies_and_TV',", "\n", "#        'Kindle_Store','Home_and_Kitchen','Health_and_Personal_Care','Grocery_and_Gourmet_Food','Electronics',", "\n", "#        'Digital_Music','Clothing_Shoes_and_Jewelry','Cell_Phones_and_Accessories','CDs_and_Vinyl',", "\n", "#        'Books','Beauty','Baby','Automotive','Apps_for_Android','Amazon_Instant_Video']", "\n", "\n", "# dsc_domains_10 = ['Video_Games','Toys_and_Games','Tools_and_Home_Improvement','Sports_and_Outdoors','Pet_Supplies',", "\n", "#            'Patio_Lawn_and_Garden','Office_Products','Musical_Instruments','Movies_and_TV',", "\n", "#            'Kindle_Store']", "\n", "\n", "# ssc_domains = ['airconditioner','bike','diaper','GPS','headphone',", "\n", "# 'hotel','luggage','smartphone','stove','TV']", "\n", "\n", "\n", "# with open('asc_random_19','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ninteen_domains)", "\n", "#         f_random_seq.writelines('\\t'.join(ninteen_domains) + '\\n')", "\n", "\n", "# with open('asc_random_10','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ten_domains)", "\n", "#         f_random_seq.writelines('\\t'.join(ten_domains) + '\\n')", "\n", "\n", "# with open('ner_random','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ner_domains_6)", "\n", "#         f_random_seq.writelines('\\t'.join(ner_domains_6) + '\\n')", "\n", "\n", "# with open('ner_random','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ner_domains_full)", "\n", "#         f_random_seq.writelines('\\t'.join(ner_domains_full) + '\\n')", "\n", "\n", "\n", "# with open('ner_random_overlap','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ner_domains_overlap)", "\n", "#         f_random_seq.writelines('\\t'.join(ner_domains_overlap) + '\\n')", "\n", "\n", "# with open('nli_random','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(nli_domains)", "\n", "#         f_random_seq.writelines('\\t'.join(nli_domains) + '\\n')", "\n", "\n", "# with open('dsc_random_10','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(dsc_domains_10)", "\n", "#         f_random_seq.writelines('\\t'.join(dsc_domains_10) + '\\n')", "\n", "\n", "# with open('ssc_random','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(ssc_domains)", "\n", "#         f_random_seq.writelines('\\t'.join(ssc_domains) + '\\n')", "\n", "\n", "\n", "# newsgroup_domains_10 = ['newsgroup_'+str(x) for x in range(10)]", "\n", "# with open('newsgroup_random_10','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(newsgroup_domains_10)", "\n", "#         f_random_seq.writelines('\\t'.join(newsgroup_domains_10) + '\\n')", "\n", "\n", "#", "\n", "# celeba_10 = ['celeba-'+str(x) for x in range(10)]", "\n", "#", "\n", "# with open('celeba_10','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(celeba_10)", "\n", "#         f_random_seq.writelines('\\t'.join(celeba_10) + '\\n')", "\n", "\n", "# femnist_10 = ['femnist-'+str(x) for x in range(10)]", "\n", "#", "\n", "# with open('femnist_10','w') as f_random_seq:", "\n", "#     for repeat_num in range(20):", "\n", "#         random.shuffle(femnist_10)", "\n", "#         f_random_seq.writelines('\\t'.join(femnist_10) + '\\n')", "\n", "\n", "femnist_20", "=", "[", "'femnist-'", "+", "str", "(", "x", ")", "for", "x", "in", "range", "(", "20", ")", "]", "\n", "\n", "with", "open", "(", "'femnist_20'", ",", "'w'", ")", "as", "f_random_seq", ":", "\n", "        ", "for", "repeat_num", "in", "range", "(", "20", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "femnist_20", ")", "\n", "f_random_seq", ".", "writelines", "(", "'\\t'", ".", "join", "(", "femnist_20", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.statistic.read_bing_reviews": [[9, 23], ["open", "json.load", "json.load.items", "aspects.append", "sentiments.append", "sentences.append"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "read_bing_reviews", "(", "location", ")", ":", "\n", "    ", "num_sentence", "=", "0", "\n", "sentences", "=", "[", "]", "\n", "sentiments", "=", "[", "]", "\n", "aspects", "=", "[", "]", "\n", "\n", "with", "open", "(", "location", ",", "'r'", ")", "as", "review_file", ":", "\n", "        ", "instance", "=", "json", ".", "load", "(", "review_file", ")", "\n", "for", "id", ",", "ins", "in", "instance", ".", "items", "(", ")", ":", "\n", "            ", "if", "ins", "[", "'term'", "]", "==", "'NULL'", ":", "continue", "\n", "aspects", ".", "append", "(", "ins", "[", "'term'", "]", ")", "\n", "sentiments", ".", "append", "(", "ins", "[", "'polarity'", "]", ")", "\n", "sentences", ".", "append", "(", "ins", "[", "'sentence'", "]", ")", "\n", "", "", "return", "sentences", ",", "aspects", ",", "sentiments", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.statistic.read_xu_semseval14": [[26, 39], ["open", "json.load", "json.load.items", "aspects.append", "sentiments.append", "sentences.append"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_xu_semseval14", "(", "location", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "sentiments", "=", "[", "]", "\n", "aspects", "=", "[", "]", "\n", "\n", "with", "open", "(", "location", ",", "'r'", ")", "as", "review_file", ":", "\n", "        ", "instance", "=", "json", ".", "load", "(", "review_file", ")", "\n", "for", "id", ",", "ins", "in", "instance", ".", "items", "(", ")", ":", "\n", "            ", "if", "ins", "[", "'term'", "]", "==", "'NULL'", ":", "continue", "\n", "aspects", ".", "append", "(", "ins", "[", "'term'", "]", ")", "\n", "sentiments", ".", "append", "(", "ins", "[", "'polarity'", "]", ")", "\n", "sentences", ".", "append", "(", "ins", "[", "'sentence'", "]", ")", "\n", "", "", "return", "sentences", ",", "aspects", ",", "sentiments", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.statistic.statistic": [[43, 67], ["print", "print", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "list", "list", "set", "str", "set", "str", "str", "str", "str"], "function", ["None"], ["", "def", "statistic", "(", "sentences", ",", "aspects", ",", "sentiments", ")", ":", "\n", "    ", "'''\n    #sentences\n    #postive\n    #negative\n    #neutral\n    #aspects\n\n    '''", "\n", "print", "(", "'#sentences: '", ",", "len", "(", "list", "(", "set", "(", "sentences", ")", ")", ")", ")", "\n", "print", "(", "'#aspects: '", ",", "len", "(", "aspects", ")", ")", "\n", "print", "(", "'#postive: '", ",", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'positive'", "or", "s", "==", "'+'", "]", ")", ")", "\n", "print", "(", "'#negative: '", ",", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'negative'", "or", "s", "==", "'-'", "]", ")", ")", "\n", "print", "(", "'#neutral: '", ",", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'neutral'", "or", "s", "==", "'='", "]", ")", ")", "\n", "\n", "num_sentences", "=", "len", "(", "list", "(", "set", "(", "sentences", ")", ")", ")", "\n", "num_aspects", "=", "len", "(", "aspects", ")", "\n", "num_positive", "=", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'positive'", "or", "s", "==", "'+'", "]", ")", "\n", "num_negative", "=", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'negative'", "or", "s", "==", "'-'", "]", ")", "\n", "num_neutral", "=", "len", "(", "[", "s", "for", "s", "in", "sentiments", "if", "s", "==", "'neutral'", "or", "s", "==", "'='", "]", ")", "\n", "\n", "\n", "return", "str", "(", "num_sentences", ")", "+", "' S./'", "+", "str", "(", "num_aspects", ")", "+", "' A./'", "+", "str", "(", "num_positive", ")", "+", "' P./'", "+", "str", "(", "num_negative", ")", "+", "' N./'", "+", "str", "(", "num_neutral", ")", "+", "' Ne.'", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.prep_nli.parse_nli": [[20, 39], ["open", "senetence_file.readlines", "corpus.append", "sentence.split", "sentence.split", "sentence.split", "sentence.split"], "function", ["None"], ["def", "parse_nli", "(", "fn", ",", "domain", ")", ":", "\n", "    ", "id", "=", "0", "\n", "corpus", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "senetence_file", ":", "\n", "        ", "sentences", "=", "senetence_file", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "if", "sentence", ".", "split", "(", "'\\t'", ")", "[", "9", "]", "!=", "domain", ":", "continue", "\n", "sentence1", "=", "sentence", ".", "split", "(", "'\\t'", ")", "[", "5", "]", "\n", "sentence2", "=", "sentence", ".", "split", "(", "'\\t'", ")", "[", "6", "]", "\n", "label", "=", "sentence", ".", "split", "(", "'\\t'", ")", "[", "0", "]", "\n", "\n", "# print('sentence1: ',sentence1)", "\n", "# print('sentence2: ',sentence2)", "\n", "# print('label: ',label)", "\n", "#", "\n", "if", "label", "not", "in", "polar_idx", ":", "continue", "\n", "corpus", ".", "append", "(", "{", "\"id\"", ":", "id", ",", "\"sentence\"", ":", "sentence1", ",", "\"term\"", ":", "sentence2", ",", "\"polarity\"", ":", "label", "}", ")", "\n", "id", "+=", "1", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.prep_dsc.parse_nli": [[19, 38], ["open", "senetence_file.readlines", "[].replace", "corpus.append", "sentence.split", "sentence.split"], "function", ["None"], ["def", "parse_nli", "(", "fn", ",", "train_data_size", "=", "None", ")", ":", "\n", "    ", "id", "=", "0", "\n", "corpus", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "senetence_file", ":", "\n", "        ", "sentences", "=", "senetence_file", ".", "readlines", "(", ")", "\n", "\n", "# if train_data_size is not None: #TODO: if you want cut", "\n", "#     random.Random(0).shuffle(sentences) #more robust", "\n", "#     sentences = sentences[:train_data_size]", "\n", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "sentence1", "=", "sentence", ".", "split", "(", "'\\t'", ")", "[", "0", "]", "\n", "label", "=", "sentence", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "# print('label: ',label)", "\n", "#", "\n", "if", "label", "not", "in", "polar_idx", ":", "continue", "\n", "corpus", ".", "append", "(", "{", "\"id\"", ":", "id", ",", "\"sentence\"", ":", "sentence1", ",", "\"term\"", ":", "None", ",", "\"polarity\"", ":", "label", "}", ")", "\n", "id", "+=", "1", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.prep_asc.parse_Bing": [[22, 51], ["open", "review_file.readlines", "set", "[].replace", "enumerate", "review.split", "aspect_str.split", "corpus.append", "set.add", "set.add", "review.split", "review.split", "each_aspect.split", "aspect_str.split", "review.split", "each_aspect.split", "aspect_str.split"], "function", ["None"], ["def", "parse_Bing", "(", "fn", ")", ":", "\n", "    ", "id", "=", "0", "\n", "corpus", "=", "[", "]", "\n", "with", "open", "(", "fn", ",", "'r'", ")", "as", "review_file", ":", "\n", "        ", "reviews", "=", "review_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "            ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "# print(review.split('##')[0])", "\n", "                ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "#aspects: may be more than one", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                    ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                        ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                    ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                    ", "corpus", ".", "append", "(", "{", "\"id\"", ":", "id", ",", "\"sentence\"", ":", "current_sentence", ",", "\"term\"", ":", "opin", "[", "0", "]", ",", "\"polarity\"", ":", "opin", "[", "-", "1", "]", "}", ")", "\n", "id", "+=", "1", "\n", "", "", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.tools.prep_ssc.parse_nli": [[26, 40], ["open", "senetence_file.readlines", "sentence[].replace", "sentence[].replace", "corpus.append"], "function", ["None"], ["def", "parse_nli", "(", "fn", ")", ":", "\n", "    ", "id", "=", "0", "\n", "corpus", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "senetence_file", ":", "\n", "        ", "sentences", "=", "senetence_file", ".", "readlines", "(", ")", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "sentence1", "=", "sentence", "[", "1", ":", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "label", "=", "sentence", "[", "0", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "# print('label: ',label)", "\n", "#", "\n", "if", "label", "not", "in", "polar_idx", ":", "continue", "\n", "corpus", ".", "append", "(", "{", "\"id\"", ":", "id", ",", "\"sentence\"", ":", "sentence1", ",", "\"term\"", ":", "None", ",", "\"polarity\"", ":", "label", "}", ")", "\n", "id", "+=", "1", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.__init__": [[12, 31], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "bert_kim_cat.MainContinualLearning", "bert_kim_cat.TransferLayer", "bert_kim_cat.KnowledgeTransfer", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "mcl", "=", "MainContinualLearning", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "transfer", "=", "TransferLayer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "kt", "=", "KnowledgeTransfer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "smax", "=", "args", ".", "smax", "\n", "\n", "\n", "print", "(", "'bert + KIM + HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.mcl_feature": [[33, 58], ["bert_kim_cat.Net.mcl.bert", "sequence_output.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_kim_cat.Net.view", "bert_kim_cat.Net.dropout", "bert_kim_cat.Net.dropout", "gc1.unsqueeze().expand_as", "gc2.unsqueeze().expand_as", "gc3.unsqueeze().expand_as", "sequence_output.size", "bert_kim_cat.Net.relu", "gfc1.expand_as", "bert_kim_cat.Net.relu", "gfc2.expand_as", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "bert_kim_cat.Net.mcl.fc1", "bert_kim_cat.Net.mcl.fc2", "torch.relu", "torch.relu", "gc1.unsqueeze", "torch.relu", "torch.relu", "gc2.unsqueeze", "torch.relu", "torch.relu", "gc3.unsqueeze", "bert_kim_cat.Net.mcl.c1", "bert_kim_cat.Net.mcl.c2", "bert_kim_cat.Net.mcl.c3"], "methods", ["None"], ["", "def", "mcl_feature", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "\n", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "mcl", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "mcl", ".", "WORD_DIM", "*", "self", ".", "args", ".", "max_seq_length", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c1", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "mcl", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h1", "=", "h1", "*", "gc1", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h1", ")", "\n", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c2", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "mcl", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h2", "=", "h2", "*", "gc2", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h2", ")", "\n", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c3", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "mcl", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "h3", "=", "h3", "*", "gc3", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h3", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.forward": [[60, 213], ["bert_kim_cat.Net.mask", "bert_kim_cat.Net.mcl_feature", "bert_kim_cat.Net.mcl.mask_last", "bert_kim_cat.Net.mask", "bert_kim_cat.Net.mcl_feature", "range", "bert_kim_cat.Net.mask", "gc1.data.clone", "gc2.data.clone", "gc3.data.clone", "gfc1.data.clone", "gfc2.data.clone", "bert_kim_cat.Net.mcl_feature", "pre_models.append", "pre_ts.append", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "task_models.permute.permute.permute", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "bert_kim_cat.Net.kt.encoder", "bert_kim_cat.Net.mcl_feature", "bert_kim_cat.Net.append", "bert_kim_cat.Net.clone", "bert_kim_cat.Net.relu().expand", "bert_kim_cat.Net.mcl.mask_last", "bert_kim_cat.Net.mcl.att_last", "bert_kim_cat.Net.Tsim_mask", "bert_kim_cat.Net.mcl_feature", "bert_kim_cat.Net.mcl_feature", "task_models.permute.permute.size", "bert_kim_cat.Net.mcl.mask_last", "bert_kim_cat.Net.mcl.mask_last", "bert_kim_cat.Net.mcl.att_last", "bert_kim_cat.Net.mcl.mask_last", "check_federated.check_t", "bert_kim_cat.Net.relu", "bert_kim_cat.Net.append", "bert_kim_cat.Net.append", "bert_kim_cat.Net.append", "bert_kim_cat.Net.mcl.mask_last", "bert_kim_cat.Net.kt.q1", "bert_kim_cat.Net.append", "bert_kim_cat.Net.append", "bert_kim_cat.Net.append", "bert_kim_cat.Net.append", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.check_t", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", ",", "phase", "=", "None", ",", "\n", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ",", "\n", "similarity", "=", "None", ",", "history_mask_pre", "=", "None", ",", "check_federated", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "\n", "if", "'mcl'", "in", "phase", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "h", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "\n", "", "elif", "'mcl'", "in", "phase", "and", "'multi-loss-joint-Tsim'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "pre_models", "=", "[", "]", "\n", "\n", "pre_ts", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "if", "self", ".", "training", "==", "True", "and", "similarity", "[", "pre_t", "]", ":", "\n", "                    ", "continue", "\n", "", "elif", "self", ".", "training", "==", "False", "and", "check_federated", ".", "check_t", "(", "pre_t", ")", "==", "False", ":", "\n", "                    ", "continue", "\n", "\n", "", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "pre_t", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "pre_gc1", "=", "gc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc2", "=", "gc2", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc3", "=", "gc3", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc1", "=", "gfc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc2", "=", "gfc2", ".", "data", ".", "clone", "(", ")", "\n", "\n", "pre_h", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "pre_gc1", ",", "pre_gc2", ",", "pre_gc3", ",", "pre_gfc1", ",", "pre_gfc2", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "pre_ts", ".", "append", "(", "pre_t", ")", "\n", "#Tsim: model for each Tsim", "\n", "\n", "", "if", "len", "(", "pre_models", ")", ">", "1", ":", "\n", "                ", "task_models", "=", "torch", ".", "stack", "(", "pre_models", ")", "\n", "task_models", "=", "task_models", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "query", "=", "torch", ".", "unsqueeze", "(", "self", ".", "relu", "(", "self", ".", "kt", ".", "q1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ".", "expand", "(", "task_models", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "#hard to train", "\n", "\n", "h_attn", ",", "_", "=", "self", ".", "kt", ".", "encoder", "(", "task_models", ",", "query", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                        ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "if", "'no-isolate'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "history_mask_pre", ",", "similarity", "=", "similarity", ")", "\n", "\n", "h_attn", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "transfer", ".", "last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.mask": [[215, 224], ["bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.mcl.ec1", "bert_kim_cat.Net.mcl.ec2", "bert_kim_cat.Net.mcl.ec3", "bert_kim_cat.Net.mcl.efc1", "bert_kim_cat.Net.mcl.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ",", "phase", "=", "None", ")", ":", "\n", "#used by training", "\n", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.Tsim_mask": [[226, 260], ["range", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "bert_kim_cat.Net.gate", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "bert_kim_cat.Net.mcl.ec1", "bert_kim_cat.Net.mcl.ec2", "bert_kim_cat.Net.mcl.ec3", "bert_kim_cat.Net.mcl.efc1", "bert_kim_cat.Net.mcl.efc2", "[].round", "[].round", "[].round", "[].round", "[].round", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "Tsim_mask", "(", "self", ",", "t", ",", "history_mask_pre", "=", "None", ",", "similarity", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "#find the distinct mask, used by block the backward pass", "\n", "\n", "#want aggregate Tsim", "\n", "        ", "if", "phase", "is", "None", ":", "\n", "#Tsim mask", "\n", "            ", "Tsim_gc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc3", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "\n", "\n", "", "for", "history_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "history_t", "==", "0", ":", "\n", "                ", "Tsim_gc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "else", ":", "\n", "                ", "Tsim_gc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "0", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "1", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "2", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "3", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "4", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "if", "similarity", "[", "history_t", "]", "==", "0", ":", "\n", "                ", "Tsim_gc1", "[", "Tsim_gc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc2", "[", "Tsim_gc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc3", "[", "Tsim_gc3_index", "[", ":", ",", "0", "]", ",", "Tsim_gc3_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc1", "[", "Tsim_gfc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc2", "[", "Tsim_gfc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "\n", "", "", "return", "[", "Tsim_gc1", ",", "Tsim_gc2", ",", "Tsim_gc3", ",", "Tsim_gfc1", ",", "Tsim_gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.Net.get_view_for": [[263, 296], ["gc1.data.view().expand_as", "gc1.data.view", "gc1.data.view", "gc2.data.view().expand_as", "gc2.data.view", "gc2.data.view", "gc3.data.view().expand_as", "gc3.data.view", "gc3.data.view", "gfc1.data.view().expand_as", "gc3.data.view().expand().contiguous().view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc1.data.view", "gfc1.data.view", "gc3.data.view().expand().contiguous().view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gc3.data.view().expand().contiguous", "gfc2.data.view", "gfc1.data.view", "gc3.data.view().expand", "gc3.data.view", "bert_kim_cat.Net.mcl.ec3.weight.size"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'mcl.c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'mcl.c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c2", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'mcl.c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'mcl.c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "mcl", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "3", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.MainContinualLearning.__init__": [[301, 344], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim_cat.MainContinualLearning.bert.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_cat.MainContinualLearning.mask_last.append", "bert_kim_cat.MainContinualLearning.att_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "MainContinualLearning", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "bert_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "mask_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "att_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.TransferLayer.__init__": [[348, 409], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim_cat.TransferLayer.bert.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_cat.TransferLayer.transfer.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_cat.TransferLayer.transfer_to_n.append", "bert_kim_cat.TransferLayer.last.append", "bert_kim_cat.TransferLayer.last_fusion.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_cat.TransferLayer.transfer.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bert_kim_cat.TransferLayer.transfer_to_n.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "TransferLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "bert_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "self", ".", "fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", "*", "2", ",", "args", ".", "bert_hidden_size", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", "*", "2", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "# this one will not change according to different scenario", "\n", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "args", ".", "nclasses", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "last_fusion", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "from_n", ",", "to_n", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.KnowledgeTransfer.__init__": [[412, 419], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "bert_kim_cat.EncoderLayer", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "KnowledgeTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nhid", "=", "args", ".", "bert_hidden_size", "\n", "#self-attention ==============", "\n", "self", ".", "q1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "encoder", "=", "EncoderLayer", "(", "args", ".", "n_head", ",", "nhid", ",", "nhid", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "args", "=", "args", ")", "\n", "# n_head, d_model, d_k, d_v", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.EncoderLayer.__init__": [[425, 433], ["torch.nn.Module.__init__", "bert_kim_cat.MultiHeadAttention", "bert_kim_cat.PositionwiseFeedForward", "bert_kim_cat.PositionalEncoding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_inner", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.EncoderLayer.forward": [[434, 448], ["bert_kim_cat.EncoderLayer.layer_norm", "bert_kim_cat.EncoderLayer.slf_attn", "bert_kim_cat.EncoderLayer.pos_ffn", "bert_kim_cat.EncoderLayer.slf_attn", "bert_kim_cat.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "enc_q", "=", "None", ",", "ranking", "=", "None", ")", ":", "\n", "#TODO: Positional/ranking embedding", "\n", "\n", "        ", "if", "enc_q", "is", "None", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_input", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "else", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_q", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.MultiHeadAttention.__init__": [[452, 468], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bert_kim_cat.ScaledDotProductAttention", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "#sqrt d_k", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.MultiHeadAttention.forward": [[470, 504], ["torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "bert_kim_cat.MultiHeadAttention.layer_norm", "bert_kim_cat.MultiHeadAttention.w_qs().view", "bert_kim_cat.MultiHeadAttention.w_ks().view", "bert_kim_cat.MultiHeadAttention.w_vs().view", "bert_kim_cat.MultiHeadAttention.attention", "bert_kim_cat.MultiHeadAttention.dropout", "q.transpose().contiguous().view.transpose().contiguous().view.size", "q.transpose().contiguous().view.transpose().contiguous().view.size", "bert_kim_cat.MultiHeadAttention.size", "bert_kim_cat.MultiHeadAttention.size", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "bert_kim_cat.MultiHeadAttention.transpose", "bert_kim_cat.MultiHeadAttention.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "bert_kim_cat.MultiHeadAttention.fc", "bert_kim_cat.MultiHeadAttention.w_qs", "bert_kim_cat.MultiHeadAttention.w_ks", "bert_kim_cat.MultiHeadAttention.w_vs", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "torch", ".", "squeeze", "(", "q", ",", "1", ")", "\n", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "\n", "q", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "\n", "if", "len_q", "==", "1", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "\n", "", "q", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "q", ")", ")", "\n", "q", "+=", "residual", "\n", "\n", "return", "q", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.ScaledDotProductAttention.__init__": [[508, 512], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.ScaledDotProductAttention.forward": [[513, 520], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "bert_kim_cat.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.PositionwiseFeedForward.__init__": [[524, 530], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "# position-wise", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.PositionwiseFeedForward.forward": [[531, 541], ["bert_kim_cat.PositionwiseFeedForward.layer_norm", "bert_kim_cat.PositionwiseFeedForward.w_2", "bert_kim_cat.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "bert_kim_cat.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "w_2", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "+=", "residual", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.PositionalEncoding.__init__": [[545, 550], ["torch.nn.Module.__init__", "bert_kim_cat.PositionalEncoding.register_buffer", "bert_kim_cat.PositionalEncoding._get_sinusoid_encoding_table"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding._get_sinusoid_encoding_table"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "n_position", "=", "40", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Not a parameter", "\n", "self", ".", "register_buffer", "(", "'pos_table'", ",", "self", ".", "_get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.PositionalEncoding._get_sinusoid_encoding_table": [[551, 563], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "bert_kim_cat.PositionalEncoding._get_sinusoid_encoding_table.get_position_angle_vec"], "methods", ["None"], ["", "def", "_get_sinusoid_encoding_table", "(", "self", ",", "n_position", ",", "d_hid", ")", ":", "\n", "        ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy", "\n", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "            ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_cat.PositionalEncoding.forward": [[564, 566], ["bert_kim_cat.PositionalEncoding.pos_table[].clone().detach", "bert_kim_cat.PositionalEncoding.pos_table[].clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "ranking", ")", ":", "\n", "        ", "return", "enc_input", "+", "self", ".", "pos_table", "[", ":", ",", "ranking", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter.Net.__init__": [[13, 67], ["super().__init__", "transformers.BertConfig.from_pretrained", "my_transformers.MyBertModel.from_pretrained", "bert_adapter.Net.bert.parameters", "torch.nn.Dropout", "torch.nn.Dropout", "print", "adapter.parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_adapter.Net.last.append", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "range", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "args", ".", "build_adapter", "=", "True", "\n", "self", ".", "bert", "=", "MyBertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ",", "args", "=", "args", ")", "\n", "\n", "#BERT fixed all ===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "# param.requires_grad = True", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "#But adapter is open", "\n", "\n", "#Only adapters are trainable", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "self", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "", "for", "adapter", "in", "adaters", ":", "\n", "            ", "for", "param", "in", "adapter", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "args", "=", "args", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'BERT ADAPTER'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter.Net.forward": [[68, 87], ["bert_adapter.Net.bert", "bert_adapter.Net.dropout", "torch.normalize", "torch.normalize", "bert_adapter.Net.last", "bert_adapter.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "#shared head", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.__init__": [[15, 80], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "print", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_hat.Net.last.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_hat.Net.self_attns.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "cnn_hat.Net.self_attns_.append", "cnn_hat.Self_Attn"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "\n", "", "", "if", "'Attn-HCHP-Outside'", "in", "self", ".", "args", ".", "mix_type", ":", "\n", "            ", "if", "self", ".", "args", ".", "task_based", ":", "\n", "                ", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "                    ", "self", ".", "self_attns_", "=", "nn", ".", "ModuleList", "(", ")", "\n", "offset", "=", "0", "\n", "for", "n", "in", "range", "(", "args", ".", "naug", ")", ":", "\n", "                        ", "if", "n", ">", "1", ":", "offset", "+=", "1", "\n", "if", "t", "+", "1", "-", "offset", "==", "0", ":", "break", "\n", "self", ".", "self_attns_", ".", "append", "(", "Self_Attn", "(", "t", "+", "1", "-", "offset", ")", ")", "\n", "", "self", ".", "self_attns", ".", "append", "(", "self", ".", "self_attns_", ")", "\n", "\n", "", "", "", "\"\"\" (e.g., used in the compression experiments)\n        lo,hi=0,2\n        self.ec1.weight.data.uniform_(lo,hi)\n        self.ec2.weight.data.uniform_(lo,hi)\n        self.ec3.weight.data.uniform_(lo,hi)\n        self.efc1.weight.data.uniform_(lo,hi)\n        self.efc2.weight.data.uniform_(lo,hi)\n        #\"\"\"", "\n", "\n", "print", "(", "'DIL CNN HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.forward": [[81, 114], ["torch.normalize", "torch.normalize", "torch.normalize", "cnn_hat.Net.mask", "cnn_hat.Net.get_feature", "cnn_hat.Net.mask", "cnn_hat.Net.get_feature", "cnn_hat.Net.last", "cnn_hat.Net.self_attention_feature", "cnn_hat.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.self_attention_feature"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "start_mixup", "=", "None", ",", "s", "=", "None", ",", "l", "=", "None", ",", "idx", "=", "None", ",", "mix_type", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "\n", "if", "start_mixup", "and", "'Attn-HCHP-Outside'", "in", "mix_type", ":", "\n", "# print('attn type: ', self.args.attn_type)", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "if", "self", ".", "args", ".", "attn_type", "==", "'self'", ":", "\n", "                ", "h", "=", "self", ".", "self_attention_feature", "(", "t", ",", "x", ",", "h", ",", "l", ",", "idx", ",", "self", ".", "args", ".", "smax", ")", "\n", "\n", "", "", "else", ":", "\n", "# print('others: ')", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.self_attention_feature": [[115, 146], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pooled_output.sum.sum.sum", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pooled_output.sum.sum.sum", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cnn_hat.Net.mask", "cnn_hat.Net.get_feature", "cnn_hat.Net.unsqueeze().clone", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cnn_hat.Net.mask", "cnn_hat.Net.get_feature", "cnn_hat.Net.unsqueeze().clone", "pooled_output.sum.sum.unsqueeze().clone", "cnn_hat.Net.unsqueeze", "cnn_hat.Net.unsqueeze", "pooled_output.sum.sum.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature"], ["", "def", "self_attention_feature", "(", "self", ",", "t", ",", "x", ",", "pooled_output", ",", "order", ",", "idx", ",", "smax", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "feature_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "1", ")", "#softmax on task", "\n", "\n", "", "elif", "self", ".", "args", ".", "task_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "-", "1", ")", "\n", "pre_hs", "=", "torch", ".", "cat", "(", "[", "pre_hs", ",", "pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "]", ",", "-", "1", ")", "# include itselves", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "t", "]", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "-", "1", ")", "#softmax on task", "\n", "\n", "", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.get_feature": [[150, 163], ["cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "cnn_hat.Net.view", "cnn_hat.Net.drop2", "cnn_hat.Net.drop2", "cnn_hat.Net.drop1", "gc1.view().expand_as", "cnn_hat.Net.drop1", "gc2.view().expand_as", "cnn_hat.Net.drop2", "gc3.view().expand_as", "x.size", "cnn_hat.Net.relu", "gfc1.expand_as", "cnn_hat.Net.relu", "gfc2.expand_as", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.fc1", "cnn_hat.Net.fc2", "cnn_hat.Net.c1", "gc1.view", "cnn_hat.Net.c2", "gc2.view", "cnn_hat.Net.c3", "gc3.view"], "methods", ["None"], ["", "def", "get_feature", "(", "self", ",", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.get_feature_augment": [[166, 191], ["cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "cnn_hat.Net.view", "cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "cnn_hat.Net.maxpool", "h_b.view.view.view", "cnn_hat.Net.drop2", "cnn_hat.Net.drop2", "cnn_hat.Net.drop1", "gc1.view().expand_as", "cnn_hat.Net.drop1", "gc2.view().expand_as", "cnn_hat.Net.drop2", "gc3.view().expand_as", "x.size", "cnn_hat.Net.drop1", "gc1.view().expand_as", "cnn_hat.Net.drop1", "gc2.view().expand_as", "cnn_hat.Net.drop2", "gc3.view().expand_as", "x.size", "cnn_hat.Net.relu", "gfc1.expand_as", "cnn_hat.Net.relu", "gfc2.expand_as", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.relu", "cnn_hat.Net.fc1", "cnn_hat.Net.fc2", "cnn_hat.Net.c1", "gc1.view", "cnn_hat.Net.c2", "gc2.view", "cnn_hat.Net.c3", "gc3.view", "cnn_hat.Net.c1", "gc1.view", "cnn_hat.Net.c2", "gc2.view", "cnn_hat.Net.c3", "gc3.view"], "methods", ["None"], ["", "def", "get_feature_augment", "(", "self", ",", "x", ",", "x_b", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ",", "l", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "h_b", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h", "=", "l", "*", "h", "+", "(", "1", "-", "l", ")", "*", "h_b", "\n", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.mask": [[193, 200], ["cnn_hat.Net.gate", "cnn_hat.Net.gate", "cnn_hat.Net.gate", "cnn_hat.Net.gate", "cnn_hat.Net.gate", "cnn_hat.Net.ec1", "cnn_hat.Net.ec2", "cnn_hat.Net.ec3", "cnn_hat.Net.efc1", "cnn_hat.Net.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Net.get_view_for": [[201, 232], ["gfc1.data.view().expand_as", "gc3.data.view().expand().contiguous().view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gfc1.data.view", "gfc1.data.view", "gc3.data.view().expand().contiguous().view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gc3.data.view().expand().contiguous", "gfc2.data.view", "gfc1.data.view", "gc1.data.view().expand_as", "gc1.data.view", "gc3.data.view().expand", "gc1.data.view", "gc2.data.view().expand_as", "gc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gc2.data.view", "gc3.data.view", "cnn_hat.Net.ec3.weight.size", "gc2.data.view", "gc1.data.view", "gc3.data.view().expand_as", "gc2.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gc3.data.view", "gc3.data.view", "gc2.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "if", "n", "==", "'fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "self", ".", "smid", ",", "self", ".", "smid", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "pre", "=", "gc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "pre", "=", "gc2", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Self_Attn.__init__": [[239, 248], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "attn_size", ")", ":", "\n", "        ", "super", "(", "Self_Attn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Self_Attn.forward": [[249, 278], ["x.size", "cnn_hat.Self_Attn.query_conv().view().permute", "cnn_hat.Self_Attn.key_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "cnn_hat.Self_Attn.softmax", "cnn_hat.Self_Attn.value_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.view.view.view", "cnn_hat.Self_Attn.permute", "cnn_hat.Self_Attn.query_conv().view", "cnn_hat.Self_Attn.key_conv", "cnn_hat.Self_Attn.value_conv", "cnn_hat.Self_Attn.query_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n            inputs :\n                x : input feature maps( B,max_length,hidden_size)\n            returns :\n                out : self attention value + input feature\n                attention: B X N X N (N is Width*Height)\n        \"\"\"", "\n", "\n", "# print('x: ',x.size())", "\n", "m_batchsize", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "# print('energy: ',energy.size())", "\n", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "\n", "# attention =  F.gumbel_softmax(energy,hard=True,dim=-1)", "\n", "# print('attention: ',attention)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C X N", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "\n", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert.Net.__init__": [[11, 48], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "torch.nn.Dropout", "torch.nn.Dropout", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "'''\n        In case you want to fix some layers\n        '''", "\n", "#BERT fixed some ===========", "\n", "# modules = [self.bert.embeddings, self.bert.encoder.layer[:args.activate_layer_num]] #Replace activate_layer_num by what you want", "\n", "# modules = [self.bert.encoder.layer[-1]]", "\n", "#", "\n", "# for module in modules:", "\n", "#     for param in module.parameters():", "\n", "#         param.requires_grad = False", "\n", "\n", "#BERT fixed all ===========", "\n", "# for param in self.bert.parameters():", "\n", "#     param.requires_grad = False", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert.Net.forward": [[49, 68], ["bert.Net.bert", "bert.Net.dropout", "torch.normalize", "torch.normalize", "bert.Net.last", "bert.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.Net.__init__": [[10, 44], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_gru_kan.Net.bert.parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "bert_gru_kan.MCL", "bert_gru_kan.AC", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_gru_kan.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "mcl", "=", "MCL", "(", "args", ",", "taskcla", ")", "\n", "self", ".", "ac", "=", "AC", "(", "args", ",", "taskcla", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'BERT (Fixed) + GRU + KAN'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.Net.forward": [[45, 79], ["bert_gru_kan.Net.bert", "bert_gru_kan.Net.ac.mask", "bert_gru_kan.Net.mcl.gru", "bert_gru_kan.Net.relu", "bert_gru_kan.Net.last", "bert_gru_kan.Net.mcl.gru", "bert_gru_kan.Net.relu", "bert_gru_kan.Net.ac.gru", "bert_gru_kan.Net.relu", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bert_gru_kan.Net.expand_as", "bert_gru_kan.Net.expand_as", "bert_gru_kan.Net.append", "bert_gru_kan.Net.expand_as"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "which_type", ",", "s", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "gfc", "=", "self", ".", "ac", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "if", "which_type", "==", "'mcl'", ":", "\n", "            ", "mcl_output", ",", "mcl_hidden", "=", "self", ".", "mcl", ".", "gru", "(", "sequence_output", ")", "\n", "if", "t", "==", "0", ":", "mcl_hidden", "=", "mcl_hidden", "*", "torch", ".", "ones_like", "(", "gfc", ".", "expand_as", "(", "mcl_hidden", ")", ")", "# everyone open", "\n", "else", ":", "mcl_hidden", "=", "mcl_hidden", "*", "gfc", ".", "expand_as", "(", "mcl_hidden", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "mcl_hidden", ")", "\n", "\n", "", "elif", "which_type", "==", "'ac'", ":", "\n", "            ", "mcl_output", ",", "mcl_hidden", "=", "self", ".", "mcl", ".", "gru", "(", "sequence_output", ")", "\n", "mcl_output", "=", "self", ".", "relu", "(", "mcl_output", ")", "\n", "mcl_output", "=", "mcl_output", "*", "gfc", ".", "expand_as", "(", "mcl_output", ")", "\n", "ac_output", ",", "ac_hidden", "=", "self", ".", "ac", ".", "gru", "(", "mcl_output", ")", "\n", "h", "=", "self", ".", "relu", "(", "ac_hidden", ")", "\n", "\n", "#loss ==============", "\n", "\n", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.Net.get_view_for": [[80, 91], ["mask.data.view().expand_as", "mask.data.view().expand_as", "mask.data.view", "mask.data.view().repeat", "mask.data.view", "mask.data.view().repeat", "mask.data.view", "mask.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "mask", ")", ":", "\n", "        ", "if", "n", "==", "'mcl.gru.rnn.weight_ih_l0'", ":", "\n", "# print('not none')", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "gru", ".", "rnn", ".", "weight_ih_l0", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.weight_hh_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "gru", ".", "rnn", ".", "weight_hh_l0", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.bias_ih_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "-", "1", ")", ".", "repeat", "(", "3", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.bias_hh_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "-", "1", ")", ".", "repeat", "(", "3", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.AC.__init__": [[95, 108], ["torch.nn.Module.__init__", "bert_gru_kan.GRU", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "gru", "=", "GRU", "(", "\n", "embedding_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "n_layers", "=", "1", ",", "\n", "bidirectional", "=", "False", ",", "\n", "dropout", "=", "0.5", ",", "\n", "args", "=", "args", ")", "\n", "\n", "self", ".", "efc", "=", "torch", ".", "nn", ".", "Embedding", "(", "args", ".", "ntasks", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.AC.mask": [[110, 113], ["bert_gru_kan.AC.gate", "bert_gru_kan.AC.efc", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gfc", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "gfc", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.MCL.__init__": [[116, 126], ["torch.nn.Module.__init__", "bert_gru_kan.GRU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "gru", "=", "GRU", "(", "\n", "embedding_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "n_layers", "=", "1", ",", "\n", "bidirectional", "=", "False", ",", "\n", "dropout", "=", "0.5", ",", "\n", "args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.GRU.__init__": [[128, 139], ["torch.nn.Module.__init__", "torch.nn.GRU", "torch.nn.GRU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_dim", ",", "n_layers", ",", "\n", "bidirectional", ",", "dropout", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "\n", "hidden_dim", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_kan.GRU.forward": [[140, 146], ["bert_gru_kan.GRU.rnn", "hidden.view.view.view", "output.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "x", ")", "\n", "hidden", "=", "hidden", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "bert_hidden_size", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "max_seq_length", ",", "self", ".", "args", ".", "bert_hidden_size", ")", "\n", "\n", "return", "output", ",", "hidden", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.__init__": [[12, 31], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "w2v_kim_cat.MainContinualLearning", "w2v_kim_cat.TransferLayer", "w2v_kim_cat.KnowledgeTransfer", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "mcl", "=", "MainContinualLearning", "(", "taskcla", ",", "embeddings", ",", "args", ")", "\n", "self", ".", "transfer", "=", "TransferLayer", "(", "taskcla", ",", "embeddings", ",", "args", ")", "\n", "self", ".", "kt", "=", "KnowledgeTransfer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "smax", "=", "args", ".", "smax", "\n", "\n", "\n", "print", "(", "'W2V + KIM + HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.mcl_feature": [[33, 51], ["w2v_kim_cat.Net.mcl.sentence_embedding().float", "w2v_kim_cat.Net.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "w2v_kim_cat.Net.view", "w2v_kim_cat.Net.dropout", "w2v_kim_cat.Net.dropout", "w2v_kim_cat.Net.size", "w2v_kim_cat.Net.relu", "gfc1.expand_as", "w2v_kim_cat.Net.relu", "gfc2.expand_as", "w2v_kim_cat.Net.mcl.sentence_embedding", "sentence.size", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "w2v_kim_cat.Net.mcl.fc1", "w2v_kim_cat.Net.mcl.fc2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "w2v_kim_cat.Net.mcl.c1", "w2v_kim_cat.Net.mcl.c2", "w2v_kim_cat.Net.mcl.c3", "sentence.size", "sentence.size", "sentence.size"], "methods", ["None"], ["", "def", "mcl_feature", "(", "self", ",", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "sequence_output", "=", "self", ".", "mcl", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "mcl", ".", "WORD_DIM", "*", "sentence", ".", "size", "(", "1", ")", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c1", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "mcl", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c2", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "mcl", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "mcl", ".", "c3", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "mcl", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "mcl", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.forward": [[53, 206], ["w2v_kim_cat.Net.mask", "w2v_kim_cat.Net.mcl_feature", "w2v_kim_cat.Net.mcl.mask_last", "w2v_kim_cat.Net.mask", "w2v_kim_cat.Net.mcl_feature", "range", "w2v_kim_cat.Net.mask", "gc1.data.clone", "gc2.data.clone", "gc3.data.clone", "gfc1.data.clone", "gfc2.data.clone", "w2v_kim_cat.Net.mcl_feature", "pre_models.append", "pre_ts.append", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "task_models.permute.permute.permute", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "w2v_kim_cat.Net.kt.encoder", "w2v_kim_cat.Net.mcl_feature", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.clone", "w2v_kim_cat.Net.relu().expand", "w2v_kim_cat.Net.mcl.mask_last", "w2v_kim_cat.Net.mcl.att_last", "w2v_kim_cat.Net.Tsim_mask", "w2v_kim_cat.Net.mcl_feature", "w2v_kim_cat.Net.mcl_feature", "task_models.permute.permute.size", "w2v_kim_cat.Net.mcl.mask_last", "w2v_kim_cat.Net.mcl.mask_last", "w2v_kim_cat.Net.mcl.att_last", "w2v_kim_cat.Net.mcl.mask_last", "check_federated.check_t", "w2v_kim_cat.Net.relu", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.mcl.mask_last", "w2v_kim_cat.Net.kt.q1", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.append", "w2v_kim_cat.Net.append", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.check_t", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "t", ",", "term", ",", "sentence", ",", "s", ",", "phase", "=", "None", ",", "\n", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ",", "\n", "similarity", "=", "None", ",", "history_mask_pre", "=", "None", ",", "check_federated", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "\n", "if", "'mcl'", "in", "phase", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "h", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "\n", "", "elif", "'mcl'", "in", "phase", "and", "'multi-loss-joint-Tsim'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "pre_models", "=", "[", "]", "\n", "\n", "pre_ts", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "if", "self", ".", "training", "==", "True", "and", "similarity", "[", "pre_t", "]", ":", "\n", "                    ", "continue", "\n", "", "elif", "self", ".", "training", "==", "False", "and", "check_federated", ".", "check_t", "(", "pre_t", ")", "==", "False", ":", "\n", "                    ", "continue", "\n", "\n", "", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "pre_t", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "pre_gc1", "=", "gc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc2", "=", "gc2", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc3", "=", "gc3", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc1", "=", "gfc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc2", "=", "gfc2", ".", "data", ".", "clone", "(", ")", "\n", "\n", "pre_h", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "pre_gc1", ",", "pre_gc2", ",", "pre_gc3", ",", "pre_gfc1", ",", "pre_gfc2", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "pre_ts", ".", "append", "(", "pre_t", ")", "\n", "#Tsim: model for each Tsim", "\n", "\n", "", "if", "len", "(", "pre_models", ")", ">", "1", ":", "\n", "                ", "task_models", "=", "torch", ".", "stack", "(", "pre_models", ")", "\n", "task_models", "=", "task_models", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "query", "=", "torch", ".", "unsqueeze", "(", "self", ".", "relu", "(", "self", ".", "kt", ".", "q1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ".", "expand", "(", "task_models", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "#hard to train", "\n", "\n", "h_attn", ",", "_", "=", "self", ".", "kt", ".", "encoder", "(", "task_models", ",", "query", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                        ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "if", "'no-isolate'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "history_mask_pre", ",", "similarity", "=", "similarity", ")", "\n", "\n", "h_attn", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "sentence", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "transfer", ".", "last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.mask": [[208, 217], ["w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.mcl.ec1", "w2v_kim_cat.Net.mcl.ec2", "w2v_kim_cat.Net.mcl.ec3", "w2v_kim_cat.Net.mcl.efc1", "w2v_kim_cat.Net.mcl.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ",", "phase", "=", "None", ")", ":", "\n", "#used by training", "\n", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.Tsim_mask": [[219, 253], ["range", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "w2v_kim_cat.Net.gate", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "w2v_kim_cat.Net.mcl.ec1", "w2v_kim_cat.Net.mcl.ec2", "w2v_kim_cat.Net.mcl.ec3", "w2v_kim_cat.Net.mcl.efc1", "w2v_kim_cat.Net.mcl.efc2", "[].round", "[].round", "[].round", "[].round", "[].round", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "Tsim_mask", "(", "self", ",", "t", ",", "history_mask_pre", "=", "None", ",", "similarity", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "#find the distinct mask, used by block the backward pass", "\n", "\n", "#want aggregate Tsim", "\n", "        ", "if", "phase", "is", "None", ":", "\n", "#Tsim mask", "\n", "            ", "Tsim_gc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc3", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "\n", "\n", "", "for", "history_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "history_t", "==", "0", ":", "\n", "                ", "Tsim_gc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "else", ":", "\n", "                ", "Tsim_gc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "0", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "1", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "2", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "3", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "4", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "if", "similarity", "[", "history_t", "]", "==", "0", ":", "\n", "                ", "Tsim_gc1", "[", "Tsim_gc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc2", "[", "Tsim_gc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc3", "[", "Tsim_gc3_index", "[", ":", ",", "0", "]", ",", "Tsim_gc3_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc1", "[", "Tsim_gfc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc2", "[", "Tsim_gfc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "\n", "", "", "return", "[", "Tsim_gc1", ",", "Tsim_gc2", ",", "Tsim_gc3", ",", "Tsim_gfc1", ",", "Tsim_gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.Net.get_view_for": [[256, 289], ["gc1.data.view().expand_as", "gc1.data.view", "gc1.data.view", "gc2.data.view().expand_as", "gc2.data.view", "gc2.data.view", "gc3.data.view().expand_as", "gc3.data.view", "gc3.data.view", "gfc1.data.view().expand_as", "gc3.data.view().expand().contiguous().view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc1.data.view", "gfc1.data.view", "gc3.data.view().expand().contiguous().view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gc3.data.view().expand().contiguous", "gfc2.data.view", "gfc1.data.view", "gc3.data.view().expand", "gc3.data.view", "w2v_kim_cat.Net.mcl.ec3.weight.size"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'mcl.c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'mcl.c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c2", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'mcl.c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'mcl.c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'mcl.fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "mcl", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "3", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.MainContinualLearning.__init__": [[294, 335], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim_cat.MainContinualLearning.sentence_embedding.parameters", "w2v_kim_cat.MainContinualLearning.aspect_embedding.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_cat.MainContinualLearning.mask_last.append", "w2v_kim_cat.MainContinualLearning.att_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "MainContinualLearning", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "w2v_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "mask_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "att_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.TransferLayer.__init__": [[339, 399], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim_cat.TransferLayer.sentence_embedding.parameters", "w2v_kim_cat.TransferLayer.aspect_embedding.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_cat.TransferLayer.transfer.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_cat.TransferLayer.transfer_to_n.append", "w2v_kim_cat.TransferLayer.last.append", "w2v_kim_cat.TransferLayer.last_fusion.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_cat.TransferLayer.transfer.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "w2v_kim_cat.TransferLayer.transfer_to_n.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "TransferLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "w2v_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "self", ".", "fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", "*", "2", ",", "args", ".", "w2v_hidden_size", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", "*", "2", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "# this one will not change according to different scenario", "\n", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "args", ".", "nclasses", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "last_fusion", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "from_n", ",", "to_n", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.KnowledgeTransfer.__init__": [[402, 409], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "w2v_kim_cat.EncoderLayer", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "KnowledgeTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nhid", "=", "args", ".", "w2v_hidden_size", "\n", "#self-attention ==============", "\n", "self", ".", "q1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "encoder", "=", "EncoderLayer", "(", "args", ".", "n_head", ",", "nhid", ",", "nhid", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "args", "=", "args", ")", "\n", "# n_head, d_model, d_k, d_v", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.EncoderLayer.__init__": [[415, 423], ["torch.nn.Module.__init__", "w2v_kim_cat.MultiHeadAttention", "w2v_kim_cat.PositionwiseFeedForward", "w2v_kim_cat.PositionalEncoding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_inner", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.EncoderLayer.forward": [[424, 438], ["w2v_kim_cat.EncoderLayer.layer_norm", "w2v_kim_cat.EncoderLayer.slf_attn", "w2v_kim_cat.EncoderLayer.pos_ffn", "w2v_kim_cat.EncoderLayer.slf_attn", "w2v_kim_cat.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "enc_q", "=", "None", ",", "ranking", "=", "None", ")", ":", "\n", "#TODO: Positional/ranking embedding", "\n", "\n", "        ", "if", "enc_q", "is", "None", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_input", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "else", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_q", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.MultiHeadAttention.__init__": [[442, 458], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "w2v_kim_cat.ScaledDotProductAttention", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "#sqrt d_k", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.MultiHeadAttention.forward": [[460, 494], ["torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "w2v_kim_cat.MultiHeadAttention.layer_norm", "w2v_kim_cat.MultiHeadAttention.w_qs().view", "w2v_kim_cat.MultiHeadAttention.w_ks().view", "w2v_kim_cat.MultiHeadAttention.w_vs().view", "w2v_kim_cat.MultiHeadAttention.attention", "w2v_kim_cat.MultiHeadAttention.dropout", "q.transpose().contiguous().view.transpose().contiguous().view.size", "q.transpose().contiguous().view.transpose().contiguous().view.size", "w2v_kim_cat.MultiHeadAttention.size", "w2v_kim_cat.MultiHeadAttention.size", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "w2v_kim_cat.MultiHeadAttention.transpose", "w2v_kim_cat.MultiHeadAttention.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "w2v_kim_cat.MultiHeadAttention.fc", "w2v_kim_cat.MultiHeadAttention.w_qs", "w2v_kim_cat.MultiHeadAttention.w_ks", "w2v_kim_cat.MultiHeadAttention.w_vs", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "torch", ".", "squeeze", "(", "q", ",", "1", ")", "\n", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "\n", "q", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "\n", "if", "len_q", "==", "1", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "\n", "", "q", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "q", ")", ")", "\n", "q", "+=", "residual", "\n", "\n", "return", "q", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.ScaledDotProductAttention.__init__": [[498, 502], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.ScaledDotProductAttention.forward": [[503, 510], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "w2v_kim_cat.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.PositionwiseFeedForward.__init__": [[514, 520], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "# position-wise", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.PositionwiseFeedForward.forward": [[521, 531], ["w2v_kim_cat.PositionwiseFeedForward.layer_norm", "w2v_kim_cat.PositionwiseFeedForward.w_2", "w2v_kim_cat.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "w2v_kim_cat.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "w_2", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "+=", "residual", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.PositionalEncoding.__init__": [[535, 540], ["torch.nn.Module.__init__", "w2v_kim_cat.PositionalEncoding.register_buffer", "w2v_kim_cat.PositionalEncoding._get_sinusoid_encoding_table"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding._get_sinusoid_encoding_table"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "n_position", "=", "40", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Not a parameter", "\n", "self", ".", "register_buffer", "(", "'pos_table'", ",", "self", ".", "_get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.PositionalEncoding._get_sinusoid_encoding_table": [[541, 553], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "w2v_kim_cat.PositionalEncoding._get_sinusoid_encoding_table.get_position_angle_vec"], "methods", ["None"], ["", "def", "_get_sinusoid_encoding_table", "(", "self", ",", "n_position", ",", "d_hid", ")", ":", "\n", "        ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy", "\n", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "            ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_cat.PositionalEncoding.forward": [[554, 556], ["w2v_kim_cat.PositionalEncoding.pos_table[].clone().detach", "w2v_kim_cat.PositionalEncoding.pos_table[].clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "ranking", ")", ":", "\n", "        ", "return", "enc_input", "+", "self", ".", "pos_table", "[", ":", ",", "ranking", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_ucl.Net.__init__": [[9, 42], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "bayes_layer.BayesianLinear", "bayes_layer.BayesianLinear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_ucl.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", "=", "0", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "\n", "self", ".", "fc1", "=", "BayesianLinear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "self", ".", "fc2", "=", "BayesianLinear", "(", "nhid", ",", "nhid", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'MLP'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_ucl.Net.forward": [[43, 62], ["mlp_ucl.Net.drop1", "mlp_ucl.Net.drop2", "mlp_ucl.Net.drop2", "torch.normalize", "torch.normalize", "x.view", "mlp_ucl.Net.relu", "mlp_ucl.Net.relu", "mlp_ucl.Net.last", "x.size", "mlp_ucl.Net.fc1", "mlp_ucl.Net.fc2", "mlp_ucl.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ",", "sample", ")", ")", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Shared.__init__": [[11, 35], ["super().__init__", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Shared", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "s", "*", "s", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Shared.forward": [[37, 46], ["x_s.view_as.view_as.view_as", "cnn_acl.Shared.maxpool", "cnn_acl.Shared.maxpool", "cnn_acl.Shared.maxpool", "cnn_acl.Shared.view", "cnn_acl.Shared.drop2", "cnn_acl.Shared.drop2", "cnn_acl.Shared.drop1", "cnn_acl.Shared.drop1", "cnn_acl.Shared.drop2", "x_s.view_as.view_as.size", "cnn_acl.Shared.relu", "cnn_acl.Shared.relu", "cnn_acl.Shared.relu", "cnn_acl.Shared.relu", "cnn_acl.Shared.relu", "cnn_acl.Shared.fc1", "cnn_acl.Shared.fc2", "cnn_acl.Shared.conv1", "cnn_acl.Shared.conv2", "cnn_acl.Shared.conv3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_s", ")", ":", "\n", "        ", "x_s", "=", "x_s", ".", "view_as", "(", "x_s", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x_s", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "conv3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x_s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Private.__init__": [[50, 86], ["super().__init__", "torch.nn.ModuleList", "range", "torch.nn.Sequential", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "utils.compute_conv_output_size", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "utils.compute_conv_output_size", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.conv.add_module", "utils.compute_conv_output_size", "cnn_acl.Private.conv.add_module", "cnn_acl.Private.task_out.append", "torch.nn.Sequential", "cnn_acl.Private.linear.add_module", "cnn_acl.Private.linear.add_module", "cnn_acl.Private.task_out.append", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Linear", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Private", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "\n", "self", ".", "task_out", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv1'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'relu1'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'drop1'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool1'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv2'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'relu2'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'dropout2'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool2'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv3'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'relu3'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'dropout3'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool3'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool2'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "self", ".", "task_out", ".", "append", "(", "self", ".", "conv", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "\n", "self", ".", "linear", ".", "add_module", "(", "'linear1'", ",", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "s", "*", "s", ",", "2048", ")", ")", "\n", "self", ".", "linear", ".", "add_module", "(", "'relu3'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "task_out", ".", "append", "(", "self", ".", "linear", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Private.forward": [[88, 96], ["x.view_as.view_as.view_as", "cnn_acl.Private.task_out[].forward", "cnn_acl.Private.view", "cnn_acl.Private.task_out[].forward", "cnn_acl.Private.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "t", ")", ":", "\n", "        ", "x", "=", "x", ".", "view_as", "(", "x", ")", "\n", "out", "=", "self", ".", "task_out", "[", "2", "*", "t", "]", ".", "forward", "(", "x", ")", "\n", "#TODO: check whether it is ok to use this in DIL. What is the different between use different head and different part", "\n", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "task_out", "[", "2", "*", "t", "+", "1", "]", ".", "forward", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Net.__init__": [[101, 134], ["super().__init__", "cnn_acl.Shared", "cnn_acl.Private", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ModuleList", "range", "cnn_acl.Net.last.append", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "self", ".", "shared", "=", "Shared", "(", "args", ")", "\n", "self", ".", "private", "=", "Private", "(", "args", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "args", ".", "nclasses", ")", "\n", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "taskcla", "[", "i", "]", "[", "1", "]", ")", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Net.forward": [[137, 159], ["cnn_acl.Net.view_as", "cnn_acl.Net.view_as", "cnn_acl.Net.shared", "cnn_acl.Net.private", "torch.cat", "cnn_acl.Net.last", "cnn_acl.Net.append"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x_s", ",", "x_p", ",", "tt", ",", "t", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "x_s", "=", "x_s", ".", "view_as", "(", "x_s", ")", "\n", "x_p", "=", "x_p", ".", "view_as", "(", "x_p", ")", "\n", "\n", "x_s", "=", "self", ".", "shared", "(", "x_s", ")", "\n", "x_p", "=", "self", ".", "private", "(", "x_p", ",", "t", ")", "# t decides which part of private to use", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x_p", ",", "x_s", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "x", ")", "\n", "\n", "", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "x", ")", ")", "\n", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Net.get_encoded_ftrs": [[162, 164], ["cnn_acl.Net.shared", "cnn_acl.Net.private"], "methods", ["None"], ["", "def", "get_encoded_ftrs", "(", "self", ",", "x_s", ",", "x_p", ",", "t", ")", ":", "\n", "        ", "return", "self", ".", "shared", "(", "x_s", ")", ",", "self", ".", "private", "(", "x_p", ",", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Net.print_model_size": [[165, 181], ["sum", "sum", "sum", "print", "print", "print", "print", "print", "print", "print", "print", "p.numel", "p.numel", "p.numel", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.private.parameters", "cnn_acl.Net.shared.parameters", "cnn_acl.Net.last.parameters", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print", "cnn_acl.Net.pretty_print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print"], ["", "def", "print_model_size", "(", "self", ")", ":", "\n", "        ", "count_P", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "private", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_S", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "shared", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_H", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "last", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "print", "(", "'Num parameters in S       = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_S", ")", ")", ")", "\n", "print", "(", "'Num parameters in P       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_P", ")", ",", "self", ".", "pretty_print", "(", "count_P", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in p       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_H", ")", ",", "self", ".", "pretty_print", "(", "count_H", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in P+p    = %s '", "%", "self", ".", "pretty_print", "(", "count_P", "+", "count_H", ")", ")", "\n", "print", "(", "'-------------------------->   Architecture size: %s parameters (%sB)'", "%", "(", "self", ".", "pretty_print", "(", "count_S", "+", "count_P", "+", "count_H", ")", ",", "\n", "self", ".", "pretty_print", "(", "4", "*", "(", "count_S", "+", "count_P", "+", "count_H", ")", ")", ")", ")", "\n", "\n", "print", "(", "\"-------------------------->   Memory size: %s samples per task (%sB)\"", "%", "(", "self", ".", "samples", ",", "\n", "self", ".", "pretty_print", "(", "self", ".", "num_tasks", "*", "4", "*", "self", ".", "samples", "*", "self", ".", "image_size", ")", ")", ")", "\n", "print", "(", "\"------------------------------------------------------------------------------\"", ")", "\n", "print", "(", "\"                               TOTAL:  %sB\"", "%", "self", ".", "pretty_print", "(", "4", "*", "(", "count_S", "+", "count_P", "+", "count_H", ")", "+", "self", ".", "num_tasks", "*", "4", "*", "self", ".", "samples", "*", "self", ".", "image_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Net.pretty_print": [[182, 188], ["abs"], "methods", ["None"], ["", "def", "pretty_print", "(", "self", ",", "num", ")", ":", "\n", "        ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "            ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.Net.__init__": [[10, 43], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_gru_kan.Net.sentence_embedding.parameters", "w2v_gru_kan.Net.aspect_embedding.parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "w2v_gru_kan.MCL", "w2v_gru_kan.AC", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_gru_kan.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "mcl", "=", "MCL", "(", "args", ",", "taskcla", ")", "\n", "self", ".", "ac", "=", "AC", "(", "args", ",", "taskcla", ")", "\n", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'W2V (Fixed) + GRU + KAN'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.Net.forward": [[44, 76], ["w2v_gru_kan.Net.sentence_embedding().float", "w2v_gru_kan.Net.ac.mask", "torch.normalize", "torch.normalize", "w2v_gru_kan.Net.mcl.gru", "w2v_gru_kan.Net.relu", "w2v_gru_kan.Net.last", "w2v_gru_kan.Net.sentence_embedding", "w2v_gru_kan.Net.mcl.gru", "w2v_gru_kan.Net.relu", "w2v_gru_kan.Net.ac.gru", "w2v_gru_kan.Net.relu", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "w2v_gru_kan.Net.expand_as", "w2v_gru_kan.Net.expand_as", "w2v_gru_kan.Net.append", "w2v_gru_kan.Net.expand_as"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "term", ",", "sentence", ",", "which_type", ",", "s", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "gfc", "=", "self", ".", "ac", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "if", "which_type", "==", "'mcl'", ":", "\n", "            ", "mcl_output", ",", "mcl_hidden", "=", "self", ".", "mcl", ".", "gru", "(", "sequence_output", ")", "\n", "if", "t", "==", "0", ":", "mcl_hidden", "=", "mcl_hidden", "*", "torch", ".", "ones_like", "(", "gfc", ".", "expand_as", "(", "mcl_hidden", ")", ")", "# everyone open", "\n", "else", ":", "mcl_hidden", "=", "mcl_hidden", "*", "gfc", ".", "expand_as", "(", "mcl_hidden", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "mcl_hidden", ")", "\n", "\n", "", "elif", "which_type", "==", "'ac'", ":", "\n", "            ", "mcl_output", ",", "mcl_hidden", "=", "self", ".", "mcl", ".", "gru", "(", "sequence_output", ")", "\n", "mcl_output", "=", "self", ".", "relu", "(", "mcl_output", ")", "\n", "mcl_output", "=", "mcl_output", "*", "gfc", ".", "expand_as", "(", "mcl_output", ")", "\n", "ac_output", ",", "ac_hidden", "=", "self", ".", "ac", ".", "gru", "(", "mcl_output", ")", "\n", "h", "=", "self", ".", "relu", "(", "ac_hidden", ")", "\n", "\n", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.Net.get_view_for": [[77, 88], ["mask.data.view().expand_as", "mask.data.view().expand_as", "mask.data.view", "mask.data.view().repeat", "mask.data.view", "mask.data.view().repeat", "mask.data.view", "mask.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "mask", ")", ":", "\n", "        ", "if", "n", "==", "'mcl.gru.rnn.weight_ih_l0'", ":", "\n", "# print('not none')", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "gru", ".", "rnn", ".", "weight_ih_l0", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.weight_hh_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "gru", ".", "rnn", ".", "weight_hh_l0", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.bias_ih_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "-", "1", ")", ".", "repeat", "(", "3", ")", "\n", "", "elif", "n", "==", "'mcl.gru.rnn.bias_hh_l0'", ":", "\n", "            ", "return", "mask", ".", "data", ".", "view", "(", "-", "1", ")", ".", "repeat", "(", "3", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.AC.__init__": [[92, 105], ["torch.nn.Module.__init__", "w2v_gru_kan.GRU", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "gru", "=", "GRU", "(", "\n", "embedding_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "n_layers", "=", "1", ",", "\n", "bidirectional", "=", "False", ",", "\n", "dropout", "=", "0.5", ",", "\n", "args", "=", "args", ")", "\n", "\n", "self", ".", "efc", "=", "torch", ".", "nn", ".", "Embedding", "(", "args", ".", "ntasks", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.AC.mask": [[107, 110], ["w2v_gru_kan.AC.gate", "w2v_gru_kan.AC.efc", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gfc", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "gfc", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.MCL.__init__": [[113, 123], ["torch.nn.Module.__init__", "w2v_gru_kan.GRU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "gru", "=", "GRU", "(", "\n", "embedding_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "n_layers", "=", "1", ",", "\n", "bidirectional", "=", "False", ",", "\n", "dropout", "=", "0.5", ",", "\n", "args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.GRU.__init__": [[125, 136], ["torch.nn.Module.__init__", "torch.nn.GRU", "torch.nn.GRU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_dim", ",", "n_layers", ",", "\n", "bidirectional", ",", "dropout", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "\n", "hidden_dim", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_kan.GRU.forward": [[137, 144], ["w2v_gru_kan.GRU.rnn", "hidden.view.view.view", "output.view.view.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "x", ")", "\n", "hidden", "=", "hidden", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "w2v_hidden_size", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "args", ".", "w2v_hidden_size", ")", "\n", "# output = output.view(-1,self.args.max_sentence_length,self.args.w2v_hidden_size)", "\n", "\n", "return", "output", ",", "hidden", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Net.__init__": [[13, 48], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_owm.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "padding", "=", "torch", ".", "nn", ".", "ReplicationPad2d", "(", "1", ")", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "4", "*", "4", ",", "1000", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "1000", ",", "bias", "=", "False", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'DIL CNN'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Net.forward": [[50, 94], ["cnn_owm.Net.padding", "x_list.append", "cnn_owm.Net.drop1", "cnn_owm.Net.maxpool", "cnn_owm.Net.padding", "x_list.append", "cnn_owm.Net.drop1", "cnn_owm.Net.maxpool", "cnn_owm.Net.padding", "x_list.append", "cnn_owm.Net.drop1", "cnn_owm.Net.maxpool", "cnn_owm.Net.view", "h_list.append", "cnn_owm.Net.relu", "h_list.append", "cnn_owm.Net.relu", "h_list.append", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.relu", "cnn_owm.Net.size", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.fc1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.fc2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cnn_owm.Net.last", "cnn_owm.Net.c1", "cnn_owm.Net.c2", "cnn_owm.Net.c3", "cnn_owm.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h_list", "=", "[", "]", "\n", "x_list", "=", "[", "]", "\n", "# Gated", "\n", "x", "=", "self", ".", "padding", "(", "x", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "x", ",", "0", ",", "True", ")", ")", "\n", "con1", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", "\n", "con1_p", "=", "self", ".", "maxpool", "(", "con1", ")", "\n", "\n", "con1_p", "=", "self", ".", "padding", "(", "con1_p", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "con1_p", ",", "0", ",", "True", ")", ")", "\n", "con2", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "con1_p", ")", ")", ")", "\n", "con2_p", "=", "self", ".", "maxpool", "(", "con2", ")", "\n", "\n", "con2_p", "=", "self", ".", "padding", "(", "con2_p", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "con2_p", ",", "0", ",", "True", ")", ")", "\n", "con3", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "con2_p", ")", ")", ")", "\n", "con3_p", "=", "self", ".", "maxpool", "(", "con3", ")", "\n", "\n", "h", "=", "con3_p", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "output_dict", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim.Net.__init__": [[10, 47], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim.Net.sentence_embedding.parameters", "w2v_kim.Net.aspect_embedding.parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'W2V + CNN'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim.Net.forward": [[48, 75], ["w2v_kim.Net.sentence_embedding().float", "w2v_kim.Net.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "w2v_kim.Net.view", "w2v_kim.Net.dropout", "torch.normalize", "torch.normalize", "w2v_kim.Net.size", "w2v_kim.Net.last", "w2v_kim.Net.sentence_embedding", "sentence.size", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "w2v_kim.Net.append", "w2v_kim.Net.c1", "w2v_kim.Net.c2", "w2v_kim.Net.c3", "sentence.size", "sentence.size", "sentence.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "term", ",", "sentence", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "sentence", ".", "size", "(", "1", ")", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c1", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "#loss ==============", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.__init__": [[17, 81], ["super().__init__", "transformers.BertConfig.from_pretrained", "my_transformers.MyBertModel.from_pretrained", "bert_adapter_mask.Net.bert.parameters", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "len", "torch.device", "torch.device", "torch.device", "torch.device", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "print", "adapter_mask.parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bert_adapter_mask.Net.self_attns.append", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_adapter_mask.Self_Attn", "bert_adapter_mask.Net.last.append", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "range", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "args", ".", "build_adapter_mask", "=", "True", "\n", "self", ".", "bert", "=", "MyBertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ",", "args", "=", "args", ")", "\n", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "# param.requires_grad = True", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "for", "adapter_mask", "in", "adapter_masks", ":", "\n", "            ", "for", "param", "in", "adapter_mask", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_task", "=", "len", "(", "taskcla", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "self", ".", "self_attns", ".", "append", "(", "Self_Attn", "(", "t", "+", "1", ")", ")", "\n", "\n", "\n", "", "print", "(", "' BERT ADAPTER MASK'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.forward": [[82, 112], ["torch.normalize", "torch.normalize", "bert_adapter_mask.Net.bert", "bert_adapter_mask.Net.mask", "bert_adapter_mask.Net.self_attention_feature", "bert_adapter_mask.Net.dropout", "bert_adapter_mask.Net.bert", "bert_adapter_mask.Net.mask", "bert_adapter_mask.Net.dropout", "bert_adapter_mask.Net.last", "bert_adapter_mask.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.self_attention_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "start_mixup", "=", "None", ",", "s", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "start_mixup", ":", "\n", "            ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "pooled_output", "=", "self", ".", "self_attention_feature", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "pooled_output", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.self_attention_feature": [[115, 131], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pooled_output.sum.sum.sum", "torch.cat.append", "torch.cat.append", "range", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_mask.Net.bert", "pre_pooled_output.unsqueeze().clone", "pooled_output.sum.sum.unsqueeze().clone", "pre_pooled_output.unsqueeze", "pooled_output.sum.sum.unsqueeze"], "methods", ["None"], ["", "def", "self_attention_feature", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "pooled_output", ")", ":", "\n", "        ", "pre_pooled_outputs", "=", "[", "]", "\n", "for", "pre_t", "in", "[", "x", "for", "x", "in", "range", "(", "t", ")", "]", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "pre_pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "pre_t", ",", "s", "=", "self", ".", "args", ".", "smax", ")", "\n", "", "pre_pooled_outputs", ".", "append", "(", "pre_pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "\n", "", "pre_pooled_outputs", "=", "torch", ".", "cat", "(", "pre_pooled_outputs", ",", "-", "1", ")", "\n", "pre_pooled_outputs", "=", "torch", ".", "cat", "(", "[", "pre_pooled_outputs", ",", "pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "]", ",", "-", "1", ")", "# include itselves", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "t", "]", "(", "pre_pooled_outputs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "-", "1", ")", "#softmax on task", "\n", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.mask": [[134, 149], ["range", "bert_adapter_mask.Net.bert.encoder.layer[].attention.output.adapter_mask.mask", "bert_adapter_mask.Net.bert.encoder.layer[].output.adapter_mask.mask", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "masks", "=", "{", "}", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "\n", "", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.last_mask": [[151, 155], ["bert_adapter_mask.Net.elast", "bert_adapter_mask.Net.gate", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "last_mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "elast", "=", "self", ".", "elast", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "glast", "=", "self", ".", "gate", "(", "s", "*", "elast", ")", "\n", "return", "glast", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Net.get_view_for": [[156, 183], ["range", "masks[].data.view().expand_as", "masks[].data.view", "str", "masks[].data.view", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "str", "masks[].data.view", "str", "masks[].data.view", "masks[].data.view", "masks[].data.view().expand_as", "str", "masks[].data.view", "n.replace", "str", "masks[].data.view", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "n.replace", "str", "masks[].data.view", "n.replace", "str", "masks[].data.view", "masks[].data.view", "n.replace", "n.replace().replace", "str", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace().replace", "n.replace"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "p", ",", "masks", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1.weight'", ":", "\n", "# print('not nont')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Self_Attn.__init__": [[187, 196], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Softmax", "torch.nn.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "attn_size", ")", ":", "\n", "        ", "super", "(", "Self_Attn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Self_Attn.forward": [[197, 226], ["x.size", "bert_adapter_mask.Self_Attn.query_conv().view().permute", "bert_adapter_mask.Self_Attn.key_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "bert_adapter_mask.Self_Attn.softmax", "bert_adapter_mask.Self_Attn.value_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.view.view.view", "bert_adapter_mask.Self_Attn.permute", "bert_adapter_mask.Self_Attn.query_conv().view", "bert_adapter_mask.Self_Attn.key_conv", "bert_adapter_mask.Self_Attn.value_conv", "bert_adapter_mask.Self_Attn.query_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n            inputs :\n                x : input feature maps( B,max_length,hidden_size)\n            returns :\n                out : self attention value + input feature\n                attention: B X N X N (N is Width*Height)\n        \"\"\"", "\n", "\n", "# print('x: ',x.size())", "\n", "m_batchsize", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "# print('energy: ',energy.size())", "\n", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "\n", "# attention =  F.gumbel_softmax(energy,hard=True,dim=-1)", "\n", "# print('attention: ',attention)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C X N", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "\n", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_ucl.Net.__init__": [[11, 45], ["torch.Module.__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim_ucl.Net.sentence_embedding.parameters", "w2v_kim_ucl.Net.aspect_embedding.parameters", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bayes_layer.BayesianConv2D", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_ucl.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "ratio", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "self", ".", "MAX_SENT_LEN", "=", "args", ".", "max_sentence_length", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "BayesianConv2D", "(", "1", ",", "100", ",", "(", "K", ",", "self", ".", "WORD_DIM", ")", ")", "for", "K", "in", "self", ".", "FILTERS", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'W2V + CNN UCL'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_ucl.Net.forward": [[46, 71], ["w2v_kim_ucl.Net.sentence_embedding().float", "w2v_kim_ucl.Net.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "w2v_kim_ucl.Net.dropout", "torch.normalize", "torch.normalize", "torch.normalize", "sentence.size", "torch.relu().squeeze", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "w2v_kim_ucl.Net.last", "w2v_kim_ucl.Net.sentence_embedding", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "w2v_kim_ucl.Net.append", "conv", "i.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "term", ",", "sentence", ",", "sample", "=", "False", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "sentence", ".", "size", "(", "1", ")", ",", "self", ".", "WORD_DIM", ")", "\n", "\n", "h", "=", "[", "F", ".", "relu", "(", "conv", "(", "h", ",", "sample", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs", "]", "# [(N, Co, W), ...]*len(Ks)", "\n", "h", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "h", "]", "# [(N, Co), ...]*len(Ks)", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "1", ")", "\n", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_owm.Net.__init__": [[13, 50], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim_owm.Net.bert.parameters", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_owm.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "self", ".", "MAX_SENT_LEN", "=", "args", ".", "max_seq_length", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "100", ",", "(", "K", ",", "self", ".", "WORD_DIM", ")", ")", "for", "K", "in", "self", ".", "FILTERS", "]", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "300", ",", "300", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "300", ",", "300", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_owm.Net.forward": [[51, 89], ["bert_kim_owm.Net.bert", "sequence_output.view", "x_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_kim_owm.Net.relu", "h_list.append", "bert_kim_owm.Net.relu", "h_list.append", "bert_kim_owm.Net.dropout", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu().squeeze", "torch.relu().squeeze", "torch.relu().squeeze", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bert_kim_owm.Net.fc1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bert_kim_owm.Net.fc2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bert_kim_owm.Net.last", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "bert_kim_owm.Net.append", "conv", "i.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "x_list", "=", "[", "]", "\n", "h_list", "=", "[", "]", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "args", ".", "max_seq_length", ",", "self", ".", "WORD_DIM", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "[", "F", ".", "relu", "(", "conv", "(", "h", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs", "]", "# [(N, Co, W), ...]*len(Ks)", "\n", "h", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "h", "]", "# [(N, Co), ...]*len(Ks)", "\n", "x_list", "+=", "[", "torch", ".", "mean", "(", "h_e", ",", "0", ",", "True", ")", "for", "h_e", "in", "h", "]", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "1", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_hat.Net.__init__": [[10, 57], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim_hat.Net.bert.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "print", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_hat.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "bert_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "bert_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'CONTEXTUAL + KIM + HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_hat.Net.forward": [[58, 102], ["bert_kim_hat.Net.bert", "bert_kim_hat.Net.mask", "sequence_output.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_kim_hat.Net.view", "bert_kim_hat.Net.dropout", "bert_kim_hat.Net.dropout", "torch.normalize", "torch.normalize", "gc1.unsqueeze().expand_as", "gc2.unsqueeze().expand_as", "gc3.unsqueeze().expand_as", "sequence_output.size", "bert_kim_hat.Net.relu", "gfc1.expand_as", "bert_kim_hat.Net.relu", "gfc2.expand_as", "bert_kim_hat.Net.last", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "bert_kim_hat.Net.fc1", "bert_kim_hat.Net.fc2", "torch.relu", "torch.relu", "gc1.unsqueeze", "torch.relu", "torch.relu", "gc2.unsqueeze", "torch.relu", "torch.relu", "gc3.unsqueeze", "bert_kim_hat.Net.append", "bert_kim_hat.Net.c1", "bert_kim_hat.Net.c2", "bert_kim_hat.Net.c3"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", ")", ":", "\n", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "self", ".", "args", ".", "max_seq_length", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c1", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h1", "=", "h1", "*", "gc1", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h1", ")", "\n", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h2", "=", "h2", "*", "gc2", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h2", ")", "\n", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "h3", "=", "h3", "*", "gc3", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "h3", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "#loss ==============", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_hat.Net.mask": [[103, 110], ["bert_kim_hat.Net.gate", "bert_kim_hat.Net.gate", "bert_kim_hat.Net.gate", "bert_kim_hat.Net.gate", "bert_kim_hat.Net.gate", "bert_kim_hat.Net.ec1", "bert_kim_hat.Net.ec2", "bert_kim_hat.Net.ec3", "bert_kim_hat.Net.efc1", "bert_kim_hat.Net.efc2"], "methods", ["None"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec1", "(", "t", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec2", "(", "t", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec3", "(", "t", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc1", "(", "t", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc2", "(", "t", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_hat.Net.get_view_for": [[112, 147], ["gc1.data.view().expand_as", "gc1.data.view", "gc1.data.view", "gc2.data.view().expand_as", "gc2.data.view", "gc2.data.view", "gc3.data.view().expand_as", "gc3.data.view", "gc3.data.view", "gfc1.data.view().expand_as", "gc3.data.view().expand().contiguous().view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc1.data.view", "gfc1.data.view", "gc3.data.view().expand().contiguous().view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gc3.data.view().expand().contiguous", "gfc2.data.view", "gfc1.data.view", "gc3.data.view().expand", "gc3.data.view", "bert_kim_hat.Net.ec3.weight.size"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "3", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "return", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.Net.__init__": [[12, 56], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_gru_srk.Net.bert.parameters", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "bert_gru_srk.FLN", "bert_gru_srk.KRN", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_gru_srk.Net.last.append", "bert_gru_srk.Net.krn_last.append", "bert_gru_srk.Net.fln_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fln", "=", "FLN", "(", "args", ",", "taskcla", ")", "\n", "self", ".", "krn", "=", "KRN", "(", "args", ",", "taskcla", ")", "\n", "\n", "\n", "self", ".", "fln_fc", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "bert_hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "krn_fc", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "bert_hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "krn_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "fln_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "krn_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fln_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "krn_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "fln_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'BERT (Fixed) + GRU + SRK'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.Net.forward": [[57, 95], ["bert_gru_srk.Net.bert", "bert_gru_srk.Net.fln.gru", "bert_gru_srk.Net.krn.gru", "bert_gru_srk.Net.gate", "control_1.data.clone", "control_2.data.clone", "control_3.data.clone", "bert_gru_srk.Net.last", "bert_gru_srk.Net.last", "bert_gru_srk.Net.last", "bert_gru_srk.Net.fln_fc", "bert_gru_srk.Net.krn_fc", "bert_gru_srk.Net.append", "bert_gru_srk.Net.append", "bert_gru_srk.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "\n", "fln_output", ",", "fln_hidden", ",", "c1", ",", "c2", ",", "c3", "=", "self", ".", "fln", ".", "gru", "(", "sequence_output", ")", "\n", "krn_output", ",", "krn_hidden", ",", "control_1", ",", "control_2", ",", "control_3", "=", "self", ".", "krn", ".", "gru", "(", "sequence_output", ")", "\n", "\n", "g", "=", "self", ".", "gate", "(", "self", ".", "fln_fc", "(", "fln_hidden", ")", "+", "self", ".", "krn_fc", "(", "krn_hidden", ")", ")", "\n", "h", "=", "(", "1", "-", "g", ")", "*", "fln_hidden", "+", "g", "*", "(", "krn_hidden", ")", "\n", "\n", "#loss ==============", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "krn_y", "=", "self", ".", "last", "(", "krn_hidden", ")", "\n", "fln_y", "=", "self", ".", "last", "(", "fln_hidden", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "krn_y", "=", "[", "]", "\n", "fln_y", "=", "[", "]", "\n", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "krn_y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "krn_hidden", ")", ")", "\n", "fln_y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "fln_hidden", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'fln_y'", "]", "=", "fln_y", "\n", "output_dict", "[", "'krn_y'", "]", "=", "krn_y", "\n", "output_dict", "[", "'control_1'", "]", "=", "control_1", ".", "data", ".", "clone", "(", ")", "\n", "output_dict", "[", "'control_2'", "]", "=", "control_2", ".", "data", ".", "clone", "(", ")", "\n", "output_dict", "[", "'control_3'", "]", "=", "control_3", ".", "data", ".", "clone", "(", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.Net.get_view_for": [[96, 107], ["control_1_mask.data.view().expand_as", "control_2_mask.data.view().expand_as", "control_1_mask.data.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "control_2_mask.data.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", ")", ":", "\n", "        ", "if", "n", "==", "'krn.gru.gru_cell.x2h.weight'", ":", "\n", "# print('not none')", "\n", "            ", "return", "control_1_mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "krn", ".", "gru", ".", "gru_cell", ".", "x2h", ".", "weight", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.h2h.weight'", ":", "\n", "            ", "return", "control_2_mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "krn", ".", "gru", ".", "gru_cell", ".", "h2h", ".", "weight", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.h2h.bias'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", "]", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.x2h.bias'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", "]", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.FLN.__init__": [[110, 126], ["torch.nn.Module.__init__", "bert_gru_srk.GRUModel"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# self.gru = GRU(", "\n", "#             embedding_dim = args.bert_hidden_size,", "\n", "#             hidden_dim = args.bert_hidden_size,", "\n", "#             n_layers=1,", "\n", "#             bidirectional=False,", "\n", "#             dropout=0.5,", "\n", "#             args=args)", "\n", "\n", "self", ".", "gru", "=", "GRUModel", "(", "\n", "input_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "layer_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "output_dim", "=", "args", ".", "bert_hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.KRN.__init__": [[129, 145], ["torch.nn.Module.__init__", "bert_gru_srk.GRUModel"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# self.gru = GRU(", "\n", "#             embedding_dim = args.bert_hidden_size,", "\n", "#             hidden_dim = args.bert_hidden_size,", "\n", "#             n_layers=1,", "\n", "#             bidirectional=False,", "\n", "#             dropout=0.5,", "\n", "#             args=args)", "\n", "\n", "self", ".", "gru", "=", "GRUModel", "(", "\n", "input_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "layer_dim", "=", "args", ".", "bert_hidden_size", ",", "\n", "output_dim", "=", "args", ".", "bert_hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.GRUModel.__init__": [[149, 158], ["torch.nn.Module.__init__", "bert_gru_srk.GRUCell"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "layer_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "GRUModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Hidden dimensions", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "# Number of hidden layers", "\n", "self", ".", "layer_dim", "=", "layer_dim", "\n", "\n", "self", ".", "gru_cell", "=", "GRUCell", "(", "input_dim", ",", "hidden_dim", ",", "layer_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.GRUModel.forward": [[159, 194], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "outs[].squeeze", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.size", "bert_gru_srk.GRUModel.gru_cell", "outs.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "len", "hidden.unsqueeze.unsqueeze.unsqueeze", "x.size", "hidden.unsqueeze.unsqueeze.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "# Initialize hidden state with zeros", "\n", "#######################", "\n", "#  USE GPU FOR MODEL  #", "\n", "#######################", "\n", "#print(x.shape,\"x.shape\")100, 28, 28", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "h0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_dim", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "h0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_dim", ")", "\n", "", "outs", "=", "[", "]", "\n", "control_1", "=", "[", "]", "\n", "control_2", "=", "[", "]", "\n", "control_3", "=", "[", "]", "\n", "hn", "=", "h0", "[", "0", ",", ":", ",", ":", "]", "\n", "for", "seq", "in", "range", "(", "x", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "hn", ",", "c_1", ",", "c_2", ",", "c_3", "=", "self", ".", "gru_cell", "(", "x", "[", ":", ",", "seq", ",", ":", "]", ",", "hn", ")", "\n", "outs", ".", "append", "(", "hn", ")", "\n", "control_1", ".", "append", "(", "c_1", ")", "\n", "control_2", ".", "append", "(", "c_2", ")", "\n", "control_3", ".", "append", "(", "c_3", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outs", ")", "\n", "control_1", "=", "torch", ".", "cat", "(", "control_1", ")", "\n", "control_2", "=", "torch", ".", "cat", "(", "control_2", ")", "\n", "control_3", "=", "torch", ".", "cat", "(", "control_3", ")", "\n", "\n", "hidden", "=", "outs", "[", "-", "1", "]", ".", "squeeze", "(", ")", "\n", "\n", "if", "len", "(", "hidden", ".", "size", "(", ")", ")", "<", "2", ":", "\n", "            ", "hidden", "=", "hidden", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "\n", "", "return", "output", ",", "hidden", ",", "control_1", ",", "control_2", ",", "control_3", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.GRUCell.__init__": [[203, 212], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bert_gru_srk.GRUCell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUCell.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "GRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "x2h", "=", "nn", ".", "Linear", "(", "input_size", ",", "3", "*", "hidden_size", ",", "bias", "=", "bias", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "3", "*", "hidden_size", ",", "bias", "=", "bias", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "self", ".", "k", "=", "0.001", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.GRUCell.reset_parameters": [[212, 216], ["bert_gru_srk.GRUCell.parameters", "math.sqrt", "w.data.uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "std", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_size", ")", "\n", "for", "w", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "w", ".", "data", ".", "uniform_", "(", "-", "std", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_gru_srk.GRUCell.forward": [[217, 246], ["x.view.view.view", "bert_gru_srk.GRUCell.x2h", "bert_gru_srk.GRUCell.h2h", "gate_x.unsqueeze.unsqueeze.squeeze", "gate_h.unsqueeze.unsqueeze.squeeze", "gate_x.unsqueeze.unsqueeze.chunk", "gate_h.unsqueeze.unsqueeze.chunk", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "x.view.view.size", "len", "gate_x.unsqueeze.unsqueeze.unsqueeze", "gate_h.unsqueeze.unsqueeze.unsqueeze", "gate_x.unsqueeze.unsqueeze.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "hidden", ")", ":", "\n", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "\n", "gate_x", "=", "self", ".", "x2h", "(", "x", ")", "\n", "gate_h", "=", "self", ".", "h2h", "(", "hidden", ")", "\n", "\n", "gate_x", "=", "gate_x", ".", "squeeze", "(", ")", "\n", "gate_h", "=", "gate_h", ".", "squeeze", "(", ")", "\n", "\n", "if", "len", "(", "gate_x", ".", "size", "(", ")", ")", "<", "2", ":", "\n", "            ", "gate_x", "=", "gate_x", ".", "unsqueeze", "(", "0", ")", "\n", "gate_h", "=", "gate_h", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "\n", "", "i_r", ",", "i_i", ",", "i_n", "=", "gate_x", ".", "chunk", "(", "3", ",", "1", ")", "\n", "h_r", ",", "h_i", ",", "h_n", "=", "gate_h", ".", "chunk", "(", "3", ",", "1", ")", "\n", "\n", "\n", "resetgate", "=", "F", ".", "sigmoid", "(", "i_r", "+", "h_r", ")", "\n", "inputgate", "=", "F", ".", "sigmoid", "(", "i_i", "+", "h_i", ")", "\n", "newgate", "=", "i_n", "+", "(", "resetgate", "*", "h_n", ")", "\n", "newgate", "[", "newgate", ">=", "0.9", "]", "=", "0.9", "+", "self", ".", "k", "*", "newgate", "[", "newgate", ">=", "0.9", "]", "\n", "newgate", "[", "newgate", "<=", "0", "]", "=", "self", ".", "k", "*", "newgate", "[", "newgate", "<=", "0", "]", "\n", "\n", "hy", "=", "newgate", "+", "inputgate", "*", "(", "hidden", "-", "newgate", ")", "\n", "\n", "\n", "return", "hy", ",", "x", ",", "hidden", ",", "(", "resetgate", "*", "h_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_capsule_mask.Net.__init__": [[18, 57], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "torch.nn.Dropout", "torch.nn.Dropout", "BertAdapterCapsuleMask", "bert_capsule_mask.Net.bert.parameters", "len", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_capsule_mask.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "#nomral bert here, and fixed weight", "\n", "if", "args", ".", "use_imp", ":", "\n", "            ", "from", "adapters", "import", "BertAdapterCapsuleMaskImp", "as", "BertAdapterCapsuleMask", "\n", "from", "adapters", "import", "BertAdapterCapsuleImp", "as", "BertAdapterCapsule", "\n", "", "else", ":", "\n", "            ", "from", "adapters", "import", "BertAdapterCapsuleMask", "\n", "from", "adapters", "import", "BertAdapterCapsule", "\n", "\n", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "adapter_capsule_mask", "=", "BertAdapterCapsuleMask", "(", "args", ")", "\n", "\n", "# BERT fixed, i.e. BERT as feature extractor", "\n", "# not adapter_capsule is still trainable", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "num_task", "=", "len", "(", "taskcla", ")", "\n", "self", ".", "num_kernel", "=", "3", "\n", "self", ".", "config", "=", "config", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_capsule_mask.Net.forward": [[58, 82], ["bert_capsule_mask.Net.bert", "bert_capsule_mask.Net.adapter_capsule_mask", "bert_capsule_mask.Net.dropout", "bert_capsule_mask.Net.mask", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bert_capsule_mask.Net.last", "bert_capsule_mask.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "s", ")", ":", "\n", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "output_dict", "=", "self", ".", "adapter_capsule_mask", "(", "sequence_output", ",", "t", ",", "s", ",", "targets", ")", "\n", "hidden_states", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "torch", ".", "mean", "(", "hidden_states", ",", "1", ")", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_capsule_mask.Net.mask": [[85, 99], ["bert_capsule_mask.Net.adapter_capsule_mask.mask", "bert_capsule_mask.Net.adapter_capsule_mask.capsule_net.tsv_capsules.mask"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "# TSM and also the larger, all larger needs the mask", "\n", "# we use dict to remember the layer that needs masked", "\n", "        ", "masks", "=", "{", "}", "\n", "\n", "fc1_key", "=", "'adapter_capsule_mask.fc1'", "# gfc1", "\n", "fc2_key", "=", "'adapter_capsule_mask.fc2'", "# gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "adapter_capsule_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "key", "=", "'adapter_capsule_mask.capsule_net.tsv_capsules.larger'", "# gfc1", "\n", "masks", "[", "key", "]", "=", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_capsule_mask.Net.get_view_for": [[102, 124], ["masks[].data.view().expand_as", "masks[].data.view().expand_as", "masks[].data.view", "masks[].data.view", "masks[].data.view", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "masks[].data.view", "masks[].data.view", "masks[].data.view", "masks[].data.view", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace().replace", "n.replace"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "p", ",", "masks", ")", ":", "\n", "\n", "        ", "if", "n", "==", "'adapter_capsule_mask.fc1.weight'", ":", "\n", "            ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.fc1.bias'", ":", "\n", "            ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.fc2.weight'", ":", "\n", "            ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.fc2.bias'", ":", "\n", "            ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.tsv_capsules.larger.weight'", ":", "#gfc1", "\n", "# print('tsv_capsules not none')", "\n", "            ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.capsule_net.tsv_capsules.larger.bias'", ":", "#gfc1", "\n", "            ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_capsule_mask.Net.get_view_for_tsv": [[128, 168], ["range", "bert_capsule_mask.Net.adapter_capsule_mask.capsule_net.tsv_capsules.tsv[].data.view", "range", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "get_view_for_tsv", "(", "self", ",", "n", ",", "t", ")", ":", "\n", "#TODO: Cautions! Don't preint, this is used in forward transfer", "\n", "        ", "if", "n", "==", "'adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", ":", "\n", "# print('not none')", "\n", "            ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "", "for", "c_t", "in", "range", "(", "self", ".", "num_task", ")", ":", "\n", "            ", "if", "n", "==", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('not none')", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "for", "m_t", "in", "range", "(", "self", ".", "num_kernel", ")", ":", "\n", "                ", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "# print('not none')", "\n", "                    ", "return", "self", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "", "", "return", "1", "#if no condition is satified", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.__init__": [[14, 50], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "cnn_cat.MainContinualLearning", "cnn_cat.TransferLayer", "cnn_cat.KnowledgeTransfer", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "mcl", "=", "MainContinualLearning", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "transfer", "=", "TransferLayer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "kt", "=", "KnowledgeTransfer", "(", "ncha", ",", "size", ",", "self", ".", "taskcla", ",", "args", ")", "\n", "self", ".", "smax", "=", "args", ".", "smax", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "print", "(", "'CNN CAT'", ")", "\n", "print", "(", "'pdrop1: '", ",", "pdrop1", ")", "\n", "print", "(", "'pdrop2: '", ",", "pdrop2", ")", "\n", "\n", "\"\"\" (e.g., used with compression experiments)\n        lo,hi=0,2\n        self.efc1.weight.data.uniform_(lo,hi)\n        self.efc2.weight.data.uniform_(lo,hi)\n        self.efc3.weight.data.uniform_(lo,hi)\n        #\"\"\"", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.mcl_feature": [[51, 64], ["cnn_cat.Net.maxpool", "cnn_cat.Net.maxpool", "cnn_cat.Net.maxpool", "cnn_cat.Net.view", "cnn_cat.Net.drop2", "cnn_cat.Net.drop2", "cnn_cat.Net.drop1", "gc1.view().expand_as", "cnn_cat.Net.drop1", "gc2.view().expand_as", "cnn_cat.Net.drop2", "gc3.view().expand_as", "x.size", "cnn_cat.Net.relu", "gfc1.expand_as", "cnn_cat.Net.relu", "gfc2.expand_as", "cnn_cat.Net.relu", "cnn_cat.Net.relu", "cnn_cat.Net.relu", "cnn_cat.Net.mcl.fc1", "cnn_cat.Net.mcl.fc2", "cnn_cat.Net.mcl.c1", "gc1.view", "cnn_cat.Net.mcl.c2", "gc2.view", "cnn_cat.Net.mcl.c3", "gc3.view"], "methods", ["None"], ["", "def", "mcl_feature", "(", "self", ",", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.forward": [[67, 218], ["cnn_cat.Net.mask", "cnn_cat.Net.mcl_feature", "cnn_cat.Net.mcl.mask_last", "cnn_cat.Net.mask", "cnn_cat.Net.mcl_feature", "range", "cnn_cat.Net.mask", "gc1.data.clone", "gc2.data.clone", "gc3.data.clone", "gfc1.data.clone", "gfc2.data.clone", "cnn_cat.Net.mcl_feature", "pre_models.append", "pre_ts.append", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "task_models.permute.permute.permute", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "cnn_cat.Net.kt.encoder", "cnn_cat.Net.mcl_feature", "cnn_cat.Net.append", "cnn_cat.Net.clone", "cnn_cat.Net.relu().expand", "cnn_cat.Net.mcl.mask_last", "cnn_cat.Net.mcl.att_last", "cnn_cat.Net.Tsim_mask", "cnn_cat.Net.mcl_feature", "cnn_cat.Net.mcl_feature", "task_models.permute.permute.size", "cnn_cat.Net.mcl.mask_last", "cnn_cat.Net.mcl.mask_last", "cnn_cat.Net.mcl.att_last", "cnn_cat.Net.mcl.mask_last", "check_federated.check_t", "cnn_cat.Net.relu", "cnn_cat.Net.append", "cnn_cat.Net.append", "cnn_cat.Net.append", "cnn_cat.Net.mcl.mask_last", "cnn_cat.Net.kt.q1", "cnn_cat.Net.append", "cnn_cat.Net.append", "cnn_cat.Net.append", "cnn_cat.Net.append", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.check_t", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", "=", "1", ",", "phase", "=", "None", ",", "\n", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ",", "\n", "similarity", "=", "None", ",", "history_mask_pre", "=", "None", ",", "check_federated", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "'mcl'", "in", "phase", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "'mcl'", "in", "phase", "and", "'multi-loss-joint-Tsim'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "pre_models", "=", "[", "]", "\n", "\n", "pre_ts", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "if", "self", ".", "training", "==", "True", "and", "similarity", "[", "pre_t", "]", ":", "\n", "                    ", "continue", "\n", "", "elif", "self", ".", "training", "==", "False", "and", "check_federated", ".", "check_t", "(", "pre_t", ")", "==", "False", ":", "\n", "                    ", "continue", "\n", "\n", "", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "pre_t", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "pre_gc1", "=", "gc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc2", "=", "gc2", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc3", "=", "gc3", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc1", "=", "gfc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc2", "=", "gfc2", ".", "data", ".", "clone", "(", ")", "\n", "\n", "pre_h", "=", "self", ".", "mcl_feature", "(", "x", ",", "pre_gc1", ",", "pre_gc2", ",", "pre_gc3", ",", "pre_gfc1", ",", "pre_gfc2", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "pre_ts", ".", "append", "(", "pre_t", ")", "\n", "#Tsim: model for each Tsim", "\n", "\n", "", "if", "len", "(", "pre_models", ")", ">", "1", ":", "\n", "                ", "task_models", "=", "torch", ".", "stack", "(", "pre_models", ")", "\n", "task_models", "=", "task_models", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "query", "=", "torch", ".", "unsqueeze", "(", "self", ".", "relu", "(", "self", ".", "kt", ".", "q1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ".", "expand", "(", "task_models", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "#hard to train", "\n", "\n", "h_attn", ",", "_", "=", "self", ".", "kt", ".", "encoder", "(", "task_models", ",", "query", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                        ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "if", "'no-isolate'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "history_mask_pre", ",", "similarity", "=", "similarity", ")", "\n", "\n", "h_attn", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "transfer", ".", "last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.mask": [[220, 229], ["cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.mcl.ec1", "cnn_cat.Net.mcl.ec2", "cnn_cat.Net.mcl.ec3", "cnn_cat.Net.mcl.efc1", "cnn_cat.Net.mcl.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ",", "phase", "=", "None", ")", ":", "\n", "#used by training", "\n", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.Tsim_mask": [[230, 264], ["range", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "cnn_cat.Net.gate", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "[].round().nonzero", "cnn_cat.Net.mcl.ec1", "cnn_cat.Net.mcl.ec2", "cnn_cat.Net.mcl.ec3", "cnn_cat.Net.mcl.efc1", "cnn_cat.Net.mcl.efc2", "[].round", "[].round", "[].round", "[].round", "[].round", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "Tsim_mask", "(", "self", ",", "t", ",", "history_mask_pre", "=", "None", ",", "similarity", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "#find the distinct mask, used by block the backward pass", "\n", "\n", "#want aggregate Tsim", "\n", "        ", "if", "phase", "is", "None", ":", "\n", "#Tsim mask", "\n", "            ", "Tsim_gc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc3", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "\n", "\n", "", "for", "history_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "history_t", "==", "0", ":", "\n", "                ", "Tsim_gc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "else", ":", "\n", "                ", "Tsim_gc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "0", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "1", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "2", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "3", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "4", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "if", "similarity", "[", "history_t", "]", "==", "0", ":", "\n", "                ", "Tsim_gc1", "[", "Tsim_gc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc2", "[", "Tsim_gc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc3", "[", "Tsim_gc3_index", "[", ":", ",", "0", "]", ",", "Tsim_gc3_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc1", "[", "Tsim_gfc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc2", "[", "Tsim_gfc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "\n", "", "", "return", "[", "Tsim_gc1", ",", "Tsim_gc2", ",", "Tsim_gc3", ",", "Tsim_gfc1", ",", "Tsim_gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Net.get_view_for": [[267, 293], ["gfc1.data.view().expand_as", "gfc1.data.view", "gfc1.data.view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gfc2.data.view", "gfc1.data.view", "gc2.data.view().expand_as", "gc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gc2.data.view", "gc2.data.view", "gc1.data.view", "gc3.data.view().expand_as", "gc2.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gc3.data.view", "gc3.data.view", "gc2.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'mcl.fc1.weight'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'mcl.fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c2", ".", "weight", ")", "\n", "pre", "=", "gc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "pre", "=", "gc2", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.MainContinualLearning.__init__": [[298, 345], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_cat.MainContinualLearning.mask_last.append", "cnn_cat.MainContinualLearning.att_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "MainContinualLearning", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "mask_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "att_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.TransferLayer.__init__": [[349, 414], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_cat.TransferLayer.transfer.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_cat.TransferLayer.transfer_to_n.append", "cnn_cat.TransferLayer.last.append", "cnn_cat.TransferLayer.last_fusion.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_cat.TransferLayer.transfer.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "cnn_cat.TransferLayer.transfer_to_n.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "TransferLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "args", "=", "args", "\n", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "\n", "self", ".", "fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "2048", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "# this one will not change according to different scenario", "\n", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "args", ".", "nclasses", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "last_fusion", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "from_n", ",", "to_n", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.KnowledgeTransfer.__init__": [[417, 424], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "cnn_cat.EncoderLayer", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ncha", ",", "size", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "KnowledgeTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nhid", "=", "2048", "\n", "#self-attention ==============", "\n", "self", ".", "q1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "encoder", "=", "EncoderLayer", "(", "args", ".", "n_head", ",", "nhid", ",", "nhid", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "args", "=", "args", ")", "\n", "# n_head, d_model, d_k, d_v", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.EncoderLayer.__init__": [[430, 438], ["torch.Module.__init__", "cnn_cat.MultiHeadAttention", "cnn_cat.PositionwiseFeedForward", "cnn_cat.PositionalEncoding", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_inner", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.EncoderLayer.forward": [[439, 453], ["cnn_cat.EncoderLayer.layer_norm", "cnn_cat.EncoderLayer.slf_attn", "cnn_cat.EncoderLayer.pos_ffn", "cnn_cat.EncoderLayer.slf_attn", "cnn_cat.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "enc_q", "=", "None", ",", "ranking", "=", "None", ")", ":", "\n", "#TODO: Positional/ranking embedding", "\n", "\n", "        ", "if", "enc_q", "is", "None", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_input", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "else", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_q", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.MultiHeadAttention.__init__": [[457, 473], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "cnn_cat.ScaledDotProductAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "#sqrt d_k", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.MultiHeadAttention.forward": [[475, 509], ["torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "cnn_cat.MultiHeadAttention.layer_norm", "cnn_cat.MultiHeadAttention.w_qs().view", "cnn_cat.MultiHeadAttention.w_ks().view", "cnn_cat.MultiHeadAttention.w_vs().view", "cnn_cat.MultiHeadAttention.attention", "cnn_cat.MultiHeadAttention.dropout", "q.transpose().contiguous().view.transpose().contiguous().view.size", "q.transpose().contiguous().view.transpose().contiguous().view.size", "cnn_cat.MultiHeadAttention.size", "cnn_cat.MultiHeadAttention.size", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "cnn_cat.MultiHeadAttention.transpose", "cnn_cat.MultiHeadAttention.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "cnn_cat.MultiHeadAttention.fc", "cnn_cat.MultiHeadAttention.w_qs", "cnn_cat.MultiHeadAttention.w_ks", "cnn_cat.MultiHeadAttention.w_vs", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "torch", ".", "squeeze", "(", "q", ",", "1", ")", "\n", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "\n", "q", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "\n", "if", "len_q", "==", "1", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "\n", "", "q", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "q", ")", ")", "\n", "q", "+=", "residual", "\n", "\n", "return", "q", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.ScaledDotProductAttention.__init__": [[513, 517], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.ScaledDotProductAttention.forward": [[518, 525], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "cnn_cat.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.PositionwiseFeedForward.__init__": [[529, 535], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "# position-wise", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.PositionwiseFeedForward.forward": [[536, 546], ["cnn_cat.PositionwiseFeedForward.layer_norm", "cnn_cat.PositionwiseFeedForward.w_2", "cnn_cat.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "cnn_cat.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "w_2", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "+=", "residual", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.PositionalEncoding.__init__": [[550, 555], ["torch.Module.__init__", "cnn_cat.PositionalEncoding.register_buffer", "cnn_cat.PositionalEncoding._get_sinusoid_encoding_table"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding._get_sinusoid_encoding_table"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "n_position", "=", "40", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Not a parameter", "\n", "self", ".", "register_buffer", "(", "'pos_table'", ",", "self", ".", "_get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.PositionalEncoding._get_sinusoid_encoding_table": [[556, 568], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "cnn_cat.PositionalEncoding._get_sinusoid_encoding_table.get_position_angle_vec"], "methods", ["None"], ["", "def", "_get_sinusoid_encoding_table", "(", "self", ",", "n_position", ",", "d_hid", ")", ":", "\n", "        ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy", "\n", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "            ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.PositionalEncoding.forward": [[569, 571], ["cnn_cat.PositionalEncoding.pos_table[].clone().detach", "cnn_cat.PositionalEncoding.pos_table[].clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "ranking", ")", ":", "\n", "        ", "return", "enc_input", "+", "self", ".", "pos_table", "[", ":", ",", "ranking", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.__init__": [[9, 41], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", "=", "0", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'MLP'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.forward": [[42, 59], ["mlp.Net.features", "torch.normalize", "torch.normalize", "mlp.Net.last", "mlp.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h", "=", "self", ".", "features", "(", "x", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.features": [[61, 66], ["mlp.Net.drop1", "mlp.Net.drop2", "mlp.Net.drop2", "x.view", "mlp.Net.relu", "mlp.Net.relu", "x.size", "mlp.Net.fc1", "mlp.Net.fc2"], "methods", ["None"], ["", "def", "features", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.get_params": [[68, 78], ["list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mlp.Net.parameters", "params.append", "pp.view"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns all the parameters concatenated in a single tensor.\n        :return: parameters tensor (input_size * 100 + 100 + 100 * 100 + 100 +\n                                    + 100 * output_size + output_size)\n        \"\"\"", "\n", "params", "=", "[", "]", "\n", "for", "pp", "in", "list", "(", "self", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "params", ".", "append", "(", "pp", ".", "view", "(", "-", "1", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.set_params": [[79, 92], ["list", "new_params.size", "mlp.Net.get_params().size", "mlp.Net.parameters", "new_params[].view", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "pp.size", "mlp.Net.get_params", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pp.size", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pp.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params"], ["", "def", "set_params", "(", "self", ",", "new_params", ":", "torch", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the parameters to a given value.\n        :param new_params: concatenated values to be set (input_size * 100\n                    + 100 + 100 * 100 + 100 + 100 * output_size + output_size)\n        \"\"\"", "\n", "assert", "new_params", ".", "size", "(", ")", "==", "self", ".", "get_params", "(", ")", ".", "size", "(", ")", "\n", "progress", "=", "0", "\n", "for", "pp", "in", "list", "(", "self", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "cand_params", "=", "new_params", "[", "progress", ":", "progress", "+", "\n", "torch", ".", "tensor", "(", "pp", ".", "size", "(", ")", ")", ".", "prod", "(", ")", "]", ".", "view", "(", "pp", ".", "size", "(", ")", ")", "\n", "progress", "+=", "torch", ".", "tensor", "(", "pp", ".", "size", "(", ")", ")", ".", "prod", "(", ")", "\n", "pp", ".", "data", "=", "cand_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp.Net.num_flat_features": [[93, 104], ["x.size"], "methods", ["None"], ["", "", "def", "num_flat_features", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Computes the total number of items except the first dimension.\n        :param x: input tensor\n        :return: number of item from the second dimension onward\n        \"\"\"", "\n", "size", "=", "x", ".", "size", "(", ")", "[", "1", ":", "]", "\n", "num_features", "=", "1", "\n", "for", "ff", "in", "size", ":", "\n", "            ", "num_features", "*=", "ff", "\n", "", "return", "num_features", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_owm.Net.__init__": [[10, 52], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim_owm.Net.sentence_embedding.parameters", "w2v_kim_owm.Net.aspect_embedding.parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_owm.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "100", ",", "(", "K", ",", "self", ".", "WORD_DIM", ")", ")", "for", "K", "in", "self", ".", "FILTERS", "]", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "300", ",", "300", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "300", ",", "300", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'W2V + CNN OWM'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_owm.Net.forward": [[53, 90], ["w2v_kim_owm.Net.sentence_embedding().float", "w2v_kim_owm.Net.view", "x_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "w2v_kim_owm.Net.relu", "h_list.append", "w2v_kim_owm.Net.relu", "h_list.append", "w2v_kim_owm.Net.dropout", "torch.normalize", "torch.normalize", "sentence.size", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "w2v_kim_owm.Net.fc1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "w2v_kim_owm.Net.fc2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "w2v_kim_owm.Net.last", "w2v_kim_owm.Net.sentence_embedding", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "w2v_kim_owm.Net.append", "conv", "i.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "term", ",", "sentence", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "x_list", "=", "[", "]", "\n", "h_list", "=", "[", "]", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "sentence", ".", "size", "(", "1", ")", ",", "self", ".", "WORD_DIM", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "[", "F", ".", "relu", "(", "conv", "(", "h", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs", "]", "# [(N, Co, W), ...]*len(Ks)", "\n", "h", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "h", "]", "# [(N, Co), ...]*len(Ks)", "\n", "x_list", "+=", "[", "torch", ".", "mean", "(", "h_e", ",", "0", ",", "True", ")", "for", "h_e", "in", "h", "]", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "1", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Net.__init__": [[15, 73], ["super().__init__", "transformers.BertConfig.from_pretrained", "my_transformers.MyBertModel.from_pretrained", "bert_adapter_owm.Net.bert.parameters", "torch.nn.Dropout", "print", "adapter.parameters", "torch.nn.Linear", "torch.nn.ModuleList", "bert_adapter_owm.Net.last.append", "range", "torch.nn.Linear", "range", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "args", ".", "build_adapter_owm", "=", "True", "\n", "self", ".", "bert", "=", "MyBertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ",", "args", "=", "args", ")", "\n", "\n", "\n", "#BERT fixed all ===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "# param.requires_grad = True", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "#But adapter is open", "\n", "\n", "#Only adapters are trainable", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "", "for", "adapter", "in", "adaters", ":", "\n", "            ", "for", "param", "in", "adapter", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "\n", "", "", "print", "(", "'BERT ADAPTER OWM'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Net.forward": [[74, 100], ["bert_adapter_owm.Net.bert", "bert_adapter_owm.Net.dropout", "bert_adapter_owm.Net.last", "bert_adapter_owm.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict_", "=", "{", "}", "# more flexible", "\n", "\n", "output_dict", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict_", "[", "'y'", "]", "=", "y", "\n", "output_dict_", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict_", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "\n", "return", "output_dict_", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_hat.Net.__init__": [[10, 58], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_kim_hat.Net.sentence_embedding.parameters", "w2v_kim_hat.Net.aspect_embedding.parameters", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_kim_hat.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "w2v_hidden_size", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "300", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "w2v_hidden_size", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "args", ".", "w2v_hidden_size", ")", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'W2V + KIM + HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_hat.Net.forward": [[59, 97], ["w2v_kim_hat.Net.sentence_embedding().float", "w2v_kim_hat.Net.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "w2v_kim_hat.Net.view", "w2v_kim_hat.Net.mask", "w2v_kim_hat.Net.dropout", "w2v_kim_hat.Net.dropout", "torch.normalize", "torch.normalize", "w2v_kim_hat.Net.size", "w2v_kim_hat.Net.relu", "gfc1.expand_as", "w2v_kim_hat.Net.relu", "gfc2.expand_as", "w2v_kim_hat.Net.last", "w2v_kim_hat.Net.sentence_embedding", "sentence.size", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "w2v_kim_hat.Net.fc1", "w2v_kim_hat.Net.fc2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "w2v_kim_hat.Net.append", "w2v_kim_hat.Net.c1", "w2v_kim_hat.Net.c2", "w2v_kim_hat.Net.c3", "sentence.size", "sentence.size", "sentence.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "term", ",", "sentence", ",", "s", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "sentence", ".", "size", "(", "1", ")", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c1", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ",", "sentence", ".", "size", "(", "1", ")", "-", "self", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "#loss ==============", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "#loss ==============", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_hat.Net.mask": [[98, 105], ["w2v_kim_hat.Net.gate", "w2v_kim_hat.Net.gate", "w2v_kim_hat.Net.gate", "w2v_kim_hat.Net.gate", "w2v_kim_hat.Net.gate", "w2v_kim_hat.Net.ec1", "w2v_kim_hat.Net.ec2", "w2v_kim_hat.Net.ec3", "w2v_kim_hat.Net.efc1", "w2v_kim_hat.Net.efc2"], "methods", ["None"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec1", "(", "t", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec2", "(", "t", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec3", "(", "t", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc1", "(", "t", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc2", "(", "t", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_kim_hat.Net.get_view_for": [[107, 142], ["gc1.data.view().expand_as", "gc1.data.view", "gc1.data.view", "gc2.data.view().expand_as", "gc2.data.view", "gc2.data.view", "gc3.data.view().expand_as", "gc3.data.view", "gc3.data.view", "gfc1.data.view().expand_as", "gc3.data.view().expand().contiguous().view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc1.data.view", "gfc1.data.view", "gc3.data.view().expand().contiguous().view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gc3.data.view().expand().contiguous", "gfc2.data.view", "gfc1.data.view", "gc3.data.view().expand", "gc3.data.view", "w2v_kim_hat.Net.ec3.weight.size"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "return", "post", "\n", "", "elif", "n", "==", "'c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "3", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "return", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim.Net.__init__": [[10, 47], ["super().__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim.Net.bert.parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Dropout", "torch.nn.Dropout", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "0", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "1", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "2", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "' BERT (Fixed) + CNN'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim.Net.forward": [[48, 78], ["bert_kim.Net.bert", "sequence_output.view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_kim.Net.view", "bert_kim.Net.dropout", "torch.normalize", "torch.normalize", "sequence_output.size", "bert_kim.Net.last", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "bert_kim.Net.append", "bert_kim.Net.c1", "bert_kim.Net.c2", "bert_kim.Net.c3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "#sentence ============", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "self", ".", "args", ".", "max_seq_length", ")", "\n", "\n", "h1", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c1", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "0", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "0", "]", ",", "1", ")", "\n", "h2", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "1", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "1", "]", ",", "1", ")", "\n", "h3", "=", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ",", "self", ".", "args", ".", "max_seq_length", "-", "self", ".", "FILTERS", "[", "2", "]", "+", "1", ")", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "2", "]", ",", "1", ")", "\n", "\n", "h", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "h", "=", "h", ".", "view", "(", "sequence_output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "#loss ==============", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_owm.Net.__init__": [[9, 41], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_owm.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", "=", "0", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'MLP'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_owm.Net.forward": [[42, 68], ["mlp_owm.Net.drop1", "h_list.append", "mlp_owm.Net.drop2", "h_list.append", "mlp_owm.Net.drop2", "torch.normalize", "torch.normalize", "x.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "mlp_owm.Net.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "mlp_owm.Net.relu", "mlp_owm.Net.last", "x.size", "mlp_owm.Net.fc1", "mlp_owm.Net.fc2", "mlp_owm.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "h_list", "=", "[", "]", "\n", "\n", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "output_dict", "[", "'h_list'", "]", "=", "h_list", "\n", "output_dict", "[", "'x_list'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.__init__": [[12, 91], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_hat.Net.last.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "list", "mlp_hat.Net.fc_zoomin.append", "mlp_hat.Net.fc_zoomout.append", "range", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "mlp_hat.Net.self_attns.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "mlp_hat.Net.fc_zoomin.append", "mlp_hat.Net.fc_zoomout.append", "mlp_hat.Self_Attn", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "mlp_hat.Net.self_attns.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "random.Random().sample", "mlp_hat.Net.n_order.append", "mlp_hat.Net.n_order.append", "mlp_hat.Net.self_attns_.append", "mlp_hat.Self_Attn", "random.Random"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n", "", "", "if", "'Attn-HCHP-Outside'", "in", "self", ".", "args", ".", "mix_type", ":", "\n", "            ", "if", "self", ".", "args", ".", "attn_type", "==", "'self'", ":", "\n", "                ", "if", "self", ".", "args", ".", "feature_based", ":", "\n", "                    ", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "n", "in", "range", "(", "args", ".", "naug", ")", ":", "\n", "                        ", "self", ".", "self_attns", ".", "append", "(", "Self_Attn", "(", "nhid", ")", ")", "\n", "", "", "elif", "self", ".", "args", ".", "task_based", ":", "\n", "                    ", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "                        ", "self", ".", "self_attns_", "=", "nn", ".", "ModuleList", "(", ")", "\n", "offset", "=", "0", "\n", "for", "n", "in", "range", "(", "args", ".", "naug", ")", ":", "\n", "                            ", "if", "n", ">", "1", ":", "offset", "+=", "1", "\n", "if", "t", "+", "1", "-", "offset", "==", "0", ":", "break", "\n", "self", ".", "self_attns_", ".", "append", "(", "Self_Attn", "(", "t", "+", "1", "-", "offset", ")", ")", "\n", "", "self", ".", "self_attns", ".", "append", "(", "self", ".", "self_attns_", ")", "\n", "\n", "", "", "", "elif", "self", ".", "args", ".", "attn_type", "==", "'cos'", ":", "\n", "                ", "self", ".", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ")", "\n", "\n", "self", ".", "fc_zoomin", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fc_zoomout", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# self.convs4 = nn.ModuleList()", "\n", "\n", "n_orders", "=", "list", "(", "range", "(", "args", ".", "ntasks", ")", ")", "\n", "self", ".", "n_order", "=", "[", "n_orders", "[", ":", "]", "]", "\n", "self", ".", "fc_zoomin", ".", "append", "(", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "semantic_cap_size", ")", ")", "\n", "self", ".", "fc_zoomout", ".", "append", "(", "nn", ".", "Linear", "(", "args", ".", "semantic_cap_size", ",", "nhid", ")", ")", "\n", "\n", "seed", "=", "args", ".", "data_seed", "\n", "for", "n", "in", "range", "(", "args", ".", "naug", ")", ":", "\n", "                    ", "self", ".", "fc_zoomin", ".", "append", "(", "nn", ".", "Linear", "(", "nhid", ",", "args", ".", "semantic_cap_size", ")", ")", "\n", "self", ".", "fc_zoomout", ".", "append", "(", "nn", ".", "Linear", "(", "args", ".", "semantic_cap_size", ",", "nhid", ")", ")", "\n", "# random.Random(seed).shuffle(n_orders)", "\n", "if", "args", ".", "nsamples", ">", "1", ":", "\n", "#you may want to only sample some: random.sample(population, k, *, counts=None)", "\n", "                        ", "n_orders_samples", "=", "random", ".", "Random", "(", "seed", ")", ".", "sample", "(", "n_orders", ",", "args", ".", "nsamples", ")", "\n", "self", ".", "n_order", ".", "append", "(", "n_orders_samples", "[", ":", "]", ")", "#deep copy", "\n", "", "else", ":", "\n", "                        ", "self", ".", "n_order", ".", "append", "(", "n_orders", "[", ":", "]", ")", "#deep copy", "\n", "\n", "", "seed", "+=", "1", "\n", "", "print", "(", "'self.n_order: '", ",", "self", ".", "n_order", ")", "\n", "\n", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.forward": [[92, 125], ["torch.normalize", "torch.normalize", "torch.normalize", "mlp_hat.Net.mask", "mlp_hat.Net.get_feature", "mlp_hat.Net.mask", "mlp_hat.Net.get_feature", "mlp_hat.Net.last", "mlp_hat.Net.self_attention_feature", "mlp_hat.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.self_attention_feature"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "start_mixup", "=", "None", ",", "s", "=", "None", ",", "l", "=", "None", ",", "idx", "=", "None", ",", "mix_type", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "start_mixup", "and", "'Attn-HCHP-Outside'", "in", "mix_type", ":", "\n", "# print('attn type: ', self.args.attn_type)", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "if", "self", ".", "args", ".", "attn_type", "==", "'self'", ":", "\n", "                ", "h", "=", "self", ".", "self_attention_feature", "(", "t", ",", "x", ",", "h", ",", "l", ",", "idx", ",", "self", ".", "args", ".", "smax", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "# print('others: ')", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.get_feature_augment": [[127, 144], ["mlp_hat.Net.drop1", "mlp_hat.Net.drop2", "mlp_hat.Net.drop2", "mlp_hat.Net.drop1", "mlp_hat.Net.drop2", "mlp_hat.Net.drop2", "x.view", "mlp_hat.Net.relu", "gfc1.expand_as", "mlp_hat.Net.relu", "gfc2.expand_as", "x_b.view", "mlp_hat.Net.relu", "gfc1.expand_as", "mlp_hat.Net.relu", "gfc2.expand_as", "x.size", "mlp_hat.Net.fc1", "mlp_hat.Net.fc2", "x_b.size", "mlp_hat.Net.fc1", "mlp_hat.Net.fc2"], "methods", ["None"], ["", "def", "get_feature_augment", "(", "self", ",", "x", ",", "x_b", ",", "gfc1", ",", "gfc2", ",", "l", ")", ":", "\n", "        ", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "h_b", "=", "self", ".", "drop1", "(", "x_b", ".", "view", "(", "x_b", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h_b", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h_b", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gfc1", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h_b", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gfc2", ".", "expand_as", "(", "h_b", ")", "\n", "\n", "\n", "h", "=", "l", "*", "h", "+", "(", "1", "-", "l", ")", "*", "h_b", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.self_attention_feature": [[146, 177], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pooled_output.sum.sum.sum", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pooled_output.sum.sum.sum", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mlp_hat.Net.mask", "mlp_hat.Net.get_feature", "mlp_hat.Net.unsqueeze().clone", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mlp_hat.Net.mask", "mlp_hat.Net.get_feature", "mlp_hat.Net.unsqueeze().clone", "pooled_output.sum.sum.unsqueeze().clone", "mlp_hat.Net.unsqueeze", "mlp_hat.Net.unsqueeze", "pooled_output.sum.sum.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature"], ["", "def", "self_attention_feature", "(", "self", ",", "t", ",", "x", ",", "pooled_output", ",", "order", ",", "idx", ",", "smax", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "feature_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "1", ")", "#softmax on task", "\n", "\n", "", "elif", "self", ".", "args", ".", "task_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "-", "1", ")", "\n", "pre_hs", "=", "torch", ".", "cat", "(", "[", "pre_hs", ",", "pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "]", ",", "-", "1", ")", "# include itselves", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "t", "]", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "-", "1", ")", "#softmax on task", "\n", "\n", "", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.cos_attention_feature": [[179, 203], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pre_hs.append", "mlp_hat.Net.cos", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mlp_hat.Net.mask", "mlp_hat.Net.get_feature", "mlp_hat.Net.unsqueeze().clone", "mlp_hat.Net.view().clone", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "mlp_hat.Net.unsqueeze", "mlp_hat.Net.view"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature"], ["", "def", "cos_attention_feature", "(", "self", ",", "t", ",", "x", ",", "h", ",", "l", ",", "smax", ")", ":", "\n", "        ", "h", "=", "self", ".", "fc_zoomin", "[", "l", "]", "(", "h", ")", "\n", "\n", "pre_hs", "=", "[", "]", "\n", "decision_maker", "=", "[", "]", "\n", "for", "pre_t", "in", "self", ".", "n_order", "[", "l", "]", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_h", "=", "self", ".", "fc_zoomin", "[", "l", "]", "(", "pre_h", ")", "# zoom in should be trainable", "\n", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "z", "=", "self", ".", "cos", "(", "pre_h", ",", "h", ")", "#similarity", "\n", "decision_maker", ".", "append", "(", "z", ".", "view", "(", "-", "1", ",", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "\n", "", "decision_maker", "=", "torch", ".", "cat", "(", "decision_maker", ",", "1", ")", "\n", "pre_pooled_outputs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "1", ")", "\n", "pooled_output", "=", "(", "pre_pooled_outputs", "*", "decision_maker", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "\n", "pooled_output", "=", "self", ".", "fc_zoomout", "[", "l", "]", "(", "pooled_output", ")", "\n", "\n", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.get_feature": [[204, 211], ["mlp_hat.Net.drop1", "mlp_hat.Net.drop2", "mlp_hat.Net.drop2", "x.view", "mlp_hat.Net.relu", "gfc1.expand_as", "mlp_hat.Net.relu", "gfc2.expand_as", "x.size", "mlp_hat.Net.fc1", "mlp_hat.Net.fc2"], "methods", ["None"], ["", "def", "get_feature", "(", "self", ",", "x", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.mask": [[213, 217], ["mlp_hat.Net.gate", "mlp_hat.Net.gate", "mlp_hat.Net.efc1", "mlp_hat.Net.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Net.get_view_for": [[218, 234], ["gfc1.data.view().expand_as", "gfc1.data.view", "gfc1.data.view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gfc2.data.view", "gfc1.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "\n", "        ", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'fc1.weight'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Self_Attn.__init__": [[240, 249], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "attn_size", ")", ":", "\n", "        ", "super", "(", "Self_Attn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_hat.Self_Attn.forward": [[250, 279], ["x.size", "mlp_hat.Self_Attn.query_conv().view().permute", "mlp_hat.Self_Attn.key_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "mlp_hat.Self_Attn.softmax", "mlp_hat.Self_Attn.value_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.view.view.view", "mlp_hat.Self_Attn.permute", "mlp_hat.Self_Attn.query_conv().view", "mlp_hat.Self_Attn.key_conv", "mlp_hat.Self_Attn.value_conv", "mlp_hat.Self_Attn.query_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n            inputs :\n                x : input feature maps( B,max_length,hidden_size)\n            returns :\n                out : self attention value + input feature\n                attention: B X N X N (N is Width*Height)\n        \"\"\"", "\n", "\n", "# print('x: ',x.size())", "\n", "m_batchsize", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "# print('energy: ',energy.size())", "\n", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "\n", "# attention =  F.gumbel_softmax(energy,hard=True,dim=-1)", "\n", "# print('attention: ',attention)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C X N", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "\n", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_ucl.Net.__init__": [[11, 41], ["torch.Module.__init__", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "bert_kim_ucl.Net.bert.parameters", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bayes_layer.BayesianConv2D", "sum", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "bert_kim_ucl.Net.last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "FILTERS", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "FILTER_NUM", "=", "[", "100", ",", "100", ",", "100", "]", "\n", "self", ".", "WORD_DIM", "=", "args", ".", "bert_hidden_size", "\n", "self", ".", "MAX_SENT_LEN", "=", "args", ".", "max_seq_length", "\n", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ")", "\n", "\n", "#BERT fixed, i.e. BERT as feature extractor===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "BayesianConv2D", "(", "1", ",", "100", ",", "(", "K", ",", "self", ".", "WORD_DIM", ")", ")", "for", "K", "in", "self", ".", "FILTERS", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_kim_ucl.Net.forward": [[44, 67], ["bert_kim_ucl.Net.bert", "sequence_output.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_kim_ucl.Net.dropout", "torch.relu().squeeze", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "bert_kim_ucl.Net.last", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "bert_kim_ucl.Net.append", "conv", "i.size"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "sample", "=", "False", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "h", "=", "sequence_output", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "args", ".", "max_seq_length", ",", "self", ".", "WORD_DIM", ")", "\n", "\n", "h", "=", "[", "F", ".", "relu", "(", "conv", "(", "h", ",", "sample", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs", "]", "# [(N, Co, W), ...]*len(Ks)", "\n", "h", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "h", "]", "# [(N, Co), ...]*len(Ks)", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "1", ")", "\n", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Net.__init__": [[14, 71], ["super().__init__", "transformers.BertConfig.from_pretrained", "my_transformers.MyBertModel.from_pretrained", "bert_adapter_ucl.Net.bert.parameters", "torch.nn.Dropout", "print", "adapter.parameters", "torch.nn.Linear", "torch.nn.ModuleList", "bert_adapter_ucl.Net.last.append", "range", "torch.nn.Linear", "range", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "args", ".", "build_adapter_ucl", "=", "True", "\n", "self", ".", "bert", "=", "MyBertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ",", "args", "=", "args", ")", "\n", "\n", "\n", "#BERT fixed all ===========", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "# param.requires_grad = True", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "#But adapter is open", "\n", "\n", "#Only adapters are trainable", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "", "for", "adapter", "in", "adaters", ":", "\n", "            ", "for", "param", "in", "adapter", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'BERT ADAPTER UCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Net.forward": [[72, 89], ["bert_adapter_ucl.Net.bert", "bert_adapter_ucl.Net.dropout", "bert_adapter_ucl.Net.last", "bert_adapter_ucl.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.Net.__init__": [[12, 57], ["super().__init__", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "w2v_gru_srk.Net.sentence_embedding.parameters", "w2v_gru_srk.Net.aspect_embedding.parameters", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "w2v_gru_srk.FLN", "w2v_gru_srk.KRN", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "w2v_gru_srk.Net.last.append", "w2v_gru_srk.Net.krn_last.append", "w2v_gru_srk.Net.fln_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "embeddings", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "sentence_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "aspect_embedding", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "for", "param", "in", "self", ".", "sentence_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "aspect_embedding", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fln", "=", "FLN", "(", "args", ",", "taskcla", ")", "\n", "self", ".", "krn", "=", "KRN", "(", "args", ",", "taskcla", ")", "\n", "\n", "\n", "self", ".", "fln_fc", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "w2v_hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "krn_fc", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "w2v_hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "krn_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "fln_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "krn_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fln_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "krn_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "self", ".", "fln_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "w2v_hidden_size", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'W2V (Fixed) + GRU + SRK'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.Net.forward": [[58, 94], ["w2v_gru_srk.Net.sentence_embedding().float", "w2v_gru_srk.Net.fln.gru", "w2v_gru_srk.Net.krn.gru", "w2v_gru_srk.Net.gate", "control_1.data.clone", "control_2.data.clone", "control_3.data.clone", "w2v_gru_srk.Net.last", "w2v_gru_srk.Net.last", "w2v_gru_srk.Net.last", "w2v_gru_srk.Net.sentence_embedding", "w2v_gru_srk.Net.fln_fc", "w2v_gru_srk.Net.krn_fc", "w2v_gru_srk.Net.append", "w2v_gru_srk.Net.append", "w2v_gru_srk.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "t", ",", "term", ",", "sentence", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", "=", "self", ".", "sentence_embedding", "(", "sentence", ")", ".", "float", "(", ")", "#sentence only", "\n", "\n", "fln_output", ",", "fln_hidden", ",", "c1", ",", "c2", ",", "c3", "=", "self", ".", "fln", ".", "gru", "(", "sequence_output", ")", "\n", "krn_output", ",", "krn_hidden", ",", "control_1", ",", "control_2", ",", "control_3", "=", "self", ".", "krn", ".", "gru", "(", "sequence_output", ")", "\n", "\n", "g", "=", "self", ".", "gate", "(", "self", ".", "fln_fc", "(", "fln_hidden", ")", "+", "self", ".", "krn_fc", "(", "krn_hidden", ")", ")", "\n", "h", "=", "(", "1", "-", "g", ")", "*", "fln_hidden", "+", "g", "*", "(", "krn_hidden", ")", "\n", "\n", "#loss ==============", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "krn_y", "=", "self", ".", "last", "(", "krn_hidden", ")", "\n", "fln_y", "=", "self", ".", "last", "(", "fln_hidden", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "krn_y", "=", "[", "]", "\n", "fln_y", "=", "[", "]", "\n", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "krn_y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "krn_hidden", ")", ")", "\n", "fln_y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "fln_hidden", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'fln_y'", "]", "=", "fln_y", "\n", "output_dict", "[", "'krn_y'", "]", "=", "krn_y", "\n", "output_dict", "[", "'control_1'", "]", "=", "control_1", ".", "data", ".", "clone", "(", ")", "\n", "output_dict", "[", "'control_2'", "]", "=", "control_2", ".", "data", ".", "clone", "(", ")", "\n", "output_dict", "[", "'control_3'", "]", "=", "control_3", ".", "data", ".", "clone", "(", ")", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.Net.get_view_for": [[95, 106], ["control_1_mask.data.view().expand_as", "control_2_mask.data.view().expand_as", "control_1_mask.data.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "control_2_mask.data.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", ")", ":", "\n", "        ", "if", "n", "==", "'krn.gru.gru_cell.x2h.weight'", ":", "\n", "# print('not none')", "\n", "            ", "return", "control_1_mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "krn", ".", "gru", ".", "gru_cell", ".", "x2h", ".", "weight", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.h2h.weight'", ":", "\n", "            ", "return", "control_2_mask", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "krn", ".", "gru", ".", "gru_cell", ".", "h2h", ".", "weight", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.h2h.bias'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", "]", ")", "\n", "", "elif", "n", "==", "'krn.gru.gru_cell.x2h.bias'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", "]", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.FLN.__init__": [[109, 125], ["torch.nn.Module.__init__", "w2v_gru_srk.GRUModel"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# self.gru = GRU(", "\n", "#             embedding_dim = args.w2v_hidden_size,", "\n", "#             hidden_dim = args.w2v_hidden_size,", "\n", "#             n_layers=1,", "\n", "#             bidirectional=False,", "\n", "#             dropout=0.5,", "\n", "#             args=args)", "\n", "\n", "self", ".", "gru", "=", "GRUModel", "(", "\n", "input_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "layer_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "output_dim", "=", "args", ".", "w2v_hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.KRN.__init__": [[128, 144], ["torch.nn.Module.__init__", "w2v_gru_srk.GRUModel"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "taskcla", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# self.gru = GRU(", "\n", "#             embedding_dim = args.w2v_hidden_size,", "\n", "#             hidden_dim = args.w2v_hidden_size,", "\n", "#             n_layers=1,", "\n", "#             bidirectional=False,", "\n", "#             dropout=0.5,", "\n", "#             args=args)", "\n", "\n", "self", ".", "gru", "=", "GRUModel", "(", "\n", "input_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "hidden_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "layer_dim", "=", "args", ".", "w2v_hidden_size", ",", "\n", "output_dim", "=", "args", ".", "w2v_hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUModel.__init__": [[148, 157], ["torch.nn.Module.__init__", "w2v_gru_srk.GRUCell"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "layer_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "GRUModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Hidden dimensions", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "# Number of hidden layers", "\n", "self", ".", "layer_dim", "=", "layer_dim", "\n", "\n", "self", ".", "gru_cell", "=", "GRUCell", "(", "input_dim", ",", "hidden_dim", ",", "layer_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUModel.forward": [[158, 192], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "outs[].squeeze", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.size", "w2v_gru_srk.GRUModel.gru_cell", "outs.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "len", "hidden.unsqueeze.unsqueeze.unsqueeze", "x.size", "hidden.unsqueeze.unsqueeze.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "# Initialize hidden state with zeros", "\n", "#######################", "\n", "#  USE GPU FOR MODEL  #", "\n", "#######################", "\n", "#print(x.shape,\"x.shape\")100, 28, 28", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "h0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_dim", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "h0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_dim", ")", "\n", "", "outs", "=", "[", "]", "\n", "control_1", "=", "[", "]", "\n", "control_2", "=", "[", "]", "\n", "control_3", "=", "[", "]", "\n", "hn", "=", "h0", "[", "0", ",", ":", ",", ":", "]", "\n", "for", "seq", "in", "range", "(", "x", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "hn", ",", "c_1", ",", "c_2", ",", "c_3", "=", "self", ".", "gru_cell", "(", "x", "[", ":", ",", "seq", ",", ":", "]", ",", "hn", ")", "\n", "outs", ".", "append", "(", "hn", ")", "\n", "control_1", ".", "append", "(", "c_1", ")", "\n", "control_2", ".", "append", "(", "c_2", ")", "\n", "control_3", ".", "append", "(", "c_3", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outs", ")", "\n", "control_1", "=", "torch", ".", "cat", "(", "control_1", ")", "\n", "control_2", "=", "torch", ".", "cat", "(", "control_2", ")", "\n", "control_3", "=", "torch", ".", "cat", "(", "control_3", ")", "\n", "\n", "hidden", "=", "outs", "[", "-", "1", "]", ".", "squeeze", "(", ")", "\n", "\n", "if", "len", "(", "hidden", ".", "size", "(", ")", ")", "<", "2", ":", "\n", "            ", "hidden", "=", "hidden", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "output", ",", "hidden", ",", "control_1", ",", "control_2", ",", "control_3", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUCell.__init__": [[201, 210], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "w2v_gru_srk.GRUCell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUCell.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "GRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "x2h", "=", "nn", ".", "Linear", "(", "input_size", ",", "3", "*", "hidden_size", ",", "bias", "=", "bias", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "3", "*", "hidden_size", ",", "bias", "=", "bias", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "self", ".", "k", "=", "0.001", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUCell.reset_parameters": [[210, 214], ["w2v_gru_srk.GRUCell.parameters", "math.sqrt", "w.data.uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "std", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_size", ")", "\n", "for", "w", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "w", ".", "data", ".", "uniform_", "(", "-", "std", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_gru_srk.GRUCell.forward": [[215, 242], ["x.view.view.view", "w2v_gru_srk.GRUCell.x2h", "w2v_gru_srk.GRUCell.h2h", "gate_x.unsqueeze.unsqueeze.squeeze", "gate_h.unsqueeze.unsqueeze.squeeze", "gate_x.unsqueeze.unsqueeze.chunk", "gate_h.unsqueeze.unsqueeze.chunk", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "x.view.view.size", "len", "gate_x.unsqueeze.unsqueeze.unsqueeze", "gate_h.unsqueeze.unsqueeze.unsqueeze", "gate_x.unsqueeze.unsqueeze.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "hidden", ")", ":", "\n", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "gate_x", "=", "self", ".", "x2h", "(", "x", ")", "\n", "gate_h", "=", "self", ".", "h2h", "(", "hidden", ")", "\n", "\n", "gate_x", "=", "gate_x", ".", "squeeze", "(", ")", "\n", "gate_h", "=", "gate_h", ".", "squeeze", "(", ")", "\n", "\n", "if", "len", "(", "gate_x", ".", "size", "(", ")", ")", "<", "2", ":", "\n", "            ", "gate_x", "=", "gate_x", ".", "unsqueeze", "(", "0", ")", "\n", "gate_h", "=", "gate_h", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "i_r", ",", "i_i", ",", "i_n", "=", "gate_x", ".", "chunk", "(", "3", ",", "1", ")", "\n", "h_r", ",", "h_i", ",", "h_n", "=", "gate_h", ".", "chunk", "(", "3", ",", "1", ")", "\n", "\n", "\n", "resetgate", "=", "F", ".", "sigmoid", "(", "i_r", "+", "h_r", ")", "\n", "inputgate", "=", "F", ".", "sigmoid", "(", "i_i", "+", "h_i", ")", "\n", "newgate", "=", "i_n", "+", "(", "resetgate", "*", "h_n", ")", "\n", "newgate", "[", "newgate", ">=", "0.9", "]", "=", "0.9", "+", "self", ".", "k", "*", "newgate", "[", "newgate", ">=", "0.9", "]", "\n", "newgate", "[", "newgate", "<=", "0", "]", "=", "self", ".", "k", "*", "newgate", "[", "newgate", "<=", "0", "]", "\n", "\n", "hy", "=", "newgate", "+", "inputgate", "*", "(", "hidden", "-", "newgate", ")", "\n", "\n", "\n", "return", "hy", ",", "x", ",", "hidden", ",", "(", "resetgate", "*", "h_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.__init__": [[14, 49], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "mlp_cat.MainContinualLearning", "mlp_cat.TransferLayer", "mlp_cat.KnowledgeTransfer", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "pdrop1", "=", "0.2", "\n", "pdrop2", "=", "0.5", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "\n", "self", ".", "mcl", "=", "MainContinualLearning", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "transfer", "=", "TransferLayer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "kt", "=", "KnowledgeTransfer", "(", "nhid", ",", "ncha", ",", "size", ",", "self", ".", "taskcla", ",", "args", ")", "\n", "self", ".", "smax", "=", "args", ".", "smax", "\n", "\n", "print", "(", "'MLP CAT'", ")", "\n", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature": [[50, 59], ["mlp_cat.Net.drop1", "mlp_cat.Net.drop2", "mlp_cat.Net.drop2", "x.view", "mlp_cat.Net.relu", "gfc1.expand_as", "mlp_cat.Net.relu", "gfc2.expand_as", "x.size", "mlp_cat.Net.mcl.fc1", "mlp_cat.Net.mcl.fc2"], "methods", ["None"], ["", "def", "mcl_feature", "(", "self", ",", "x", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.forward": [[61, 215], ["mlp_cat.Net.mask", "mlp_cat.Net.mcl_feature", "mlp_cat.Net.mcl.mask_last", "mlp_cat.Net.mask", "mlp_cat.Net.mcl_feature", "range", "mlp_cat.Net.mask", "pre_gfc1.data.clone.data.clone.data.clone", "pre_gfc2.data.clone.data.clone.data.clone", "mlp_cat.Net.mcl_feature", "pre_models.append", "pre_ts.append", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "task_models.permute.permute.permute", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "mlp_cat.Net.kt.encoder", "mlp_cat.Net.mcl_feature", "mlp_cat.Net.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mlp_cat.Net.clone", "mlp_cat.Net.relu().expand", "mlp_cat.Net.mcl.mask_last", "mlp_cat.Net.mcl.att_last", "mlp_cat.Net.Tsim_mask", "mlp_cat.Net.mcl_feature", "mlp_cat.Net.mcl_feature", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "task_models.permute.permute.size", "mlp_cat.Net.mcl.mask_last", "mlp_cat.Net.mcl.mask_last", "mlp_cat.Net.mcl.att_last", "mlp_cat.Net.mcl.mask_last", "check_federated.check_t", "mlp_cat.Net.relu", "mlp_cat.Net.append", "mlp_cat.Net.append", "mlp_cat.Net.append", "mlp_cat.Net.mcl.mask_last", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mlp_cat.Net.kt.q1", "mlp_cat.Net.append", "mlp_cat.Net.append", "mlp_cat.Net.append", "mlp_cat.Net.append", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mcl_feature", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.check_t", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", "=", "1", ",", "phase", "=", "None", ",", "\n", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ",", "\n", "similarity", "=", "None", ",", "history_mask_pre", "=", "None", ",", "check_federated", "=", "None", ")", ":", "\n", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "'mcl'", "in", "phase", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "'mcl'", "in", "phase", "and", "'multi-loss-joint-Tsim'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "pre_models", "=", "[", "]", "\n", "\n", "pre_ts", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "if", "self", ".", "training", "==", "True", "and", "similarity", "[", "pre_t", "]", ":", "\n", "                    ", "continue", "\n", "", "elif", "self", ".", "training", "==", "False", "and", "check_federated", ".", "check_t", "(", "pre_t", ")", "==", "False", ":", "\n", "#Cautions: testing needs to be careful", "\n", "                    ", "continue", "\n", "\n", "", "pre_gfc1", ",", "pre_gfc2", "=", "self", ".", "mask", "(", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "pre_t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", ",", "s", "=", "self", ".", "smax", ")", "\n", "pre_gfc1", "=", "pre_gfc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc2", "=", "pre_gfc2", ".", "data", ".", "clone", "(", ")", "\n", "\n", "pre_h", "=", "self", ".", "mcl_feature", "(", "x", ",", "pre_gfc1", ",", "pre_gfc2", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "pre_ts", ".", "append", "(", "pre_t", ")", "\n", "#Tsim: model for each Tsim", "\n", "\n", "", "if", "len", "(", "pre_models", ")", ">", "1", ":", "\n", "                ", "task_models", "=", "torch", ".", "stack", "(", "pre_models", ")", "\n", "task_models", "=", "task_models", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "query", "=", "torch", ".", "unsqueeze", "(", "self", ".", "relu", "(", "self", ".", "kt", ".", "q1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ".", "expand", "(", "task_models", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "#hard to train", "\n", "\n", "h_attn", ",", "_", "=", "self", ".", "kt", ".", "encoder", "(", "task_models", ",", "query", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                        ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "else", ":", "\n", "                ", "if", "'no-isolate'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "# only care about myself, even in forward pass", "\n", "                    ", "gfc1", ",", "gfc2", "=", "self", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "history_mask_pre", ",", "similarity", "=", "similarity", ")", "\n", "\n", "h_attn", "=", "self", ".", "mcl_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "transfer", ".", "last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.mask": [[218, 224], ["mlp_cat.Net.gate", "mlp_cat.Net.gate", "mlp_cat.Net.mcl.efc1", "mlp_cat.Net.mcl.efc2", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ",", "phase", "=", "None", ")", ":", "\n", "#used by training", "\n", "\n", "        ", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask": [[225, 247], ["range", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "mlp_cat.Net.gate", "mlp_cat.Net.gate", "[].round().nonzero", "[].round().nonzero", "mlp_cat.Net.mcl.efc1", "mlp_cat.Net.mcl.efc2", "[].round", "[].round", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "Tsim_mask", "(", "self", ",", "t", ",", "history_mask_pre", "=", "None", ",", "similarity", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "#find the distinct mask, used by block the backward pass", "\n", "\n", "#want aggregate Tsim", "\n", "        ", "if", "phase", "is", "None", ":", "\n", "#Tsim mask", "\n", "            ", "Tsim_gfc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "\n", "\n", "", "for", "history_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "history_t", "==", "0", ":", "\n", "                ", "Tsim_gfc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "else", ":", "\n", "                ", "Tsim_gfc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "0", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "1", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "if", "similarity", "[", "history_t", "]", "==", "0", ":", "\n", "                ", "Tsim_gfc1", "[", "Tsim_gfc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc2", "[", "Tsim_gfc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "\n", "", "", "return", "[", "Tsim_gfc1", ",", "Tsim_gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.get_view_for": [[249, 263], ["gfc1.data.view().expand_as", "gfc1.data.view", "gfc1.data.view", "gfc2.data.view().expand_as", "gfc1.data.view().expand_as", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "gfc2.data.view", "gfc2.data.view", "gfc1.data.view"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'mcl.fc1.weight'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'mcl.fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.pre_model_generator": [[265, 282], ["range", "mlp_cat.Net.mask", "mlp_cat.Net.drop1", "mlp_cat.Net.drop2", "mlp_cat.Net.drop2", "pre_models.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.view", "mlp_cat.Net.relu", "pre_gfc1.expand_as", "mlp_cat.Net.relu", "pre_gfc2.expand_as", "mlp_cat.Net.clone", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "x.size", "mlp_cat.Net.mcl.fc1", "mlp_cat.Net.mcl.fc2", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "pre_model_generator", "(", "self", ",", "t", ",", "similarity", ",", "x", ")", ":", "\n", "        ", "pre_models", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "similarity", "[", "pre_t", "]", "==", "0", ":", "\n", "                ", "continue", "\n", "", "pre_gfc1", ",", "pre_gfc2", "=", "self", ".", "mask", "(", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "pre_t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "pre_h", "=", "self", ".", "drop1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "\n", "pre_h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "pre_h", ")", ")", ")", "#fc1 is changing", "\n", "pre_h", "=", "pre_h", "*", "pre_gfc1", ".", "expand_as", "(", "pre_h", ")", "\n", "\n", "pre_h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "pre_h", ")", ")", ")", "\n", "pre_h", "=", "pre_h", "*", "pre_gfc2", ".", "expand_as", "(", "pre_h", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "", "return", "pre_models", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.MainContinualLearning.__init__": [[285, 313], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "len", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_cat.MainContinualLearning.mask_last.append", "mlp_cat.MainContinualLearning.att_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "MainContinualLearning", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "mask_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "self", ".", "att_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.TransferLayer.__init__": [[316, 361], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_cat.TransferLayer.transfer.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_cat.TransferLayer.transfer_to_n.append", "mlp_cat.TransferLayer.last.append", "mlp_cat.TransferLayer.last_fusion.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mlp_cat.TransferLayer.transfer.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "mlp_cat.TransferLayer.transfer_to_n.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "TransferLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n", "self", ".", "fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", "*", "2", ",", "nhid", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", "*", "2", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "# this one will not change according to different scenario", "\n", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "args", ".", "nclasses", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "self", ".", "last_fusion", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", "*", "2", ",", "n", ")", ")", "\n", "\n", "\n", "# this one will not change according to different scenario", "\n", "", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "from_n", ",", "to_n", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.KnowledgeTransfer.__init__": [[364, 378], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "mlp_cat.EncoderLayer", "mlp_cat.KnowledgeTransfer.last.append", "len", "len", "len", "int", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nhid", ",", "ncha", ",", "size", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "KnowledgeTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "taskcla", ":", "\n", "            ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "n", ")", ")", "\n", "\n", "", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "\n", "#self-attention ==============", "\n", "self", ".", "q1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "encoder", "=", "EncoderLayer", "(", "args", ".", "n_head", ",", "nhid", ",", "nhid", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "args", "=", "args", ")", "\n", "# n_head, d_model, d_k, d_v", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.EncoderLayer.__init__": [[384, 392], ["torch.Module.__init__", "mlp_cat.MultiHeadAttention", "mlp_cat.PositionwiseFeedForward", "mlp_cat.PositionalEncoding", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_inner", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.EncoderLayer.forward": [[393, 407], ["mlp_cat.EncoderLayer.layer_norm", "mlp_cat.EncoderLayer.slf_attn", "mlp_cat.EncoderLayer.pos_ffn", "mlp_cat.EncoderLayer.slf_attn", "mlp_cat.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "enc_q", "=", "None", ",", "ranking", "=", "None", ")", ":", "\n", "#TODO: Positional/ranking embedding", "\n", "\n", "        ", "if", "enc_q", "is", "None", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_input", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "else", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_q", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.MultiHeadAttention.__init__": [[411, 427], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "mlp_cat.ScaledDotProductAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "#sqrt d_k", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.MultiHeadAttention.forward": [[429, 463], ["torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "mlp_cat.MultiHeadAttention.layer_norm", "mlp_cat.MultiHeadAttention.w_qs().view", "mlp_cat.MultiHeadAttention.w_ks().view", "mlp_cat.MultiHeadAttention.w_vs().view", "mlp_cat.MultiHeadAttention.attention", "mlp_cat.MultiHeadAttention.dropout", "q.transpose().contiguous().view.transpose().contiguous().view.size", "q.transpose().contiguous().view.transpose().contiguous().view.size", "mlp_cat.MultiHeadAttention.size", "mlp_cat.MultiHeadAttention.size", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "mlp_cat.MultiHeadAttention.transpose", "mlp_cat.MultiHeadAttention.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "mlp_cat.MultiHeadAttention.fc", "mlp_cat.MultiHeadAttention.w_qs", "mlp_cat.MultiHeadAttention.w_ks", "mlp_cat.MultiHeadAttention.w_vs", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "q.transpose().contiguous().view.transpose().contiguous().view.transpose", "q.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "torch", ".", "squeeze", "(", "q", ",", "1", ")", "\n", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "\n", "q", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "\n", "if", "len_q", "==", "1", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "\n", "", "q", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "q", ")", ")", "\n", "q", "+=", "residual", "\n", "\n", "return", "q", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.ScaledDotProductAttention.__init__": [[467, 471], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.ScaledDotProductAttention.forward": [[472, 479], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "mlp_cat.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionwiseFeedForward.__init__": [[483, 489], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "# position-wise", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionwiseFeedForward.forward": [[490, 500], ["mlp_cat.PositionwiseFeedForward.layer_norm", "mlp_cat.PositionwiseFeedForward.w_2", "mlp_cat.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "mlp_cat.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "w_2", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "+=", "residual", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding.__init__": [[504, 509], ["torch.Module.__init__", "mlp_cat.PositionalEncoding.register_buffer", "mlp_cat.PositionalEncoding._get_sinusoid_encoding_table"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding._get_sinusoid_encoding_table"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "n_position", "=", "40", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Not a parameter", "\n", "self", ".", "register_buffer", "(", "'pos_table'", ",", "self", ".", "_get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding._get_sinusoid_encoding_table": [[510, 522], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "mlp_cat.PositionalEncoding._get_sinusoid_encoding_table.get_position_angle_vec"], "methods", ["None"], ["", "def", "_get_sinusoid_encoding_table", "(", "self", ",", "n_position", ",", "d_hid", ")", ":", "\n", "        ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy", "\n", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "            ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.PositionalEncoding.forward": [[523, 525], ["mlp_cat.PositionalEncoding.pos_table[].clone().detach", "mlp_cat.PositionalEncoding.pos_table[].clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "ranking", ")", ":", "\n", "        ", "return", "enc_input", "+", "self", ".", "pos_table", "[", ":", ",", "ranking", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.__init__": [[12, 56], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn.Net.last.append", "cnn.Net.merge_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "s", "*", "s", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "self", ".", "old_weight_norm", "=", "[", "]", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "nclasses", "*", "2", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "merge_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "n", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'CNN'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.forward": [[57, 74], ["cnn.Net.features", "torch.normalize", "torch.normalize", "cnn.Net.last", "cnn.Net.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h", "=", "self", ".", "features", "(", "x", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features": [[75, 83], ["cnn.Net.maxpool", "cnn.Net.maxpool", "cnn.Net.maxpool", "cnn.Net.view", "cnn.Net.drop2", "cnn.Net.drop2", "cnn.Net.drop1", "cnn.Net.drop1", "cnn.Net.drop2", "x.size", "cnn.Net.relu", "cnn.Net.relu", "cnn.Net.relu", "cnn.Net.relu", "cnn.Net.relu", "cnn.Net.fc1", "cnn.Net.fc2", "cnn.Net.conv1", "cnn.Net.conv2", "cnn.Net.conv3"], "methods", ["None"], ["", "def", "features", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "conv3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.save_old_norm": [[87, 90], ["cnn.Net.old_weight_norm.append", "cnn.Net.last.weight.cpu().detach().numpy", "cnn.Net.last.weight.cpu().detach", "cnn.Net.last.weight.cpu"], "methods", ["None"], ["", "def", "save_old_norm", "(", "self", ")", ":", "\n", "        ", "old_weight", "=", "self", ".", "last", ".", "weight", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "copy", "\n", "self", ".", "old_weight_norm", ".", "append", "(", "old_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.align_norms": [[91, 115], ["new_layer.weight.cpu().detach().numpy", "numpy.concatenate", "print", "print", "numpy.linalg.norm", "numpy.linalg.norm", "print", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "numpy.mean", "numpy.mean", "new_layer.weight.cpu().detach", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "new_layer.weight.cpu", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "align_norms", "(", "self", ")", ":", "\n", "# Fetch old and new layers", "\n", "\n", "        ", "new_layer", "=", "self", ".", "last", "\n", "old_layers", "=", "self", ".", "old_weight_norm", "\n", "\n", "# Get weight of layers", "\n", "new_weight", "=", "new_layer", ".", "weight", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "old_weight", "=", "np", ".", "concatenate", "(", "[", "old_layers", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "old_weight_norm", ")", ")", "]", ")", "\n", "\n", "print", "(", "\"old_weight's shape is: \"", ",", "old_weight", ".", "shape", ")", "\n", "print", "(", "\"new_weight's shape is: \"", ",", "new_weight", ".", "shape", ")", "\n", "\n", "# Calculate the norm", "\n", "Norm_of_new", "=", "np", ".", "linalg", ".", "norm", "(", "new_weight", ",", "axis", "=", "1", ")", "\n", "Norm_of_old", "=", "np", ".", "linalg", ".", "norm", "(", "old_weight", ",", "axis", "=", "1", ")", "\n", "# Calculate the Gamma", "\n", "gamma", "=", "np", ".", "mean", "(", "Norm_of_new", ")", "/", "np", ".", "mean", "(", "Norm_of_old", ")", "\n", "print", "(", "\"Gamma = \"", ",", "gamma", ")", "\n", "\n", "# Update new layer's weight", "\n", "updated_new_weight", "=", "torch", ".", "Tensor", "(", "gamma", "*", "new_weight", ")", ".", "cuda", "(", ")", "\n", "self", ".", "last", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "updated_new_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.merge_head": [[118, 126], ["cnn.Net.merge_last", "cnn.Net.append"], "methods", ["None"], ["", "def", "merge_head", "(", "self", ",", "h", ")", ":", "\n", "        ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "merge_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "merge_last", "[", "t", "]", "(", "h", ")", ")", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params": [[129, 139], ["list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn.Net.parameters", "params.append", "pp.view"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns all the parameters concatenated in a single tensor.\n        :return: parameters tensor (input_size * 100 + 100 + 100 * 100 + 100 +\n                                    + 100 * output_size + output_size)\n        \"\"\"", "\n", "params", "=", "[", "]", "\n", "for", "pp", "in", "list", "(", "self", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "params", ".", "append", "(", "pp", ".", "view", "(", "-", "1", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.set_params": [[140, 153], ["list", "new_params.size", "cnn.Net.get_params().size", "cnn.Net.parameters", "new_params[].view", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "pp.size", "cnn.Net.get_params", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pp.size", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor().prod", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pp.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params"], ["", "def", "set_params", "(", "self", ",", "new_params", ":", "torch", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the parameters to a given value.\n        :param new_params: concatenated values to be set (input_size * 100\n                    + 100 + 100 * 100 + 100 + 100 * output_size + output_size)\n        \"\"\"", "\n", "assert", "new_params", ".", "size", "(", ")", "==", "self", ".", "get_params", "(", ")", ".", "size", "(", ")", "\n", "progress", "=", "0", "\n", "for", "pp", "in", "list", "(", "self", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "cand_params", "=", "new_params", "[", "progress", ":", "progress", "+", "\n", "torch", ".", "tensor", "(", "pp", ".", "size", "(", ")", ")", ".", "prod", "(", ")", "]", ".", "view", "(", "pp", ".", "size", "(", ")", ")", "\n", "progress", "+=", "torch", ".", "tensor", "(", "pp", ".", "size", "(", ")", ")", ".", "prod", "(", ")", "\n", "pp", ".", "data", "=", "cand_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.num_flat_features": [[154, 165], ["x.size"], "methods", ["None"], ["", "", "def", "num_flat_features", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Computes the total number of items except the first dimension.\n        :param x: input tensor\n        :return: number of item from the second dimension onward\n        \"\"\"", "\n", "size", "=", "x", ".", "size", "(", ")", "[", "1", ":", "]", "\n", "num_features", "=", "1", "\n", "for", "ff", "in", "size", ":", "\n", "            ", "num_features", "*=", "ff", "\n", "", "return", "num_features", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.__init__": [[14, 62], ["super().__init__", "transformers.BertConfig.from_pretrained", "my_transformers.MyBertModel.from_pretrained", "bert_adapter_capsule_mask.Net.bert.parameters", "torch.nn.ModuleList", "torch.nn.Dropout", "len", "print", "adapter_mask.parameters", "bert_adapter_capsule_mask.Net.last.append", "torch.nn.Linear", "range", "range", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "config", ".", "return_dict", "=", "False", "\n", "args", ".", "build_adapter_capsule_mask", "=", "True", "\n", "self", ".", "bert", "=", "MyBertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "config", "=", "config", ",", "args", "=", "args", ")", "\n", "\n", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "# param.requires_grad = True", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "for", "adapter_mask", "in", "adapter_masks", ":", "\n", "            ", "for", "param", "in", "adapter_mask", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "            ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_task", "=", "len", "(", "taskcla", ")", "\n", "self", ".", "num_kernel", "=", "3", "\n", "\n", "print", "(", "'BERT ADAPTER CAPSULE MASK'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.forward": [[63, 83], ["bert_adapter_capsule_mask.Net.bert", "bert_adapter_capsule_mask.Net.dropout", "bert_adapter_capsule_mask.Net.mask", "y.append"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "s", "=", "1", ")", ":", "\n", "\n", "\n", "        ", "output_dict", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "\n", "targets", "=", "None", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "            ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.mask": [[84, 107], ["range", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].output.adapter_capsule_mask.mask", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].output.adapter_capsule_mask.capsule_net.tsv_capsules.mask", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].attention.output.adapter_capsule_mask.mask", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.mask", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "masks", "=", "{", "}", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "\n", "            ", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "                ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger'", "#gfc1", "\n", "masks", "[", "key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "                ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger'", "#gfc1", "\n", "masks", "[", "key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "", "", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for": [[111, 152], ["range", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "masks[].data.view", "masks[].data.view", "masks[].data.view", "str", "masks[].data.view", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "torch.min", "str", "masks[].data.view", "str", "masks[].data.view", "str", "masks[].data.view", "str", "str", "str", "masks[].data.view", "masks[].data.view", "masks[].data.view().expand_as", "str", "masks[].data.view", "n.replace", "str", "masks[].data.view", "masks[].data.view().expand_as", "masks[].data.view().expand_as", "torch.min", "n.replace", "n.replace", "n.replace", "str", "masks[].data.view", "n.replace", "n.replace", "n.replace", "str", "masks[].data.view", "masks[].data.view", "n.replace", "n.replace().replace", "str", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace", "n.replace().replace", "n.replace"], "methods", ["None"], ["", "def", "get_view_for", "(", "self", ",", "n", ",", "p", ",", "masks", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.weight'", ":", "#gfc1", "\n", "# print('tsv_capsules not none')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.bias'", ":", "#gfc1", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.weight'", ":", "#gfc1", "\n", "# print('tsv_capsules not none')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.bias'", ":", "#gfc1", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for_tsv": [[153, 231], ["range", "range", "range", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].output.adapter_capsule_mask.capsule_net.tsv_capsules.tsv[].data.view", "range", "bert_adapter_capsule_mask.Net.bert.encoder.layer[].attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.tsv[].data.view", "range", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "get_view_for_tsv", "(", "self", ",", "n", ",", "t", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", ":", "\n", "# print('not none')", "\n", "                ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "", "for", "c_t", "in", "range", "(", "self", ".", "num_task", ")", ":", "\n", "                ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('not none')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "for", "m_t", "in", "range", "(", "self", ".", "num_kernel", ")", ":", "\n", "                    ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "# print('not none')", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", ":", "\n", "# print('not none')", "\n", "                ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "for", "c_t", "in", "range", "(", "self", ".", "num_task", ")", ":", "\n", "                ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('not none')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "\n", "", "for", "m_t", "in", "range", "(", "self", ".", "num_kernel", ")", ":", "\n", "                    ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "", "", "", "return", "1", "#if no condition is satified", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Net.__init__": [[12, 52], ["torch.Module.__init__", "bayes_layer.BayesianConv2D", "utils.compute_conv_output_size", "bayes_layer.BayesianConv2D", "utils.compute_conv_output_size", "bayes_layer.BayesianConv2D", "utils.compute_conv_output_size", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "bayes_layer.BayesianLinear", "bayes_layer.BayesianLinear", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "cnn_ucl.Net.last.append", "cnn_ucl.Net.merge_last.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.compute_conv_output_size"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "self", ".", "conv1", "=", "BayesianConv2D", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv2", "=", "BayesianConv2D", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv3", "=", "BayesianConv2D", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "BayesianLinear", "(", "256", "*", "s", "*", "s", ",", "2048", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "self", ".", "fc2", "=", "BayesianLinear", "(", "2048", ",", "2048", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "self", ".", "old_weight_norm", "=", "[", "]", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "nclasses", "*", "2", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "merge_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "n", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'DIL CNN'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Net.forward": [[54, 76], ["cnn_ucl.Net.maxpool", "cnn_ucl.Net.maxpool", "cnn_ucl.Net.maxpool", "cnn_ucl.Net.view", "cnn_ucl.Net.drop2", "cnn_ucl.Net.drop2", "torch.normalize", "torch.normalize", "torch.normalize", "cnn_ucl.Net.drop1", "cnn_ucl.Net.drop1", "cnn_ucl.Net.drop2", "x.size", "cnn_ucl.Net.relu", "cnn_ucl.Net.relu", "cnn_ucl.Net.last", "cnn_ucl.Net.relu", "cnn_ucl.Net.relu", "cnn_ucl.Net.relu", "cnn_ucl.Net.fc1", "cnn_ucl.Net.fc2", "cnn_ucl.Net.conv1", "cnn_ucl.Net.conv2", "cnn_ucl.Net.conv3", "cnn_ucl.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "conv3", "(", "h", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ",", "sample", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ",", "sample", ")", ")", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Private.__init__": [[10, 25], ["super().__init__", "torch.nn.ModuleList", "range", "torch.nn.Sequential", "mlp_acl.Private.linear.add_module", "mlp_acl.Private.linear.add_module", "mlp_acl.Private.task_out.append", "torch.nn.Linear", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Private", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "self", ".", "task_out", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "linear", ".", "add_module", "(", "'linear'", ",", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", ")", "\n", "self", ".", "linear", ".", "add_module", "(", "'relu'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "task_out", ".", "append", "(", "self", ".", "linear", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Private.forward": [[26, 29], ["x_p.view.view.view", "mlp_acl.Private.task_out[].forward", "x_p.view.view.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "", "def", "forward", "(", "self", ",", "x_p", ",", "t", ")", ":", "\n", "        ", "x_p", "=", "x_p", ".", "view", "(", "x_p", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "return", "self", ".", "task_out", "[", "t", "]", ".", "forward", "(", "x_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Shared.__init__": [[34, 46], ["super().__init__", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Shared", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "ncha", "*", "size", "*", "size", ",", "nhid", ")", "\n", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Shared.forward": [[47, 54], ["x_s.view", "mlp_acl.Shared.drop", "mlp_acl.Shared.drop", "x_s.size", "mlp_acl.Shared.relu", "mlp_acl.Shared.relu", "mlp_acl.Shared.fc1", "mlp_acl.Shared.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_s", ")", ":", "\n", "\n", "        ", "h", "=", "x_s", ".", "view", "(", "x_s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.__init__": [[58, 96], ["super().__init__", "mlp_acl.Shared", "mlp_acl.Private", "print", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ModuleList", "range", "mlp_acl.Net.last.append", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "nhid", "=", "args", ".", "mlp_adapter_size", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "\n", "self", ".", "shared", "=", "Shared", "(", "args", ")", "\n", "self", ".", "private", "=", "Private", "(", "args", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "self", ".", "taskcla", "[", "i", "]", "[", "1", "]", ")", "\n", ")", ")", "\n", "\n", "", "", "print", "(", "'MLP ACL'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.forward": [[97, 122], ["mlp_acl.Net.view", "mlp_acl.Net.view", "mlp_acl.Net.shared", "mlp_acl.Net.private", "torch.cat", "mlp_acl.Net.size", "mlp_acl.Net.size", "mlp_acl.Net.last", "mlp_acl.Net.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_s", ",", "x_p", ",", "tt", ",", "t", ")", ":", "\n", "# train_tt = []  # task module labels", "\n", "# train_td = []  # disctiminator labels", "\n", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h_s", "=", "x_s", ".", "view", "(", "x_s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h_p", "=", "x_s", ".", "view", "(", "x_p", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "x_s", "=", "self", ".", "shared", "(", "h_s", ")", "\n", "x_p", "=", "self", ".", "private", "(", "h_p", ",", "t", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x_p", ",", "x_s", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "x", ")", "\n", "\n", "", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "x", ")", ")", "\n", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.get_encoded_ftrs": [[123, 125], ["mlp_acl.Net.shared", "mlp_acl.Net.private"], "methods", ["None"], ["", "def", "get_encoded_ftrs", "(", "self", ",", "x_s", ",", "x_p", ",", "t", ")", ":", "\n", "        ", "return", "self", ".", "shared", "(", "x_s", ")", ",", "self", ".", "private", "(", "x_p", ",", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.print_model_size": [[127, 138], ["sum", "sum", "sum", "print", "print", "print", "print", "print", "p.numel", "p.numel", "p.numel", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print", "mlp_acl.Net.private.parameters", "mlp_acl.Net.shared.parameters", "mlp_acl.Net.last.parameters", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print", "mlp_acl.Net.pretty_print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print"], ["", "def", "print_model_size", "(", "self", ")", ":", "\n", "        ", "count_P", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "private", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_S", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "shared", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_H", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "last", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "print", "(", "'Num parameters in S       = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_S", ")", ")", ")", "\n", "print", "(", "'Num parameters in P       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_P", ")", ",", "self", ".", "pretty_print", "(", "count_P", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in p       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_H", ")", ",", "self", ".", "pretty_print", "(", "count_H", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in P+p     = %s '", "%", "self", ".", "pretty_print", "(", "count_P", "+", "count_H", ")", ")", "\n", "print", "(", "'-------------------------->   Total architecture size: %s parameters (%sB)'", "%", "(", "self", ".", "pretty_print", "(", "count_S", "+", "count_P", "+", "count_H", ")", ",", "\n", "self", ".", "pretty_print", "(", "4", "*", "(", "count_S", "+", "count_P", "+", "count_H", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.pretty_print": [[139, 145], ["abs"], "methods", ["None"], ["", "def", "pretty_print", "(", "self", ",", "num", ")", ":", "\n", "        ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "            ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.2f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_derpp.Appr.__init__": [[31, 36], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'DIL BERT Adapter NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_derpp.Appr.train": [[37, 120], ["bert_adapter_derpp.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "print", "int", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "input_ids.to.to.to", "segment_ids.to.to.to", "input_mask.to.to.to", "targets.to.to.to", "bert_adapter_derpp.Appr.model.forward", "bert_adapter_derpp.Appr.buffer.add_data", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_derpp.Appr.train_epoch", "time.time", "bert_adapter_derpp.Appr.eval", "time.time", "print", "bert_adapter_derpp.Appr.eval", "print", "print", "len", "iter", "bert_adapter_derpp.Appr.model.named_parameters", "utils.get_model", "print", "len", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "any", "len", "len", "any", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "self", ".", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "labels", "=", "targets", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", ",", "\n", "logits", "=", "cur_task_output", ".", "data", "\n", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_derpp.Appr.train_epoch": [[121, 175], ["bert_adapter_derpp.Appr.model.train", "enumerate", "bert_adapter_derpp.Appr.model.forward", "bert_adapter_derpp.Appr.ce", "iter_bar.set_description", "bert_adapter_derpp.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_derpp.Appr.buffer.is_empty", "bert_adapter_derpp.Appr.buffer.get_data", "buf_inputs.long", "buf_segment_ids.long", "buf_input_mask.long", "buf_labels.long", "bert_adapter_derpp.Appr.model.forward", "bert_adapter_derpp.Appr.warmup_linear", "bat.to", "bert_adapter_derpp.Appr.ce", "bert_adapter_derpp.Appr.mse", "bert_adapter_derpp.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_logits", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "\n", "buf_task_inputs", "=", "buf_inputs", ".", "long", "(", ")", "\n", "buf_task_segment", "=", "buf_segment_ids", ".", "long", "(", ")", "\n", "buf_task_mask", "=", "buf_input_mask", ".", "long", "(", ")", "\n", "buf_task_labels", "=", "buf_labels", ".", "long", "(", ")", "\n", "buf_task_logits", "=", "buf_logits", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "buf_task_inputs", ",", "buf_task_segment", ",", "buf_task_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "+=", "self", ".", "args", ".", "beta", "*", "self", ".", "ce", "(", "cur_task_output", ",", "buf_task_labels", ")", "\n", "loss", "+=", "self", ".", "args", ".", "alpha", "*", "self", ".", "mse", "(", "cur_task_output", ",", "buf_task_logits", ")", "\n", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_derpp.Appr.eval": [[176, 211], ["bert_adapter_derpp.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_adapter_derpp.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_derpp.Appr.model.forward", "bert_adapter_derpp.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_derpp.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_derpp.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_derpp.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Appr.__init__": [[22, 28], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["self", ".", "args", "=", "args", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Appr.train": [[30, 92], ["utils.get_model", "cnn_hat.Appr._get_optimizer", "utils.set_model_", "cnn_hat.Appr.model.mask", "range", "cnn_hat.Appr.model.named_parameters", "range", "len", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "cnn_hat.Appr.model.get_view_for", "time.time", "tqdm.tqdm.tqdm", "cnn_hat.Appr.train_epoch", "time.time", "cnn_hat.Appr.eval", "time.time", "print", "cnn_hat.Appr.eval", "print", "print", "print", "mask[].data.clone", "len", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "utils.get_model", "print", "len", "len", "print", "cnn_hat.Appr._get_optimizer", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "\n", "", "", "if", "'Attn-HCHP-Outside'", "in", "self", ".", "args", ".", "mix_type", ":", "\n", "            ", "if", "self", ".", "args", ".", "task_based", ":", "\n", "                ", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "                    ", "self", ".", "self_attns_", "=", "nn", ".", "ModuleList", "(", ")", "\n", "offset", "=", "0", "\n", "for", "n", "in", "range", "(", "args", ".", "naug", ")", ":", "\n", "                        ", "if", "n", ">", "1", ":", "offset", "+=", "1", "\n", "if", "t", "+", "1", "-", "offset", "==", "0", ":", "break", "\n", "self", ".", "self_attns_", ".", "append", "(", "Self_Attn", "(", "t", "+", "1", "-", "offset", ")", ")", "\n", "", "self", ".", "self_attns", ".", "append", "(", "self", ".", "self_attns_", ")", "\n", "\n", "", "", "", "\"\"\" (e.g., used in the compression experiments)\n        lo,hi=0,2\n        self.ec1.weight.data.uniform_(lo,hi)\n        self.ec2.weight.data.uniform_(lo,hi)\n        self.ec3.weight.data.uniform_(lo,hi)\n        self.efc1.weight.data.uniform_(lo,hi)\n        self.efc2.weight.data.uniform_(lo,hi)\n        #\"\"\"", "\n", "\n", "print", "(", "'DIL CNN HAT'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "start_mixup", "=", "None", ",", "s", "=", "None", ",", "l", "=", "None", ",", "idx", "=", "None", ",", "mix_type", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "\n", "if", "start_mixup", "and", "'Attn-HCHP-Outside'", "in", "mix_type", ":", "\n", "# print('attn type: ', self.args.attn_type)", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "if", "self", ".", "args", ".", "attn_type", "==", "'self'", ":", "\n", "                ", "h", "=", "self", ".", "self_attention_feature", "(", "t", ",", "x", ",", "h", ",", "l", ",", "idx", ",", "self", ".", "args", ".", "smax", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Appr.train_epoch": [[93, 170], ["cnn_hat.Appr.model.train", "enumerate", "cnn_hat.Appr.model", "cnn_hat.Appr.criterion_hat", "iter_bar.set_description", "cnn_hat.Appr.optimizer.zero_grad", "loss.backward", "cnn_hat.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "cnn_hat.Appr.optimizer.step", "cnn_hat.Appr.model.named_parameters", "cnn_hat.Appr.model.named_parameters", "n.startswith", "cnn_hat.Appr.model.parameters", "n.startswith", "t.to", "len", "torch.normalize", "torch.normalize", "torch.normalize", "cnn_hat.Appr.amix_loss", "cnn_hat.Appr.amix_loss", "torch.normalize", "torch.normalize", "torch.normalize", "cnn_hat.Appr.augment_distill_loss", "cnn_hat.Appr.augment_distill_loss", "torch.normalize", "torch.normalize", "torch.normalize", "cnn_hat.Appr.sup_loss", "cnn_hat.Appr.sup_loss", "loss.item", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.amix_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.amix_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.augment_distill_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.augment_distill_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["\n", "", "", "else", ":", "\n", "# print('others: ')", "\n", "\n", "            ", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "", "def", "self_attention_feature", "(", "self", ",", "t", ",", "x", ",", "pooled_output", ",", "order", ",", "idx", ",", "smax", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "feature_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "1", ")", "#softmax on task", "\n", "\n", "", "elif", "self", ".", "args", ".", "task_based", ":", "\n", "            ", "pre_hs", "=", "[", "]", "\n", "for", "pre_t", "in", "order", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "pre_t", ",", "s", "=", "smax", ")", "\n", "pre_h", "=", "self", ".", "get_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "", "pre_hs", ".", "append", "(", "pre_h", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "pre_hs", "=", "torch", ".", "cat", "(", "pre_hs", ",", "-", "1", ")", "\n", "pre_hs", "=", "torch", ".", "cat", "(", "[", "pre_hs", ",", "pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "]", ",", "-", "1", ")", "# include itselves", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "t", "]", "[", "idx", "]", "(", "pre_hs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "-", "1", ")", "#softmax on task", "\n", "\n", "", "return", "pooled_output", "\n", "\n", "\n", "\n", "\n", "", "def", "get_feature", "(", "self", ",", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n", "\n", "\n", "", "def", "get_feature_augment", "(", "self", ",", "x", ",", "x_b", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ",", "l", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hat.Appr.eval": [[171, 232], ["cnn_hat.Appr.model.eval", "cnn_hat.Appr.f1_compute_fn", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "targets.size", "cnn_hat.Appr.criterion_hat", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "loss.data.cpu().numpy().item", "t.to", "cnn_hat.Appr.model.forward", "cnn_hat.Appr.model.forward", "hits.sum().data.cpu().numpy", "cnn_hat.Appr.ent_id_detection", "cnn_hat.Appr.ent_id_detection", "cnn_hat.Appr.model.forward", "loss.data.cpu().numpy", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "h_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "h_b", ")", ")", ")", ")", "\n", "h_b", "=", "h_b", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h_b", ")", "\n", "h_b", "=", "h_b", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "h", "=", "l", "*", "h", "+", "(", "1", "-", "l", ")", "*", "h_b", "\n", "\n", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n", "\n", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n", "", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "if", "n", "==", "'fc1.weight'", ":", "\n", "            ", "post", "=", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "pre", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "(", "self", ".", "ec3", ".", "weight", ".", "size", "(", "1", ")", ",", "self", ".", "smid", ",", "self", ".", "smid", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c1.weight'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'c1.bias'", ":", "\n", "            ", "return", "gc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "pre", "=", "gc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'c2.bias'", ":", "\n", "            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "pre", "=", "gc2", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "c3", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ncl.Appr.__init__": [[30, 35], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'DIL BERT Adapter NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ncl.Appr.train": [[36, 87], ["bert_adapter_ncl.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_ncl.Appr.train_epoch", "time.time", "bert_adapter_ncl.Appr.eval", "time.time", "print", "bert_adapter_ncl.Appr.eval", "print", "print", "bert_adapter_ncl.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ncl.Appr.train_epoch": [[88, 123], ["bert_adapter_ncl.Appr.model.train", "enumerate", "bert_adapter_ncl.Appr.model.forward", "bert_adapter_ncl.Appr.ce", "iter_bar.set_description", "bert_adapter_ncl.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_ncl.Appr.sup_loss", "bert_adapter_ncl.Appr.warmup_linear", "bat.to", "bert_adapter_ncl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ncl.Appr.eval": [[124, 159], ["bert_adapter_ncl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_adapter_ncl.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_ncl.Appr.model.forward", "bert_adapter_ncl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_ncl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_ncl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_ncl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.warmup_linear": [[15, 19], ["None"], "methods", ["None"], ["    ", "def", "warmup_linear", "(", "self", ",", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "        ", "if", "x", "<", "warmup", ":", "\n", "            ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.__init__": [[21, 51], ["copy.deepcopy", "random.seed", "numpy.random.seed", "torch.manual_seed", "args.output_dir.replace", "os.makedirs", "json.dump", "torch.device", "torch.cuda.device_count", "logger.info", "torch.nn.CrossEntropyLoss", "print", "os.getenv", "open", "os.path.join", "torch.cuda.is_available"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "args", ".", "output_dir", "=", "args", ".", "output_dir", ".", "replace", "(", "\n", "'[PT_OUTPUT_DIR]'", ",", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ",", "''", ")", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "json", ".", "dump", "(", "args", ".", "__dict__", ",", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'opt.json'", ")", ",", "'w'", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "2", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"device: {} n_gpu: {}\"", ".", "format", "(", "\n", "self", ".", "device", ",", "self", ".", "n_gpu", ")", ")", "\n", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "print", "(", "'DIL BERT MTL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.train": [[52, 103], ["copy.deepcopy", "bert_mtl.Appr.model.to", "pytorch_pretrained_bert.optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_mtl.Appr.train_epoch", "time.time", "bert_mtl.Appr.eval_validation", "time.time", "print", "bert_mtl.Appr.eval_validation", "print", "print", "bert_mtl.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval_validation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval_validation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model", "\n", "\n", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", "=", "self", ".", "eval_validation", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f} |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", "=", "self", ".", "eval_validation", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f} |'", ".", "format", "(", "valid_loss", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.train_epoch": [[104, 130], ["bert_mtl.Appr.model.train", "enumerate", "bert_mtl.Appr.model.forward", "bert_mtl.Appr.criterion_train", "iter_bar.set_description", "bert_mtl.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_mtl.Appr.warmup_linear", "bat.to", "bert_mtl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.criterion_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "_", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "tasks", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "# Forward", "\n", "loss", "=", "self", ".", "criterion_train", "(", "tasks", ",", "outputs", ",", "targets", ")", "\n", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.eval_validation": [[131, 155], ["bert_mtl.Appr.model.eval", "torch.no_grad", "enumerate", "input_ids.size", "bert_mtl.Appr.model.forward", "bert_mtl.Appr.criterion_train", "bert_mtl.Appr.data.cpu().numpy().item", "bat.to", "bert_mtl.Appr.data.cpu().numpy", "bert_mtl.Appr.data.cpu"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.criterion_train"], ["", "def", "eval_validation", "(", "self", ",", "_", ",", "data", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Loop batches", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "tasks", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "# Forward", "\n", "loss", "=", "self", ".", "criterion_train", "(", "tasks", ",", "outputs", ",", "targets", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_num", "+=", "real_b", "\n", "\n", "\n", "", "", "return", "total_loss", "/", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.eval": [[156, 192], ["bert_mtl.Appr.model.eval", "torch.no_grad", "enumerate", "bert_mtl.Appr.f1_compute_fn", "input_ids.size", "bert_mtl.Appr.model.forward", "bert_mtl.Appr.criterion", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_mtl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_mtl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_mtl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "# This is used for the test. All tasks separately", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "# Forward", "\n", "# output=outputs #shared head", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.criterion_train": [[196, 210], ["numpy.unique", "tasks.data.cpu().numpy", "int", "targets.size", "bert_mtl.Appr.criterion", "len", "tasks.data.cpu"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "criterion_train", "(", "self", ",", "tasks", ",", "outputs", ",", "targets", ")", ":", "\n", "        ", "loss", "=", "0", "\n", "for", "t", "in", "np", ".", "unique", "(", "tasks", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ":", "\n", "            ", "t", "=", "int", "(", "t", ")", "\n", "# output = outputs  # shared head", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "outputs", "#always shared head", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "idx", "=", "(", "tasks", "==", "t", ")", ".", "data", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss", "+=", "self", ".", "criterion", "(", "output", "[", "idx", ",", ":", "]", ",", "targets", "[", "idx", "]", ")", "*", "len", "(", "idx", ")", "\n", "", "return", "loss", "/", "targets", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_mtl.Appr.f1_compute_fn": [[211, 220], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.__init__": [[31, 40], ["bert_adapter_base.Appr.__init__", "print", "print", "logger.info"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\" Class implementing the L2 approach described in https://github.com/GT-RIPL/Continual-Learning-Benchmark/blob/master/agents/regularization.py \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL + KIM NCL'", ")", "\n", "print", "(", "'BERT ADAPTER L2 NCL'", ")", "\n", "logger", ".", "info", "(", "'BERT ADAPTER L2 NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.train": [[41, 113], ["bert_adapter_l2.Appr.model.to", "optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "bert_adapter_l2.Appr.params.items", "bert_adapter_l2.Appr.calculate_importance", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_l2.Appr.train_epoch", "time.time", "bert_adapter_l2.Appr.eval", "time.time", "bert_adapter_l2.Appr.logger.info", "bert_adapter_l2.Appr.eval", "bert_adapter_l2.Appr.logger.info", "print", "p.clone().detach", "bert_adapter_l2.Appr.model.named_parameters", "utils.get_model", "bert_adapter_l2.Appr.logger.info", "len", "p.clone", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.calculate_importance", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "self", ".", "logger", ".", "info", "(", "' *'", ")", "\n", "# print(' *',end='')", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "# 2.Backup the weight of current task", "\n", "task_param", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "task_param", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# 3.Calculate the importance of weights for current task", "\n", "", "importance", "=", "self", ".", "calculate_importance", "(", ")", "\n", "\n", "# Save the weight and importance of weights of current task", "\n", "self", ".", "task_count", "+=", "1", "\n", "if", "self", ".", "online_reg", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Always use only one slot in self.regularization_terms", "\n", "            ", "self", ".", "regularization_terms", "[", "1", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "", "else", ":", "\n", "# Use a new slot to store the task-specific information", "\n", "            ", "self", ".", "regularization_terms", "[", "self", ".", "task_count", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.train_epoch": [[114, 144], ["bert_adapter_l2.Appr.model.train", "enumerate", "bert_adapter_l2.Appr.model.forward", "bert_adapter_l2.Appr.criterion", "iter_bar.set_description", "bert_adapter_l2.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_l2.Appr.warmup_linear", "bat.to", "bert_adapter_l2.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.eval": [[145, 189], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_l2.Appr.model.eval", "enumerate", "bert_adapter_l2.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_l2.Appr.model.forward", "bert_adapter_l2.Appr.criterion", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_l2.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_l2.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_l2.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "# break", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.calculate_importance": [[191, 197], ["bert_adapter_l2.Appr.params.items", "p.clone().detach().fill_", "p.clone().detach", "p.clone"], "methods", ["None"], ["", "def", "calculate_importance", "(", "self", ")", ":", "\n", "# Use an identity importance so it is an L2 regularization.", "\n", "        ", "importance", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "1", ")", "# Identity", "\n", "", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_l2.Appr.criterion": [[199, 214], ["bert_adapter_l2.Appr.ce", "bert_adapter_l2.Appr.regularization_terms.items", "len", "bert_adapter_l2.Appr.params.items"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "inputs", ",", "targets", ",", "regularization", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss", "=", "self", ".", "ce", "(", "inputs", ",", "targets", ",", "**", "kwargs", ")", "\n", "\n", "if", "regularization", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Calculate the reg_loss only when the regularization_terms exists", "\n", "            ", "reg_loss", "=", "0", "\n", "for", "i", ",", "reg_term", "in", "self", ".", "regularization_terms", ".", "items", "(", ")", ":", "\n", "                ", "task_reg_loss", "=", "0", "\n", "importance", "=", "reg_term", "[", "'importance'", "]", "\n", "task_param", "=", "reg_term", "[", "'task_param'", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                    ", "task_reg_loss", "+=", "(", "importance", "[", "n", "]", "*", "(", "p", "-", "task_param", "[", "n", "]", ")", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "reg_loss", "+=", "task_reg_loss", "\n", "", "loss", "+=", "self", ".", "lamb", "*", "reg_loss", "\n", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.__init__": [[14, 21], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CNN MTL'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr._get_optimizer": [[23, 26], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_mtl.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.train": [[27, 75], ["copy.deepcopy", "utils.get_model", "cnn_mtl.Appr._get_optimizer", "utils.set_model_", "range", "time.time", "tqdm.tqdm.tqdm", "cnn_mtl.Appr.train_epoch", "time.time", "cnn_mtl.Appr.eval_validation", "time.time", "print", "cnn_mtl.Appr.eval_validation", "print", "print", "print", "utils.get_model", "print", "print", "cnn_mtl.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval_validation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval_validation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", "=", "self", ".", "eval_validation", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f} |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", "=", "self", ".", "eval_validation", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f} |'", ".", "format", "(", "valid_loss", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.train_epoch": [[76, 104], ["cnn_mtl.Appr.model.train", "enumerate", "cnn_mtl.Appr.model.forward", "cnn_mtl.Appr.criterion_train", "cnn_mtl.Appr.optimizer.zero_grad", "cnn_mtl.Appr.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "cnn_mtl.Appr.optimizer.step", "cnn_mtl.Appr.til_output_friendly", "cnn_mtl.Appr.model.parameters", "t.to"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.criterion_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.til_output_friendly"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", ",", "tasks", "=", "batch", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "self", ".", "til_output_friendly", "(", "tasks", ",", "outputs", ")", "\n", "", "elif", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "outputs", "\n", "\n", "", "loss", "=", "self", ".", "criterion_train", "(", "tasks", ",", "output", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval_validation": [[105, 134], ["cnn_mtl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "targets.size", "cnn_mtl.Appr.model.forward", "cnn_mtl.Appr.criterion_train", "cnn_mtl.Appr.til_output_friendly", "cnn_mtl.Appr.data.cpu().numpy().item", "t.to", "cnn_mtl.Appr.data.cpu().numpy", "cnn_mtl.Appr.data.cpu"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.criterion_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.til_output_friendly"], ["", "def", "eval_validation", "(", "self", ",", "_", ",", "data", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", ",", "tasks", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "self", ".", "til_output_friendly", "(", "tasks", ",", "outputs", ")", "\n", "", "elif", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "outputs", "\n", "", "loss", "=", "self", ".", "criterion_train", "(", "tasks", ",", "output", ",", "targets", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "", "return", "total_loss", "/", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.eval": [[135, 173], ["cnn_mtl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_mtl.Appr.f1_compute_fn", "targets.size", "cnn_mtl.Appr.model.forward", "cnn_mtl.Appr.ce", "cnn_mtl.Appr.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_mtl.Appr.til_output_friendly", "cnn_mtl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "cnn_mtl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_mtl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.til_output_friendly"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "# This is used for the test. All tasks separately", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", ",", "tasks", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "self", ".", "til_output_friendly", "(", "tasks", ",", "outputs", ")", "\n", "", "elif", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "outputs", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_mtl.Appr.criterion_train": [[175, 179], ["cnn_mtl.Appr.ce", "len", "targets.size"], "methods", ["None"], ["", "def", "criterion_train", "(", "self", ",", "tasks", ",", "output", ",", "targets", ")", ":", "\n", "#MTL training", "\n", "        ", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "*", "len", "(", "tasks", ")", "\n", "return", "loss", "/", "targets", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ncl.Appr.__init__": [[13, 20], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL + KIM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ncl.Appr.train": [[22, 68], ["utils.get_model", "bert_cnn_ncl.Appr._get_optimizer", "range", "utils.set_model_", "print", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_ncl.Appr.train_epoch", "time.time", "bert_cnn_ncl.Appr.eval", "time.time", "print", "bert_cnn_ncl.Appr.eval", "print", "print", "utils.get_model", "print", "print", "bert_cnn_ncl.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "print", "(", "'saved: '", ")", "#TODO: debug, why so well on 20newsgroup", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ncl.Appr.train_epoch": [[71, 104], ["bert_cnn_ncl.Appr.model.train", "enumerate", "bert_cnn_ncl.Appr.model.forward", "bert_cnn_ncl.Appr.ce", "iter_bar.set_description", "bert_cnn_ncl.Appr.optimizer.zero_grad", "bert_cnn_ncl.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_ncl.Appr.optimizer.step", "bert_cnn_ncl.Appr.sup_loss", "bert_cnn_ncl.Appr.model.parameters", "bat.to", "bert_cnn_ncl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ncl.Appr.eval": [[105, 142], ["bert_cnn_ncl.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_ncl.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_ncl.Appr.model.forward", "bert_cnn_ncl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_ncl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_ncl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_ncl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_hat.Appr.__init__": [[15, 22], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", "=", "None", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'DIL CONTEXTUAL + KIM HAT'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_hat.Appr.train": [[24, 91], ["utils.get_model", "bert_cnn_hat.Appr._get_optimizer", "range", "utils.set_model_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_cnn_hat.Appr.model.mask", "range", "bert_cnn_hat.Appr.model.named_parameters", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_hat.Appr.train_epoch", "time.time", "bert_cnn_hat.Appr.eval", "time.time", "print", "bert_cnn_hat.Appr.eval", "print", "print", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "len", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "bert_cnn_hat.Appr.model.get_view_for", "utils.get_model", "print", "mask[].data.clone", "len", "torch.max", "torch.max", "torch.max", "torch.max", "print", "bert_cnn_hat.Appr._get_optimizer", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ",", "trained_task", "=", "t", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ",", "trained_task", "=", "t", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Activations mask", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", ":", "\n", "            ", "mask", "[", "i", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", "[", "i", "]", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "if", "t", "==", "0", ":", "\n", "            ", "self", ".", "mask_pre", "=", "mask", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mask_pre", ")", ")", ":", "\n", "                ", "self", ".", "mask_pre", "[", "i", "]", "=", "torch", ".", "max", "(", "self", ".", "mask_pre", "[", "i", "]", ",", "mask", "[", "i", "]", ")", "\n", "\n", "# Weights mask", "\n", "", "", "self", ".", "mask_back", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "self", ".", "mask_pre", ")", "\n", "if", "vals", "is", "not", "None", ":", "\n", "                ", "self", ".", "mask_back", "[", "n", "]", "=", "1", "-", "vals", "\n", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_hat.Appr.train_epoch": [[94, 150], ["bert_cnn_hat.Appr.model.train", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_cnn_hat.Appr.model.forward", "bert_cnn_hat.Appr.criterion_hat", "iter_bar.set_description", "bert_cnn_hat.Appr.optimizer.zero_grad", "loss.backward", "bert_cnn_hat.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "bert_cnn_hat.Appr.optimizer.step", "bert_cnn_hat.Appr.model.named_parameters", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_cnn_hat.Appr.model.named_parameters", "n.startswith", "bert_cnn_hat.Appr.model.parameters", "n.startswith", "bat.to", "len", "loss.item", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "s", ")", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", ",", "_", "=", "self", ".", "criterion_hat", "(", "output", ",", "targets", ",", "masks", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Restrict layer gradients in backprop", "\n", "if", "t", ">", "0", ":", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "self", ".", "mask_back", ":", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "mask_back", "[", "n", "]", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", ".", "startswith", "(", "'e'", ")", ":", "\n", "                    ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "thres_cosh", ",", "self", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Constrain embeddings", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", ".", "startswith", "(", "'e'", ")", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "thres_emb", ",", "self", ".", "thres_emb", ")", "\n", "\n", "#print(masks[-1].data.view(1,-1))", "\n", "#if i>=5*self.sbatch: sys.exit()", "\n", "#if i==0: print(masks[-2].data.view(1,-1),masks[-2].data.max(),masks[-2].data.min())", "\n", "#print(masks[-2].data.view(1,-1))", "\n", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_hat.Appr.eval": [[151, 207], ["bert_cnn_hat.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_cnn_hat.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_hat.Appr.criterion_hat", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_cnn_hat.Appr.model.forward", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_cnn_hat.Appr.model.forward", "hits.sum().data.cpu().numpy", "bert_cnn_hat.Appr.ent_id_detection", "loss.data.cpu().numpy", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                        ", "task", "=", "torch", ".", "LongTensor", "(", "[", "trained_task", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "#but don't know which one ========", "\n", "# this is parameter-isolation method, kind of like multi-head", "\n", "", "elif", "self", ".", "args", ".", "ent_id", ":", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "t", "=", "t", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "masks", "=", "output_d", "[", "'masks'", "]", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "task", "=", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "#but don't know which one ========", "\n", "\n", "\n", "", "loss", ",", "reg", "=", "self", ".", "criterion_hat", "(", "output", ",", "targets", ",", "masks", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ewc.Appr.__init__": [[14, 18], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'DIL CONTEXTUAL CNN EWC NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ewc.Appr.train": [[21, 88], ["utils.get_model", "bert_cnn_ewc.Appr._get_optimizer", "range", "utils.set_model_", "copy.deepcopy", "bert_cnn_ewc.Appr.model_old.eval", "utils.freeze_model", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_ewc.Appr.train_epoch", "time.time", "bert_cnn_ewc.Appr.eval", "time.time", "print", "bert_cnn_ewc.Appr.eval", "print", "print", "bert_cnn_ewc.Appr.model.named_parameters", "utils.fisher_matrix_diag_bert_dil", "bert_cnn_ewc.Appr.model.named_parameters", "utils.get_model", "print", "bert_cnn_ewc.Appr.fisher[].clone", "utils.fisher_matrix_diag_bert", "print", "bert_cnn_ewc.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert_dil", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "# Fisher ops", "\n", "if", "t", ">", "0", ":", "\n", "            ", "fisher_old", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "fisher_old", "[", "n", "]", "=", "self", ".", "fisher", "[", "n", "]", ".", "clone", "(", ")", "\n", "\n", "", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_bert_dil", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion_ewc", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_bert", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion_ewc", ")", "\n", "\n", "", "if", "t", ">", "0", ":", "\n", "# Watch out! We do not want to keep t models (or fisher diagonals) in memory, therefore we have to merge fisher diagonals", "\n", "            ", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "fisher", "[", "n", "]", "=", "(", "self", ".", "fisher", "[", "n", "]", "+", "fisher_old", "[", "n", "]", "*", "t", ")", "/", "(", "t", "+", "1", ")", "# Checked: it is better than the other option", "\n", "#self.fisher[n]=0.5*(self.fisher[n]+fisher_old[n])", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ewc.Appr.train_epoch": [[89, 114], ["bert_cnn_ewc.Appr.model.train", "enumerate", "bert_cnn_ewc.Appr.model.forward", "bert_cnn_ewc.Appr.criterion_ewc", "iter_bar.set_description", "bert_cnn_ewc.Appr.optimizer.zero_grad", "bert_cnn_ewc.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_ewc.Appr.optimizer.step", "bert_cnn_ewc.Appr.model.parameters", "bat.to", "bert_cnn_ewc.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward current model", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ewc.Appr.eval": [[115, 151], ["bert_cnn_ewc.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_ewc.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_ewc.Appr.model.forward", "bert_cnn_ewc.Appr.criterion_ewc", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_ewc.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_ewc.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_ewc.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_kan.Appr.__init__": [[22, 29], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "logger", "=", "None", ",", "taskcla", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL + RNN NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_kan.Appr.train": [[31, 86], ["print", "utils.get_model", "bert_rnn_kan.Appr._get_optimizer_kan", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "bert_rnn_kan.Appr.train_epoch", "time.time", "bert_rnn_kan.Appr.eval", "time.time", "print", "print", "bert_rnn_kan.Appr.eval", "print", "print", "float", "utils.get_model", "print", "print", "bert_rnn_kan.Appr._get_optimizer_kan", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_kan", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_kan"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "\n", "        ", "if", "t", "==", "0", ":", "which_types", "=", "[", "'mcl'", "]", "\n", "else", ":", "which_types", "=", "[", "'ac'", ",", "'mcl'", "]", "\n", "\n", "for", "which_type", "in", "which_types", ":", "\n", "\n", "            ", "print", "(", "'Training Type: '", ",", "which_type", ")", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_kan", "(", "lr", ",", "which_type", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "which_type", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ",", "train_data", ",", "which_type", ",", "trained_task", "=", "t", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ",", "valid_data", ",", "which_type", ",", "trained_task", "=", "t", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_kan", "(", "lr", ",", "which_type", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_kan.Appr.train_epoch": [[89, 141], ["bert_rnn_kan.Appr.model.train", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_rnn_kan.Appr.model.forward", "bert_rnn_kan.Appr.ce", "iter_bar.set_description", "bert_rnn_kan.Appr.optimizer.zero_grad", "bert_rnn_kan.Appr.backward", "bert_rnn_kan.Appr.model.ac.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "bert_rnn_kan.Appr.optimizer.step", "bert_rnn_kan.Appr.model.ac.named_parameters", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_rnn_kan.Appr.model.ac.mask", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_rnn_kan.Appr.model.named_parameters", "bert_rnn_kan.Appr.model.parameters", "bat.to", "len", "bert_rnn_kan.Appr.item", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.autograd.Variable.data.clone", "torch.autograd.Variable.data.clone", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "bert_rnn_kan.Appr.model.get_view_for", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "which_type", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "which_type", ",", "s", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "t", ">", "0", "and", "which_type", "==", "'mcl'", ":", "\n", "                ", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "ac", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "rnn_weights", ":", "\n", "# print('n: ',n)", "\n", "# print('p: ',p.grad.size())", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "mask", ")", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "ac", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'ac.e'", "in", "n", ":", "\n", "                    ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "thres_cosh", ",", "self", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Constrain embeddings", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "ac", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'ac.e'", "in", "n", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "thres_emb", ",", "self", ".", "thres_emb", ")", "\n", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_kan.Appr.eval": [[142, 187], ["bert_rnn_kan.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_rnn_kan.Appr.f1_compute_fn", "input_ids.size", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_rnn_kan.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_rnn_kan.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "bert_rnn_kan.Appr.model.forward", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_rnn_kan.Appr.model.forward", "hits.sum().data.cpu().numpy", "bert_rnn_kan.Appr.ent_id_detection", "bert_rnn_kan.Appr.data.cpu().numpy", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hits.sum().data.cpu", "bert_rnn_kan.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", ",", "which_type", ",", "trained_task", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "task", "=", "torch", ".", "LongTensor", "(", "[", "trained_task", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                        ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "ent_id", ":", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "t", ",", "which_type", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "task", "=", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_owm.Appr.__init__": [[15, 20], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'DIL CONTEXTUAL CNN OWM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_owm.Appr.train": [[23, 79], ["utils.get_model", "bert_cnn_owm.Appr._get_optimizer_owm", "utils.set_model_", "range", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_owm.Appr.train_epoch", "time.time", "bert_cnn_owm.Appr.eval", "print", "bert_cnn_owm.Appr.eval", "print", "print", "print", "print", "utils.get_model", "print", "print", "bert_cnn_owm.Appr._get_optimizer_owm", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_acc", "=", "0", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "# patience = self.lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_owm", "(", "lr", ")", "\n", "nepochs", "=", "self", ".", "nepochs", "\n", "test_max", "=", "0", "\n", "# Loop epochs", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "cur_epoch", "=", "e", ",", "nepoch", "=", "nepochs", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| [{:d}/10], Epoch {:d}/{:d}, | Train: loss={:.3f}, acc={:2.2f}% |'", ".", "format", "(", "t", "+", "1", ",", "e", "+", "1", ",", "\n", "nepochs", ",", "train_loss", ",", "\n", "100", "*", "train_acc", ")", ",", "\n", "end", "=", "''", ")", "\n", "# # Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.2f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "print", "(", ")", "\n", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                   ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_owm", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best validation model", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_owm.Appr.train_epoch": [[80, 159], ["bert_cnn_owm.Appr.model.train", "enumerate", "bert_cnn_owm.Appr.model.forward", "bert_cnn_owm.Appr.ce", "bert_cnn_owm.Appr.optimizer.zero_grad", "bert_cnn_owm.Appr.backward", "iter_bar.set_description", "bert_cnn_owm.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "bert_cnn_owm.Appr.optimizer.step", "x.detach.detach.detach", "p.detach.detach.detach", "bert_cnn_owm.Appr.model.parameters", "bat.to", "bert_cnn_owm.Appr.item", "int", "int", "range", "torch.mm().view_as", "torch.mm", "p.detach.detach.sub_", "torch.mm", "bert_cnn_owm.Appr.train_epoch.pro_weight"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "cur_epoch", "=", "0", ",", "nepoch", "=", "0", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "lamda", "=", "step", "/", "len", "(", "batch", ")", "/", "nepoch", "+", "cur_epoch", "/", "nepoch", "\n", "\n", "alpha_array", "=", "[", "1.0", "*", "0.00001", "**", "lamda", ",", "1.0", "*", "0.0001", "**", "lamda", ",", "1.0", "*", "0.01", "**", "lamda", ",", "1.0", "*", "0.1", "**", "lamda", "]", "\n", "\n", "def", "pro_weight", "(", "p", ",", "x", ",", "w", ",", "alpha", "=", "1.0", ",", "cnn", "=", "True", ",", "stride", "=", "1", ")", ":", "\n", "# print('x: ',x.size()) #1,300", "\n", "# print('w: ',w.size()) #300,300", "\n", "# print('p: ',p.size()) #300,300", "\n", "\n", "                ", "x", "=", "x", ".", "detach", "(", ")", "\n", "p", "=", "p", ".", "detach", "(", ")", "\n", "\n", "if", "cnn", ":", "\n", "                    ", "_", ",", "_", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "F", ",", "_", ",", "HH", ",", "WW", "=", "w", ".", "shape", "\n", "S", "=", "stride", "# stride", "\n", "Ho", "=", "int", "(", "1", "+", "(", "H", "-", "HH", ")", "/", "S", ")", "\n", "Wo", "=", "int", "(", "1", "+", "(", "W", "-", "WW", ")", "/", "S", ")", "\n", "for", "i", "in", "range", "(", "Ho", ")", ":", "\n", "                        ", "for", "j", "in", "range", "(", "Wo", ")", ":", "\n", "# N*C*HH*WW, C*HH*WW = N*C*HH*WW, sum -> N*1", "\n", "                            ", "r", "=", "x", "[", ":", ",", ":", ",", "i", "*", "S", ":", "i", "*", "S", "+", "HH", ",", "j", "*", "S", ":", "j", "*", "S", "+", "WW", "]", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "# r = r[:, range(r.shape[1] - 1, -1, -1)]", "\n", "k", "=", "torch", ".", "mm", "(", "p", ",", "torch", ".", "t", "(", "r", ")", ")", "\n", "p", ".", "sub_", "(", "torch", ".", "mm", "(", "k", ",", "torch", ".", "t", "(", "k", ")", ")", "/", "(", "alpha", "+", "torch", ".", "mm", "(", "r", ",", "k", ")", ")", ")", "\n", "", "", "w", ".", "grad", ".", "data", "=", "torch", ".", "mm", "(", "w", ".", "grad", ".", "data", ".", "view", "(", "F", ",", "-", "1", ")", ",", "torch", ".", "t", "(", "p", ".", "data", ")", ")", ".", "view_as", "(", "w", ")", "\n", "", "else", ":", "\n", "                    ", "r", "=", "x", "\n", "k", "=", "torch", ".", "mm", "(", "p", ",", "torch", ".", "t", "(", "r", ")", ")", "\n", "p", ".", "sub_", "(", "torch", ".", "mm", "(", "k", ",", "torch", ".", "t", "(", "k", ")", ")", "/", "(", "alpha", "+", "torch", ".", "mm", "(", "r", ",", "k", ")", ")", ")", "\n", "w", ".", "grad", ".", "data", "=", "torch", ".", "mm", "(", "w", ".", "grad", ".", "data", ",", "torch", ".", "t", "(", "p", ".", "data", ")", ")", "\n", "# Compensate embedding gradients", "\n", "", "", "for", "n", ",", "w", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", "==", "'c1.weight'", ":", "#TODO: change to convs. Note: only work when the weight matrix is systemetic", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc1", ",", "x_list", "[", "0", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'c2.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc2", ",", "x_list", "[", "1", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'c3.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc3", ",", "x_list", "[", "2", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'fc1.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "P1", ",", "h_list", "[", "0", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "1", "]", ",", "cnn", "=", "False", ")", "\n", "\n", "", "if", "n", "==", "'fc2.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "P2", ",", "h_list", "[", "1", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "2", "]", ",", "cnn", "=", "False", ")", "\n", "\n", "\n", "# Apply step", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_owm.Appr.eval": [[160, 194], ["bert_cnn_owm.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_owm.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_owm.Appr.model.forward", "bert_cnn_owm.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_owm.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_owm.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_owm.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "# Forward", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "%", "10", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.__init__": [[14, 18], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'W2V NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.train": [[19, 90], ["utils.get_model", "w2v_cnn_l2.Appr._get_optimizer", "range", "utils.set_model_", "w2v_cnn_l2.Appr.params.items", "w2v_cnn_l2.Appr.calculate_importance", "time.time", "tqdm.tqdm.tqdm", "w2v_cnn_l2.Appr.train_epoch", "time.time", "w2v_cnn_l2.Appr.eval", "time.time", "w2v_cnn_l2.Appr.logger.info", "w2v_cnn_l2.Appr.eval", "w2v_cnn_l2.Appr.logger.info", "print", "p.clone().detach", "utils.get_model", "print", "len", "print", "w2v_cnn_l2.Appr._get_optimizer", "p.clone", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.calculate_importance", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# 2.Backup the weight of current task", "\n", "task_param", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "task_param", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# 3.Calculate the importance of weights for current task", "\n", "", "importance", "=", "self", ".", "calculate_importance", "(", ")", "\n", "\n", "# Save the weight and importance of weights of current task", "\n", "self", ".", "task_count", "+=", "1", "\n", "if", "self", ".", "online_reg", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Always use only one slot in self.regularization_terms", "\n", "            ", "self", ".", "regularization_terms", "[", "1", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "", "else", ":", "\n", "# Use a new slot to store the task-specific information", "\n", "            ", "self", ".", "regularization_terms", "[", "self", ".", "task_count", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.train_epoch": [[93, 126], ["w2v_cnn_l2.Appr.model.train", "enumerate", "w2v_cnn_l2.Appr.model.forward", "w2v_cnn_l2.Appr.criterion", "iter_bar.set_description", "w2v_cnn_l2.Appr.optimizer.zero_grad", "w2v_cnn_l2.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_cnn_l2.Appr.optimizer.step", "w2v_cnn_l2.Appr.sup_loss", "w2v_cnn_l2.Appr.model.parameters", "t.to", "w2v_cnn_l2.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.eval": [[127, 161], ["w2v_cnn_l2.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_cnn_l2.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_cnn_l2.Appr.model.forward", "w2v_cnn_l2.Appr.criterion", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_cnn_l2.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "w2v_cnn_l2.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_cnn_l2.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.calculate_importance": [[162, 168], ["w2v_cnn_l2.Appr.params.items", "p.clone().detach().fill_", "p.clone().detach", "p.clone"], "methods", ["None"], ["", "def", "calculate_importance", "(", "self", ")", ":", "\n", "# Use an identity importance so it is an L2 regularization.", "\n", "        ", "importance", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "1", ")", "# Identity", "\n", "", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_l2.Appr.criterion": [[170, 185], ["w2v_cnn_l2.Appr.ce", "w2v_cnn_l2.Appr.regularization_terms.items", "len", "w2v_cnn_l2.Appr.params.items"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "inputs", ",", "targets", ",", "regularization", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss", "=", "self", ".", "ce", "(", "inputs", ",", "targets", ",", "**", "kwargs", ")", "\n", "\n", "if", "regularization", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Calculate the reg_loss only when the regularization_terms exists", "\n", "            ", "reg_loss", "=", "0", "\n", "for", "i", ",", "reg_term", "in", "self", ".", "regularization_terms", ".", "items", "(", ")", ":", "\n", "                ", "task_reg_loss", "=", "0", "\n", "importance", "=", "reg_term", "[", "'importance'", "]", "\n", "task_param", "=", "reg_term", "[", "'task_param'", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                    ", "task_reg_loss", "+=", "(", "importance", "[", "n", "]", "*", "(", "p", "-", "task_param", "[", "n", "]", ")", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "reg_loss", "+=", "task_reg_loss", "\n", "", "loss", "+=", "self", ".", "lamb", "*", "reg_loss", "\n", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.__init__": [[25, 73], ["cnn_base.Appr.__init__", "print", "cnn_acl.Appr.get_discriminator", "cnn_acl.Appr.discriminator.get_size", "torch.nn.CrossEntropyLoss().to", "torch.nn.CrossEntropyLoss().to", "torch.nn.CrossEntropyLoss().to", "DiffLoss().to", "cnn_acl.Appr.get_S_optimizer", "cnn_acl.Appr.get_D_optimizer", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "cnn_acl.DiffLoss"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_discriminator", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.get_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_S_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_D_optimizer"], ["self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "s", "*", "s", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "\n", "", "def", "forward", "(", "self", ",", "x_s", ")", ":", "\n", "        ", "x_s", "=", "x_s", ".", "view_as", "(", "x_s", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x_s", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "conv3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x_s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "return", "h", "\n", "\n", "\n", "\n", "", "", "class", "Private", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Private", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "\n", "self", ".", "task_out", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv1'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'relu1'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'drop1'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool1'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv2'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'relu2'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'dropout2'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool2'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'conv3'", ",", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_discriminator": [[74, 77], ["networks.classification.discriminator.Discriminator().to", "networks.classification.discriminator.Discriminator"], "methods", ["None"], ["self", ".", "conv", ".", "add_module", "(", "'relu3'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'dropout3'", ",", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", ")", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool3'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_S_optimizer": [[78, 83], ["torch.optim.SGD", "cnn_acl.Appr.model.parameters"], "methods", ["None"], ["s", "=", "s", "//", "2", "\n", "self", ".", "conv", ".", "add_module", "(", "'maxpool2'", ",", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", ")", "\n", "self", ".", "task_out", ".", "append", "(", "self", ".", "conv", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "\n", "self", ".", "linear", ".", "add_module", "(", "'linear1'", ",", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "s", "*", "s", ",", "2048", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_D_optimizer": [[84, 88], ["torch.optim.SGD", "cnn_acl.Appr.discriminator.parameters"], "methods", ["None"], ["self", ".", "linear", ".", "add_module", "(", "'relu3'", ",", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "task_out", ".", "append", "(", "self", ".", "linear", ")", "\n", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "t", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.train": [[89, 179], ["cnn_acl.Appr.get_discriminator", "utils.get_model", "utils.get_model", "cnn_acl.Appr.get_D_optimizer", "cnn_acl.Appr.get_S_optimizer", "range", "cnn_acl.Appr.model.load_state_dict", "cnn_acl.Appr.discriminator.load_state_dict", "int", "torch.utils.data.DataLoader", "next", "images.to.to.to", "targets.to.to.to", "cnn_acl.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "cnn_acl.Appr.train_epoch", "time.time", "cnn_acl.Appr.eval_", "utils.report_tr", "cnn_acl.Appr.eval_", "utils.report_val", "print", "copy.deepcopy", "copy.deepcopy", "iter", "utils.get_model", "print", "utils.get_model", "len", "print", "cnn_acl.Appr.get_S_optimizer", "print", "cnn_acl.Appr.get_D_optimizer", "torch.ones().to", "print", "print", "print", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_discriminator", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_D_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_S_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.report_tr", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.report_val", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_S_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.get_D_optimizer"], ["        ", "x", "=", "x", ".", "view_as", "(", "x", ")", "\n", "out", "=", "self", ".", "task_out", "[", "2", "*", "t", "]", ".", "forward", "(", "x", ")", "\n", "#TODO: check whether it is ok to use this in DIL. What is the different between use different head and different part", "\n", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "task_out", "[", "2", "*", "t", "+", "1", "]", ".", "forward", "(", "out", ")", "\n", "return", "out", "\n", "\n", "\n", "\n", "", "", "class", "Net", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "num_tasks", "=", "args", ".", "ntasks", "\n", "\n", "self", ".", "shared", "=", "Shared", "(", "args", ")", "\n", "self", ".", "private", "=", "Private", "(", "args", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "args", ".", "nclasses", ")", "\n", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "taskcla", "[", "i", "]", "[", "1", "]", ")", "\n", ")", ")", "\n", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "x_s", ",", "x_p", ",", "tt", ",", "t", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "x_s", "=", "x_s", ".", "view_as", "(", "x_s", ")", "\n", "x_p", "=", "x_p", ".", "view_as", "(", "x_p", ")", "\n", "\n", "x_s", "=", "self", ".", "shared", "(", "x_s", ")", "\n", "x_p", "=", "self", ".", "private", "(", "x_p", ",", "t", ")", "# t decides which part of private to use", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x_p", ",", "x_s", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "x", ")", "\n", "\n", "", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "x", ")", ")", "\n", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "return", "output_dict", "\n", "\n", "\n", "\n", "", "def", "get_encoded_ftrs", "(", "self", ",", "x_s", ",", "x_p", ",", "t", ")", ":", "\n", "        ", "return", "self", ".", "shared", "(", "x_s", ")", ",", "self", ".", "private", "(", "x_p", ",", "t", ")", "\n", "\n", "", "def", "print_model_size", "(", "self", ")", ":", "\n", "        ", "count_P", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "private", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_S", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "shared", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "count_H", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "last", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "print", "(", "'Num parameters in S       = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_S", ")", ")", ")", "\n", "print", "(", "'Num parameters in P       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_P", ")", ",", "self", ".", "pretty_print", "(", "count_P", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in p       = %s,  per task = %s '", "%", "(", "self", ".", "pretty_print", "(", "count_H", ")", ",", "self", ".", "pretty_print", "(", "count_H", "/", "self", ".", "num_tasks", ")", ")", ")", "\n", "print", "(", "'Num parameters in P+p    = %s '", "%", "self", ".", "pretty_print", "(", "count_P", "+", "count_H", ")", ")", "\n", "print", "(", "'-------------------------->   Architecture size: %s parameters (%sB)'", "%", "(", "self", ".", "pretty_print", "(", "count_S", "+", "count_P", "+", "count_H", ")", ",", "\n", "self", ".", "pretty_print", "(", "4", "*", "(", "count_S", "+", "count_P", "+", "count_H", ")", ")", ")", ")", "\n", "\n", "print", "(", "\"-------------------------->   Memory size: %s samples per task (%sB)\"", "%", "(", "self", ".", "samples", ",", "\n", "self", ".", "pretty_print", "(", "self", ".", "num_tasks", "*", "4", "*", "self", ".", "samples", "*", "self", ".", "image_size", ")", ")", ")", "\n", "print", "(", "\"------------------------------------------------------------------------------\"", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.train_epoch": [[182, 290], ["cnn_acl.Appr.model.train", "cnn_acl.Appr.discriminator.train", "enumerate", "images.size", "images.to", "targets.to", "torch.LongTensor().repeat", "torch.LongTensor().repeat.to", "torch.eq().cpu().numpy", "torch.cat.clone", "range", "x_task_module.to.to.to", "torch.cat.to", "torch.zeros_like().to", "range", "range", "cnn_acl.Appr.buffer.is_empty", "cnn_acl.Appr.buffer.get_data", "buf_labels.long.long.long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like", "torch.cat.size", "cnn_acl.Appr.optimizer_S.zero_grad", "cnn_acl.Appr.model.zero_grad", "cnn_acl.Appr.model", "cnn_acl.Appr.task_loss", "cnn_acl.Appr.model.get_encoded_ftrs", "cnn_acl.Appr.discriminator.forward", "cnn_acl.Appr.adversarial_loss_s", "total_loss.backward", "cnn_acl.Appr.optimizer_S.step", "cnn_acl.Appr.optimizer_D.zero_grad", "cnn_acl.Appr.discriminator.zero_grad", "cnn_acl.Appr.model", "cnn_acl.Appr.model.get_encoded_ftrs", "cnn_acl.Appr.discriminator.forward", "cnn_acl.Appr.adversarial_loss_d", "cnn_acl.Appr.backward", "torch.as_tensor", "cnn_acl.Appr.discriminator.forward", "cnn_acl.Appr.adversarial_loss_d", "cnn_acl.Appr.backward", "cnn_acl.Appr.optimizer_D.step", "bat.to", "torch.LongTensor", "torch.eq().cpu", "x_task_module[].detach", "torch.zeros_like", "cnn_acl.Appr.diff_loss", "torch.tensor().to", "shared_encoded.detach", "numpy.random.normal", "torch.eq", "torch.tensor", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.get_encoded_ftrs", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.get_encoded_ftrs", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "pretty_print", "(", "self", ",", "num", ")", ":", "\n", "        ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "            ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.eval_": [[292, 357], ["cnn_acl.Appr.model.eval", "cnn_acl.Appr.discriminator.eval", "cnn_acl.Appr.loader_size", "torch.no_grad", "enumerate", "loss_d.item", "loss_total.item", "images.size", "images.to", "targets.to", "torch.LongTensor().repeat", "torch.LongTensor().repeat.to", "cnn_acl.Appr.model", "cnn_acl.Appr.model.get_encoded_ftrs", "output.max", "pred.eq().sum().item", "cnn_acl.Appr.discriminator.forward", "cnn_acl.Appr.max", "pred_d.eq().sum().item", "cnn_acl.Appr.task_loss", "cnn_acl.Appr.adversarial_loss_d", "images.to.size", "loss_t.item", "loss_a.item", "cnn_acl.Appr.diff_loss", "torch.tensor().to", "t.to", "torch.LongTensor", "pred.eq().sum", "pred_d.eq().sum", "torch.tensor", "pred.eq", "pred_d.eq", "targets.to.view_as", "t_real_D.view_as"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.loader_size", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_acl.Net.get_encoded_ftrs", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.eval": [[360, 412], ["cnn_acl.Appr.model.eval", "torch.no_grad", "enumerate", "cnn_acl.Appr.f1_compute_fn", "targets.size", "images.to", "cnn_acl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_acl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "torch.LongTensor().repeat", "torch.LongTensor().repeat.to", "cnn_acl.Appr.model", "hits.sum().data.cpu().numpy", "cnn_acl.Appr.ent_id_detection", "cnn_acl.Appr.ent_id_detection", "torch.LongTensor().repeat", "torch.LongTensor().repeat.to", "cnn_acl.Appr.model.forward", "cnn_acl.Appr.data.cpu().numpy", "torch.LongTensor", "hits.sum().data.cpu", "torch.LongTensor", "cnn_acl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.Appr.loader_size": [[414, 416], ["data_loader.dataset.__len__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__len__"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.DiffLoss.__init__": [[422, 424], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_acl.DiffLoss.forward": [[425, 436], ["D1.view.view.view", "torch.norm().detach", "D1.view.view.div", "D2.view.view.view", "torch.norm().detach", "D2.view.view.div", "torch.mean", "D1.view.view.size", "D2.view.view.size", "D1.view.div.mm().pow", "torch.norm", "D1.view.div.expand_as", "torch.norm", "D2.view.div.expand_as", "D1.view.div.mm", "D2.view.div.t"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_derpp.Appr.__init__": [[17, 23], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL CNN EWC NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_derpp.Appr.train": [[25, 102], ["utils.get_model", "bert_cnn_derpp.Appr._get_optimizer", "range", "utils.set_model_", "print", "int", "print", "torch.utils.data.DataLoader", "next", "input_ids.to.to.to", "segment_ids.to.to.to", "input_mask.to.to.to", "targets.to.to.to", "bert_cnn_derpp.Appr.model.forward", "bert_cnn_derpp.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_derpp.Appr.train_epoch", "time.time", "bert_cnn_derpp.Appr.eval", "time.time", "print", "bert_cnn_derpp.Appr.eval", "print", "print", "len", "iter", "utils.get_model", "print", "len", "print", "bert_cnn_derpp.Appr._get_optimizer", "torch.ones().to", "len", "len", "print", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "self", ".", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "labels", "=", "targets", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", ",", "\n", "logits", "=", "cur_task_output", ".", "data", "\n", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_derpp.Appr.train_epoch": [[103, 148], ["bert_cnn_derpp.Appr.model.train", "enumerate", "bert_cnn_derpp.Appr.model.forward", "bert_cnn_derpp.Appr.ce", "iter_bar.set_description", "bert_cnn_derpp.Appr.optimizer.zero_grad", "bert_cnn_derpp.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_derpp.Appr.optimizer.step", "bert_cnn_derpp.Appr.buffer.is_empty", "bert_cnn_derpp.Appr.buffer.get_data", "buf_inputs.long.long.long", "buf_segment_ids.long", "buf_input_mask.long", "buf_labels.long.long.long", "bert_cnn_derpp.Appr.model.forward", "bert_cnn_derpp.Appr.model.parameters", "bat.to", "bert_cnn_derpp.Appr.ce", "bert_cnn_derpp.Appr.mse", "bert_cnn_derpp.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_logits", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "\n", "buf_inputs", "=", "buf_inputs", ".", "long", "(", ")", "\n", "buf_segment", "=", "buf_segment_ids", ".", "long", "(", ")", "\n", "buf_mask", "=", "buf_input_mask", ".", "long", "(", ")", "\n", "buf_labels", "=", "buf_labels", ".", "long", "(", ")", "\n", "buf_logits", "=", "buf_logits", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "buf_inputs", ",", "buf_segment", ",", "buf_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "+=", "self", ".", "args", ".", "beta", "*", "self", ".", "ce", "(", "cur_task_output", ",", "buf_labels", ")", "\n", "loss", "+=", "self", ".", "args", ".", "alpha", "*", "self", ".", "mse", "(", "cur_task_output", ",", "buf_logits", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_derpp.Appr.eval": [[149, 185], ["bert_cnn_derpp.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_derpp.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_derpp.Appr.model.forward", "bert_cnn_derpp.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_derpp.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_derpp.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_derpp.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Appr.__init__": [[15, 20], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Appr.train": [[23, 79], ["utils.get_model", "cnn_owm.Appr._get_optimizer_owm", "utils.set_model_", "range", "time.time", "tqdm.tqdm.tqdm", "cnn_owm.Appr.train_epoch", "time.time", "cnn_owm.Appr.eval", "print", "cnn_owm.Appr.eval", "print", "print", "print", "print", "utils.get_model", "print", "print", "cnn_owm.Appr._get_optimizer_owm", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm"], ["\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "4", "*", "4", ",", "1000", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "1000", ",", "bias", "=", "False", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'DIL CNN'", ")", "\n", "\n", "return", "\n", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h_list", "=", "[", "]", "\n", "x_list", "=", "[", "]", "\n", "# Gated", "\n", "x", "=", "self", ".", "padding", "(", "x", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "x", ",", "0", ",", "True", ")", ")", "\n", "con1", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c1", "(", "x", ")", ")", ")", "\n", "con1_p", "=", "self", ".", "maxpool", "(", "con1", ")", "\n", "\n", "con1_p", "=", "self", ".", "padding", "(", "con1_p", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "con1_p", ",", "0", ",", "True", ")", ")", "\n", "con2", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c2", "(", "con1_p", ")", ")", ")", "\n", "con2_p", "=", "self", ".", "maxpool", "(", "con2", ")", "\n", "\n", "con2_p", "=", "self", ".", "padding", "(", "con2_p", ")", "\n", "x_list", ".", "append", "(", "torch", ".", "mean", "(", "con2_p", ",", "0", ",", "True", ")", ")", "\n", "con3", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "c3", "(", "con2_p", ")", ")", ")", "\n", "con3_p", "=", "self", ".", "maxpool", "(", "con3", ")", "\n", "\n", "h", "=", "con3_p", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Appr.train_epoch": [[80, 156], ["cnn_owm.Appr.model.train", "enumerate", "cnn_owm.Appr.model.forward", "cnn_owm.Appr.ce", "cnn_owm.Appr.optimizer.zero_grad", "cnn_owm.Appr.backward", "iter_bar.set_description", "cnn_owm.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "cnn_owm.Appr.optimizer.step", "x.detach.detach.detach", "p.detach.detach.detach", "cnn_owm.Appr.model.parameters", "bat.to", "cnn_owm.Appr.item", "int", "int", "range", "torch.mm().view_as", "torch.mm", "p.detach.detach.sub_", "torch.mm", "cnn_owm.Appr.train_epoch.pro_weight"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "output_dict", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "return", "output_dict", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_owm.Appr.eval": [[157, 196], ["cnn_owm.Appr.model.eval", "torch.no_grad", "enumerate", "cnn_owm.Appr.f1_compute_fn", "images.size", "cnn_owm.Appr.model.forward", "cnn_owm.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_owm.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "cnn_owm.Appr.ent_id_detection", "cnn_owm.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_owm.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ncl.Appr.__init__": [[17, 24], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CNN NCL'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ncl.Appr.train": [[27, 71], ["utils.get_model", "cnn_ncl.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "cnn_ncl.Appr.train_epoch", "time.time", "cnn_ncl.Appr.eval", "time.time", "print", "cnn_ncl.Appr.eval", "print", "print", "utils.get_model", "print", "print", "cnn_ncl.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ncl.Appr.train_epoch": [[72, 110], ["cnn_ncl.Appr.model.train", "enumerate", "cnn_ncl.Appr.model.forward", "cnn_ncl.Appr.ce", "iter_bar.set_description", "cnn_ncl.Appr.optimizer.zero_grad", "cnn_ncl.Appr.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "cnn_ncl.Appr.optimizer.step", "cnn_ncl.Appr.model.parameters", "t.to", "torch.normalize", "torch.normalize", "cnn_ncl.Appr.sup_loss", "cnn_ncl.Appr.sup_loss", "cnn_ncl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "#TODO: TIL with detected ID, Don't forgeet to save the model!!!", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "if", "self", ".", "args", ".", "sup_head_norm", ":", "\n", "                    ", "output_rep", "=", "F", ".", "normalize", "(", "output", ",", "dim", "=", "1", ")", "\n", "loss", "+=", "self", ".", "sup_loss", "(", "output_rep", ",", "pooled_rep", ",", "images", ",", "targets", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "images", ",", "targets", ")", "\n", "\n", "\n", "", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ncl.Appr.eval": [[111, 151], ["cnn_ncl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_ncl.Appr.f1_compute_fn", "targets.size", "cnn_ncl.Appr.model.forward", "cnn_ncl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_ncl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "cnn_ncl.Appr.ent_id_detection", "cnn_ncl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_ncl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "if", "self", ".", "args", ".", "ent_id", ":", "#detected id", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "images", ",", "t", "=", "t", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "", "else", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_derpp.Appr.__init__": [[18, 25], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CNN DERPP NCL'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_derpp.Appr.train": [[28, 95], ["utils.get_model", "cnn_derpp.Appr._get_optimizer", "range", "utils.set_model_", "int", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "images.to.to.to", "targets.to.to.to", "cnn_derpp.Appr.model.forward", "cnn_derpp.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "cnn_derpp.Appr.train_epoch", "time.time", "cnn_derpp.Appr.eval", "time.time", "print", "cnn_derpp.Appr.eval", "print", "print", "iter", "utils.get_model", "print", "len", "print", "cnn_derpp.Appr._get_optimizer", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "len", "len", "print", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "\n", "images", ",", "targets", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "images", "=", "images", ".", "to", "(", "self", ".", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "images", ",", "\n", "labels", "=", "targets", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", ",", "\n", "logits", "=", "cur_task_output", ".", "data", ",", "\n", "segment_ids", "=", "images", ",", "#dumy", "\n", "input_mask", "=", "images", ",", "\n", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_derpp.Appr.train_epoch": [[96, 141], ["cnn_derpp.Appr.model.train", "enumerate", "cnn_derpp.Appr.model.forward", "cnn_derpp.Appr.ce", "iter_bar.set_description", "cnn_derpp.Appr.optimizer.zero_grad", "cnn_derpp.Appr.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "cnn_derpp.Appr.optimizer.step", "cnn_derpp.Appr.buffer.is_empty", "cnn_derpp.Appr.buffer.get_data", "buf_labels.long.long.long", "cnn_derpp.Appr.model", "cnn_derpp.Appr.model.parameters", "t.to", "cnn_derpp.Appr.ce", "cnn_derpp.Appr.mse", "cnn_derpp.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_logits", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "buf_inputs", "=", "buf_inputs", "\n", "buf_labels", "=", "buf_labels", ".", "long", "(", ")", "\n", "buf_logits", "=", "buf_logits", "\n", "\n", "output_dict", "=", "self", ".", "model", "(", "buf_inputs", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "+=", "self", ".", "args", ".", "beta", "*", "self", ".", "ce", "(", "cur_task_output", ",", "buf_labels", ")", "\n", "loss", "+=", "self", ".", "args", ".", "alpha", "*", "self", ".", "mse", "(", "cur_task_output", ",", "buf_logits", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_derpp.Appr.eval": [[142, 182], ["cnn_derpp.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_derpp.Appr.f1_compute_fn", "targets.size", "cnn_derpp.Appr.model.forward", "cnn_derpp.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_derpp.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "cnn_derpp.Appr.ent_id_detection", "cnn_derpp.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_derpp.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "if", "self", ".", "args", ".", "ent_id", ":", "#detected id", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "images", ",", "t", "=", "t", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "", "else", ":", "\n", "                        ", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_one.Appr.__init__": [[31, 37], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'BERT Adapter ONE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_one.Appr.train": [[38, 90], ["bert_adapter_one.Appr.model.to", "copy.deepcopy", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_one.Appr.train_epoch", "time.time", "bert_adapter_one.Appr.eval", "time.time", "print", "bert_adapter_one.Appr.eval", "print", "print", "bert_adapter_one.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model: isolate", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_one.Appr.train_epoch": [[91, 121], ["bert_adapter_one.Appr.model.train", "enumerate", "bert_adapter_one.Appr.model.forward", "bert_adapter_one.Appr.ce", "iter_bar.set_description", "bert_adapter_one.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_one.Appr.sup_loss", "bert_adapter_one.Appr.warmup_linear", "bat.to", "bert_adapter_one.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_one.Appr.eval": [[122, 155], ["bert_adapter_one.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_adapter_one.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_one.Appr.model.forward", "bert_adapter_one.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_one.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_one.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_one.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "# Forward", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Appr.__init__": [[35, 40], ["bert_adapter_mask_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adapter_masks", "="]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Appr.train": [[41, 121], ["bert_adapter_mask.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "bert_adapter_mask.Appr.items", "bert_adapter_mask.Appr.model.named_parameters", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_mask.Appr.train_epoch", "time.time", "bert_adapter_mask.Appr.eval", "time.time", "bert_adapter_mask.Appr.logger.info", "bert_adapter_mask.Appr.eval", "bert_adapter_mask.Appr.logger.info", "print", "bert_adapter_mask.Appr.model.module.mask", "bert_adapter_mask.Appr.model.mask", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_adapter_mask.Appr.mask_pre.items", "bert_adapter_mask.Appr.model.named_parameters", "utils.get_model", "print", "value.data.clone", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "bert_adapter_mask.Appr.model.module.get_view_for", "bert_adapter_mask.Appr.model.get_view_for", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "for", "adapter_mask", "in", "adapter_masks", ":", "\n", "            ", "for", "param", "in", "adapter_mask", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_task", "=", "len", "(", "taskcla", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "self", ".", "self_attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "self", ".", "self_attns", ".", "append", "(", "Self_Attn", "(", "t", "+", "1", ")", ")", "\n", "\n", "\n", "", "print", "(", "' BERT ADAPTER MASK'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "start_mixup", "=", "None", ",", "s", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "start_mixup", ":", "\n", "            ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "pooled_output", "=", "self", ".", "self_attention_feature", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "pooled_output", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "\n", "", "def", "self_attention_feature", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "pooled_output", ")", ":", "\n", "        ", "pre_pooled_outputs", "=", "[", "]", "\n", "for", "pre_t", "in", "[", "x", "for", "x", "in", "range", "(", "t", ")", "]", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "pre_pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "t", "=", "pre_t", ",", "s", "=", "self", ".", "args", ".", "smax", ")", "\n", "", "pre_pooled_outputs", ".", "append", "(", "pre_pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Appr.train_epoch": [[122, 192], ["bert_adapter_mask.Appr.model.train", "enumerate", "bert_adapter_mask.Appr.model", "bert_adapter_mask.Appr.hat_criterion_adapter", "iter_bar.set_description", "loss.backward", "bert_adapter_mask.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "optimizer.zero_grad", "bert_adapter_mask.Appr.model.named_parameters", "bert_adapter_mask.Appr.amix_loss", "bert_adapter_mask.Appr.augment_distill_loss", "bert_adapter_mask.Appr.sup_loss", "bert_adapter_mask.Appr.model.named_parameters", "bert_adapter_mask.Appr.warmup_linear", "bert_adapter_mask.Appr.model.parameters", "bat.to", "len", "loss.item", "n.startswith", "n.startswith", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.amix_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.augment_distill_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["\n", "\n", "", "pre_pooled_outputs", "=", "torch", ".", "cat", "(", "pre_pooled_outputs", ",", "-", "1", ")", "\n", "pre_pooled_outputs", "=", "torch", ".", "cat", "(", "[", "pre_pooled_outputs", ",", "pooled_output", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "]", ",", "-", "1", ")", "# include itselves", "\n", "\n", "pooled_output", "=", "self", ".", "self_attns", "[", "t", "]", "(", "pre_pooled_outputs", ")", "#softmax on task", "\n", "pooled_output", "=", "pooled_output", ".", "sum", "(", "-", "1", ")", "#softmax on task", "\n", "\n", "return", "pooled_output", "\n", "\n", "\n", "\n", "", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "masks", "=", "{", "}", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "\n", "", "return", "masks", "\n", "\n", "\n", "", "def", "last_mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "elast", "=", "self", ".", "elast", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "glast", "=", "self", ".", "gate", "(", "s", "*", "elast", ")", "\n", "return", "glast", "\n", "\n", "", "def", "get_view_for", "(", "self", ",", "n", ",", "p", ",", "masks", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1.weight'", ":", "\n", "# print('not nont')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "", "", "return", "None", "\n", "\n", "\n", "", "", "class", "Self_Attn", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\" Self attention Layer\"\"\"", "\n", "def", "__init__", "(", "self", ",", "attn_size", ")", ":", "\n", "        ", "super", "(", "Self_Attn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Linear", "(", "attn_size", ",", "attn_size", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_mask.Appr.eval": [[197, 265], ["bert_adapter_mask.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_adapter_mask.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_mask.Appr.hat_criterion_adapter", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "bert_adapter_mask.Appr.model", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_adapter_mask.Appr.model.forward", "hits.sum().data.cpu().numpy", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "loss.data.cpu().numpy", "range", "range", "bert_adapter_mask.Appr.model", "outputs.append", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "entropies.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hits.sum().data.cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.data.cpu", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n            inputs :\n                x : input feature maps( B,max_length,hidden_size)\n            returns :\n                out : self attention value + input feature\n                attention: B X N X N (N is Width*Height)\n        \"\"\"", "\n", "\n", "# print('x: ',x.size())", "\n", "m_batchsize", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "# print('energy: ',energy.size())", "\n", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "\n", "# attention =  F.gumbel_softmax(energy,hard=True,dim=-1)", "\n", "# print('attention: ',attention)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "# B X C X N", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "width", ",", "height", ")", "\n", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ewc.Appr.__init__": [[14, 21], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CNN EWC NCL'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ewc.Appr.train": [[24, 88], ["utils.get_model", "cnn_ewc.Appr._get_optimizer", "range", "utils.set_model_", "copy.deepcopy", "cnn_ewc.Appr.model_old.eval", "utils.freeze_model", "utils.fisher_matrix_diag_cnn", "time.time", "tqdm.tqdm.tqdm", "cnn_ewc.Appr.train_epoch", "time.time", "cnn_ewc.Appr.eval", "time.time", "print", "cnn_ewc.Appr.eval", "print", "print", "cnn_ewc.Appr.model.named_parameters", "cnn_ewc.Appr.model.named_parameters", "utils.get_model", "print", "cnn_ewc.Appr.fisher[].clone", "print", "cnn_ewc.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_cnn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "# Fisher ops", "\n", "if", "t", ">", "0", ":", "\n", "            ", "fisher_old", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "fisher_old", "[", "n", "]", "=", "self", ".", "fisher", "[", "n", "]", ".", "clone", "(", ")", "\n", "\n", "", "", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_cnn", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion_ewc", ",", "self", ".", "args", ")", "\n", "\n", "if", "t", ">", "0", ":", "\n", "# Watch out! We do not want to keep t models (or fisher diagonals) in memory, therefore we have to merge fisher diagonals", "\n", "            ", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "fisher", "[", "n", "]", "=", "(", "self", ".", "fisher", "[", "n", "]", "+", "fisher_old", "[", "n", "]", "*", "t", ")", "/", "(", "t", "+", "1", ")", "# Checked: it is better than the other option", "\n", "#self.fisher[n]=0.5*(self.fisher[n]+fisher_old[n])", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ewc.Appr.train_epoch": [[89, 114], ["cnn_ewc.Appr.model.train", "enumerate", "cnn_ewc.Appr.model.forward", "cnn_ewc.Appr.criterion_ewc", "iter_bar.set_description", "cnn_ewc.Appr.optimizer.zero_grad", "cnn_ewc.Appr.backward", "torch.nn.utils.clip_grad_norm", "cnn_ewc.Appr.optimizer.step", "cnn_ewc.Appr.model.parameters", "bat.to", "cnn_ewc.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward current model", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ewc.Appr.eval": [[115, 158], ["cnn_ewc.Appr.model.eval", "torch.no_grad", "enumerate", "cnn_ewc.Appr.f1_compute_fn", "images.size", "cnn_ewc.Appr.model.forward", "cnn_ewc.Appr.criterion_ewc", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_ewc.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "cnn_ewc.Appr.ent_id_detection", "cnn_ewc.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_ewc.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "real_b", "=", "images", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "if", "self", ".", "args", ".", "ent_id", ":", "#detected id", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "images", ",", "t", "=", "t", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "", "else", ":", "\n", "                        ", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "\n", "", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_kan.Appr.__init__": [[23, 30], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'W2V + RNN NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_kan.Appr.train": [[33, 88], ["print", "utils.get_model", "w2v_rnn_kan.Appr._get_optimizer_kan", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "w2v_rnn_kan.Appr.train_epoch", "time.time", "w2v_rnn_kan.Appr.eval", "time.time", "print", "print", "w2v_rnn_kan.Appr.eval", "print", "print", "float", "utils.get_model", "print", "print", "w2v_rnn_kan.Appr._get_optimizer_kan", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_kan", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_kan"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "\n", "        ", "if", "t", "==", "0", ":", "which_types", "=", "[", "'mcl'", "]", "\n", "else", ":", "which_types", "=", "[", "'ac'", ",", "'mcl'", "]", "\n", "\n", "for", "which_type", "in", "which_types", ":", "\n", "\n", "            ", "print", "(", "'Training Type: '", ",", "which_type", ")", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_kan", "(", "lr", ",", "which_type", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "which_type", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ",", "train_data", ",", "which_type", ",", "trained_task", "=", "t", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "10", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ",", "valid_data", ",", "which_type", ",", "trained_task", "=", "t", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_kan", "(", "lr", ",", "which_type", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_kan.Appr.train_epoch": [[91, 144], ["w2v_rnn_kan.Appr.model.train", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "w2v_rnn_kan.Appr.model.forward", "w2v_rnn_kan.Appr.ce", "iter_bar.set_description", "w2v_rnn_kan.Appr.optimizer.zero_grad", "w2v_rnn_kan.Appr.backward", "w2v_rnn_kan.Appr.model.ac.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "w2v_rnn_kan.Appr.optimizer.step", "w2v_rnn_kan.Appr.model.ac.named_parameters", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "w2v_rnn_kan.Appr.model.ac.mask", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "w2v_rnn_kan.Appr.model.named_parameters", "w2v_rnn_kan.Appr.model.parameters", "bat.to", "len", "w2v_rnn_kan.Appr.item", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.autograd.Variable.data.clone", "torch.autograd.Variable.data.clone", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "w2v_rnn_kan.Appr.model.get_view_for", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "which_type", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "which_type", ",", "s", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "#no regularization", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "t", ">", "0", "and", "which_type", "==", "'mcl'", ":", "\n", "                ", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "ac", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "rnn_weights", ":", "\n", "# print('n: ',n)", "\n", "# print('p: ',p.grad.size())", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "mask", ")", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "ac", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'ac.e'", "in", "n", ":", "\n", "                    ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "thres_cosh", ",", "self", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Constrain embeddings", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "ac", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'ac.e'", "in", "n", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "thres_emb", ",", "self", ".", "thres_emb", ")", "\n", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_kan.Appr.eval": [[145, 190], ["w2v_rnn_kan.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "w2v_rnn_kan.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_rnn_kan.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_rnn_kan.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "w2v_rnn_kan.Appr.model.forward", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "w2v_rnn_kan.Appr.model.forward", "hits.sum().data.cpu().numpy", "w2v_rnn_kan.Appr.ent_id_detection", "w2v_rnn_kan.Appr.data.cpu().numpy", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hits.sum().data.cpu", "w2v_rnn_kan.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", ",", "which_type", ",", "trained_task", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                        ", "task", "=", "torch", ".", "LongTensor", "(", "[", "trained_task", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "self", ".", "args", ".", "ent_id", ":", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "t", ",", "which_type", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "task", "=", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.__init__": [[15, 22], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\" Class implementing the L2 approach described in https://github.com/GT-RIPL/Continual-Learning-Benchmark/blob/master/agents/regularization.py \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL + KIM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.train": [[24, 87], ["utils.get_model", "bert_cnn_l2.Appr._get_optimizer", "range", "utils.set_model_", "bert_cnn_l2.Appr.params.items", "bert_cnn_l2.Appr.calculate_importance", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_l2.Appr.train_epoch", "time.time", "bert_cnn_l2.Appr.eval", "time.time", "print", "bert_cnn_l2.Appr.eval", "print", "print", "p.clone().detach", "utils.get_model", "print", "len", "print", "bert_cnn_l2.Appr._get_optimizer", "p.clone", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.calculate_importance", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "# 2.Backup the weight of current task", "\n", "task_param", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "task_param", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# 3.Calculate the importance of weights for current task", "\n", "", "importance", "=", "self", ".", "calculate_importance", "(", ")", "\n", "\n", "# Save the weight and importance of weights of current task", "\n", "self", ".", "task_count", "+=", "1", "\n", "if", "self", ".", "online_reg", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Always use only one slot in self.regularization_terms", "\n", "            ", "self", ".", "regularization_terms", "[", "1", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "", "else", ":", "\n", "# Use a new slot to store the task-specific information", "\n", "            ", "self", ".", "regularization_terms", "[", "self", ".", "task_count", "]", "=", "{", "'importance'", ":", "importance", ",", "'task_param'", ":", "task_param", "}", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.train_epoch": [[88, 114], ["bert_cnn_l2.Appr.model.train", "enumerate", "bert_cnn_l2.Appr.model.forward", "bert_cnn_l2.Appr.criterion", "iter_bar.set_description", "bert_cnn_l2.Appr.optimizer.zero_grad", "bert_cnn_l2.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_l2.Appr.optimizer.step", "bert_cnn_l2.Appr.model.parameters", "bat.to", "bert_cnn_l2.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward current model", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.eval": [[115, 151], ["bert_cnn_l2.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_l2.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_l2.Appr.model.forward", "bert_cnn_l2.Appr.criterion", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_l2.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_l2.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_l2.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.calculate_importance": [[153, 159], ["bert_cnn_l2.Appr.params.items", "p.clone().detach().fill_", "p.clone().detach", "p.clone"], "methods", ["None"], ["", "def", "calculate_importance", "(", "self", ")", ":", "\n", "# Use an identity importance so it is an L2 regularization.", "\n", "        ", "importance", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "1", ")", "# Identity", "\n", "", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_l2.Appr.criterion": [[161, 176], ["bert_cnn_l2.Appr.ce", "bert_cnn_l2.Appr.regularization_terms.items", "len", "bert_cnn_l2.Appr.params.items"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "inputs", ",", "targets", ",", "regularization", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss", "=", "self", ".", "ce", "(", "inputs", ",", "targets", ",", "**", "kwargs", ")", "\n", "\n", "if", "regularization", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Calculate the reg_loss only when the regularization_terms exists", "\n", "            ", "reg_loss", "=", "0", "\n", "for", "i", ",", "reg_term", "in", "self", ".", "regularization_terms", ".", "items", "(", ")", ":", "\n", "                ", "task_reg_loss", "=", "0", "\n", "importance", "=", "reg_term", "[", "'importance'", "]", "\n", "task_param", "=", "reg_term", "[", "'task_param'", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                    ", "task_reg_loss", "+=", "(", "importance", "[", "n", "]", "*", "(", "p", "-", "task_param", "[", "n", "]", ")", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "reg_loss", "+=", "task_reg_loss", "\n", "", "loss", "+=", "self", ".", "lamb", "*", "reg_loss", "\n", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_owm.Appr.__init__": [[15, 19], ["w2v_cnn_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_owm.Appr.train": [[20, 76], ["utils.get_model", "w2v_cnn_owm.Appr._get_optimizer_owm", "utils.set_model_", "range", "time.time", "tqdm.tqdm.tqdm", "time.time", "w2v_cnn_owm.Appr.train_epoch", "w2v_cnn_owm.Appr.eval", "print", "print", "w2v_cnn_owm.Appr.eval", "print", "print", "print", "print", "float", "utils.get_model", "print", "print", "w2v_cnn_owm.Appr._get_optimizer_owm", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_acc", "=", "0", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "# patience = self.lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_owm", "(", "lr", ")", "\n", "nepochs", "=", "self", ".", "nepochs", "\n", "test_max", "=", "0", "\n", "# Loop epochs", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "cur_epoch", "=", "e", ",", "nepoch", "=", "nepochs", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| [{:d}/19], Epoch {:d}/{:d}, | Train: loss={:.3f}, acc={:2.2f}% |'", ".", "format", "(", "t", "+", "1", ",", "e", "+", "1", ",", "\n", "nepochs", ",", "train_loss", ",", "\n", "100", "*", "train_acc", ")", ",", "\n", "end", "=", "''", ")", "\n", "# # Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.2f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "print", "(", ")", "\n", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                   ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_owm", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best validation model", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_owm.Appr.train_epoch": [[77, 153], ["w2v_cnn_owm.Appr.model.train", "enumerate", "w2v_cnn_owm.Appr.model.forward", "w2v_cnn_owm.Appr.ce", "w2v_cnn_owm.Appr.optimizer.zero_grad", "w2v_cnn_owm.Appr.backward", "iter_bar.set_description", "w2v_cnn_owm.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "w2v_cnn_owm.Appr.optimizer.step", "x.detach.detach.detach", "p.detach.detach.detach", "w2v_cnn_owm.Appr.model.parameters", "bat.to", "w2v_cnn_owm.Appr.item", "int", "int", "range", "torch.mm().view_as", "torch.mm", "p.detach.detach.sub_", "torch.mm", "w2v_cnn_owm.Appr.train_epoch.pro_weight"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "cur_epoch", "=", "0", ",", "nepoch", "=", "0", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "lamda", "=", "step", "/", "len", "(", "batch", ")", "/", "nepoch", "+", "cur_epoch", "/", "nepoch", "\n", "\n", "alpha_array", "=", "[", "1.0", "*", "0.00001", "**", "lamda", ",", "1.0", "*", "0.0001", "**", "lamda", ",", "1.0", "*", "0.01", "**", "lamda", ",", "1.0", "*", "0.1", "**", "lamda", "]", "\n", "\n", "def", "pro_weight", "(", "p", ",", "x", ",", "w", ",", "alpha", "=", "1.0", ",", "cnn", "=", "True", ",", "stride", "=", "1", ")", ":", "\n", "                ", "x", "=", "x", ".", "detach", "(", ")", "\n", "p", "=", "p", ".", "detach", "(", ")", "\n", "\n", "if", "cnn", ":", "\n", "                    ", "_", ",", "_", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "F", ",", "_", ",", "HH", ",", "WW", "=", "w", ".", "shape", "\n", "S", "=", "stride", "# stride", "\n", "Ho", "=", "int", "(", "1", "+", "(", "H", "-", "HH", ")", "/", "S", ")", "\n", "Wo", "=", "int", "(", "1", "+", "(", "W", "-", "WW", ")", "/", "S", ")", "\n", "for", "i", "in", "range", "(", "Ho", ")", ":", "\n", "                        ", "for", "j", "in", "range", "(", "Wo", ")", ":", "\n", "# N*C*HH*WW, C*HH*WW = N*C*HH*WW, sum -> N*1", "\n", "                            ", "r", "=", "x", "[", ":", ",", ":", ",", "i", "*", "S", ":", "i", "*", "S", "+", "HH", ",", "j", "*", "S", ":", "j", "*", "S", "+", "WW", "]", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "# r = r[:, range(r.shape[1] - 1, -1, -1)]", "\n", "k", "=", "torch", ".", "mm", "(", "p", ",", "torch", ".", "t", "(", "r", ")", ")", "\n", "p", ".", "sub_", "(", "torch", ".", "mm", "(", "k", ",", "torch", ".", "t", "(", "k", ")", ")", "/", "(", "alpha", "+", "torch", ".", "mm", "(", "r", ",", "k", ")", ")", ")", "\n", "", "", "w", ".", "grad", ".", "data", "=", "torch", ".", "mm", "(", "w", ".", "grad", ".", "data", ".", "view", "(", "F", ",", "-", "1", ")", ",", "torch", ".", "t", "(", "p", ".", "data", ")", ")", ".", "view_as", "(", "w", ")", "\n", "", "else", ":", "\n", "                    ", "r", "=", "x", "\n", "k", "=", "torch", ".", "mm", "(", "p", ",", "torch", ".", "t", "(", "r", ")", ")", "\n", "p", ".", "sub_", "(", "torch", ".", "mm", "(", "k", ",", "torch", ".", "t", "(", "k", ")", ")", "/", "(", "alpha", "+", "torch", ".", "mm", "(", "r", ",", "k", ")", ")", ")", "\n", "w", ".", "grad", ".", "data", "=", "torch", ".", "mm", "(", "w", ".", "grad", ".", "data", ",", "torch", ".", "t", "(", "p", ".", "data", ")", ")", "\n", "# Compensate embedding gradients", "\n", "", "", "for", "n", ",", "w", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", "==", "'c1.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc1", ",", "x_list", "[", "0", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'c2.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc2", ",", "x_list", "[", "1", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'c3.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "Pc3", ",", "x_list", "[", "2", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "n", "==", "'fc1.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "P1", ",", "h_list", "[", "0", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "1", "]", ",", "cnn", "=", "False", ")", "\n", "\n", "", "if", "n", "==", "'fc2.weight'", ":", "\n", "                    ", "pro_weight", "(", "self", ".", "P2", ",", "h_list", "[", "1", "]", ",", "w", ",", "alpha", "=", "alpha_array", "[", "2", "]", ",", "cnn", "=", "False", ")", "\n", "\n", "\n", "# Apply step", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_owm.Appr.eval": [[154, 190], ["w2v_cnn_owm.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_cnn_owm.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_cnn_owm.Appr.model.forward", "w2v_cnn_owm.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_cnn_owm.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "w2v_cnn_owm.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_cnn_owm.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "# Forward", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "%", "10", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_one.Appr.__init__": [[18, 25], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'CNN ONE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_one.Appr.train": [[27, 73], ["copy.deepcopy", "utils.get_model", "cnn_one.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "cnn_one.Appr.train_epoch", "time.time", "cnn_one.Appr.eval", "time.time", "print", "cnn_one.Appr.eval", "print", "print", "utils.get_model", "print", "print", "cnn_one.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model: isolate", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_one.Appr.train_epoch": [[74, 109], ["cnn_one.Appr.model.train", "enumerate", "cnn_one.Appr.model.forward", "cnn_one.Appr.ce", "iter_bar.set_description", "cnn_one.Appr.optimizer.zero_grad", "cnn_one.Appr.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "cnn_one.Appr.optimizer.step", "cnn_one.Appr.model.parameters", "t.to", "cnn_one.Appr.item", "torch.normalize", "torch.normalize", "cnn_one.Appr.sup_loss", "cnn_one.Appr.sup_loss"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "#TIL setting", "\n", "\n", "# print('targets: ',targets)", "\n", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "if", "self", ".", "args", ".", "sup_head_norm", ":", "\n", "                    ", "output_rep", "=", "F", ".", "normalize", "(", "output", ",", "dim", "=", "1", ")", "\n", "loss", "+=", "self", ".", "sup_loss", "(", "output_rep", ",", "pooled_rep", ",", "images", ",", "targets", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "images", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_one.Appr.eval": [[110, 142], ["cnn_one.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_one.Appr.f1_compute_fn", "targets.size", "cnn_one.Appr.model.forward", "cnn_one.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_one.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "cnn_one.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_one.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "#TIL", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ucl.Appr.__init__": [[28, 33], ["w2v_cnn_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ucl.Appr.train": [[35, 101], ["utils.get_model", "w2v_cnn_ucl.Appr._get_optimizer_ucl", "range", "utils.set_model_", "copy.deepcopy", "time.time", "tqdm.tqdm.tqdm", "len", "w2v_cnn_ucl.Appr.train_epoch", "time.time", "w2v_cnn_ucl.Appr.eval", "time.time", "print", "print", "w2v_cnn_ucl.Appr.eval", "print", "print", "utils.freeze_model", "float", "utils.get_model", "print", "print", "w2v_cnn_ucl.Appr._get_optimizer_ucl", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "lr_rho", "=", "self", ".", "lr_rho", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_ucl", "(", "lr", ",", "lr_rho", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "            ", "self", ".", "epoch", "=", "self", ".", "epoch", "+", "1", "\n", "# Train", "\n", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "\n", "num_batch", "=", "len", "(", "train", ")", "\n", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "\n", "e", "+", "1", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "num_batch", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "num_batch", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "# save log for current task & old tasks at every epoch", "\n", "# self.logger.add(epoch=(t * self.nepochs) + e, task_num=t + 1, valid_loss=valid_loss, valid_acc=valid_acc)", "\n", "\n", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "lr_rho", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_ucl", "(", "lr", ",", "lr_rho", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "saved", "=", "1", "\n", "\n", "# self.logger.save()", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ucl.Appr.train_epoch": [[102, 136], ["w2v_cnn_ucl.Appr.model.train", "enumerate", "len", "w2v_cnn_ucl.Appr.model.forward", "w2v_cnn_ucl.Appr.ce", "w2v_cnn_ucl.Appr.custom_regularization", "iter_bar.set_description", "w2v_cnn_ucl.Appr.optimizer.zero_grad", "w2v_cnn_ucl.Appr.backward", "w2v_cnn_ucl.Appr.optimizer.step", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "bat.to", "w2v_cnn_ucl.Appr.item", "w2v_cnn_ucl.Appr.model.parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.custom_regularization", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "\n", "# Forward current model", "\n", "mini_batch_size", "=", "len", "(", "targets", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "sample", "=", "True", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "# if self.split:", "\n", "#     output = F.log_softmax(self.model(input_ids, segment_ids, input_mask, sample=True)[t],dim=1)", "\n", "# else:", "\n", "#     output = self.model(input_ids, segment_ids, input_mask, sample=True)", "\n", "# loss = F.nll_loss(output, targets, reduction='sum')", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "loss", "=", "self", ".", "custom_regularization", "(", "self", ".", "model_old", ",", "self", ".", "model", ",", "mini_batch_size", ",", "loss", ")", "\n", "# Backward", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'SGD'", "or", "self", ".", "args", ".", "optimizer", "==", "'SGD_momentum_decay'", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ucl.Appr.eval": [[137, 182], ["w2v_cnn_ucl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "w2v_cnn_ucl.Appr.f1_compute_fn", "tokens_term_ids.size", "len", "w2v_cnn_ucl.Appr.model.forward", "w2v_cnn_ucl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_cnn_ucl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "w2v_cnn_ucl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_cnn_ucl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "# Forward", "\n", "mini_batch_size", "=", "len", "(", "targets", ")", "\n", "# if self.split:", "\n", "#     output = F.log_softmax(self.model( input_ids, segment_ids, input_mask, sample=False)[t],dim=1)", "\n", "# else:", "\n", "#     output = self.model( input_ids, segment_ids, input_mask, sample=False)", "\n", "# loss = F.nll_loss(output, targets, reduction='sum')", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "sample", "=", "False", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ucl.Appr.custom_regularization": [[186, 280], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "zip", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "saver_net.named_children", "trainer_net.named_children", "bayes_layer._calculate_fan_in_and_fan_out", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "isinstance", "isinstance", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "math.sqrt", "math.sqrt", "len", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "isinstance", "isinstance", "len", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.expand", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.permute", "prev_weight_strength.reshape.reshape.permute", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], ["", "def", "custom_regularization", "(", "self", ",", "saver_net", ",", "trainer_net", ",", "mini_batch_size", ",", "loss", "=", "None", ")", ":", "\n", "\n", "        ", "sigma_weight_reg_sum", "=", "0", "\n", "sigma_bias_reg_sum", "=", "0", "\n", "sigma_weight_normal_reg_sum", "=", "0", "\n", "sigma_bias_normal_reg_sum", "=", "0", "\n", "mu_weight_reg_sum", "=", "0", "\n", "mu_bias_reg_sum", "=", "0", "\n", "L1_mu_weight_reg_sum", "=", "0", "\n", "L1_mu_bias_reg_sum", "=", "0", "\n", "\n", "out_features_max", "=", "512", "\n", "alpha", "=", "self", ".", "args", ".", "alpha", "\n", "if", "self", ".", "saved", ":", "\n", "            ", "alpha", "=", "1", "\n", "\n", "", "prev_weight_strength", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "1", ",", "1", ",", "1", ")", ".", "uniform_", "(", "0", ",", "0", ")", ")", "\n", "\n", "\n", "for", "(", "_", ",", "saver_layer", ")", ",", "(", "_", ",", "trainer_layer", ")", "in", "zip", "(", "saver_net", ".", "named_children", "(", ")", ",", "trainer_net", ".", "named_children", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "trainer_layer", ",", "BayesianLinear", ")", "==", "False", "and", "isinstance", "(", "trainer_layer", ",", "BayesianConv2D", ")", "==", "False", ":", "\n", "                ", "continue", "\n", "# calculate mu regularization", "\n", "", "trainer_weight_mu", "=", "trainer_layer", ".", "weight_mu", "\n", "saver_weight_mu", "=", "saver_layer", ".", "weight_mu", "\n", "trainer_bias", "=", "trainer_layer", ".", "bias", "\n", "saver_bias", "=", "saver_layer", ".", "bias", "\n", "\n", "fan_in", ",", "fan_out", "=", "_calculate_fan_in_and_fan_out", "(", "trainer_weight_mu", ")", "\n", "\n", "trainer_weight_sigma", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "trainer_layer", ".", "weight_rho", ")", ")", "\n", "saver_weight_sigma", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "saver_layer", ".", "weight_rho", ")", ")", "\n", "\n", "if", "isinstance", "(", "trainer_layer", ",", "BayesianLinear", ")", ":", "\n", "                ", "std_init", "=", "math", ".", "sqrt", "(", "(", "2", "/", "fan_in", ")", "*", "self", ".", "args", ".", "ratio", ")", "\n", "", "if", "isinstance", "(", "trainer_layer", ",", "BayesianConv2D", ")", ":", "\n", "                ", "std_init", "=", "math", ".", "sqrt", "(", "(", "2", "/", "fan_out", ")", "*", "self", ".", "args", ".", "ratio", ")", "\n", "\n", "", "saver_weight_strength", "=", "(", "std_init", "/", "saver_weight_sigma", ")", "\n", "\n", "if", "len", "(", "saver_weight_mu", ".", "shape", ")", "==", "4", ":", "\n", "                ", "out_features", ",", "in_features", ",", "_", ",", "_", "=", "saver_weight_mu", ".", "shape", "\n", "curr_strength", "=", "saver_weight_strength", ".", "expand", "(", "out_features", ",", "in_features", ",", "1", ",", "1", ")", "\n", "prev_strength", "=", "prev_weight_strength", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "expand", "(", "out_features", ",", "in_features", ",", "1", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "out_features", ",", "in_features", "=", "saver_weight_mu", ".", "shape", "\n", "curr_strength", "=", "saver_weight_strength", ".", "expand", "(", "out_features", ",", "in_features", ")", "\n", "if", "len", "(", "prev_weight_strength", ".", "shape", ")", "==", "4", ":", "\n", "                    ", "feature_size", "=", "in_features", "//", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "reshape", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "expand", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ",", "feature_size", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "prev_strength", "=", "prev_weight_strength", ".", "permute", "(", "1", ",", "0", ")", ".", "expand", "(", "out_features", ",", "in_features", ")", "\n", "\n", "", "L2_strength", "=", "torch", ".", "max", "(", "curr_strength", ",", "prev_strength", ")", "\n", "bias_strength", "=", "torch", ".", "squeeze", "(", "saver_weight_strength", ")", "\n", "\n", "L1_sigma", "=", "saver_weight_sigma", "\n", "bias_sigma", "=", "torch", ".", "squeeze", "(", "saver_weight_sigma", ")", "\n", "\n", "prev_weight_strength", "=", "saver_weight_strength", "\n", "\n", "mu_weight_reg", "=", "(", "L2_strength", "*", "(", "trainer_weight_mu", "-", "saver_weight_mu", ")", ")", ".", "norm", "(", "2", ")", "**", "2", "\n", "mu_bias_reg", "=", "(", "bias_strength", "*", "(", "trainer_bias", "-", "saver_bias", ")", ")", ".", "norm", "(", "2", ")", "**", "2", "\n", "\n", "L1_mu_weight_reg", "=", "(", "torch", ".", "div", "(", "saver_weight_mu", "**", "2", ",", "L1_sigma", "**", "2", ")", "*", "(", "trainer_weight_mu", "-", "saver_weight_mu", ")", ")", ".", "norm", "(", "1", ")", "\n", "L1_mu_bias_reg", "=", "(", "torch", ".", "div", "(", "saver_bias", "**", "2", ",", "bias_sigma", "**", "2", ")", "*", "(", "trainer_bias", "-", "saver_bias", ")", ")", ".", "norm", "(", "1", ")", "\n", "\n", "L1_mu_weight_reg", "=", "L1_mu_weight_reg", "*", "(", "std_init", "**", "2", ")", "\n", "L1_mu_bias_reg", "=", "L1_mu_bias_reg", "*", "(", "std_init", "**", "2", ")", "\n", "\n", "weight_sigma", "=", "(", "trainer_weight_sigma", "**", "2", "/", "saver_weight_sigma", "**", "2", ")", "\n", "\n", "normal_weight_sigma", "=", "trainer_weight_sigma", "**", "2", "\n", "\n", "sigma_weight_reg_sum", "=", "sigma_weight_reg_sum", "+", "(", "weight_sigma", "-", "torch", ".", "log", "(", "weight_sigma", ")", ")", ".", "sum", "(", ")", "\n", "sigma_weight_normal_reg_sum", "=", "sigma_weight_normal_reg_sum", "+", "(", "normal_weight_sigma", "-", "torch", ".", "log", "(", "normal_weight_sigma", ")", ")", ".", "sum", "(", ")", "\n", "\n", "mu_weight_reg_sum", "=", "mu_weight_reg_sum", "+", "mu_weight_reg", "\n", "mu_bias_reg_sum", "=", "mu_bias_reg_sum", "+", "mu_bias_reg", "\n", "L1_mu_weight_reg_sum", "=", "L1_mu_weight_reg_sum", "+", "L1_mu_weight_reg", "\n", "L1_mu_bias_reg_sum", "=", "L1_mu_bias_reg_sum", "+", "L1_mu_bias_reg", "\n", "\n", "# elbo loss", "\n", "", "loss", "=", "loss", "/", "mini_batch_size", "\n", "# L2 loss", "\n", "loss", "=", "loss", "+", "alpha", "*", "(", "mu_weight_reg_sum", "+", "mu_bias_reg_sum", ")", "/", "(", "2", "*", "mini_batch_size", ")", "\n", "# L1 loss", "\n", "loss", "=", "loss", "+", "self", ".", "saved", "*", "(", "L1_mu_weight_reg_sum", "+", "L1_mu_bias_reg_sum", ")", "/", "(", "mini_batch_size", ")", "\n", "# sigma regularization", "\n", "loss", "=", "loss", "+", "self", ".", "beta", "*", "(", "sigma_weight_reg_sum", "+", "sigma_weight_normal_reg_sum", ")", "/", "(", "2", "*", "mini_batch_size", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.__init__": [[19, 23], ["cnn_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.auto_similarity": [[25, 76], ["range", "print", "numpy.savetxt", "print", "numpy.savetxt", "print", "print", "range", "cnn_cat.Appr.model.mask", "print", "cnn_cat.Appr.real_train", "cnn_cat.Appr.eval_", "len", "gfc1.detach", "gfc2.detach", "cnn_cat.Appr.model.mask", "print", "cnn_cat.Appr.real_train", "cnn_cat.Appr.eval_", "range", "gc1.detach", "gc2.detach", "gc3.detach", "gfc1.detach", "gfc2.detach", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_"], ["pdrop2", "=", "0.5", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop1", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "pdrop2", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "mcl", "=", "MainContinualLearning", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "transfer", "=", "TransferLayer", "(", "taskcla", ",", "args", ")", "\n", "self", ".", "kt", "=", "KnowledgeTransfer", "(", "ncha", ",", "size", ",", "self", ".", "taskcla", ",", "args", ")", "\n", "self", ".", "smax", "=", "args", ".", "smax", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "print", "(", "'CNN CAT'", ")", "\n", "print", "(", "'pdrop1: '", ",", "pdrop1", ")", "\n", "print", "(", "'pdrop2: '", ",", "pdrop2", ")", "\n", "\n", "\"\"\" (e.g., used with compression experiments)\n        lo,hi=0,2\n        self.efc1.weight.data.uniform_(lo,hi)\n        self.efc2.weight.data.uniform_(lo,hi)\n        self.efc3.weight.data.uniform_(lo,hi)\n        #\"\"\"", "\n", "\n", "return", "\n", "\n", "", "def", "mcl_feature", "(", "self", ",", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", ":", "\n", "        ", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c1", "(", "x", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc1", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c2", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc2", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "c3", "(", "h", ")", ")", ")", ")", "\n", "h", "=", "h", "*", "gc3", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "mcl", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "return", "h", "\n", "\n", "\n", "# progressive style", "\n", "", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", "=", "1", ",", "phase", "=", "None", ",", "\n", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ",", "\n", "similarity", "=", "None", ",", "history_mask_pre", "=", "None", ",", "check_federated", "=", "None", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "if", "'mcl'", "in", "phase", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.train": [[78, 86], ["cnn_cat.Appr.auto_similarity", "cnn_cat.Appr.similarities.append", "print", "print", "cnn_cat.Appr.check_federated.set_similarities", "cnn_cat.Appr.real_train"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.auto_similarity", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.set_similarities", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train"], ["                ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.real_train": [[89, 180], ["copy.deepcopy", "utils.get_model", "print", "cnn_cat.Appr._get_optimizer_cat", "utils.set_model_", "range", "torch.autograd.Variable", "cnn_cat.Appr.model.mask", "range", "cnn_cat.Appr.model.named_parameters", "cnn_cat.Appr.history_mask_pre.append", "time.time", "tqdm.tqdm.tqdm", "cnn_cat.Appr.train_epoch", "time.time", "cnn_cat.Appr.eval_", "time.time", "print", "cnn_cat.Appr.eval_", "print", "print", "print", "torch.LongTensor().cuda", "len", "torch.autograd.Variable", "range", "cnn_cat.Appr.model.get_view_for", "utils.get_model", "print", "mask[].data.clone", "len", "torch.max", "m.data.clone", "print", "cnn_cat.Appr._get_optimizer_cat", "torch.LongTensor", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat"], ["\n", "", "elif", "'mcl'", "in", "phase", "and", "'multi-loss-joint-Tsim'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "max_masks", "=", "self", ".", "mask", "(", "t", ",", "s", "=", "s", ")", "\n", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "max_masks", "\n", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "pre_models", "=", "[", "]", "\n", "\n", "pre_ts", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "if", "self", ".", "training", "==", "True", "and", "similarity", "[", "pre_t", "]", ":", "\n", "                    ", "continue", "\n", "", "elif", "self", ".", "training", "==", "False", "and", "check_federated", ".", "check_t", "(", "pre_t", ")", "==", "False", ":", "\n", "                    ", "continue", "\n", "\n", "", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "pre_t", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "pre_gc1", "=", "gc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc2", "=", "gc2", ".", "data", ".", "clone", "(", ")", "\n", "pre_gc3", "=", "gc3", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc1", "=", "gfc1", ".", "data", ".", "clone", "(", ")", "\n", "pre_gfc2", "=", "gfc2", ".", "data", ".", "clone", "(", ")", "\n", "\n", "pre_h", "=", "self", ".", "mcl_feature", "(", "x", ",", "pre_gc1", ",", "pre_gc2", ",", "pre_gc3", ",", "pre_gfc1", ",", "pre_gfc2", ")", "\n", "\n", "pre_models", ".", "append", "(", "pre_h", ".", "clone", "(", ")", ")", "\n", "pre_ts", ".", "append", "(", "pre_t", ")", "\n", "#Tsim: model for each Tsim", "\n", "\n", "", "if", "len", "(", "pre_models", ")", ">", "1", ":", "\n", "                ", "task_models", "=", "torch", ".", "stack", "(", "pre_models", ")", "\n", "task_models", "=", "task_models", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "query", "=", "torch", ".", "unsqueeze", "(", "self", ".", "relu", "(", "self", ".", "kt", ".", "q1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ".", "expand", "(", "task_models", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "#hard to train", "\n", "\n", "h_attn", ",", "_", "=", "self", ".", "kt", ".", "encoder", "(", "task_models", ",", "query", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                        ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "if", "'no-isolate'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "return", "output_dict", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "history_mask_pre", ",", "similarity", "=", "similarity", ")", "\n", "\n", "h_attn", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y", "=", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", "\n", "y_attn", "=", "self", ".", "mcl", ".", "att_last", "(", "h", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "y_attn", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                            ", "y", ".", "append", "(", "self", ".", "mcl", ".", "mask_last", "[", "t", "]", "(", "h", ")", ")", "\n", "y_attn", ".", "append", "(", "self", ".", "mcl", ".", "att_last", "[", "t", "]", "(", "h_attn", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'y_attn'", "]", "=", "y_attn", "\n", "output_dict", "[", "'masks'", "]", "=", "max_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.train_epoch": [[181, 281], ["cnn_cat.Appr.model.train", "cnn_cat.Appr.model.train", "enumerate", "cnn_cat.Appr.optimizer.zero_grad", "cnn_cat.Appr.backward", "torch.nn.utils.clip_grad_norm", "cnn_cat.Appr.optimizer.step", "cnn_cat.Appr.model", "cnn_cat.Appr.model.named_parameters", "cnn_cat.Appr.model.parameters", "cnn_cat.Appr.model.named_parameters", "t.to", "len", "cnn_cat.Appr.criterion", "cnn_cat.Appr.joint_criterion", "cnn_cat.Appr.model", "cnn_cat.Appr.transfer_criterion", "cnn_cat.Appr.model.named_parameters", "cnn_cat.Appr.model.named_parameters", "n.startswith", "cnn_cat.Appr.model.named_parameters", "n.startswith", "torch.clamp", "n.startswith", "cnn_cat.Appr.model.Tsim_mask", "cnn_cat.Appr.model.get_view_for().clone", "torch.max", "torch.cosh", "torch.cosh", "n.startswith", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "cnn_cat.Appr.model.get_view_for", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["\n", "return", "output_dict", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "pre_mask", "\n", "h", "=", "self", ".", "mcl_feature", "(", "x", ",", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "mcl", ".", "mask_last", "(", "h", ")", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                    ", "y", ".", "append", "(", "self", ".", "transfer", ".", "transfer", "[", "pre_task", "]", "[", "t", "]", "(", "self", ".", "transfer", ".", "last", "[", "pre_task", "]", "(", "h", ")", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "\n", "\n", "", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ",", "phase", "=", "None", ")", ":", "\n", "#used by training", "\n", "\n", "        ", "gc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gc3", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "[", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "]", "\n", "\n", "", "def", "Tsim_mask", "(", "self", ",", "t", ",", "history_mask_pre", "=", "None", ",", "similarity", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "#find the distinct mask, used by block the backward pass", "\n", "\n", "#want aggregate Tsim", "\n", "        ", "if", "phase", "is", "None", ":", "\n", "#Tsim mask", "\n", "            ", "Tsim_gc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gc3", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "ec3", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc1", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "Tsim_gfc2", "=", "torch", ".", "ones_like", "(", "self", ".", "gate", "(", "0", "*", "self", ".", "mcl", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", ")", "\n", "\n", "\n", "", "for", "history_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "history_t", "==", "0", ":", "\n", "                ", "Tsim_gc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "else", ":", "\n", "                ", "Tsim_gc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "0", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "0", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "1", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "1", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gc3_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "2", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "2", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc1_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "3", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "3", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "Tsim_gfc2_index", "=", "(", "history_mask_pre", "[", "history_t", "]", "[", "4", "]", "-", "history_mask_pre", "[", "history_t", "-", "1", "]", "[", "4", "]", ")", ".", "round", "(", ")", ".", "nonzero", "(", ")", "\n", "", "if", "similarity", "[", "history_t", "]", "==", "0", ":", "\n", "                ", "Tsim_gc1", "[", "Tsim_gc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc2", "[", "Tsim_gc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gc3", "[", "Tsim_gc3_index", "[", ":", ",", "0", "]", ",", "Tsim_gc3_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc1", "[", "Tsim_gfc1_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc1_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "Tsim_gfc2", "[", "Tsim_gfc2_index", "[", ":", ",", "0", "]", ",", "Tsim_gfc2_index", "[", ":", ",", "1", "]", "]", "=", "0", "\n", "\n", "", "", "return", "[", "Tsim_gc1", ",", "Tsim_gc2", ",", "Tsim_gc3", ",", "Tsim_gfc1", ",", "Tsim_gfc2", "]", "\n", "\n", "\n", "\n", "", "def", "get_view_for", "(", "self", ",", "n", ",", "masks", ")", ":", "\n", "        ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "masks", "\n", "\n", "if", "n", "==", "'mcl.fc1.weight'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc1", ".", "weight", ")", "\n", "", "elif", "n", "==", "'mcl.fc1.bias'", ":", "\n", "            ", "return", "gfc1", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.weight'", ":", "\n", "            ", "post", "=", "gfc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "pre", "=", "gfc1", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "fc2", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.fc2.bias'", ":", "\n", "            ", "return", "gfc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.c2.weight'", ":", "\n", "            ", "post", "=", "gc2", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c2", ".", "weight", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.eval_": [[285, 306], ["cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["            ", "return", "gc2", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'mcl.c3.weight'", ":", "\n", "            ", "post", "=", "gc3", ".", "data", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "pre", "=", "gc2", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "self", ".", "mcl", ".", "c3", ".", "weight", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'mcl.c3.bias'", ":", "\n", "            ", "return", "gc3", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "return", "None", "\n", "\n", "\n", "\n", "", "", "class", "MainContinualLearning", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "MainContinualLearning", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.eval": [[308, 337], ["cnn_cat.Appr.compute_acc", "print", "cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.compute_acc": [[339, 455], ["cnn_cat.Appr.model.eval", "print", "torch.no_grad", "enumerate", "cnn_cat.Appr.f1_compute_fn", "targets.size", "target_list.append", "len", "cnn_cat.Appr.f1_compute_fn", "output_attn.max", "output.max", "pred_att_list.append", "pred_mask_list.append", "mask_hits.sum().data.cpu().numpy().item", "att_hits.sum().data.cpu().numpy().item", "output.max", "pred_mask_list.append", "hits.sum().data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "cnn_cat.Appr.criterion", "cnn_cat.Appr.joint_criterion", "cnn_cat.Appr.model", "cnn_cat.Appr.transfer_criterion", "cnn_cat.Appr.data.cpu().numpy().item", "cnn_cat.Appr.data.cpu().numpy().item", "cnn_cat.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "cnn_cat.Appr.model", "cnn_cat.Appr.ent_id_detection", "mask_hits.sum().data.cpu().numpy", "att_hits.sum().data.cpu().numpy", "hits.sum().data.cpu().numpy", "cnn_cat.Appr.ent_id_detection", "cnn_cat.Appr.model.forward", "cnn_cat.Appr.data.cpu().numpy", "cnn_cat.Appr.data.cpu().numpy", "cnn_cat.Appr.data.cpu().numpy", "mask_hits.sum().data.cpu", "att_hits.sum().data.cpu", "hits.sum().data.cpu", "cnn_cat.Appr.data.cpu", "cnn_cat.Appr.data.cpu", "cnn_cat.Appr.data.cpu", "mask_hits.sum", "att_hits.sum", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "mask_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "mask_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "att_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "", "", "class", "TransferLayer", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "TransferLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "self", ".", "args", "=", "args", "\n", "\n", "\n", "self", ".", "c1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ncha", ",", "64", ",", "kernel_size", "=", "size", "//", "8", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "size", ",", "size", "//", "8", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "c3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "smid", "=", "s", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "256", "*", "self", ".", "smid", "*", "self", ".", "smid", ",", "2048", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "# All embedding stuff should start with 'e'", "\n", "self", ".", "ec1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "64", ")", "\n", "self", ".", "ec2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "128", ")", "\n", "self", ".", "ec3", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "256", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "self", ".", "taskcla", ")", ",", "2048", ")", "\n", "\n", "\n", "self", ".", "fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "2048", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "self", ".", "args", ".", "nclasses", ")", "\n", "\n", "# this one will not change according to different scenario", "\n", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "args", ".", "nclasses", ",", "self", ".", "args", ".", "nclasses", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "last_fusion", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "last_fusion", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "self", ".", "transfer", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "from_t", ",", "from_n", "in", "taskcla", ":", "\n", "                ", "self", ".", "transfer_to_n", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "to_t", ",", "to_n", "in", "taskcla", ":", "\n", "                    ", "self", ".", "transfer_to_n", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "from_n", ",", "to_n", ")", ")", "\n", "", "self", ".", "transfer", ".", "append", "(", "self", ".", "transfer_to_n", ")", "\n", "\n", "", "", "", "", "class", "KnowledgeTransfer", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "ncha", ",", "size", ",", "taskcla", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "KnowledgeTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nhid", "=", "2048", "\n", "#self-attention ==============", "\n", "self", ".", "q1", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "taskcla", ")", ",", "nhid", ")", "\n", "self", ".", "encoder", "=", "EncoderLayer", "(", "args", ".", "n_head", ",", "nhid", ",", "nhid", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "int", "(", "nhid", "/", "args", ".", "n_head", ")", ",", "args", "=", "args", ")", "\n", "# n_head, d_model, d_k, d_v", "\n", "\n", "\n", "", "", "class", "EncoderLayer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "''' Compose with two layers '''", "\n", "\n", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_inner", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "enc_input", ",", "enc_q", "=", "None", ",", "ranking", "=", "None", ")", ":", "\n", "#TODO: Positional/ranking embedding", "\n", "\n", "        ", "if", "enc_q", "is", "None", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_input", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "else", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "enc_q", ",", "enc_input", ",", "enc_input", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n", "", "", "class", "MultiHeadAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "''' Multi-Head Attention module '''", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.transfer_criterion": [[456, 458], ["cnn_cat.Appr.ce"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.joint_criterion": [[460, 462], ["cnn_cat.Appr.criterion", "cnn_cat.Appr.ce"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_cat.Appr.criterion": [[463, 480], ["zip", "cnn_cat.Appr.ce", "aux.sum", "m.sum", "numpy.prod().item", "numpy.prod", "m.size"], "methods", ["None"], ["\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "#sqrt d_k", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n", "\n", "", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_one.Appr.__init__": [[31, 37], ["bert_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'BERT ONE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_one.Appr.train": [[38, 89], ["bert_one.Appr.model.to", "copy.deepcopy", "pytorch_pretrained_bert.optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_one.Appr.train_epoch", "time.time", "bert_one.Appr.eval", "time.time", "print", "bert_one.Appr.eval", "print", "print", "bert_one.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model: isolate", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_one.Appr.train_epoch": [[90, 121], ["bert_one.Appr.model.train", "enumerate", "bert_one.Appr.model.forward", "bert_one.Appr.ce", "iter_bar.set_description", "bert_one.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_one.Appr.sup_loss", "bert_one.Appr.warmup_linear", "bat.to", "bert_one.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "# Forward", "\n", "output", "=", "outputs", "[", "t", "]", "#always til", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_one.Appr.eval": [[122, 155], ["bert_one.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_one.Appr.f1_compute_fn", "input_ids.size", "bert_one.Appr.model.forward", "bert_one.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_one.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_one.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_one.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "# Forward", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_one.Appr.__init__": [[13, 20], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CONTEXTUAL + KIM ONE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_one.Appr.train": [[23, 69], ["copy.deepcopy", "utils.get_model", "bert_cnn_one.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_one.Appr.train_epoch", "time.time", "bert_cnn_one.Appr.eval", "time.time", "print", "bert_cnn_one.Appr.eval", "print", "print", "utils.get_model", "print", "print", "bert_cnn_one.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "args", ")", ":", "\n", "        ", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model: isolate", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_one.Appr.train_epoch": [[72, 103], ["bert_cnn_one.Appr.model.train", "enumerate", "bert_cnn_one.Appr.model.forward", "bert_cnn_one.Appr.ce", "iter_bar.set_description", "bert_cnn_one.Appr.optimizer.zero_grad", "bert_cnn_one.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_one.Appr.optimizer.step", "bert_cnn_one.Appr.sup_loss", "bert_cnn_one.Appr.model.parameters", "bat.to", "bert_cnn_one.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_one.Appr.eval": [[104, 136], ["bert_cnn_one.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_one.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_one.Appr.model.forward", "bert_cnn_one.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_one.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_one.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_one.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.__init__": [[19, 26], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'CNN HAL NCL'", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.train": [[29, 100], ["utils.get_model", "cnn_hal.Appr._get_optimizer", "range", "utils.set_model_", "int", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "images.to.to.to", "targets.to.to.to", "cnn_hal.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "cnn_hal.Appr.train_epoch", "time.time", "cnn_hal.Appr.eval", "time.time", "print", "cnn_hal.Appr.eval", "print", "print", "len", "cnn_hal.Appr.get_anchors", "iter", "utils.get_model", "print", "len", "print", "cnn_hal.Appr._get_optimizer", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "len", "len", "print", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.get_anchors", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "self", ".", "task_number", "=", "t", "\n", "# ring buffer mgmt (if we are not loading", "\n", "if", "self", ".", "task_number", ">", "self", ".", "buffer", ".", "task_number", ":", "\n", "            ", "self", ".", "buffer", ".", "num_seen_examples", "=", "0", "\n", "self", ".", "buffer", ".", "task_number", "=", "self", ".", "task_number", "\n", "# get anchors (provided that we are not loading the model", "\n", "", "if", "len", "(", "self", ".", "anchors", ")", "<", "self", ".", "task_number", "*", "self", ".", "args", ".", "nclasses", ":", "\n", "            ", "self", ".", "get_anchors", "(", "t", ",", "train", ")", "\n", "del", "self", ".", "phi", "\n", "\n", "\n", "", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "\n", "images", ",", "targets", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "images", "=", "images", ".", "to", "(", "self", ".", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "images", ",", "\n", "labels", "=", "targets", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", ",", "\n", "segment_ids", "=", "images", ",", "#dumy", "\n", "input_mask", "=", "images", ",", "\n", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.get_anchors": [[101, 179], ["cnn_hal.Appr.model.get_params().detach().clone", "cnn_hal.Appr.spare_model.set_params", "range", "cnn_hal.Appr.spare_model.get_params().detach().clone", "range", "cnn_hal.Appr.spare_model.zero_grad", "cnn_hal.Appr.buffer.get_data", "cnn_hal.Appr.spare_opt.zero_grad", "cnn_hal.Appr.spare_model", "cnn_hal.Appr.ce", "torch.sum.backward", "torch.sum.backward", "cnn_hal.Appr.spare_opt.step", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "print", "range", "e_t.detach.detach.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "cnn_hal.Appr.model.get_params().detach", "cnn_hal.Appr.spare_model.get_params().detach", "torch.optim.SGD.zero_grad", "torch.optim.SGD.zero_grad", "cnn_hal.Appr.spare_opt.zero_grad", "cnn_hal.Appr.spare_model.set_params", "cnn_hal.Appr.spare_model", "torch.sum.backward", "torch.sum.backward", "torch.sum.item", "torch.sum.item", "cnn_hal.Appr.spare_opt.zero_grad", "cnn_hal.Appr.spare_model.set_params", "cnn_hal.Appr.spare_model", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.backward", "torch.sum.backward", "torch.sum.item", "torch.sum.item", "cnn_hal.Appr.spare_opt.zero_grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.backward", "torch.sum.backward", "torch.sum.item", "torch.sum.item", "torch.optim.SGD.step", "torch.optim.SGD.step", "len", "cnn_hal.Appr.detach().clone", "e_t.detach.detach.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "cnn_hal.Appr.detach().clone", "e_t.detach.detach.unsqueeze", "cnn_hal.Appr.ce", "e_t.detach.detach.unsqueeze", "cnn_hal.Appr.model.get_params", "cnn_hal.Appr.spare_model.get_params", "cnn_hal.Appr.ce", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "cnn_hal.Appr.detach", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "cnn_hal.Appr.detach", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "cnn_hal.Appr.spare_model.features", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "e_t.detach.detach.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.set_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.set_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.set_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features"], ["", "def", "get_anchors", "(", "self", ",", "t", ",", "dataset", ")", ":", "\n", "        ", "theta_t", "=", "self", ".", "model", ".", "get_params", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "self", ".", "spare_model", ".", "set_params", "(", "theta_t", ")", "\n", "\n", "# fine tune on memory buffer", "\n", "for", "_", "in", "range", "(", "self", ".", "finetuning_epochs", ")", ":", "\n", "            ", "buf_inputs", ",", "buf_labels", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "inputs", "=", "buf_inputs", "\n", "labels", "=", "buf_labels", "\n", "\n", "self", ".", "spare_opt", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "self", ".", "spare_model", "(", "inputs", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "out", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "out", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "out", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "spare_opt", ".", "step", "(", ")", "\n", "\n", "", "theta_m", "=", "self", ".", "spare_model", ".", "get_params", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "classes_for_this_task", "=", "range", "(", "self", ".", "args", ".", "nclasses", ")", "#for scenrios other than DIL, you need to check he website for adaptation", "\n", "\n", "for", "a_class", "in", "classes_for_this_task", ":", "\n", "            ", "e_t", "=", "torch", ".", "rand", "(", "self", ".", "input_shape", ",", "requires_grad", "=", "True", ",", "device", "=", "self", ".", "device", ")", "\n", "e_t_opt", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "e_t", "]", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "print", "(", "file", "=", "sys", ".", "stderr", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "anchor_optimization_steps", ")", ":", "\n", "                ", "e_t_opt", ".", "zero_grad", "(", ")", "\n", "cum_loss", "=", "0", "\n", "\n", "self", ".", "spare_opt", ".", "zero_grad", "(", ")", "\n", "self", ".", "spare_model", ".", "set_params", "(", "theta_m", ".", "detach", "(", ")", ".", "clone", "(", ")", ")", "\n", "output_dict", "=", "self", ".", "spare_model", "(", "e_t", ".", "unsqueeze", "(", "0", ")", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "-", "torch", ".", "sum", "(", "self", ".", "ce", "(", "output", ",", "torch", ".", "tensor", "(", "[", "a_class", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "cum_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "self", ".", "spare_opt", ".", "zero_grad", "(", ")", "\n", "self", ".", "spare_model", ".", "set_params", "(", "theta_t", ".", "detach", "(", ")", ".", "clone", "(", ")", ")", "\n", "\n", "output_dict", "=", "self", ".", "spare_model", "(", "e_t", ".", "unsqueeze", "(", "0", ")", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "torch", ".", "sum", "(", "self", ".", "ce", "(", "output", ",", "torch", ".", "tensor", "(", "[", "a_class", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "cum_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "self", ".", "spare_opt", ".", "zero_grad", "(", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "self", ".", "args", ".", "gamma", "*", "(", "self", ".", "spare_model", ".", "features", "(", "e_t", ".", "unsqueeze", "(", "0", ")", ")", "-", "self", ".", "phi", ")", "**", "2", ")", "\n", "assert", "not", "self", ".", "phi", ".", "requires_grad", "\n", "loss", ".", "backward", "(", ")", "\n", "cum_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "e_t_opt", ".", "step", "(", ")", "\n", "\n", "", "e_t", "=", "e_t", ".", "detach", "(", ")", "\n", "e_t", ".", "requires_grad", "=", "False", "\n", "self", ".", "anchors", "=", "torch", ".", "cat", "(", "(", "self", ".", "anchors", ",", "e_t", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "del", "e_t", "\n", "print", "(", "'Total anchors:'", ",", "len", "(", "self", ".", "anchors", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "self", ".", "spare_model", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.train_epoch": [[183, 254], ["cnn_hal.Appr.model.train", "enumerate", "cnn_hal.Appr.model.get_params().detach().clone", "cnn_hal.Appr.optimizer.zero_grad", "cnn_hal.Appr.model", "cnn_hal.Appr.ce", "cnn_hal.Appr.backward", "cnn_hal.Appr.optimizer.step", "hasattr", "hasattr", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "hasattr", "print", "cnn_hal.Appr.buffer.is_empty", "cnn_hal.Appr.buffer.get_data", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "cnn_hal.Appr.model.set_params", "cnn_hal.Appr.model", "cnn_hal.Appr.backward", "cnn_hal.Appr.optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "t.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "cnn_hal.Appr.model.get_params().detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cnn_hal.Appr.model", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "cnn_hal.Appr.model.features", "cnn_hal.Appr.model.features().mean", "tuple", "images[].unsqueeze", "cnn_hal.Appr.model.get_params", "cnn_hal.Appr.model.features", "list"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.set_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.get_params", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn.Net.features"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "\n", "\n", "real_batch_size", "=", "images", ".", "shape", "[", "0", "]", "\n", "if", "not", "hasattr", "(", "self", ",", "'input_shape'", ")", ":", "\n", "                ", "self", ".", "input_shape", "=", "images", ".", "shape", "[", "1", ":", "]", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'anchors'", ")", ":", "\n", "                ", "self", ".", "anchors", "=", "torch", ".", "zeros", "(", "tuple", "(", "[", "0", "]", "+", "list", "(", "self", ".", "input_shape", ")", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'phi'", ")", ":", "\n", "                ", "print", "(", "'Building phi'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "self", ".", "phi", "=", "torch", ".", "zeros_like", "(", "self", ".", "model", ".", "features", "(", "images", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "assert", "not", "self", ".", "phi", ".", "requires_grad", "\n", "\n", "", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "# ACL does use memeory", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "images", "=", "torch", ".", "cat", "(", "(", "images", ",", "buf_inputs", ")", ")", "\n", "targets", "=", "torch", ".", "cat", "(", "(", "targets", ",", "buf_labels", ")", ")", "\n", "\n", "\n", "", "old_weights", "=", "self", ".", "model", ".", "get_params", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# print('self.anchors: ',self.anchors.size())", "\n", "# assert len(self.anchors) == self.args.nclasses #for scenrios other than DIL, you need to check he website for adaptation", "\n", "\n", "if", "len", "(", "self", ".", "anchors", ")", ">", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "output_dict", "=", "self", ".", "model", "(", "self", ".", "anchors", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "pred_anchors", "=", "output", "\n", "\n", "", "self", ".", "model", ".", "set_params", "(", "old_weights", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "self", ".", "anchors", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "pred_anchors", "-=", "output", "\n", "loss", "=", "self", ".", "args", ".", "hal_lambda", "*", "(", "pred_anchors", "**", "2", ")", ".", "mean", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "phi", "=", "self", ".", "args", ".", "beta", "*", "self", ".", "phi", "+", "(", "1", "-", "self", ".", "args", ".", "beta", ")", "*", "self", ".", "model", ".", "features", "(", "images", "[", ":", "real_batch_size", "]", ")", ".", "mean", "(", "0", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_hal.Appr.eval": [[255, 295], ["cnn_hal.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_hal.Appr.f1_compute_fn", "targets.size", "cnn_hal.Appr.model.forward", "cnn_hal.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_hal.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "cnn_hal.Appr.ent_id_detection", "cnn_hal.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_hal.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "images", ",", "targets", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "# notthing to do with id", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "if", "self", ".", "args", ".", "ent_id", ":", "#detected id", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "images", ",", "t", "=", "t", ")", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "", "else", ":", "\n", "                        ", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.__init__": [[19, 23], ["bert_cnn_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.auto_similarity": [[25, 72], ["range", "print", "numpy.savetxt", "print", "numpy.savetxt", "print", "bert_cnn_cat.Appr.model.mask", "print", "range", "gc1.detach", "gc2.detach", "gc3.detach", "gfc1.detach", "gfc2.detach", "print", "bert_cnn_cat.Appr.real_train", "bert_cnn_cat.Appr.eval_", "len", "print", "bert_cnn_cat.Appr.real_train", "bert_cnn_cat.Appr.eval_", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_"], ["", "def", "auto_similarity", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "#TODO: to detect the task similarity", "\n", "\n", "        ", "for", "pre_task", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "model", ".", "mask", "(", "pre_task", ")", "\n", "pre_mask", "=", "[", "gc1", ".", "detach", "(", ")", ",", "gc2", ".", "detach", "(", ")", ",", "gc3", ".", "detach", "(", ")", ",", "gfc1", ".", "detach", "(", ")", ",", "gfc2", ".", "detach", "(", ")", "]", "\n", "\n", "if", "pre_task", "==", "t", ":", "# the last one", "\n", "                ", "print", "(", "'>>> Now Training Phase: {:6s} <<<'", ".", "format", "(", "'reference'", ")", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'reference'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "# implemented as random mask", "\n", "", "elif", "pre_task", "!=", "t", ":", "\n", "                ", "print", "(", "'>>> Now Training Phase: {:6s} <<<'", ".", "format", "(", "'transfer'", ")", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'transfer'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "\n", "", "if", "pre_task", "==", "t", ":", "# the last one", "\n", "                ", "test_loss", ",", "test_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "phase", "=", "'reference'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "", "elif", "pre_task", "!=", "t", ":", "\n", "                ", "test_loss", ",", "test_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "phase", "=", "'transfer'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "\n", "", "self", ".", "acc_transfer", "[", "t", ",", "pre_task", "]", "=", "test_acc", "\n", "self", ".", "lss_transfer", "[", "t", ",", "pre_task", "]", "=", "test_loss", "\n", "\n", "# print('test_acc: ',self.acc_transfer[t][:t+1])", "\n", "# print('test_loss: ',self.lss_transfer[t][:t+1])", "\n", "", "print", "(", "'Save at transfer_acc'", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "args", ".", "output", "+", "'_acc_transfer'", ",", "self", ".", "acc_transfer", ",", "'%.4f'", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "similarity", "=", "[", "0", "]", "\n", "if", "t", ">", "0", ":", "\n", "            ", "acc_list", "=", "self", ".", "acc_transfer", "[", "t", "]", "[", ":", "t", "]", "#t from 0", "\n", "print", "(", "'acc_list: '", ",", "acc_list", ")", "\n", "\n", "similarity", "=", "[", "0", "if", "(", "acc_list", "[", "acc_id", "]", "<=", "self", ".", "acc_transfer", "[", "t", "]", "[", "t", "]", ")", "else", "1", "for", "acc_id", "in", "range", "(", "len", "(", "acc_list", ")", ")", "]", "# remove all acc < 0.5", "\n", "\n", "for", "source_task", "in", "range", "(", "len", "(", "similarity", ")", ")", ":", "\n", "                ", "self", ".", "similarity_transfer", "[", "t", ",", "source_task", "]", "=", "similarity", "[", "source_task", "]", "\n", "\n", "", "", "print", "(", "'Save at similarity_transfer'", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "args", ".", "output", "+", "'_similarity_transfer'", ",", "self", ".", "similarity_transfer", ",", "'%.4f'", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "print", "(", "'similarity: '", ",", "similarity", ")", "\n", "return", "similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.train": [[74, 82], ["bert_cnn_cat.Appr.auto_similarity", "bert_cnn_cat.Appr.similarities.append", "print", "print", "bert_cnn_cat.Appr.check_federated.set_similarities", "bert_cnn_cat.Appr.real_train"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.auto_similarity", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.set_similarities", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "similarity", "=", "self", ".", "auto_similarity", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", "\n", "self", ".", "similarities", ".", "append", "(", "similarity", ")", "\n", "print", "(", "'similarity: '", ",", "self", ".", "similarities", "[", "-", "1", "]", ")", "\n", "print", "(", "'similarities: '", ",", "self", ".", "similarities", ")", "\n", "\n", "self", ".", "check_federated", ".", "set_similarities", "(", "self", ".", "similarities", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.real_train": [[85, 176], ["copy.deepcopy", "utils.get_model", "print", "bert_cnn_cat.Appr._get_optimizer_cat", "utils.set_model_", "range", "torch.autograd.Variable", "bert_cnn_cat.Appr.model.mask", "range", "bert_cnn_cat.Appr.model.named_parameters", "bert_cnn_cat.Appr.history_mask_pre.append", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_cat.Appr.train_epoch", "time.time", "bert_cnn_cat.Appr.eval_", "time.time", "print", "bert_cnn_cat.Appr.eval_", "print", "print", "print", "torch.LongTensor().cuda", "len", "torch.autograd.Variable", "range", "bert_cnn_cat.Appr.model.get_view_for", "utils.get_model", "print", "mask[].data.clone", "len", "torch.max", "m.data.clone", "print", "bert_cnn_cat.Appr._get_optimizer_cat", "torch.LongTensor", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat"], ["", "def", "real_train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'mcl'", ",", "pre_task", "=", "None", ",", "pre_mask", "=", "None", ")", ":", "\n", "\n", "#TODO: before the real training, we defenitely need to first detect the task similarity", "\n", "\n", "\n", "\n", "        ", "self", ".", "model", ".", "transfer", "=", "deepcopy", "(", "self", ".", "transfer_initial_model", ")", "# Restart transfer network: isolate", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "print", "(", "'phase: '", ",", "phase", ")", "\n", "\n", "if", "phase", "==", "'mcl'", "or", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "            ", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "nepochs", "=", "self", ".", "nepochs", "\n", "\n", "\n", "", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_cat", "(", "lr", ",", "phase", ")", "\n", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", "=", "self", ".", "eval_", "(", "t", ",", "train", ",", "trained_task", "=", "t", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "trained_task", "=", "t", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_cat", "(", "lr", ",", "phase", ")", "\n", "", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best validation model", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Activations mask", "\n", "            ", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", ":", "\n", "                ", "mask", "[", "i", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", "[", "i", "]", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "t", "==", "0", ":", "\n", "                ", "self", ".", "mask_pre", "=", "mask", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mask_pre", ")", ")", ":", "\n", "                    ", "self", ".", "mask_pre", "[", "i", "]", "=", "torch", ".", "max", "(", "self", ".", "mask_pre", "[", "i", "]", ",", "mask", "[", "i", "]", ")", "\n", "\n", "# Weights mask", "\n", "", "", "self", ".", "mask_back", "=", "{", "}", "\n", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "self", ".", "mask_pre", ")", "\n", "if", "vals", "is", "not", "None", ":", "\n", "                    ", "self", ".", "mask_back", "[", "n", "]", "=", "1", "-", "vals", "\n", "\n", "#TODO: make the end function separately", "\n", "", "", "", "if", "phase", "==", "'mcl'", ":", "\n", "            ", "self", ".", "history_mask_pre", ".", "append", "(", "[", "m", ".", "data", ".", "clone", "(", ")", "for", "m", "in", "self", ".", "mask_pre", "]", ")", "\n", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.train_epoch": [[177, 274], ["bert_cnn_cat.Appr.model.train", "bert_cnn_cat.Appr.model.train", "enumerate", "bert_cnn_cat.Appr.optimizer.zero_grad", "bert_cnn_cat.Appr.backward", "torch.nn.utils.clip_grad_norm", "bert_cnn_cat.Appr.optimizer.step", "bert_cnn_cat.Appr.model", "bert_cnn_cat.Appr.model.named_parameters", "bert_cnn_cat.Appr.model.parameters", "bert_cnn_cat.Appr.model.named_parameters", "t.to", "len", "bert_cnn_cat.Appr.criterion", "bert_cnn_cat.Appr.joint_criterion", "bert_cnn_cat.Appr.model", "bert_cnn_cat.Appr.transfer_criterion", "bert_cnn_cat.Appr.model.named_parameters", "bert_cnn_cat.Appr.model.named_parameters", "n.startswith", "bert_cnn_cat.Appr.model.named_parameters", "n.startswith", "torch.clamp", "n.startswith", "bert_cnn_cat.Appr.model.Tsim_mask", "bert_cnn_cat.Appr.model.get_view_for().clone", "torch.max", "torch.cosh", "torch.cosh", "n.startswith", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "bert_cnn_cat.Appr.model.get_view_for", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "\n", "# Forward", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "s", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "outputs_attn", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "output_attn", "=", "outputs_attn", "[", "t", "]", "\n", "\n", "", "if", "output_attn", "is", "None", ":", "\n", "                    ", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ",", "masks", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "self", ".", "joint_criterion", "(", "output", ",", "targets", ",", "masks", ",", "output_attn", ")", "\n", "\n", "\n", "", "", "elif", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "\n", "                ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "s", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "transfer_criterion", "(", "output", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Restrict layer gradients in backprop", "\n", "                ", "if", "t", ">", "0", ":", "\n", "                    ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "if", "n", "in", "self", ".", "mask_back", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                            ", "Tsim_mask", "=", "self", ".", "model", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ")", "\n", "Tsim_vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "Tsim_mask", ")", ".", "clone", "(", ")", "\n", "p", ".", "grad", ".", "data", "*=", "torch", ".", "max", "(", "self", ".", "mask_back", "[", "n", "]", ",", "Tsim_vals", ")", "\n", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'mcl.e'", ")", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_cosh", ",", "self", ".", "args", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'reference'", ":", "\n", "# Compensate embedding gradients", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'transfer.e'", ")", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_cosh", ",", "self", ".", "args", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "# Apply step", "\n", "", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Constrain embeddings", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'mcl.e'", ")", ":", "\n", "                        ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_emb", ",", "self", ".", "args", ".", "thres_emb", ")", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'reference'", ":", "\n", "# Constrain embeddings", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'transfer.e'", ")", ":", "\n", "                        ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_emb", ",", "self", ".", "args", ".", "thres_emb", ")", "\n", "", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.eval_": [[278, 299], ["bert_cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["", "def", "eval_", "(", "self", ",", "t", ",", "test", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "test", ",", "trained_task", ",", "phase", ",", "pre_mask", ",", "pre_task", ")", "\n", "\n", "if", "'all-one'", "in", "self", ".", "args", ".", "similarity_detection", ":", "\n", "            ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "\n", "", "if", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "if", "total_att_acc", ">", "total_mask_acc", ":", "\n", "                ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "", "else", ":", "\n", "                ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "\n", "", "", "else", ":", "\n", "                ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.eval": [[301, 330], ["bert_cnn_cat.Appr.compute_acc", "print", "bert_cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["", "def", "eval", "(", "self", ",", "t", ",", "test", ",", "valid", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "\n", "        ", "choose_att", "=", "False", "\n", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "valid", ",", "trained_task", ",", "phase", ")", "\n", "\n", "if", "'all-one'", "in", "self", ".", "args", ".", "similarity_detection", ":", "\n", "            ", "choose_att", "=", "True", "\n", "", "elif", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "if", "total_att_acc", ">", "total_mask_acc", ":", "\n", "                ", "choose_att", "=", "True", "\n", "\n", "", "", "print", "(", "'choose_att: '", ",", "choose_att", ")", "\n", "#Here simply use validation to choose attention in testing.", "\n", "# One can also remember which tasks have used the attention in training and then apply attention for testing", "\n", "\n", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "test", ",", "trained_task", ",", "phase", ")", "\n", "\n", "if", "choose_att", "==", "True", ":", "\n", "            ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "total_f1", "=", "f1_att", "\n", "", "else", ":", "\n", "            ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "total_f1", "=", "f1_mask", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "total_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.compute_acc": [[332, 436], ["bert_cnn_cat.Appr.model.eval", "print", "torch.no_grad", "enumerate", "bert_cnn_cat.Appr.f1_compute_fn", "targets.size", "target_list.append", "len", "bert_cnn_cat.Appr.f1_compute_fn", "output_attn.max", "output.max", "pred_att_list.append", "pred_mask_list.append", "mask_hits.sum().data.cpu().numpy().item", "att_hits.sum().data.cpu().numpy().item", "output.max", "pred_mask_list.append", "hits.sum().data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "bert_cnn_cat.Appr.criterion", "bert_cnn_cat.Appr.joint_criterion", "bert_cnn_cat.Appr.model", "bert_cnn_cat.Appr.transfer_criterion", "bert_cnn_cat.Appr.data.cpu().numpy().item", "bert_cnn_cat.Appr.data.cpu().numpy().item", "bert_cnn_cat.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bert_cnn_cat.Appr.model", "bert_cnn_cat.Appr.model", "mask_hits.sum().data.cpu().numpy", "att_hits.sum().data.cpu().numpy", "hits.sum().data.cpu().numpy", "bert_cnn_cat.Appr.data.cpu().numpy", "bert_cnn_cat.Appr.data.cpu().numpy", "bert_cnn_cat.Appr.data.cpu().numpy", "mask_hits.sum().data.cpu", "att_hits.sum().data.cpu", "hits.sum().data.cpu", "bert_cnn_cat.Appr.data.cpu", "bert_cnn_cat.Appr.data.cpu", "bert_cnn_cat.Appr.data.cpu", "mask_hits.sum", "att_hits.sum", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion"], ["", "def", "compute_acc", "(", "self", ",", "t", ",", "data", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "total_att_loss", "=", "0", "\n", "total_att_acc", "=", "0", "\n", "\n", "total_mask_loss", "=", "0", "\n", "total_mask_acc", "=", "0", "\n", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_att_list", "=", "[", "]", "\n", "pred_mask_list", "=", "[", "]", "\n", "\n", "print", "(", "'phase: '", ",", "phase", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "\n", "# Forward", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "\n", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                            ", "output_dict", "=", "self", ".", "model", "(", "trained_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "\n", "\n", "", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "outputs_attn", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "output_attn", "=", "outputs_attn", "[", "t", "]", "\n", "\n", "", "if", "output_attn", "is", "None", ":", "\n", "                        ", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ",", "masks", ")", "\n", "", "else", ":", "\n", "                        ", "loss", "=", "self", ".", "joint_criterion", "(", "output", ",", "targets", ",", "masks", ",", "output_attn", ")", "\n", "\n", "", "", "elif", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "                    ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "transfer_criterion", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "# if phase=='mcl' and (similarity is not None and t<len(similarity) and np.count_nonzero(similarity[:t])>1 and similarity[t]==1):", "\n", "\n", "", "if", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", "and", "output_attn", "is", "not", "None", ":", "\n", "                    ", "_", ",", "att_pred", "=", "output_attn", ".", "max", "(", "1", ")", "\n", "_", ",", "mask_pred", "=", "output", ".", "max", "(", "1", ")", "\n", "\n", "pred_att_list", ".", "append", "(", "att_pred", ")", "\n", "pred_mask_list", ".", "append", "(", "mask_pred", ")", "\n", "\n", "mask_hits", "=", "(", "mask_pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "att_hits", "=", "(", "att_pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "# Log", "\n", "total_mask_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_mask_acc", "+=", "mask_hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Log", "\n", "total_att_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_att_acc", "+=", "att_hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "else", ":", "\n", "                    ", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "pred_mask_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_mask_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_mask_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "total_num", "+=", "real_b", "\n", "\n", "", "f1_mask", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_mask_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "if", "len", "(", "pred_att_list", ")", ">", "1", ":", "\n", "                ", "f1_att", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_att_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "", "else", ":", "\n", "                ", "f1_att", "=", "None", "\n", "", "", "return", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.transfer_criterion": [[437, 439], ["bert_cnn_cat.Appr.ce"], "methods", ["None"], ["", "def", "transfer_criterion", "(", "self", ",", "outputs", ",", "targets", ",", "mask", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.joint_criterion": [[441, 443], ["bert_cnn_cat.Appr.criterion", "bert_cnn_cat.Appr.ce"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "joint_criterion", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ",", "outputs_attn", ")", ":", "\n", "        ", "return", "self", ".", "criterion", "(", "outputs", ",", "targets", ",", "masks", ")", "+", "self", ".", "args", ".", "model_weights", "*", "self", ".", "ce", "(", "outputs_attn", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_cat.Appr.criterion": [[444, 461], ["zip", "bert_cnn_cat.Appr.ce", "aux.sum", "m.sum", "numpy.prod().item", "numpy.prod", "m.size"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "mp", "in", "zip", "(", "masks", ",", "self", ".", "mask_pre", ")", ":", "\n", "                ", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m", "in", "masks", ":", "\n", "                ", "reg", "+=", "m", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "", "", "reg", "/=", "count", "\n", "\n", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_one.Appr.__init__": [[13, 19], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'W2V ONE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_one.Appr.train": [[21, 74], ["copy.deepcopy", "utils.get_model", "w2v_one.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "w2v_one.Appr.train_epoch", "time.time", "w2v_one.Appr.eval", "time.time", "w2v_one.Appr.logger.info", "w2v_one.Appr.eval", "w2v_one.Appr.logger.info", "print", "utils.get_model", "print", "print", "w2v_one.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "deepcopy", "(", "self", ".", "initial_model", ")", "# Restart model: isolate", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_one.Appr.train_epoch": [[77, 107], ["w2v_one.Appr.model.train", "enumerate", "w2v_one.Appr.model.forward", "w2v_one.Appr.ce", "iter_bar.set_description", "w2v_one.Appr.optimizer.zero_grad", "w2v_one.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_one.Appr.optimizer.step", "w2v_one.Appr.sup_loss", "w2v_one.Appr.model.parameters", "t.to", "w2v_one.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_one.Appr.eval": [[108, 139], ["w2v_one.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_one.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_one.Appr.model.forward", "w2v_one.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_one.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "w2v_one.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_one.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Appr.__init__": [[35, 40], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Appr.train": [[43, 91], ["bert_adapter_owm.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "utils.get_model", "utils.get_model", "utils.get_model", "range", "utils.set_model_", "utils.set_model_", "utils.set_model_", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_owm.Appr.train_epoch", "time.time", "bert_adapter_owm.Appr.eval", "time.time", "print", "bert_adapter_owm.Appr.eval", "print", "print", "bert_adapter_owm.Appr.model.named_parameters", "utils.get_model", "utils.get_model", "utils.get_model", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_owm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "", "for", "adapter", "in", "adaters", ":", "\n", "            ", "for", "param", "in", "adapter", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "\n", "", "", "print", "(", "'BERT ADAPTER OWM'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict_", "=", "{", "}", "# more flexible", "\n", "\n", "output_dict", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Appr.train_epoch": [[92, 175], ["bert_adapter_owm.Appr.model.train", "enumerate", "bert_adapter_owm.Appr.model.forward", "bert_adapter_owm.Appr.ce", "optimizer.zero_grad", "bert_adapter_owm.Appr.backward", "iter_bar.set_description", "bert_adapter_owm.Appr.model.named_parameters", "optimizer.step", "optimizer.zero_grad", "x.detach.detach.detach", "p.detach.detach.detach", "range", "bert_adapter_owm.Appr.warmup_linear", "bat.to", "bert_adapter_owm.Appr.item", "int", "int", "range", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm().view_as", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "p.detach.detach.sub_", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "len", "range", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "bert_adapter_owm.Appr.train_epoch.pro_weight"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict_", "[", "'y'", "]", "=", "y", "\n", "output_dict_", "[", "'x_list'", "]", "=", "x_list", "\n", "output_dict_", "[", "'h_list'", "]", "=", "h_list", "\n", "\n", "\n", "return", "output_dict_", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_owm.Appr.eval": [[176, 210], ["bert_adapter_owm.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_adapter_owm.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_owm.Appr.model.forward", "bert_adapter_owm.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_owm.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_owm.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_owm.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ucl.Appr.__init__": [[23, 28], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", "=", "None", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'DIL CONTEXTUAL CNN UCL NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ucl.Appr.train": [[30, 96], ["utils.get_model", "bert_cnn_ucl.Appr._get_optimizer_ucl", "range", "utils.set_model_", "copy.deepcopy", "time.time", "tqdm.tqdm.tqdm", "len", "bert_cnn_ucl.Appr.train_epoch", "time.time", "bert_cnn_ucl.Appr.eval", "time.time", "print", "bert_cnn_ucl.Appr.eval", "print", "print", "utils.freeze_model", "utils.get_model", "print", "print", "bert_cnn_ucl.Appr._get_optimizer_ucl", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "lr_rho", "=", "self", ".", "lr_rho", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_ucl", "(", "lr", ",", "lr_rho", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "            ", "self", ".", "epoch", "=", "self", ".", "epoch", "+", "1", "\n", "# Train", "\n", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "\n", "num_batch", "=", "len", "(", "train", ")", "\n", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "\n", "e", "+", "1", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "num_batch", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "num_batch", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "# save log for current task & old tasks at every epoch", "\n", "# self.logger.add(epoch=(t * self.nepochs) + e, task_num=t + 1, valid_loss=valid_loss, valid_acc=valid_acc)", "\n", "\n", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "lr_rho", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_ucl", "(", "lr", ",", "lr_rho", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "saved", "=", "1", "\n", "\n", "# self.logger.save()", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ucl.Appr.train_epoch": [[97, 130], ["bert_cnn_ucl.Appr.model.train", "enumerate", "len", "bert_cnn_ucl.Appr.model.forward", "bert_cnn_ucl.Appr.ce", "bert_cnn_ucl.Appr.custom_regularization", "iter_bar.set_description", "bert_cnn_ucl.Appr.optimizer.zero_grad", "bert_cnn_ucl.Appr.backward", "bert_cnn_ucl.Appr.optimizer.step", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "bat.to", "bert_cnn_ucl.Appr.item", "bert_cnn_ucl.Appr.model.parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.custom_regularization", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward current model", "\n", "mini_batch_size", "=", "len", "(", "targets", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "sample", "=", "True", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "# if self.split:", "\n", "#     output = F.log_softmax(self.model(input_ids, segment_ids, input_mask, sample=True)[t],dim=1)", "\n", "# else:", "\n", "#     output = self.model(input_ids, segment_ids, input_mask, sample=True)", "\n", "# loss = F.nll_loss(output, targets, reduction='sum')", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "loss", "=", "self", ".", "custom_regularization", "(", "self", ".", "model_old", ",", "self", ".", "model", ",", "mini_batch_size", ",", "loss", ")", "\n", "# Backward", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'SGD'", "or", "self", ".", "args", ".", "optimizer", "==", "'SGD_momentum_decay'", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ucl.Appr.eval": [[131, 176], ["bert_cnn_ucl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_cnn_ucl.Appr.f1_compute_fn", "input_ids.size", "len", "bert_cnn_ucl.Appr.model.forward", "bert_cnn_ucl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_ucl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_ucl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_ucl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "# Forward", "\n", "mini_batch_size", "=", "len", "(", "targets", ")", "\n", "# if self.split:", "\n", "#     output = F.log_softmax(self.model( input_ids, segment_ids, input_mask, sample=False)[t],dim=1)", "\n", "# else:", "\n", "#     output = self.model( input_ids, segment_ids, input_mask, sample=False)", "\n", "# loss = F.nll_loss(output, targets, reduction='sum')", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "sample", "=", "False", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_ucl.Appr.custom_regularization": [[180, 274], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "zip", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "saver_net.named_children", "trainer_net.named_children", "bayes_layer._calculate_fan_in_and_fan_out", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "isinstance", "isinstance", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "math.sqrt", "math.sqrt", "len", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "isinstance", "isinstance", "len", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.expand", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.permute", "prev_weight_strength.reshape.reshape.permute", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], ["", "def", "custom_regularization", "(", "self", ",", "saver_net", ",", "trainer_net", ",", "mini_batch_size", ",", "loss", "=", "None", ")", ":", "\n", "\n", "        ", "sigma_weight_reg_sum", "=", "0", "\n", "sigma_bias_reg_sum", "=", "0", "\n", "sigma_weight_normal_reg_sum", "=", "0", "\n", "sigma_bias_normal_reg_sum", "=", "0", "\n", "mu_weight_reg_sum", "=", "0", "\n", "mu_bias_reg_sum", "=", "0", "\n", "L1_mu_weight_reg_sum", "=", "0", "\n", "L1_mu_bias_reg_sum", "=", "0", "\n", "\n", "out_features_max", "=", "512", "\n", "alpha", "=", "self", ".", "args", ".", "alpha", "\n", "if", "self", ".", "saved", ":", "\n", "            ", "alpha", "=", "1", "\n", "\n", "", "prev_weight_strength", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "1", ",", "1", ",", "1", ")", ".", "uniform_", "(", "0", ",", "0", ")", ")", "\n", "\n", "\n", "for", "(", "_", ",", "saver_layer", ")", ",", "(", "_", ",", "trainer_layer", ")", "in", "zip", "(", "saver_net", ".", "named_children", "(", ")", ",", "trainer_net", ".", "named_children", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "trainer_layer", ",", "BayesianLinear", ")", "==", "False", "and", "isinstance", "(", "trainer_layer", ",", "BayesianConv2D", ")", "==", "False", ":", "\n", "                ", "continue", "\n", "# calculate mu regularization", "\n", "", "trainer_weight_mu", "=", "trainer_layer", ".", "weight_mu", "\n", "saver_weight_mu", "=", "saver_layer", ".", "weight_mu", "\n", "trainer_bias", "=", "trainer_layer", ".", "bias", "\n", "saver_bias", "=", "saver_layer", ".", "bias", "\n", "\n", "fan_in", ",", "fan_out", "=", "_calculate_fan_in_and_fan_out", "(", "trainer_weight_mu", ")", "\n", "\n", "trainer_weight_sigma", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "trainer_layer", ".", "weight_rho", ")", ")", "\n", "saver_weight_sigma", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "saver_layer", ".", "weight_rho", ")", ")", "\n", "\n", "if", "isinstance", "(", "trainer_layer", ",", "BayesianLinear", ")", ":", "\n", "                ", "std_init", "=", "math", ".", "sqrt", "(", "(", "2", "/", "fan_in", ")", "*", "self", ".", "args", ".", "ratio", ")", "\n", "", "if", "isinstance", "(", "trainer_layer", ",", "BayesianConv2D", ")", ":", "\n", "                ", "std_init", "=", "math", ".", "sqrt", "(", "(", "2", "/", "fan_out", ")", "*", "self", ".", "args", ".", "ratio", ")", "\n", "\n", "", "saver_weight_strength", "=", "(", "std_init", "/", "saver_weight_sigma", ")", "\n", "\n", "if", "len", "(", "saver_weight_mu", ".", "shape", ")", "==", "4", ":", "\n", "                ", "out_features", ",", "in_features", ",", "_", ",", "_", "=", "saver_weight_mu", ".", "shape", "\n", "curr_strength", "=", "saver_weight_strength", ".", "expand", "(", "out_features", ",", "in_features", ",", "1", ",", "1", ")", "\n", "prev_strength", "=", "prev_weight_strength", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "expand", "(", "out_features", ",", "in_features", ",", "1", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "out_features", ",", "in_features", "=", "saver_weight_mu", ".", "shape", "\n", "curr_strength", "=", "saver_weight_strength", ".", "expand", "(", "out_features", ",", "in_features", ")", "\n", "if", "len", "(", "prev_weight_strength", ".", "shape", ")", "==", "4", ":", "\n", "                    ", "feature_size", "=", "in_features", "//", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "reshape", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "expand", "(", "prev_weight_strength", ".", "shape", "[", "0", "]", ",", "feature_size", ")", "\n", "prev_weight_strength", "=", "prev_weight_strength", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "prev_strength", "=", "prev_weight_strength", ".", "permute", "(", "1", ",", "0", ")", ".", "expand", "(", "out_features", ",", "in_features", ")", "\n", "\n", "", "L2_strength", "=", "torch", ".", "max", "(", "curr_strength", ",", "prev_strength", ")", "\n", "bias_strength", "=", "torch", ".", "squeeze", "(", "saver_weight_strength", ")", "\n", "\n", "L1_sigma", "=", "saver_weight_sigma", "\n", "bias_sigma", "=", "torch", ".", "squeeze", "(", "saver_weight_sigma", ")", "\n", "\n", "prev_weight_strength", "=", "saver_weight_strength", "\n", "\n", "mu_weight_reg", "=", "(", "L2_strength", "*", "(", "trainer_weight_mu", "-", "saver_weight_mu", ")", ")", ".", "norm", "(", "2", ")", "**", "2", "\n", "mu_bias_reg", "=", "(", "bias_strength", "*", "(", "trainer_bias", "-", "saver_bias", ")", ")", ".", "norm", "(", "2", ")", "**", "2", "\n", "\n", "L1_mu_weight_reg", "=", "(", "torch", ".", "div", "(", "saver_weight_mu", "**", "2", ",", "L1_sigma", "**", "2", ")", "*", "(", "trainer_weight_mu", "-", "saver_weight_mu", ")", ")", ".", "norm", "(", "1", ")", "\n", "L1_mu_bias_reg", "=", "(", "torch", ".", "div", "(", "saver_bias", "**", "2", ",", "bias_sigma", "**", "2", ")", "*", "(", "trainer_bias", "-", "saver_bias", ")", ")", ".", "norm", "(", "1", ")", "\n", "\n", "L1_mu_weight_reg", "=", "L1_mu_weight_reg", "*", "(", "std_init", "**", "2", ")", "\n", "L1_mu_bias_reg", "=", "L1_mu_bias_reg", "*", "(", "std_init", "**", "2", ")", "\n", "\n", "weight_sigma", "=", "(", "trainer_weight_sigma", "**", "2", "/", "saver_weight_sigma", "**", "2", ")", "\n", "\n", "normal_weight_sigma", "=", "trainer_weight_sigma", "**", "2", "\n", "\n", "sigma_weight_reg_sum", "=", "sigma_weight_reg_sum", "+", "(", "weight_sigma", "-", "torch", ".", "log", "(", "weight_sigma", ")", ")", ".", "sum", "(", ")", "\n", "sigma_weight_normal_reg_sum", "=", "sigma_weight_normal_reg_sum", "+", "(", "normal_weight_sigma", "-", "torch", ".", "log", "(", "normal_weight_sigma", ")", ")", ".", "sum", "(", ")", "\n", "\n", "mu_weight_reg_sum", "=", "mu_weight_reg_sum", "+", "mu_weight_reg", "\n", "mu_bias_reg_sum", "=", "mu_bias_reg_sum", "+", "mu_bias_reg", "\n", "L1_mu_weight_reg_sum", "=", "L1_mu_weight_reg_sum", "+", "L1_mu_weight_reg", "\n", "L1_mu_bias_reg_sum", "=", "L1_mu_bias_reg_sum", "+", "L1_mu_bias_reg", "\n", "\n", "# elbo loss", "\n", "", "loss", "=", "loss", "/", "mini_batch_size", "\n", "# L2 loss", "\n", "loss", "=", "loss", "+", "alpha", "*", "(", "mu_weight_reg_sum", "+", "mu_bias_reg_sum", ")", "/", "(", "2", "*", "mini_batch_size", ")", "\n", "# L1 loss", "\n", "loss", "=", "loss", "+", "self", ".", "saved", "*", "(", "L1_mu_weight_reg_sum", "+", "L1_mu_bias_reg_sum", ")", "/", "(", "mini_batch_size", ")", "\n", "# sigma regularization", "\n", "loss", "=", "loss", "+", "self", ".", "beta", "*", "(", "sigma_weight_reg_sum", "+", "sigma_weight_normal_reg_sum", ")", "/", "(", "2", "*", "mini_batch_size", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ewc.Appr.__init__": [[31, 36], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'BERT ADAPTER EWC NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ewc.Appr.train": [[37, 109], ["bert_adapter_ewc.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "copy.deepcopy", "bert_adapter_ewc.Appr.model_old.eval", "utils.freeze_model", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_ewc.Appr.train_epoch", "time.time", "bert_adapter_ewc.Appr.eval", "time.time", "print", "print", "bert_adapter_ewc.Appr.eval", "print", "print", "bert_adapter_ewc.Appr.model.named_parameters", "utils.fisher_matrix_diag_bert_dil", "bert_adapter_ewc.Appr.model.named_parameters", "bert_adapter_ewc.Appr.model.named_parameters", "float", "utils.get_model", "print", "bert_adapter_ewc.Appr.fisher[].clone", "utils.fisher_matrix_diag_bert", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert_dil", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_bert"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "10", "*", "25", ")", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, f1_avg={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "# Fisher ops", "\n", "if", "t", ">", "0", ":", "\n", "            ", "fisher_old", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "fisher_old", "[", "n", "]", "=", "self", ".", "fisher", "[", "n", "]", ".", "clone", "(", ")", "\n", "\n", "", "", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_bert_dil", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_bert", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion", ")", "\n", "\n", "", "if", "t", ">", "0", ":", "\n", "# Watch out! We do not want to keep t models (or fisher diagonals) in memory, therefore we have to merge fisher diagonals", "\n", "            ", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "fisher", "[", "n", "]", "=", "(", "self", ".", "fisher", "[", "n", "]", "+", "fisher_old", "[", "n", "]", "*", "t", ")", "/", "(", "t", "+", "1", ")", "# Checked: it is better than the other option", "\n", "#self.fisher[n]=0.5*(self.fisher[n]+fisher_old[n])", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ewc.Appr.train_epoch": [[110, 140], ["bert_adapter_ewc.Appr.model.train", "enumerate", "bert_adapter_ewc.Appr.model.forward", "bert_adapter_ewc.Appr.criterion", "iter_bar.set_description", "bert_adapter_ewc.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_ewc.Appr.warmup_linear", "bat.to", "bert_adapter_ewc.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "num_labels", "=", "self", ".", "taskcla", "[", "t", "]", "[", "1", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion", "(", "t", ",", "output", ",", "targets", ")", "\n", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ewc.Appr.eval": [[141, 183], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_ewc.Appr.model.eval", "enumerate", "bert_adapter_ewc.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_ewc.Appr.model.forward", "bert_adapter_ewc.Appr.criterion", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_ewc.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_ewc.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_ewc.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion", "(", "t", ",", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "# break", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.__init__": [[16, 23], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'CONTEXTUAL CNN EWC NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.train": [[26, 97], ["utils.get_model", "bert_cnn_gem.Appr._get_optimizer", "range", "utils.set_model_", "copy.deepcopy", "bert_cnn_gem.Appr.model_old.eval", "utils.freeze_model", "bert_cnn_gem.Appr.grads_cs.append", "print", "int", "print", "torch.utils.data.DataLoader", "next", "bert_cnn_gem.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_gem.Appr.train_epoch", "time.time", "bert_cnn_gem.Appr.eval", "time.time", "print", "bert_cnn_gem.Appr.eval", "print", "print", "torch.zeros().to", "len", "iter", "utils.get_model", "print", "len", "input_ids.to", "segment_ids.to", "input_mask.to", "targets.to", "print", "bert_cnn_gem.Appr._get_optimizer", "torch.zeros", "torch.ones().to", "len", "len", "print", "numpy.sum", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "self", ".", "grads_cs", ".", "append", "(", "torch", ".", "zeros", "(", "\n", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "labels", "=", "targets", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", "\n", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.train_epoch": [[98, 163], ["bert_cnn_gem.Appr.model.train", "enumerate", "bert_cnn_gem.Appr.optimizer.zero_grad", "bert_cnn_gem.Appr.model.forward", "bert_cnn_gem.Appr.ce", "iter_bar.set_description", "bert_cnn_gem.Appr.backward", "bert_cnn_gem.Appr.optimizer.step", "bert_cnn_gem.Appr.buffer.is_empty", "bert_cnn_gem.Appr.buffer.get_data", "buf_task_labels.unique", "bert_cnn_gem.Appr.buffer.is_empty", "bert_cnn_gem.Appr.store_grad", "torch.mm", "bat.to", "bert_cnn_gem.Appr.optimizer.zero_grad", "buf_inputs[].long", "buf_segment_ids[].long", "buf_input_mask[].long", "buf_labels[].long", "bert_cnn_gem.Appr.model.forward", "bert_cnn_gem.Appr.ce", "bert_cnn_gem.Appr.backward", "bert_cnn_gem.Appr.store_grad", "bert_cnn_gem.Appr.item", "bert_cnn_gem.Appr.grads_da.unsqueeze", "bert_cnn_gem.Appr.project2cone2", "bert_cnn_gem.Appr.overwrite_grad", "torch.stack", "bert_cnn_gem.Appr.grads_da.unsqueeze", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.project2cone2", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.overwrite_grad"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "# Forward current model", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "# print('buf_segment_ids: ',buf_segment_ids.size())", "\n", "# print('buf_input_mask: ',buf_input_mask.size())", "\n", "\n", "for", "tt", "in", "buf_task_labels", ".", "unique", "(", ")", ":", "\n", "# compute gradient on the memory buffer", "\n", "                    ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "cur_task_inputs", "=", "buf_inputs", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_segment", "=", "buf_segment_ids", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_mask", "=", "buf_input_mask", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_labels", "=", "buf_labels", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "cur_task_inputs", ",", "cur_task_segment", ",", "cur_task_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "tt", "]", "\n", "", "penalty", "=", "self", ".", "ce", "(", "cur_task_output", ",", "cur_task_labels", ")", "\n", "penalty", ".", "backward", "(", ")", "\n", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_cs", "[", "tt", "]", ",", "self", ".", "grad_dims", ")", "\n", "\n", "# now compute the grad on the current data", "\n", "", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm(self.model.parameters(),self.clipgrad)", "\n", "\n", "# check if gradient violates buffer constraints", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "# copy gradient", "\n", "                ", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_da", ",", "self", ".", "grad_dims", ")", "\n", "\n", "dot_prod", "=", "torch", ".", "mm", "(", "self", ".", "grads_da", ".", "unsqueeze", "(", "0", ")", ",", "\n", "torch", ".", "stack", "(", "self", ".", "grads_cs", ")", ".", "T", ")", "\n", "if", "(", "dot_prod", "<", "0", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "                    ", "self", ".", "project2cone2", "(", "self", ".", "grads_da", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "stack", "(", "self", ".", "grads_cs", ")", ".", "T", ",", "margin", "=", "self", ".", "args", ".", "gamma", ")", "\n", "# copy gradients back", "\n", "self", ".", "overwrite_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_da", ",", "\n", "self", ".", "grad_dims", ")", "\n", "\n", "# Backward", "\n", "", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.eval": [[164, 202], ["bert_cnn_gem.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_gem.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_gem.Appr.model.forward", "bert_cnn_gem.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_gem.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_gem.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_gem.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.store_grad": [[206, 222], ["grads.fill_", "params", "numpy.sum", "grads[].copy_", "sum", "param.grad.data.view"], "methods", ["None"], ["", "def", "store_grad", "(", "self", ",", "params", ",", "grads", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This stores parameter gradients of past tasks.\n            pp: parameters\n            grads: gradients\n            grad_dims: list with number of parameters per layers\n        \"\"\"", "\n", "# store the gradients", "\n", "grads", ".", "fill_", "(", "0.0", ")", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "np", ".", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "grads", "[", "begin", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.overwrite_grad": [[224, 241], ["params", "sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "methods", ["None"], ["", "", "def", "overwrite_grad", "(", "self", ",", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This is used to overwrite the gradients with a new gradient\n            vector, whenever violations occur.\n            pp: parameters\n            newgrad: corrected gradient\n            grad_dims: list storing number of parameters at each layer\n        \"\"\"", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "begin", ":", "end", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_gem.Appr.project2cone2": [[243, 263], ["memories.cpu().t().double().numpy", "gradient.cpu().contiguous().view().double().numpy", "numpy.dot", "numpy.eye", "gradient.copy_", "memories.cpu().t().double().numpy.transpose", "numpy.dot", "numpy.zeros", "quadprog.solve_qp", "numpy.dot", "torch.from_numpy().view", "memories.cpu().t().double", "gradient.cpu().contiguous().view().double", "numpy.eye", "numpy.dot.transpose", "torch.from_numpy", "memories.cpu().t", "gradient.cpu().contiguous().view", "memories.cpu", "gradient.cpu().contiguous", "gradient.cpu"], "methods", ["None"], ["", "", "def", "project2cone2", "(", "self", ",", "gradient", ",", "memories", ",", "margin", "=", "0.5", ",", "eps", "=", "1e-3", ")", ":", "\n", "        ", "\"\"\"\n            Solves the GEM dual QP described in the paper given a proposed\n            gradient \"gradient\", and a memory of task gradients \"memories\".\n            Overwrites \"gradient\" with the final projected update.\n            input:  gradient, p-vector\n            input:  memories, (t * p)-vector\n            output: x, p-vector\n        \"\"\"", "\n", "memories_np", "=", "memories", ".", "cpu", "(", ")", ".", "t", "(", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "gradient_np", "=", "gradient", ".", "cpu", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "n_rows", "=", "memories_np", ".", "shape", "[", "0", "]", "\n", "self_prod", "=", "np", ".", "dot", "(", "memories_np", ",", "memories_np", ".", "transpose", "(", ")", ")", "\n", "self_prod", "=", "0.5", "*", "(", "self_prod", "+", "self_prod", ".", "transpose", "(", ")", ")", "+", "np", ".", "eye", "(", "n_rows", ")", "*", "eps", "\n", "grad_prod", "=", "np", ".", "dot", "(", "memories_np", ",", "gradient_np", ")", "*", "-", "1", "\n", "G", "=", "np", ".", "eye", "(", "n_rows", ")", "\n", "h", "=", "np", ".", "zeros", "(", "n_rows", ")", "+", "margin", "\n", "v", "=", "quadprog", ".", "solve_qp", "(", "self_prod", ",", "grad_prod", ",", "G", ",", "h", ")", "[", "0", "]", "\n", "x", "=", "np", ".", "dot", "(", "v", ",", "memories_np", ")", "+", "gradient_np", "\n", "gradient", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_agem.Appr.__init__": [[16, 23], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'CONTEXTUAL CNN AGEM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_agem.Appr.train": [[26, 91], ["utils.get_model", "bert_cnn_agem.Appr._get_optimizer", "range", "utils.set_model_", "print", "int", "print", "torch.utils.data.DataLoader", "next", "bert_cnn_agem.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "bert_cnn_agem.Appr.train_epoch", "time.time", "bert_cnn_agem.Appr.eval", "time.time", "print", "bert_cnn_agem.Appr.eval", "print", "print", "len", "iter", "utils.get_model", "print", "len", "input_ids.to", "segment_ids.to", "input_mask.to", "targets.to", "print", "bert_cnn_agem.Appr._get_optimizer", "torch.ones().to", "len", "len", "print", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Update old", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "labels", "=", "targets", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", "\n", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_agem.Appr.train_epoch": [[92, 153], ["bert_cnn_agem.Appr.model.train", "enumerate", "bert_cnn_agem.Appr.optimizer.zero_grad", "bert_cnn_agem.Appr.model.forward", "bert_cnn_agem.Appr.ce", "bert_cnn_agem.Appr.backward", "iter_bar.set_description", "torch.nn.utils.clip_grad_norm", "bert_cnn_agem.Appr.optimizer.step", "bert_cnn_agem.Appr.buffer.is_empty", "bert_cnn_agem.Appr.store_grad", "bert_cnn_agem.Appr.buffer.get_data", "bert_cnn_agem.Appr.model.zero_grad", "buf_inputs.long.long.long", "buf_segment_ids.long", "buf_input_mask.long", "buf_labels.long.long.long", "bert_cnn_agem.Appr.model.forward", "bert_cnn_agem.Appr.ce", "bert_cnn_agem.Appr.backward", "bert_cnn_agem.Appr.store_grad", "torch.dot", "bert_cnn_agem.Appr.model.parameters", "bat.to", "torch.dot.item", "bert_cnn_agem.Appr.project", "bert_cnn_agem.Appr.overwrite_grad", "bert_cnn_agem.Appr.overwrite_grad", "bert_cnn_agem.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.project", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.overwrite_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.overwrite_grad"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "\n", "# now compute the grad on the current data", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "#backward first", "\n", "\n", "\n", "# Forward current model", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grad_xy", ",", "self", ".", "grad_dims", ")", "\n", "buf_inputs", ",", "buf_labels", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "buf_inputs", "=", "buf_inputs", ".", "long", "(", ")", "\n", "buf_segment", "=", "buf_segment_ids", ".", "long", "(", ")", "\n", "buf_mask", "=", "buf_input_mask", ".", "long", "(", ")", "\n", "buf_labels", "=", "buf_labels", ".", "long", "(", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "buf_inputs", ",", "buf_segment", ",", "buf_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "cur_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "penalty", "=", "self", ".", "ce", "(", "cur_output", ",", "buf_labels", ")", "\n", "penalty", ".", "backward", "(", ")", "\n", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grad_er", ",", "self", ".", "grad_dims", ")", "\n", "\n", "dot_prod", "=", "torch", ".", "dot", "(", "self", ".", "grad_xy", ",", "self", ".", "grad_er", ")", "\n", "if", "dot_prod", ".", "item", "(", ")", "<", "0", ":", "\n", "                    ", "g_tilde", "=", "self", ".", "project", "(", "gxy", "=", "self", ".", "grad_xy", ",", "ger", "=", "self", ".", "grad_er", ")", "\n", "self", ".", "overwrite_grad", "(", "self", ".", "model", ".", "parameters", ",", "g_tilde", ",", "self", ".", "grad_dims", ")", "\n", "", "else", ":", "\n", "                     ", "self", ".", "overwrite_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grad_xy", ",", "self", ".", "grad_dims", ")", "\n", "\n", "\n", "\n", "\n", "", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_cnn_agem.Appr.eval": [[154, 192], ["bert_cnn_agem.Appr.model.eval", "torch.no_grad", "enumerate", "bert_cnn_agem.Appr.f1_compute_fn", "input_ids.size", "bert_cnn_agem.Appr.model.forward", "bert_cnn_agem.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_cnn_agem.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_cnn_agem.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_cnn_agem.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_srk.Appr.__init__": [[27, 33], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'W2V + RNN SRK NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_srk.Appr._get_optimizer": [[34, 42], ["print", "torch.optim.SGD", "w2v_rnn_srk.Appr.model.parameters", "print", "torch.optim.Adam", "w2v_rnn_srk.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "print", "(", "'sgd'", ")", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "            ", "print", "(", "'adam'", ")", "\n", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_srk.Appr.train": [[43, 88], ["utils.get_model", "w2v_rnn_srk.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "w2v_rnn_srk.Appr.train_epoch", "time.time", "w2v_rnn_srk.Appr.eval", "time.time", "print", "w2v_rnn_srk.Appr.eval", "print", "print", "utils.get_model", "print", "print", "w2v_rnn_srk.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_srk.Appr.train_epoch": [[91, 165], ["w2v_rnn_srk.Appr.model.train", "enumerate", "torch.autograd.Variable", "w2v_rnn_srk.Appr.model.forward", "iter_bar.set_description", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "w2v_rnn_srk.Appr.optimizer.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm", "w2v_rnn_srk.Appr.optimizer.step", "torch.LongTensor().cuda", "w2v_rnn_srk.Appr.ce", "control_1.sum", "control_2.sum", "control_3.sum", "w2v_rnn_srk.Appr.model.named_parameters", "w2v_rnn_srk.Appr.model.parameters", "bat.to", "math.exp", "w2v_rnn_srk.Appr.ce", "w2v_rnn_srk.Appr.ce", "loss.item", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.LongTensor", "int", "int", "int", "w2v_rnn_srk.Appr.model.get_view_for", "w2v_rnn_srk.Appr.control_1_s.size", "w2v_rnn_srk.Appr.control_2_s.size", "w2v_rnn_srk.Appr.control_3_s.size", "w2v_rnn_srk.Appr.control_1_s.size", "w2v_rnn_srk.Appr.control_2_s.size", "w2v_rnn_srk.Appr.control_3_s.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "s", "=", "(", "1", "-", "0.1", ")", "*", "math", ".", "exp", "(", "-", "0.1", "*", "t", ")", "+", "0.1", "\n", "# print('s: ',s) samller than 1", "\n", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "# Forward", "\n", "# outputs,fln_outputs,krn_outputs,krn_hidden=self.model.forward(task,input_ids, segment_ids, input_mask)", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "control_1", "=", "output_dict", "[", "'control_1'", "]", "\n", "control_2", "=", "output_dict", "[", "'control_2'", "]", "\n", "control_3", "=", "output_dict", "[", "'control_3'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "fln_output", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_output", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "fln_outputs", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_outputs", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "fln_output", "=", "fln_outputs", "[", "t", "]", "\n", "krn_output", "=", "krn_outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "ce", "(", "fln_output", ",", "targets", ")", "+", "self", ".", "ce", "(", "krn_output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "control_1_s", "+=", "torch", ".", "abs", "(", "control_1", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_1_s", "=", "(", "self", ".", "control_1_s", "-", "torch", ".", "min", "(", "self", ".", "control_1_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_1_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_1_s", ")", ")", "\n", "control_1_sorted", ",", "control_1_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_1_s", ")", "\n", "\n", "control_1_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_1_s", ")", ".", "cuda", "(", ")", "\n", "control_1_mask", "[", ":", "int", "(", "self", ".", "control_1_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_1_sorted", "[", ":", "int", "(", "self", ".", "control_1_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "self", ".", "control_2_s", "+=", "torch", ".", "abs", "(", "control_2", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_2_s", "=", "(", "self", ".", "control_2_s", "-", "torch", ".", "min", "(", "self", ".", "control_2_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_2_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_2_s", ")", ")", "\n", "control_2_sorted", ",", "control_2_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_2_s", ")", "\n", "\n", "control_2_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_2_s", ")", ".", "cuda", "(", ")", "\n", "control_2_mask", "[", ":", "int", "(", "self", ".", "control_2_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_2_sorted", "[", ":", "int", "(", "self", ".", "control_2_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "self", ".", "control_3_s", "+=", "torch", ".", "abs", "(", "control_3", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_3_s", "=", "(", "self", ".", "control_3_s", "-", "torch", ".", "min", "(", "self", ".", "control_3_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_3_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_3_s", ")", ")", "\n", "control_3_sorted", ",", "control_3_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_3_s", ")", "\n", "\n", "control_3_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_3_s", ")", ".", "cuda", "(", ")", "\n", "control_3_mask", "[", ":", "int", "(", "self", ".", "control_3_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_3_sorted", "[", ":", "int", "(", "self", ".", "control_3_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "t", ">", "0", ":", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "rnn_weights", ":", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", ")", "\n", "\n", "\n", "\n", "", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_rnn_srk.Appr.eval": [[166, 215], ["w2v_rnn_srk.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_rnn_srk.Appr.f1_compute_fn", "tokens_term_ids.size", "torch.autograd.Variable", "w2v_rnn_srk.Appr.model.forward", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "torch.LongTensor().cuda", "w2v_rnn_srk.Appr.ce", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "w2v_rnn_srk.Appr.ce", "w2v_rnn_srk.Appr.ce", "hits.sum().data.cpu().numpy", "torch.LongTensor", "loss.data.cpu().numpy", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "# outputs,fln_outputs,krn_outputs,krn_hidden = self.model.forward(task,input_ids, segment_ids, input_mask)", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "fln_output", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_output", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "fln_outputs", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_outputs", "=", "output_dict", "[", "'krn_y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "fln_output", "=", "fln_outputs", "[", "t", "]", "\n", "krn_output", "=", "krn_outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "ce", "(", "fln_output", ",", "targets", ")", "+", "self", ".", "ce", "(", "krn_output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_srk.Appr.__init__": [[27, 35], ["bert_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "logger", "=", "None", ",", "taskcla", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'CONTEXTUAL + RNN SRK NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_srk.Appr.train": [[36, 83], ["utils.get_model", "bert_rnn_srk.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "bert_rnn_srk.Appr.train_epoch", "time.time", "bert_rnn_srk.Appr.eval", "time.time", "print", "print", "bert_rnn_srk.Appr.eval", "print", "print", "float", "utils.get_model", "print", "print", "bert_rnn_srk.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "args", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_srk.Appr.train_epoch": [[86, 162], ["bert_rnn_srk.Appr.model.train", "enumerate", "torch.autograd.Variable", "bert_rnn_srk.Appr.model.forward", "iter_bar.set_description", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "torch.abs", "torch.sort", "torch.zeros_like().cuda", "bert_rnn_srk.Appr.optimizer.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm", "bert_rnn_srk.Appr.optimizer.step", "torch.LongTensor().cuda", "bert_rnn_srk.Appr.ce", "control_1.sum", "control_2.sum", "control_3.sum", "bert_rnn_srk.Appr.model.named_parameters", "bert_rnn_srk.Appr.model.parameters", "bat.to", "math.exp", "bert_rnn_srk.Appr.ce", "bert_rnn_srk.Appr.ce", "loss.item", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.min", "torch.max", "torch.min", "torch.zeros_like", "int", "torch.LongTensor", "int", "int", "int", "bert_rnn_srk.Appr.model.get_view_for", "bert_rnn_srk.Appr.control_1_s.size", "bert_rnn_srk.Appr.control_2_s.size", "bert_rnn_srk.Appr.control_3_s.size", "bert_rnn_srk.Appr.control_1_s.size", "bert_rnn_srk.Appr.control_2_s.size", "bert_rnn_srk.Appr.control_3_s.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "s", "=", "(", "1", "-", "0.1", ")", "*", "math", ".", "exp", "(", "-", "0.1", "*", "t", ")", "+", "0.1", "\n", "# print('s: ',s) samller than 1", "\n", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "# Forward", "\n", "# outputs,fln_outputs,krn_outputs,krn_hidden=self.model.forward(task,input_ids, segment_ids, input_mask)", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "control_1", "=", "output_dict", "[", "'control_1'", "]", "\n", "control_2", "=", "output_dict", "[", "'control_2'", "]", "\n", "control_3", "=", "output_dict", "[", "'control_3'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "fln_output", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_output", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "fln_outputs", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_outputs", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "fln_output", "=", "fln_outputs", "[", "t", "]", "\n", "krn_output", "=", "krn_outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "ce", "(", "fln_output", ",", "targets", ")", "+", "self", ".", "ce", "(", "krn_output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "control_1_s", "+=", "torch", ".", "abs", "(", "control_1", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_1_s", "=", "(", "self", ".", "control_1_s", "-", "torch", ".", "min", "(", "self", ".", "control_1_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_1_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_1_s", ")", ")", "\n", "control_1_sorted", ",", "control_1_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_1_s", ")", "\n", "\n", "control_1_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_1_s", ")", ".", "cuda", "(", ")", "\n", "control_1_mask", "[", ":", "int", "(", "self", ".", "control_1_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_1_sorted", "[", ":", "int", "(", "self", ".", "control_1_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "self", ".", "control_2_s", "+=", "torch", ".", "abs", "(", "control_2", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_2_s", "=", "(", "self", ".", "control_2_s", "-", "torch", ".", "min", "(", "self", ".", "control_2_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_2_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_2_s", ")", ")", "\n", "control_2_sorted", ",", "control_2_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_2_s", ")", "\n", "\n", "control_2_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_2_s", ")", ".", "cuda", "(", ")", "\n", "control_2_mask", "[", ":", "int", "(", "self", ".", "control_2_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_2_sorted", "[", ":", "int", "(", "self", ".", "control_2_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "self", ".", "control_3_s", "+=", "torch", ".", "abs", "(", "control_3", ".", "sum", "(", "0", ")", ")", "\n", "self", ".", "control_3_s", "=", "(", "self", ".", "control_3_s", "-", "torch", ".", "min", "(", "self", ".", "control_3_s", ")", ")", "/", "(", "torch", ".", "max", "(", "self", ".", "control_3_s", ")", "-", "torch", ".", "min", "(", "self", ".", "control_3_s", ")", ")", "\n", "control_3_sorted", ",", "control_3_indices", "=", "torch", ".", "sort", "(", "self", ".", "control_3_s", ")", "\n", "\n", "control_3_mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "control_3_s", ")", ".", "cuda", "(", ")", "\n", "control_3_mask", "[", ":", "int", "(", "self", ".", "control_3_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "=", "1", "-", "control_3_sorted", "[", ":", "int", "(", "self", ".", "control_3_s", ".", "size", "(", "-", "1", ")", "*", "s", ")", "]", "\n", "\n", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "t", ">", "0", ":", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "rnn_weights", ":", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "control_1_mask", ",", "control_2_mask", ",", "control_3_mask", ")", "\n", "\n", "\n", "\n", "", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_rnn_srk.Appr.eval": [[163, 212], ["bert_rnn_srk.Appr.model.eval", "torch.no_grad", "enumerate", "bert_rnn_srk.Appr.f1_compute_fn", "input_ids.size", "torch.autograd.Variable", "bert_rnn_srk.Appr.model.forward", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "torch.LongTensor().cuda", "bert_rnn_srk.Appr.ce", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "bat.to", "bert_rnn_srk.Appr.ce", "bert_rnn_srk.Appr.ce", "hits.sum().data.cpu().numpy", "torch.LongTensor", "loss.data.cpu().numpy", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "# outputs,fln_outputs,krn_outputs,krn_hidden = self.model.forward(task,input_ids, segment_ids, input_mask)", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "fln_output", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_output", "=", "output_dict", "[", "'krn_y'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "fln_outputs", "=", "output_dict", "[", "'fln_y'", "]", "\n", "krn_outputs", "=", "output_dict", "[", "'krn_y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "fln_output", "=", "fln_outputs", "[", "t", "]", "\n", "krn_output", "=", "krn_outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "ce", "(", "fln_output", ",", "targets", ")", "+", "self", ".", "ce", "(", "krn_output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Appr.__init__": [[27, 32], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["\n", "#But adapter is open", "\n", "\n", "#Only adapters are trainable", "\n", "\n", "", "if", "args", ".", "apply_bert_output", "and", "args", ".", "apply_bert_attention_output", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Appr.train": [[33, 85], ["bert_adapter_ucl.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "copy.deepcopy", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_ucl.Appr.train_epoch", "time.time", "bert_adapter_ucl.Appr.eval", "time.time", "print", "bert_adapter_ucl.Appr.eval", "print", "print", "utils.freeze_model", "bert_adapter_ucl.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adaters", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_ucl", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "", "for", "adapter", "in", "adaters", ":", "\n", "            ", "for", "param", "in", "adapter", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'BERT ADAPTER UCL'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Appr.train_epoch": [[86, 123], ["bert_adapter_ucl.Appr.model.train", "enumerate", "len", "bert_adapter_ucl.Appr.model.forward", "bert_adapter_ucl.Appr.ce", "bert_adapter_ucl.Appr.custom_regularization", "iter_bar.set_description", "bert_adapter_ucl.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_ucl.Appr.warmup_linear", "bat.to", "bert_adapter_ucl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.custom_regularization", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Appr.eval": [[124, 165], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_ucl.Appr.model.eval", "enumerate", "bert_adapter_ucl.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_ucl.Appr.model.forward", "bert_adapter_ucl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_ucl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_ucl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_ucl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_ucl.Appr.custom_regularization": [[169, 264], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "zip", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "saver_net.named_children", "trainer_net.named_children", "bayes_layer._calculate_fan_in_and_fan_out", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "isinstance", "isinstance", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "math.sqrt", "math.sqrt", "len", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "isinstance", "isinstance", "len", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.expand", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.permute", "prev_weight_strength.reshape.reshape.permute", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_derpp.Appr.__init__": [[17, 21], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'W2V NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_derpp.Appr.train": [[22, 110], ["utils.get_model", "w2v_cnn_derpp.Appr._get_optimizer", "range", "utils.set_model_", "print", "int", "print", "torch.utils.data.DataLoader", "next", "tokens_term_ids.to", "tokens_sentence_ids.to", "tokens_term_ids.to", "targets.to.to.to", "w2v_cnn_derpp.Appr.model.forward", "w2v_cnn_derpp.Appr.buffer.add_data", "time.time", "tqdm.tqdm.tqdm", "w2v_cnn_derpp.Appr.train_epoch", "time.time", "w2v_cnn_derpp.Appr.eval", "time.time", "w2v_cnn_derpp.Appr.logger.info", "w2v_cnn_derpp.Appr.eval", "w2v_cnn_derpp.Appr.logger.info", "print", "len", "iter", "utils.get_model", "print", "len", "print", "w2v_cnn_derpp.Appr._get_optimizer", "torch.ones().to", "len", "len", "print", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "# Update old", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "input_ids", "=", "tokens_term_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "segment_ids", "=", "tokens_sentence_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "input_mask", "=", "tokens_term_ids", ".", "to", "(", "self", ".", "device", ")", "#dummpy", "\n", "targets", "=", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "labels", "=", "targets", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", ",", "\n", "logits", "=", "cur_task_output", ".", "data", "\n", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_derpp.Appr.train_epoch": [[113, 164], ["w2v_cnn_derpp.Appr.model.train", "enumerate", "w2v_cnn_derpp.Appr.model.forward", "w2v_cnn_derpp.Appr.ce", "iter_bar.set_description", "w2v_cnn_derpp.Appr.optimizer.zero_grad", "w2v_cnn_derpp.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_cnn_derpp.Appr.optimizer.step", "w2v_cnn_derpp.Appr.buffer.is_empty", "w2v_cnn_derpp.Appr.buffer.get_data", "buf_inputs.long", "buf_segment_ids.long", "buf_input_mask.long", "buf_labels.long", "w2v_cnn_derpp.Appr.model.forward", "w2v_cnn_derpp.Appr.model.parameters", "t.to", "w2v_cnn_derpp.Appr.ce", "w2v_cnn_derpp.Appr.mse", "w2v_cnn_derpp.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_logits", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "\n", "buf_task_inputs", "=", "buf_inputs", ".", "long", "(", ")", "\n", "buf_task_segment", "=", "buf_segment_ids", ".", "long", "(", ")", "\n", "buf_task_mask", "=", "buf_input_mask", ".", "long", "(", ")", "#dummy", "\n", "buf_task_labels", "=", "buf_labels", ".", "long", "(", ")", "\n", "buf_task_logits", "=", "buf_logits", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "buf_task_inputs", ",", "buf_task_segment", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "+=", "self", ".", "args", ".", "beta", "*", "self", ".", "ce", "(", "cur_task_output", ",", "buf_task_labels", ")", "\n", "loss", "+=", "self", ".", "args", ".", "alpha", "*", "self", ".", "mse", "(", "cur_task_output", ",", "buf_task_logits", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_derpp.Appr.eval": [[165, 199], ["w2v_cnn_derpp.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_cnn_derpp.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_cnn_derpp.Appr.model.forward", "w2v_cnn_derpp.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_cnn_derpp.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "w2v_cnn_derpp.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_cnn_derpp.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.__init__": [[32, 37], ["bert_adapter_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'BERT ADAPTER GEM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.train": [[38, 120], ["bert_adapter_gem.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "copy.deepcopy", "bert_adapter_gem.Appr.model_old.eval", "utils.freeze_model", "bert_adapter_gem.Appr.grads_cs.append", "print", "int", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "bert_adapter_gem.Appr.buffer.add_data", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_gem.Appr.train_epoch", "time.time", "bert_adapter_gem.Appr.eval", "time.time", "bert_adapter_gem.Appr.logger.info", "bert_adapter_gem.Appr.eval", "bert_adapter_gem.Appr.logger.info", "print", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "len", "iter", "bert_adapter_gem.Appr.model.named_parameters", "utils.get_model", "bert_adapter_gem.Appr.logger.info", "len", "input_ids.to", "segment_ids.to", "input_mask.to", "targets.to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "any", "len", "len", "numpy.sum", "numpy.sum", "any", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "self", ".", "logger", ".", "info", "(", "' *'", ")", "\n", "# print(' *',end='')", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "self", ".", "grads_cs", ".", "append", "(", "torch", ".", "zeros", "(", "\n", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "# add data to the buffer", "\n", "print", "(", "'len(train): '", ",", "len", "(", "train_data", ")", ")", "\n", "samples_per_task", "=", "int", "(", "len", "(", "train_data", ")", "*", "self", ".", "args", ".", "buffer_percent", ")", "\n", "print", "(", "'samples_per_task: '", ",", "samples_per_task", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "samples_per_task", ")", "\n", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "next", "(", "iter", "(", "loader", ")", ")", "\n", "\n", "self", ".", "buffer", ".", "add_data", "(", "\n", "examples", "=", "input_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "labels", "=", "targets", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "task_labels", "=", "torch", ".", "ones", "(", "samples_per_task", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "*", "(", "t", ")", "\n", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.train_epoch": [[121, 197], ["bert_adapter_gem.Appr.model.train", "enumerate", "optimizer.zero_grad", "bert_adapter_gem.Appr.model.forward", "bert_adapter_gem.Appr.ce", "iter_bar.set_description", "bert_adapter_gem.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_adapter_gem.Appr.buffer.is_empty", "bert_adapter_gem.Appr.buffer.get_data", "buf_task_labels.unique", "bert_adapter_gem.Appr.buffer.is_empty", "bert_adapter_gem.Appr.store_grad", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "bert_adapter_gem.Appr.warmup_linear", "bat.to", "optimizer.zero_grad", "buf_inputs[].long", "buf_segment_ids[].long", "buf_input_mask[].long", "buf_labels[].long", "bert_adapter_gem.Appr.model.forward", "bert_adapter_gem.Appr.ce", "bert_adapter_gem.Appr.backward", "bert_adapter_gem.Appr.store_grad", "bert_adapter_gem.Appr.item", "bert_adapter_gem.Appr.grads_da.unsqueeze", "bert_adapter_gem.Appr.project2cone2", "bert_adapter_gem.Appr.overwrite_grad", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_adapter_gem.Appr.grads_da.unsqueeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.project2cone2", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.overwrite_grad"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "num_labels", "=", "self", ".", "taskcla", "[", "t", "]", "[", "1", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "\n", "\n", "# Forward current model", "\n", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "                ", "buf_inputs", ",", "buf_labels", ",", "buf_task_labels", ",", "buf_segment_ids", ",", "buf_input_mask", "=", "self", ".", "buffer", ".", "get_data", "(", "\n", "self", ".", "args", ".", "buffer_size", ")", "\n", "# print('buf_segment_ids: ',buf_segment_ids.size())", "\n", "# print('buf_input_mask: ',buf_input_mask.size())", "\n", "\n", "for", "tt", "in", "buf_task_labels", ".", "unique", "(", ")", ":", "\n", "# compute gradient on the memory buffer", "\n", "                    ", "optimizer", ".", "zero_grad", "(", ")", "\n", "cur_task_inputs", "=", "buf_inputs", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_segment", "=", "buf_segment_ids", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_mask", "=", "buf_input_mask", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "cur_task_labels", "=", "buf_labels", "[", "buf_task_labels", "==", "tt", "]", ".", "long", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "cur_task_inputs", ",", "cur_task_segment", ",", "cur_task_mask", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "cur_task_output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "cur_task_output", "=", "outputs", "[", "tt", "]", "\n", "\n", "", "penalty", "=", "self", ".", "ce", "(", "cur_task_output", ",", "cur_task_labels", ")", "\n", "penalty", ".", "backward", "(", ")", "\n", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_cs", "[", "tt", "]", ",", "self", ".", "grad_dims", ")", "\n", "\n", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# check if gradient violates buffer constraints", "\n", "if", "not", "self", ".", "buffer", ".", "is_empty", "(", ")", ":", "\n", "# copy gradient", "\n", "                ", "self", ".", "store_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_da", ",", "self", ".", "grad_dims", ")", "\n", "\n", "dot_prod", "=", "torch", ".", "mm", "(", "self", ".", "grads_da", ".", "unsqueeze", "(", "0", ")", ",", "\n", "torch", ".", "stack", "(", "self", ".", "grads_cs", ")", ".", "T", ")", "\n", "if", "(", "dot_prod", "<", "0", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "                    ", "self", ".", "project2cone2", "(", "self", ".", "grads_da", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "stack", "(", "self", ".", "grads_cs", ")", ".", "T", ",", "margin", "=", "self", ".", "args", ".", "gamma", ")", "\n", "# copy gradients back", "\n", "self", ".", "overwrite_grad", "(", "self", ".", "model", ".", "parameters", ",", "self", ".", "grads_da", ",", "\n", "self", ".", "grad_dims", ")", "\n", "\n", "\n", "", "", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.eval": [[198, 242], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_gem.Appr.model.eval", "enumerate", "bert_adapter_gem.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_gem.Appr.model.forward", "bert_adapter_gem.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_adapter_gem.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_adapter_gem.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_adapter_gem.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "# Forward", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "# break", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.store_grad": [[246, 262], ["grads.fill_", "params", "numpy.sum", "numpy.sum", "grads[].copy_", "sum", "param.grad.data.view"], "methods", ["None"], ["", "def", "store_grad", "(", "self", ",", "params", ",", "grads", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This stores parameter gradients of past tasks.\n            pp: parameters\n            grads: gradients\n            grad_dims: list with number of parameters per layers\n        \"\"\"", "\n", "# store the gradients", "\n", "grads", ".", "fill_", "(", "0.0", ")", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "np", ".", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "grads", "[", "begin", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.overwrite_grad": [[264, 281], ["params", "sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "methods", ["None"], ["", "", "def", "overwrite_grad", "(", "self", ",", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This is used to overwrite the gradients with a new gradient\n            vector, whenever violations occur.\n            pp: parameters\n            newgrad: corrected gradient\n            grad_dims: list storing number of parameters at each layer\n        \"\"\"", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "begin", ":", "end", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_gem.Appr.project2cone2": [[283, 303], ["memories.cpu().t().double().numpy", "gradient.cpu().contiguous().view().double().numpy", "numpy.dot", "numpy.dot", "numpy.eye", "numpy.eye", "gradient.copy_", "memories.cpu().t().double().numpy.transpose", "numpy.dot", "numpy.dot", "numpy.zeros", "numpy.zeros", "quadprog.solve_qp", "numpy.dot", "numpy.dot", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "memories.cpu().t().double", "gradient.cpu().contiguous().view().double", "numpy.eye", "numpy.eye", "numpy.dot.transpose", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "memories.cpu().t", "gradient.cpu().contiguous().view", "memories.cpu", "gradient.cpu().contiguous", "gradient.cpu"], "methods", ["None"], ["", "", "def", "project2cone2", "(", "self", ",", "gradient", ",", "memories", ",", "margin", "=", "0.5", ",", "eps", "=", "1e-3", ")", ":", "\n", "        ", "\"\"\"\n            Solves the GEM dual QP described in the paper given a proposed\n            gradient \"gradient\", and a memory of task gradients \"memories\".\n            Overwrites \"gradient\" with the final projected update.\n            input:  gradient, p-vector\n            input:  memories, (t * p)-vector\n            output: x, p-vector\n        \"\"\"", "\n", "memories_np", "=", "memories", ".", "cpu", "(", ")", ".", "t", "(", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "gradient_np", "=", "gradient", ".", "cpu", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "n_rows", "=", "memories_np", ".", "shape", "[", "0", "]", "\n", "self_prod", "=", "np", ".", "dot", "(", "memories_np", ",", "memories_np", ".", "transpose", "(", ")", ")", "\n", "self_prod", "=", "0.5", "*", "(", "self_prod", "+", "self_prod", ".", "transpose", "(", ")", ")", "+", "np", ".", "eye", "(", "n_rows", ")", "*", "eps", "\n", "grad_prod", "=", "np", ".", "dot", "(", "memories_np", ",", "gradient_np", ")", "*", "-", "1", "\n", "G", "=", "np", ".", "eye", "(", "n_rows", ")", "\n", "h", "=", "np", ".", "zeros", "(", "n_rows", ")", "+", "margin", "\n", "v", "=", "quadprog", ".", "solve_qp", "(", "self_prod", ",", "grad_prod", ",", "G", ",", "h", ")", "[", "0", "]", "\n", "x", "=", "np", ".", "dot", "(", "v", ",", "memories_np", ")", "+", "gradient_np", "\n", "gradient", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_ncl.Appr.__init__": [[30, 33], ["bert_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_ncl.Appr.train": [[34, 84], ["bert_ncl.Appr.model.to", "pytorch_pretrained_bert.optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "int", "time.time", "tqdm.tqdm.tqdm", "bert_ncl.Appr.train_epoch", "time.time", "bert_ncl.Appr.eval", "time.time", "print", "bert_ncl.Appr.eval", "print", "print", "bert_ncl.Appr.model.named_parameters", "utils.get_model", "print", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "\n", "        ", "global_step", "=", "0", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "param_optimizer", "=", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "==", "True", "]", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "if", "'pooler'", "not", "in", "n", "[", "0", "]", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "num_train_steps", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "self", ".", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "t_total", ")", "\n", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "int", "(", "self", ".", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "global_step", "=", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*10*25))", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "\n", "", "print", "(", ")", "\n", "# break", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_ncl.Appr.train_epoch": [[85, 121], ["bert_ncl.Appr.model.train", "enumerate", "bert_ncl.Appr.model.forward", "bert_ncl.Appr.ce", "iter_bar.set_description", "bert_ncl.Appr.backward", "optimizer.step", "optimizer.zero_grad", "bert_ncl.Appr.sup_loss", "bert_ncl.Appr.warmup_linear", "bat.to", "bert_ncl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "optimizer", ",", "t_total", ",", "global_step", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "# print('step: ',step)", "\n", "            ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "lr_this_step", "=", "self", ".", "args", ".", "learning_rate", "*", "self", ".", "warmup_linear", "(", "global_step", "/", "t_total", ",", "self", ".", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_ncl.Appr.eval": [[122, 162], ["bert_ncl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "bert_ncl.Appr.f1_compute_fn", "input_ids.size", "bert_ncl.Appr.model.forward", "bert_ncl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "bert_ncl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "bert_ncl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "bert_ncl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "#Note: for CIL, task id t should not be used in testing", "\n", "\n", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "bat", ".", "to", "(", "self", ".", "device", ")", "if", "bat", "is", "not", "None", "else", "None", "for", "bat", "in", "batch", "]", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "_", "=", "batch", "\n", "real_b", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_hat.Appr.__init__": [[15, 21], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "\n", "print", "(", "'W2V HAT NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_hat.Appr.train": [[24, 90], ["utils.get_model", "w2v_cnn_hat.Appr._get_optimizer", "range", "utils.set_model_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "w2v_cnn_hat.Appr.model.mask", "range", "w2v_cnn_hat.Appr.model.named_parameters", "time.time", "tqdm.tqdm.tqdm", "w2v_cnn_hat.Appr.train_epoch", "time.time", "w2v_cnn_hat.Appr.eval", "time.time", "print", "print", "w2v_cnn_hat.Appr.eval", "print", "print", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "len", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "w2v_cnn_hat.Appr.model.get_view_for", "float", "utils.get_model", "print", "mask[].data.clone", "len", "torch.max", "torch.max", "torch.max", "torch.max", "print", "w2v_cnn_hat.Appr._get_optimizer", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ",", "trained_task", "=", "t", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ",", "trained_task", "=", "t", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "# Activations mask", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", ":", "\n", "            ", "mask", "[", "i", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", "[", "i", "]", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "if", "t", "==", "0", ":", "\n", "            ", "self", ".", "mask_pre", "=", "mask", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mask_pre", ")", ")", ":", "\n", "                ", "self", ".", "mask_pre", "[", "i", "]", "=", "torch", ".", "max", "(", "self", ".", "mask_pre", "[", "i", "]", ",", "mask", "[", "i", "]", ")", "\n", "\n", "# Weights mask", "\n", "", "", "self", ".", "mask_back", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "self", ".", "mask_pre", ")", "\n", "if", "vals", "is", "not", "None", ":", "\n", "                ", "self", ".", "mask_back", "[", "n", "]", "=", "1", "-", "vals", "\n", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_hat.Appr.train_epoch": [[93, 149], ["w2v_cnn_hat.Appr.model.train", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "w2v_cnn_hat.Appr.model.forward", "w2v_cnn_hat.Appr.criterion_hat", "iter_bar.set_description", "w2v_cnn_hat.Appr.optimizer.zero_grad", "loss.backward", "w2v_cnn_hat.Appr.model.named_parameters", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "w2v_cnn_hat.Appr.optimizer.step", "w2v_cnn_hat.Appr.model.named_parameters", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "w2v_cnn_hat.Appr.model.named_parameters", "n.startswith", "w2v_cnn_hat.Appr.model.parameters", "n.startswith", "t.to", "len", "loss.item", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "s", ")", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", ",", "_", "=", "self", ".", "criterion_hat", "(", "output", ",", "targets", ",", "masks", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Restrict layer gradients in backprop", "\n", "if", "t", ">", "0", ":", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", "in", "self", ".", "mask_back", ":", "\n", "                        ", "p", ".", "grad", ".", "data", "*=", "self", ".", "mask_back", "[", "n", "]", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", ".", "startswith", "(", "'e'", ")", ":", "\n", "                    ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "thres_cosh", ",", "self", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Constrain embeddings", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "n", ".", "startswith", "(", "'e'", ")", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "thres_emb", ",", "self", ".", "thres_emb", ")", "\n", "\n", "#print(masks[-1].data.view(1,-1))", "\n", "#if i>=5*self.sbatch: sys.exit()", "\n", "#if i==0: print(masks[-2].data.view(1,-1),masks[-2].data.max(),masks[-2].data.min())", "\n", "#print(masks[-2].data.view(1,-1))", "\n", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_hat.Appr.eval": [[150, 196], ["w2v_cnn_hat.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "w2v_cnn_hat.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_cnn_hat.Appr.criterion_hat", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "t.to", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "w2v_cnn_hat.Appr.model.forward", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "w2v_cnn_hat.Appr.model.forward", "hits.sum().data.cpu().numpy", "w2v_cnn_hat.Appr.ent_id_detection", "loss.data.cpu().numpy", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                        ", "task", "=", "torch", ".", "LongTensor", "(", "[", "trained_task", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ")", "\n", "output", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "ent_id", ":", "\n", "                        ", "output_d", "=", "self", ".", "ent_id_detection", "(", "trained_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "t", "=", "t", ")", "\n", "masks", "=", "output_d", "[", "'masks'", "]", "\n", "output", "=", "output_d", "[", "'output'", "]", "\n", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "task", "=", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ")", "\n", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", ",", "reg", "=", "self", ".", "criterion_hat", "(", "output", ",", "targets", ",", "masks", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_ncl.Appr.__init__": [[14, 18], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "print", "(", "'W2V NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_ncl.Appr.train": [[19, 73], ["utils.get_model", "w2v_ncl.Appr._get_optimizer", "range", "utils.set_model_", "time.time", "tqdm.tqdm.tqdm", "w2v_ncl.Appr.train_epoch", "time.time", "w2v_ncl.Appr.eval", "time.time", "w2v_ncl.Appr.logger.info", "w2v_ncl.Appr.eval", "w2v_ncl.Appr.logger.info", "print", "utils.get_model", "print", "print", "w2v_ncl.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "# print('time: ',float((clock1-clock0)*30*25))", "\n", "\n", "# print('| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,", "\n", "#     1000*self.train_batch_size*(clock1-clock0)/len(train),1000*self.train_batch_size*(clock2-clock1)/len(train),train_loss,100*train_acc),end='')", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "# print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss,100*valid_acc),end='')", "\n", "self", ".", "logger", ".", "info", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ")", "\n", "\n", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_ncl.Appr.train_epoch": [[76, 109], ["w2v_ncl.Appr.model.train", "enumerate", "w2v_ncl.Appr.model.forward", "w2v_ncl.Appr.ce", "iter_bar.set_description", "w2v_ncl.Appr.optimizer.zero_grad", "w2v_ncl.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_ncl.Appr.optimizer.step", "w2v_ncl.Appr.sup_loss", "w2v_ncl.Appr.model.parameters", "t.to", "w2v_ncl.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "pooled_rep", "=", "output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "if", "self", ".", "args", ".", "sup_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "sup_loss", "(", "output", ",", "pooled_rep", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", ",", "t", ")", "\n", "\n", "\n", "", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_ncl.Appr.eval": [[110, 144], ["w2v_ncl.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_ncl.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_ncl.Appr.model.forward", "w2v_ncl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_ncl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "w2v_ncl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_ncl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ewc.Appr.__init__": [[13, 18], ["w2v_cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "print", "(", "'W2VE EWC NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ewc.Appr.train": [[20, 86], ["utils.get_model", "w2v_cnn_ewc.Appr._get_optimizer", "range", "utils.set_model_", "copy.deepcopy", "w2v_cnn_ewc.Appr.model_old.eval", "utils.freeze_model", "utils.fisher_matrix_diag_w2v", "time.time", "tqdm.tqdm.tqdm", "w2v_cnn_ewc.Appr.train_epoch", "time.time", "w2v_cnn_ewc.Appr.eval", "time.time", "print", "print", "w2v_cnn_ewc.Appr.eval", "print", "print", "w2v_cnn_ewc.Appr.model.named_parameters", "w2v_cnn_ewc.Appr.model.named_parameters", "float", "utils.get_model", "print", "w2v_cnn_ewc.Appr.fisher[].clone", "print", "w2v_cnn_ewc.Appr._get_optimizer", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.fisher_matrix_diag_w2v", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "# self.model=deepcopy(self.initial_model) # Restart model: isolate", "\n", "\n", "        ", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "\n", "# Loop epochs", "\n", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "            ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", ",", "train_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "train", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "float", "(", "(", "clock1", "-", "clock0", ")", "*", "30", "*", "25", ")", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", ",", "valid_f1_macro", "=", "self", ".", "eval", "(", "t", ",", "valid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                    ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                        ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", "lr", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "# Update old", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "model_old", ".", "eval", "(", ")", "\n", "utils", ".", "freeze_model", "(", "self", ".", "model_old", ")", "# Freeze the weights", "\n", "\n", "# Fisher ops", "\n", "if", "t", ">", "0", ":", "\n", "            ", "fisher_old", "=", "{", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "fisher_old", "[", "n", "]", "=", "self", ".", "fisher", "[", "n", "]", ".", "clone", "(", ")", "\n", "", "", "self", ".", "fisher", "=", "utils", ".", "fisher_matrix_diag_w2v", "(", "t", ",", "train_data", ",", "self", ".", "device", ",", "self", ".", "model", ",", "self", ".", "criterion_ewc", ",", "self", ".", "args", ")", "\n", "if", "t", ">", "0", ":", "\n", "# Watch out! We do not want to keep t models (or fisher diagonals) in memory, therefore we have to merge fisher diagonals", "\n", "            ", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "fisher", "[", "n", "]", "=", "(", "self", ".", "fisher", "[", "n", "]", "+", "fisher_old", "[", "n", "]", "*", "t", ")", "/", "(", "t", "+", "1", ")", "# Checked: it is better than the other option", "\n", "#self.fisher[n]=0.5*(self.fisher[n]+fisher_old[n])", "\n", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ewc.Appr.train_epoch": [[89, 115], ["w2v_cnn_ewc.Appr.model.train", "enumerate", "w2v_cnn_ewc.Appr.model.forward", "w2v_cnn_ewc.Appr.criterion_ewc", "iter_bar.set_description", "w2v_cnn_ewc.Appr.optimizer.zero_grad", "w2v_cnn_ewc.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_cnn_ewc.Appr.optimizer.step", "w2v_cnn_ewc.Appr.model.parameters", "t.to", "w2v_cnn_ewc.Appr.item"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "# print('tokens_term_ids: ',tokens_term_ids)", "\n", "# Forward", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "iter_bar", ".", "set_description", "(", "'Train Iter (loss=%5.3f)'", "%", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_ewc.Appr.eval": [[116, 149], ["w2v_cnn_ewc.Appr.model.eval", "torch.no_grad", "enumerate", "w2v_cnn_ewc.Appr.f1_compute_fn", "tokens_term_ids.size", "w2v_cnn_ewc.Appr.model.forward", "w2v_cnn_ewc.Appr.criterion_ewc", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "w2v_cnn_ewc.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "hits.sum().data.cpu().numpy", "w2v_cnn_ewc.Appr.data.cpu().numpy", "hits.sum().data.cpu", "w2v_cnn_ewc.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc"], ["", "def", "eval", "(", "self", ",", "t", ",", "data", ",", "test", "=", "None", ",", "trained_task", "=", "None", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "tokens_term_ids", ".", "size", "(", "0", ")", "\n", "\n", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "tokens_term_ids", ",", "tokens_sentence_ids", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "", "loss", "=", "self", ".", "criterion_ewc", "(", "t", ",", "output", ",", "targets", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "real_b", "\n", "", "f1", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.__init__": [[19, 23], ["w2v_cnn_base.Appr.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "logger", "=", "logger", ",", "taskcla", "=", "taskcla", ",", "args", "=", "args", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.auto_similarity": [[25, 72], ["range", "print", "numpy.savetxt", "print", "numpy.savetxt", "print", "w2v_cnn_cat.Appr.model.mask", "print", "range", "gc1.detach", "gc2.detach", "gc3.detach", "gfc1.detach", "gfc2.detach", "print", "w2v_cnn_cat.Appr.real_train", "w2v_cnn_cat.Appr.eval_", "len", "print", "w2v_cnn_cat.Appr.real_train", "w2v_cnn_cat.Appr.eval_", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_"], ["", "def", "auto_similarity", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "\n", "#TODO: to detect the task similarity", "\n", "\n", "        ", "for", "pre_task", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "\n", "            ", "gc1", ",", "gc2", ",", "gc3", ",", "gfc1", ",", "gfc2", "=", "self", ".", "model", ".", "mask", "(", "pre_task", ")", "\n", "pre_mask", "=", "[", "gc1", ".", "detach", "(", ")", ",", "gc2", ".", "detach", "(", ")", ",", "gc3", ".", "detach", "(", ")", ",", "gfc1", ".", "detach", "(", ")", ",", "gfc2", ".", "detach", "(", ")", "]", "\n", "\n", "if", "pre_task", "==", "t", ":", "# the last one", "\n", "                ", "print", "(", "'>>> Now Training Phase: {:6s} <<<'", ".", "format", "(", "'reference'", ")", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'reference'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "# implemented as random mask", "\n", "", "elif", "pre_task", "!=", "t", ":", "\n", "                ", "print", "(", "'>>> Now Training Phase: {:6s} <<<'", ".", "format", "(", "'transfer'", ")", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'transfer'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "\n", "", "if", "pre_task", "==", "t", ":", "# the last one", "\n", "                ", "test_loss", ",", "test_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "phase", "=", "'reference'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "", "elif", "pre_task", "!=", "t", ":", "\n", "                ", "test_loss", ",", "test_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "phase", "=", "'transfer'", ",", "\n", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "\n", "", "self", ".", "acc_transfer", "[", "t", ",", "pre_task", "]", "=", "test_acc", "\n", "self", ".", "lss_transfer", "[", "t", ",", "pre_task", "]", "=", "test_loss", "\n", "\n", "# print('test_acc: ',self.acc_transfer[t][:t+1])", "\n", "# print('test_loss: ',self.lss_transfer[t][:t+1])", "\n", "", "print", "(", "'Save at transfer_acc'", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "args", ".", "output", "+", "'_acc_transfer'", ",", "self", ".", "acc_transfer", ",", "'%.4f'", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "similarity", "=", "[", "0", "]", "\n", "if", "t", ">", "0", ":", "\n", "            ", "acc_list", "=", "self", ".", "acc_transfer", "[", "t", "]", "[", ":", "t", "]", "#t from 0", "\n", "print", "(", "'acc_list: '", ",", "acc_list", ")", "\n", "\n", "similarity", "=", "[", "0", "if", "(", "acc_list", "[", "acc_id", "]", "<=", "self", ".", "acc_transfer", "[", "t", "]", "[", "t", "]", ")", "else", "1", "for", "acc_id", "in", "range", "(", "len", "(", "acc_list", ")", ")", "]", "# remove all acc < 0.5", "\n", "\n", "for", "source_task", "in", "range", "(", "len", "(", "similarity", ")", ")", ":", "\n", "                ", "self", ".", "similarity_transfer", "[", "t", ",", "source_task", "]", "=", "similarity", "[", "source_task", "]", "\n", "\n", "", "", "print", "(", "'Save at similarity_transfer'", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "args", ".", "output", "+", "'_similarity_transfer'", ",", "self", ".", "similarity_transfer", ",", "'%.4f'", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "print", "(", "'similarity: '", ",", "similarity", ")", "\n", "return", "similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.train": [[74, 82], ["w2v_cnn_cat.Appr.auto_similarity", "w2v_cnn_cat.Appr.similarities.append", "print", "print", "w2v_cnn_cat.Appr.check_federated.set_similarities", "w2v_cnn_cat.Appr.real_train"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.auto_similarity", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.set_similarities", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train"], ["", "def", "train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", ":", "#N-CL", "\n", "        ", "similarity", "=", "self", ".", "auto_similarity", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", "\n", "self", ".", "similarities", ".", "append", "(", "similarity", ")", "\n", "print", "(", "'similarity: '", ",", "self", ".", "similarities", "[", "-", "1", "]", ")", "\n", "print", "(", "'similarities: '", ",", "self", ".", "similarities", ")", "\n", "\n", "self", ".", "check_federated", ".", "set_similarities", "(", "self", ".", "similarities", ")", "\n", "self", ".", "real_train", "(", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.real_train": [[85, 176], ["copy.deepcopy", "utils.get_model", "print", "w2v_cnn_cat.Appr._get_optimizer_cat", "utils.set_model_", "range", "torch.autograd.Variable", "w2v_cnn_cat.Appr.model.mask", "range", "w2v_cnn_cat.Appr.model.named_parameters", "w2v_cnn_cat.Appr.history_mask_pre.append", "time.time", "tqdm.tqdm.tqdm", "w2v_cnn_cat.Appr.train_epoch", "time.time", "w2v_cnn_cat.Appr.eval_", "time.time", "print", "w2v_cnn_cat.Appr.eval_", "print", "print", "print", "torch.LongTensor().cuda", "len", "torch.autograd.Variable", "range", "w2v_cnn_cat.Appr.model.get_view_for", "utils.get_model", "print", "mask[].data.clone", "len", "torch.max", "m.data.clone", "print", "w2v_cnn_cat.Appr._get_optimizer_cat", "torch.LongTensor", "len", "len", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat"], ["", "def", "real_train", "(", "self", ",", "t", ",", "train", ",", "valid", ",", "num_train_steps", ",", "train_data", ",", "valid_data", ",", "phase", "=", "'mcl'", ",", "pre_task", "=", "None", ",", "pre_mask", "=", "None", ")", ":", "\n", "\n", "#TODO: before the real training, we defenitely need to first detect the task similarity", "\n", "\n", "\n", "\n", "        ", "self", ".", "model", ".", "transfer", "=", "deepcopy", "(", "self", ".", "transfer_initial_model", ")", "# Restart transfer network: isolate", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "\n", "print", "(", "'phase: '", ",", "phase", ")", "\n", "\n", "if", "phase", "==", "'mcl'", "or", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "            ", "lr", "=", "self", ".", "lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "nepochs", "=", "self", ".", "nepochs", "\n", "\n", "\n", "", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_cat", "(", "lr", ",", "phase", ")", "\n", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "iter_bar", "=", "tqdm", "(", "train", ",", "desc", "=", "'Train Iter (loss=X.XXX)'", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "train", ",", "iter_bar", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", "=", "self", ".", "eval_", "(", "t", ",", "train", ",", "trained_task", "=", "t", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock1", "-", "clock0", ")", "/", "len", "(", "train", ")", ",", "1000", "*", "self", ".", "train_batch_size", "*", "(", "clock2", "-", "clock1", ")", "/", "len", "(", "train", ")", ",", "train_loss", ",", "100", "*", "train_acc", ")", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", "=", "self", ".", "eval_", "(", "t", ",", "valid", ",", "trained_task", "=", "t", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "\n", "pre_task", "=", "pre_task", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "# Adapt lr", "\n", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "utils", ".", "get_model", "(", "self", ".", "model", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer_cat", "(", "lr", ",", "phase", ")", "\n", "", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best validation model", "\n", "", "utils", ".", "set_model_", "(", "self", ".", "model", ",", "best_model", ")", "\n", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Activations mask", "\n", "            ", "task", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "False", ")", "\n", "mask", "=", "self", ".", "model", ".", "mask", "(", "task", ",", "s", "=", "self", ".", "smax", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", ":", "\n", "                ", "mask", "[", "i", "]", "=", "torch", ".", "autograd", ".", "Variable", "(", "mask", "[", "i", "]", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "t", "==", "0", ":", "\n", "                ", "self", ".", "mask_pre", "=", "mask", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mask_pre", ")", ")", ":", "\n", "                    ", "self", ".", "mask_pre", "[", "i", "]", "=", "torch", ".", "max", "(", "self", ".", "mask_pre", "[", "i", "]", ",", "mask", "[", "i", "]", ")", "\n", "\n", "# Weights mask", "\n", "", "", "self", ".", "mask_back", "=", "{", "}", "\n", "\n", "for", "n", ",", "_", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "self", ".", "mask_pre", ")", "\n", "if", "vals", "is", "not", "None", ":", "\n", "                    ", "self", ".", "mask_back", "[", "n", "]", "=", "1", "-", "vals", "\n", "\n", "#TODO: make the end function separately", "\n", "", "", "", "if", "phase", "==", "'mcl'", ":", "\n", "            ", "self", ".", "history_mask_pre", ".", "append", "(", "[", "m", ".", "data", ".", "clone", "(", ")", "for", "m", "in", "self", ".", "mask_pre", "]", ")", "\n", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.train_epoch": [[177, 274], ["w2v_cnn_cat.Appr.model.train", "w2v_cnn_cat.Appr.model.train", "enumerate", "w2v_cnn_cat.Appr.optimizer.zero_grad", "w2v_cnn_cat.Appr.backward", "torch.nn.utils.clip_grad_norm", "w2v_cnn_cat.Appr.optimizer.step", "w2v_cnn_cat.Appr.model", "w2v_cnn_cat.Appr.model.named_parameters", "w2v_cnn_cat.Appr.model.parameters", "w2v_cnn_cat.Appr.model.named_parameters", "t.to", "len", "w2v_cnn_cat.Appr.criterion", "w2v_cnn_cat.Appr.joint_criterion", "w2v_cnn_cat.Appr.model", "w2v_cnn_cat.Appr.transfer_criterion", "w2v_cnn_cat.Appr.model.named_parameters", "w2v_cnn_cat.Appr.model.named_parameters", "n.startswith", "w2v_cnn_cat.Appr.model.named_parameters", "n.startswith", "torch.clamp", "n.startswith", "w2v_cnn_cat.Appr.model.Tsim_mask", "w2v_cnn_cat.Appr.model.get_view_for().clone", "torch.max", "torch.cosh", "torch.cosh", "n.startswith", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "w2v_cnn_cat.Appr.model.get_view_for", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.mlp_cat.Net.Tsim_mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "data", ",", "iter_bar", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "# Loop batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_bar", ")", ":", "\n", "            ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "\n", "s", "=", "(", "self", ".", "smax", "-", "1", "/", "self", ".", "smax", ")", "*", "step", "/", "len", "(", "data", ")", "+", "1", "/", "self", ".", "smax", "\n", "\n", "# Forward", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "s", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "outputs_attn", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "output_attn", "=", "outputs_attn", "[", "t", "]", "\n", "\n", "", "if", "output_attn", "is", "None", ":", "\n", "                    ", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ",", "masks", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "self", ".", "joint_criterion", "(", "output", ",", "targets", ",", "masks", ",", "output_attn", ")", "\n", "\n", "\n", "", "", "elif", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "\n", "                ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "s", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "transfer_criterion", "(", "output", ",", "targets", ")", "\n", "\n", "# Backward", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Restrict layer gradients in backprop", "\n", "                ", "if", "t", ">", "0", ":", "\n", "                    ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "if", "n", "in", "self", ".", "mask_back", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                            ", "Tsim_mask", "=", "self", ".", "model", ".", "Tsim_mask", "(", "t", ",", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ")", "\n", "Tsim_vals", "=", "self", ".", "model", ".", "get_view_for", "(", "n", ",", "Tsim_mask", ")", ".", "clone", "(", ")", "\n", "p", ".", "grad", ".", "data", "*=", "torch", ".", "max", "(", "self", ".", "mask_back", "[", "n", "]", ",", "Tsim_vals", ")", "\n", "\n", "\n", "# Compensate embedding gradients", "\n", "", "", "", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'mcl.e'", ")", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_cosh", ",", "self", ".", "args", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'reference'", ":", "\n", "# Compensate embedding gradients", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'transfer.e'", ")", "and", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "num", "=", "torch", ".", "cosh", "(", "torch", ".", "clamp", "(", "s", "*", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_cosh", ",", "self", ".", "args", ".", "thres_cosh", ")", ")", "+", "1", "\n", "den", "=", "torch", ".", "cosh", "(", "p", ".", "data", ")", "+", "1", "\n", "p", ".", "grad", ".", "data", "*=", "self", ".", "smax", "/", "s", "*", "num", "/", "den", "\n", "\n", "# Apply step", "\n", "", "", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clipgrad", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "# Constrain embeddings", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'mcl.e'", ")", ":", "\n", "                        ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_emb", ",", "self", ".", "args", ".", "thres_emb", ")", "\n", "\n", "\n", "", "", "", "elif", "phase", "==", "'reference'", ":", "\n", "# Constrain embeddings", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "n", ".", "startswith", "(", "'transfer.e'", ")", ":", "\n", "                        ", "p", ".", "data", "=", "torch", ".", "clamp", "(", "p", ".", "data", ",", "-", "self", ".", "args", ".", "thres_emb", ",", "self", ".", "args", ".", "thres_emb", ")", "\n", "", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval_": [[278, 299], ["w2v_cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["", "def", "eval_", "(", "self", ",", "t", ",", "test", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "test", ",", "trained_task", ",", "phase", ",", "pre_mask", ",", "pre_task", ")", "\n", "\n", "if", "'all-one'", "in", "self", ".", "args", ".", "similarity_detection", ":", "\n", "            ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "\n", "", "if", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "if", "total_att_acc", ">", "total_mask_acc", ":", "\n", "                ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "", "else", ":", "\n", "                ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "\n", "", "", "else", ":", "\n", "                ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.eval": [[301, 330], ["w2v_cnn_cat.Appr.compute_acc", "print", "w2v_cnn_cat.Appr.compute_acc"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc"], ["", "def", "eval", "(", "self", ",", "t", ",", "test", ",", "valid", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "\n", "        ", "choose_att", "=", "False", "\n", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "valid", ",", "trained_task", ",", "phase", ")", "\n", "\n", "if", "'all-one'", "in", "self", ".", "args", ".", "similarity_detection", ":", "\n", "            ", "choose_att", "=", "True", "\n", "", "elif", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "if", "total_att_acc", ">", "total_mask_acc", ":", "\n", "                ", "choose_att", "=", "True", "\n", "\n", "", "", "print", "(", "'choose_att: '", ",", "choose_att", ")", "\n", "#Here simply use validation to choose attention in testing.", "\n", "# One can also remember which tasks have used the attention in training and then apply attention for testing", "\n", "\n", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "=", "self", ".", "compute_acc", "(", "t", ",", "test", ",", "trained_task", ",", "phase", ")", "\n", "\n", "if", "choose_att", "==", "True", ":", "\n", "            ", "total_loss", "=", "total_att_loss", "\n", "total_acc", "=", "total_att_acc", "\n", "total_f1", "=", "f1_att", "\n", "", "else", ":", "\n", "            ", "total_loss", "=", "total_mask_loss", "\n", "total_acc", "=", "total_mask_acc", "\n", "total_f1", "=", "f1_mask", "\n", "\n", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", ",", "total_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.compute_acc": [[332, 436], ["w2v_cnn_cat.Appr.model.eval", "print", "torch.no_grad", "enumerate", "w2v_cnn_cat.Appr.f1_compute_fn", "targets.size", "target_list.append", "len", "w2v_cnn_cat.Appr.f1_compute_fn", "output_attn.max", "output.max", "pred_att_list.append", "pred_mask_list.append", "mask_hits.sum().data.cpu().numpy().item", "att_hits.sum().data.cpu().numpy().item", "output.max", "pred_mask_list.append", "hits.sum().data.cpu().numpy().item", "torch.cat", "torch.cat", "t.to", "w2v_cnn_cat.Appr.criterion", "w2v_cnn_cat.Appr.joint_criterion", "w2v_cnn_cat.Appr.model", "w2v_cnn_cat.Appr.transfer_criterion", "w2v_cnn_cat.Appr.data.cpu().numpy().item", "w2v_cnn_cat.Appr.data.cpu().numpy().item", "w2v_cnn_cat.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "w2v_cnn_cat.Appr.model", "w2v_cnn_cat.Appr.model", "mask_hits.sum().data.cpu().numpy", "att_hits.sum().data.cpu().numpy", "hits.sum().data.cpu().numpy", "w2v_cnn_cat.Appr.data.cpu().numpy", "w2v_cnn_cat.Appr.data.cpu().numpy", "w2v_cnn_cat.Appr.data.cpu().numpy", "mask_hits.sum().data.cpu", "att_hits.sum().data.cpu", "hits.sum().data.cpu", "w2v_cnn_cat.Appr.data.cpu", "w2v_cnn_cat.Appr.data.cpu", "w2v_cnn_cat.Appr.data.cpu", "mask_hits.sum", "att_hits.sum", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion"], ["", "def", "compute_acc", "(", "self", ",", "t", ",", "data", ",", "trained_task", "=", "None", ",", "phase", "=", "None", ",", "pre_mask", "=", "None", ",", "pre_task", "=", "None", ")", ":", "\n", "        ", "total_att_loss", "=", "0", "\n", "total_att_acc", "=", "0", "\n", "\n", "total_mask_loss", "=", "0", "\n", "total_mask_acc", "=", "0", "\n", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "target_list", "=", "[", "]", "\n", "pred_att_list", "=", "[", "]", "\n", "pred_mask_list", "=", "[", "]", "\n", "\n", "print", "(", "'phase: '", ",", "phase", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "batch", "=", "[", "\n", "t", ".", "to", "(", "self", ".", "device", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "batch", "]", "\n", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", "=", "batch", "\n", "real_b", "=", "targets", ".", "size", "(", "0", ")", "\n", "target_list", ".", "append", "(", "targets", ")", "\n", "\n", "# Forward", "\n", "\n", "if", "phase", "==", "'mcl'", ":", "\n", "\n", "\n", "                    ", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "if", "self", ".", "args", ".", "last_id", ":", "# fix 0", "\n", "                            ", "output_dict", "=", "self", ".", "model", "(", "trained_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "\n", "\n", "", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "outputs_attn", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "output_attn", "=", "outputs_attn", "[", "t", "]", "\n", "\n", "", "if", "output_attn", "is", "None", ":", "\n", "                        ", "loss", "=", "self", ".", "criterion", "(", "output", ",", "targets", ",", "masks", ")", "\n", "", "else", ":", "\n", "                        ", "loss", "=", "self", ".", "joint_criterion", "(", "output", ",", "targets", ",", "masks", ",", "output_attn", ")", "\n", "\n", "", "", "elif", "phase", "==", "'transfer'", "or", "phase", "==", "'reference'", ":", "\n", "                    ", "output_dict", "=", "self", ".", "model", "(", "t", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "phase", ",", "pre_mask", "=", "pre_mask", ",", "pre_task", "=", "pre_task", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                        ", "outputs", "=", "output_dict", "[", "'y'", "]", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "\n", "", "loss", "=", "self", ".", "transfer_criterion", "(", "output", ",", "targets", ")", "\n", "\n", "\n", "# if phase=='mcl' and (similarity is not None and t<len(similarity) and np.count_nonzero(similarity[:t])>1 and similarity[t]==1):", "\n", "\n", "", "if", "phase", "==", "'mcl'", "and", "'no_attention'", "not", "in", "self", ".", "args", ".", "loss_type", "and", "output_attn", "is", "not", "None", ":", "\n", "                    ", "_", ",", "att_pred", "=", "output_attn", ".", "max", "(", "1", ")", "\n", "_", ",", "mask_pred", "=", "output", ".", "max", "(", "1", ")", "\n", "\n", "pred_att_list", ".", "append", "(", "att_pred", ")", "\n", "pred_mask_list", ".", "append", "(", "mask_pred", ")", "\n", "\n", "mask_hits", "=", "(", "mask_pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "att_hits", "=", "(", "att_pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "\n", "# Log", "\n", "total_mask_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_mask_acc", "+=", "mask_hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Log", "\n", "total_att_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_att_acc", "+=", "att_hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "else", ":", "\n", "                    ", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ")", "\n", "hits", "=", "(", "pred", "==", "targets", ")", ".", "float", "(", ")", "\n", "pred_mask_list", ".", "append", "(", "pred", ")", "\n", "\n", "# Log", "\n", "total_mask_loss", "+=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "*", "real_b", "\n", "total_mask_acc", "+=", "hits", ".", "sum", "(", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "total_num", "+=", "real_b", "\n", "\n", "", "f1_mask", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_mask_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "if", "len", "(", "pred_att_list", ")", ">", "1", ":", "\n", "                ", "f1_att", "=", "self", ".", "f1_compute_fn", "(", "y_pred", "=", "torch", ".", "cat", "(", "pred_att_list", ",", "0", ")", ",", "y_true", "=", "torch", ".", "cat", "(", "target_list", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "", "else", ":", "\n", "                ", "f1_att", "=", "None", "\n", "", "", "return", "total_mask_acc", ",", "total_mask_loss", ",", "total_att_acc", ",", "total_att_loss", ",", "total_num", ",", "f1_mask", ",", "f1_att", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.transfer_criterion": [[437, 439], ["w2v_cnn_cat.Appr.ce"], "methods", ["None"], ["", "def", "transfer_criterion", "(", "self", ",", "outputs", ",", "targets", ",", "mask", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.joint_criterion": [[441, 443], ["w2v_cnn_cat.Appr.criterion", "w2v_cnn_cat.Appr.ce"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion"], ["", "def", "joint_criterion", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ",", "outputs_attn", ")", ":", "\n", "        ", "return", "self", ".", "criterion", "(", "outputs", ",", "targets", ",", "masks", ")", "+", "self", ".", "args", ".", "model_weights", "*", "self", ".", "ce", "(", "outputs_attn", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.w2v_cnn_cat.Appr.criterion": [[444, 461], ["zip", "w2v_cnn_cat.Appr.ce", "aux.sum", "m.sum", "numpy.prod().item", "numpy.prod", "m.size"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "mp", "in", "zip", "(", "masks", ",", "self", ".", "mask_pre", ")", ":", "\n", "                ", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m", "in", "masks", ":", "\n", "                ", "reg", "+=", "m", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "", "", "reg", "/=", "count", "\n", "\n", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Appr.__init__": [[28, 33], ["bert_adapter_mask_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_output", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Appr.train": [[34, 108], ["bert_adapter_capsule_mask.Appr.model.to", "my_optimization.BertAdam", "utils.get_model", "range", "utils.set_model_", "bert_adapter_capsule_mask.Appr.model.mask", "bert_adapter_capsule_mask.Appr.items", "bert_adapter_capsule_mask.Appr.model.named_parameters", "int", "time.time", "tqdm.tqdm.tqdm", "bert_adapter_capsule_mask.Appr.train_epoch", "time.time", "bert_adapter_capsule_mask.Appr.eval", "time.time", "bert_adapter_capsule_mask.Appr.logger.info", "bert_adapter_capsule_mask.Appr.eval", "bert_adapter_capsule_mask.Appr.logger.info", "print", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "bert_adapter_capsule_mask.Appr.mask_pre.items", "bert_adapter_capsule_mask.Appr.model.get_view_for", "bert_adapter_capsule_mask.Appr.model.named_parameters", "utils.get_model", "bert_adapter_capsule_mask.Appr.logger.info", "value.data.clone", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "any", "len", "len", "any"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model"], ["            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "elif", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "adapter_masks", "=", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "LayerNorm", "for", "layer_id", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "", "for", "adapter_mask", "in", "adapter_masks", ":", "\n", "            ", "for", "param", "in", "adapter_mask", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "# param.requires_grad = False", "\n", "\n", "", "", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "            ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_task", "=", "len", "(", "taskcla", ")", "\n", "self", ".", "num_kernel", "=", "3", "\n", "\n", "print", "(", "'BERT ADAPTER CAPSULE MASK'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "s", "=", "1", ")", ":", "\n", "\n", "\n", "        ", "output_dict", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ",", "\n", "targets", "=", "None", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "            ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "masks", "=", "self", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'masks'", "]", "=", "masks", "\n", "\n", "return", "output_dict", "\n", "\n", "", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "masks", "=", "{", "}", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "\n", "            ", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "                ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger'", "#gfc1", "\n", "masks", "[", "key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "                ", "fc1_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1'", "#gfc1", "\n", "fc2_key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2'", "#gfc2", "\n", "\n", "masks", "[", "fc1_key", "]", ",", "masks", "[", "fc2_key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "key", "=", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger'", "#gfc1", "\n", "masks", "[", "key", "]", "=", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "mask", "(", "t", ",", "s", ")", "\n", "\n", "", "", "return", "masks", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Appr.train_epoch": [[109, 161], ["bert_adapter_capsule_mask.Appr.model.train", "enumerate", "bert_adapter_capsule_mask.Appr.model.forward", "bert_adapter_capsule_mask.Appr.hat_criterion_adapter", "iter_bar.set_description", "loss.backward", "bert_adapter_capsule_mask.Appr.model.named_parameters", "optimizer.step", "optimizer.zero_grad", "bert_adapter_capsule_mask.Appr.model.named_parameters", "bert_adapter_capsule_mask.Appr.model.named_parameters", "bert_adapter_capsule_mask.Appr.warmup_linear", "bat.to", "len", "loss.item", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "torch.cosh", "bert_adapter_capsule_mask.Appr.model.get_view_for_tsv", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Net.get_view_for_tsv"], ["\n", "\n", "", "def", "get_view_for", "(", "self", ",", "n", ",", "p", ",", "masks", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.weight'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.weight'", ":", "\n", "                ", "post", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "pre", "=", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", ".", "replace", "(", "'fc2'", ",", "'fc1'", ")", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "return", "torch", ".", "min", "(", "post", ",", "pre", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.bias'", ":", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.weight'", ":", "#gfc1", "\n", "# print('tsv_capsules not none')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.bias'", ":", "#gfc1", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.weight'", ":", "#gfc1", "\n", "# print('tsv_capsules not none')", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.weight'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "p", ")", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.larger.bias'", ":", "#gfc1", "\n", "                ", "return", "masks", "[", "n", ".", "replace", "(", "'.bias'", ",", "''", ")", "]", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "", "return", "None", "\n", "\n", "", "def", "get_view_for_tsv", "(", "self", ",", "n", ",", "t", ")", ":", "\n", "        ", "for", "layer_id", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", ":", "\n", "# print('not none')", "\n", "                ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "", "for", "c_t", "in", "range", "(", "self", ".", "num_task", ")", ":", "\n", "                ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.bert_adapter_capsule_mask.Appr.eval": [[162, 205], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_adapter_capsule_mask.Appr.model.eval", "enumerate", "bert_adapter_capsule_mask.Appr.f1_compute_fn", "input_ids.size", "bert_adapter_capsule_mask.Appr.model.forward", "bert_adapter_capsule_mask.Appr.hat_criterion_adapter", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "loss.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "loss.data.cpu().numpy", "hits.sum().data.cpu", "loss.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter"], ["", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('not none')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.fc_aspect.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "for", "m_t", "in", "range", "(", "self", ".", "num_kernel", ")", ":", "\n", "                    ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs3.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs2.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.weight'", ":", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.transfer_capsules.convs1.'", "+", "str", "(", "c_t", ")", "+", "'.'", "+", "str", "(", "m_t", ")", "+", "'.bias'", ":", "\n", "# print('not none')", "\n", "                        ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "", "", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", ":", "\n", "# print('not none')", "\n", "                ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "for", "c_t", "in", "range", "(", "self", ".", "num_task", ")", ":", "\n", "                ", "if", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('attention semantic_capsules fc1')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", ":", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n", "\n", "", "elif", "n", "==", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", ":", "\n", "# print('not none')", "\n", "                    ", "return", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer_id", "]", ".", "attention", ".", "output", ".", "adapter_capsule_mask", ".", "capsule_net", ".", "tsv_capsules", ".", "tsv", "[", "t", "]", "[", "c_t", "]", ".", "data", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.__init__": [[23, 30], ["cnn_base.Appr.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["self", ".", "conv2", "=", "BayesianConv2D", "(", "64", ",", "128", ",", "kernel_size", "=", "size", "//", "10", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "size", "//", "10", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "conv3", "=", "BayesianConv2D", "(", "128", ",", "256", ",", "kernel_size", "=", "2", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "s", "=", "utils", ".", "compute_conv_output_size", "(", "s", ",", "2", ")", "\n", "s", "=", "s", "//", "2", "\n", "self", ".", "maxpool", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train": [[32, 98], ["utils.get_model", "cnn_ucl.Appr._get_optimizer_ucl", "range", "utils.set_model_", "copy.deepcopy", "time.time", "tqdm.tqdm.tqdm", "len", "cnn_ucl.Appr.train_epoch", "time.time", "cnn_ucl.Appr.eval", "time.time", "print", "cnn_ucl.Appr.eval", "print", "print", "utils.freeze_model", "utils.get_model", "print", "print", "cnn_ucl.Appr._get_optimizer_ucl", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.set_model_", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.freeze_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.utils.get_model", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl"], ["\n", "self", ".", "drop1", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "BayesianLinear", "(", "256", "*", "s", "*", "s", ",", "2048", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "self", ".", "fc2", "=", "BayesianLinear", "(", "2048", ",", "2048", ",", "ratio", "=", "args", ".", "ratio", ")", "\n", "self", ".", "old_weight_norm", "=", "[", "]", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "args", ".", "nclasses", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "nclasses", "*", "2", ",", "args", ".", "nclasses", ")", "\n", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "merge_last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "n", ")", ")", "\n", "self", ".", "merge_last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "n", "*", "2", ",", "n", ")", ")", "\n", "\n", "", "", "print", "(", "'DIL CNN'", ")", "\n", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "self", ".", "maxpool", "(", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "conv3", "(", "h", ",", "sample", ")", ")", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ",", "sample", ")", ")", ")", "\n", "h", "=", "self", ".", "drop2", "(", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ",", "sample", ")", ")", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "h", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "h", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "h", ",", "dim", "=", "1", ")", "\n", "output_dict", "[", "'masks'", "]", "=", "None", "\n", "\n", "return", "output_dict", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train_epoch": [[99, 128], ["cnn_ucl.Appr.model.train", "enumerate", "len", "cnn_ucl.Appr.model.forward", "cnn_ucl.Appr.ce", "cnn_ucl.Appr.custom_regularization", "iter_bar.set_description", "cnn_ucl.Appr.optimizer.zero_grad", "cnn_ucl.Appr.backward", "cnn_ucl.Appr.optimizer.step", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "bat.to", "cnn_ucl.Appr.item", "cnn_ucl.Appr.model.parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.train", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.custom_regularization", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval": [[129, 170], ["cnn_ucl.Appr.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "cnn_ucl.Appr.f1_compute_fn", "images.size", "cnn_ucl.Appr.model.forward", "cnn_ucl.Appr.ce", "output.max", "target_list.append", "pred_list.append", "hits.sum().data.cpu().numpy().item", "cnn_ucl.Appr.data.cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bat.to", "hits.sum().data.cpu().numpy", "cnn_ucl.Appr.ent_id_detection", "cnn_ucl.Appr.data.cpu().numpy", "hits.sum().data.cpu", "cnn_ucl.Appr.data.cpu", "hits.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.custom_regularization": [[174, 275], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "zip", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "saver_net.named_children", "trainer_net.named_children", "bayes_layer._calculate_fan_in_and_fan_out", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "isinstance", "isinstance", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "math.sqrt", "math.sqrt", "len", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "saver_weight_strength.expand", "prev_weight_strength.reshape.reshape.permute().expand", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "isinstance", "isinstance", "len", "prev_weight_strength.reshape.reshape.reshape", "prev_weight_strength.reshape.reshape.expand", "prev_weight_strength.reshape.reshape.reshape", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "prev_weight_strength.reshape.reshape.permute", "prev_weight_strength.reshape.reshape.permute", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.__init__": [[10, 35], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "discriminator.GradientReversal", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "t", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", "=", "args", ".", "image_channel", "\n", "size", "=", "args", ".", "image_size", "\n", "\n", "if", "'mlp'", "in", "args", ".", "approach", ":", "\n", "            ", "nhid", "=", "args", ".", "mlp_adapter_size", "#if nlp", "\n", "", "else", ":", "\n", "            ", "nhid", "=", "2048", "#if nlp", "\n", "\n", "", "if", "args", ".", "diff", "==", "'yes'", ":", "\n", "            ", "self", ".", "dis", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "GradientReversal", "(", "args", ".", "lam", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "t", "+", "2", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dis", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "nhid", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "nhid", ",", "t", "+", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.forward": [[38, 40], ["discriminator.Discriminator.dis"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "z", ",", "labels", ",", "task_id", ")", ":", "\n", "        ", "return", "self", ".", "dis", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print": [[41, 47], ["abs"], "methods", ["None"], ["", "def", "pretty_print", "(", "self", ",", "num", ")", ":", "\n", "        ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "            ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.get_size": [[49, 52], ["sum", "print", "p.numel", "discriminator.Discriminator.pretty_print", "discriminator.Discriminator.dis.parameters"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.Discriminator.pretty_print"], ["", "def", "get_size", "(", "self", ")", ":", "\n", "        ", "count", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "dis", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "'Num parameters in D       = %s '", "%", "(", "self", ".", "pretty_print", "(", "count", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.forward": [[65, 69], ["x.clone"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "lambda_", ")", ":", "\n", "        ", "ctx", ".", "lambda_", "=", "lambda_", "\n", "return", "x", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversalFunction.backward": [[70, 76], ["grads.new_tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grads", ")", ":", "\n", "        ", "lambda_", "=", "ctx", ".", "lambda_", "\n", "lambda_", "=", "grads", ".", "new_tensor", "(", "lambda_", ")", "\n", "dx", "=", "-", "lambda_", "*", "grads", "\n", "return", "dx", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversal.__init__": [[79, 82], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lambda_", ")", ":", "\n", "        ", "super", "(", "GradientReversal", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.discriminator.GradientReversal.forward": [[83, 85], ["GradientReversalFunction.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "GradientReversalFunction", ".", "apply", "(", "x", ",", "self", ".", "lambda_", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertSelfOutput.__init__": [[77, 104], ["transformers.models.bert.modeling_bert.BertSelfOutput.__init__", "print", "adapters.BertAdapter", "adapters.BertAdapterUcl", "adapters.BertAdapterOwm", "adapters.BertAdapterMask", "BertAdapterCapsuleMask", "BertAdapterCapsule"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "args", ".", "use_imp", ":", "\n", "            ", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleMaskImp", "as", "BertAdapterCapsuleMask", "\n", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleImp", "as", "BertAdapterCapsule", "\n", "", "else", ":", "\n", "            ", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleMask", "\n", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsule", "\n", "\n", "\n", "", "if", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "print", "(", "'apply to attention'", ")", "\n", "if", "args", ".", "build_adapter", ":", "\n", "                ", "self", ".", "adapter", "=", "BertAdapter", "(", "args", ")", "\n", "", "if", "args", ".", "build_adapter_ucl", ":", "\n", "                ", "self", ".", "adapter_ucl", "=", "BertAdapterUcl", "(", "args", ")", "\n", "", "if", "args", ".", "build_adapter_owm", ":", "\n", "                ", "self", ".", "adapter_owm", "=", "BertAdapterOwm", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_mask", ":", "\n", "                ", "self", ".", "adapter_mask", "=", "BertAdapterMask", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "self", ".", "adapter_capsule_mask", "=", "BertAdapterCapsuleMask", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "self", ".", "adapter_capsule", "=", "BertAdapterCapsule", "(", "args", ")", "\n", "\n", "", "", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertSelfOutput.forward": [[105, 143], ["my_transformers.MyBertSelfOutput.dense", "my_transformers.MyBertSelfOutput.dropout", "my_transformers.MyBertSelfOutput.LayerNorm", "my_transformers.MyBertSelfOutput.adapter", "my_transformers.MyBertSelfOutput.adapter_ucl", "my_transformers.MyBertSelfOutput.adapter_owm", "my_transformers.MyBertSelfOutput.adapter_mask", "my_transformers.MyBertSelfOutput.adapter_capsule_mask", "my_transformers.MyBertSelfOutput.adapter_capsule"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "**", "kwargs", ")", ":", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter", "(", "hidden_states", ")", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_ucl", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_ucl", "(", "hidden_states", ")", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "self", ".", "adapter_owm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_mask", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_mask", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "self", ".", "adapter_capsule_mask", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "hidden_states", "=", "output_dict", "[", "'outputs'", "]", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_capsule", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "hidden_states", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "hidden_states", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "hidden_states", "\n", "", "else", ":", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertAttention.__init__": [[145, 150], ["transformers.models.bert.modeling_bert.BertAttention.__init__", "my_transformers.MyBertSelfOutput", "my_transformers.BertSelfAttention"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output", "=", "MyBertSelfOutput", "(", "config", ",", "args", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "args", "=", "args", "\n", "", "def", "forward", "(", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertAttention.forward": [[150, 201], ["my_transformers.MyBertAttention.self", "my_transformers.MyBertAttention.output", "my_transformers.MyBertAttention.output", "my_transformers.MyBertAttention.output", "my_transformers.MyBertAttention.output", "my_transformers.MyBertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "\n", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", "\n", ")", "\n", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "attention_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "attention_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "", "else", ":", "\n", "                ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "", "", "else", ":", "\n", "            ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "outputs", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "outputs", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "outputs", "\n", "", "else", ":", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.__init__": [[204, 225], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "getattr", "ValueError", "torch.nn.Embedding", "torch.nn.Embedding", "hasattr"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "self", ".", "max_position_embeddings", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "distance_embedding", "=", "nn", ".", "Embedding", "(", "2", "*", "config", ".", "max_position_embeddings", "-", "1", ",", "self", ".", "attention_head_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.transpose_for_scores": [[226, 230], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.forward": [[231, 300], ["my_transformers.BertSelfAttention.query", "my_transformers.BertSelfAttention.transpose_for_scores", "my_transformers.BertSelfAttention.transpose_for_scores", "my_transformers.BertSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "my_transformers.BertSelfAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "my_transformers.BertSelfAttention.key", "my_transformers.BertSelfAttention.value", "my_transformers.BertSelfAttention.key", "my_transformers.BertSelfAttention.value", "my_transformers.BertSelfAttention.transpose", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "my_transformers.BertSelfAttention.distance_embedding", "positional_embedding.to.to.to", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "hidden_states.size", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "context_layer.view.view.permute", "context_layer.view.view.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "encoder_hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "seq_length", "=", "hidden_states", ".", "size", "(", ")", "[", "1", "]", "\n", "position_ids_l", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "position_ids_r", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "distance", "=", "position_ids_l", "-", "position_ids_r", "\n", "positional_embedding", "=", "self", ".", "distance_embedding", "(", "distance", "+", "self", ".", "max_position_embeddings", "-", "1", ")", "\n", "positional_embedding", "=", "positional_embedding", ".", "to", "(", "dtype", "=", "query_layer", ".", "dtype", ")", "# fp16 compatibility", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", ":", "\n", "                ", "relative_position_scores", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores", "\n", "", "elif", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "                ", "relative_position_scores_query", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "relative_position_scores_key", "=", "torch", ".", "einsum", "(", "\"bhrd,lrd->bhlr\"", ",", "key_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores_query", "+", "relative_position_scores_key", "\n", "\n", "", "", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertOutput.__init__": [[302, 329], ["transformers.models.bert.modeling_bert.BertOutput.__init__", "print", "adapters.BertAdapter", "adapters.BertAdapterUcl", "adapters.BertAdapterOwm", "adapters.BertAdapterMask", "BertAdapterCapsuleMask", "BertAdapterCapsule"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "args", ".", "use_imp", ":", "\n", "            ", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleMaskImp", "as", "BertAdapterCapsuleMask", "\n", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleImp", "as", "BertAdapterCapsule", "\n", "", "else", ":", "\n", "            ", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsuleMask", "\n", "from", "networks", ".", "base", ".", "adapters", "import", "BertAdapterCapsule", "\n", "\n", "\n", "", "if", "args", ".", "apply_bert_output", ":", "\n", "            ", "print", "(", "'apply to output'", ")", "\n", "if", "args", ".", "build_adapter", ":", "\n", "                ", "self", ".", "adapter", "=", "BertAdapter", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_ucl", ":", "\n", "                ", "self", ".", "adapter_ucl", "=", "BertAdapterUcl", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_owm", ":", "\n", "                ", "self", ".", "adapter_owm", "=", "BertAdapterOwm", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_mask", ":", "\n", "                ", "self", ".", "adapter_mask", "=", "BertAdapterMask", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "self", ".", "adapter_capsule_mask", "=", "BertAdapterCapsuleMask", "(", "args", ")", "\n", "", "elif", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "self", ".", "adapter_capsule", "=", "BertAdapterCapsule", "(", "args", ")", "\n", "\n", "", "", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertOutput.forward": [[330, 374], ["my_transformers.MyBertOutput.dense", "my_transformers.MyBertOutput.dropout", "my_transformers.MyBertOutput.LayerNorm", "my_transformers.MyBertOutput.adapter", "my_transformers.MyBertOutput.adapter_ucl", "my_transformers.MyBertOutput.adapter_owm", "my_transformers.MyBertOutput.adapter_mask", "my_transformers.MyBertOutput.adapter_capsule_mask", "my_transformers.MyBertOutput.adapter_capsule"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "**", "kwargs", ")", ":", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter", "(", "hidden_states", ")", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_ucl", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_ucl", "(", "hidden_states", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "self", ".", "adapter_owm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_mask", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_mask", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "self", ".", "adapter_capsule_mask", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "hidden_states", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "hidden_states", "=", "self", ".", "adapter_capsule", "(", "hidden_states", ",", "t", ",", "s", ")", "\n", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "hidden_states", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "hidden_states", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "hidden_states", "\n", "", "else", ":", "\n", "            ", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertLayer.__init__": [[377, 385], ["transformers.models.bert.modeling_bert.BertLayer.__init__", "my_transformers.MyBertAttention", "my_transformers.MyBertOutput", "my_transformers.MyBertAttention"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "MyBertAttention", "(", "config", ",", "args", ")", "\n", "if", "self", ".", "add_cross_attention", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "f\"{self} should be used as a decoder model if cross attention is added\"", "\n", "self", ".", "crossattention", "=", "MyBertAttention", "(", "config", ",", "args", ")", "\n", "", "self", ".", "output", "=", "MyBertOutput", "(", "config", ",", "args", ")", "\n", "self", ".", "args", "=", "args", "\n", "", "def", "forward", "(", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertLayer.forward": [[385, 505], ["my_transformers.MyBertLayer.attention", "hasattr", "my_transformers.MyBertLayer.crossattention", "my_transformers.apply_chunking_to_forward", "my_transformers.MyBertLayer.attention", "my_transformers.apply_chunking_to_forward", "my_transformers.MyBertLayer.attention", "my_transformers.apply_chunking_to_forward", "h_list.append", "x_list.append", "my_transformers.MyBertLayer.attention", "my_transformers.MyBertLayer.attention", "my_transformers.apply_chunking_to_forward", "my_transformers.apply_chunking_to_forward"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "if", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", "\n", ")", "\n", "self_attention_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "self_attention_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "", "", "else", ":", "\n", "\n", "            ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"crossattention\"", "\n", ")", ",", "f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"", "\n", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "# add cross attentions if we output attention weights", "\n", "\n", "", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "layer_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ")", "\n", "layer_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "h_list", ".", "append", "(", "output_dict", "[", "'h_list'", "]", ")", "\n", "x_list", ".", "append", "(", "output_dict", "[", "'x_list'", "]", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "\n", "", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "if", "self", ".", "args", ".", "apply_bert_output", "or", "self", ".", "args", ".", "apply_bert_attention_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "outputs", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "outputs", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "outputs", "\n", "", "else", ":", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertLayer.feed_forward_chunk": [[506, 538], ["my_transformers.MyBertLayer.intermediate", "my_transformers.MyBertLayer.output", "my_transformers.MyBertLayer.output", "my_transformers.MyBertLayer.output", "my_transformers.MyBertLayer.output", "my_transformers.MyBertLayer.output"], "methods", ["None"], ["", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ",", "\n", "t", "=", "None", ",", "s", "=", "1", ",", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "\n", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "layer_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", ")", "\n", "layer_output", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", ")", "\n", "\n", "", "else", ":", "\n", "                ", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", ")", "\n", "", "if", "self", ".", "args", ".", "apply_bert_output", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "layer_output", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "layer_output", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "layer_output", "\n", "", "else", ":", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertEncoder.__init__": [[541, 545], ["transformers.models.bert.modeling_bert.BertEncoder.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "my_transformers.MyBertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "MyBertLayer", "(", "config", ",", "args", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "self", ".", "args", "=", "args", "\n", "", "def", "compute_layer_outputs", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertEncoder.compute_layer_outputs": [[545, 626], ["getattr", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "my_transformers.MyBertEncoder.compute_layer_outputs.create_custom_forward"], "methods", ["None"], ["", "def", "compute_layer_outputs", "(", "self", ",", "\n", "output_attentions", ",", "layer_module", ",", "\n", "hidden_states", ",", "attention_mask", ",", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "**", "kwargs", ")", ":", "\n", "\n", "# add parameters --------------", "\n", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "\n", "\n", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", ":", "\n", "            ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                    ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "layer_module", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "                ", "output_dict", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", "\n", ")", "\n", "layer_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", ".", "append", "(", "output_dict", "[", "'x_list'", "]", ")", "\n", "h_list", ".", "append", "(", "output_dict", "[", "'h_list'", "]", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "                ", "output_dict", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "layer_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "\n", "", "", "return", "layer_outputs", ",", "x_list", ",", "h_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertEncoder.forward": [[627, 681], ["enumerate", "transformers.modeling_outputs.BaseModelOutputWithCrossAttentions", "my_transformers.MyBertEncoder.compute_layer_outputs", "tuple", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertEncoder.compute_layer_outputs"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "True", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_self_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "output_attentions", "and", "self", ".", "config", ".", "add_cross_attention", "else", "None", "\n", "\n", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_head_mask", "=", "head_mask", "[", "i", "]", "if", "head_mask", "is", "not", "None", "else", "None", "\n", "layer_outputs", ",", "x_list", ",", "h_list", "=", "self", ".", "compute_layer_outputs", "(", "\n", "output_attentions", ",", "layer_module", ",", "\n", "hidden_states", ",", "attention_mask", ",", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ",", "x_list", "=", "x_list", ",", "h_list", "=", "h_list", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "output_attentions", ":", "\n", "                ", "all_self_attentions", "=", "all_self_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "if", "self", ".", "config", ".", "add_cross_attention", ":", "\n", "                    ", "all_cross_attentions", "=", "all_cross_attentions", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "\n", "", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "all_hidden_states", ",", "all_self_attentions", ",", "all_cross_attentions", "]", "if", "v", "is", "not", "None", ")", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "all_hidden_states", ",", "all_self_attentions", ",", "all_cross_attentions", "]", "if", "v", "is", "not", "None", ")", ",", "'h_list'", ":", "h_list", ",", "'x_list'", ":", "x_list", "}", "\n", "else", ":", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "all_hidden_states", ",", "all_self_attentions", ",", "all_cross_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "BaseModelOutputWithCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "all_hidden_states", ",", "attentions", "=", "all_self_attentions", ",", "cross_attentions", "=", "all_cross_attentions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertModel.__init__": [[698, 703], ["transformers.models.bert.modeling_bert.BertModel.__init__", "my_transformers.MyBertEncoder", "my_transformers.MyBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "args", ",", "add_pooling_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "encoder", "=", "MyBertEncoder", "(", "config", ",", "args", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertModel.forward": [[704, 810], ["my_transformers.MyBertModel.get_extended_attention_mask", "my_transformers.MyBertModel.get_head_mask", "my_transformers.MyBertModel.embeddings", "my_transformers.MyBertModel.compute_encoder_outputs", "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "encoder_hidden_states.size", "my_transformers.MyBertModel.invert_attention_mask", "my_transformers.MyBertModel.pooler", "input_ids.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "inputs_embeds.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertModel.compute_encoder_outputs"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "\n", "        ", "r\"\"\"\n        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n            the model is configured as a decoder.\n        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n\n            - 1 for tokens that are **not masked**,\n            - 0 for tokens that are **masked**.\n        \"\"\"", "\n", "\n", "# add parameters --------------", "\n", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "x_list", "=", "[", "]", "#accumulate for every forward pass", "\n", "h_list", "=", "[", "]", "\n", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "\n", "# If a 2D or 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_hidden_layers", ")", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "\n", "encoder_outputs", ",", "x_list", ",", "h_list", "=", "self", ".", "compute_encoder_outputs", "(", "\n", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", ",", "\n", "encoder_hidden_states", ",", "encoder_extended_attention_mask", ",", "output_attentions", ",", "\n", "output_hidden_states", ",", "return_dict", ",", "t", "=", "t", ",", "s", "=", "s", ",", "x_list", "=", "x_list", ",", "h_list", "=", "h_list", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "if", "self", ".", "pooler", "is", "not", "None", "else", "None", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "if", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "return", "{", "'outputs'", ":", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "}", "\n", "elif", "self", ".", "args", ".", "build_adapter_owm", ":", "return", "{", "'outputs'", ":", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "else", ":", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPoolingAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "encoder_outputs", ".", "cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.MyBertModel.compute_encoder_outputs": [[812, 880], ["my_transformers.MyBertModel.encoder", "my_transformers.MyBertModel.encoder", "my_transformers.MyBertModel.encoder", "my_transformers.MyBertModel.encoder"], "methods", ["None"], ["", "def", "compute_encoder_outputs", "(", "self", ",", "\n", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", ",", "\n", "encoder_hidden_states", ",", "encoder_extended_attention_mask", ",", "output_attentions", ",", "\n", "output_hidden_states", ",", "return_dict", ",", "**", "kwargs", ")", ":", "\n", "\n", "\n", "# add parameters --------------", "\n", "        ", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "if", "self", ".", "args", ".", "build_adapter_owm", ":", "\n", "            ", "output_dict", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "x_list", "=", "x_list", ",", "h_list", "=", "h_list", "\n", ")", "\n", "\n", "encoder_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "x_list", "=", "output_dict", "[", "'x_list'", "]", "\n", "h_list", "=", "output_dict", "[", "'h_list'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule_mask", ":", "\n", "            ", "output_dict", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "\n", "encoder_outputs", "=", "output_dict", "[", "'outputs'", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "build_adapter_capsule", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "t", "=", "t", ",", "s", "=", "s", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "t", "=", "t", ",", "s", "=", "s", "\n", ")", "\n", "\n", "", "return", "encoder_outputs", ",", "x_list", ",", "h_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_transformers.apply_chunking_to_forward": [[885, 962], ["all", "forward_fn", "len", "tuple", "tuple", "torch.cat", "torch.cat", "input_tensor.chunk", "forward_fn", "zip"], "function", ["None"], ["def", "apply_chunking_to_forward", "(", "\n", "forward_fn", ":", "Callable", "[", "...", ",", "torch", ".", "Tensor", "]", ",", "chunk_size", ":", "int", ",", "chunk_dim", ":", "int", ",", "*", "input_tensors", ",", "**", "kwargs", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    This function chunks the :obj:`input_tensors` into smaller input tensor parts of size :obj:`chunk_size` over the\n    dimension :obj:`chunk_dim`. It then applies a layer :obj:`forward_fn` to each chunk independently to save memory.\n\n    If the :obj:`forward_fn` is independent across the :obj:`chunk_dim` this function will yield the same result as\n    directly applying :obj:`forward_fn` to :obj:`input_tensors`.\n\n    Args:\n        forward_fn (:obj:`Callable[..., torch.Tensor]`):\n            The forward function of the model.\n        chunk_size (:obj:`int`):\n            The chunk size of a chunked tensor: :obj:`num_chunks = len(input_tensors[0]) / chunk_size`.\n        chunk_dim (:obj:`int`):\n            The dimension over which the :obj:`input_tensors` should be chunked.\n        input_tensors (:obj:`Tuple[torch.Tensor]`):\n            The input tensors of ``forward_fn`` which will be chunked\n\n    Returns:\n        :obj:`torch.Tensor`: A tensor with the same shape as the :obj:`forward_fn` would have given if applied`.\n\n\n    Examples::\n\n        # rename the usual forward() fn to forward_chunk()\n        def forward_chunk(self, hidden_states):\n            hidden_states = self.decoder(hidden_states)\n            return hidden_states\n\n        # implement a chunked forward function\n        def forward(self, hidden_states):\n            return apply_chunking_to_forward(self.forward_chunk, self.chunk_size_lm_head, self.seq_len_dim, hidden_states)\n    \"\"\"", "\n", "\n", "# add parameters --------------", "\n", "s", ",", "t", ",", "x_list", ",", "h_list", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "'t'", "in", "kwargs", ":", "t", "=", "kwargs", "[", "'t'", "]", "\n", "if", "'s'", "in", "kwargs", ":", "s", "=", "kwargs", "[", "'s'", "]", "\n", "if", "'x_list'", "in", "kwargs", ":", "x_list", "=", "kwargs", "[", "'x_list'", "]", "\n", "if", "'h_list'", "in", "kwargs", ":", "h_list", "=", "kwargs", "[", "'h_list'", "]", "\n", "# other parameters --------------", "\n", "\n", "\n", "assert", "len", "(", "input_tensors", ")", ">", "0", ",", "\"{} has to be a tuple/list of tensors\"", ".", "format", "(", "input_tensors", ")", "\n", "tensor_shape", "=", "input_tensors", "[", "0", "]", ".", "shape", "[", "chunk_dim", "]", "\n", "assert", "all", "(", "\n", "input_tensor", ".", "shape", "[", "chunk_dim", "]", "==", "tensor_shape", "for", "input_tensor", "in", "input_tensors", "\n", ")", ",", "\"All input tenors have to be of the same shape\"", "\n", "\n", "# inspect.signature exist since python 3.5 and is a python method -> no problem with backward compatibility", "\n", "# num_args_in_forward_chunk_fn = len(inspect.signature(forward_fn).parameters)", "\n", "# assert num_args_in_forward_chunk_fn == len(", "\n", "#     input_tensors", "\n", "# ), \"forward_chunk_fn expects {} arguments, but only {} input tensors are given\".format(", "\n", "#     num_args_in_forward_chunk_fn, len(input_tensors)", "\n", "# )", "\n", "\n", "if", "chunk_size", ">", "0", ":", "\n", "        ", "assert", "(", "\n", "input_tensors", "[", "0", "]", ".", "shape", "[", "chunk_dim", "]", "%", "chunk_size", "==", "0", "\n", ")", ",", "\"The dimension to be chunked {} has to be a multiple of the chunk size {}\"", ".", "format", "(", "\n", "input_tensors", "[", "0", "]", ".", "shape", "[", "chunk_dim", "]", ",", "chunk_size", "\n", ")", "\n", "\n", "num_chunks", "=", "input_tensors", "[", "0", "]", ".", "shape", "[", "chunk_dim", "]", "//", "chunk_size", "\n", "\n", "# chunk input tensor into tuples", "\n", "input_tensors_chunks", "=", "tuple", "(", "input_tensor", ".", "chunk", "(", "num_chunks", ",", "dim", "=", "chunk_dim", ")", "for", "input_tensor", "in", "input_tensors", ")", "\n", "# apply forward fn to every tuple", "\n", "output_chunks", "=", "tuple", "(", "forward_fn", "(", "*", "input_tensors_chunk", ",", "t", "=", "t", ",", "s", "=", "s", ")", "for", "input_tensors_chunk", "in", "zip", "(", "*", "input_tensors_chunks", ")", ")", "\n", "# concatenate output at same dimension", "\n", "return", "torch", ".", "cat", "(", "output_chunks", ",", "dim", "=", "chunk_dim", ")", "\n", "\n", "", "return", "forward_fn", "(", "*", "input_tensors", ",", "\n", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.__init__": [[29, 34], ["object.__init__", "mu.cuda", "rho.cuda", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "mu", ",", "rho", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mu", "=", "mu", ".", "cuda", "(", ")", "\n", "self", ".", "rho", "=", "rho", ".", "cuda", "(", ")", "\n", "self", ".", "normal", "=", "torch", ".", "distributions", ".", "Normal", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sigma": [[35, 38], ["torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "@", "property", "\n", "def", "sigma", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "self", ".", "rho", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample": [[39, 42], ["bayes_layer.Gaussian.normal.sample().cuda", "bayes_layer.Gaussian.normal.sample", "bayes_layer.Gaussian.mu.size"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "epsilon", "=", "self", ".", "normal", ".", "sample", "(", "self", ".", "mu", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "return", "self", ".", "mu", "+", "self", ".", "sigma", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.BayesianLinear.__init__": [[44, 68], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "bayes_layer._calculate_fan_in_and_fan_out", "numpy.log", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "bayes_layer.Gaussian", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "numpy.exp", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "ratio", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "\n", "fan_in", ",", "_", "=", "_calculate_fan_in_and_fan_out", "(", "self", ".", "weight_mu", ")", "\n", "gain", "=", "1", "# Var[w] + sigma^2 = 2/fan_in", "\n", "\n", "total_var", "=", "2", "/", "fan_in", "\n", "noise_var", "=", "total_var", "*", "ratio", "\n", "mu_var", "=", "total_var", "-", "noise_var", "\n", "\n", "noise_std", ",", "mu_std", "=", "math", ".", "sqrt", "(", "noise_var", ")", ",", "math", ".", "sqrt", "(", "mu_var", ")", "\n", "bound", "=", "math", ".", "sqrt", "(", "3.0", ")", "*", "mu_std", "\n", "rho_init", "=", "np", ".", "log", "(", "np", ".", "exp", "(", "noise_std", ")", "-", "1", ")", "\n", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight_mu", ",", "-", "bound", ",", "bound", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ".", "uniform_", "(", "0", ",", "0", ")", ")", "\n", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "1", ")", ".", "uniform_", "(", "rho_init", ",", "rho_init", ")", ")", "\n", "\n", "self", ".", "weight", "=", "Gaussian", "(", "self", ".", "weight_mu", ",", "self", ".", "weight_rho", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.BayesianLinear.forward": [[69, 78], ["torch.linear", "torch.linear", "torch.linear", "bayes_layer.BayesianLinear.weight.sample"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample"], ["", "def", "forward", "(", "self", ",", "input", ",", "sample", "=", "False", ")", ":", "\n", "        ", "if", "sample", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "sample", "(", ")", "\n", "bias", "=", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "mu", "\n", "bias", "=", "self", ".", "bias", "\n", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._BayesianConvNd.__init__": [[81, 121], ["torch.Module.__init__", "hasattr", "bayes_layer._calculate_fan_in_and_fan_out", "numpy.log", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "bayes_layer.Gaussian", "ValueError", "ValueError", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.exp", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "stride", ",", "padding", ",", "dilation", ",", "transposed", ",", "output_padding", ",", "groups", ",", "bias", ",", "ratio", ")", ":", "\n", "        ", "super", "(", "_BayesianConvNd", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "in_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'in_channels must be divisible by groups'", ")", "\n", "", "if", "out_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'out_channels must be divisible by groups'", ")", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "transposed", "=", "transposed", "\n", "self", ".", "output_padding", "=", "output_padding", "\n", "self", ".", "groups", "=", "groups", "\n", "\n", "# print(kernel_size)", "\n", "if", "hasattr", "(", "kernel_size", ",", "'__iter__'", ")", ":", "\n", "            ", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "kernel_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "kernel_size", ")", ")", "\n", "\n", "# print(self.weight_mu.size())", "\n", "\n", "", "_", ",", "fan_out", "=", "_calculate_fan_in_and_fan_out", "(", "self", ".", "weight_mu", ")", "\n", "total_var", "=", "2", "/", "fan_out", "\n", "noise_var", "=", "total_var", "*", "ratio", "\n", "mu_var", "=", "total_var", "-", "noise_var", "\n", "\n", "noise_std", ",", "mu_std", "=", "math", ".", "sqrt", "(", "noise_var", ")", ",", "math", ".", "sqrt", "(", "mu_var", ")", "\n", "bound", "=", "math", ".", "sqrt", "(", "3.0", ")", "*", "mu_std", "\n", "rho_init", "=", "np", ".", "log", "(", "np", ".", "exp", "(", "noise_std", ")", "-", "1", ")", "\n", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight_mu", ",", "-", "bound", ",", "bound", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ".", "uniform_", "(", "0", ",", "0", ")", ",", "requires_grad", "=", "bias", ")", "\n", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ",", "1", ",", "1", ",", "1", ")", ".", "uniform_", "(", "rho_init", ",", "rho_init", ")", ")", "\n", "\n", "self", ".", "weight", "=", "Gaussian", "(", "self", ".", "weight_mu", ",", "self", ".", "weight_rho", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.BayesianConv2D.__init__": [[124, 132], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "bayes_layer._BayesianConvNd.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "ratio", "=", "0.25", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "BayesianConv2D", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "stride", ",", "padding", ",", "dilation", ",", "False", ",", "_pair", "(", "0", ")", ",", "groups", ",", "bias", ",", "ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.BayesianConv2D.forward": [[133, 141], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "bayes_layer.BayesianConv2D.weight.sample"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample"], ["", "def", "forward", "(", "self", ",", "input", ",", "sample", "=", "False", ")", ":", "\n", "        ", "if", "sample", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "sample", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "mu", "\n", "\n", "", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer._calculate_fan_in_and_fan_out": [[9, 27], ["tensor.dim", "ValueError", "tensor.size", "tensor.size", "tensor.size", "tensor.size", "tensor.dim", "[].numel"], "function", ["None"], ["def", "_calculate_fan_in_and_fan_out", "(", "tensor", ")", ":", "\n", "    ", "dimensions", "=", "tensor", ".", "dim", "(", ")", "\n", "if", "dimensions", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\"", ")", "\n", "\n", "", "if", "dimensions", "==", "2", ":", "# Linear", "\n", "        ", "fan_in", "=", "tensor", ".", "size", "(", "1", ")", "\n", "fan_out", "=", "tensor", ".", "size", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "num_input_fmaps", "=", "tensor", ".", "size", "(", "1", ")", "\n", "num_output_fmaps", "=", "tensor", ".", "size", "(", "0", ")", "\n", "receptive_field_size", "=", "1", "\n", "if", "tensor", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "receptive_field_size", "=", "tensor", "[", "0", "]", "[", "0", "]", ".", "numel", "(", ")", "\n", "", "fan_in", "=", "num_input_fmaps", "*", "receptive_field_size", "\n", "fan_out", "=", "num_output_fmaps", "*", "receptive_field_size", "\n", "\n", "", "return", "fan_in", ",", "fan_out", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapter.__init__": [[14, 21], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", ",", "config", ".", "bert_adapter_size", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_adapter_size", ",", "config", ".", "bert_hidden_size", ")", "\n", "if", "config", ".", "use_gelu", ":", "self", ".", "activation", "=", "torch", ".", "nn", ".", "GELU", "(", ")", "\n", "else", ":", "self", ".", "activation", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "print", "(", "'BertAdapter'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapter.forward": [[22, 28], ["adapters.BertAdapter.activation", "adapters.BertAdapter.activation", "adapters.BertAdapter.fc1", "adapters.BertAdapter.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "h", "=", "self", ".", "activation", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "\n", "return", "x", "+", "h", "\n", "# return h", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapter.squash": [[30, 35], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "squash", "(", "self", ",", "input_tensor", ",", "dim", "=", "-", "1", ",", "epsilon", "=", "1e-16", ")", ":", "# 0 will happen in our case, has to add an epsilon", "\n", "        ", "squared_norm", "=", "(", "input_tensor", "**", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "squared_norm", "=", "squared_norm", "+", "epsilon", "\n", "scale", "=", "squared_norm", "/", "(", "1", "+", "squared_norm", ")", "\n", "return", "scale", "*", "input_tensor", "/", "torch", ".", "sqrt", "(", "squared_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.__init__": [[38, 46], ["adapters.BertAdapter.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "efc1", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_adapter_size", ")", "\n", "self", ".", "efc2", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "print", "(", "'BertAdapterMask'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.forward": [[48, 54], ["adapters.BertAdapterMask.mask", "adapters.BertAdapterMask.get_feature"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature"], ["", "def", "forward", "(", "self", ",", "x", ",", "t", ",", "s", ")", ":", "\n", "\n", "        ", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "h", "=", "self", ".", "get_feature", "(", "gfc1", ",", "gfc2", ",", "x", ")", "\n", "\n", "return", "x", "+", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.get_feature": [[56, 64], ["adapters.BertAdapterMask.activation", "adapters.BertAdapterMask.activation", "adapters.BertAdapterMask.fc1", "gfc1.expand_as", "adapters.BertAdapterMask.fc2", "gfc2.expand_as"], "methods", ["None"], ["", "def", "get_feature", "(", "self", ",", "gfc1", ",", "gfc2", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "activation", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "return", "h", "\n", "", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.mask": [[64, 73], ["adapters.BertAdapterMask.efc1", "adapters.BertAdapterMask.efc2", "adapters.BertAdapterMask.gate", "adapters.BertAdapterMask.gate", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "def", "mask", "(", "self", ",", "t", ",", "s", "=", "1", ")", ":", "\n", "\n", "       ", "efc1", "=", "self", ".", "efc1", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", "\n", "efc2", "=", "self", ".", "efc2", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "gfc1", "=", "self", ".", "gate", "(", "s", "*", "efc1", ")", "\n", "gfc2", "=", "self", ".", "gate", "(", "s", "*", "efc2", ")", "\n", "\n", "return", "[", "gfc1", ",", "gfc2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterMask.my_softmax": [[75, 79], ["input.transpose", "torch.softmax", "torch.softmax", "torch.softmax.view().transpose", "input.transpose.contiguous().view", "len", "input.transpose.size", "torch.softmax.view", "len", "input.size", "input.transpose.contiguous", "input.size", "input.transpose.size"], "methods", ["None"], ["", "def", "my_softmax", "(", "self", ",", "input", ",", "dim", "=", "1", ")", ":", "\n", "        ", "transposed_input", "=", "input", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "softmaxed_output", "=", "F", ".", "softmax", "(", "transposed_input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "transposed_input", ".", "size", "(", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "softmaxed_output", ".", "view", "(", "*", "transposed_input", ".", "size", "(", ")", ")", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleMaskImp.__init__": [[90, 98], ["adapters.BertAdapterMask.__init__", "adapters.CapsNetImp", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "capsule_net", "=", "CapsNetImp", "(", "config", ")", "\n", "# self.fc1=torch.nn.Linear(semantic_cap_size,adapter_size)", "\n", "self", ".", "gelu", "=", "torch", ".", "nn", ".", "GELU", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "print", "(", "'BertAdapterCapsuleMaskImp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleMaskImp.forward": [[100, 125], ["adapters.BertAdapterCapsuleMaskImp.capsule_net", "adapters.BertAdapterCapsuleMaskImp.mask", "adapters.BertAdapterCapsuleMaskImp.gelu", "adapters.BertAdapterCapsuleMaskImp.gelu", "adapters.BertAdapterCapsuleMaskImp.activation", "adapters.BertAdapterCapsuleMaskImp.activation", "adapters.BertAdapterCapsuleMaskImp.fc1", "gfc1.expand_as", "adapters.BertAdapterCapsuleMaskImp.fc2", "gfc2.expand_as", "adapters.BertAdapterCapsuleMaskImp.fc1", "gfc1.expand_as", "adapters.BertAdapterCapsuleMaskImp.fc2", "gfc2.expand_as"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "x", ",", "t", ",", "s", ")", ":", "\n", "# task shared", "\n", "        ", "capsule_output", "=", "self", ".", "capsule_net", "(", "t", ",", "x", ",", "s", ")", "\n", "\n", "\n", "h", "=", "x", "+", "capsule_output", "#skip-connection", "\n", "\n", "# task specifc", "\n", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "if", "self", ".", "config", ".", "use_gelu", ":", "\n", "            ", "h", "=", "self", ".", "gelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "gelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "", "else", ":", "\n", "            ", "h", "=", "self", ".", "activation", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "", "return", "{", "'outputs'", ":", "x", "+", "h", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsNetImp.__init__": [[128, 140], ["torch.nn.Module.__init__", "adapters.CapsuleLayerImp", "adapters.CapsuleLayerImp", "print", "adapters.CapsuleLayerImp", "adapters.CapsuleLayerImp"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "semantic_capsules", "=", "CapsuleLayerImp", "(", "config", ",", "'semantic'", ")", "\n", "if", "config", ".", "transfer_route", ":", "\n", "            ", "self", ".", "transfer_capsules", "=", "CapsuleLayerImp", "(", "config", ",", "'transfer_route'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "transfer_capsules", "=", "CapsuleLayerImp", "(", "config", ",", "'transfer'", ")", "\n", "\n", "", "self", ".", "tsv_capsules", "=", "CapsuleLayerImp", "(", "config", ",", "'tsv'", ")", "\n", "self", ".", "config", "=", "config", "\n", "print", "(", "'CapsNet'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsNetImp.forward": [[141, 150], ["adapters.CapsNetImp.semantic_capsules", "adapters.CapsNetImp.tsv_capsules", "adapters.CapsNetImp.transfer_capsules", "adapters.CapsNetImp.transfer_capsules"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", ")", ":", "\n", "        ", "semantic_output", "=", "self", ".", "semantic_capsules", "(", "t", ",", "x", ",", "s", ",", "'semantic'", ")", "\n", "if", "self", ".", "config", ".", "transfer_route", ":", "\n", "            ", "transfer_output", "=", "self", ".", "transfer_capsules", "(", "t", ",", "semantic_output", ",", "s", ",", "'transfer_route'", ")", "\n", "", "else", ":", "\n", "            ", "transfer_output", "=", "self", ".", "transfer_capsules", "(", "t", ",", "semantic_output", ",", "s", ",", "'transfer'", ")", "\n", "\n", "", "tsv_output", "=", "self", ".", "tsv_capsules", "(", "t", ",", "transfer_output", ",", "s", ",", "'tsv'", ")", "\n", "return", "tsv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayerImp.__init__": [[152, 262], ["torch.nn.Module.__init__", "print", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Parameter", "torch.nn.Parameter", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "range", "range", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "layer_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "layer_type", "==", "'semantic'", ":", "\n", "            ", "if", "config", ".", "apply_one_layer_shared", ":", "\n", "                ", "print", "(", "'apply_one_layer_shared '", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", ",", "config", ".", "semantic_cap_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "\n", "", "elif", "config", ".", "apply_two_layer_shared", ":", "\n", "                ", "print", "(", "'apply_two_layer_shared '", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", ",", "config", ".", "mid_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "mid_size", ",", "config", ".", "semantic_cap_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "", "print", "(", "'CapsuleLayer'", ")", "\n", "self", ".", "gelu", "=", "torch", ".", "nn", ".", "GELU", "(", ")", "\n", "\n", "", "elif", "layer_type", "==", "'transfer'", ":", "\n", "            ", "D", "=", "config", ".", "semantic_cap_size", "\n", "self", ".", "Co", "=", "config", ".", "max_seq_length", "\n", "\n", "if", "config", ".", "semantic_cap_size", "==", "2", ":", "\n", "                ", "Ks", "=", "[", "3", ",", "4", "]", "\n", "", "elif", "config", ".", "semantic_cap_size", "==", "3", ":", "\n", "                ", "Ks", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "", "elif", "config", ".", "semantic_cap_size", "==", "4", ":", "\n", "                ", "Ks", "=", "[", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n", "", "self", ".", "len_ks", "=", "len", "(", "Ks", ")", "\n", "self", ".", "convs1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "self", ".", "Co", ",", "K", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs2", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "self", ".", "Co", ",", "K", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs3", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "self", ".", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "fc_aspect", "=", "nn", ".", "Linear", "(", "self", ".", "Co", "*", "self", ".", "len_ks", ",", "self", ".", "Co", ")", "\n", "\n", "", "elif", "layer_type", "==", "'tsv'", ":", "\n", "            ", "self", ".", "num_routes", "=", "config", ".", "ntasks", "\n", "self", ".", "num_capsules", "=", "config", ".", "semantic_cap_size", "\n", "self", ".", "class_dim", "=", "config", ".", "max_seq_length", "\n", "self", ".", "in_channel", "=", "config", ".", "max_seq_length", "*", "config", ".", "semantic_cap_size", "\n", "# self.in_channel = 100", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "num_iterations", "=", "3", "\n", "\n", "#no routing for max_seq_length", "\n", "self", ".", "route_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "config", ".", "num_semantic_cap", ",", "self", ".", "num_routes", ",", "config", ".", "semantic_cap_size", ",", "config", ".", "semantic_cap_size", ")", ")", "\n", "\n", "if", "config", ".", "exp", "in", "[", "'2layer_whole'", ",", "'2layer_aspect_transfer'", "]", ":", "\n", "                ", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "larger", "=", "torch", ".", "nn", ".", "Linear", "(", "3", "*", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "#each task has its own larger way", "\n", "", "else", ":", "\n", "                ", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "larger", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "semantic_cap_size", "*", "config", ".", "num_semantic_cap", ",", "config", ".", "bert_hidden_size", ")", "#each task has its own larger way", "\n", "\n", "", "if", "config", ".", "no_tsv_mask", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "", "else", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "\n", "\n", "\n", "", "", "elif", "layer_type", "==", "'transfer_route'", ":", "\n", "\n", "            ", "D", "=", "config", ".", "semantic_cap_size", "*", "config", ".", "num_semantic_cap", "\n", "self", ".", "Co", "=", "100", "\n", "\n", "Ks", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "\n", "self", ".", "len_ks", "=", "len", "(", "Ks", ")", "\n", "\n", "# self.convs1 = nn.ModuleList([nn.Conv1d(D, self.Co, K) for K in Ks])", "\n", "self", ".", "convs2", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "self", ".", "Co", ",", "K", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs3", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "self", ".", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "fc_cur", "=", "nn", ".", "Linear", "(", "self", ".", "Co", "*", "self", ".", "len_ks", ",", "self", ".", "Co", ")", "\n", "self", ".", "fc_sim", "=", "nn", ".", "Linear", "(", "300", ",", "config", ".", "num_semantic_cap", "*", "config", ".", "semantic_cap_size", ")", "\n", "self", ".", "convs4", "=", "nn", ".", "Conv1d", "(", "300", ",", "2", ",", "1", ")", "\n", "\n", "self", ".", "num_routes", "=", "config", ".", "ntasks", "\n", "self", ".", "num_capsules", "=", "config", ".", "semantic_cap_size", "\n", "self", ".", "class_dim", "=", "config", ".", "max_seq_length", "\n", "self", ".", "in_channel", "=", "config", ".", "max_seq_length", "*", "config", ".", "semantic_cap_size", "\n", "# self.in_channel = 100", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "#no routing for max_seq_length", "\n", "self", ".", "route_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "config", ".", "num_semantic_cap", ",", "self", ".", "num_routes", ",", "config", ".", "semantic_cap_size", ",", "config", ".", "semantic_cap_size", ")", ")", "\n", "\n", "if", "config", ".", "larger_as_list", ":", "\n", "                ", "self", ".", "larger", "=", "nn", ".", "ModuleList", "(", "[", "\n", "torch", ".", "nn", ".", "Linear", "(", "\n", "config", ".", "semantic_cap_size", "*", "config", ".", "num_semantic_cap", ",", "\n", "config", ".", "bert_hidden_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "#each task has its own larger way", "\n", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "# for capusle only", "\n", "\n", "", "elif", "config", ".", "larger_as_share", ":", "\n", "                ", "self", ".", "larger", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "semantic_cap_size", "*", "config", ".", "num_semantic_cap", ",", "config", ".", "bert_hidden_size", ")", "#each task has its own larger way", "\n", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "larger", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "semantic_cap_size", "*", "config", ".", "num_semantic_cap", ",", "config", ".", "bert_hidden_size", ")", "#each task has its own larger way", "\n", "\n", "\n", "\n", "", "if", "config", ".", "no_tsv_mask", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "", "else", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "\n", "", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayerImp.forward": [[263, 387], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "adapters.CapsuleLayerImp.squash", "x.transpose.transpose.size", "x.transpose.transpose.contiguous().view", "list", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vote_outputs.view", "fc1().view", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "feature.view.view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "z.view.view.view", "torch.cat.append", "torch.cat.append", "adapters.CapsuleLayerImp.convs4().squeeze", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.cat.append", "torch.cat.append", "x.transpose.transpose.size", "torch.cat.transpose", "torch.cat.transpose", "x.transpose.transpose.size", "fc2().view", "x.transpose.transpose.contiguous", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "adapters.CapsuleLayerImp.fc_sim().unsqueeze", "score.view", "adapters.CapsuleLayerImp.larger", "adapters.CapsuleLayerImp.larger", "adapters.CapsuleLayerImp.mask", "list", "aspect_v.contiguous().view.contiguous().view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "aspect_v.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc1", "x.transpose.transpose.size", "zip", "torch.cat.contiguous", "torch.cat.contiguous", "conv", "feature.view.view.contiguous", "adapters.CapsuleLayerImp.convs4", "adapters.CapsuleLayerImp.expand_as", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "x.transpose.transpose.size", "x.transpose.transpose.transpose", "x.transpose.transpose.contiguous().view", "adapters.CapsuleLayerImp.larger", "adapters.CapsuleLayerImp.mask", "fc2", "torch.cat.transpose", "torch.cat.transpose", "torch.max_pool1d", "torch.max_pool1d", "conv", "adapters.CapsuleLayerImp.fc_cur().unsqueeze", "torch.max_pool1d", "torch.max_pool1d", "adapters.CapsuleLayerImp.fc_sim", "torch.cat.repeat().view", "torch.cat.repeat().view", "conv", "feature.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "z.view.view.view", "aspect_v.contiguous().view.contiguous().view.contiguous", "adapters.CapsuleLayerImp.expand_as", "fc1", "a.size", "feature.view.view.transpose", "i.size", "z.view.view.squeeze", "adapters.CapsuleLayerImp.tsv[].data.view", "torch.cat.repeat().view", "torch.cat.repeat().view", "aspect_v.contiguous().view.contiguous().view.transpose", "torch.max_pool1d", "torch.max_pool1d", "torch.tanh", "torch.tanh", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "x.transpose.transpose.contiguous", "adapters.CapsuleLayerImp.fc_cur", "torch.cat.repeat", "torch.cat.repeat", "a.size", "conv", "zip", "torch.cat.repeat", "torch.cat.repeat", "feature.view.view.transpose", "conv", "adapters.CapsuleLayerImp.fc_aspect().unsqueeze", "torch.max_pool1d", "torch.max_pool1d", "feature.view.view.transpose", "i.size", "adapters.CapsuleLayerImp.fc_aspect"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.squash", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", ",", "layer_type", "=", "None", ")", ":", "\n", "\n", "        ", "if", "layer_type", "==", "'semantic'", ":", "\n", "\n", "            ", "if", "self", ".", "config", ".", "apply_one_layer_shared", ":", "\n", "                ", "outputs", "=", "[", "fc1", "(", "x", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "for", "fc1", "in", "self", ".", "fc1", "]", "\n", "", "elif", "self", ".", "config", ".", "apply_two_layer_shared", ":", "\n", "                ", "outputs", "=", "[", "fc2", "(", "fc1", "(", "x", ")", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "for", "fc1", ",", "fc2", "in", "zip", "(", "self", ".", "fc1", ",", "self", ".", "fc2", ")", "]", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "-", "1", ")", "#(B,cap_size,19)", "\n", "\n", "outputs", "=", "self", ".", "squash", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n", "", "elif", "layer_type", "==", "'transfer_route'", ":", "\n", "                ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "self", ".", "config", ".", "max_seq_length", ",", "-", "1", ",", "self", ".", "config", ".", "semantic_cap_size", ")", "\n", "\n", "priors", "=", "x", "[", "None", ",", ":", ",", ":", ",", "None", ",", ":", "]", "@", "self", ".", "route_weights", "[", ":", ",", "None", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "outputs_list", "=", "list", "(", "torch", ".", "unbind", "(", "priors", ",", "dim", "=", "2", ")", ")", "\n", "\n", "decision_maker", "=", "[", "]", "\n", "sim_attn", "=", "[", "]", "\n", "for", "pre_t", "in", "range", "(", "self", ".", "config", ".", "ntasks", ")", ":", "\n", "\n", "#Regarding ASC, for numberical stable, I change relu to gelu", "\n", "                        ", "cur_v", "=", "outputs_list", "[", "t", "]", "#current_task", "\n", "cur_v", "=", "cur_v", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "num_semantic_cap", "*", "self", ".", "config", ".", "semantic_cap_size", ")", "\n", "\n", "aa", "=", "[", "F", ".", "relu", "(", "conv", "(", "cur_v", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs3", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "aa", "=", "[", "F", ".", "max_pool1d", "(", "a", ",", "a", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "a", "in", "aa", "]", "\n", "cur_v", "=", "torch", ".", "cat", "(", "aa", ",", "1", ")", "\n", "\n", "feature", "=", "outputs_list", "[", "pre_t", "]", "\n", "feature", "=", "feature", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "num_semantic_cap", "*", "self", ".", "config", ".", "semantic_cap_size", ")", "\n", "# z = [F.tanh(conv(feature.transpose(1, 2))) for conv in self.convs1]  # [(N,Co,L), ...]*len(Ks)", "\n", "y", "=", "[", "F", ".", "relu", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", "+", "self", ".", "fc_cur", "(", "cur_v", ")", ".", "unsqueeze", "(", "2", ")", ")", "for", "conv", "in", "self", ".", "convs2", "]", "#mix information", "\n", "# z = [i*j for i, j in zip(z, y)]", "\n", "# z = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in z]  # [(N,Co), ...]*len(Ks)", "\n", "z", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "y", "]", "# [(N,Co), ...]*len(Ks)", "\n", "\n", "z", "=", "torch", ".", "cat", "(", "z", ",", "1", ")", "\n", "z", "=", "z", ".", "view", "(", "batch_size", ",", "self", ".", "Co", "*", "self", ".", "len_ks", ",", "1", ")", "\n", "sim_attn", ".", "append", "(", "self", ".", "fc_sim", "(", "z", ".", "squeeze", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "decision_learner", "=", "self", ".", "convs4", "(", "z", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "gumbel_one_hot", "=", "F", ".", "gumbel_softmax", "(", "decision_learner", ",", "hard", "=", "True", ")", "\n", "# _,score = gumbel_one_hot.max(1) #hard attention gate, but not differciable", "\n", "score", "=", "gumbel_one_hot", "[", ":", ",", "0", "]", "#hard attention gate, so that differeciable", "\n", "decision_maker", ".", "append", "(", "score", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "", "decision_maker", "=", "torch", ".", "cat", "(", "decision_maker", ",", "1", ")", "\n", "sim_attn", "=", "torch", ".", "cat", "(", "sim_attn", ",", "2", ")", "#TODO: Normalized the similarity", "\n", "\n", "vote_outputs", "=", "(", "self", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "\n", "sim_attn", ".", "repeat", "(", "self", ".", "config", ".", "max_seq_length", ",", "1", ",", "1", ")", "\n", ".", "view", "(", "self", ".", "config", ".", "num_semantic_cap", ",", "-", "1", ",", "self", ".", "config", ".", "ntasks", ",", "1", ",", "self", ".", "config", ".", "semantic_cap_size", ")", "*", "\n", "decision_maker", ".", "repeat", "(", "self", ".", "config", ".", "max_seq_length", ",", "1", ")", "\n", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "config", ".", "ntasks", ",", "1", ",", "1", ")", "*", "\n", "priors", ")", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "#route", "\n", "\n", "\n", "h_output", "=", "vote_outputs", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "-", "1", ")", "\n", "# print('h_output: ',h_output.size())", "\n", "if", "self", ".", "config", ".", "larger_as_list", ":", "\n", "                    ", "h_output", "=", "self", ".", "larger", "[", "t", "]", "(", "h_output", ")", "\n", "", "elif", "self", ".", "config", ".", "larger_as_share", ":", "\n", "                    ", "h_output", "=", "self", ".", "larger", "(", "h_output", ")", "\n", "", "else", ":", "\n", "                    ", "h_output", "=", "self", ".", "larger", "(", "h_output", ")", "\n", "glarger", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "h_output", "=", "h_output", "*", "glarger", ".", "expand_as", "(", "h_output", ")", "\n", "\n", "", "return", "h_output", "\n", "\n", "\n", "", "elif", "layer_type", "==", "'transfer'", ":", "\n", "            ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "config", ".", "exp", "in", "[", "'2layer_whole'", "]", ":", "#task,transfer,representation", "\n", "\n", "                ", "outputs_list", "=", "list", "(", "torch", ".", "unbind", "(", "x", ",", "dim", "=", "-", "1", ")", ")", "\n", "aspect_v", "=", "outputs_list", "[", "t", "]", "#current_task", "\n", "aspect_v", "=", "aspect_v", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "semantic_cap_size", ")", "\n", "\n", "aa", "=", "[", "F", ".", "relu", "(", "conv", "(", "aspect_v", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs3", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "aa", "=", "[", "F", ".", "max_pool1d", "(", "a", ",", "a", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "a", "in", "aa", "]", "\n", "aspect_v", "=", "torch", ".", "cat", "(", "aa", ",", "1", ")", "\n", "\n", "for", "pre_t", "in", "range", "(", "self", ".", "config", ".", "ntasks", ")", ":", "\n", "                    ", "if", "pre_t", "!=", "t", ":", "\n", "                        ", "feature", "=", "outputs_list", "[", "pre_t", "]", "\n", "feature", "=", "feature", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "semantic_cap_size", ")", "\n", "z", "=", "[", "F", ".", "tanh", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs1", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "y", "=", "[", "F", ".", "relu", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", "+", "self", ".", "fc_aspect", "(", "aspect_v", ")", ".", "unsqueeze", "(", "2", ")", ")", "for", "conv", "in", "self", ".", "convs2", "]", "\n", "z", "=", "[", "i", "*", "j", "for", "i", ",", "j", "in", "zip", "(", "z", ",", "y", ")", "]", "\n", "z", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "z", "]", "# [(N,Co), ...]*len(Ks)", "\n", "z", "=", "torch", ".", "cat", "(", "z", ",", "1", ")", "\n", "z", "=", "z", ".", "view", "(", "batch_size", ",", "self", ".", "Co", "*", "self", ".", "len_ks", ",", "1", ")", "\n", "outputs_list", "[", "pre_t", "]", "=", "z", "\n", "", "", "aspect_v", "=", "aspect_v", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "self", ".", "Co", "*", "self", ".", "len_ks", ",", "1", ")", "\n", "outputs_list", "[", "t", "]", "=", "aspect_v", "\n", "\n", "outputs", "=", "torch", ".", "cat", "(", "outputs_list", ",", "dim", "=", "-", "1", ")", "\n", "# print('outputs: ',outputs.size())", "\n", "\n", "\n", "", "return", "outputs", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "\n", "\n", "", "elif", "layer_type", "==", "'tsv'", ":", "\n", "\n", "            ", "if", "self", ".", "config", ".", "transfer_route", ":", "return", "x", "\n", "\n", "if", "self", ".", "config", ".", "exp", "in", "[", "'2layer_whole'", ",", "'2layer_aspect_transfer'", "]", ":", "#task,transfer,representation", "\n", "                ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "1", ")", "\n", "h_output", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "-", "1", ")", "\n", "h_output", "=", "self", ".", "larger", "(", "h_output", ")", "\n", "glarger", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "h_output", "=", "h_output", "*", "glarger", ".", "expand_as", "(", "h_output", ")", "\n", "return", "h_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayerImp.mask": [[389, 392], ["adapters.CapsuleLayerImp.gate", "adapters.CapsuleLayerImp.elarger", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "glarger", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "elarger", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "glarger", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayerImp.my_softmax": [[393, 397], ["input.transpose", "torch.softmax", "torch.softmax", "torch.softmax.view().transpose", "input.transpose.contiguous().view", "len", "input.transpose.size", "torch.softmax.view", "len", "input.size", "input.transpose.contiguous", "input.size", "input.transpose.size"], "methods", ["None"], ["", "def", "my_softmax", "(", "self", ",", "input", ",", "dim", "=", "1", ")", ":", "\n", "        ", "transposed_input", "=", "input", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "softmaxed_output", "=", "F", ".", "softmax", "(", "transposed_input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "transposed_input", ".", "size", "(", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "softmaxed_output", ".", "view", "(", "*", "transposed_input", ".", "size", "(", ")", ")", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayerImp.squash": [[402, 407], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "squash", "(", "self", ",", "input_tensor", ",", "dim", "=", "-", "1", ",", "epsilon", "=", "1e-16", ")", ":", "# 0 will happen in our case, has to add an epsilon", "\n", "        ", "squared_norm", "=", "(", "input_tensor", "**", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "squared_norm", "=", "squared_norm", "+", "epsilon", "\n", "scale", "=", "squared_norm", "/", "(", "1", "+", "squared_norm", ")", "\n", "return", "scale", "*", "input_tensor", "/", "torch", ".", "sqrt", "(", "squared_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleMask.__init__": [[414, 421], ["adapters.BertAdapterMask.__init__", "adapters.CapsNet", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "capsule_net", "=", "CapsNet", "(", "config", ")", "\n", "# self.fc1=torch.nn.Linear(semantic_cap_size,adapter_size)", "\n", "self", ".", "config", "=", "config", "\n", "print", "(", "'BertAdapterCapsuleMask'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleMask.forward": [[423, 447], ["adapters.BertAdapterCapsuleMask.capsule_net", "adapters.BertAdapterCapsuleMask.mask", "adapters.BertAdapterCapsuleMask.gelu", "adapters.BertAdapterCapsuleMask.gelu", "adapters.BertAdapterCapsuleMask.activation", "adapters.BertAdapterCapsuleMask.activation", "adapters.BertAdapterCapsuleMask.fc1", "gfc1.expand_as", "adapters.BertAdapterCapsuleMask.fc2", "gfc2.expand_as", "adapters.BertAdapterCapsuleMask.fc1", "gfc1.expand_as", "adapters.BertAdapterCapsuleMask.fc2", "gfc2.expand_as"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask"], ["", "def", "forward", "(", "self", ",", "x", ",", "t", ",", "s", ")", ":", "\n", "# task shared", "\n", "        ", "capsule_output", "=", "self", ".", "capsule_net", "(", "t", ",", "x", ",", "s", ")", "\n", "\n", "h", "=", "x", "+", "capsule_output", "#skip-connection", "\n", "# h = capsule_output #skip-connection", "\n", "\n", "# task specifc", "\n", "gfc1", ",", "gfc2", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "\n", "if", "self", ".", "config", ".", "use_gelu", ":", "\n", "            ", "h", "=", "self", ".", "gelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "gelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "", "else", ":", "\n", "            ", "h", "=", "self", ".", "activation", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc1", ".", "expand_as", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "h", "*", "gfc2", ".", "expand_as", "(", "h", ")", "\n", "\n", "", "return", "{", "'outputs'", ":", "x", "+", "h", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsNet.__init__": [[452, 457], ["torch.nn.Module.__init__", "adapters.CapsuleLayer", "adapters.CapsuleLayer", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "semantic_capsules", "=", "CapsuleLayer", "(", "config", ",", "'semantic'", ")", "\n", "self", ".", "tsv_capsules", "=", "CapsuleLayer", "(", "config", ",", "'tsv'", ")", "\n", "print", "(", "'CapsNet'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsNet.forward": [[458, 462], ["adapters.CapsNet.semantic_capsules", "adapters.CapsNet.tsv_capsules"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", ")", ":", "\n", "        ", "semantic_output", "=", "self", ".", "semantic_capsules", "(", "t", ",", "x", ",", "s", ",", "'semantic'", ")", "\n", "tsv_output", "=", "self", ".", "tsv_capsules", "(", "t", ",", "semantic_output", ",", "s", ",", "'tsv'", ")", "\n", "return", "tsv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.__init__": [[466, 501], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.ones().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "torch.tril().data.cuda", "print", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "layer_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "layer_type", "==", "'tsv'", ":", "\n", "            ", "self", ".", "num_routes", "=", "config", ".", "ntasks", "\n", "self", ".", "num_capsules", "=", "config", ".", "semantic_cap_size", "\n", "self", ".", "class_dim", "=", "config", ".", "max_seq_length", "\n", "self", ".", "in_channel", "=", "config", ".", "max_seq_length", "*", "config", ".", "semantic_cap_size", "\n", "# self.in_channel = 100", "\n", "self", ".", "elarger", "=", "torch", ".", "nn", ".", "Embedding", "(", "config", ".", "ntasks", ",", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "larger", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "semantic_cap_size", ",", "config", ".", "bert_hidden_size", ")", "#each task has its own larger way", "\n", "self", ".", "gate", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "num_iterations", "=", "3", "\n", "self", ".", "route_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "num_capsules", ",", "self", ".", "num_routes", ",", "self", ".", "in_channel", ",", "self", ".", "class_dim", ")", ")", "\n", "\n", "if", "config", ".", "no_tsv_mask", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "", "else", ":", "\n", "                ", "self", ".", "tsv", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "config", ".", "ntasks", ",", "config", ".", "ntasks", ")", ")", ".", "data", ".", "cuda", "(", ")", "# for backward", "\n", "\n", "\n", "", "", "elif", "layer_type", "==", "'semantic'", ":", "\n", "            ", "if", "config", ".", "apply_one_layer_shared", ":", "\n", "                ", "print", "(", "'apply_one_layer_shared '", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", ",", "config", ".", "semantic_cap_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "\n", "", "elif", "config", ".", "apply_two_layer_shared", ":", "\n", "                ", "print", "(", "'apply_two_layer_shared '", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", ",", "100", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "ModuleList", "(", "[", "torch", ".", "nn", ".", "Linear", "(", "100", ",", "config", ".", "semantic_cap_size", ")", "for", "_", "in", "range", "(", "config", ".", "ntasks", ")", "]", ")", "\n", "", "print", "(", "'CapsuleLayer'", ")", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.forward": [[502, 546], ["x.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().data.cuda", "torch.zeros().data.cuda", "torch.zeros().data.cuda", "torch.zeros().data.cuda", "range", "range", "vote_outputs.view", "adapters.CapsuleLayer.larger", "adapters.CapsuleLayer.mask", "adapters.CapsuleLayer.my_softmax", "adapters.CapsuleLayer.squash", "adapters.CapsuleLayer.expand_as", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "adapters.CapsuleLayer.squash", "adapters.CapsuleLayer.transpose", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask[].fill_", "adapters.CapsuleLayer.tsv[].data.view", "torch.zeros().data.cuda.data.view", "torch.zeros().data.cuda.data.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "fc1().view", "priors.size", "x.size", "fc2().view", "fc1", "x.size", "zip", "fc2", "fc1"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.my_softmax", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.squash", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.squash"], ["", "def", "forward", "(", "self", ",", "t", ",", "x", ",", "s", ",", "layer_type", "=", "None", ")", ":", "\n", "\n", "        ", "if", "layer_type", "==", "'tsv'", ":", "\n", "            ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "priors", "=", "x", "[", "None", ",", ":", ",", ":", ",", "None", ",", ":", "]", "@", "self", ".", "route_weights", "[", ":", ",", "None", ",", ":", ",", ":", ",", ":", "]", "\n", "logits", "=", "torch", ".", "zeros", "(", "*", "priors", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "# print('logits: ',logits.size())  torch.Size([3, 32, 19, 1, 128])", "\n", "mask", "=", "torch", ".", "zeros", "(", "self", ".", "config", ".", "ntasks", ")", ".", "data", ".", "cuda", "(", ")", "\n", "# print('self.tsv[t]: ',self.tsv[t])", "\n", "for", "x_id", "in", "range", "(", "self", ".", "config", ".", "ntasks", ")", ":", "\n", "                ", "if", "self", ".", "tsv", "[", "t", "]", "[", "x_id", "]", "==", "0", ":", "mask", "[", "x_id", "]", ".", "fill_", "(", "-", "10000", ")", "# block future, all previous are the same", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_iterations", ")", ":", "\n", "                ", "logits", "=", "logits", "*", "self", ".", "tsv", "[", "t", "]", ".", "data", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ",", "1", ")", "#multiply 0 to future task", "\n", "logits", "=", "logits", "+", "mask", ".", "data", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ",", "1", ")", "#add a very small negative number", "\n", "probs", "=", "self", ".", "my_softmax", "(", "logits", ",", "dim", "=", "2", ")", "\n", "vote_outputs", "=", "(", "probs", "*", "priors", ")", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "#voted", "\n", "outputs", "=", "self", ".", "squash", "(", "vote_outputs", ")", "\n", "\n", "if", "i", "!=", "self", ".", "num_iterations", "-", "1", ":", "\n", "                    ", "delta_logits", "=", "(", "priors", "*", "outputs", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "logits", "=", "logits", "+", "delta_logits", "\n", "\n", "", "", "h_output", "=", "vote_outputs", ".", "view", "(", "batch_size", ",", "self", ".", "config", ".", "max_seq_length", ",", "-", "1", ")", "\n", "\n", "h_output", "=", "self", ".", "larger", "(", "h_output", ")", "\n", "glarger", "=", "self", ".", "mask", "(", "t", "=", "t", ",", "s", "=", "s", ")", "\n", "h_output", "=", "h_output", "*", "glarger", ".", "expand_as", "(", "h_output", ")", "\n", "\n", "return", "h_output", "\n", "\n", "", "elif", "layer_type", "==", "'semantic'", ":", "\n", "\n", "            ", "if", "self", ".", "config", ".", "apply_one_layer_shared", ":", "\n", "# print('apply_one_layer_shared ')", "\n", "                ", "outputs", "=", "[", "fc1", "(", "x", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "for", "fc1", "in", "self", ".", "fc1", "]", "\n", "\n", "", "elif", "self", ".", "config", ".", "apply_two_layer_shared", ":", "\n", "# print('apply_two_layer_shared ')", "\n", "                ", "outputs", "=", "[", "fc2", "(", "fc1", "(", "x", ")", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "for", "fc1", ",", "fc2", "in", "zip", "(", "self", ".", "fc1", ",", "self", ".", "fc2", ")", "]", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "self", ".", "squash", "(", "outputs", ")", "\n", "return", "outputs", ".", "transpose", "(", "2", ",", "1", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.mask": [[547, 550], ["adapters.CapsuleLayer.gate", "adapters.CapsuleLayer.elarger", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "mask", "(", "self", ",", "t", ",", "s", ")", ":", "\n", "        ", "glarger", "=", "self", ".", "gate", "(", "s", "*", "self", ".", "elarger", "(", "torch", ".", "LongTensor", "(", "[", "t", "]", ")", ".", "cuda", "(", ")", ")", ")", "\n", "return", "glarger", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.my_softmax": [[551, 555], ["input.transpose", "torch.softmax", "torch.softmax", "torch.softmax.view().transpose", "input.transpose.contiguous().view", "len", "input.transpose.size", "torch.softmax.view", "len", "input.size", "input.transpose.contiguous", "input.size", "input.transpose.size"], "methods", ["None"], ["", "def", "my_softmax", "(", "self", ",", "input", ",", "dim", "=", "1", ")", ":", "\n", "        ", "transposed_input", "=", "input", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "softmaxed_output", "=", "F", ".", "softmax", "(", "transposed_input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "transposed_input", ".", "size", "(", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "softmaxed_output", ".", "view", "(", "*", "transposed_input", ".", "size", "(", ")", ")", ".", "transpose", "(", "dim", ",", "len", "(", "input", ".", "size", "(", ")", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.CapsuleLayer.squash": [[556, 560], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "squash", "(", "self", ",", "tensor", ",", "dim", "=", "-", "1", ")", ":", "\n", "        ", "squared_norm", "=", "(", "tensor", "**", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "scale", "=", "squared_norm", "/", "(", "1", "+", "squared_norm", ")", "\n", "return", "scale", "*", "tensor", "/", "torch", ".", "sqrt", "(", "squared_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterUcl.__init__": [[566, 574], ["torch.nn.Module.__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "bayes_layer.BayesianLinear", "bayes_layer.BayesianLinear", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc1", "=", "BayesianLinear", "(", "config", ".", "bert_hidden_size", ",", "config", ".", "bert_adapter_size", ",", "ratio", "=", "config", ".", "ratio", ")", "\n", "self", ".", "fc2", "=", "BayesianLinear", "(", "config", ".", "bert_adapter_size", ",", "config", ".", "bert_hidden_size", ",", "ratio", "=", "config", ".", "ratio", ")", "\n", "# self.fc1=torch.nn.Linear(config.bert_hidden_size,config.adapter_size)", "\n", "# self.fc2=torch.nn.Linear(config.adapter_size,config.bert_hidden_size)", "\n", "print", "(", "'BertAdapterUcl'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterUcl.forward": [[581, 587], ["adapters.BertAdapterUcl.relu", "adapters.BertAdapterUcl.relu", "adapters.BertAdapterUcl.fc1", "adapters.BertAdapterUcl.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "sample", "=", "True", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "x", ",", "sample", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ",", "sample", ")", ")", "\n", "\n", "return", "x", "+", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterOwm.__init__": [[590, 601], ["torch.nn.Module.__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc4", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_hidden_size", "*", "config", ".", "max_seq_length", ",", "config", ".", "bert_adapter_size", ")", "\n", "#TODO: self.fc4=torch.nn.Linear(config.bert_hidden_size,config.adapter_size)", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_adapter_size", ",", "config", ".", "bert_adapter_size", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_adapter_size", ",", "config", ".", "bert_adapter_size", ")", "\n", "self", ".", "fc3", "=", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "bert_adapter_size", ",", "config", ".", "max_seq_length", "*", "config", ".", "bert_hidden_size", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "config", "=", "config", "\n", "print", "(", "'BertAdapterOwm'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterOwm.forward": [[602, 616], ["x.view.view.view", "adapters.BertAdapterOwm.relu", "adapters.BertAdapterOwm.relu", "h_list.append", "adapters.BertAdapterOwm.relu", "h_list.append", "adapters.BertAdapterOwm.relu", "h.view.view.view", "x.view.view.view", "x.view.view.size", "adapters.BertAdapterOwm.fc4", "adapters.BertAdapterOwm.fc1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "adapters.BertAdapterOwm.fc2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "adapters.BertAdapterOwm.fc3", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "h_list", "=", "[", "]", "\n", "x_list", "=", "[", "]", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc4", "(", "x", ")", ")", "#OOM has to have somehting else", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h_list", ".", "append", "(", "torch", ".", "mean", "(", "h", ",", "0", ",", "True", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc3", "(", "h", ")", ")", "\n", "h", "=", "h", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "bert_hidden_size", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "config", ".", "max_seq_length", ",", "self", ".", "config", ".", "bert_hidden_size", ")", "\n", "\n", "return", "{", "'outputs'", ":", "x", "+", "h", ",", "'x_list'", ":", "x_list", ",", "'h_list'", ":", "h_list", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsule.__init__": [[620, 624], ["adapters.BertAdapter.__init__", "adapters.CapsNet", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "capsule_net", "=", "CapsNet", "(", "config", ")", "\n", "print", "(", "'BertAdapterCapsule'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsule.forward": [[625, 628], ["adapters.BertAdapterCapsule.capsule_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "t", ",", "s", ")", ":", "\n", "        ", "h", "=", "self", ".", "capsule_net", "(", "t", ",", "x", ",", "s", ")", "\n", "return", "x", "+", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleImp.__init__": [[632, 637], ["adapters.BertAdapter.__init__", "adapters.CapsNetImp", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "torch.nn.GELU", "print"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "capsule_net", "=", "CapsNetImp", "(", "config", ")", "\n", "self", ".", "gelu", "=", "torch", ".", "nn", ".", "GELU", "(", ")", "\n", "print", "(", "'BertAdapterCapsuleImp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.adapters.BertAdapterCapsuleImp.forward": [[638, 641], ["adapters.BertAdapterCapsuleImp.capsule_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "t", ",", "s", ")", ":", "\n", "        ", "h", "=", "self", ".", "capsule_net", "(", "t", ",", "x", ",", "s", ")", "\n", "return", "x", "+", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.__init__": [[19, 134], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "w2v_cnn_base.Appr._get_optimizer", "contrastive_loss.SupConLoss", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "print", "copy.deepcopy", "copy.deepcopy", "w2v_cnn_base.Appr.model.named_parameters", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "buffer.Buffer", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "buffer.Buffer", "w2v_cnn_base.Appr.model.parameters", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.device", "torch.device", "torch.device", "torch.device", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "copy.deepcopy", "w2v_cnn_base.CheckFederated", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "w2v_cnn_base.Appr.param_name.append", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "w2v_cnn_base.Appr.grad_dims.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "param.data.numel", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "w2v_cnn_base.Appr.model.named_parameters", "len", "len", "len", "len", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "# self.initial_model=deepcopy(model)", "\n", "\n", "self", ".", "nepochs", "=", "args", ".", "nepochs", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "lr", "=", "args", ".", "lr", "\n", "self", ".", "lr_min", "=", "args", ".", "lr_min", "\n", "self", ".", "lr_factor", "=", "args", ".", "lr_factor", "\n", "self", ".", "lr_patience", "=", "args", ".", "lr_patience", "\n", "self", ".", "clipgrad", "=", "args", ".", "clipgrad", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", ")", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "if", "args", ".", "baseline", "==", "'one'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ewc'", ":", "\n", "            ", "self", ".", "model_old", "=", "None", "\n", "self", ".", "fisher", "=", "None", "\n", "self", ".", "lamb", "=", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'kan'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ucl'", ":", "\n", "            ", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "lr_rho", "=", "args", ".", "lr_rho", "\n", "self", ".", "lr_min", "=", "args", ".", "lr", "/", "(", "args", ".", "lr_factor", "**", "5", ")", "\n", "self", ".", "iteration", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "saved", "=", "0", "\n", "self", ".", "beta", "=", "args", ".", "beta", "\n", "self", ".", "drop", "=", "[", "20", ",", "40", ",", "60", ",", "75", ",", "90", "]", "\n", "self", ".", "param_name", "=", "[", "]", "\n", "\n", "for", "(", "name", ",", "p", ")", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "param_name", ".", "append", "(", "name", ")", "\n", "\n", "", "", "if", "args", ".", "baseline", "==", "'owm'", ":", "\n", "            ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "# run on GPU", "\n", "self", ".", "Pc1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc3", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "300", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "300", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "test_max", "=", "0", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'srk'", ":", "\n", "            ", "self", ".", "control_1_s", "=", "torch", ".", "zeros", "(", "args", ".", "w2v_hidden_size", ")", ".", "cuda", "(", ")", "\n", "self", ".", "control_2_s", "=", "torch", ".", "zeros", "(", "args", ".", "w2v_hidden_size", ")", ".", "cuda", "(", ")", "\n", "self", ".", "control_3_s", "=", "torch", ".", "zeros", "(", "args", ".", "w2v_hidden_size", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'hat'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'derpp'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "mse", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'a-gem'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "", "self", ".", "grad_xy", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "grad_er", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'l2'", ":", "\n", "            ", "self", ".", "lamb", "=", "self", ".", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "}", "# For convenience", "\n", "self", ".", "regularization_terms", "=", "{", "}", "\n", "self", ".", "task_count", "=", "0", "\n", "self", ".", "online_reg", "=", "False", "# True: There will be only one importance matrix and previous model parameters", "\n", "# False: Each task has its own importance matrix and model parameters", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'cat'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "self", ".", "acc_transfer", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "acc_reference", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "lss_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "similarity_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "self", ".", "transfer_initial_model", "=", "deepcopy", "(", "self", ".", "model", ".", "transfer", ")", "\n", "\n", "self", ".", "check_federated", "=", "CheckFederated", "(", ")", "\n", "self", ".", "history_mask_pre", "=", "[", "]", "\n", "self", ".", "similarities", "=", "[", "]", "\n", "\n", "", "print", "(", "'W2V NCL'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr._get_optimizer_cat": [[137, 151], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "w2v_cnn_base.Appr.model.mcl.parameters", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "list", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "w2v_cnn_base.Appr.model.kt.parameters", "w2v_cnn_base.Appr.model.mcl.parameters", "w2v_cnn_base.Appr.model.transfer.parameters", "list", "w2v_cnn_base.Appr.model.transfer.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_cat", "(", "self", ",", "lr", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "\n", "elif", "phase", "==", "'mcl'", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'mcl'", "and", "'joint'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "kt", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.project": [[153, 156], ["torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot"], "methods", ["None"], ["", "", "def", "project", "(", "self", ",", "gxy", ":", "torch", ".", "Tensor", ",", "ger", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "corr", "=", "torch", ".", "dot", "(", "gxy", ",", "ger", ")", "/", "torch", ".", "dot", "(", "ger", ",", "ger", ")", "\n", "return", "gxy", "-", "corr", "*", "ger", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.store_grad": [[158, 174], ["grads.fill_", "params", "numpy.sum", "grads[].copy_", "sum", "param.grad.data.view"], "methods", ["None"], ["", "def", "store_grad", "(", "self", ",", "params", ",", "grads", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This stores parameter gradients of past tasks.\n            pp: parameters\n            grads: gradients\n            grad_dims: list with number of parameters per layers\n        \"\"\"", "\n", "# store the gradients", "\n", "grads", ".", "fill_", "(", "0.0", ")", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "np", ".", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "grads", "[", "begin", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.overwrite_grad": [[176, 193], ["params", "sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "methods", ["None"], ["", "", "def", "overwrite_grad", "(", "self", ",", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This is used to overwrite the gradients with a new gradient\n            vector, whenever violations occur.\n            pp: parameters\n            newgrad: corrected gradient\n            grad_dims: list storing number of parameters at each layer\n        \"\"\"", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "begin", ":", "end", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr._get_optimizer_kan": [[258, 277], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "w2v_cnn_base.Appr.model.mcl.parameters", "w2v_cnn_base.Appr.model.last.parameters", "w2v_cnn_base.Appr.model.mcl.parameters", "w2v_cnn_base.Appr.model.last.parameters", "w2v_cnn_base.Appr.model.ac.parameters", "w2v_cnn_base.Appr.model.last.parameters", "w2v_cnn_base.Appr.model.ac.parameters", "w2v_cnn_base.Appr.model.last.parameters"], "methods", ["None"], ["", "", "def", "_get_optimizer_kan", "(", "self", ",", "lr", "=", "None", ",", "which_type", "=", "None", ")", ":", "\n", "\n", "        ", "if", "which_type", "==", "'mcl'", ":", "\n", "            ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "SGD", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "\n", "", "", "elif", "which_type", "==", "'ac'", ":", "\n", "            ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "SGD", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "ac", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "                    ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "ac", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.sup_loss": [[222, 230], ["w2v_cnn_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "", "", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "targets", ",", "t", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr._get_optimizer_owm": [[233, 248], ["list", "list", "filter", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "map", "map", "w2v_cnn_base.Appr.model.parameters", "w2v_cnn_base.Appr.model.fc1.parameters", "w2v_cnn_base.Appr.model.fc2.parameters", "id", "w2v_cnn_base.Appr.model.fc1.parameters", "w2v_cnn_base.Appr.model.fc2.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_owm", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "# if lr is None:", "\n", "#     lr = self.lr", "\n", "        ", "lr", "=", "self", ".", "lr", "\n", "lr_owm", "=", "self", ".", "lr", "\n", "fc1_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ")", ")", "\n", "fc2_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ")", ")", "\n", "base_params", "=", "filter", "(", "lambda", "p", ":", "id", "(", "p", ")", "not", "in", "fc1_params", "+", "fc2_params", ",", "\n", "self", ".", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "base_params", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "]", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ")", "\n", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr._get_optimizer_ucl": [[249, 256], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "w2v_cnn_base.Appr.model.parameters", "w2v_cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_ucl", "(", "self", ",", "lr", "=", "None", ",", "lr_rho", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "lr_rho", "is", "None", ":", "lr_rho", "=", "self", ".", "lr_rho", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'Adam'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "lr_rho", "=", "lr_rho", ",", "param_name", "=", "self", ".", "param_name", ")", "\n", "", "if", "self", ".", "args", ".", "optimizer", "==", "'SGD'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.ent_id_detection": [[279, 311], ["torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "range", "range", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "outputs.append", "torch.softmax", "torch.softmax", "entropies.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "w2v_cnn_base.Appr.model.forward", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "w2v_cnn_base.Appr.model.forward", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "", "", "def", "ent_id_detection", "(", "self", ",", "trained_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "t", ",", "which_type", "=", "None", ")", ":", "\n", "\n", "        ", "output_d", "=", "{", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "\n", "if", "trained_task", "is", "None", ":", "#training", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "t", "+", "1", ")", "\n", "", "else", ":", "#testing", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "trained_task", "+", "1", ")", "\n", "\n", "", "for", "e", "in", "entrop_to_test", ":", "\n", "            ", "e_task", "=", "torch", ".", "LongTensor", "(", "[", "e", "]", ")", ".", "cuda", "(", ")", "\n", "if", "'hat'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "s", "=", "self", ".", "smax", ")", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output_d", "[", "'masks'", "]", "=", "masks", "\n", "", "elif", "'kan'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e_task", ",", "tokens_term_ids", ",", "tokens_sentence_ids", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "", "output", "=", "output_dict", "[", "'y'", "]", "\n", "outputs", ".", "append", "(", "output", ")", "#shared head", "\n", "\n", "Y_hat", "=", "F", ".", "softmax", "(", "output", ",", "-", "1", ")", "\n", "entropy", "=", "-", "1", "*", "torch", ".", "sum", "(", "Y_hat", "*", "torch", ".", "log", "(", "Y_hat", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", ")", "\n", "", "inf_task_id", "=", "torch", ".", "argmin", "(", "torch", ".", "stack", "(", "entropies", ")", ")", "\n", "output", "=", "outputs", "[", "inf_task_id", "]", "\n", "\n", "output_d", "[", "'output'", "]", "=", "output", "\n", "\n", "return", "output_d", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.criterion_hat": [[314, 328], ["zip", "aux.sum", "m.sum", "numpy.prod().item", "w2v_cnn_base.Appr.ce", "numpy.prod", "m.size"], "methods", ["None"], ["", "def", "criterion_hat", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "mp", "in", "zip", "(", "masks", ",", "self", ".", "mask_pre", ")", ":", "\n", "                ", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m", "in", "masks", ":", "\n", "                ", "reg", "+=", "m", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "", "", "reg", "/=", "count", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", ",", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.criterion_ewc": [[330, 338], ["zip", "w2v_cnn_base.Appr.ce", "w2v_cnn_base.Appr.model.named_parameters", "w2v_cnn_base.Appr.model_old.named_parameters", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "criterion_ewc", "(", "self", ",", "t", ",", "output", ",", "targets", ")", ":", "\n", "# Regularization for all previous tasks", "\n", "        ", "loss_reg", "=", "0", "\n", "if", "t", ">", "0", ":", "\n", "            ", "for", "(", "name", ",", "param", ")", ",", "(", "_", ",", "param_old", ")", "in", "zip", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ",", "self", ".", "model_old", ".", "named_parameters", "(", ")", ")", ":", "\n", "                ", "loss_reg", "+=", "torch", ".", "sum", "(", "self", ".", "fisher", "[", "name", "]", "*", "(", "param_old", "-", "param", ")", ".", "pow", "(", "2", ")", ")", "/", "2", "\n", "\n", "", "", "return", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "lamb", "*", "loss_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr._get_optimizer": [[341, 352], ["print", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "w2v_cnn_base.Appr.model.parameters", "print", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "w2v_cnn_base.Appr.model.parameters", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "w2v_cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", "and", "self", ".", "args", ".", "momentum", ":", "\n", "            ", "print", "(", "'sgd+momentum'", ")", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "print", "(", "'sgd'", ")", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "            ", "print", "(", "'adam'", ")", "\n", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.Appr.f1_compute_fn": [[354, 363], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.CheckFederated.__init__": [[366, 368], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.CheckFederated.set_similarities": [[368, 370], ["None"], "methods", ["None"], ["", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n", "        ", "self", ".", "similarities", "=", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.CheckFederated.fix_length": [[371, 373], ["len"], "methods", ["None"], ["", "def", "fix_length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "similarities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.CheckFederated.get_similarities": [[374, 376], ["None"], "methods", ["None"], ["", "def", "get_similarities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.w2v_cnn_base.CheckFederated.check_t": [[378, 389], ["len", "numpy.count_nonzero", "sum", "sum", "len", "itertools.zip_longest", "itertools.zip_longest"], "methods", ["None"], ["", "def", "check_t", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "t", "<", "len", "(", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", ")", "and", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", "[", "t", "]", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "np", ".", "count_nonzero", "(", "self", ".", "similarities", "[", "t", "]", ")", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "t", "<", "len", "(", "self", ".", "similarities", "[", "-", "1", "]", ")", "and", "self", ".", "similarities", "[", "-", "1", "]", "[", "t", "]", "==", "1", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.__init__": [[37, 48], ["eval"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval"], ["def", "__init__", "(", "self", ",", "buffer_size", ",", "device", ",", "n_tasks", "=", "None", ",", "mode", "=", "'reservoir'", ")", ":", "\n", "        ", "assert", "mode", "in", "[", "'ring'", ",", "'reservoir'", "]", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "num_seen_examples", "=", "0", "\n", "self", ".", "functional_index", "=", "eval", "(", "mode", ")", "\n", "if", "mode", "==", "'ring'", ":", "\n", "            ", "assert", "n_tasks", "is", "not", "None", "\n", "self", ".", "task_number", "=", "n_tasks", "\n", "self", ".", "buffer_portion_size", "=", "buffer_size", "//", "n_tasks", "\n", "", "self", ".", "attributes", "=", "[", "'examples'", ",", "'labels'", ",", "'logits'", ",", "'task_labels'", ",", "'segment_ids'", ",", "'input_mask'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.init_tensors": [[49, 69], ["eval", "setattr", "hasattr", "attr_str.endswith", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.classification.cnn_ucl.Appr.eval"], ["", "def", "init_tensors", "(", "self", ",", "\n", "examples", ":", "torch", ".", "Tensor", ",", "\n", "segment_ids", ":", "torch", ".", "Tensor", ",", "\n", "input_mask", ":", "torch", ".", "Tensor", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "task_labels", ":", "torch", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initializes just the required tensors.\n        :param examples: tensor containing the images\n        :param labels: tensor containing the labels\n        :param logits: tensor containing the outputs of the network\n        :param task_labels: tensor containing the task labels\n        \"\"\"", "\n", "for", "attr_str", "in", "self", ".", "attributes", ":", "\n", "            ", "attr", "=", "eval", "(", "attr_str", ")", "\n", "if", "attr", "is", "not", "None", "and", "not", "hasattr", "(", "self", ",", "attr_str", ")", ":", "\n", "                ", "typ", "=", "torch", ".", "int64", "if", "attr_str", ".", "endswith", "(", "'els'", ")", "else", "torch", ".", "float32", "\n", "setattr", "(", "self", ",", "attr_str", ",", "torch", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "\n", "*", "attr", ".", "shape", "[", "1", ":", "]", ")", ",", "dtype", "=", "typ", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "", "", "", "def", "add_data", "(", "self", ",", "examples", ",", "segment_ids", "=", "None", ",", "input_mask", "=", "None", ",", "labels", "=", "None", ",", "logits", "=", "None", ",", "task_labels", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.add_data": [[69, 101], ["print", "print", "range", "segment_ids.size", "hasattr", "buffer.Buffer.init_tensors", "buffer.Buffer.segment_ids.size", "buffer.reservoir", "examples[].to", "labels[].to", "segment_ids[].to", "input_mask[].to", "logits[].to", "task_labels[].to"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.init_tensors", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.reservoir"], ["", "", "", "def", "add_data", "(", "self", ",", "examples", ",", "segment_ids", "=", "None", ",", "input_mask", "=", "None", ",", "labels", "=", "None", ",", "logits", "=", "None", ",", "task_labels", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Adds the data to the memory buffer according to the reservoir strategy.\n        :param examples: tensor containing the images\n        :param labels: tensor containing the labels\n        :param logits: tensor containing the outputs of the network\n        :param task_labels: tensor containing the task labels\n        :return:\n        \"\"\"", "\n", "\n", "print", "(", "'segment_ids: '", ",", "segment_ids", ".", "size", "(", ")", ")", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "'examples'", ")", ":", "\n", "            ", "self", ".", "init_tensors", "(", "examples", ",", "segment_ids", ",", "input_mask", ",", "labels", ",", "logits", ",", "task_labels", ")", "\n", "\n", "", "print", "(", "'segment_ids: '", ",", "self", ".", "segment_ids", ".", "size", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "examples", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "index", "=", "reservoir", "(", "self", ".", "num_seen_examples", ",", "self", ".", "buffer_size", ")", "\n", "self", ".", "num_seen_examples", "+=", "1", "\n", "if", "index", ">=", "0", ":", "\n", "                ", "self", ".", "examples", "[", "index", "]", "=", "examples", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "self", ".", "labels", "[", "index", "]", "=", "labels", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "segment_ids", "is", "not", "None", ":", "\n", "                    ", "self", ".", "segment_ids", "[", "index", "]", "=", "segment_ids", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "logits", "is", "not", "None", ":", "\n", "                    ", "self", ".", "input_mask", "[", "index", "]", "=", "input_mask", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "logits", "is", "not", "None", ":", "\n", "                    ", "self", ".", "logits", "[", "index", "]", "=", "logits", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "task_labels", "is", "not", "None", ":", "\n", "                    ", "self", ".", "task_labels", "[", "index", "]", "=", "task_labels", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_data": [[102, 123], ["numpy.random.choice", "min", "min", "min", "torch.stack().to", "hasattr", "getattr", "torch.stack", "transform", "ee.cpu"], "methods", ["None"], ["", "", "", "", "def", "get_data", "(", "self", ",", "size", ":", "int", ",", "transform", ":", "transforms", "=", "None", ")", "->", "Tuple", ":", "\n", "        ", "\"\"\"\n        Random samples a batch of size items.\n        :param size: the number of requested items\n        :param transform: the transformation to be applied (data augmentation)\n        :return:\n        \"\"\"", "\n", "if", "size", ">", "min", "(", "self", ".", "num_seen_examples", ",", "self", ".", "examples", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "size", "=", "min", "(", "self", ".", "num_seen_examples", ",", "self", ".", "examples", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "choice", "=", "np", ".", "random", ".", "choice", "(", "min", "(", "self", ".", "num_seen_examples", ",", "self", ".", "examples", ".", "shape", "[", "0", "]", ")", ",", "\n", "size", "=", "size", ",", "replace", "=", "False", ")", "\n", "if", "transform", "is", "None", ":", "transform", "=", "lambda", "x", ":", "x", "\n", "ret_tuple", "=", "(", "torch", ".", "stack", "(", "[", "transform", "(", "ee", ".", "cpu", "(", ")", ")", "\n", "for", "ee", "in", "self", ".", "examples", "[", "choice", "]", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", ")", "\n", "for", "attr_str", "in", "self", ".", "attributes", "[", "1", ":", "]", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "attr_str", ")", ":", "\n", "                ", "attr", "=", "getattr", "(", "self", ",", "attr_str", ")", "\n", "ret_tuple", "+=", "(", "attr", "[", "choice", "]", ",", ")", "\n", "\n", "", "", "return", "ret_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.is_empty": [[124, 132], ["None"], "methods", ["None"], ["", "def", "is_empty", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns true if the buffer is empty, false otherwise.\n        \"\"\"", "\n", "if", "self", ".", "num_seen_examples", "==", "0", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.get_all_data": [[133, 147], ["torch.stack().to", "hasattr", "getattr", "torch.stack", "transform", "ee.cpu"], "methods", ["None"], ["", "", "def", "get_all_data", "(", "self", ",", "transform", ":", "transforms", "=", "None", ")", "->", "Tuple", ":", "\n", "        ", "\"\"\"\n        Return all the items in the memory buffer.\n        :param transform: the transformation to be applied (data augmentation)\n        :return: a tuple with all the items in the memory buffer\n        \"\"\"", "\n", "if", "transform", "is", "None", ":", "transform", "=", "lambda", "x", ":", "x", "\n", "ret_tuple", "=", "(", "torch", ".", "stack", "(", "[", "transform", "(", "ee", ".", "cpu", "(", ")", ")", "\n", "for", "ee", "in", "self", ".", "examples", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", ")", "\n", "for", "attr_str", "in", "self", ".", "attributes", "[", "1", ":", "]", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "attr_str", ")", ":", "\n", "                ", "attr", "=", "getattr", "(", "self", ",", "attr_str", ")", "\n", "ret_tuple", "+=", "(", "attr", ",", ")", "\n", "", "", "return", "ret_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.Buffer.empty": [[148, 156], ["hasattr", "delattr"], "methods", ["None"], ["", "def", "empty", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set all the tensors to None.\n        \"\"\"", "\n", "for", "attr_str", "in", "self", ".", "attributes", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "attr_str", ")", ":", "\n", "                ", "delattr", "(", "self", ",", "attr_str", ")", "\n", "", "", "self", ".", "num_seen_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.reservoir": [[12, 27], ["numpy.random.randint"], "function", ["None"], ["def", "reservoir", "(", "num_seen_examples", ":", "int", ",", "buffer_size", ":", "int", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Reservoir sampling algorithm.\n    :param num_seen_examples: the number of seen examples\n    :param buffer_size: the maximum buffer size\n    :return: the target index if the current image is sampled, else -1\n    \"\"\"", "\n", "if", "num_seen_examples", "<", "buffer_size", ":", "\n", "        ", "return", "num_seen_examples", "\n", "\n", "", "rand", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_seen_examples", "+", "1", ")", "\n", "if", "rand", "<", "buffer_size", ":", "#total batch size", "\n", "        ", "return", "rand", "\n", "", "else", ":", "\n", "        ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.buffer.ring": [[29, 31], ["None"], "function", ["None"], ["", "", "def", "ring", "(", "num_seen_examples", ":", "int", ",", "buffer_portion_size", ":", "int", ",", "task", ":", "int", ")", "->", "int", ":", "\n", "    ", "return", "num_seen_examples", "%", "buffer_portion_size", "+", "task", "*", "buffer_portion_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_base.Appr.warmup_linear": [[28, 32], ["None"], "methods", ["None"], ["    ", "def", "warmup_linear", "(", "self", ",", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "        ", "if", "x", "<", "warmup", ":", "\n", "            ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_base.Appr.__init__": [[34, 62], ["random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logger.info", "contrastive_loss.SupConLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "print", "copy.deepcopy", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"device: {} n_gpu: {}\"", ".", "format", "(", "\n", "self", ".", "device", ",", "self", ".", "n_gpu", ")", ")", "\n", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "if", "'one'", "in", "args", ".", "approach", ":", "\n", "            ", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "print", "(", "'BERT NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_base.Appr.sup_loss": [[63, 71], ["bert_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_base.Appr.f1_compute_fn": [[73, 82], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.warmup_linear": [[29, 33], ["None"], "methods", ["None"], ["    ", "def", "warmup_linear", "(", "self", ",", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "        ", "if", "x", "<", "warmup", ":", "\n", "            ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.__init__": [[35, 111], ["random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logger.info", "contrastive_loss.SupConLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "print", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "copy.deepcopy", "copy.deepcopy", "buffer.Buffer", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "buffer.Buffer", "model.parameters", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "buffer.Buffer", "bert_adapter_base.Appr.model.parameters", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "bert_adapter_base.Appr.grad_dims.append", "bert_adapter_base.Appr.grad_dims.append", "pp.data.numel", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "param.data.numel", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "bert_adapter_base.Appr.model.named_parameters", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"device: {} n_gpu: {}\"", ".", "format", "(", "\n", "self", ".", "device", ",", "self", ".", "n_gpu", ")", ")", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "\n", "# shared ==============", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_old", "=", "None", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "if", "args", ".", "baseline", "==", "'ewc'", ":", "\n", "            ", "self", ".", "lamb", "=", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "self", ".", "fisher", "=", "None", "\n", "\n", "#OWM ============", "\n", "", "if", "args", ".", "baseline", "==", "'owm'", ":", "\n", "            ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "# run on GPU", "\n", "self", ".", "P1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "self", ".", "args", ".", "bert_adapter_size", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "#inference only", "\n", "self", ".", "P2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "self", ".", "args", ".", "bert_adapter_size", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "#UCL ======================", "\n", "", "if", "args", ".", "baseline", "==", "'ucl'", ":", "\n", "            ", "self", ".", "saved", "=", "0", "\n", "self", ".", "beta", "=", "args", ".", "beta", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'one'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'derpp'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "mse", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'gem'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "# Allocate temporary synaptic memory", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "pp", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "self", ".", "grad_dims", ".", "append", "(", "pp", ".", "data", ".", "numel", "(", ")", ")", "\n", "\n", "", "self", ".", "grads_cs", "=", "[", "]", "\n", "self", ".", "grads_da", "=", "torch", ".", "zeros", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'a-gem'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "", "self", ".", "grad_xy", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "grad_er", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'l2'", ":", "\n", "            ", "self", ".", "lamb", "=", "self", ".", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "}", "# For convenience", "\n", "self", ".", "regularization_terms", "=", "{", "}", "\n", "self", ".", "task_count", "=", "0", "\n", "self", ".", "online_reg", "=", "False", "# True: There will be only one importance matrix and previous model parameters", "\n", "# False: Each task has its own importance matrix and model parameters", "\n", "", "print", "(", "'BERT ADAPTER BASE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.sup_loss": [[112, 120], ["bert_adapter_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.order_generation": [[122, 131], ["range", "orders.append", "orders.append", "random.Random().sample", "range", "random.Random", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bayes_layer.Gaussian.sample"], ["", "def", "order_generation", "(", "self", ",", "t", ")", ":", "\n", "        ", "orders", "=", "[", "]", "\n", "nsamples", "=", "t", "\n", "for", "n", "in", "range", "(", "self", ".", "args", ".", "naug", ")", ":", "\n", "            ", "if", "n", "==", "0", ":", "orders", ".", "append", "(", "[", "pre_t", "for", "pre_t", "in", "range", "(", "t", ")", "]", ")", "\n", "elif", "nsamples", ">=", "1", ":", "\n", "                ", "orders", ".", "append", "(", "random", ".", "Random", "(", "self", ".", "args", ".", "seed", ")", ".", "sample", "(", "[", "pre_t", "for", "pre_t", "in", "range", "(", "t", ")", "]", ",", "nsamples", ")", ")", "\n", "nsamples", "-=", "1", "\n", "", "", "return", "orders", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.idx_generator": [[132, 155], ["range", "ls.append", "idxs.append", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "numpy.random.beta", "numpy.random.beta", "numpy.random.choice", "numpy.random.choice", "max"], "methods", ["None"], ["", "def", "idx_generator", "(", "self", ",", "bsz", ")", ":", "\n", "#TODO: why don't we generate more?", "\n", "        ", "ls", ",", "idxs", "=", "[", "]", ",", "[", "]", "\n", "for", "n", "in", "range", "(", "self", ".", "args", ".", "ntmix", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "tmix", ":", "\n", "                ", "if", "self", ".", "args", ".", "co", ":", "\n", "                    ", "mix_", "=", "np", ".", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "mix_", "=", "1", "\n", "\n", "", "if", "mix_", "==", "1", ":", "\n", "                    ", "l", "=", "np", ".", "random", ".", "beta", "(", "self", ".", "args", ".", "alpha", ",", "self", ".", "args", ".", "alpha", ")", "\n", "if", "self", ".", "args", ".", "separate_mix", ":", "\n", "                        ", "l", "=", "l", "\n", "", "else", ":", "\n", "                        ", "l", "=", "max", "(", "l", ",", "1", "-", "l", ")", "\n", "", "", "else", ":", "\n", "                    ", "l", "=", "1", "\n", "", "idx", "=", "torch", ".", "randperm", "(", "bsz", ")", "# Note I currently do not havce unsupervised data", "\n", "", "ls", ".", "append", "(", "l", ")", "\n", "idxs", ".", "append", "(", "idx", ")", "\n", "\n", "", "return", "idxs", ",", "ls", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.f1_compute_fn": [[157, 166], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_base.Appr.criterion": [[167, 175], ["zip", "bert_adapter_base.Appr.ce", "bert_adapter_base.Appr.model.named_parameters", "bert_adapter_base.Appr.model_old.named_parameters", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "t", ",", "output", ",", "targets", ")", ":", "\n", "# Regularization for all previous tasks", "\n", "        ", "loss_reg", "=", "0", "\n", "if", "t", ">", "0", ":", "\n", "            ", "for", "(", "name", ",", "param", ")", ",", "(", "_", ",", "param_old", ")", "in", "zip", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ",", "self", ".", "model_old", ".", "named_parameters", "(", ")", ")", ":", "\n", "                ", "loss_reg", "+=", "torch", ".", "sum", "(", "self", ".", "fisher", "[", "name", "]", "*", "(", "param_old", "-", "param", ")", ".", "pow", "(", "2", ")", ")", "/", "2", "\n", "\n", "", "", "return", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "lamb", "*", "loss_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.SoftCrossEntropy.__init__": [[34, 36], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SoftCrossEntropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.SoftCrossEntropy.forward": [[37, 41], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "target", ")", ":", "\n", "        ", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "1", ")", "\n", "loss", "=", "(", "-", "target", "*", "torch", ".", "log", "(", "probs", ")", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.warmup_linear": [[44, 48], ["None"], "methods", ["None"], ["    ", "def", "warmup_linear", "(", "self", ",", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "        ", "if", "x", "<", "warmup", ":", "\n", "            ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.__init__": [[50, 183], ["random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logger.info", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "bert_adapter_mask_base.SoftCrossEntropy", "contrastive_loss.SupConLoss", "contrastive_loss.DistillKL", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "range", "range", "range", "str", "range", "range", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "str", "str", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "range", "range", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "str", "str", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "range", "range", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "str", "str", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "range", "range", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "range", "str", "str", "range", "str", "str", "range", "str", "str", "str", "str", "range", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "str"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "model", ",", "aux_model", "=", "None", ",", "logger", "=", "None", ",", "taskcla", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "# can deal with aux and unaux", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"device: {} n_gpu: {}\"", ".", "format", "(", "\n", "self", ".", "device", ",", "self", ".", "n_gpu", ")", ")", "\n", "\n", "self", ".", "clipgrad", "=", "10000", "\n", "\n", "self", ".", "aux_model", "=", "aux_model", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "soft_ce", "=", "SoftCrossEntropy", "(", ")", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "self", ".", "kd", "=", "DistillKL", "(", "4", ")", "\n", "\n", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "self", ".", "aux_mask_pre", "=", "None", "\n", "self", ".", "aux_mask_back", "=", "None", "\n", "\n", "\n", "self", ".", "tsv_para", "=", "[", "'adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", "]", "+", "[", "'adapter_capsule_mask.route_weights'", "]", "+", "[", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "]", "+", "[", "'adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.tsv_capsules.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule_mask.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.capsule_net.tsv_capsules.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.output.adapter_capsule.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.capsule_net.tsv_capsules.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.route_weights'", "\n", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.capsule_net.semantic_capsules.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.capsule_net.semantic_capsules.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.fc1.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.weight'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "+", "[", "'bert.encoder.layer.'", "+", "str", "(", "layer_id", ")", "+", "'.attention.output.adapter_capsule.fc2.'", "+", "str", "(", "c_t", ")", "+", "'.bias'", "\n", "for", "c_t", "in", "range", "(", "self", ".", "model", ".", "num_task", ")", "for", "layer_id", "in", "range", "(", "self", ".", "model", ".", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n", "\n", "\n", "\n", "print", "(", "'DIL BERT ADAPTER MASK BASE'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.sup_loss": [[184, 192], ["bert_adapter_mask_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ",", "s", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "sup_loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "sup_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.augment_distill_loss": [[194, 215], ["input_ids.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_adapter_mask_base.Appr.sup_con", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "bert_adapter_mask_base.Appr.model", "pre_output.unsqueeze().clone", "pre_pooled_rep.unsqueeze().clone", "output.clone", "pooled_rep.clone", "pre_output.unsqueeze", "pre_pooled_rep.unsqueeze"], "methods", ["None"], ["", "def", "augment_distill_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ",", "s", ")", ":", "\n", "        ", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "args", ".", "distill_head", ":", "\n", "            ", "outputs", "=", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "                ", "pre_output_dict", "=", "self", ".", "model", "(", "pre_t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ")", "\n", "pre_pooled_rep", "=", "pre_output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "pre_output", "=", "pre_output_dict", "[", "'y'", "]", "\n", "", "", "if", "self", ".", "args", ".", "distill_head", ":", "\n", "            ", "outputs", ".", "append", "(", "pre_output", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ".", "append", "(", "pre_pooled_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "augment_distill_loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "args", "=", "self", ".", "args", ")", "\n", "\n", "return", "augment_distill_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.amix_loss": [[217, 245], ["bert_adapter_mask_base.Appr.model", "bert_adapter_mask_base.Appr.hat_criterion_adapter", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_adapter_mask_base.Appr.sup_con", "mix_pooled_reps.append", "mix_pooled_reps.append", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "mix_output.unsqueeze().clone", "mix_pooled_rep.unsqueeze().clone", "output.clone", "pooled_rep.clone", "mix_output.unsqueeze", "mix_pooled_rep.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter"], ["", "def", "amix_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ",", "s", ")", ":", "\n", "        ", "amix_loss", "=", "0", "\n", "if", "self", ".", "args", ".", "amix_head", ":", "\n", "            ", "mix_pooled_reps", "=", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "mix_pooled_reps", "=", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "\n", "\n", "", "mix_output_dict", "=", "self", ".", "model", "(", "t", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "s", ",", "start_mixup", "=", "True", ")", "\n", "mix_output", "=", "mix_output_dict", "[", "'y'", "]", "\n", "mix_masks", "=", "mix_output_dict", "[", "'masks'", "]", "\n", "mix_pooled_rep", "=", "mix_output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "mix_output", "=", "mix_output", "[", "t", "]", "\n", "", "n_loss", ",", "_", "=", "self", ".", "hat_criterion_adapter", "(", "mix_output", ",", "targets", ",", "mix_masks", ")", "# it self is also training", "\n", "amix_loss", "+=", "n_loss", "# let's first do some pre-training", "\n", "\n", "if", "self", ".", "args", ".", "amix_head", ":", "\n", "            ", "mix_pooled_reps", ".", "append", "(", "mix_output", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "mix_pooled_reps", ".", "append", "(", "mix_pooled_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "\n", "", "cur_mix_outputs", "=", "torch", ".", "cat", "(", "mix_pooled_reps", ",", "dim", "=", "1", ")", "\n", "\n", "amix_loss", "+=", "self", ".", "sup_con", "(", "cur_mix_outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "#train attention and contrastive learning at the same time", "\n", "return", "amix_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter_aux": [[247, 267], ["masks.items", "set", "set", "aux.sum", "m_value.sum", "numpy.prod().item", "numpy.prod().item", "bert_adapter_mask_base.Appr.ce", "masks.keys", "bert_adapter_mask_base.Appr.aux_mask_pre.keys", "numpy.prod", "numpy.prod", "m_value.size"], "methods", ["None"], ["", "def", "hat_criterion_adapter_aux", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ",", "t", "=", "None", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "ewc_loss", "=", "0", "\n", "\n", "if", "self", ".", "aux_mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "key", "in", "set", "(", "masks", ".", "keys", "(", ")", ")", "&", "set", "(", "self", ".", "aux_mask_pre", ".", "keys", "(", ")", ")", ":", "\n", "                ", "m", "=", "masks", "[", "key", "]", "\n", "mp", "=", "self", ".", "aux_mask_pre", "[", "key", "]", "\n", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m_key", ",", "m_value", "in", "masks", ".", "items", "(", ")", ":", "\n", "                ", "reg", "+=", "m_value", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m_value", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "", "", "reg", "/=", "count", "\n", "\n", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", ",", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.hat_criterion_adapter": [[269, 289], ["masks.items", "set", "set", "aux.sum", "m_value.sum", "numpy.prod().item", "numpy.prod().item", "bert_adapter_mask_base.Appr.ce", "masks.keys", "bert_adapter_mask_base.Appr.mask_pre.keys", "numpy.prod", "numpy.prod", "m_value.size"], "methods", ["None"], ["", "def", "hat_criterion_adapter", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "# for m,mp in zip(masks,self.mask_pre):", "\n", "            ", "for", "key", "in", "set", "(", "masks", ".", "keys", "(", ")", ")", "&", "set", "(", "self", ".", "mask_pre", ".", "keys", "(", ")", ")", ":", "\n", "                ", "m", "=", "masks", "[", "key", "]", "\n", "mp", "=", "self", ".", "mask_pre", "[", "key", "]", "\n", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m_key", ",", "m_value", "in", "masks", ".", "items", "(", ")", ":", "\n", "                ", "reg", "+=", "m_value", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m_value", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "", "reg", "/=", "count", "\n", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", ",", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.f1_compute_fn": [[291, 300], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_adapter_mask_base.Appr.acc_compute_fn": [[302, 311], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "accuracy_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "acc_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "accuracy_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.MyContrastive.__init__": [[17, 34], ["torch.nn.Module.__init__", "torch.nn.Sequential().cuda", "torch.nn.Sequential().cuda", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        dim: feature dimension (default: 128)\n        K: queue size; number of negative keys (default: 65536)\n        m: moco momentum of updating key encoder (default: 0.999)\n        T: softmax temperature (default: 0.07)\n        \"\"\"", "\n", "super", "(", "MyContrastive", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "#Z function as a simple 2 layers of MLP", "\n", "self", ".", "contrast_encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "args", ".", "bert_hidden_size", ",", "self", ".", "args", ".", "bert_hidden_size", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "self", ".", "T", "=", "self", ".", "args", ".", "temp", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.MyContrastive.forward": [[36, 83], ["contrastive_loss.MyContrastive.ce", "contrastive_loss.MyContrastive.contrast_encoder", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "contrastive_loss.MyContrastive.contrast_encoder", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.nn.functional.normalize.unsqueeze", "torch.nn.functional.normalize.permute", "torch.nn.functional.normalize.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "aug_x", ",", "order_x", ",", "weights", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Input:\n            im_q: a batch of query images, in our case, Aug(X)\n            im_k: a batch of key images, in our case, F_0, F_1, F_2...., F_n\n        Output:\n            logits, targets; so that you can use cross entropy\n        \"\"\"", "\n", "if", "self", ".", "args", ".", "contrastive_with_mlp", ":", "\n", "# compute query features", "\n", "# print('aug_x: ',aug_x.size())", "\n", "\n", "            ", "aug_x", "=", "self", ".", "contrast_encoder", "(", "aug_x", ")", "# queries: NxC", "\n", "aug_x", "=", "nn", ".", "functional", ".", "normalize", "(", "aug_x", ",", "dim", "=", "1", ")", "\n", "\n", "# print('aug_x: ',aug_x.size())", "\n", "# print('underly_x: ',underly_x.size())", "\n", "\n", "order_x", "=", "self", ".", "contrast_encoder", "(", "order_x", ")", "# keys: NxC", "\n", "order_x", "=", "nn", ".", "functional", ".", "normalize", "(", "order_x", ",", "dim", "=", "1", ")", "\n", "# print('underly_x: ',underly_x.size())", "\n", "\n", "", "else", ":", "\n", "\n", "\n", "            ", "aug_x", "=", "nn", ".", "functional", ".", "normalize", "(", "aug_x", ",", "dim", "=", "-", "1", ")", "\n", "order_x", "=", "nn", ".", "functional", ".", "normalize", "(", "order_x", ",", "dim", "=", "-", "1", ")", "\n", "\n", "\n", "\n", "#we don't need to separate neg and pos", "\n", "#  logits: NxK", "\n", "", "if", "self", ".", "args", ".", "contrastive_with_mlp", ":", "\n", "            ", "l_order", "=", "torch", ".", "einsum", "(", "'nci,nkc->nki'", ",", "[", "aug_x", ".", "unsqueeze", "(", "-", "1", ")", ",", "order_x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "]", ")", ".", "squeeze", "(", "-", "1", ")", "# compute similarity for negative", "\n", "", "else", ":", "\n", "            ", "l_order", "=", "torch", ".", "einsum", "(", "'nci,nkc->nki'", ",", "[", "aug_x", ".", "unsqueeze", "(", "-", "1", ")", ",", "order_x", "]", ")", ".", "squeeze", "(", "-", "1", ")", "# compute similarity for negative", "\n", "\n", "# logits: Nx(1+K)", "\n", "", "logits", "=", "l_order", "\n", "\n", "# apply temperature", "\n", "logits", "/=", "self", ".", "T", "\n", "\n", "# labels: positive key indicators", "\n", "amix_loss", "=", "self", ".", "ce", "(", "logits", ",", "tasks", ")", "\n", "\n", "return", "amix_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.LabelSmoothingCrossEntropy.__init__": [[88, 91], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "eps", ":", "float", "=", "0.1", ",", "size_average", "=", "None", ",", "reduce", "=", "None", ",", "reduction", ":", "str", "=", "'mean'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "size_average", ",", "reduce", ",", "reduction", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.LabelSmoothingCrossEntropy.forward": [[92, 104], ["torch.log_softmax", "torch.log_softmax", "loss.mean", "loss.sum", "ValueError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "Tensor", ",", "target", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "log_input", "=", "F", ".", "log_softmax", "(", "input", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "(", "-", "target", "*", "log_input", ")", ".", "sum", "(", "-", "1", ")", "\n", "if", "self", ".", "reduction", "==", "\"none\"", ":", "\n", "            ", "ret", "=", "loss", "\n", "", "elif", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "ret", "=", "loss", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "ret", "=", "loss", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "self", ".", "reduction", "+", "\" is not valid\"", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.DistillKL.__init__": [[109, 112], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "T", ")", ":", "\n", "        ", "super", "(", "DistillKL", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "T", "=", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.DistillKL.forward": [[113, 118], ["torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.kl_div", "torch.kl_div"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "y_s", ",", "y_t", ")", ":", "\n", "        ", "p_s", "=", "F", ".", "log_softmax", "(", "y_s", "/", "self", ".", "T", ",", "dim", "=", "1", ")", "\n", "p_t", "=", "F", ".", "softmax", "(", "y_t", "/", "self", ".", "T", ",", "dim", "=", "1", ")", "\n", "loss", "=", "F", ".", "kl_div", "(", "p_s", ",", "p_t", ",", "size_average", "=", "False", ")", "*", "(", "self", ".", "T", "**", "2", ")", "/", "y_s", ".", "shape", "[", "0", "]", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.SupConLoss.__init__": [[128, 134], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "temperature", "=", "0.07", ",", "contrast_mode", "=", "'all'", ",", "\n", "base_temperature", "=", "0.07", ")", ":", "\n", "        ", "super", "(", "SupConLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "contrast_mode", "=", "contrast_mode", "\n", "self", ".", "base_temperature", "=", "base_temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.SupConLoss.forward": [[135, 218], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.div", "torch.div", "torch.div", "torch.div", "torch.max", "torch.max", "torch.max", "torch.max", "mask.float().to.float().to.repeat", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "loss.view().mean.view().mean.view().mean", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "len", "ValueError", "len", "features.view.view.view", "ValueError", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "logits_max.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "ValueError", "exp_logits.sum", "mask.float().to.float().to.sum", "loss.view().mean.view().mean.view", "labels.contiguous().view.contiguous().view.contiguous().view", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "mask.float().to.float().to.float().to", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "ValueError", "labels.contiguous().view.contiguous().view.contiguous", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "mask.float().to.float().to.float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "labels", "=", "None", ",", "mask", "=", "None", ",", "scores", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute loss for model. If both `labels` and `mask` are None,\n        it degenerates to SimCLR unsupervised loss:\n        https://arxiv.org/pdf/2002.05709.pdf\n\n        Args:\n            features: hidden vector of shape [bsz, n_views, ...].\n            labels: ground truth of shape [bsz].\n            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n                has the same class as sample i. Can be asymmetric.\n        Returns:\n            A loss scalar.\n        \"\"\"", "\n", "device", "=", "(", "torch", ".", "device", "(", "'cuda'", ")", "\n", "if", "features", ".", "is_cuda", "\n", "else", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "\n", "if", "len", "(", "features", ".", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'`features` needs to be [bsz, n_views, ...],'", "\n", "'at least 3 dimensions are required'", ")", "\n", "", "if", "len", "(", "features", ".", "shape", ")", ">", "3", ":", "\n", "            ", "features", "=", "features", ".", "view", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "", "batch_size", "=", "features", ".", "shape", "[", "0", "]", "\n", "if", "labels", "is", "not", "None", "and", "mask", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Cannot define both `labels` and `mask`'", ")", "\n", "", "elif", "labels", "is", "None", "and", "mask", "is", "None", ":", "\n", "            ", "mask", "=", "torch", ".", "eye", "(", "batch_size", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "labels", "is", "not", "None", ":", "\n", "            ", "labels", "=", "labels", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "if", "labels", ".", "shape", "[", "0", "]", "!=", "batch_size", ":", "\n", "                ", "raise", "ValueError", "(", "'Num of labels does not match num of features'", ")", "\n", "", "mask", "=", "torch", ".", "eq", "(", "labels", ",", "labels", ".", "T", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "#mask out different label, only consider the same label", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "contrast_count", "=", "features", ".", "shape", "[", "1", "]", "\n", "contrast_feature", "=", "torch", ".", "cat", "(", "torch", ".", "unbind", "(", "features", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", "\n", "\n", "if", "self", ".", "contrast_mode", "==", "'one'", ":", "\n", "            ", "anchor_feature", "=", "features", "[", ":", ",", "0", "]", "\n", "anchor_count", "=", "1", "\n", "", "elif", "self", ".", "contrast_mode", "==", "'all'", ":", "\n", "            ", "anchor_feature", "=", "contrast_feature", "\n", "anchor_count", "=", "contrast_count", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "self", ".", "contrast_mode", ")", ")", "\n", "\n", "\n", "# compute logits", "\n", "", "anchor_dot_contrast", "=", "torch", ".", "div", "(", "\n", "torch", ".", "matmul", "(", "anchor_feature", ",", "contrast_feature", ".", "T", ")", ",", "\n", "self", ".", "temperature", ")", "\n", "# logit can be high", "\n", "\n", "# for numerical stability", "\n", "logits_max", ",", "_", "=", "torch", ".", "max", "(", "anchor_dot_contrast", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "logits", "=", "anchor_dot_contrast", "-", "logits_max", ".", "detach", "(", ")", "\n", "\n", "# tile mask", "\n", "mask", "=", "mask", ".", "repeat", "(", "anchor_count", ",", "contrast_count", ")", "\n", "# mask-out self-contrast cases, not the other, so labels==None case is fine", "\n", "logits_mask", "=", "torch", ".", "scatter", "(", "\n", "torch", ".", "ones_like", "(", "mask", ")", ",", "\n", "1", ",", "\n", "torch", ".", "arange", "(", "batch_size", "*", "anchor_count", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "to", "(", "device", ")", ",", "\n", "0", "\n", ")", "\n", "\n", "mask", "=", "mask", "*", "logits_mask", "\n", "\n", "# compute log_prob", "\n", "exp_logits", "=", "(", "torch", ".", "exp", "(", "logits", ")", "*", "logits_mask", ")", "#negative here, even eps, the results are very bad", "\n", "log_prob", "=", "logits", "-", "torch", ".", "log", "(", "exp_logits", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "# finish contrastive loss", "\n", "\n", "# compute mean of log-likelihood over positive", "\n", "mean_log_prob_pos", "=", "(", "mask", "*", "log_prob", ")", ".", "sum", "(", "1", ")", "/", "(", "mask", ".", "sum", "(", "1", ")", "+", "eps", ")", "#postive here", "\n", "\n", "# loss", "\n", "loss", "=", "-", "(", "self", ".", "temperature", "/", "self", ".", "base_temperature", ")", "*", "mean_log_prob_pos", "\n", "loss", "=", "loss", ".", "view", "(", "anchor_count", ",", "batch_size", ")", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.CRDLoss.__init__": [[237, 246], ["torch.nn.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "Embed().to", "Embed().to", "memory.ContrastMemory().to", "ContrastLoss().to", "ContrastLoss().to", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "contrastive_loss.Embed", "contrastive_loss.Embed", "memory.ContrastMemory", "contrastive_loss.ContrastLoss", "contrastive_loss.ContrastLoss"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "CRDLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "self", ".", "embed_s", "=", "Embed", "(", "opt", ".", "s_dim", ",", "opt", ".", "feat_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "embed_t", "=", "Embed", "(", "opt", ".", "t_dim", ",", "opt", ".", "feat_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "contrast", "=", "ContrastMemory", "(", "opt", ".", "feat_dim", ",", "opt", ".", "n_data", ",", "opt", ".", "nce_k", ",", "opt", ".", "nce_t", ",", "opt", ".", "nce_m", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "criterion_t", "=", "ContrastLoss", "(", "opt", ".", "n_data", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "criterion_s", "=", "ContrastLoss", "(", "opt", ".", "n_data", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.CRDLoss.forward": [[247, 269], ["contrastive_loss.CRDLoss.embed_s", "contrastive_loss.CRDLoss.embed_t", "contrastive_loss.CRDLoss.contrast", "contrastive_loss.CRDLoss.criterion_s", "contrastive_loss.CRDLoss.criterion_t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "f_s", ",", "f_t", ",", "idx", ",", "contrast_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            f_s: the feature of student network, size [batch_size, s_dim]\n            f_t: the feature of teacher network, size [batch_size, t_dim]\n            idx: the indices of these positive samples in the dataset, size [batch_size]\n            contrast_idx: the indices of negative samples, size [batch_size, nce_k]\n\n        Returns:\n            The contrastive loss\n        \"\"\"", "\n", "\n", "# print('f_s: ',f_s.size())", "\n", "# print('f_t: ',f_t.size())", "\n", "\n", "f_s", "=", "self", ".", "embed_s", "(", "f_s", ")", "\n", "f_t", "=", "self", ".", "embed_t", "(", "f_t", ")", "\n", "out_s", ",", "out_t", "=", "self", ".", "contrast", "(", "f_s", ",", "f_t", ",", "idx", ",", "contrast_idx", ")", "\n", "s_loss", "=", "self", ".", "criterion_s", "(", "out_s", ")", "\n", "t_loss", "=", "self", ".", "criterion_t", "(", "out_t", ")", "\n", "loss", "=", "s_loss", "+", "t_loss", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.ContrastLoss.__init__": [[275, 278], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "n_data", ")", ":", "\n", "        ", "super", "(", "ContrastLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_data", "=", "n_data", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.ContrastLoss.forward": [[279, 297], ["x.select", "torch.div().log_", "torch.div().log_", "torch.div().log_", "torch.div().log_", "x.narrow", "torch.div().log_", "torch.div().log_", "torch.div().log_", "torch.div().log_", "x.size", "float", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "x.select.add", "x.narrow.clone().fill_", "x.narrow.add", "torch.div().log_.sum", "torch.div().log_.sum", "torch.div().log_.view().sum", "torch.div().log_.view().sum", "x.narrow.clone", "torch.div().log_.view", "torch.div().log_.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "bsz", "=", "x", ".", "shape", "[", "0", "]", "\n", "m", "=", "x", ".", "size", "(", "1", ")", "-", "1", "\n", "\n", "# noise distribution", "\n", "Pn", "=", "1", "/", "float", "(", "self", ".", "n_data", ")", "\n", "\n", "# loss for positive pair", "\n", "P_pos", "=", "x", ".", "select", "(", "1", ",", "0", ")", "\n", "log_D1", "=", "torch", ".", "div", "(", "P_pos", ",", "P_pos", ".", "add", "(", "m", "*", "Pn", "+", "eps", ")", ")", ".", "log_", "(", ")", "\n", "\n", "# loss for K negative pair", "\n", "P_neg", "=", "x", ".", "narrow", "(", "1", ",", "1", ",", "m", ")", "\n", "log_D0", "=", "torch", ".", "div", "(", "P_neg", ".", "clone", "(", ")", ".", "fill_", "(", "m", "*", "Pn", ")", ",", "P_neg", ".", "add", "(", "m", "*", "Pn", "+", "eps", ")", ")", ".", "log_", "(", ")", "\n", "\n", "loss", "=", "-", "(", "log_D1", ".", "sum", "(", "0", ")", "+", "log_D0", ".", "view", "(", "-", "1", ",", "1", ")", ".", "sum", "(", "0", ")", ")", "/", "bsz", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.Embed.__init__": [[301, 305], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "contrastive_loss.Normalize"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "dim_in", "=", "1024", ",", "dim_out", "=", "128", ")", ":", "\n", "        ", "super", "(", "Embed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "dim_in", ",", "dim_out", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.Embed.forward": [[306, 311], ["contrastive_loss.Embed.view", "contrastive_loss.Embed.linear", "contrastive_loss.Embed.l2norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "x", "=", "self", ".", "l2norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.Normalize.__init__": [[315, 318], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "power", "=", "2", ")", ":", "\n", "        ", "super", "(", "Normalize", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "power", "=", "power", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.contrastive_loss.Normalize.forward": [[319, 323], ["x.pow().sum().pow", "x.div", "x.pow().sum", "x.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "norm", "=", "x", ".", "pow", "(", "self", ".", "power", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "1.", "/", "self", ".", "power", ")", "\n", "out", "=", "x", ".", "div", "(", "norm", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.__init__": [[26, 136], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "contrastive_loss.SupConLoss", "contrastive_loss.MyContrastive", "print", "copy.deepcopy", "cnn_base.Appr.model.named_parameters", "copy.deepcopy", "buffer.Buffer", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "buffer.Buffer", "buffer.Buffer", "copy.deepcopy", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "copy.deepcopy", "cnn_base.CheckFederated", "copy.deepcopy", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "cnn_base.Appr.param_name.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "cnn_base.Appr.spare_model.parameters", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "len", "len", "len", "len", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "lr", "=", "0.05", ",", "lr_min", "=", "1e-4", ",", "lr_factor", "=", "3", ",", "lr_patience", "=", "5", ",", "clipgrad", "=", "10000", ",", "args", "=", "None", ",", "taskcla", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "nepochs", "=", "args", ".", "nepochs", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "lr_min", "=", "lr_min", "\n", "self", ".", "lr_factor", "=", "lr_factor", "\n", "self", ".", "lr_patience", "=", "lr_patience", "\n", "self", ".", "clipgrad", "=", "clipgrad", "\n", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# self.optimizer=self._get_optimizer()", "\n", "# self.aux_optimizer=self._get_optimizer_aux()", "\n", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "self", ".", "model_old", "=", "None", "\n", "self", ".", "my_con", "=", "MyContrastive", "(", "args", "=", "args", ")", "# let's use a new version of contrastive loss", "\n", "\n", "\n", "if", "args", ".", "baseline", "==", "'ucl'", ":", "\n", "            ", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "lr_rho", "=", "args", ".", "lr_rho", "\n", "self", ".", "lr_min", "=", "args", ".", "lr", "/", "(", "args", ".", "lr_factor", "**", "5", ")", "\n", "self", ".", "iteration", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "saved", "=", "0", "\n", "self", ".", "beta", "=", "args", ".", "beta", "\n", "self", ".", "drop", "=", "[", "20", ",", "40", ",", "60", ",", "75", ",", "90", "]", "\n", "self", ".", "param_name", "=", "[", "]", "\n", "\n", "for", "(", "name", ",", "p", ")", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "param_name", ".", "append", "(", "name", ")", "\n", "\n", "", "", "if", "args", ".", "baseline", "==", "'one'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ewc'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "model_old", "=", "None", "\n", "self", ".", "fisher", "=", "None", "\n", "self", ".", "lamb", "=", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'owm'", ":", "\n", "            ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "# run on GPU", "\n", "self", ".", "test_max", "=", "0", "\n", "\n", "if", "args", ".", "backbone", "==", "'cnn'", ":", "\n", "                ", "self", ".", "Pc1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "3", "*", "2", "*", "2", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "64", "*", "2", "*", "2", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc3", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "128", "*", "2", "*", "2", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "256", "*", "4", "*", "4", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "1000", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "", "elif", "args", ".", "backbone", "==", "'mlp'", ":", "\n", "                ", "self", ".", "P1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "args", ".", "image_channel", "*", "args", ".", "image_size", "*", "args", ".", "image_size", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "args", ".", "mlp_adapter_size", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "\n", "", "", "if", "args", ".", "baseline", "==", "'derpp'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "mse", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'acl'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'hal'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ",", "self", ".", "args", ".", "ntasks", ",", "mode", "=", "'ring'", ")", "\n", "self", ".", "spare_model", "=", "deepcopy", "(", "model", ")", "\n", "self", ".", "finetuning_epochs", "=", "1", "\n", "self", ".", "anchor_optimization_steps", "=", "100", "\n", "self", ".", "spare_opt", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "spare_model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'cat'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "self", ".", "acc_transfer", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "acc_reference", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "lss_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "similarity_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "self", ".", "transfer_initial_model", "=", "deepcopy", "(", "self", ".", "model", ".", "transfer", ")", "\n", "\n", "self", ".", "check_federated", "=", "CheckFederated", "(", ")", "\n", "self", ".", "history_mask_pre", "=", "[", "]", "\n", "self", ".", "similarities", "=", "[", "]", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'mtl'", ":", "\n", "            ", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "print", "(", "'CNN BASE'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr._get_optimizer_merge": [[137, 140], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_base.Appr.model.parameters", "cnn_base.Appr.aux_model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_merge", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "aux_model", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr._get_optimizer_cat": [[142, 156], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_base.Appr.model.mcl.parameters", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "list", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_base.Appr.model.kt.parameters", "cnn_base.Appr.model.mcl.parameters", "cnn_base.Appr.model.transfer.parameters", "list", "cnn_base.Appr.model.transfer.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_cat", "(", "self", ",", "lr", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "\n", "elif", "phase", "==", "'mcl'", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'mcl'", "and", "'joint'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "kt", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr._get_optimizer": [[159, 162], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "", "def", "_get_optimizer", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr._get_optimizer_owm": [[163, 178], ["list", "list", "filter", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "map", "map", "cnn_base.Appr.model.parameters", "cnn_base.Appr.model.fc1.parameters", "cnn_base.Appr.model.fc2.parameters", "id", "cnn_base.Appr.model.fc1.parameters", "cnn_base.Appr.model.fc2.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_owm", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "# if lr is None:", "\n", "#     lr = self.lr", "\n", "        ", "lr", "=", "self", ".", "lr", "\n", "lr_owm", "=", "self", ".", "lr", "\n", "fc1_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ")", ")", "\n", "fc2_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ")", ")", "\n", "base_params", "=", "filter", "(", "lambda", "p", ":", "id", "(", "p", ")", "not", "in", "fc1_params", "+", "fc2_params", ",", "\n", "self", ".", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "base_params", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "]", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ")", "\n", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr._get_optimizer_ucl": [[179, 186], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "cnn_base.Appr.model.parameters", "cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_ucl", "(", "self", ",", "lr", "=", "None", ",", "lr_rho", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "lr_rho", "is", "None", ":", "lr_rho", "=", "self", ".", "lr_rho", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'Adam'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "lr_rho", "=", "lr_rho", ",", "param_name", "=", "self", ".", "param_name", ")", "\n", "", "if", "self", ".", "args", ".", "optimizer", "==", "'SGD'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.til_output_friendly": [[187, 193], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "[].unsqueeze"], "methods", ["None"], ["", "", "def", "til_output_friendly", "(", "self", ",", "tasks", ",", "outputs", ")", ":", "\n", "        ", "output", "=", "[", "]", "\n", "for", "t_id", ",", "t", "in", "enumerate", "(", "tasks", ")", ":", "#different task in the same batch", "\n", "            ", "output", ".", "append", "(", "outputs", "[", "t", "]", "[", "t_id", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "output", ",", "0", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.sup_loss": [[195, 203], ["cnn_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "images", ",", "targets", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "sup_loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "sup_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.augment_distill_loss": [[205, 235], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_base.Appr.sup_con", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cnn_base.Appr.model", "torch.normalize", "torch.normalize", "torch.normalize", "torch.cat.append", "torch.cat.append", "torch.cat.append", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "pre_pooled_rep.unsqueeze().clone", "torch.normalize.unsqueeze().clone", "pre_output.unsqueeze().clone", "output.clone", "pooled_rep.clone", "pre_pooled_rep.unsqueeze", "torch.normalize.unsqueeze", "pre_output.unsqueeze"], "methods", ["None"], ["", "def", "augment_distill_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "images", ",", "targets", ",", "t", ")", ":", "\n", "        ", "augment_distill_loss", "=", "0", "\n", "for", "pre_t", "in", "range", "(", "t", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "distill_head", ":", "\n", "                ", "outputs", "=", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "#previous models are fixed in any time", "\n", "                ", "pre_output_dict", "=", "self", ".", "model", "(", "pre_t", ",", "images", ",", "s", "=", "self", ".", "smax", ")", "\n", "", "pre_pooled_rep", "=", "pre_output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "if", "self", ".", "args", ".", "distill_head_norm", ":", "\n", "                ", "pre_output", "=", "pre_output_dict", "[", "'y'", "]", "\n", "pre_output_rep", "=", "F", ".", "normalize", "(", "pre_output", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "pre_output", "=", "pre_output_dict", "[", "'y'", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "distill_head", ":", "#append everyone", "\n", "                ", "if", "self", ".", "args", ".", "distill_head_norm", ":", "\n", "                    ", "outputs", ".", "append", "(", "pre_output_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "outputs", ".", "append", "(", "pre_output", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "pre_pooled_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "augment_distill_loss", "+=", "self", ".", "sup_con", "(", "outputs", ",", "args", "=", "self", ".", "args", ")", "#sum up all distillation", "\n", "\n", "", "return", "augment_distill_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.amix_loss": [[238, 280], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_base.Appr.sup_con", "enumerate", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "cnn_base.Appr.model", "cnn_base.Appr.criterion_hat", "mix_pooled_reps.append", "output.clone", "pooled_rep.clone", "range", "torch.normalize", "torch.normalize", "torch.normalize", "mix_pooled_reps.append", "mix_pooled_reps.append", "mix_pooled_rep.unsqueeze().clone", "torch.normalize.unsqueeze().clone", "mix_output.unsqueeze().clone", "mix_pooled_rep.unsqueeze", "torch.normalize.unsqueeze", "mix_output.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat"], ["", "def", "amix_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "images", ",", "targets", ",", "t", ",", "s", ")", ":", "\n", "\n", "#s1: train hat", "\n", "#s2: train aux: aux", "\n", "#s3: train aux: base", "\n", "\n", "        ", "amix_loss", "=", "0", "\n", "if", "self", ".", "args", ".", "amix_head", ":", "\n", "            ", "mix_pooled_reps", "=", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "mix_pooled_reps", "=", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "attn_type", "==", "'self'", ":", "\n", "            ", "orders", "=", "[", "[", "pre_t", "for", "prre_t", "in", "range", "(", "t", ")", "]", "]", "\n", "\n", "for", "order_id", ",", "order", "in", "enumerate", "(", "orders", ")", ":", "\n", "                ", "mix_output_dict", "=", "self", ".", "model", "(", "t", ",", "images", ",", "s", "=", "s", ",", "start_mixup", "=", "True", ",", "l", "=", "order", ",", "idx", "=", "order_id", ",", "mix_type", "=", "self", ".", "args", ".", "mix_type", ")", "\n", "mix_output", "=", "mix_output_dict", "[", "'y'", "]", "\n", "mix_masks", "=", "mix_output_dict", "[", "'masks'", "]", "\n", "mix_pooled_rep", "=", "mix_output_dict", "[", "'normalized_pooled_rep'", "]", "\n", "\n", "if", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "mix_output", "=", "mix_output", "[", "t", "]", "\n", "\n", "", "n_loss", ",", "_", "=", "self", ".", "criterion_hat", "(", "mix_output", ",", "targets", ",", "mix_masks", ")", "# it self is also training", "\n", "amix_loss", "+=", "n_loss", "# let's first do some pre-training", "\n", "\n", "\n", "if", "self", ".", "args", ".", "amix_head", ":", "\n", "                    ", "if", "self", ".", "args", ".", "amix_head_norm", ":", "\n", "                        ", "mix_output_rep", "=", "F", ".", "normalize", "(", "mix_output", ",", "dim", "=", "1", ")", "\n", "mix_pooled_reps", ".", "append", "(", "mix_output_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                        ", "mix_pooled_reps", ".", "append", "(", "mix_output", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "mix_pooled_reps", ".", "append", "(", "mix_pooled_rep", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ")", "\n", "\n", "", "", "", "cur_mix_outputs", "=", "torch", ".", "cat", "(", "mix_pooled_reps", ",", "dim", "=", "1", ")", "\n", "\n", "amix_loss", "+=", "self", ".", "sup_con", "(", "cur_mix_outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "#train attention and contrastive learning at the same time", "\n", "return", "amix_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.ent_id_detection": [[283, 370], ["torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "range", "range", "outputs.append", "torch.softmax", "torch.softmax", "torch.softmax", "entropies.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat", "torch.LongTensor().repeat.to", "torch.LongTensor().repeat.to", "torch.LongTensor().repeat.to", "cnn_base.Appr.model", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "images.size", "cnn_base.Appr.model.forward", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "cnn_base.Appr.model.forward", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "cnn_base.Appr.model.forward", "cnn_base.Appr.model.forward", "outputs_attn.append", "cnn_base.Appr.model.forward"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "def", "ent_id_detection", "(", "self", ",", "trained_task", ",", "images", ",", "t", ")", ":", "\n", "\n", "        ", "output_d", "=", "{", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "outputs_attn", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "\n", "if", "trained_task", "is", "None", ":", "#training", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "t", "+", "1", ")", "\n", "", "else", ":", "#testing", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "trained_task", "+", "1", ")", "\n", "# print('entrop_to_test: ',list(entrop_to_test))", "\n", "", "for", "e", "in", "entrop_to_test", ":", "\n", "            ", "if", "'acl'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "task", "=", "torch", ".", "LongTensor", "(", "[", "e", "]", ")", ".", "repeat", "(", "images", ".", "size", "(", "0", ")", ")", "\n", "tt", "=", "task", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "images", ",", "images", ",", "tt", ",", "trained_task", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "\n", "", "", "elif", "'hat_merge'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "\n", "", "", "elif", "'hat'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e", ",", "images", ",", "s", "=", "self", ".", "smax", ")", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output_d", "[", "'masks'", "]", "=", "masks", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "\n", "", "", "elif", "'ucl'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ",", "sample", "=", "False", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "\n", "", "", "elif", "'cat'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e", ",", "images", ",", "s", "=", "self", ".", "smax", ",", "phase", "=", "'mcl'", ",", "similarity", "=", "self", ".", "similarities", "[", "-", "1", "]", ",", "\n", "history_mask_pre", "=", "self", ".", "history_mask_pre", ",", "check_federated", "=", "self", ".", "check_federated", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "\n", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "output_attn", "=", "output_dict", "[", "'y_attn'", "]", "[", "e", "]", "\n", "\n", "", "outputs_attn", ".", "append", "(", "output_attn", ")", "#shared head", "\n", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output_d", "[", "'masks'", "]", "=", "masks", "\n", "", "else", ":", "\n", "#In TIL setting, we want to know which head to use", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "images", ")", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "                    ", "output", "=", "output_dict", "[", "'y'", "]", "[", "e", "]", "\n", "\n", "", "", "outputs", ".", "append", "(", "output", ")", "#shared head", "\n", "\n", "Y_hat", "=", "F", ".", "softmax", "(", "output", ",", "-", "1", ")", "\n", "entropy", "=", "-", "1", "*", "torch", ".", "sum", "(", "Y_hat", "*", "torch", ".", "log", "(", "Y_hat", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", ")", "\n", "", "inf_task_id", "=", "torch", ".", "argmin", "(", "torch", ".", "stack", "(", "entropies", ")", ")", "\n", "# print('inf_task_id: ',inf_task_id)", "\n", "output", "=", "outputs", "[", "inf_task_id", "]", "\n", "if", "'cat'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "            ", "output_attn", "=", "outputs_attn", "[", "inf_task_id", "]", "\n", "output_d", "[", "'output_attn'", "]", "=", "output_attn", "\n", "\n", "", "output_d", "[", "'output'", "]", "=", "output", "\n", "\n", "return", "output_d", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.criterion_ewc": [[372, 383], ["cnn_base.Appr.ce", "zip", "cnn_base.Appr.ce", "cnn_base.Appr.model.named_parameters", "cnn_base.Appr.model_old.named_parameters", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "criterion_ewc", "(", "self", ",", "t", ",", "output", ",", "targets", ")", ":", "\n", "# Regularization for all previous tasks", "\n", "        ", "if", "self", ".", "args", ".", "eval_only", ":", "\n", "            ", "return", "self", ".", "ce", "(", "output", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "loss_reg", "=", "0", "\n", "if", "t", ">", "0", ":", "\n", "                ", "for", "(", "name", ",", "param", ")", ",", "(", "_", ",", "param_old", ")", "in", "zip", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ",", "self", ".", "model_old", ".", "named_parameters", "(", ")", ")", ":", "\n", "                    ", "loss_reg", "+=", "torch", ".", "sum", "(", "self", ".", "fisher", "[", "name", "]", "*", "(", "param_old", "-", "param", ")", ".", "pow", "(", "2", ")", ")", "/", "2", "\n", "\n", "", "", "return", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "lamb", "*", "loss_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.criterion_hat": [[384, 401], ["zip", "aux.sum", "m.sum", "numpy.prod().item", "cnn_base.Appr.ce", "numpy.prod", "m.size"], "methods", ["None"], ["", "", "def", "criterion_hat", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ",", "t", "=", "None", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "ewc_loss", "=", "0", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "mp", "in", "zip", "(", "masks", ",", "self", ".", "mask_pre", ")", ":", "\n", "                ", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m", "in", "masks", ":", "\n", "                ", "reg", "+=", "m", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "", "reg", "/=", "count", "\n", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", ",", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.Appr.f1_compute_fn": [[402, 411], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "########################################################################################################################", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.CheckFederated.__init__": [[413, 415], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.CheckFederated.set_similarities": [[415, 417], ["None"], "methods", ["None"], ["", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n", "        ", "self", ".", "similarities", "=", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.CheckFederated.fix_length": [[418, 420], ["len"], "methods", ["None"], ["", "def", "fix_length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "similarities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.CheckFederated.get_similarities": [[421, 423], ["None"], "methods", ["None"], ["", "def", "get_similarities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.cnn_base.CheckFederated.check_t": [[425, 436], ["len", "numpy.count_nonzero", "sum", "sum", "len", "itertools.zip_longest", "itertools.zip_longest"], "methods", ["None"], ["", "def", "check_t", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "t", "<", "len", "(", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", ")", "and", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", "[", "t", "]", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "np", ".", "count_nonzero", "(", "self", ".", "similarities", "[", "t", "]", ")", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "t", "<", "len", "(", "self", ".", "similarities", "[", "-", "1", "]", ")", "and", "self", ".", "similarities", "[", "-", "1", "]", "[", "t", "]", "==", "1", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.__init__": [[71, 93], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.get_lr": [[94, 109], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "\n", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.BertAdam.step": [[110, 196], ["closure", "enumerate", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "type", "=", "None", ",", "t", "=", "None", ",", "mask_back", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p_id", ",", "p", "in", "enumerate", "(", "group", "[", "'params'", "]", ")", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "\n", "if", "type", "==", "'mask'", ":", "\n", "# adam may change the grad", "\n", "# Restrict layer gradients in backprop", "\n", "                    ", "if", "t", ">", "0", ":", "\n", "                        ", "n", "=", "group", "[", "'name'", "]", "[", "p_id", "]", "\n", "if", "n", "in", "mask_back", ":", "\n", "                            ", "update", "*=", "mask_back", "[", "n", "]", "\n", "\n", "", "", "", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "\n", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "\n", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_cosine": [[28, 32], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_constant": [[34, 38], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.my_optimization.warmup_linear": [[40, 44], ["max"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "max", "(", "(", "x", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.__init__": [[16, 145], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "bert_cnn_base.Appr._get_optimizer", "contrastive_loss.SupConLoss", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "print", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "copy.deepcopy", "bert_cnn_base.Appr.model.named_parameters", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "copy.deepcopy", "buffer.Buffer", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "buffer.Buffer", "model.parameters", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "buffer.Buffer", "bert_cnn_base.Appr.model.parameters", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.device", "torch.device", "torch.device", "torch.device", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "copy.deepcopy", "bert_cnn_base.CheckFederated", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "bert_cnn_base.Appr.param_name.append", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "bert_cnn_base.Appr.grad_dims.append", "bert_cnn_base.Appr.grad_dims.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pp.data.numel", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "param.data.numel", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "bert_cnn_base.Appr.model.named_parameters", "len", "len", "len", "len", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "numpy.sum", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "logger", ",", "taskcla", ",", "args", "=", "None", ")", ":", "\n", "# def __init__(self,model,nepochs=100,sbatch=64,lr=0.001,lr_min=1e-5,lr_factor=2,lr_patience=3,clipgrad=10000,args=None,logger=None):", "\n", "        ", "self", ".", "model", "=", "model", "\n", "# self.initial_model=deepcopy(model)", "\n", "self", ".", "nepochs", "=", "args", ".", "nepochs", "\n", "self", ".", "lr", "=", "args", ".", "lr", "\n", "self", ".", "lr_min", "=", "args", ".", "lr_min", "\n", "self", ".", "lr_factor", "=", "args", ".", "lr_factor", "\n", "self", ".", "lr_patience", "=", "args", ".", "lr_patience", "\n", "self", ".", "clipgrad", "=", "args", ".", "clipgrad", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "eval_batch_size", "=", "args", ".", "eval_batch_size", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "optimizer", "=", "self", ".", "_get_optimizer", "(", ")", "\n", "self", ".", "sup_con", "=", "SupConLoss", "(", "temperature", "=", "args", ".", "temp", ",", "base_temperature", "=", "args", ".", "base_temp", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "\n", "if", "args", ".", "baseline", "==", "'ewc'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "model_old", "=", "None", "\n", "self", ".", "fisher", "=", "None", "\n", "self", ".", "lamb", "=", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'srk'", ":", "\n", "            ", "self", ".", "control_1_s", "=", "torch", ".", "zeros", "(", "args", ".", "bert_hidden_size", ")", ".", "cuda", "(", ")", "\n", "self", ".", "control_2_s", "=", "torch", ".", "zeros", "(", "args", ".", "bert_hidden_size", ")", ".", "cuda", "(", ")", "\n", "self", ".", "control_3_s", "=", "torch", ".", "zeros", "(", "args", ".", "bert_hidden_size", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'kan'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'ucl'", ":", "\n", "            ", "self", ".", "model_old", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "self", ".", "lr_rho", "=", "args", ".", "lr_rho", "\n", "self", ".", "lr_min", "=", "args", ".", "lr", "/", "(", "args", ".", "lr_factor", "**", "5", ")", "\n", "self", ".", "iteration", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "saved", "=", "0", "\n", "self", ".", "beta", "=", "args", ".", "beta", "\n", "self", ".", "drop", "=", "[", "20", ",", "40", ",", "60", ",", "75", ",", "90", "]", "\n", "self", ".", "param_name", "=", "[", "]", "\n", "\n", "for", "(", "name", ",", "p", ")", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "param_name", ".", "append", "(", "name", ")", "\n", "\n", "\n", "", "", "if", "args", ".", "baseline", "==", "'owm'", ":", "\n", "            ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "# run on GPU", "\n", "self", ".", "Pc1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "Pc3", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "100", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P1", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "300", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "P2", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "eye", "(", "300", ")", ".", "type", "(", "dtype", ")", ",", "volatile", "=", "True", ")", "\n", "self", ".", "test_max", "=", "0", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'one'", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "self", ".", "initial_model", "=", "deepcopy", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'hat'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "# Grid search = [140,200,300,400]; best was 400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'derpp'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "mse", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'gem'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "# Allocate temporary synaptic memory", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "pp", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "self", ".", "grad_dims", ".", "append", "(", "pp", ".", "data", ".", "numel", "(", ")", ")", "\n", "\n", "", "self", ".", "grads_cs", "=", "[", "]", "\n", "self", ".", "grads_da", "=", "torch", ".", "zeros", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'a-gem'", ":", "\n", "            ", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "args", ".", "buffer_size", ",", "self", ".", "device", ")", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "", "self", ".", "grad_xy", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "grad_er", "=", "torch", ".", "Tensor", "(", "np", ".", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'l2'", ":", "\n", "            ", "self", ".", "lamb", "=", "self", ".", "args", ".", "lamb", "# Grid search = [500,1000,2000,5000,10000,20000,50000]; best was 5000", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "}", "# For convenience", "\n", "self", ".", "regularization_terms", "=", "{", "}", "\n", "self", ".", "task_count", "=", "0", "\n", "self", ".", "online_reg", "=", "False", "# True: There will be only one importance matrix and previous model parameters", "\n", "# False: Each task has its own importance matrix and model parameters", "\n", "\n", "\n", "", "if", "args", ".", "baseline", "==", "'cat'", ":", "\n", "            ", "self", ".", "smax", "=", "400", "\n", "self", ".", "thres_cosh", "=", "50", "\n", "self", ".", "thres_emb", "=", "6", "\n", "self", ".", "lamb", "=", "0.75", "\n", "self", ".", "mask_pre", "=", "None", "\n", "self", ".", "mask_back", "=", "None", "\n", "\n", "self", ".", "acc_transfer", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "acc_reference", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "ntasks", ",", "self", ".", "args", ".", "ntasks", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "lss_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "similarity_transfer", "=", "np", ".", "zeros", "(", "(", "len", "(", "taskcla", ")", ",", "len", "(", "taskcla", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "self", ".", "transfer_initial_model", "=", "deepcopy", "(", "self", ".", "model", ".", "transfer", ")", "\n", "\n", "self", ".", "check_federated", "=", "CheckFederated", "(", ")", "\n", "self", ".", "history_mask_pre", "=", "[", "]", "\n", "self", ".", "similarities", "=", "[", "]", "\n", "\n", "", "print", "(", "'CONTEXTUAL + KIM NCL'", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_cat": [[147, 161], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "bert_cnn_base.Appr.model.mcl.parameters", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "list", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "bert_cnn_base.Appr.model.kt.parameters", "bert_cnn_base.Appr.model.mcl.parameters", "bert_cnn_base.Appr.model.transfer.parameters", "list", "bert_cnn_base.Appr.model.transfer.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_cat", "(", "self", ",", "lr", "=", "None", ",", "phase", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "\n", "elif", "phase", "==", "'mcl'", "and", "'no_attention'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'mcl'", "and", "'joint'", "in", "self", ".", "args", ".", "loss_type", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "kt", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'transfer'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "", "elif", "phase", "==", "'reference'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "list", "(", "self", ".", "model", ".", "transfer", ".", "parameters", "(", ")", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.project": [[164, 167], ["torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot"], "methods", ["None"], ["", "", "def", "project", "(", "self", ",", "gxy", ":", "torch", ".", "Tensor", ",", "ger", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "corr", "=", "torch", ".", "dot", "(", "gxy", ",", "ger", ")", "/", "torch", ".", "dot", "(", "ger", ",", "ger", ")", "\n", "return", "gxy", "-", "corr", "*", "ger", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.store_grad": [[169, 185], ["grads.fill_", "params", "numpy.sum", "grads[].copy_", "sum", "param.grad.data.view"], "methods", ["None"], ["", "def", "store_grad", "(", "self", ",", "params", ",", "grads", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This stores parameter gradients of past tasks.\n            pp: parameters\n            grads: gradients\n            grad_dims: list with number of parameters per layers\n        \"\"\"", "\n", "# store the gradients", "\n", "grads", ".", "fill_", "(", "0.0", ")", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "np", ".", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "grads", "[", "begin", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.overwrite_grad": [[187, 204], ["params", "sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "methods", ["None"], ["", "", "def", "overwrite_grad", "(", "self", ",", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n            This is used to overwrite the gradients with a new gradient\n            vector, whenever violations occur.\n            pp: parameters\n            newgrad: corrected gradient\n            grad_dims: list storing number of parameters at each layer\n        \"\"\"", "\n", "count", "=", "0", "\n", "for", "param", "in", "params", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "begin", "=", "0", "if", "count", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "count", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "count", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "begin", ":", "end", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.sup_loss": [[207, 215], ["bert_cnn_base.Appr.sup_con", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.clone().unsqueeze", "output.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "pooled_rep.clone().unsqueeze", "output.clone", "output.clone", "pooled_rep.clone", "pooled_rep.clone"], "methods", ["None"], ["", "", "def", "sup_loss", "(", "self", ",", "output", ",", "pooled_rep", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "targets", ",", "t", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sup_head", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "output", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "torch", ".", "cat", "(", "[", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", ",", "pooled_rep", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "loss", "=", "self", ".", "sup_con", "(", "outputs", ",", "targets", ",", "args", "=", "self", ".", "args", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_owm": [[217, 232], ["list", "list", "filter", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "map", "map", "bert_cnn_base.Appr.model.parameters", "bert_cnn_base.Appr.model.fc1.parameters", "bert_cnn_base.Appr.model.fc2.parameters", "id", "bert_cnn_base.Appr.model.fc1.parameters", "bert_cnn_base.Appr.model.fc2.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_owm", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "# if lr is None:", "\n", "#     lr = self.lr", "\n", "        ", "lr", "=", "self", ".", "lr", "\n", "lr_owm", "=", "self", ".", "lr", "\n", "fc1_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ")", ")", "\n", "fc2_params", "=", "list", "(", "map", "(", "id", ",", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ")", ")", "\n", "base_params", "=", "filter", "(", "lambda", "p", ":", "id", "(", "p", ")", "not", "in", "fc1_params", "+", "fc2_params", ",", "\n", "self", ".", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "base_params", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "{", "'params'", ":", "self", ".", "model", ".", "fc2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_owm", "}", ",", "\n", "]", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ")", "\n", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_ucl": [[233, 240], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "bert_cnn_base.Appr.model.parameters", "bert_cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer_ucl", "(", "self", ",", "lr", "=", "None", ",", "lr_rho", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "lr_rho", "is", "None", ":", "lr_rho", "=", "self", ".", "lr_rho", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'Adam'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "lr_rho", "=", "lr_rho", ",", "param_name", "=", "self", ".", "param_name", ")", "\n", "", "if", "self", ".", "args", ".", "optimizer", "==", "'SGD'", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer_kan": [[242, 261], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "bert_cnn_base.Appr.model.mcl.parameters", "bert_cnn_base.Appr.model.last.parameters", "bert_cnn_base.Appr.model.mcl.parameters", "bert_cnn_base.Appr.model.last.parameters", "bert_cnn_base.Appr.model.ac.parameters", "bert_cnn_base.Appr.model.last.parameters", "bert_cnn_base.Appr.model.ac.parameters", "bert_cnn_base.Appr.model.last.parameters"], "methods", ["None"], ["", "", "def", "_get_optimizer_kan", "(", "self", ",", "lr", "=", "None", ",", "which_type", "=", "None", ")", ":", "\n", "\n", "        ", "if", "which_type", "==", "'mcl'", ":", "\n", "            ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "SGD", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "mcl", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "\n", "", "", "elif", "which_type", "==", "'ac'", ":", "\n", "            ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "return", "torch", ".", "optim", ".", "SGD", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "ac", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "                    ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "ac", ".", "parameters", "(", ")", "]", "+", "[", "p", "for", "p", "in", "self", ".", "model", ".", "last", ".", "parameters", "(", ")", "]", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr._get_optimizer": [[264, 275], ["print", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "bert_cnn_base.Appr.model.parameters", "print", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "bert_cnn_base.Appr.model.parameters", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "bert_cnn_base.Appr.model.parameters"], "methods", ["None"], ["", "", "", "def", "_get_optimizer", "(", "self", ",", "lr", "=", "None", ")", ":", "\n", "        ", "if", "lr", "is", "None", ":", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "args", ".", "optimizer", "==", "'sgd'", "and", "self", ".", "args", ".", "momentum", ":", "\n", "            ", "print", "(", "'sgd+momentum'", ")", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "print", "(", "'sgd'", ")", "\n", "return", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "", "elif", "self", ".", "args", ".", "optimizer", "==", "'adam'", ":", "\n", "            ", "print", "(", "'adam'", ")", "\n", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.ent_id_detection": [[277, 310], ["torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "range", "range", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "outputs.append", "torch.softmax", "torch.softmax", "entropies.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_cnn_base.Appr.model.forward", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "bert_cnn_base.Appr.model.forward", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward"], ["", "", "def", "ent_id_detection", "(", "self", ",", "trained_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "t", ",", "which_type", "=", "None", ")", ":", "\n", "\n", "        ", "output_d", "=", "{", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "\n", "if", "trained_task", "is", "None", ":", "#training", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "t", "+", "1", ")", "\n", "", "else", ":", "#testing", "\n", "            ", "entrop_to_test", "=", "range", "(", "0", ",", "trained_task", "+", "1", ")", "\n", "\n", "", "for", "e", "in", "entrop_to_test", ":", "\n", "            ", "e_task", "=", "torch", ".", "LongTensor", "(", "[", "e", "]", ")", ".", "cuda", "(", ")", "\n", "if", "'hat'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "s", "=", "self", ".", "smax", ")", "\n", "masks", "=", "output_dict", "[", "'masks'", "]", "\n", "output_d", "[", "'masks'", "]", "=", "masks", "\n", "\n", "", "elif", "'kan'", "in", "self", ".", "args", ".", "baseline", ":", "\n", "                ", "output_dict", "=", "self", ".", "model", ".", "forward", "(", "e_task", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "which_type", ",", "s", "=", "self", ".", "smax", ")", "\n", "", "output", "=", "output_dict", "[", "'y'", "]", "\n", "outputs", ".", "append", "(", "output", ")", "#shared head", "\n", "\n", "Y_hat", "=", "F", ".", "softmax", "(", "output", ",", "-", "1", ")", "\n", "entropy", "=", "-", "1", "*", "torch", ".", "sum", "(", "Y_hat", "*", "torch", ".", "log", "(", "Y_hat", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", ")", "\n", "", "inf_task_id", "=", "torch", ".", "argmin", "(", "torch", ".", "stack", "(", "entropies", ")", ")", "\n", "output", "=", "outputs", "[", "inf_task_id", "]", "\n", "\n", "output_d", "[", "'output'", "]", "=", "output", "\n", "\n", "return", "output_d", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_hat": [[314, 329], ["zip", "aux.sum", "m.sum", "numpy.prod().item", "bert_cnn_base.Appr.ce", "numpy.prod", "m.size"], "methods", ["None"], ["", "def", "criterion_hat", "(", "self", ",", "outputs", ",", "targets", ",", "masks", ")", ":", "\n", "        ", "reg", "=", "0", "\n", "count", "=", "0", "\n", "if", "self", ".", "mask_pre", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "mp", "in", "zip", "(", "masks", ",", "self", ".", "mask_pre", ")", ":", "\n", "                ", "aux", "=", "1", "-", "mp", "\n", "reg", "+=", "(", "m", "*", "aux", ")", ".", "sum", "(", ")", "\n", "count", "+=", "aux", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "m", "in", "masks", ":", "\n", "                ", "reg", "+=", "m", ".", "sum", "(", ")", "\n", "count", "+=", "np", ".", "prod", "(", "m", ".", "size", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "", "reg", "/=", "count", "\n", "return", "self", ".", "ce", "(", "outputs", ",", "targets", ")", "+", "self", ".", "lamb", "*", "reg", ",", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.criterion_ewc": [[330, 338], ["zip", "bert_cnn_base.Appr.ce", "bert_cnn_base.Appr.model.named_parameters", "bert_cnn_base.Appr.model_old.named_parameters", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "criterion_ewc", "(", "self", ",", "t", ",", "output", ",", "targets", ")", ":", "\n", "# Regularization for all previous tasks", "\n", "        ", "loss_reg", "=", "0", "\n", "if", "t", ">", "0", ":", "\n", "            ", "for", "(", "name", ",", "param", ")", ",", "(", "_", ",", "param_old", ")", "in", "zip", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ",", "self", ".", "model_old", ".", "named_parameters", "(", ")", ")", ":", "\n", "                ", "loss_reg", "+=", "torch", ".", "sum", "(", "self", ".", "fisher", "[", "name", "]", "*", "(", "param_old", "-", "param", ")", ".", "pow", "(", "2", ")", ")", "/", "2", "\n", "\n", "", "", "return", "self", ".", "ce", "(", "output", ",", "targets", ")", "+", "self", ".", "lamb", "*", "loss_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.Appr.f1_compute_fn": [[341, 350], ["y_true.cpu().numpy.cpu().numpy.cpu().numpy", "y_pred.cpu().numpy.cpu().numpy.cpu().numpy", "f1_score", "RuntimeError", "y_true.cpu().numpy.cpu().numpy.cpu", "y_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "f1_compute_fn", "(", "self", ",", "y_true", ",", "y_pred", ",", "average", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "sklearn", ".", "metrics", "import", "f1_score", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"This contrib module requires sklearn to be installed.\"", ")", "\n", "\n", "", "y_true", "=", "y_true", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "average", ")", "\n", "########################################################################################################################", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.__init__": [[352, 354], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.set_similarities": [[354, 356], ["None"], "methods", ["None"], ["", "def", "set_similarities", "(", "self", ",", "similarities", ")", ":", "\n", "        ", "self", ".", "similarities", "=", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.fix_length": [[357, 359], ["len"], "methods", ["None"], ["", "def", "fix_length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "similarities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.get_similarities": [[360, 362], ["None"], "methods", ["None"], ["", "def", "get_similarities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.bert_cnn_base.CheckFederated.check_t": [[364, 375], ["len", "numpy.count_nonzero", "sum", "sum", "len", "itertools.zip_longest", "itertools.zip_longest"], "methods", ["None"], ["", "def", "check_t", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "t", "<", "len", "(", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", ")", "and", "[", "sum", "(", "x", ")", "for", "x", "in", "zip_longest", "(", "*", "self", ".", "similarities", ",", "fillvalue", "=", "0", ")", "]", "[", "t", "]", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "np", ".", "count_nonzero", "(", "self", ".", "similarities", "[", "t", "]", ")", ">", "0", ":", "\n", "            ", "return", "True", "\n", "\n", "", "elif", "t", "<", "len", "(", "self", ".", "similarities", "[", "-", "1", "]", ")", "and", "self", ".", "similarities", "[", "-", "1", "]", "[", "t", "]", "==", "1", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.__init__": [[10, 22], ["torch.nn.Module.__init__", "torch.ones", "memory.AliasMethod", "memory.ContrastMemory.multinomial.cuda", "memory.ContrastMemory.register_buffer", "memory.ContrastMemory.register_buffer", "memory.ContrastMemory.register_buffer", "torch.tensor", "math.sqrt", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["def", "__init__", "(", "self", ",", "inputSize", ",", "outputSize", ",", "K", ",", "T", "=", "0.07", ",", "momentum", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "ContrastMemory", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nLem", "=", "outputSize", "\n", "self", ".", "unigrams", "=", "torch", ".", "ones", "(", "self", ".", "nLem", ")", "\n", "self", ".", "multinomial", "=", "AliasMethod", "(", "self", ".", "unigrams", ")", "\n", "self", ".", "multinomial", ".", "cuda", "(", ")", "\n", "self", ".", "K", "=", "K", "\n", "\n", "self", ".", "register_buffer", "(", "'params'", ",", "torch", ".", "tensor", "(", "[", "K", ",", "T", ",", "-", "1", ",", "-", "1", ",", "momentum", "]", ")", ")", "\n", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "inputSize", "/", "3", ")", "\n", "self", ".", "register_buffer", "(", "'memory_v1'", ",", "torch", ".", "rand", "(", "outputSize", ",", "inputSize", ")", ".", "mul_", "(", "2", "*", "stdv", ")", ".", "add_", "(", "-", "stdv", ")", ")", "\n", "self", ".", "register_buffer", "(", "'memory_v2'", ",", "torch", ".", "rand", "(", "outputSize", ",", "inputSize", ")", ".", "mul_", "(", "2", "*", "stdv", ")", ".", "add_", "(", "-", "stdv", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.ContrastMemory.forward": [[23, 80], ["int", "memory.ContrastMemory.params[].item", "memory.ContrastMemory.params[].item", "memory.ContrastMemory.params[].item", "memory.ContrastMemory.params[].item", "v1.size", "memory.ContrastMemory.memory_v1.size", "memory.ContrastMemory.memory_v1.size", "torch.index_select().detach", "weight_v1.view.view.view", "torch.bmm", "torch.exp", "torch.index_select().detach", "weight_v2.view.view.view", "torch.bmm", "torch.exp", "torch.div().contiguous", "torch.div().contiguous", "memory.ContrastMemory.params[].item", "memory.ContrastMemory.multinomial.draw().view", "memory.ContrastMemory.select().copy_", "v2.view", "torch.div", "v1.view", "torch.div", "memory.ContrastMemory.params[].clone().detach().item", "print", "memory.ContrastMemory.params[].clone().detach().item", "print", "torch.no_grad", "torch.index_select", "torch.index_select.mul_", "torch.index_select.add_", "torch.index_select.pow().sum().pow", "torch.index_select.div", "memory.ContrastMemory.memory_v1.index_copy_", "torch.index_select", "torch.index_select.mul_", "torch.index_select.add_", "torch.index_select.pow().sum().pow", "torch.index_select.div", "memory.ContrastMemory.memory_v2.index_copy_", "torch.index_select", "torch.index_select", "torch.div().contiguous.mean", "torch.div().contiguous.mean", "torch.div", "torch.div", "y.view", "torch.mul", "y.view", "torch.mul", "memory.ContrastMemory.multinomial.draw", "memory.ContrastMemory.select", "memory.ContrastMemory.view", "memory.ContrastMemory.view", "memory.ContrastMemory.params[].clone().detach", "memory.ContrastMemory.params[].clone().detach", "torch.index_select.pow().sum", "torch.index_select.pow().sum", "memory.ContrastMemory.params[].clone", "memory.ContrastMemory.params[].clone", "torch.index_select.pow", "torch.index_select.pow"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.draw"], ["", "def", "forward", "(", "self", ",", "v1", ",", "v2", ",", "y", ",", "idx", "=", "None", ")", ":", "\n", "        ", "K", "=", "int", "(", "self", ".", "params", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "T", "=", "self", ".", "params", "[", "1", "]", ".", "item", "(", ")", "\n", "Z_v1", "=", "self", ".", "params", "[", "2", "]", ".", "item", "(", ")", "\n", "Z_v2", "=", "self", ".", "params", "[", "3", "]", ".", "item", "(", ")", "\n", "\n", "momentum", "=", "self", ".", "params", "[", "4", "]", ".", "item", "(", ")", "\n", "batchSize", "=", "v1", ".", "size", "(", "0", ")", "\n", "outputSize", "=", "self", ".", "memory_v1", ".", "size", "(", "0", ")", "\n", "inputSize", "=", "self", ".", "memory_v1", ".", "size", "(", "1", ")", "\n", "\n", "# original score computation", "\n", "if", "idx", "is", "None", ":", "\n", "            ", "idx", "=", "self", ".", "multinomial", ".", "draw", "(", "batchSize", "*", "(", "self", ".", "K", "+", "1", ")", ")", ".", "view", "(", "batchSize", ",", "-", "1", ")", "\n", "idx", ".", "select", "(", "1", ",", "0", ")", ".", "copy_", "(", "y", ".", "data", ")", "\n", "# sample", "\n", "", "weight_v1", "=", "torch", ".", "index_select", "(", "self", ".", "memory_v1", ",", "0", ",", "idx", ".", "view", "(", "-", "1", ")", ")", ".", "detach", "(", ")", "\n", "weight_v1", "=", "weight_v1", ".", "view", "(", "batchSize", ",", "K", "+", "1", ",", "inputSize", ")", "\n", "out_v2", "=", "torch", ".", "bmm", "(", "weight_v1", ",", "v2", ".", "view", "(", "batchSize", ",", "inputSize", ",", "1", ")", ")", "\n", "out_v2", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "out_v2", ",", "T", ")", ")", "\n", "# sample", "\n", "weight_v2", "=", "torch", ".", "index_select", "(", "self", ".", "memory_v2", ",", "0", ",", "idx", ".", "view", "(", "-", "1", ")", ")", ".", "detach", "(", ")", "\n", "weight_v2", "=", "weight_v2", ".", "view", "(", "batchSize", ",", "K", "+", "1", ",", "inputSize", ")", "\n", "out_v1", "=", "torch", ".", "bmm", "(", "weight_v2", ",", "v1", ".", "view", "(", "batchSize", ",", "inputSize", ",", "1", ")", ")", "\n", "out_v1", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "out_v1", ",", "T", ")", ")", "\n", "\n", "# set Z if haven't been set yet", "\n", "if", "Z_v1", "<", "0", ":", "\n", "            ", "self", ".", "params", "[", "2", "]", "=", "out_v1", ".", "mean", "(", ")", "*", "outputSize", "\n", "Z_v1", "=", "self", ".", "params", "[", "2", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "print", "(", "\"normalization constant Z_v1 is set to {:.1f}\"", ".", "format", "(", "Z_v1", ")", ")", "\n", "", "if", "Z_v2", "<", "0", ":", "\n", "            ", "self", ".", "params", "[", "3", "]", "=", "out_v2", ".", "mean", "(", ")", "*", "outputSize", "\n", "Z_v2", "=", "self", ".", "params", "[", "3", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "print", "(", "\"normalization constant Z_v2 is set to {:.1f}\"", ".", "format", "(", "Z_v2", ")", ")", "\n", "\n", "# compute out_v1, out_v2", "\n", "", "out_v1", "=", "torch", ".", "div", "(", "out_v1", ",", "Z_v1", ")", ".", "contiguous", "(", ")", "\n", "out_v2", "=", "torch", ".", "div", "(", "out_v2", ",", "Z_v2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# update memory", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "l_pos", "=", "torch", ".", "index_select", "(", "self", ".", "memory_v1", ",", "0", ",", "y", ".", "view", "(", "-", "1", ")", ")", "\n", "l_pos", ".", "mul_", "(", "momentum", ")", "\n", "l_pos", ".", "add_", "(", "torch", ".", "mul", "(", "v1", ",", "1", "-", "momentum", ")", ")", "\n", "l_norm", "=", "l_pos", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "0.5", ")", "\n", "updated_v1", "=", "l_pos", ".", "div", "(", "l_norm", ")", "\n", "self", ".", "memory_v1", ".", "index_copy_", "(", "0", ",", "y", ",", "updated_v1", ")", "\n", "\n", "ab_pos", "=", "torch", ".", "index_select", "(", "self", ".", "memory_v2", ",", "0", ",", "y", ".", "view", "(", "-", "1", ")", ")", "\n", "ab_pos", ".", "mul_", "(", "momentum", ")", "\n", "ab_pos", ".", "add_", "(", "torch", ".", "mul", "(", "v2", ",", "1", "-", "momentum", ")", ")", "\n", "ab_norm", "=", "ab_pos", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "0.5", ")", "\n", "updated_v2", "=", "ab_pos", ".", "div", "(", "ab_norm", ")", "\n", "self", ".", "memory_v2", ".", "index_copy_", "(", "0", ",", "y", ",", "updated_v2", ")", "\n", "\n", "", "return", "out_v1", ",", "out_v2", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.__init__": [[86, 122], ["len", "torch.zeros", "torch.LongTensor", "enumerate", "probs.sum", "probs.div_", "smaller.pop", "larger.pop", "probs.sum", "smaller.append", "larger.append", "len", "len", "smaller.append", "larger.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "probs", ")", ":", "\n", "\n", "        ", "if", "probs", ".", "sum", "(", ")", ">", "1", ":", "\n", "            ", "probs", ".", "div_", "(", "probs", ".", "sum", "(", ")", ")", "\n", "", "K", "=", "len", "(", "probs", ")", "\n", "self", ".", "prob", "=", "torch", ".", "zeros", "(", "K", ")", "\n", "self", ".", "alias", "=", "torch", ".", "LongTensor", "(", "[", "0", "]", "*", "K", ")", "\n", "\n", "# Sort the data into the outcomes with probabilities", "\n", "# that are larger and smaller than 1/K.", "\n", "smaller", "=", "[", "]", "\n", "larger", "=", "[", "]", "\n", "for", "kk", ",", "prob", "in", "enumerate", "(", "probs", ")", ":", "\n", "            ", "self", ".", "prob", "[", "kk", "]", "=", "K", "*", "prob", "\n", "if", "self", ".", "prob", "[", "kk", "]", "<", "1.0", ":", "\n", "                ", "smaller", ".", "append", "(", "kk", ")", "\n", "", "else", ":", "\n", "                ", "larger", ".", "append", "(", "kk", ")", "\n", "\n", "# Loop though and create little binary mixtures that", "\n", "# appropriately allocate the larger outcomes over the", "\n", "# overall uniform mixture.", "\n", "", "", "while", "len", "(", "smaller", ")", ">", "0", "and", "len", "(", "larger", ")", ">", "0", ":", "\n", "            ", "small", "=", "smaller", ".", "pop", "(", ")", "\n", "large", "=", "larger", ".", "pop", "(", ")", "\n", "\n", "self", ".", "alias", "[", "small", "]", "=", "large", "\n", "self", ".", "prob", "[", "large", "]", "=", "(", "self", ".", "prob", "[", "large", "]", "-", "1.0", ")", "+", "self", ".", "prob", "[", "small", "]", "\n", "\n", "if", "self", ".", "prob", "[", "large", "]", "<", "1.0", ":", "\n", "                ", "smaller", ".", "append", "(", "large", ")", "\n", "", "else", ":", "\n", "                ", "larger", ".", "append", "(", "large", ")", "\n", "\n", "", "", "for", "last_one", "in", "smaller", "+", "larger", ":", "\n", "            ", "self", ".", "prob", "[", "last_one", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda": [[123, 126], ["memory.AliasMethod.prob.cuda", "memory.AliasMethod.alias.cuda"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda", "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.cuda"], ["", "", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "prob", "=", "self", ".", "prob", ".", "cuda", "(", ")", "\n", "self", ".", "alias", "=", "self", ".", "alias", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.base.memory.AliasMethod.draw": [[127, 140], ["memory.AliasMethod.alias.size", "torch.zeros().random_", "memory.AliasMethod.prob.index_select", "memory.AliasMethod.alias.index_select", "torch.bernoulli", "torch.zeros().random_.mul", "memory.AliasMethod.mul", "torch.bernoulli.long", "torch.zeros"], "methods", ["None"], ["", "def", "draw", "(", "self", ",", "N", ")", ":", "\n", "        ", "\"\"\" Draw N samples from multinomial \"\"\"", "\n", "K", "=", "self", ".", "alias", ".", "size", "(", "0", ")", "\n", "\n", "kk", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "prob", ".", "device", ")", ".", "random_", "(", "0", ",", "K", ")", "\n", "prob", "=", "self", ".", "prob", ".", "index_select", "(", "0", ",", "kk", ")", "\n", "alias", "=", "self", ".", "alias", ".", "index_select", "(", "0", ",", "kk", ")", "\n", "# b is whether a random number is greater than q", "\n", "b", "=", "torch", ".", "bernoulli", "(", "prob", ")", "\n", "oq", "=", "kk", ".", "mul", "(", "b", ".", "long", "(", ")", ")", "\n", "oj", "=", "alias", ".", "mul", "(", "(", "1", "-", "b", ")", ".", "long", "(", ")", ")", "\n", "\n", "return", "oq", "+", "oj", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.dataloaders.contrastive_dataset.InstanceSample.__init__": [[35, 77], ["torch.utils.data.TensorDataset.__init__", "len", "range", "range", "numpy.asarray", "numpy.asarray", "contrastive_dataset.InstanceSample.cls_positive[].append", "range", "numpy.asarray", "numpy.asarray", "int", "range", "range", "contrastive_dataset.InstanceSample.cls_negative[].extend", "range", "range", "len", "numpy.random.permutation", "range"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__"], ["def", "__init__", "(", "self", ",", "*", "tensors", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "tensors", ")", "\n", "k", "=", "transformer_args", ".", "nce_k", "\n", "mode", "=", "'exact'", "\n", "is_sample", "=", "True", "\n", "percent", "=", "1.0", "\n", "self", ".", "image_tasks", "=", "[", "'celeba'", "]", "\n", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "is_sample", "=", "is_sample", "\n", "\n", "num_classes", "=", "transformer_args", ".", "nclasses", "\n", "num_samples", "=", "len", "(", "tensors", "[", "0", "]", ")", "\n", "\n", "if", "transformer_args", ".", "task", "in", "self", ".", "image_tasks", ":", "\n", "            ", "label", "=", "tensors", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "tensors", "[", "-", "2", "]", "\n", "\n", "\n", "", "self", ".", "cls_positive", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "i", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "self", ".", "cls_positive", "[", "label", "[", "i", "]", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "self", ".", "cls_negative", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "num_classes", ")", ":", "\n", "                ", "if", "j", "==", "i", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "cls_negative", "[", "i", "]", ".", "extend", "(", "self", ".", "cls_positive", "[", "j", "]", ")", "\n", "\n", "", "", "self", ".", "cls_positive", "=", "[", "np", ".", "asarray", "(", "self", ".", "cls_positive", "[", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "self", ".", "cls_negative", "=", "[", "np", ".", "asarray", "(", "self", ".", "cls_negative", "[", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "if", "0", "<", "percent", "<", "1", ":", "\n", "            ", "n", "=", "int", "(", "len", "(", "self", ".", "cls_negative", "[", "0", "]", ")", "*", "percent", ")", "\n", "self", ".", "cls_negative", "=", "[", "np", ".", "random", ".", "permutation", "(", "self", ".", "cls_negative", "[", "i", "]", ")", "[", "0", ":", "n", "]", "\n", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "", "self", ".", "cls_positive", "=", "np", ".", "asarray", "(", "self", ".", "cls_positive", ")", "\n", "self", ".", "cls_negative", "=", "np", ".", "asarray", "(", "self", ".", "cls_negative", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.dataloaders.contrastive_dataset.InstanceSample.__getitem__": [[78, 102], ["numpy.random.choice", "numpy.hstack", "tuple", "numpy.random.choice", "NotImplementedError", "len", "numpy.asarray"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "transformer_args", ".", "task", "in", "self", ".", "image_tasks", ":", "\n", "            ", "target", "=", "self", ".", "tensors", "[", "-", "1", "]", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "target", "=", "self", ".", "tensors", "[", "-", "2", "]", "[", "index", "]", "\n", "\n", "\n", "# sample contrastive examples", "\n", "", "if", "self", ".", "mode", "==", "'exact'", ":", "\n", "            ", "pos_idx", "=", "index", "\n", "", "elif", "self", ".", "mode", "==", "'relax'", ":", "\n", "            ", "pos_idx", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "cls_positive", "[", "target", "]", ",", "1", ")", "#TODO: need to fix the seed", "\n", "pos_idx", "=", "pos_idx", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "self", ".", "mode", ")", "\n", "", "replace", "=", "True", "if", "self", ".", "k", ">", "len", "(", "self", ".", "cls_negative", "[", "target", "]", ")", "else", "False", "\n", "neg_idx", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "cls_negative", "[", "target", "]", ",", "self", ".", "k", ",", "replace", "=", "replace", ")", "\n", "sample_idx", "=", "np", ".", "hstack", "(", "(", "np", ".", "asarray", "(", "[", "pos_idx", "]", ")", ",", "neg_idx", ")", ")", "\n", "\n", "# print('index: ',index)", "\n", "# print('sample_idx: ',sample_idx)", "\n", "\n", "return", "tuple", "(", "[", "tensor", "[", "index", "]", "for", "tensor", "in", "self", ".", "tensors", "]", "+", "[", "index", "]", "+", "[", "sample_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATrain.__init__": [[245, 271], ["os.listdir", "torch.cat().view", "torch.LongTensor().view().numpy", "open", "json.load", "data[].items", "torch.cat", "torch.LongTensor().view", "value.items", "range", "len", "celeba.CELEBATrain.user.append", "torch.LongTensor", "numpy.array", "PIL.Image.open", "numpy.array", "celeba.CELEBATrain.x.append", "celeba.CELEBATrain.y.append", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "size", "=", "[", "218", ",", "178", ",", "3", "]", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "user", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "            ", "with", "open", "(", "root_dir", "+", "file", ")", "as", "json_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "json_file", ")", "# read file and do whatever we need to do.", "\n", "for", "key", ",", "value", "in", "data", "[", "'user_data'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "for", "type", ",", "data", "in", "value", ".", "items", "(", ")", ":", "\n", "                        ", "if", "type", "==", "'x'", ":", "\n", "                            ", "for", "img", "in", "data", ":", "\n", "                                ", "img_name", "=", "img_dir", "+", "img", "\n", "im", "=", "Image", ".", "open", "(", "img_name", ")", "\n", "np_im", "=", "np", ".", "array", "(", "im", ")", "\n", "self", ".", "x", ".", "append", "(", "torch", ".", "from_numpy", "(", "np_im", ")", ")", "\n", "", "", "elif", "type", "==", "'y'", ":", "\n", "                            ", "self", ".", "y", ".", "append", "(", "data", ")", "\n", "\n", "", "", "for", "_", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                        ", "self", ".", "user", ".", "append", "(", "key", ")", "\n", "\n", "", "", "", "", "self", ".", "x", "=", "torch", ".", "cat", "(", "self", ".", "x", ",", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "size", "[", "0", "]", ",", "self", ".", "size", "[", "1", "]", ",", "self", ".", "size", "[", "2", "]", ")", "\n", "self", ".", "y", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "[", "d", "for", "f", "in", "self", ".", "y", "for", "d", "in", "f", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATrain.__len__": [[272, 274], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATrain.__getitem__": [[275, 288], ["celeba.CELEBATrain.data.numpy", "PIL.Image.fromarray", "celeba.CELEBATrain.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "user", "=", "self", ".", "user", "[", "idx", "]", "\n", "x", "=", "self", ".", "x", "[", "idx", "]", "\n", "y", "=", "self", ".", "y", "[", "idx", "]", "\n", "\n", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "x", "=", "Image", ".", "fromarray", "(", "x", ")", "\n", "# x = Image.fromarray((x * 255).astype(np.uint8))", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "user", ",", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATest.__init__": [[297, 323], ["os.listdir", "torch.cat().view", "torch.LongTensor().view().numpy", "open", "json.load", "data[].items", "torch.cat", "torch.LongTensor().view", "value.items", "range", "len", "celeba.CELEBATest.user.append", "torch.LongTensor", "numpy.array", "PIL.Image.open", "numpy.array", "celeba.CELEBATest.x.append", "celeba.CELEBATest.y.append", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "size", "=", "[", "218", ",", "178", ",", "3", "]", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "user", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "            ", "with", "open", "(", "root_dir", "+", "file", ")", "as", "json_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "json_file", ")", "# read file and do whatever we need to do.", "\n", "for", "key", ",", "value", "in", "data", "[", "'user_data'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "for", "type", ",", "data", "in", "value", ".", "items", "(", ")", ":", "\n", "                        ", "if", "type", "==", "'x'", ":", "\n", "                            ", "for", "img", "in", "data", ":", "\n", "                                ", "img_name", "=", "img_dir", "+", "img", "\n", "im", "=", "Image", ".", "open", "(", "img_name", ")", "\n", "np_im", "=", "np", ".", "array", "(", "im", ")", "\n", "self", ".", "x", ".", "append", "(", "torch", ".", "from_numpy", "(", "np_im", ")", ")", "\n", "", "", "elif", "type", "==", "'y'", ":", "\n", "                            ", "self", ".", "y", ".", "append", "(", "data", ")", "\n", "\n", "", "", "for", "_", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                        ", "self", ".", "user", ".", "append", "(", "key", ")", "\n", "\n", "", "", "", "", "self", ".", "x", "=", "torch", ".", "cat", "(", "self", ".", "x", ",", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "size", "[", "0", "]", ",", "self", ".", "size", "[", "1", "]", ",", "self", ".", "size", "[", "2", "]", ")", "\n", "self", ".", "y", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "[", "d", "for", "f", "in", "self", ".", "y", "for", "d", "in", "f", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATest.__len__": [[324, 326], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.CELEBATest.__getitem__": [[327, 340], ["celeba.CELEBATest.data.numpy", "PIL.Image.fromarray", "celeba.CELEBATest.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "user", "=", "self", ".", "user", "[", "idx", "]", "\n", "x", "=", "self", ".", "x", "[", "idx", "]", "\n", "y", "=", "self", ".", "y", "[", "idx", "]", "\n", "\n", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "x", "=", "Image", ".", "fromarray", "(", "x", ")", "\n", "# x = Image.fromarray((x * 255).astype(np.uint8))", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "user", ",", "x", ",", "y", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.get": [[15, 36], ["print", "celeba.read_celeba", "range", "print", "str", "open", "[].split", "all_celeba.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.read_celeba"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'celeba_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "data_celeba", ",", "taskcla_celeba", "=", "read_celeba", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "all_celeba", "=", "[", "data_celeba", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "celeba_id", "=", "all_celeba", ".", "index", "(", "random_sep", "[", "t", "]", ")", "\n", "data", "[", "t", "]", "=", "data_celeba", "[", "celeba_id", "]", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data_celeba", "[", "celeba_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.celeba.celeba.read_celeba": [[37, 234], ["range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "celeba.CELEBATrain", "celeba.CELEBATest", "users.sort", "print", "print", "enumerate", "range", "dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "len", "torch.utils.data.DataLoader", "enumerate", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "str", "str", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "set", "str", "[].append", "[].append", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "target.numpy", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.expanduser", "os.path.expanduser", "numpy.array", "torch.utils.data.DataLoader", "str", "str", "str", "str", "users.index", "users.index"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_celeba", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "data_type", "=", "args", ".", "data_size", "\n", "\n", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "\n", "# celeba", "\n", "dat", "=", "{", "}", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "\n", "\n", "if", "args", ".", "unseen", "and", "args", ".", "ntasks_unseen", ":", "\n", "        ", "file_name", "=", "'./dat/celeba/'", "+", "data_type", "+", "'_binary_celeba_unseen/'", "+", "str", "(", "args", ".", "ntasks_unseen", ")", "+", "'/'", "\n", "", "else", ":", "\n", "        ", "file_name", "=", "'./dat/celeba/'", "+", "data_type", "+", "'_binary_celeba/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", "\n", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "file_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "\n", "train_dataset", "=", "CELEBATrain", "(", "root_dir", "=", "'./dat/celeba/'", "+", "data_type", "+", "'/iid/train/'", ",", "img_dir", "=", "'./dat/celeba/data/raw/img_align_celeba/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "size", "=", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ")", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'train'", "]", "=", "train_dataset", "\n", "\n", "test_dataset", "=", "CELEBATest", "(", "root_dir", "=", "'./dat/celeba/'", "+", "data_type", "+", "'/iid/test/'", ",", "img_dir", "=", "'./dat/celeba/data/raw/img_align_celeba/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "size", "=", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ")", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "test_dataset", "\n", "\n", "users", "=", "[", "x", "[", "0", "]", "for", "x", "in", "set", "(", "[", "user", "for", "user", ",", "image", ",", "target", "in", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "'train'", "]", ",", "batch_size", "=", "1", ")", "]", ")", "]", "# not shuffle", "\n", "users", ".", "sort", "(", ")", "\n", "\n", "if", "args", ".", "unseen", ":", "\n", "            ", "users", "=", "users", "[", "args", ".", "ntasks", ":", "args", ".", "ntasks", "+", "args", ".", "ntasks_unseen", "]", "# the first ntasks are seen, no overalpping", "\n", "", "else", ":", "\n", "            ", "users", "=", "users", "[", ":", "args", ".", "ntasks", "]", "\n", "", "print", "(", "'users: '", ",", "users", ")", "\n", "print", "(", "'users length: '", ",", "len", "(", "users", ")", ")", "\n", "\n", "# # totally 10 tasks, each tasks 2 classes (whether smiling)", "\n", "#", "\n", "for", "task_id", ",", "user", "in", "enumerate", "(", "users", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'celeba-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "2", "\n", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "\n", "for", "task_id", ",", "user", "in", "enumerate", "(", "users", ")", ":", "\n", "                ", "data", "[", "task_id", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "\n", "", "for", "user", ",", "image", ",", "target", "in", "loader", ":", "\n", "                ", "if", "user", "[", "0", "]", "not", "in", "users", ":", "continue", "# we dont want too may tasks", "\n", "label", "=", "target", ".", "numpy", "(", ")", "[", "0", "]", "\n", "data", "[", "users", ".", "index", "(", "user", "[", "0", "]", ")", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "users", ".", "index", "(", "user", "[", "0", "]", ")", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "label", ")", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'celeba-'", "+", "str", "(", "n", ")", "\n", "\n", "# Real Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.asc.bert.get": [[69, 173], ["print", "print", "print", "print", "range", "data.keys", "open", "[].split", "len", "len", "print", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "nlp_data_utils.ABSATokenizer.from_pretrained", "data_utils.AscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.AscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "transformers.BertTokenizer.from_pretrained", "data_utils.AscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "taskcla.append", "int", "len", "len", "len", "len", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features"], []], "home.repos.pwc.inspect_result.zixuanke_pycontinual.asc.w2v_as.embedding_generation": [[84, 155], ["w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "os.listdir", "os.path.exists", "open", "open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "open", "len", "json.load", "enumerate", "asc_file.readlines", "len", "asc_str.append", "set", "[].replace", "enumerate", "review.split", "aspect_str.split", "asc_str.append", "set.add", "set.add", "review.split", "review.split", "each_aspect.split", "aspect_str.split", "review.split", "each_aspect.split", "aspect_str.split"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_as_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_as_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/w2v_as_vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_as_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_as_vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.asc.w2v_as.get": [[156, 281], ["w2v_as.embedding_generation", "print", "print", "print", "print", "range", "data.keys", "print", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.AscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "open", "[].split", "len", "len", "domains.index", "taskcla.append", "int", "len", "len", "len", "len", "math.ceil", "int", "f_random_seq.readlines", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as"], ["", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "if", "'der'", "in", "args", ".", "approach", "or", "'a-gem'", "in", "args", ".", "approach", ":", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "else", ":", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v_as", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_term_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_term_sentence_ids", ",", "# return term_sentence as sentence, thus no need to change other guys", "\n", "all_label_ids", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "num_train_steps", "\n", "\n", "valid_examples", "=", "processor", ".", "get_dev_examples", "(", "dataset", ")", "\n", "valid_features", "=", "data_utils", ".", "convert_examples_to_features_w2v_as", "(", "valid_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "valid_all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_term_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "valid_data", "=", "TensorDataset", "(", "\n", "valid_all_tokens_term_ids", ",", "\n", "valid_all_tokens_term_sentence_ids", ",", "# return term_sentence as sentence, thus no need to change other guys", "\n", "valid_all_label_ids", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running validations *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num orig examples = %d\"", ",", "len", "(", "valid_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num split examples = %d\"", ",", "len", "(", "valid_features", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "valid_data", "\n", "\n", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "eval_examples", "=", "processor", ".", "get_test_examples", "(", "dataset", ")", "\n", "eval_features", "=", "data_utils", ".", "convert_examples_to_features_w2v_as", "(", "eval_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_term_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_sentence_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "eval_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_term_sentence_ids", ",", "# return term_sentence as sentence, thus no need to change other guys", "\n", "all_label_ids", ")", "\n", "\n", "data", "[", "t", "]", "[", "'test'", "]", "=", "eval_data", "\n", "\n", "t", "+=", "1", "\n", "\n", "\n", "# Others", "\n", "", "f_name", "=", "'asc_random'", "\n", "data_asc", "=", "{", "}", "\n", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "print", "(", "'domains: '", ",", "domains", ")", "\n", "\n", "print", "(", "'random_sep: '", ",", "len", "(", "random_sep", ")", ")", "\n", "print", "(", "'domains: '", ",", "len", "(", "domains", ")", ")", "\n", "\n", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "# print('task_id: ',task_id)", "\n", "        ", "asc_id", "=", "domains", ".", "index", "(", "random_sep", "[", "task_id", "]", ")", "\n", "data_asc", "[", "task_id", "]", "=", "data", "[", "asc_id", "]", "\n", "taskcla", ".", "append", "(", "(", "task_id", ",", "int", "(", "data", "[", "asc_id", "]", "[", "'ncla'", "]", ")", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "print", "(", "'W2V AS'", ")", "\n", "\n", "return", "data_asc", ",", "taskcla", ",", "vocab_size", ",", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.asc.w2v.embedding_generation": [[82, 153], ["w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "os.listdir", "os.path.exists", "open", "open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "open", "len", "json.load", "enumerate", "asc_file.readlines", "len", "asc_str.append", "set", "[].replace", "enumerate", "review.split", "aspect_str.split", "asc_str.append", "set.add", "set.add", "review.split", "review.split", "each_aspect.split", "aspect_str.split", "review.split", "each_aspect.split", "aspect_str.split"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.asc.w2v.get": [[154, 274], ["w2v.embedding_generation", "print", "print", "print", "print", "range", "data.keys", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_w2v", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.AscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_w2v", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_w2v", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "open", "[].split", "len", "len", "domains.index", "taskcla.append", "int", "len", "len", "len", "len", "math.ceil", "int", "f_random_seq.readlines", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v"], ["", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_sentence_ids", ",", "\n", "all_label_ids", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "num_train_steps", "\n", "\n", "valid_examples", "=", "processor", ".", "get_dev_examples", "(", "dataset", ")", "\n", "valid_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "valid_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "valid_all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "valid_data", "=", "TensorDataset", "(", "\n", "valid_all_tokens_term_ids", ",", "\n", "valid_all_tokens_sentence_ids", ",", "\n", "valid_all_label_ids", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running validations *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num orig examples = %d\"", ",", "len", "(", "valid_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num split examples = %d\"", ",", "len", "(", "valid_features", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "valid_data", "\n", "\n", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "eval_examples", "=", "processor", ".", "get_test_examples", "(", "dataset", ")", "\n", "eval_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "eval_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "eval_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_sentence_ids", ",", "\n", "all_label_ids", ")", "\n", "\n", "data", "[", "t", "]", "[", "'test'", "]", "=", "eval_data", "\n", "\n", "t", "+=", "1", "\n", "\n", "\n", "# Others", "\n", "", "f_name", "=", "'asc_random'", "\n", "data_asc", "=", "{", "}", "\n", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "print", "(", "'domains: '", ",", "domains", ")", "\n", "\n", "print", "(", "'random_sep: '", ",", "len", "(", "random_sep", ")", ")", "\n", "print", "(", "'domains: '", ",", "len", "(", "domains", ")", ")", "\n", "\n", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "# print('task_id: ',task_id)", "\n", "        ", "asc_id", "=", "domains", ".", "index", "(", "random_sep", "[", "task_id", "]", ")", "\n", "data_asc", "[", "task_id", "]", "=", "data", "[", "asc_id", "]", "\n", "taskcla", ".", "append", "(", "(", "task_id", ",", "int", "(", "data", "[", "asc_id", "]", "[", "'ncla'", "]", ")", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "\n", "return", "data_asc", ",", "taskcla", ",", "vocab_size", ",", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.fashionmnist.dil_fashionmnist.get": [[15, 36], ["print", "dil_fashionmnist.read_fashionmnist", "range", "print", "str", "open", "[].split", "all_fashionmnist.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.fashionmnist.dil_fashionmnist.read_fashionmnist"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'fashionmnist_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "data_fashionmnist", ",", "taskcla_fashionmnist", "=", "read_fashionmnist", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "all_fashionmnist", "=", "[", "data_fashionmnist", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "fashionmnist_id", "=", "all_fashionmnist", ".", "index", "(", "random_sep", "[", "t", "]", ")", "\n", "data", "[", "t", "]", "=", "data_fashionmnist", "[", "fashionmnist_id", "]", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data_fashionmnist", "[", "fashionmnist_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.fashionmnist.dil_fashionmnist.read_fashionmnist": [[37, 245], ["range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "range", "dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "print", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "candidate_x_train.append", "candidate_y_train.append", "candidate_x_test.append", "candidate_y_test.append", "print", "print", "print", "print", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "str", "len", "len", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "len", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "set", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "str", "str", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "[].cpu().numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.expanduser", "os.path.expanduser", "numpy.array", "str", "str", "[].cpu", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_fashionmnist", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "\n", "# fashionmnist", "\n", "dat", "=", "{", "}", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", "\n", "\n", "\n", "candidate_train", "=", "datasets", ".", "FashionMNIST", "(", "'./dat/'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "candidate_test", "=", "datasets", ".", "FashionMNIST", "(", "'./dat/'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_train", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_train", "=", "[", "]", "\n", "candidate_y_train", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_train", ".", "append", "(", "image", ")", "\n", "candidate_y_train", ".", "append", "(", "target", ")", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_test", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_test", "=", "[", "]", "\n", "candidate_y_test", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_test", ".", "append", "(", "image", ")", "\n", "candidate_y_test", ".", "append", "(", "target", ")", "\n", "\n", "\n", "", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'fashionmnist-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "10", "\n", "\n", "\n", "print", "(", "'candidate_x_train: '", ",", "len", "(", "candidate_x_train", ")", ")", "\n", "print", "(", "'candidate_y_train: '", ",", "len", "(", "candidate_y_train", ")", ")", "\n", "\n", "\n", "if", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", "==", "1", ":", "\n", "                ", "current_x_train", "=", "candidate_x_train", "\n", "current_y_train", "=", "candidate_y_train", "\n", "current_x_test", "=", "candidate_x_test", "\n", "current_y_test", "=", "candidate_y_test", "\n", "\n", "\n", "", "else", ":", "\n", "                ", "candidate_x_train", ",", "current_x_train", ",", "candidate_y_train", ",", "current_y_train", "=", "train_test_split", "(", "candidate_x_train", ",", "candidate_y_train", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_train", ")", "\n", "candidate_x_test", ",", "current_x_test", ",", "candidate_y_test", ",", "current_y_test", "=", "train_test_split", "(", "candidate_x_test", ",", "candidate_y_test", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_test", ")", "\n", "\n", "\n", "", "print", "(", "'candidate_x_train: '", ",", "len", "(", "candidate_x_train", ")", ")", "\n", "print", "(", "'candidate_y_train: '", ",", "len", "(", "candidate_y_train", ")", ")", "\n", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'x'", "]", "+=", "current_x_train", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'y'", "]", "+=", "current_y_train", "\n", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'x'", "]", "+=", "current_x_test", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'y'", "]", "+=", "current_y_test", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/fashionmnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'fashionmnist-'", "+", "str", "(", "n", ")", "\n", "\n", "# Real Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "#checked whether all tasks have samples for all set of labels. #62", "\n", "print", "(", "\" data[t]['train']['y']: \"", ",", "len", "(", "set", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.nli.bert.get": [[38, 191], ["print", "print", "range", "data.keys", "open", "[].split", "print", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "nlp_data_utils.ABSATokenizer.from_pretrained", "data_utils.AscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "data_utils.AscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "transformers.BertTokenizer.from_pretrained", "data_utils.AscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "taskcla.append", "random.Random().shuffle", "int", "len", "contrastive_dataset.InstanceSample", "torch.utils.data.TensorDataset", "random.Random().shuffle", "contrastive_dataset.InstanceSample", "torch.utils.data.TensorDataset", "len", "len", "len", "contrastive_dataset.InstanceSample", "torch.utils.data.TensorDataset", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "random.Random", "random.Random", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features"], ["            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.nli.w2v_as.embedding_generation": [[42, 93], ["w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "os.listdir", "os.path.exists", "gzip.open", "gzip.open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "open", "len", "json.load", "enumerate", "len", "asc_str.append"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["'./dat/absa/Bing5Domains/asc/CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'./dat/absa/Bing5Domains/asc/CanonG3'", ",", "\n", "'./dat/absa/Bing5Domains/asc/ApexAD2600Progressive'", ",", "\n", "\n", "'./dat/absa/Bing9Domains/asc/CanonPowerShotSD500'", ",", "\n", "'./dat/absa/Bing9Domains/asc/CanonS100'", ",", "\n", "'./dat/absa/Bing9Domains/asc/DiaperChamp'", ",", "\n", "'./dat/absa/Bing9Domains/asc/HitachiRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/ipod'", ",", "\n", "'./dat/absa/Bing9Domains/asc/LinksysRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/MicroMP3'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Nokia6600'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Norton'", ",", "\n", "]", "\n", "\n", "\n", "\n", "domains", "=", "[", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "'Bing3domains_Computer'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'Bing5domains_CanonG3'", ",", "\n", "'Bing5domains_ApexAD2600Progressive'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "'Bing9domains_HitachiRouter'", ",", "\n", "'Bing9domains_ipod'", ",", "\n", "'Bing9domains_LinksysRouter'", ",", "\n", "'Bing9domains_MicroMP3'", ",", "\n", "'Bing9domains_Nokia6600'", ",", "\n", "'Bing9domains_Norton'", "]", "\n", "\n", "\n", "def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.nli.w2v_as.get": [[94, 213], ["w2v_as.embedding_generation", "print", "print", "print", "print", "range", "data.keys", "print", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.AscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.AscProcessor", "data_utils.AscProcessor.get_labels", "data_utils.AscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_w2v_as", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "open", "[].split", "len", "len", "domains.index", "taskcla.append", "int", "len", "len", "len", "len", "math.ceil", "int", "f_random_seq.readlines", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_as"], ["                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_as_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_as_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/w2v_as_vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_as_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_as_vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n", "", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "if", "'der'", "in", "args", ".", "approach", "or", "'a-gem'", "in", "args", ".", "approach", ":", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "else", ":", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v_as", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_term_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_term_sentence_ids", ",", "# return term_sentence as sentence, thus no need to change other guys", "\n", "all_label_ids", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "num_train_steps", "\n", "\n", "valid_examples", "=", "processor", ".", "get_dev_examples", "(", "dataset", ")", "\n", "valid_features", "=", "data_utils", ".", "convert_examples_to_features_w2v_as", "(", "valid_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "valid_all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_term_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "valid_data", "=", "TensorDataset", "(", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.ssc.bert.get": [[29, 137], ["print", "print", "range", "data.keys", "open", "[].split", "print", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "nlp_data_utils.ABSATokenizer.from_pretrained", "data_utils.DscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_dsc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_dsc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "transformers.BertTokenizer.from_pretrained", "data_utils.DscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_dsc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "taskcla.append", "random.Random().shuffle", "int", "len", "random.Random().shuffle", "len", "len", "len", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "random.Random", "random.Random", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc"], ["\n", "#BERT fixed all ===========", "\n", "# for param in self.bert.parameters():", "\n", "#     param.requires_grad = False", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.ssc.w2v.embedding_generation": [[27, 77], ["w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "os.listdir", "os.path.exists", "open", "open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "open", "len", "json.load", "enumerate", "len", "asc_str.append"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["]", "\n", "\n", "\n", "datasets", "=", "[", "\n", "'./dat/absa/XuSemEval/asc/14/rest'", ",", "\n", "'./dat/absa/XuSemEval/asc/14/laptop'", ",", "\n", "\n", "'./dat/absa/Bing3Domains/asc/Speaker'", ",", "\n", "'./dat/absa/Bing3Domains/asc/Router'", ",", "\n", "'./dat/absa/Bing3Domains/asc/Computer'", ",", "\n", "\n", "'./dat/absa/Bing5Domains/asc/Nokia6610'", ",", "\n", "'./dat/absa/Bing5Domains/asc/NikonCoolpix4300'", ",", "\n", "'./dat/absa/Bing5Domains/asc/CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'./dat/absa/Bing5Domains/asc/CanonG3'", ",", "\n", "'./dat/absa/Bing5Domains/asc/ApexAD2600Progressive'", ",", "\n", "\n", "'./dat/absa/Bing9Domains/asc/CanonPowerShotSD500'", ",", "\n", "'./dat/absa/Bing9Domains/asc/CanonS100'", ",", "\n", "'./dat/absa/Bing9Domains/asc/DiaperChamp'", ",", "\n", "'./dat/absa/Bing9Domains/asc/HitachiRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/ipod'", ",", "\n", "'./dat/absa/Bing9Domains/asc/LinksysRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/MicroMP3'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Nokia6600'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Norton'", ",", "\n", "]", "\n", "\n", "\n", "\n", "domains", "=", "[", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "'Bing3domains_Computer'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'Bing5domains_CanonG3'", ",", "\n", "'Bing5domains_ApexAD2600Progressive'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "'Bing9domains_HitachiRouter'", ",", "\n", "'Bing9domains_ipod'", ",", "\n", "'Bing9domains_LinksysRouter'", ",", "\n", "'Bing9domains_MicroMP3'", ",", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.ssc.w2v.get": [[78, 192], ["w2v.embedding_generation", "print", "print", "range", "data.keys", "open", "[].split", "print", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "data_utils.DscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "data_utils.DscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "taskcla.append", "random.Random().shuffle", "int", "len", "random.Random().shuffle", "len", "len", "len", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "random.Random", "random.Random", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc"], ["'Bing9domains_Nokia6600'", ",", "\n", "'Bing9domains_Norton'", "]", "\n", "\n", "\n", "def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n", "", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.newsgroup.bert.get": [[41, 195], ["print", "print", "enumerate", "range", "data.keys", "str", "open", "[].split", "datasets.load_dataset", "datasets.load_dataset.train_test_split", "d_split[].train_test_split", "dataset[].items", "int", "taskcla.append", "str", "[].append", "random_sep[].split", "int", "nlp_data_utils.DtcProcessor", "data_utils.DtcProcessor.get_labels", "nlp_data_utils.ABSATokenizer.from_pretrained", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_dtc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_dtc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DtcProcessor", "data_utils.DtcProcessor.get_labels", "transformers.BertTokenizer.from_pretrained", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_dtc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "f_random_seq.readlines", "int", "len", "len", "len", "len", "math.ceil", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dtc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dtc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dtc"], ["for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.newsgroup.w2v.embedding_generation": [[51, 104], ["enumerate", "w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "datasets.load_dataset", "datasets.load_dataset.train_test_split", "d_split[].train_test_split", "os.path.exists", "open", "open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "len", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get"], ["'./dat/absa/Bing9Domains/asc/Nokia6600'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Norton'", ",", "\n", "]", "\n", "\n", "\n", "\n", "domains", "=", "[", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "'Bing3domains_Computer'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'Bing5domains_CanonG3'", ",", "\n", "'Bing5domains_ApexAD2600Progressive'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "'Bing9domains_HitachiRouter'", ",", "\n", "'Bing9domains_ipod'", ",", "\n", "'Bing9domains_LinksysRouter'", ",", "\n", "'Bing9domains_MicroMP3'", ",", "\n", "'Bing9domains_Nokia6600'", ",", "\n", "'Bing9domains_Norton'", "]", "\n", "\n", "\n", "def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.newsgroup.w2v.get": [[105, 255], ["w2v.embedding_generation", "print", "print", "enumerate", "range", "data.keys", "str", "open", "[].split", "datasets.load_dataset", "datasets.load_dataset.train_test_split", "d_split[].train_test_split", "dataset[].items", "int", "taskcla.append", "str", "[].append", "random_sep[].split", "int", "nlp_data_utils.DtcProcessor", "data_utils.DtcProcessor.get_labels", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DtcProcessor", "data_utils.DtcProcessor.get_labels", "data_utils.DtcProcessor._create_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "f_random_seq.readlines", "int", "len", "len", "len", "len", "math.ceil", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.StringProcessor._create_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc"], ["\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n", "", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_sentence_ids", ",", "\n", "all_label_ids", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "num_train_steps", "\n", "\n", "valid_examples", "=", "processor", ".", "get_dev_examples", "(", "dataset", ")", "\n", "valid_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "valid_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "valid_all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "valid_all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "valid_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "valid_data", "=", "TensorDataset", "(", "\n", "valid_all_tokens_term_ids", ",", "\n", "valid_all_tokens_sentence_ids", ",", "\n", "valid_all_label_ids", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running validations *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num orig examples = %d\"", ",", "len", "(", "valid_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num split examples = %d\"", ",", "len", "(", "valid_features", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "valid_data", "\n", "\n", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "eval_examples", "=", "processor", ".", "get_test_examples", "(", "dataset", ")", "\n", "eval_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "eval_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "eval_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_sentence_ids", ",", "\n", "all_label_ids", ")", "\n", "\n", "data", "[", "t", "]", "[", "'test'", "]", "=", "eval_data", "\n", "\n", "t", "+=", "1", "\n", "\n", "\n", "# Others", "\n", "", "f_name", "=", "'asc_random'", "\n", "data_asc", "=", "{", "}", "\n", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "print", "(", "'domains: '", ",", "domains", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar10.dil_cifar10.get": [[15, 36], ["print", "dil_cifar10.read_cifar10", "range", "print", "str", "open", "[].split", "all_cifar10.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar10.dil_cifar10.read_cifar10"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'cifar10_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "data_cifar10", ",", "taskcla_cifar10", "=", "read_cifar10", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "all_cifar10", "=", "[", "data_cifar10", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "cifar10_id", "=", "all_cifar10", ".", "index", "(", "random_sep", "[", "t", "]", ")", "\n", "data", "[", "t", "]", "=", "data_cifar10", "[", "cifar10_id", "]", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data_cifar10", "[", "cifar10_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar10.dil_cifar10.hetero_partition": [[38, 80], ["range", "range", "numpy.random.shuffle", "numpy.random.dirichlet", "numpy.array", "print", "enumerate", "print", "print", "print", "numpy.random.shuffle", "range", "numpy.where", "numpy.repeat", "np.array.sum", "visited_ele.append", "len", "len", "numpy.split", "idx.tolist", "zip", "zip", "numpy.split", "len", "numpy.cumsum", "len", "visited_ele.index", "visited_ele.index", "visited_ele.index", "visited_ele.index"], "function", ["None"], ["", "def", "hetero_partition", "(", "args", ",", "K", ",", "N", ",", "y", ")", ":", "\n", "    ", "net_dataidx_map", "=", "{", "}", "\n", "\n", "idx_batch", "=", "[", "[", "]", "for", "_", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "# for each class in the dataset", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "idx_k", "=", "np", ".", "where", "(", "y", "==", "k", ")", "[", "0", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx_k", ")", "\n", "proportions", "=", "np", ".", "random", ".", "dirichlet", "(", "np", ".", "repeat", "(", "0.5", ",", "args", ".", "ntasks", ")", ")", "\n", "## Balance", "\n", "proportions", "=", "np", ".", "array", "(", "[", "p", "*", "(", "len", "(", "idx_j", ")", "<", "N", "/", "args", ".", "ntasks", ")", "for", "p", ",", "idx_j", "in", "zip", "(", "proportions", ",", "idx_batch", ")", "]", ")", "\n", "proportions", "=", "proportions", "/", "proportions", ".", "sum", "(", ")", "\n", "proportions", "=", "(", "np", ".", "cumsum", "(", "proportions", ")", "*", "len", "(", "idx_k", ")", ")", ".", "astype", "(", "int", ")", "[", ":", "-", "1", "]", "\n", "\n", "print", "(", "'proportions: '", ",", "proportions", ")", "#proportion is a soted 1-D array", "\n", "\n", "visited_ele", "=", "[", "]", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "proportions", ")", ":", "\n", "\n", "            ", "if", "proportions", "[", "0", "]", "==", "0", ":", "\n", "                ", "alloc", "=", "proportions", "[", "1", "]", "//", "2", "\n", "proportions", "[", "0", "]", "+=", "alloc", "\n", "\n", "", "if", "ele", "in", "visited_ele", ":", "#some classes has 0 samples", "\n", "                ", "alloc", "=", "(", "visited_ele", "[", "visited_ele", ".", "index", "(", "ele", ")", "]", "-", "visited_ele", "[", "visited_ele", ".", "index", "(", "ele", ")", "-", "1", "]", ")", "//", "2", "\n", "proportions", "[", "visited_ele", ".", "index", "(", "ele", ")", "]", "-=", "alloc", "\n", "visited_ele", "[", "visited_ele", ".", "index", "(", "ele", ")", "]", "-=", "alloc", "\n", "", "visited_ele", ".", "append", "(", "ele", ")", "\n", "\n", "", "print", "(", "'proportions: '", ",", "proportions", ")", "#proportion is a soted 1-D array", "\n", "\n", "\n", "\n", "print", "(", "'np.split(idx_k,proportions): '", ",", "len", "(", "np", ".", "split", "(", "idx_k", ",", "proportions", ")", ")", ")", "\n", "idx_batch", "=", "[", "idx_j", "+", "idx", ".", "tolist", "(", ")", "for", "idx_j", ",", "idx", "in", "zip", "(", "idx_batch", ",", "np", ".", "split", "(", "idx_k", ",", "proportions", ")", ")", "]", "#split and corresponding to different task", "\n", "print", "(", "'idx_batch: '", ",", "len", "(", "idx_batch", ")", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "idx_batch", "[", "j", "]", ")", "\n", "net_dataidx_map", "[", "j", "]", "=", "idx_batch", "[", "j", "]", "\n", "\n", "", "return", "net_dataidx_map", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar10.dil_cifar10.read_cifar10": [[81, 300], ["range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "range", "dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "print", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "candidate_x_train.append", "candidate_y_train.append", "candidate_x_test.append", "candidate_y_test.append", "numpy.array", "dil_cifar10.hetero_partition", "range", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "len", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "net_dataidx_map_train.append", "net_dataidx_map_test.append", "str", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "set", "str", "str", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "[].cpu().numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.expanduser", "os.path.expanduser", "numpy.array", "int", "int", "[].cpu", "str", "str", "len", "len", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar10.dil_cifar10.hetero_partition", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_cifar10", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "data_type", "=", "args", ".", "data_size", "\n", "\n", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "\n", "# cifar10", "\n", "dat", "=", "{", "}", "\n", "\n", "#TODO:  one should save the data down since it takes a very long time if reload every time", "\n", "if", "args", ".", "hetero", ":", "path_name", "=", "'./dat/cifar10/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", "+", "'hetero/'", "\n", "else", ":", "path_name", "=", "'./dat/cifar10/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", "+", "'homo/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "path_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path_name", ")", "\n", "\n", "candidate_train", "=", "datasets", ".", "CIFAR10", "(", "'./dat/'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "candidate_test", "=", "datasets", ".", "CIFAR10", "(", "'./dat/'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_train", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_train", "=", "[", "]", "\n", "candidate_y_train", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_train", ".", "append", "(", "image", ")", "\n", "candidate_y_train", ".", "append", "(", "target", ")", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_test", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_test", "=", "[", "]", "\n", "candidate_y_test", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_test", ".", "append", "(", "image", ")", "\n", "candidate_y_test", ".", "append", "(", "target", ")", "\n", "\n", "", "if", "args", ".", "hetero", ":", "\n", "\n", "            ", "candidate_y", "=", "candidate_y_train", "+", "candidate_y_test", "\n", "#reallocate the trainig and testing set. since the training set are now become non-i.i.d, while we want trainig and testing are i.i.d", "\n", "candidate_x", "=", "candidate_x_train", "+", "candidate_x_test", "\n", "\n", "candidate_y", "=", "np", ".", "array", "(", "candidate_y", ")", "\n", "\n", "K", "=", "10", "#class", "\n", "N", "=", "candidate_y", ".", "shape", "[", "0", "]", "\n", "net_dataidx_map", "=", "hetero_partition", "(", "args", ",", "K", ",", "N", ",", "candidate_y", ")", "\n", "\n", "net_dataidx_map_train", "=", "[", "]", "\n", "net_dataidx_map_test", "=", "[", "]", "\n", "\n", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "                ", "net_dataidx_map_train", ".", "append", "(", "net_dataidx_map", "[", "task_id", "]", "[", ":", "int", "(", "len", "(", "net_dataidx_map", "[", "task_id", "]", ")", "*", "0.8", ")", "]", ")", "\n", "net_dataidx_map_test", ".", "append", "(", "net_dataidx_map", "[", "task_id", "]", "[", "int", "(", "len", "(", "net_dataidx_map", "[", "task_id", "]", ")", "*", "0.8", ")", ":", "]", ")", "\n", "\n", "\n", "", "", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'cifar10-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "10", "\n", "\n", "if", "args", ".", "hetero", ":", "\n", "                ", "data", "[", "task_id", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'x'", "]", "+=", "[", "candidate_x", "[", "i", "]", "for", "i", "in", "net_dataidx_map_train", "[", "task_id", "]", "]", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'y'", "]", "+=", "[", "candidate_y", "[", "i", "]", "for", "i", "in", "net_dataidx_map_train", "[", "task_id", "]", "]", "\n", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'x'", "]", "+=", "[", "candidate_x", "[", "i", "]", "for", "i", "in", "net_dataidx_map_test", "[", "task_id", "]", "]", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'y'", "]", "+=", "[", "candidate_y", "[", "i", "]", "for", "i", "in", "net_dataidx_map_test", "[", "task_id", "]", "]", "\n", "\n", "", "else", ":", "\n", "\n", "\n", "                ", "if", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", "==", "1", ":", "\n", "                    ", "current_x_train", "=", "candidate_x_train", "\n", "current_y_train", "=", "candidate_y_train", "\n", "current_x_test", "=", "candidate_x_test", "\n", "current_y_test", "=", "candidate_y_test", "\n", "\n", "\n", "", "else", ":", "\n", "                    ", "candidate_x_train", ",", "current_x_train", ",", "candidate_y_train", ",", "current_y_train", "=", "train_test_split", "(", "candidate_x_train", ",", "candidate_y_train", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_train", ")", "\n", "candidate_x_test", ",", "current_x_test", ",", "candidate_y_test", ",", "current_y_test", "=", "train_test_split", "(", "candidate_x_test", ",", "candidate_y_test", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_test", ")", "\n", "\n", "\n", "", "data", "[", "task_id", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'x'", "]", "+=", "current_x_train", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'y'", "]", "+=", "current_y_train", "\n", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'x'", "]", "+=", "current_x_test", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'y'", "]", "+=", "current_y_test", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar10-'", "+", "str", "(", "n", ")", "\n", "\n", "# Real Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "#checked whether all tasks have samples for all set of labels. #62", "\n", "print", "(", "\" data[t]['train']['y']: \"", ",", "len", "(", "set", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "\n", "", "if", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "# exit()", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.mnist.dil_mnist.get": [[15, 36], ["print", "dil_mnist.read_mnist", "range", "print", "str", "open", "[].split", "all_mnist.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.mnist.dil_mnist.read_mnist"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'mnist_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "data_mnist", ",", "taskcla_mnist", "=", "read_mnist", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "all_mnist", "=", "[", "data_mnist", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "mnist_id", "=", "all_mnist", ".", "index", "(", "random_sep", "[", "t", "]", ")", "\n", "data", "[", "t", "]", "=", "data_mnist", "[", "mnist_id", "]", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data_mnist", "[", "mnist_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.mnist.dil_mnist.read_mnist": [[37, 238], ["range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "range", "dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "print", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "candidate_x_train.append", "candidate_y_train.append", "candidate_x_test.append", "candidate_y_test.append", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "str", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "set", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "str", "str", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "[].cpu().numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.expanduser", "os.path.expanduser", "numpy.array", "str", "str", "[].cpu", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_mnist", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "\n", "# mnist", "\n", "dat", "=", "{", "}", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", "\n", "\n", "\n", "candidate_train", "=", "datasets", ".", "MNIST", "(", "'./dat/'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "candidate_test", "=", "datasets", ".", "MNIST", "(", "'./dat/'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_train", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_train", "=", "[", "]", "\n", "candidate_y_train", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_train", ".", "append", "(", "image", ")", "\n", "candidate_y_train", ".", "append", "(", "target", ")", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_test", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_test", "=", "[", "]", "\n", "candidate_y_test", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_test", ".", "append", "(", "image", ")", "\n", "candidate_y_test", ".", "append", "(", "target", ")", "\n", "\n", "\n", "", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'mnist-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "10", "\n", "\n", "\n", "\n", "if", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", "==", "1", ":", "\n", "                ", "current_x_train", "=", "candidate_x_train", "\n", "current_y_train", "=", "candidate_y_train", "\n", "current_x_test", "=", "candidate_x_test", "\n", "current_y_test", "=", "candidate_y_test", "\n", "\n", "", "else", ":", "\n", "                ", "candidate_x_train", ",", "current_x_train", ",", "candidate_y_train", ",", "current_y_train", "=", "train_test_split", "(", "candidate_x_train", ",", "candidate_y_train", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_train", ")", "\n", "candidate_x_test", ",", "current_x_test", ",", "candidate_y_test", ",", "current_y_test", "=", "train_test_split", "(", "candidate_x_test", ",", "candidate_y_test", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_test", ")", "\n", "\n", "\n", "", "data", "[", "task_id", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'x'", "]", "+=", "current_x_train", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'y'", "]", "+=", "current_y_train", "\n", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'x'", "]", "+=", "current_x_test", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'y'", "]", "+=", "current_y_test", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/mnist/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'mnist-'", "+", "str", "(", "n", ")", "\n", "\n", "# Real Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "#checked whether all tasks have samples for all set of labels. #62", "\n", "print", "(", "\" data[t]['train']['y']: \"", ",", "len", "(", "set", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.bert.get": [[30, 160], ["print", "print", "range", "data.keys", "open", "[].split", "print", "logger.info", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "nlp_data_utils.ABSATokenizer.from_pretrained", "data_utils.DscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_dsc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_dsc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "transformers.BertTokenizer.from_pretrained", "data_utils.DscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_dsc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "taskcla.append", "random.Random().shuffle", "int", "len", "len", "len", "len", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "random.Random", "len"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_dsc"], ["#BERT fixed all ===========", "\n", "# for param in self.bert.parameters():", "\n", "#     param.requires_grad = False", "\n", "\n", "self", ".", "taskcla", "=", "taskcla", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "hidden_dropout_prob", ")", "\n", "\n", "if", "'dil'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "args", ".", "nclasses", ")", "\n", "", "elif", "'til'", "in", "args", ".", "scenario", ":", "\n", "            ", "self", ".", "last", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "                ", "self", ".", "last", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "args", ".", "bert_hidden_size", ",", "n", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "'DIL BERT'", ")", "\n", "\n", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "segment_ids", ",", "input_mask", ")", ":", "\n", "        ", "output_dict", "=", "{", "}", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "if", "'dil'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "self", ".", "last", "(", "pooled_output", ")", "\n", "", "elif", "'til'", "in", "self", ".", "args", ".", "scenario", ":", "\n", "            ", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "last", "[", "t", "]", "(", "pooled_output", ")", ")", "\n", "\n", "", "", "output_dict", "[", "'y'", "]", "=", "y", "\n", "output_dict", "[", "'normalized_pooled_rep'", "]", "=", "F", ".", "normalize", "(", "pooled_output", ",", "dim", "=", "1", ")", "\n", "\n", "return", "output_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation": [[27, 77], ["w2v_util.Tokenizer", "w2v_util.Tokenizer.fit_on_texts", "w2v_util.Tokenizer.texts_to_sequences", "print", "os.listdir", "os.path.exists", "open", "open.close", "print", "numpy.zeros", "word_index.items", "torch.from_numpy", "len", "torch.save", "torch.save", "torch.load", "torch.load", "len", "line.split", "numpy.asarray", "embeddings_index.get", "open", "len", "json.load", "enumerate", "len", "asc_str.append"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.fit_on_texts", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.w2v_util.Tokenizer.texts_to_sequences", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["]", "\n", "\n", "\n", "datasets", "=", "[", "\n", "'./dat/absa/XuSemEval/asc/14/rest'", ",", "\n", "'./dat/absa/XuSemEval/asc/14/laptop'", ",", "\n", "\n", "'./dat/absa/Bing3Domains/asc/Speaker'", ",", "\n", "'./dat/absa/Bing3Domains/asc/Router'", ",", "\n", "'./dat/absa/Bing3Domains/asc/Computer'", ",", "\n", "\n", "'./dat/absa/Bing5Domains/asc/Nokia6610'", ",", "\n", "'./dat/absa/Bing5Domains/asc/NikonCoolpix4300'", ",", "\n", "'./dat/absa/Bing5Domains/asc/CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'./dat/absa/Bing5Domains/asc/CanonG3'", ",", "\n", "'./dat/absa/Bing5Domains/asc/ApexAD2600Progressive'", ",", "\n", "\n", "'./dat/absa/Bing9Domains/asc/CanonPowerShotSD500'", ",", "\n", "'./dat/absa/Bing9Domains/asc/CanonS100'", ",", "\n", "'./dat/absa/Bing9Domains/asc/DiaperChamp'", ",", "\n", "'./dat/absa/Bing9Domains/asc/HitachiRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/ipod'", ",", "\n", "'./dat/absa/Bing9Domains/asc/LinksysRouter'", ",", "\n", "'./dat/absa/Bing9Domains/asc/MicroMP3'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Nokia6600'", ",", "\n", "'./dat/absa/Bing9Domains/asc/Norton'", ",", "\n", "]", "\n", "\n", "\n", "\n", "domains", "=", "[", "\n", "'XuSemEval14_rest'", ",", "\n", "'XuSemEval14_laptop'", ",", "\n", "\n", "'Bing3domains_Speaker'", ",", "\n", "'Bing3domains_Router'", ",", "\n", "'Bing3domains_Computer'", ",", "\n", "\n", "'Bing5domains_Nokia6610'", ",", "\n", "'Bing5domains_NikonCoolpix4300'", ",", "\n", "'Bing5domains_CreativeLabsNomadJukeboxZenXtra40GB'", ",", "\n", "'Bing5domains_CanonG3'", ",", "\n", "'Bing5domains_ApexAD2600Progressive'", ",", "\n", "\n", "'Bing9domains_CanonPowerShotSD500'", ",", "\n", "'Bing9domains_CanonS100'", ",", "\n", "'Bing9domains_DiaperChamp'", ",", "\n", "'Bing9domains_HitachiRouter'", ",", "\n", "'Bing9domains_ipod'", ",", "\n", "'Bing9domains_LinksysRouter'", ",", "\n", "'Bing9domains_MicroMP3'", ",", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.get": [[78, 201], ["w2v.embedding_generation", "print", "print", "range", "data.keys", "open", "[].split", "print", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "data_utils.DscProcessor.get_train_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "data_utils.DscProcessor.get_dev_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "nlp_data_utils.DscProcessor", "data_utils.DscProcessor.get_labels", "data_utils.DscProcessor.get_test_examples", "nlp_data_utils.convert_examples_to_features_w2v_dsc", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "taskcla.append", "random.Random().shuffle", "int", "len", "os.path.exists", "torch.save", "logger.info", "torch.load", "logger.info", "len", "len", "len", "domains.index", "math.ceil", "int", "f_random_seq.readlines", "random.Random", "str", "str", "str", "len", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.dsc.w2v.embedding_generation", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_train_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_labels", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.AscProcessor.get_test_examples", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.nlp_data_utils.convert_examples_to_features_w2v_dsc", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["'Bing9domains_Nokia6600'", ",", "\n", "'Bing9domains_Norton'", "]", "\n", "\n", "\n", "def", "embedding_generation", "(", "args", ")", ":", "\n", "    ", "asc_str", "=", "[", "]", "\n", "for", "dataset", "in", "raw_datasets", ":", "\n", "        ", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset", ")", ":", "\n", "            ", "with", "open", "(", "dataset", "+", "'/'", "+", "file_name", ")", "as", "asc_file", ":", "\n", "                ", "if", "'json'", "in", "file_name", ":", "\n", "                    ", "lines", "=", "json", ".", "load", "(", "asc_file", ")", "\n", "for", "(", "i", ",", "ids", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "                        ", "asc_str", ".", "append", "(", "lines", "[", "ids", "]", "[", "'sentence'", "]", "+", "' '", "+", "lines", "[", "ids", "]", "[", "'term'", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "reviews", "=", "asc_file", ".", "readlines", "(", ")", "\n", "for", "review", "in", "reviews", ":", "\n", "                        ", "opins", "=", "set", "(", ")", "\n", "if", "review", "[", ":", "2", "]", "!=", "'##'", "and", "'##'", "in", "review", "and", "'['", "in", "review", "and", "(", "'+'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "or", "'-'", "in", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", ")", ":", "\n", "                            ", "current_sentence", "=", "review", ".", "split", "(", "'##'", ")", "[", "1", "]", "[", ":", "-", "1", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "aspect_str", "=", "review", ".", "split", "(", "'##'", ")", "[", "0", "]", "\n", "if", "','", "in", "aspect_str", ":", "\n", "                                ", "aspect_all", "=", "aspect_str", ".", "split", "(", "','", ")", "\n", "for", "each_aspect", "in", "aspect_all", ":", "\n", "                                    ", "current_aspect", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "each_aspect", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "\n", "", "", "elif", "','", "not", "in", "aspect_str", ":", "\n", "                                ", "current_aspect", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "current_sentiment", "=", "aspect_str", ".", "split", "(", "'['", ")", "[", "1", "]", "[", "0", "]", "\n", "opins", ".", "add", "(", "(", "current_aspect", ",", "current_sentiment", ")", ")", "\n", "", "for", "ix", ",", "opin", "in", "enumerate", "(", "opins", ")", ":", "\n", "                                ", "asc_str", ".", "append", "(", "current_sentence", "+", "' '", "+", "opin", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "tokenizer", ".", "fit_on_texts", "(", "asc_str", ")", "\n", "tokenizer", ".", "texts_to_sequences", "(", "asc_str", ")", "\n", "word_index", "=", "tokenizer", ".", "word_index", "\n", "\n", "# print('word_index: ',word_index)", "\n", "print", "(", "'Found %s unique tokens.'", "%", "len", "(", "word_index", ")", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "\"./dat/absa/w2v_embedding\"", ")", ":", "\n", "        ", "embeddings_index", "=", "{", "}", "\n", "# f = gzip.open('./cc.en.300.vec.gz')", "\n", "f", "=", "open", "(", "'./amazon_review_300d.vec'", ",", "'r'", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# embeddings_index[word.decode(\"utf-8\")] = coefs", "\n", "embeddings_index", "[", "word", "]", "=", "coefs", "\n", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'Found %s word vectors.'", "%", "len", "(", "embeddings_index", ")", ")", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "for", "word", ",", "i", "in", "word_index", ".", "items", "(", ")", ":", "\n", "            ", "embedding_vector", "=", "embeddings_index", ".", "get", "(", "word", ")", "\n", "if", "embedding_vector", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                ", "embedding_matrix", "[", "i", "]", "=", "embedding_vector", "\n", "\n", "# exit()", "\n", "\n", "", "", "embeddings", "=", "torch", ".", "from_numpy", "(", "embedding_matrix", ")", "\n", "vocab_size", "=", "len", "(", "word_index", ")", "\n", "\n", "torch", ".", "save", "(", "embeddings", ",", "'./dat/absa/w2v_embedding'", ")", "\n", "torch", ".", "save", "(", "vocab_size", ",", "'./dat/absa/vocab_size'", ")", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "'./dat/absa/w2v_embedding'", ")", "\n", "vocab_size", "=", "torch", ".", "load", "(", "'./dat/absa/vocab_size'", ")", "\n", "\n", "", "return", "embeddings", ",", "vocab_size", ",", "tokenizer", "\n", "\n", "", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "embeddings", ",", "vocab_size", ",", "tokenizer", "=", "embedding_generation", "(", "args", ")", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "data", "[", "t", "]", "=", "{", "}", "\n", "if", "'Bing'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "2", "\n", "", "elif", "'XuSemEval'", "in", "dataset", ":", "\n", "            ", "data", "[", "t", "]", "[", "'name'", "]", "=", "dataset", "\n", "data", "[", "t", "]", "[", "'ncla'", "]", "=", "3", "\n", "\n", "\n", "\n", "\n", "", "processor", "=", "data_utils", ".", "AscProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "train_examples", "=", "processor", ".", "get_train_examples", "(", "dataset", ")", "\n", "num_train_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "train_features", "=", "data_utils", ".", "convert_examples_to_features_w2v", "(", "\n", "train_examples", ",", "label_list", ",", "tokenizer", ",", "args", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "\n", "all_tokens_term_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_term_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_tokens_sentence_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "tokens_sentence_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# print('all_tokens_term_ids: ',all_tokens_term_ids)", "\n", "\n", "train_data", "=", "TensorDataset", "(", "\n", "all_tokens_term_ids", ",", "\n", "all_tokens_sentence_ids", ",", "\n", "all_label_ids", ")", "\n", "\n", "\n", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "num_train_steps", "\n", "\n", "valid_examples", "=", "processor", ".", "get_dev_examples", "(", "dataset", ")", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.VLCSLoader.__init__": [[300, 318], ["os.listdir", "torch.cat().view", "torch.LongTensor().view().numpy", "os.listdir", "PIL.Image.open", "numpy.array", "torch.from_numpy", "vlcs.VLCSLoader.x.append", "vlcs.VLCSLoader.y.append", "torch.cat", "torch.LongTensor().view", "list", "torch_img.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "int", "torch_img.unsqueeze().repeat.unsqueeze().repeat.size", "torch.LongTensor", "torch_img.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "size", "=", "[", "227", ",", "227", ",", "3", "]", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "for", "label", "in", "os", ".", "listdir", "(", "img_dir", ")", ":", "\n", "            ", "for", "img_name", "in", "os", ".", "listdir", "(", "img_dir", "+", "label", ")", ":", "\n", "                ", "im", "=", "Image", ".", "open", "(", "img_dir", "+", "label", "+", "'/'", "+", "img_name", ")", "\n", "np_im", "=", "np", ".", "array", "(", "im", ")", "\n", "torch_img", "=", "torch", ".", "from_numpy", "(", "np_im", ")", "\n", "if", "list", "(", "torch_img", ".", "size", "(", ")", ")", "!=", "self", ".", "size", ":", "\n", "                    ", "torch_img", "=", "torch_img", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "[", "1", ",", "1", ",", "3", "]", ")", "#some are only 1 channel", "\n", "", "self", ".", "x", ".", "append", "(", "torch_img", ")", "\n", "self", ".", "y", ".", "append", "(", "int", "(", "label", ")", ")", "\n", "\n", "", "", "self", ".", "x", "=", "torch", ".", "cat", "(", "self", ".", "x", ",", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "size", "[", "0", "]", ",", "self", ".", "size", "[", "1", "]", ",", "self", ".", "size", "[", "2", "]", ")", "\n", "self", ".", "y", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "[", "f", "for", "f", "in", "self", ".", "y", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.VLCSLoader.__len__": [[319, 321], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.VLCSLoader.__getitem__": [[322, 334], ["vlcs.VLCSLoader.data.numpy", "PIL.Image.fromarray", "vlcs.VLCSLoader.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "x", "=", "self", ".", "x", "[", "idx", "]", "\n", "y", "=", "self", ".", "y", "[", "idx", "]", "\n", "\n", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "x", "=", "Image", ".", "fromarray", "(", "x", ")", "\n", "# x = Image.fromarray((x * 255).astype(np.uint8))", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.down_sampling": [[25, 50], ["enumerate", "torch.LongTensor().view", "torch.cat", "print", "print", "torch.cat.size", "torch.LongTensor().view.size", "example_label[].append", "len", "torch.LongTensor", "example.unsqueeze", "example.unsqueeze", "numpy.array", "int", "examples_y[].numpy", "int", "examples_y[].numpy"], "function", ["None"], ["def", "down_sampling", "(", "examples_x", ",", "examples_y", ",", "remain_sample_size", ")", ":", "\n", "    ", "label_list", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "\n", "# print('examples: ',len(examples))", "\n", "example_label", "=", "{", "}", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples_x", ")", ":", "\n", "        ", "if", "examples_y", "[", "ex_index", "]", "not", "in", "example_label", ":", "\n", "            ", "example_label", "[", "int", "(", "examples_y", "[", "ex_index", "]", ".", "numpy", "(", ")", ")", "]", "=", "[", "example", ".", "unsqueeze", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "example_label", "[", "int", "(", "examples_y", "[", "ex_index", "]", ".", "numpy", "(", ")", ")", "]", ".", "append", "(", "example", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "# print('example_label: ',example_label)", "\n", "", "", "final_examples", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "label", "in", "label_list", ":", "\n", "        ", "if", "label", "not", "in", "example_label", ":", "continue", "\n", "final_examples", "+=", "example_label", "[", "label", "]", "[", ":", "remain_sample_size", "]", "#randonly pick 1 to add, if the down_sampled_size is too small", "\n", "labels", "+=", "[", "label", "]", "*", "len", "(", "example_label", "[", "label", "]", "[", ":", "remain_sample_size", "]", ")", "\n", "", "final_labels", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "labels", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "final_examples", "=", "torch", ".", "cat", "(", "final_examples", ",", "0", ")", "\n", "\n", "print", "(", "final_examples", ".", "size", "(", ")", ")", "\n", "print", "(", "final_labels", ".", "size", "(", ")", ")", "\n", "\n", "return", "final_examples", ",", "final_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.get": [[51, 73], ["print", "range", "print", "vlcs.save_statistic", "str", "open", "[].split", "vlcs.read_celeba", "taskcla.append", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.save_statistic", "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.read_celeba"], ["", "def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'vlcs_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "t", "]", "=", "read_celeba", "(", "args", "=", "args", ",", "logger", "=", "logger", ",", "domain", "=", "domains", "[", "t", "]", ",", "t", "=", "t", ")", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "\n", "_", ",", "_", "=", "save_statistic", "(", "data", ",", "taskcla", ",", "args", ")", "\n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.save_statistic": [[76, 121], ["open", "range", "str", "fn_w.writelines", "data_domain_train.append", "range", "fn_w.writelines", "cls_num_list.append", "range", "torch.utils.data.DataLoader", "range", "fn_w.writelines", "str", "range", "targets.item", "targets.item"], "function", ["None"], ["", "def", "save_statistic", "(", "data", ",", "taskcla", ",", "args", ")", ":", "\n", "# label_map = {0:'negative',1:'positive'}", "\n", "    ", "cls_num_list", "=", "[", "]", "\n", "data_domain_train", "=", "[", "]", "\n", "fn", "=", "'./res/'", "+", "args", ".", "scenario", "+", "'/'", "+", "args", ".", "task", "+", "'/'", "+", "args", ".", "experiment", "+", "'_'", "+", "args", ".", "approach", "+", "'_'", "+", "str", "(", "args", ".", "note", ")", "+", "'statistic.txt'", "\n", "with", "open", "(", "fn", ",", "'w'", ")", "as", "fn_w", ":", "\n", "        ", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "fn_w", ".", "writelines", "(", "data", "[", "t", "]", "[", "'name'", "]", "+", "'\\t'", ")", "\n", "data_label", "=", "{", "}", "\n", "data_label_train", "=", "{", "}", "\n", "data_domain_train", ".", "append", "(", "0", ")", "\n", "\n", "for", "c", "in", "range", "(", "taskcla", "[", "t", "]", "[", "1", "]", ")", ":", "#clear", "\n", "                ", "data_label_train", "[", "c", "]", "=", "0", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "\n", "                ", "for", "c", "in", "range", "(", "taskcla", "[", "t", "]", "[", "1", "]", ")", ":", "#clear", "\n", "                    ", "data_label", "[", "c", "]", "=", "0", "\n", "\n", "", "loader", "=", "DataLoader", "(", "data", "[", "t", "]", "[", "s", "]", ",", "batch_size", "=", "1", ")", "\n", "for", "dat", "in", "loader", ":", "\n", "                    ", "if", "args", ".", "mtl", ":", "\n", "                        ", "images", ",", "targets", ",", "tasks", "=", "dat", "\n", "", "else", ":", "\n", "                        ", "images", ",", "targets", "=", "dat", "\n", "\n", "", "data_label", "[", "targets", ".", "item", "(", ")", "]", "+=", "1", "\n", "\n", "if", "s", "==", "'train'", ":", "\n", "                        ", "data_label_train", "[", "targets", ".", "item", "(", ")", "]", "+=", "1", "\n", "data_domain_train", "[", "-", "1", "]", "+=", "1", "\n", "\n", "\n", "", "", "line", "=", "''", "\n", "for", "c", "in", "range", "(", "taskcla", "[", "t", "]", "[", "1", "]", ")", ":", "\n", "                    ", "line", "+=", "str", "(", "data_label", "[", "c", "]", ")", "+", "'\\t'", "\n", "", "fn_w", ".", "writelines", "(", "line", ")", "\n", "\n", "", "fn_w", ".", "writelines", "(", "'\\n'", ")", "\n", "\n", "cls_num_list", ".", "append", "(", "[", "data_label_train", "[", "i", "]", "for", "i", "in", "range", "(", "taskcla", "[", "t", "]", "[", "1", "]", ")", "]", ")", "#pos and neg", "\n", "# os.remove(fn)", "\n", "\n", "", "", "return", "cls_num_list", ",", "data_domain_train", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.read_celeba": [[122, 289], ["dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "os.path.isdir", "os.makedirs", "vlcs.VLCSLoader", "vlcs.VLCSLoader", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "[].size", "sklearn.utils.shuffle", "vlcs.down_sampling", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "str", "torch.utils.data.DataLoader", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "target.numpy", "os.path.expanduser", "os.path.expanduser", "numpy.array", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.vlcs.vlcs.down_sampling"], ["", "def", "read_celeba", "(", "pc_valid", "=", "0.10", ",", "args", "=", "None", ",", "logger", "=", "None", ",", "domain", "=", "None", ",", "t", "=", "None", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "data_type", "=", "args", ".", "data_size", "\n", "\n", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "\n", "# celeba", "\n", "dat", "=", "{", "}", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "file_name", "=", "'./dat/vlcs/'", "+", "domain", "+", "'_binary_celeba/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "file_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "\n", "train_dataset", "=", "VLCSLoader", "(", "img_dir", "=", "'./dat/vlcs/'", "+", "domain", "+", "'/train/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "size", "=", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ")", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'train'", "]", "=", "train_dataset", "\n", "\n", "test_dataset", "=", "VLCSLoader", "(", "img_dir", "=", "'./dat/vlcs/'", "+", "domain", "+", "'/test/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "size", "=", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ")", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "test_dataset", "\n", "\n", "\n", "# # totally 10 tasks, each tasks 2 classes (whether smiling)", "\n", "#", "\n", "data", "=", "{", "}", "\n", "data", "[", "'name'", "]", "=", "domain", "\n", "data", "[", "'ncla'", "]", "=", "5", "\n", "\n", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "\n", "data", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                ", "label", "=", "target", ".", "numpy", "(", ")", "[", "0", "]", "\n", "data", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "label", ")", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "torch", ".", "save", "(", "data", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "data", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "data", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "'name'", "]", "=", "domain", "\n", "\n", "\n", "\n", "logger", ".", "info", "(", "data", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "\n", "if", "args", ".", "fewshot", ":", "\n", "        ", "data", "[", "'train'", "]", "[", "'x'", "]", ",", "data", "[", "'train'", "]", "[", "'y'", "]", "=", "down_sampling", "(", "data", "[", "'train'", "]", "[", "'x'", "]", ",", "data", "[", "'train'", "]", "[", "'y'", "]", ",", "args", ".", "each_class_remain_sample", ")", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "each_class_remain_sample", "*", "args", ".", "nclasses", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "        ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "        ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "        ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "        ", "data", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "        ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "        ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "        ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "        ", "data", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "        ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "        ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "        ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTrain.__init__": [[272, 298], ["os.listdir", "print", "torch.cat().view", "torch.LongTensor().view().numpy", "len", "open", "json.load", "data[].items", "set", "torch.cat", "torch.LongTensor().view", "value.items", "range", "len", "femnist.FEMMNISTTrain.user.append", "torch.LongTensor", "femnist.FEMMNISTTrain.x.append", "numpy.array", "torch.from_numpy", "femnist.FEMMNISTTrain.y.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "transform", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "# self.size=[1,28,28]", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "user", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "            ", "with", "open", "(", "root_dir", "+", "file", ")", "as", "json_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "json_file", ")", "# read file and do whatever we need to do.", "\n", "for", "key", ",", "value", "in", "data", "[", "'user_data'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "for", "type", ",", "data", "in", "value", ".", "items", "(", ")", ":", "\n", "                        ", "if", "type", "==", "'x'", ":", "\n", "                            ", "self", ".", "x", ".", "append", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "data", ")", ")", ")", "\n", "", "elif", "type", "==", "'y'", ":", "\n", "                            ", "self", ".", "y", ".", "append", "(", "data", ")", "\n", "\n", "", "", "for", "_", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                        ", "self", ".", "user", ".", "append", "(", "key", ")", "\n", "\n", "#number of class", "\n", "", "", "", "", "print", "(", "len", "(", "set", "(", "[", "b", "for", "a", "in", "self", ".", "y", "for", "b", "in", "a", "]", ")", ")", ")", "\n", "#number of class", "\n", "\n", "self", ".", "x", "=", "torch", ".", "cat", "(", "self", ".", "x", ",", "0", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "self", ".", "y", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "[", "d", "for", "f", "in", "self", ".", "y", "for", "d", "in", "f", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTrain.__len__": [[299, 301], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTrain.__getitem__": [[302, 315], ["femnist.FEMMNISTTrain.data.numpy", "PIL.Image.fromarray", "femnist.FEMMNISTTrain.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "user", "=", "self", ".", "user", "[", "idx", "]", "\n", "x", "=", "self", ".", "x", "[", "idx", "]", "\n", "y", "=", "self", ".", "y", "[", "idx", "]", "\n", "\n", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "x", "=", "Image", ".", "fromarray", "(", "x", ")", "\n", "# x = Image.fromarray((x * 255).astype(np.uint8))", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "user", ",", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__init__": [[324, 346], ["os.listdir", "torch.cat().view", "torch.LongTensor().view().numpy", "open", "json.load", "data[].items", "torch.cat", "torch.LongTensor().view", "value.items", "range", "len", "femnist.FEMMNISTTest.user.append", "torch.LongTensor", "femnist.FEMMNISTTest.x.append", "numpy.array", "torch.from_numpy", "femnist.FEMMNISTTest.y.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "transform", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "# self.size=[1,28,28]", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "user", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "            ", "with", "open", "(", "root_dir", "+", "file", ")", "as", "json_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "json_file", ")", "# read file and do whatever we need to do.", "\n", "for", "key", ",", "value", "in", "data", "[", "'user_data'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "for", "type", ",", "data", "in", "value", ".", "items", "(", ")", ":", "\n", "                        ", "if", "type", "==", "'x'", ":", "\n", "                            ", "self", ".", "x", ".", "append", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "data", ")", ")", ")", "\n", "", "elif", "type", "==", "'y'", ":", "\n", "                            ", "self", ".", "y", ".", "append", "(", "data", ")", "\n", "\n", "", "", "for", "_", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                        ", "self", ".", "user", ".", "append", "(", "key", ")", "\n", "\n", "", "", "", "", "self", ".", "x", "=", "torch", ".", "cat", "(", "self", ".", "x", ",", "0", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "self", ".", "y", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "[", "d", "for", "f", "in", "self", ".", "y", "for", "d", "in", "f", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__len__": [[347, 349], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.FEMMNISTTest.__getitem__": [[350, 363], ["femnist.FEMMNISTTest.data.numpy", "PIL.Image.fromarray", "femnist.FEMMNISTTest.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "user", "=", "self", ".", "user", "[", "idx", "]", "\n", "x", "=", "self", ".", "x", "[", "idx", "]", "\n", "y", "=", "self", ".", "y", "[", "idx", "]", "\n", "\n", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "x", "=", "Image", ".", "fromarray", "(", "x", ")", "\n", "# x = Image.fromarray((x * 255).astype(np.uint8))", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "user", ",", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.get": [[17, 38], ["femnist.read_femnist", "range", "print", "str", "open", "[].split", "all_femnist.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.read_femnist"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "# size=[1,28,28] see arg.image_size and arg.image_channel", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "\n", "f_name", "=", "'femnist_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "\n", "", "data_femnist", ",", "taskcla_femnist", "=", "read_femnist", "(", "logger", "=", "logger", ",", "args", "=", "args", ")", "\n", "all_femnist", "=", "[", "data_femnist", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "\n", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "femnist_id", "=", "all_femnist", ".", "index", "(", "random_sep", "[", "task_id", "]", ")", "\n", "data", "[", "task_id", "]", "=", "data_femnist", "[", "femnist_id", "]", "\n", "taskcla", ".", "append", "(", "(", "task_id", ",", "data_femnist", "[", "femnist_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.femnist.femnist.read_femnist": [[39, 260], ["print", "range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "users.sort", "print", "print", "enumerate", "print", "print", "range", "dict.fromkeys", "len", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "print", "femnist.FEMMNISTTrain", "femnist.FEMMNISTTest", "len", "print", "torch.utils.data.DataLoader", "enumerate", "print", "sum", "sum", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "print", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "str", "str", "femnist.FEMMNISTTrain", "femnist.FEMMNISTTest", "femnist.FEMMNISTTrain", "femnist.FEMMNISTTest", "set", "str", "[].append", "[].append", "count_label.append", "collections.Counter", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "len", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "target.numpy", "len", "len", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "set", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "data.items", "data.items", "os.path.expanduser", "os.path.expanduser", "numpy.array", "[].cpu().numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "str", "str", "[].cpu", "str", "str", "users.index", "users.index"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_femnist", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "\n", "    ", "print", "(", "'Read FEMNIST'", ")", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[1,28,28]", "\n", "\n", "# MNIST", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "dat", "=", "{", "}", "\n", "\n", "data_type", "=", "args", ".", "data_size", "\n", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "if", "args", ".", "unseen", "and", "args", ".", "ntasks_unseen", ":", "\n", "        ", "file_name", "=", "'./dat/femnist/'", "+", "data_type", "+", "'_binary_unseen/'", "+", "str", "(", "args", ".", "ntasks_unseen", ")", "+", "'/'", "\n", "", "else", ":", "\n", "        ", "file_name", "=", "'./dat/femnist/'", "+", "data_type", "+", "'_binary/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", "\n", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "file_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "\n", "if", "args", ".", "unseen", "and", "args", ".", "ntasks_unseen", "==", "10", ":", "\n", "            ", "print", "(", "'unseen'", ")", "\n", "train_dataset", "=", "FEMMNISTTrain", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/train10_unseen/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'train'", "]", "=", "train_dataset", "\n", "\n", "test_dataset", "=", "FEMMNISTTest", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/test10_unseen/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'test'", "]", "=", "test_dataset", "\n", "\n", "\n", "\n", "", "elif", "args", ".", "ntasks", "==", "10", ":", "\n", "            ", "train_dataset", "=", "FEMMNISTTrain", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/train10/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'train'", "]", "=", "train_dataset", "\n", "\n", "test_dataset", "=", "FEMMNISTTest", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/test10/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'test'", "]", "=", "test_dataset", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "train_dataset", "=", "FEMMNISTTrain", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/train20/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'train'", "]", "=", "train_dataset", "\n", "\n", "test_dataset", "=", "FEMMNISTTest", "(", "root_dir", "=", "'./dat/femnist/'", "+", "data_type", "+", "'/iid/test20/'", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ",", "args", "=", "args", ")", "\n", "dat", "[", "'test'", "]", "=", "test_dataset", "\n", "\n", "\n", "", "users", "=", "[", "x", "[", "0", "]", "for", "x", "in", "set", "(", "[", "user", "for", "user", ",", "image", ",", "target", "in", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "'train'", "]", ",", "batch_size", "=", "1", ")", "]", ")", "]", "# not shuffle", "\n", "users", ".", "sort", "(", ")", "\n", "print", "(", "'users: '", ",", "users", ")", "\n", "print", "(", "'users length: '", ",", "len", "(", "users", ")", ")", "\n", "# # totally 47 classes, each tasks 5 classes", "\n", "#", "\n", "for", "task_id", ",", "user", "in", "enumerate", "(", "users", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'femnist-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "args", ".", "nclasses", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "print", "(", "'s: '", ",", "s", ")", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "\n", "for", "task_id", ",", "user", "in", "enumerate", "(", "users", ")", ":", "\n", "                ", "data", "[", "task_id", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "\n", "", "count_label", "=", "[", "]", "\n", "for", "user", ",", "image", ",", "target", "in", "loader", ":", "\n", "                ", "label", "=", "target", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n", "data", "[", "users", ".", "index", "(", "user", "[", "0", "]", ")", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "users", ".", "index", "(", "user", "[", "0", "]", ")", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "label", ")", "\n", "count_label", ".", "append", "(", "label", ")", "\n", "\n", "", "print", "(", "'count: '", ",", "Counter", "(", "count_label", ")", ")", "\n", "\n", "# print('testing_c: ',testing_c)", "\n", "", "print", "(", "'training len: '", ",", "sum", "(", "[", "len", "(", "value", "[", "'train'", "]", "[", "'x'", "]", ")", "for", "key", ",", "value", "in", "data", ".", "items", "(", ")", "]", ")", ")", "\n", "print", "(", "'testing len: '", ",", "sum", "(", "[", "len", "(", "value", "[", "'test'", "]", "[", "'x'", "]", ")", "for", "key", ",", "value", "in", "data", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "# # \"Unify\" and save", "\n", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "file_name", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'femnist-'", "+", "str", "(", "n", ")", "\n", "\n", "\n", "# Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "\n", "# print('len(r): ',len(r))", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "#real validataion set", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "#checked whether all tasks have samples for all set of labels. #62", "\n", "print", "(", "\" data[t]['train']['y']: \"", ",", "len", "(", "set", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.get": [[15, 36], ["print", "dil_cifar100.read_cifar100", "range", "print", "str", "open", "[].split", "all_cifar100.index", "taskcla.append", "range", "f_random_seq.readlines"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.read_cifar100"], ["def", "get", "(", "logger", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3,32,32] see arg.image_size and arg.image_channel", "\n", "\n", "f_name", "=", "'cifar100_'", "+", "str", "(", "args", ".", "ntasks", ")", "\n", "with", "open", "(", "f_name", ",", "'r'", ")", "as", "f_random_seq", ":", "\n", "        ", "random_sep", "=", "f_random_seq", ".", "readlines", "(", ")", "[", "args", ".", "idrandom", "]", ".", "split", "(", ")", "\n", "", "print", "(", "'random_sep: '", ",", "random_sep", ")", "\n", "\n", "data_cifar100", ",", "taskcla_cifar100", "=", "read_cifar100", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "all_cifar100", "=", "[", "data_cifar100", "[", "x", "]", "[", "'name'", "]", "for", "x", "in", "range", "(", "args", ".", "ntasks", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "cifar100_id", "=", "all_cifar100", ".", "index", "(", "random_sep", "[", "t", "]", ")", "\n", "data", "[", "t", "]", "=", "data_cifar100", "[", "cifar100_id", "]", "\n", "taskcla", ".", "append", "(", "(", "t", ",", "data_cifar100", "[", "cifar100_id", "]", "[", "'ncla'", "]", ")", ")", "\n", "\n", "", "print", "(", "'taskcla: '", ",", "taskcla", ")", "\n", "return", "data", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.zixuanke_pycontinual.cifar100.dil_cifar100.read_cifar100": [[37, 247], ["range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "range", "dict.fromkeys", "len", "logger.info", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "torch.tensor", "print", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "torch.tensor", "logger.info", "logger.info", "taskcla.append", "candidate_x_train.append", "candidate_y_train.append", "candidate_x_test.append", "candidate_y_test.append", "print", "print", "print", "print", "torch.load", "torch.load", "torch.stack().view", "torch.LongTensor().view", "numpy.unique", "str", "[].size", "sklearn.utils.shuffle", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "contrastive_dataset.InstanceSample", "len", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "str", "len", "len", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "len", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "len", "set", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "str", "str", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torch.stack", "torch.LongTensor", "[].cpu().numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.expanduser", "os.path.expanduser", "numpy.array", "str", "str", "[].cpu", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load", "home.repos.pwc.inspect_result.zixuanke_pycontinual.src.load_base_args.load"], ["", "def", "read_cifar100", "(", "pc_valid", "=", "0.10", ",", "args", "=", "0", ",", "logger", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "# size=[3, 32, 32] see arg.image_size and arg.image_channel", "\n", "\n", "data_type", "=", "args", ".", "data_size", "\n", "\n", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "\n", "# cifar100", "\n", "dat", "=", "{", "}", "\n", "#TODO:  one should save the data down since it takes a very long time", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", "+", "'/'", ")", "\n", "\n", "\n", "candidate_train", "=", "datasets", ".", "CIFAR100", "(", "'./dat/'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "candidate_test", "=", "datasets", ".", "CIFAR100", "(", "'./dat/'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_train", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_train", "=", "[", "]", "\n", "candidate_y_train", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_train", ".", "append", "(", "image", ")", "\n", "candidate_y_train", ".", "append", "(", "target", ")", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "candidate_test", ",", "batch_size", "=", "1", ")", "# not shuffle", "\n", "candidate_x_test", "=", "[", "]", "\n", "candidate_y_test", "=", "[", "]", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "candidate_x_test", ".", "append", "(", "image", ")", "\n", "candidate_y_test", ".", "append", "(", "target", ")", "\n", "\n", "\n", "", "for", "task_id", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "data", "[", "task_id", "]", "=", "{", "}", "\n", "data", "[", "task_id", "]", "[", "'name'", "]", "=", "'cifar100-'", "+", "str", "(", "task_id", ")", "\n", "data", "[", "task_id", "]", "[", "'ncla'", "]", "=", "10", "\n", "\n", "\n", "print", "(", "'candidate_x_train: '", ",", "len", "(", "candidate_x_train", ")", ")", "\n", "print", "(", "'candidate_y_train: '", ",", "len", "(", "candidate_y_train", ")", ")", "\n", "\n", "\n", "if", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", "==", "1", ":", "\n", "                ", "current_x_train", "=", "candidate_x_train", "\n", "current_y_train", "=", "candidate_y_train", "\n", "current_x_test", "=", "candidate_x_test", "\n", "current_y_test", "=", "candidate_y_test", "\n", "\n", "\n", "", "else", ":", "\n", "                ", "candidate_x_train", ",", "current_x_train", ",", "candidate_y_train", ",", "current_y_train", "=", "train_test_split", "(", "candidate_x_train", ",", "candidate_y_train", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_train", ")", "\n", "candidate_x_test", ",", "current_x_test", ",", "candidate_y_test", ",", "current_y_test", "=", "train_test_split", "(", "candidate_x_test", ",", "candidate_y_test", ",", "test_size", "=", "1", "/", "(", "args", ".", "ntasks", "-", "task_id", ")", ",", "stratify", "=", "candidate_y_test", ")", "\n", "\n", "\n", "", "print", "(", "'candidate_x_train: '", ",", "len", "(", "candidate_x_train", ")", ")", "\n", "print", "(", "'candidate_y_train: '", ",", "len", "(", "candidate_y_train", ")", ")", "\n", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'x'", "]", "+=", "current_x_train", "\n", "data", "[", "task_id", "]", "[", "'train'", "]", "[", "'y'", "]", "+=", "current_y_train", "\n", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'x'", "]", "+=", "current_x_test", "\n", "data", "[", "task_id", "]", "[", "'test'", "]", "[", "'y'", "]", "+=", "current_y_test", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "\n", "# # \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "args", ".", "ntasks", ")", ":", "\n", "        ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'./dat/cifar100/'", "+", "str", "(", "args", ".", "ntasks", ")", ")", ",", "'data'", "+", "str", "(", "n", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "args", ".", "image_channel", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "n", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar100-'", "+", "str", "(", "n", ")", "\n", "\n", "# Real Validation", "\n", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "args", ".", "data_seed", ")", ",", "dtype", "=", "int", ")", "# seed set", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'num_train_steps'", "]", "=", "0", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "#checked whether all tasks have samples for all set of labels. #62", "\n", "print", "(", "\" data[t]['train']['y']: \"", ",", "len", "(", "set", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "\n", "\n", "\n", "if", "args", ".", "train_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(train_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", ":", "args", ".", "train_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "train_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "train_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "\n", "", "data", "[", "t", "]", "[", "'train'", "]", "=", "train_data", "\n", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "dev_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(eval_data) #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "[", ":", "args", ".", "dev_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "dev_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "eval_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "eval_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'valid'", "]", "=", "eval_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running Dev *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_data", ")", ")", "\n", "\n", "all_tasks", "=", "torch", ".", "tensor", "(", "[", "t", "for", "f", "in", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "test_data_size", ">", "0", ":", "\n", "# random.Random(args.data_seed).shuffle(test_data)  #unlike dsc, not neccessary to shuffle", "\n", "            ", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "[", ":", "args", ".", "test_data_size", "]", "\n", "all_tasks", "=", "all_tasks", "[", ":", "args", ".", "test_data_size", "]", "\n", "\n", "", "if", "args", ".", "distill_loss", ":", "\n", "            ", "test_data", "=", "InstanceSample", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "", "elif", "args", ".", "mtl", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", ",", "\n", "all_tasks", "\n", ")", "\n", "", "else", ":", "\n", "            ", "test_data", "=", "TensorDataset", "(", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'x'", "]", ",", "\n", "data", "[", "t", "]", "[", "'test'", "]", "[", "'y'", "]", "\n", ")", "\n", "\n", "", "data", "[", "t", "]", "[", "'test'", "]", "=", "test_data", "\n", "\n", "logger", ".", "info", "(", "\"***** Running testing *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", "\n", "\n"]]}