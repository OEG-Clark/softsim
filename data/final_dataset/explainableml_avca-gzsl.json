{"home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.fix_seeds": [[35, 39], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "numpy.random.seed"], "function", ["None"], ["def", "fix_seeds", "(", "seed", "=", "42", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.loss_fn": [[89, 93], ["torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "log_var.exp", "mean.pow"], "function", ["None"], ["", "def", "loss_fn", "(", "recon_x", ",", "x", ",", "mean", ",", "log_var", ")", ":", "\n", "    ", "BCE", "=", "torch", ".", "nn", ".", "functional", ".", "binary_cross_entropy", "(", "recon_x", ",", "x", ",", "size_average", "=", "False", ")", "\n", "KLD", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "log_var", "-", "mean", ".", "pow", "(", "2", ")", "-", "log_var", ".", "exp", "(", ")", ")", "\n", "return", "BCE", "+", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.sample": [[95, 102], ["torch.utils.data.next_batch_uniform_class", "input_res.copy_", "input_att.copy_", "torch.utils.data.next_batch_unpair_test", "input_res_unpair.copy_", "input_att_unpair.copy_"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch_uniform_class", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch_unpair_test"], ["", "def", "sample", "(", ")", ":", "\n", "    ", "batch_feature", ",", "batch_label", ",", "batch_att", "=", "data", ".", "next_batch_uniform_class", "(", "opt", ".", "batch_size", ")", "\n", "input_res", ".", "copy_", "(", "batch_feature", ")", "\n", "input_att", ".", "copy_", "(", "batch_att", ")", "\n", "batch_feature", ",", "batch_label", ",", "batch_att", "=", "data", ".", "next_batch_unpair_test", "(", "opt", ".", "batch_size", ")", "\n", "input_res_unpair", ".", "copy_", "(", "batch_feature", ")", "\n", "input_att_unpair", ".", "copy_", "(", "batch_att", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.generate_syn_feature": [[104, 126], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "syn_att.cuda.cuda", "syn_noise.cuda.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "syn_att.cuda.copy_", "syn_noise.cuda.normal_", "netG", "torch.FloatTensor.narrow().copy_", "torch.LongTensor.narrow().fill_", "iclass_att.repeat", "netG.data.cpu", "torch.FloatTensor.narrow", "torch.LongTensor.narrow"], "function", ["None"], ["", "def", "generate_syn_feature", "(", "vae", ",", "classes", ",", "attribute", ",", "num", ",", "mapping", ")", ":", "\n", "    ", "nclass", "=", "classes", ".", "shape", "[", "0", "]", "\n", "syn_feature", "=", "torch", ".", "FloatTensor", "(", "nclass", "*", "num", ",", "opt", ".", "resSize", ")", "\n", "syn_label", "=", "torch", ".", "LongTensor", "(", "nclass", "*", "num", ")", "\n", "syn_att", "=", "torch", ".", "FloatTensor", "(", "num", ",", "opt", ".", "attSize", ")", "\n", "syn_noise", "=", "torch", ".", "FloatTensor", "(", "num", ",", "opt", ".", "nz", ")", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "syn_att", "=", "syn_att", ".", "cuda", "(", ")", "\n", "syn_noise", "=", "syn_noise", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "nclass", ")", ":", "\n", "            ", "iclass", "=", "classes", "[", "i", "]", "\n", "mapped_class", "=", "mapping", "[", "iclass", "]", "\n", "iclass_att", "=", "attribute", "[", "mapped_class", "]", "\n", "syn_att", ".", "copy_", "(", "iclass_att", ".", "repeat", "(", "num", ",", "1", ")", ")", "\n", "syn_noise", ".", "normal_", "(", "0", ",", "1", ")", "\n", "output", "=", "netG", "(", "syn_noise", ",", "syn_att", ")", "\n", "syn_feature", ".", "narrow", "(", "0", ",", "i", "*", "num", ",", "num", ")", ".", "copy_", "(", "output", ".", "data", ".", "cpu", "(", ")", ")", "\n", "syn_label", ".", "narrow", "(", "0", ",", "i", "*", "num", ",", "num", ")", ".", "fill_", "(", "iclass", ")", "\n", "\n", "", "", "return", "syn_feature", ",", "syn_label", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.calc_gradient_penalty": [[135, 161], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "alpha.cuda.expand", "interpolates.cuda.requires_grad_", "netD", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "real_data.size", "alpha.cuda.cuda", "interpolates.cuda.cuda", "netD.size", "ones.cuda.cuda", "torch.grad", "gradients.norm"], "function", ["None"], ["def", "calc_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "input_att", ")", ":", "\n", "# print real_data.size()", "\n", "    ", "alpha", "=", "torch", ".", "rand", "(", "opt", ".", "batch_size", ",", "1", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "size", "(", ")", ")", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "alpha", "=", "alpha", ".", "cuda", "(", ")", "\n", "\n", "", "interpolates", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "interpolates", "=", "interpolates", ".", "cuda", "(", ")", "\n", "\n", "", "interpolates", "=", "interpolates", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "disc_interpolates", "=", "netD", "(", "interpolates", ",", "input_att", ")", "\n", "\n", "ones", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "ones", "=", "ones", ".", "cuda", "(", ")", "\n", "\n", "", "gradients", "=", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolates", ",", "\n", "grad_outputs", "=", "ones", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "\n", "gradient_penalty", "=", "(", "(", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "opt", ".", "lambda1", "\n", "return", "gradient_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.vae_gan_d2_xu_fsl.calc_gradient_penalty2": [[163, 188], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "alpha.cuda.expand", "interpolates.cuda.requires_grad_", "netD", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "real_data.size", "alpha.cuda.cuda", "interpolates.cuda.cuda", "netD.size", "ones.cuda.cuda", "torch.grad", "gradients.norm"], "function", ["None"], ["", "def", "calc_gradient_penalty2", "(", "netD", ",", "real_data", ",", "fake_data", ")", ":", "\n", "# print real_data.size()", "\n", "    ", "alpha", "=", "torch", ".", "rand", "(", "opt", ".", "batch_size", ",", "1", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "size", "(", ")", ")", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "alpha", "=", "alpha", ".", "cuda", "(", ")", "\n", "\n", "", "interpolates", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "interpolates", "=", "interpolates", ".", "cuda", "(", ")", "\n", "\n", "", "interpolates", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolates", ")", "\n", "\n", "ones", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "ones", "=", "ones", ".", "cuda", "(", ")", "\n", "\n", "", "gradients", "=", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolates", ",", "\n", "grad_outputs", "=", "ones", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "\n", "gradient_penalty", "=", "(", "(", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "opt", ".", "lambda1", "\n", "return", "gradient_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.main.main": [[19, 270], ["src.args.args_main", "src.utils.fix_seeds", "src.utils.setup_experiment", "src.dataset.ContrastiveDataset", "src.dataset.ContrastiveDataset", "src.dataset.ContrastiveDataset", "src.dataset.ContrastiveDataset", "src.sampler.SamplerFactory().get", "src.sampler.SamplerFactory().get", "src.sampler.SamplerFactory().get", "src.sampler.SamplerFactory().get", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "src.model.AVGZSLNet.to", "torch.optim.Adam", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "src.train.train", "logger.info", "src.dataset.AudioSetZSLDataset", "src.dataset.AudioSetZSLDataset", "src.dataset.AudioSetZSLDataset", "src.dataset.AudioSetZSLDataset", "src.utils_improvements.get_model_params", "src.model.DeviseModel", "getattr", "src.loss.ClsContrastiveLoss", "src.model.AVGZSLNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "src.metrics.MeanClassAccuracy", "src.dataset.VGGSoundDataset", "src.dataset.VGGSoundDataset", "src.dataset.VGGSoundDataset", "src.dataset.VGGSoundDataset", "src.sampler.SamplerFactory", "list", "src.sampler.SamplerFactory", "list", "src.sampler.SamplerFactory", "list", "src.sampler.SamplerFactory", "list", "src.model.APN", "src.loss.ClsContrastiveLoss", "src.dataset.UCFDataset", "src.dataset.UCFDataset", "src.dataset.UCFDataset", "src.dataset.UCFDataset", "src.dataset.ContrastiveDataset.target_to_indices.values", "src.dataset.ContrastiveDataset.target_to_indices.values", "src.dataset.ContrastiveDataset.target_to_indices.values", "src.dataset.ContrastiveDataset.target_to_indices.values", "src.model.CJME", "src.loss.ClsContrastiveLoss", "src.dataset.ActivityNetDataset", "src.dataset.ActivityNetDataset", "src.dataset.ActivityNetDataset", "src.dataset.ActivityNetDataset", "NotImplementedError", "src.model_improvements.AVCA", "src.model.AVGZSLNet", "src.loss.APN_Loss", "src.loss.CJMELoss", "src.loss.AVGZSLLoss"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args.args_main", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.fix_seeds", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.setup_experiment", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.get", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.get", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.get", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.get", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils_improvements.get_model_params"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "args_main", "(", ")", "\n", "if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "        ", "args", ".", "input_size_audio", "=", "args", ".", "input_size", "\n", "args", ".", "input_size_video", "=", "args", ".", "input_size", "\n", "", "fix_seeds", "(", "args", ".", "seed", ")", "\n", "logger", ",", "log_dir", ",", "writer", ",", "train_stats", ",", "val_stats", "=", "setup_experiment", "(", "args", ",", "\"epoch\"", ",", "\"loss\"", ",", "\"hm\"", ")", "\n", "\n", "if", "args", ".", "dataset_name", "==", "\"AudioSetZSL\"", ":", "\n", "        ", "train_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"seen\"", ",", "\n", ")", "\n", "\n", "val_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "\"seen\"", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "\"seen\"", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "\"all\"", ",", "\n", ")", "\n", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"VGGSound\"", ":", "\n", "        ", "train_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"UCF\"", ":", "\n", "        ", "train_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"ActivityNet\"", ":", "\n", "        ", "train_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "contrastive_train_dataset", "=", "ContrastiveDataset", "(", "train_dataset", ")", "\n", "contrastive_val_dataset", "=", "ContrastiveDataset", "(", "val_dataset", ")", "\n", "contrastive_train_val_dataset", "=", "ContrastiveDataset", "(", "train_val_dataset", ")", "\n", "contrastive_val_all_dataset", "=", "ContrastiveDataset", "(", "val_all_dataset", ")", "\n", "\n", "train_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_train_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "val_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_val_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "train_val_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_train_val_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "val_all_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_val_all_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "train_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_train_dataset", ",", "\n", "batch_sampler", "=", "train_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "val_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_val_dataset", ",", "\n", "batch_sampler", "=", "val_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "train_val_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_train_val_dataset", ",", "\n", "batch_sampler", "=", "train_val_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "val_all_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_val_all_dataset", ",", "\n", "batch_sampler", "=", "val_all_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "if", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model_params", "=", "get_model_params", "(", "args", ".", "lr", ",", "args", ".", "first_additional_triplet", ",", "args", ".", "second_additional_triplet", ",", "args", ".", "reg_loss", ",", "args", ".", "additional_triplets_loss", ",", "args", ".", "embedding_dropout", ",", "args", ".", "decoder_dropout", ",", "args", ".", "additional_dropout", ",", "args", ".", "embeddings_hidden_size", ",", "args", ".", "decoder_hidden_size", ",", "args", ".", "depth_transformer", ",", "args", ".", "momentum", ")", "\n", "\n", "\n", "", "if", "args", ".", "ale", "==", "True", "or", "args", ".", "devise", "==", "True", "or", "args", ".", "sje", "==", "True", ":", "\n", "        ", "model", "=", "DeviseModel", "(", "args", ")", "\n", "", "elif", "args", ".", "apn", "==", "True", ":", "\n", "        ", "model", "=", "APN", "(", "args", ")", "\n", "", "elif", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "model", "=", "CJME", "(", "args", ")", "\n", "", "elif", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model", "=", "AVCA", "(", "model_params", ",", "input_size_audio", "=", "args", ".", "input_size_audio", ",", "input_size_video", "=", "args", ".", "input_size_video", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "AVGZSLNet", "(", "args", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "distance_fn", "=", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "args", ".", "distance_fn", ")", "(", ")", "\n", "if", "args", ".", "ale", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "False", ",", "topk", "=", "None", ",", "reduction", "=", "\"weighted\"", ")", "\n", "", "elif", "args", ".", "devise", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "False", ",", "topk", "=", "None", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "elif", "args", ".", "sje", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "True", ",", "topk", "=", "1", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "elif", "args", ".", "apn", "==", "True", ":", "\n", "        ", "criterion", "=", "APN_Loss", "(", ")", "\n", "", "elif", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "criterion", "=", "CJMELoss", "(", "margin", "=", "args", ".", "margin", ",", "distance_fn", "=", "distance_fn", ")", "\n", "", "elif", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "criterion", "=", "None", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "AVGZSLLoss", "(", "margin", "=", "args", ".", "margin", ",", "distance_fn", "=", "distance_fn", ")", "\n", "\n", "", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "\n", "lr_scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "'max'", ",", "patience", "=", "3", ",", "verbose", "=", "True", ")", "if", "args", ".", "lr_scheduler", "else", "None", "\n", "\n", "metrics", "=", "[", "\n", "MeanClassAccuracy", "(", "model", "=", "model", ",", "dataset", "=", "val_all_dataset", ",", "device", "=", "args", ".", "device", ",", "distance_fn", "=", "distance_fn", ",", "\n", "model_devise", "=", "args", ".", "ale", "or", "args", ".", "sje", "or", "args", ".", "devise", ",", "\n", "new_model_attention", "=", "args", ".", "AVCA", ",", "\n", "apn", "=", "args", ".", "apn", ",", "\n", "args", "=", "args", ")", "\n", "]", "\n", "\n", "\n", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "criterion", ")", "\n", "logger", ".", "info", "(", "optimizer", ")", "\n", "logger", ".", "info", "(", "lr_scheduler", ")", "\n", "logger", ".", "info", "(", "[", "metric", ".", "__class__", ".", "__name__", "for", "metric", "in", "metrics", "]", ")", "\n", "\n", "if", "args", ".", "val_all_loss", ":", "\n", "        ", "v_loader", "=", "val_all_loader", "\n", "", "elif", "args", ".", "retrain_all", ":", "\n", "        ", "v_loader", "=", "train_val_loader", "\n", "", "else", ":", "\n", "        ", "v_loader", "=", "val_loader", "\n", "\n", "", "best_loss", ",", "best_score", "=", "train", "(", "\n", "train_loader", "=", "train_val_loader", "if", "args", ".", "retrain_all", "else", "train_loader", ",", "\n", "val_loader", "=", "v_loader", ",", "\n", "model", "=", "model", ",", "\n", "criterion", "=", "criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "epochs", "=", "args", ".", "epochs", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "writer", "=", "writer", ",", "\n", "metrics", "=", "metrics", ",", "\n", "train_stats", "=", "train_stats", ",", "\n", "new_model_attention", "=", "args", ".", "AVCA", ",", "\n", "val_stats", "=", "val_stats", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "model_devise", "=", "args", ".", "ale", "or", "args", ".", "sje", "or", "args", ".", "devise", ",", "\n", "apn", "=", "args", ".", "apn", ",", "\n", "cjme", "=", "args", ".", "cjme", ",", "\n", "args", "=", "args", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"FINISHED. Run is stored at {log_dir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.main": [[8, 27], ["fasttext.load_model", "extract_word2vec._get_class_names", "extract_word2vec.extract_label_embeddings", "print", "numpy.save", "pathlib.Path", "len"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.load_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features._get_class_names", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.extract_label_embeddings"], ["def", "main", "(", ")", ":", "\n", "# model = fasttext.load_model(\"/shared-local/datasets/word2vec/wiki.en.bin\")", "\n", "    ", "model", "=", "fasttext", ".", "load_model", "(", "\"/shared-network/lriesch29/word2vec/wiki.en.bin\"", ")", "\n", "#audioset_classes = get_audioset_classes()", "\n", "#vggsound_classes = get_vggsound_classes()", "\n", "#data_audioset = extract_label_embeddings(model, audioset_classes)", "\n", "#data_vggsound = extract_label_embeddings(model, vggsound_classes)", "\n", "#ucf_classes = get_ucf_classes()", "\n", "activity_classes", "=", "_get_class_names", "(", "Path", "(", "\"/home/lriesch29/ExplainableAudioVisualLowShotLearning/dat/ActivityNet/class-split/all_class.txt\"", ")", ")", "\n", "#data_ucf = extract_label_embeddings(model, ucf_classes)", "\n", "data_activity", "=", "extract_label_embeddings", "(", "model", ",", "activity_classes", ")", "\n", "#print(len(data_audioset))", "\n", "#print(len(data_vggsound))", "\n", "#print(len(data_ucf))", "\n", "print", "(", "len", "(", "data_activity", ")", ")", "\n", "#np.save('word_embeddings_audiosetzsl_normed.npy', data_audioset)", "\n", "#np.save('word_embeddings_vggsound_normed.npy', data_vggsound)", "\n", "#np.save('word_embeddings_ucf_normed.npy', data_ucf)", "\n", "np", ".", "save", "(", "'word_embeddings_activity_normed.npy'", ",", "data_activity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.get_audioset_classes": [[29, 36], ["pathlib.Path", "pathlib.Path.open", "classes.append", "line.strip"], "function", ["None"], ["", "def", "get_audioset_classes", "(", ")", ":", "\n", "    ", "path_audioset", "=", "Path", "(", "\"data/all_class_clean.txt\"", ")", "\n", "classes", "=", "[", "]", "\n", "with", "path_audioset", ".", "open", "(", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "classes", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.get_ucf_classes": [[45, 47], ["list", "pandas.read_csv"], "function", ["None"], ["", "def", "get_ucf_classes", "(", ")", ":", "\n", "    ", "return", "list", "(", "pd", ".", "read_csv", "(", "\"/home/lriesch29/akata-shared/shared/avzsl/UCF/class-split/ucf_manual_names_ask.csv\"", ")", ".", "manual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.get_vggsound_classes": [[48, 55], ["pathlib.Path", "pathlib.Path.open", "classes.append", "line.strip"], "function", ["None"], ["", "def", "get_vggsound_classes", "(", ")", ":", "\n", "    ", "path_vggsound", "=", "Path", "(", "\"data/vggsound_class_clean.txt\"", ")", "\n", "classes", "=", "[", "]", "\n", "with", "path_vggsound", ".", "open", "(", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "classes", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec._get_class_names": [[56, 62], ["isinstance", "pathlib.Path", "pathlib.Path.open", "sorted", "line.strip"], "function", ["None"], ["", "def", "_get_class_names", "(", "path", ")", ":", "\n", "    ", "if", "isinstance", "(", "path", ",", "str", ")", ":", "\n", "        ", "path", "=", "Path", "(", "path", ")", "\n", "", "with", "path", ".", "open", "(", "\"r\"", ")", "as", "f", ":", "\n", "        ", "classes", "=", "sorted", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", ")", "\n", "", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.extract_word2vec.extract_label_embeddings": [[63, 72], ["numpy.array", "model.get_word_vector", "numpy.testing.assert_almost_equal", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "extract_label_embeddings", "(", "model", ",", "classes", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "result", "=", "{", "}", "\n", "for", "c", "in", "classes", ":", "\n", "        ", "value", "=", "np", ".", "array", "(", "model", ".", "get_word_vector", "(", "c", ")", ")", "\n", "if", "normalize", ":", "\n", "            ", "value", "=", "value", "/", "np", ".", "linalg", ".", "norm", "(", "value", ")", "\n", "np", ".", "testing", ".", "assert_almost_equal", "(", "np", ".", "linalg", ".", "norm", "(", "value", ")", ",", "1", ")", "\n", "", "result", "[", "c", "]", "=", "value", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.None.get_evaluation.get_evaluation": [[15, 120], ["src.args.args_eval", "src.utils.load_args", "src.utils.fix_seeds", "src.utils.setup_evaluation", "logger.info", "copy.deepcopy", "src.utils.load_model_weights", "src.utils.load_model_weights", "src.model_improvements.AVCA.to", "copy.deepcopy.to", "src.test.test", "logger.info", "src.utils.load_args.__dict__.keys", "src.dataset.AudioSetZSLDataset", "src.dataset.AudioSetZSLDataset", "src.utils_improvements.get_model_params", "src.model.AVGZSLNet", "list", "list", "src.dataset.VGGSoundDataset", "src.dataset.VGGSoundDataset", "src.model.DeviseModel", "src.args.args_eval.load_path_stage_A.glob", "src.dataset.UCFDataset", "src.dataset.UCFDataset", "src.model.APN", "src.dataset.ActivityNetDataset", "src.dataset.ActivityNetDataset", "NotImplementedError", "src.model.CJME", "src.model_improvements.AVCA"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args.args_eval", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_args", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.fix_seeds", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.setup_evaluation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_model_weights", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_model_weights", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.test", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils_improvements.get_model_params"], ["def", "get_evaluation", "(", ")", ":", "\n", "    ", "args", "=", "args_eval", "(", ")", "\n", "config", "=", "load_args", "(", "args", ".", "load_path_stage_B", ")", "\n", "assert", "config", ".", "retrain_all", ",", "f\"--retrain_all flag is not set in load_path_stage_B. Are you sure this is the correct path?. {args.load_path_stage_B}\"", "\n", "fix_seeds", "(", "config", ".", "seed", ")", "\n", "\n", "logger", ",", "eval_dir", ",", "test_stats", "=", "setup_evaluation", "(", "args", ",", "config", ".", "__dict__", ".", "keys", "(", ")", ")", "\n", "\n", "if", "args", ".", "dataset_name", "==", "\"AudioSetZSL\"", ":", "\n", "        ", "val_all_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "\"all\"", ",", "\n", ")", "\n", "test_dataset", "=", "AudioSetZSLDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"test\"", ",", "\n", "zero_shot_mode", "=", "\"all\"", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"VGGSound\"", ":", "\n", "        ", "val_all_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "#dataset_split=\"test\",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "test_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"test\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"UCF\"", ":", "\n", "        ", "val_all_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "#dataset_split=\"test\",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "test_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"test\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"ActivityNet\"", ":", "\n", "        ", "val_all_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "#dataset_split=\"test\",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "test_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "config", ",", "\n", "dataset_split", "=", "\"test\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "if", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model_params", "=", "get_model_params", "(", "config", ".", "lr", ",", "config", ".", "first_additional_triplet", ",", "config", ".", "second_additional_triplet", ",", "config", ".", "reg_loss", ",", "config", ".", "additional_triplets_loss", ",", "config", ".", "embedding_dropout", ",", "config", ".", "decoder_dropout", ",", "config", ".", "additional_dropout", ",", "\n", "config", ".", "embeddings_hidden_size", ",", "config", ".", "decoder_hidden_size", ",", "config", ".", "depth_transformer", ",", "config", ".", "momentum", ")", "\n", "\n", "", "if", "args", ".", "ale", "==", "False", "and", "args", ".", "sje", "==", "False", "and", "args", ".", "devise", "==", "False", "and", "args", ".", "apn", "==", "False", "and", "args", ".", "cjme", "==", "False", "and", "args", ".", "AVCA", "==", "False", ":", "\n", "        ", "model_A", "=", "AVGZSLNet", "(", "config", ")", "\n", "", "elif", "args", ".", "ale", "==", "True", "or", "args", ".", "sje", "==", "True", "or", "args", ".", "devise", "==", "True", ":", "\n", "        ", "model_A", "=", "DeviseModel", "(", "config", ")", "\n", "", "elif", "args", ".", "apn", "==", "True", ":", "\n", "        ", "model_A", "=", "APN", "(", "config", ")", "\n", "", "elif", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "model_A", "=", "CJME", "(", "config", ")", "\n", "", "elif", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model_A", "=", "AVCA", "(", "params_model", "=", "model_params", ",", "input_size_audio", "=", "config", ".", "input_size_audio", ",", "input_size_video", "=", "config", ".", "input_size_video", ")", "\n", "\n", "", "logger", ".", "info", "(", "model_A", ")", "\n", "\n", "model_B", "=", "copy", ".", "deepcopy", "(", "model_A", ")", "\n", "\n", "weights_path_stage_A", "=", "list", "(", "args", ".", "load_path_stage_A", ".", "glob", "(", "\"*_score.pt\"", ")", ")", "[", "0", "]", "\n", "epoch_A", "=", "load_model_weights", "(", "weights_path_stage_A", ",", "model_A", ")", "\n", "weights_path_stage_B", "=", "list", "(", "(", "args", ".", "load_path_stage_B", "/", "\"checkpoints\"", ")", ".", "glob", "(", "f\"*_ckpt_{epoch_A - 1}.pt\"", ")", ")", "[", "0", "]", "\n", "_", "=", "load_model_weights", "(", "weights_path_stage_B", ",", "model_B", ")", "\n", "\n", "model_A", ".", "to", "(", "config", ".", "device", ")", "\n", "model_B", ".", "to", "(", "config", ".", "device", ")", "\n", "\n", "\n", "\n", "test", "(", "\n", "eval_name", "=", "args", ".", "eval_name", ",", "\n", "val_dataset", "=", "val_all_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", "model_A", "=", "model_A", ",", "\n", "model_B", "=", "model_B", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "distance_fn", "=", "config", ".", "distance_fn", ",", "\n", "devise_model", "=", "args", ".", "ale", "or", "args", ".", "sje", "or", "args", ".", "devise", ",", "\n", "new_model_attention", "=", "config", ".", "AVCA", ",", "\n", "apn", "=", "args", ".", "apn", ",", "\n", "args", "=", "config", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"FINISHED\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.PreNorm.__init__": [[20, 24], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "fn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "dim", ")", "\n", "self", ".", "fn", "=", "fn", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.PreNorm.forward": [[24, 26], ["model_improvements.PreNorm.fn", "model_improvements.PreNorm.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "self", ".", "norm", "(", "x", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.FeedForward.__init__": [[28, 36], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "hidden_dim", ",", "dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "dim", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.FeedForward.forward": [[37, 39], ["model_improvements.FeedForward.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "net", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.Attention.__init__": [[41, 56], ["torch.Module.__init__", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "heads", "=", "8", ",", "dim_head", "=", "64", ",", "dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "inner_dim", "=", "dim_head", "*", "heads", "\n", "project_out", "=", "not", "(", "heads", "==", "1", "and", "dim_head", "==", "dim", ")", "\n", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "scale", "=", "dim_head", "**", "-", "0.5", "\n", "\n", "self", ".", "attend", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "to_qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "inner_dim", "*", "3", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "to_out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "inner_dim", ",", "dim", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", "\n", ")", "if", "project_out", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.Attention.forward": [[57, 68], ["model_improvements.Attention.to_qkv().chunk", "map", "model_improvements.Attention.attend", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "einops.rearrange", "model_improvements.Attention.to_out", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "model_improvements.Attention.to_qkv", "einops.rearrange", "k.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "qkv", "=", "self", ".", "to_qkv", "(", "x", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "q", ",", "k", ",", "v", "=", "map", "(", "lambda", "t", ":", "rearrange", "(", "t", ",", "'b n (h d) -> b h n d'", ",", "h", "=", "self", ".", "heads", ")", ",", "qkv", ")", "\n", "\n", "dots", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "*", "self", ".", "scale", "\n", "\n", "attn", "=", "self", ".", "attend", "(", "dots", ")", "\n", "\n", "out", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "out", "=", "rearrange", "(", "out", ",", "'b h n d -> b n (h d)'", ")", "\n", "return", "self", ".", "to_out", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.Transformer.__init__": [[70, 77], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "model_improvements.Transformer.layers.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "model_improvements.PreNorm", "model_improvements.PreNorm", "model_improvements.Attention", "model_improvements.FeedForward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "depth", ",", "heads", ",", "dim_head", ",", "mlp_dim", ",", "dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "ModuleList", "(", "[", "\n", "PreNorm", "(", "dim", ",", "Attention", "(", "dim", ",", "heads", "=", "heads", ",", "dim_head", "=", "dim_head", ",", "dropout", "=", "dropout", ")", ")", ",", "\n", "PreNorm", "(", "dim", ",", "FeedForward", "(", "dim", ",", "mlp_dim", ",", "dropout", "=", "dropout", ")", ")", "\n", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.Transformer.forward": [[78, 83], ["attn", "ff"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "attn", ",", "ff", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "attn", "(", "x", ")", "+", "x", "\n", "x", "=", "ff", "(", "x", ")", "+", "x", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.EmbeddingNet.__init__": [[86, 105], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "modules.append", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", ",", "use_bn", ",", "momentum", ",", "hidden_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "EmbeddingNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "if", "hidden_size", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "hidden_size", ")", ")", "\n", "if", "use_bn", ":", "\n", "                ", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "hidden_size", ")", ")", "\n", "", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "hidden_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "output_size", ",", "momentum", "=", "momentum", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "", "else", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "output_size", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.EmbeddingNet.forward": [[106, 109], ["model_improvements.EmbeddingNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.EmbeddingNet.get_embedding": [[110, 112], ["model_improvements.EmbeddingNet.forward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward"], ["", "def", "get_embedding", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.__init__": [[116, 203], ["torch.Module.__init__", "print", "print", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "model_improvements.Transformer", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "model_improvements.EmbeddingNet", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "print", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.lr_scheduler.ReduceLROnPlateau", "torch.lr_scheduler.ReduceLROnPlateau", "torch.lr_scheduler.ReduceLROnPlateau", "torch.lr_scheduler.ReduceLROnPlateau", "print", "print", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.TripletMarginLoss", "torch.TripletMarginLoss", "torch.TripletMarginLoss", "torch.TripletMarginLoss", "print", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "list", "list", "model_improvements.AVCA.W_proj.parameters", "list", "model_improvements.AVCA.D.parameters", "list", "model_improvements.AVCA.cross_attention.parameters", "list", "model_improvements.AVCA.A_enc.parameters", "list", "model_improvements.AVCA.V_enc.parameters", "list", "model_improvements.AVCA.V_rec.parameters", "list", "list", "model_improvements.AVCA.A_rec.parameters", "model_improvements.AVCA.A_proj.parameters", "model_improvements.AVCA.V_proj.parameters"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params_model", ",", "input_size_audio", ",", "input_size_video", ")", ":", "\n", "        ", "super", "(", "AVCA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "print", "(", "'Initializing model variables...'", ",", "end", "=", "''", ")", "\n", "# Dimension of embedding", "\n", "self", ".", "dim_out", "=", "params_model", "[", "'dim_out'", "]", "\n", "# Number of classes", "\n", "self", ".", "hidden_size_encoder", "=", "params_model", "[", "'encoder_hidden_size'", "]", "\n", "self", ".", "hidden_size_decoder", "=", "params_model", "[", "'decoder_hidden_size'", "]", "\n", "self", ".", "r_enc", "=", "params_model", "[", "'dropout_encoder'", "]", "\n", "self", ".", "r_proj", "=", "params_model", "[", "'dropout_decoder'", "]", "\n", "self", ".", "depth_transformer", "=", "params_model", "[", "'depth_transformer'", "]", "\n", "self", ".", "additional_triplets_loss", "=", "params_model", "[", "'additional_triplets_loss'", "]", "\n", "self", ".", "reg_loss", "=", "params_model", "[", "'reg_loss'", "]", "\n", "self", ".", "r_dec", "=", "params_model", "[", "'additional_dropout'", "]", "\n", "self", ".", "momentum", "=", "params_model", "[", "'momentum'", "]", "\n", "\n", "self", ".", "first_additional_triplet", "=", "params_model", "[", "'first_additional_triplet'", "]", "\n", "self", ".", "second_additional_triplet", "=", "params_model", "[", "'second_additional_triplet'", "]", "\n", "\n", "print", "(", "'Initializing trainable models...'", ",", "end", "=", "''", ")", "\n", "\n", "self", ".", "A_enc", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "input_size_audio", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size_encoder", ",", "\n", "output_size", "=", "300", ",", "\n", "dropout", "=", "self", ".", "r_enc", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "\n", "use_bn", "=", "True", "\n", ")", "\n", "self", ".", "V_enc", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "input_size_video", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size_encoder", ",", "\n", "output_size", "=", "300", ",", "\n", "dropout", "=", "self", ".", "r_enc", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "\n", "use_bn", "=", "True", "\n", ")", "\n", "self", ".", "cross_attention", "=", "Transformer", "(", "300", ",", "self", ".", "depth_transformer", ",", "3", ",", "100", ",", "64", ",", "dropout", "=", "self", ".", "r_enc", ")", "\n", "\n", "self", ".", "W_proj", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "300", ",", "\n", "output_size", "=", "self", ".", "dim_out", ",", "\n", "dropout", "=", "self", ".", "r_dec", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "\n", "use_bn", "=", "True", "\n", ")", "\n", "\n", "self", ".", "D", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "self", ".", "dim_out", ",", "\n", "output_size", "=", "300", ",", "\n", "dropout", "=", "self", ".", "r_dec", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "\n", "use_bn", "=", "True", "\n", ")", "\n", "\n", "\n", "\n", "self", ".", "A_proj", "=", "EmbeddingNet", "(", "input_size", "=", "300", ",", "hidden_size", "=", "self", ".", "hidden_size_decoder", ",", "output_size", "=", "self", ".", "dim_out", ",", "dropout", "=", "self", ".", "r_proj", ",", "momentum", "=", "self", ".", "momentum", ",", "use_bn", "=", "True", ")", "\n", "\n", "self", ".", "V_proj", "=", "EmbeddingNet", "(", "input_size", "=", "300", ",", "hidden_size", "=", "self", ".", "hidden_size_decoder", ",", "output_size", "=", "self", ".", "dim_out", ",", "dropout", "=", "self", ".", "r_proj", ",", "momentum", "=", "self", ".", "momentum", ",", "use_bn", "=", "True", ")", "\n", "\n", "self", ".", "A_rec", "=", "EmbeddingNet", "(", "input_size", "=", "self", ".", "dim_out", ",", "output_size", "=", "300", ",", "dropout", "=", "self", ".", "r_dec", ",", "momentum", "=", "self", ".", "momentum", ",", "use_bn", "=", "True", ")", "\n", "\n", "self", ".", "V_rec", "=", "EmbeddingNet", "(", "input_size", "=", "self", ".", "dim_out", ",", "output_size", "=", "300", ",", "dropout", "=", "self", ".", "r_dec", ",", "momentum", "=", "self", ".", "momentum", ",", "use_bn", "=", "True", ")", "\n", "\n", "self", ".", "pos_emb1D", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "2", ",", "300", ")", ")", "\n", "\n", "# Optimizers", "\n", "print", "(", "'Defining optimizers...'", ",", "end", "=", "''", ")", "\n", "self", ".", "lr", "=", "params_model", "[", "'lr'", "]", "\n", "self", ".", "optimizer_gen", "=", "optim", ".", "Adam", "(", "list", "(", "self", ".", "A_proj", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "V_proj", ".", "parameters", "(", ")", ")", "+", "\n", "list", "(", "self", ".", "A_rec", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "V_rec", ".", "parameters", "(", ")", ")", "+", "\n", "list", "(", "self", ".", "V_enc", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "A_enc", ".", "parameters", "(", ")", ")", "+", "\n", "list", "(", "self", ".", "cross_attention", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "D", ".", "parameters", "(", ")", ")", "+", "\n", "list", "(", "self", ".", "W_proj", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n", "self", ".", "scheduler_gen", "=", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "self", ".", "optimizer_gen", ",", "'max'", ",", "patience", "=", "3", ",", "verbose", "=", "True", ")", "\n", "\n", "print", "(", "'Done'", ")", "\n", "\n", "# Loss function", "\n", "print", "(", "'Defining losses...'", ",", "end", "=", "''", ")", "\n", "self", ".", "criterion_reg", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "triplet_loss", "=", "nn", ".", "TripletMarginLoss", "(", "margin", "=", "1.0", ")", "\n", "print", "(", "'Done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.optimize_scheduler": [[204, 206], ["model_improvements.AVCA.scheduler_gen.step"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step"], ["", "def", "optimize_scheduler", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "scheduler_gen", ".", "step", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.forward": [[207, 253], ["model_improvements.AVCA.A_enc", "model_improvements.AVCA.V_enc", "model_improvements.AVCA.A_enc", "model_improvements.AVCA.V_enc", "model_improvements.AVCA.W_proj", "model_improvements.AVCA.W_proj", "model_improvements.AVCA.D", "model_improvements.AVCA.D", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model_improvements.AVCA.cross_attention", "model_improvements.AVCA.cross_attention", "model_improvements.AVCA.V_proj", "model_improvements.AVCA.V_proj", "model_improvements.AVCA.A_proj", "model_improvements.AVCA.A_proj", "model_improvements.AVCA.V_rec", "model_improvements.AVCA.A_rec", "model_improvements.AVCA.A_proj", "model_improvements.AVCA.V_proj", "model_improvements.AVCA.D", "model_improvements.AVCA.D", "model_improvements.AVCA.D", "model_improvements.AVCA.D"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "audio", ",", "image", ",", "negative_audio", ",", "negative_image", ",", "word_embedding", ",", "negative_word_embedding", ")", ":", "\n", "\n", "        ", "self", ".", "phi_a", "=", "self", ".", "A_enc", "(", "audio", ")", "\n", "self", ".", "phi_v", "=", "self", ".", "V_enc", "(", "image", ")", "\n", "\n", "self", ".", "phi_a_neg", "=", "self", ".", "A_enc", "(", "negative_audio", ")", "\n", "self", ".", "phi_v_neg", "=", "self", ".", "V_enc", "(", "negative_image", ")", "\n", "\n", "self", ".", "w", "=", "word_embedding", "\n", "self", ".", "w_neg", "=", "negative_word_embedding", "\n", "\n", "self", ".", "theta_w", "=", "self", ".", "W_proj", "(", "word_embedding", ")", "\n", "self", ".", "theta_w_neg", "=", "self", ".", "W_proj", "(", "negative_word_embedding", ")", "\n", "\n", "self", ".", "rho_w", "=", "self", ".", "D", "(", "self", ".", "theta_w", ")", "\n", "self", ".", "rho_w_neg", "=", "self", ".", "D", "(", "self", ".", "theta_w_neg", ")", "\n", "\n", "self", ".", "positive_input", "=", "torch", ".", "stack", "(", "(", "self", ".", "phi_a", "+", "self", ".", "pos_emb1D", "[", "0", ",", ":", "]", ",", "self", ".", "phi_v", "+", "self", ".", "pos_emb1D", "[", "1", ",", ":", "]", ")", ",", "dim", "=", "1", ")", "\n", "self", ".", "negative_input", "=", "torch", ".", "stack", "(", "(", "self", ".", "phi_a_neg", "+", "self", ".", "pos_emb1D", "[", "0", ",", ":", "]", ",", "self", ".", "phi_v_neg", "+", "self", ".", "pos_emb1D", "[", "1", ",", ":", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "self", ".", "phi_attn", "=", "self", ".", "cross_attention", "(", "self", ".", "positive_input", ")", "\n", "\n", "self", ".", "phi_attn_neg", "=", "self", ".", "cross_attention", "(", "self", ".", "negative_input", ")", "\n", "\n", "self", ".", "audio_fe_attn", "=", "self", ".", "phi_a", "+", "self", ".", "phi_attn", "[", ":", ",", "0", ",", ":", "]", "\n", "self", ".", "video_fe_attn", "=", "self", ".", "phi_v", "+", "self", ".", "phi_attn", "[", ":", ",", "1", ",", ":", "]", "\n", "\n", "\n", "self", ".", "audio_fe_neg_attn", "=", "self", ".", "phi_a_neg", "+", "self", ".", "phi_attn_neg", "[", ":", ",", "0", ",", ":", "]", "\n", "self", ".", "video_fe_neg_attn", "=", "self", ".", "phi_v_neg", "+", "self", ".", "phi_attn_neg", "[", ":", ",", "1", ",", ":", "]", "\n", "\n", "self", ".", "theta_v", "=", "self", ".", "V_proj", "(", "self", ".", "video_fe_attn", ")", "\n", "self", ".", "theta_v_neg", "=", "self", ".", "V_proj", "(", "self", ".", "video_fe_neg_attn", ")", "\n", "self", ".", "theta_a", "=", "self", ".", "A_proj", "(", "self", ".", "audio_fe_attn", ")", "\n", "self", ".", "theta_a_neg", "=", "self", ".", "A_proj", "(", "self", ".", "audio_fe_neg_attn", ")", "\n", "\n", "self", ".", "phi_v_rec", "=", "self", ".", "V_rec", "(", "self", ".", "theta_v", ")", "\n", "self", ".", "phi_a_rec", "=", "self", ".", "A_rec", "(", "self", ".", "theta_a", ")", "\n", "self", ".", "se_em_hat1", "=", "self", ".", "A_proj", "(", "self", ".", "phi_a_rec", ")", "\n", "self", ".", "se_em_hat2", "=", "self", ".", "V_proj", "(", "self", ".", "phi_v_rec", ")", "\n", "\n", "\n", "self", ".", "rho_a", "=", "self", ".", "D", "(", "self", ".", "theta_a", ")", "\n", "self", ".", "rho_a_neg", "=", "self", ".", "D", "(", "self", ".", "theta_a_neg", ")", "\n", "self", ".", "rho_v", "=", "self", ".", "D", "(", "self", ".", "theta_v", ")", "\n", "self", ".", "rho_v_neg", "=", "self", ".", "D", "(", "self", ".", "theta_v_neg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward": [[255, 305], ["model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.optimizer_gen.zero_grad", "loss_gen.backward", "model_improvements.AVCA.optimizer_gen.step", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.triplet_loss", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.criterion_reg", "model_improvements.AVCA.criterion_reg"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step"], ["", "def", "backward", "(", "self", ",", "optimize", ")", ":", "\n", "\n", "        ", "if", "self", ".", "additional_triplets_loss", "==", "True", ":", "\n", "            ", "first_pair", "=", "self", ".", "first_additional_triplet", "*", "(", "self", ".", "triplet_loss", "(", "self", ".", "theta_a", ",", "self", ".", "theta_w", ",", "self", ".", "theta_a_neg", ")", "+", "self", ".", "triplet_loss", "(", "self", ".", "theta_v", ",", "self", ".", "theta_w", ",", "self", ".", "theta_v_neg", ")", ")", "\n", "second_pair", "=", "self", ".", "second_additional_triplet", "*", "(", "self", ".", "triplet_loss", "(", "self", ".", "theta_w", ",", "self", ".", "theta_a", ",", "self", ".", "theta_w_neg", ")", "+", "self", ".", "triplet_loss", "(", "self", ".", "theta_w", ",", "self", ".", "theta_v", ",", "self", ".", "theta_w_neg", ")", ")", "\n", "\n", "l_t", "=", "first_pair", "+", "second_pair", "\n", "\n", "", "if", "self", ".", "reg_loss", "==", "True", ":", "\n", "            ", "l_r", "=", "(", "self", ".", "criterion_reg", "(", "self", ".", "phi_v_rec", ",", "self", ".", "phi_v", ")", "+", "self", ".", "criterion_reg", "(", "self", ".", "phi_a_rec", ",", "self", ".", "phi_a", ")", "+", "self", ".", "criterion_reg", "(", "self", ".", "theta_v", ",", "self", ".", "theta_w", ")", "+", "self", ".", "criterion_reg", "(", "self", ".", "theta_a", ",", "self", ".", "theta_w", ")", ")", "\n", "\n", "\n", "", "l_rec", "=", "self", ".", "criterion_reg", "(", "self", ".", "w", ",", "self", ".", "rho_v", ")", "+", "self", ".", "criterion_reg", "(", "self", ".", "w", ",", "self", ".", "rho_a", ")", "+", "self", ".", "criterion_reg", "(", "self", ".", "w", ",", "self", ".", "rho_w", ")", "\n", "\n", "l_ctv", "=", "self", ".", "triplet_loss", "(", "self", ".", "rho_w", ",", "self", ".", "rho_v", ",", "self", ".", "rho_v_neg", ")", "\n", "l_cta", "=", "self", ".", "triplet_loss", "(", "self", ".", "rho_w", ",", "self", ".", "rho_a", ",", "self", ".", "rho_a_neg", ")", "\n", "l_ct", "=", "l_cta", "+", "l_ctv", "\n", "l_cmd", "=", "l_rec", "+", "l_ct", "\n", "\n", "l_tv", "=", "self", ".", "triplet_loss", "(", "self", ".", "theta_w", ",", "self", ".", "theta_v", ",", "self", ".", "theta_v_neg", ")", "\n", "l_ta", "=", "self", ".", "triplet_loss", "(", "self", ".", "theta_w", ",", "self", ".", "theta_a", ",", "self", ".", "theta_a_neg", ")", "\n", "l_at", "=", "self", ".", "triplet_loss", "(", "self", ".", "theta_a", ",", "self", ".", "theta_w", ",", "self", ".", "theta_w_neg", ")", "\n", "l_vt", "=", "self", ".", "triplet_loss", "(", "self", ".", "theta_v", ",", "self", ".", "theta_w", ",", "self", ".", "theta_w_neg", ")", "\n", "\n", "l_w", "=", "l_ta", "+", "l_at", "+", "l_tv", "+", "l_vt", "\n", "\n", "loss_gen", "=", "l_cmd", "+", "l_w", "\n", "if", "self", ".", "additional_triplets_loss", "==", "True", ":", "\n", "           ", "loss_gen", "+=", "l_t", "\n", "", "if", "self", ".", "reg_loss", "==", "True", ":", "\n", "            ", "loss_gen", "+=", "l_r", "\n", "\n", "", "if", "optimize", "==", "True", ":", "\n", "            ", "self", ".", "optimizer_gen", ".", "zero_grad", "(", ")", "\n", "loss_gen", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_gen", ".", "step", "(", ")", "\n", "\n", "", "loss", "=", "{", "'aut_enc'", ":", "0", ",", "'gen_cyc'", ":", "0", ",", "\n", "'gen_reg'", ":", "0", ",", "'gen'", ":", "loss_gen", "}", "\n", "\n", "loss_numeric", "=", "loss", "[", "'gen_cyc'", "]", "+", "loss", "[", "'gen'", "]", "\n", "\n", "return", "loss_numeric", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.optimize_params": [[306, 313], ["model_improvements.AVCA.forward", "model_improvements.AVCA.backward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward"], ["", "def", "optimize_params", "(", "self", ",", "audio", ",", "video", ",", "cls_numeric", ",", "cls_embedding", ",", "audio_negative", ",", "video_negative", ",", "negative_cls_embedding", ",", "optimize", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "forward", "(", "audio", ",", "video", ",", "audio_negative", ",", "video_negative", ",", "cls_embedding", ",", "negative_cls_embedding", ")", "\n", "\n", "loss_numeric", ",", "loss", "=", "self", ".", "backward", "(", "optimize", ")", "\n", "\n", "return", "loss_numeric", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.get_embeddings": [[314, 331], ["model_improvements.AVCA.A_enc", "model_improvements.AVCA.V_enc", "model_improvements.AVCA.W_proj", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model_improvements.AVCA.cross_attention", "model_improvements.AVCA.V_proj", "model_improvements.AVCA.A_proj"], "methods", ["None"], ["", "def", "get_embeddings", "(", "self", ",", "audio", ",", "video", ",", "embedding", ")", ":", "\n", "\n", "        ", "phi_a", "=", "self", ".", "A_enc", "(", "audio", ")", "\n", "phi_v", "=", "self", ".", "V_enc", "(", "video", ")", "\n", "theta_w", "=", "self", ".", "W_proj", "(", "embedding", ")", "\n", "\n", "input_concatenated", "=", "torch", ".", "stack", "(", "(", "phi_a", "+", "self", ".", "pos_emb1D", "[", "0", ",", ":", "]", ",", "phi_v", "+", "self", ".", "pos_emb1D", "[", "1", ",", ":", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "phi_attn", "=", "self", ".", "cross_attention", "(", "input_concatenated", ")", "\n", "\n", "phi_a", "=", "phi_a", "+", "phi_attn", "[", ":", ",", "0", ",", ":", "]", "\n", "phi_v", "=", "phi_v", "+", "phi_attn", "[", ":", ",", "1", ",", ":", "]", "\n", "\n", "theta_v", "=", "self", ".", "V_proj", "(", "phi_v", ")", "\n", "theta_a", "=", "self", ".", "A_proj", "(", "phi_a", ")", "\n", "\n", "return", "theta_a", ",", "theta_v", ",", "theta_w", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.Metric.__init__": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.Metric.__call__": [[11, 13], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.Metric.reset": [[14, 16], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.Metric.value": [[17, 19], ["None"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.Metric.name": [[20, 22], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.AverageNonzeroTripletsMetric.__init__": [[29, 32], ["metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AverageNonzeroTripletsMetric", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.AverageNonzeroTripletsMetric.__call__": [[33, 36], ["metrics.AverageNonzeroTripletsMetric.values.append", "metrics.AverageNonzeroTripletsMetric.value"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.value"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss", ")", ":", "\n", "        ", "self", ".", "values", ".", "append", "(", "loss", "[", "1", "]", ")", "\n", "return", "self", ".", "value", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.AverageNonzeroTripletsMetric.reset": [[37, 39], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.AverageNonzeroTripletsMetric.value": [[40, 42], ["numpy.mean"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.AverageNonzeroTripletsMetric.name": [[43, 45], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'Average nonzero triplets'", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.PercentOverlappingClasses.__init__": [[48, 51], ["metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PercentOverlappingClasses", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.PercentOverlappingClasses.__call__": [[52, 57], ["metrics.PercentOverlappingClasses.values.append", "len", "len", "len", "len", "torch.where", "labels1.eq"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss", ")", ":", "\n", "        ", "labels1", ",", "labels2", "=", "target", "\n", "assert", "len", "(", "labels1", ")", "==", "len", "(", "labels2", ")", "\n", "percent_overlap", "=", "len", "(", "torch", ".", "where", "(", "labels1", ".", "eq", "(", "labels2", ")", ")", "[", "0", "]", ")", "/", "len", "(", "labels1", ")", "\n", "self", ".", "values", ".", "append", "(", "percent_overlap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.PercentOverlappingClasses.reset": [[58, 60], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.PercentOverlappingClasses.value": [[61, 65], ["numpy.mean"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "value", "=", "np", ".", "mean", "(", "self", ".", "values", ")", "\n", "assert", "value", "==", "0.", "\n", "return", "{", "\"class_overlap\"", ":", "value", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.PercentOverlappingClasses.name": [[66, 68], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "\"Average p,q class overlap [%]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.DetailedLosses.__init__": [[72, 83], ["metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DetailedLosses", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cmd", "=", "[", "]", "\n", "self", ".", "ct", "=", "[", "]", "\n", "self", ".", "l_rec", "=", "[", "]", "\n", "self", ".", "l_cta", "=", "[", "]", "\n", "self", ".", "l_ctv", "=", "[", "]", "\n", "self", ".", "l_ta", "=", "[", "]", "\n", "self", ".", "l_at", "=", "[", "]", "\n", "self", ".", "l_tv", "=", "[", "]", "\n", "self", ".", "l_vt", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.DetailedLosses.__call__": [[84, 94], ["metrics.DetailedLosses.l_rec.append", "metrics.DetailedLosses.l_cta.append", "metrics.DetailedLosses.l_ctv.append", "metrics.DetailedLosses.l_ta.append", "metrics.DetailedLosses.l_at.append", "metrics.DetailedLosses.l_tv.append", "metrics.DetailedLosses.l_vt.append", "metrics.DetailedLosses.cmd.append", "metrics.DetailedLosses.ct.append", "[].item", "[].item", "[].item", "[].item", "[].item", "[].item", "[].item"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss", ")", ":", "\n", "        ", "self", ".", "l_rec", ".", "append", "(", "loss", "[", "1", "]", "[", "\"cmd\"", "]", "[", "\"l_rec\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_cta", ".", "append", "(", "loss", "[", "1", "]", "[", "\"cmd\"", "]", "[", "\"l_cta\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_ctv", ".", "append", "(", "loss", "[", "1", "]", "[", "\"cmd\"", "]", "[", "\"l_ctv\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_ta", ".", "append", "(", "loss", "[", "1", "]", "[", "\"ct\"", "]", "[", "\"l_ta\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_at", ".", "append", "(", "loss", "[", "1", "]", "[", "\"ct\"", "]", "[", "\"l_at\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_tv", ".", "append", "(", "loss", "[", "1", "]", "[", "\"ct\"", "]", "[", "\"l_tv\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "l_vt", ".", "append", "(", "loss", "[", "1", "]", "[", "\"ct\"", "]", "[", "\"l_vt\"", "]", ".", "item", "(", ")", ")", "\n", "self", ".", "cmd", ".", "append", "(", "self", ".", "l_rec", "[", "-", "1", "]", "+", "self", ".", "l_cta", "[", "-", "1", "]", "+", "self", ".", "l_ctv", "[", "-", "1", "]", ")", "\n", "self", ".", "ct", ".", "append", "(", "self", ".", "l_ta", "[", "-", "1", "]", "+", "self", ".", "l_at", "[", "-", "1", "]", "+", "self", ".", "l_tv", "[", "-", "1", "]", "+", "self", ".", "l_vt", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.DetailedLosses.reset": [[95, 105], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "cmd", "=", "[", "]", "\n", "self", ".", "ct", "=", "[", "]", "\n", "self", ".", "l_rec", "=", "[", "]", "\n", "self", ".", "l_cta", "=", "[", "]", "\n", "self", ".", "l_ctv", "=", "[", "]", "\n", "self", ".", "l_ta", "=", "[", "]", "\n", "self", ".", "l_at", "=", "[", "]", "\n", "self", ".", "l_tv", "=", "[", "]", "\n", "self", ".", "l_vt", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.DetailedLosses.value": [[106, 117], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"cmd\"", ":", "np", ".", "mean", "(", "self", ".", "cmd", ")", ",", "\n", "\"ct\"", ":", "np", ".", "mean", "(", "self", ".", "ct", ")", ",", "\n", "\"l_rec\"", ":", "np", ".", "mean", "(", "self", ".", "l_rec", ")", ",", "\n", "\"l_cta\"", ":", "np", ".", "mean", "(", "self", ".", "l_cta", ")", ",", "\n", "\"l_ctv\"", ":", "np", ".", "mean", "(", "self", ".", "l_ctv", ")", ",", "\n", "\"l_ta\"", ":", "np", ".", "mean", "(", "self", ".", "l_ta", ")", ",", "\n", "\"l_at\"", ":", "np", ".", "mean", "(", "self", ".", "l_at", ")", ",", "\n", "\"l_tv\"", ":", "np", ".", "mean", "(", "self", ".", "l_tv", ")", ",", "\n", "\"l_vt\"", ":", "np", ".", "mean", "(", "self", ".", "l_vt", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.DetailedLosses.name": [[119, 121], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "\"Debug losses\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty.__init__": [[124, 134], ["metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "TargetDifficulty", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "easy_audio", "=", "[", "]", "\n", "self", ".", "hard_audio", "=", "[", "]", "\n", "self", ".", "semi_hard_audio", "=", "[", "]", "\n", "self", ".", "easy_video", "=", "[", "]", "\n", "self", ".", "hard_video", "=", "[", "]", "\n", "self", ".", "semi_hard_video", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty.__call__": [[135, 149], ["metrics.TargetDifficulty._get_triplet_difficulty", "metrics.TargetDifficulty._get_triplet_difficulty", "metrics.TargetDifficulty.easy_audio.append", "metrics.TargetDifficulty.hard_audio.append", "metrics.TargetDifficulty.semi_hard_audio.append", "metrics.TargetDifficulty.easy_video.append", "metrics.TargetDifficulty.hard_video.append", "metrics.TargetDifficulty.semi_hard_video.append"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty._get_triplet_difficulty", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty._get_triplet_difficulty"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss", ")", ":", "\n", "# model output is:", "\n", "# x_t1, a1, v1, t1, a2, v2, t2, x_ta1, x_tv1, x_tt1, x_ta2, x_tv2", "\n", "        ", "_", ",", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "outputs", "\n", "easy_audio", ",", "hard_audio", ",", "semi_hard_audio", "=", "self", ".", "_get_triplet_difficulty", "(", "anchor", "=", "t1", ",", "positive", "=", "a1", ",", "negative", "=", "a2", ",", "\n", "margin", "=", "self", ".", "margin", ")", "\n", "easy_video", ",", "hard_video", ",", "semi_hard_video", "=", "self", ".", "_get_triplet_difficulty", "(", "anchor", "=", "t1", ",", "positive", "=", "v1", ",", "negative", "=", "v2", ",", "\n", "margin", "=", "self", ".", "margin", ")", "\n", "self", ".", "easy_audio", ".", "append", "(", "easy_audio", ")", "\n", "self", ".", "hard_audio", ".", "append", "(", "hard_audio", ")", "\n", "self", ".", "semi_hard_audio", ".", "append", "(", "semi_hard_audio", ")", "\n", "self", ".", "easy_video", ".", "append", "(", "easy_video", ")", "\n", "self", ".", "hard_video", ".", "append", "(", "hard_video", ")", "\n", "self", ".", "semi_hard_video", ".", "append", "(", "semi_hard_video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty.reset": [[150, 157], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "easy_audio", "=", "[", "]", "\n", "self", ".", "hard_audio", "=", "[", "]", "\n", "self", ".", "semi_hard_audio", "=", "[", "]", "\n", "self", ".", "easy_video", "=", "[", "]", "\n", "self", ".", "hard_video", "=", "[", "]", "\n", "self", ".", "semi_hard_video", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty.value": [[158, 166], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"easy_audio\"", ":", "np", ".", "mean", "(", "self", ".", "easy_audio", ")", ",", "\n", "\"hard_audio\"", ":", "np", ".", "mean", "(", "self", ".", "hard_audio", ")", ",", "\n", "\"semi_hard_audio\"", ":", "np", ".", "mean", "(", "self", ".", "semi_hard_audio", ")", ",", "\n", "\"easy_video\"", ":", "np", ".", "mean", "(", "self", ".", "easy_video", ")", ",", "\n", "\"hard_video\"", ":", "np", ".", "mean", "(", "self", ".", "hard_video", ")", ",", "\n", "\"semi_hard_video\"", ":", "np", ".", "mean", "(", "self", ".", "semi_hard_video", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty.name": [[168, 170], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "\"Target difficulties\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.TargetDifficulty._get_triplet_difficulty": [[171, 181], ["metrics.TargetDifficulty.distance_fn", "metrics.TargetDifficulty.distance_fn", "numpy.mean", "numpy.mean", "numpy.mean", "easy_targets.cpu().numpy", "hard_targets.cpu().numpy", "semi_hard_targets.cpu().numpy", "easy_targets.cpu", "hard_targets.cpu", "semi_hard_targets.cpu"], "methods", ["None"], ["", "def", "_get_triplet_difficulty", "(", "self", ",", "anchor", ",", "positive", ",", "negative", ",", "margin", ")", ":", "\n", "        ", "distance_positive", "=", "self", ".", "distance_fn", "(", "anchor", ",", "positive", ")", "\n", "distance_negative", "=", "self", ".", "distance_fn", "(", "anchor", ",", "negative", ")", "\n", "easy_targets", "=", "distance_negative", ">", "distance_positive", "+", "margin", "\n", "hard_targets", "=", "distance_negative", "<", "distance_positive", "\n", "semi_hard_targets", "=", "distance_negative", "<", "distance_positive", "+", "margin", "\n", "return", "(", "\n", "np", ".", "mean", "(", "easy_targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "np", ".", "mean", "(", "hard_targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "np", ".", "mean", "(", "semi_hard_targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.__init__": [[185, 216], ["metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "dataset", ",", "device", ",", "distance_fn", ",", "new_model_attention", "=", "False", ",", "model_devise", "=", "False", ",", "apn", "=", "False", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "MeanClassAccuracy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_devise", "=", "model_devise", "\n", "self", ".", "new_model_attention", "=", "new_model_attention", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "apn", "=", "apn", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "audio_seen", "=", "[", "]", "\n", "self", ".", "audio_unseen", "=", "[", "]", "\n", "self", ".", "audio_hm", "=", "[", "]", "\n", "self", ".", "audio_recall", "=", "[", "]", "\n", "self", ".", "audio_beta", "=", "[", "]", "\n", "self", ".", "audio_zsl", "=", "[", "]", "\n", "\n", "self", ".", "video_seen", "=", "[", "]", "\n", "self", ".", "video_unseen", "=", "[", "]", "\n", "self", ".", "video_hm", "=", "[", "]", "\n", "self", ".", "video_recall", "=", "[", "]", "\n", "self", ".", "video_beta", "=", "[", "]", "\n", "self", ".", "video_zsl", "=", "[", "]", "\n", "\n", "\n", "self", ".", "both_seen", "=", "[", "]", "\n", "self", ".", "both_unseen", "=", "[", "]", "\n", "self", ".", "both_hm", "=", "[", "]", "\n", "self", ".", "both_recall", "=", "[", "]", "\n", "self", ".", "both_beta", "=", "[", "]", "\n", "self", ".", "both_zsl", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.__call__": [[217, 250], ["metrics.MeanClassAccuracy.audio_seen.append", "metrics.MeanClassAccuracy.audio_unseen.append", "metrics.MeanClassAccuracy.audio_hm.append", "metrics.MeanClassAccuracy.audio_recall.append", "metrics.MeanClassAccuracy.audio_beta.append", "metrics.MeanClassAccuracy.audio_zsl.append", "metrics.MeanClassAccuracy.video_seen.append", "metrics.MeanClassAccuracy.video_unseen.append", "metrics.MeanClassAccuracy.video_hm.append", "metrics.MeanClassAccuracy.video_recall.append", "metrics.MeanClassAccuracy.video_beta.append", "metrics.MeanClassAccuracy.video_zsl.append", "metrics.MeanClassAccuracy.both_seen.append", "metrics.MeanClassAccuracy.both_unseen.append", "metrics.MeanClassAccuracy.both_hm.append", "metrics.MeanClassAccuracy.both_recall.append", "metrics.MeanClassAccuracy.both_beta.append", "metrics.MeanClassAccuracy.both_zsl.append", "src.utils.evaluate_dataset", "src.utils.evaluate_dataset_baseline"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset_baseline"], ["", "def", "__call__", "(", "self", ",", "outputs", ",", "target", ",", "loss_outputs", ")", ":", "\n", "\n", "        ", "if", "self", ".", "new_model_attention", "==", "False", "and", "self", ".", "model_devise", "==", "False", "and", "self", ".", "apn", "==", "False", ":", "\n", "            ", "evaluation", "=", "evaluate_dataset", "(", "dataset", "=", "self", ".", "dataset", ",", "model", "=", "self", ".", "model", ",", "device", "=", "self", ".", "device", ",", "\n", "distance_fn", "=", "self", ".", "distance_fn", ",", "args", "=", "self", ".", "args", ")", "\n", "", "else", ":", "\n", "            ", "evaluation", "=", "evaluate_dataset_baseline", "(", "dataset", "=", "self", ".", "dataset", ",", "model", "=", "self", ".", "model", ",", "device", "=", "self", ".", "device", ",", "\n", "distance_fn", "=", "self", ".", "distance_fn", ",", "\n", "new_model_attention", "=", "self", ".", "new_model_attention", ",", "\n", "model_devise", "=", "self", ".", "model_devise", ",", "\n", "apn", "=", "self", ".", "apn", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "\n", "", "self", ".", "audio_seen", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"seen\"", "]", ")", "\n", "self", ".", "audio_unseen", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"unseen\"", "]", ")", "\n", "self", ".", "audio_hm", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"hm\"", "]", ")", "\n", "self", ".", "audio_recall", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"recall\"", "]", ")", "\n", "self", ".", "audio_beta", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"beta\"", "]", ")", "\n", "self", ".", "audio_zsl", ".", "append", "(", "evaluation", "[", "\"audio\"", "]", "[", "\"zsl\"", "]", ")", "\n", "\n", "self", ".", "video_seen", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"seen\"", "]", ")", "\n", "self", ".", "video_unseen", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"unseen\"", "]", ")", "\n", "self", ".", "video_hm", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"hm\"", "]", ")", "\n", "self", ".", "video_recall", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"recall\"", "]", ")", "\n", "self", ".", "video_beta", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"beta\"", "]", ")", "\n", "self", ".", "video_zsl", ".", "append", "(", "evaluation", "[", "\"video\"", "]", "[", "\"zsl\"", "]", ")", "\n", "\n", "self", ".", "both_seen", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"seen\"", "]", ")", "\n", "self", ".", "both_unseen", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"unseen\"", "]", ")", "\n", "self", ".", "both_hm", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"hm\"", "]", ")", "\n", "self", ".", "both_recall", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"recall\"", "]", ")", "\n", "self", ".", "both_beta", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"beta\"", "]", ")", "\n", "self", ".", "both_zsl", ".", "append", "(", "evaluation", "[", "\"both\"", "]", "[", "\"zsl\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.reset": [[251, 272], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "audio_seen", "=", "[", "]", "\n", "self", ".", "audio_unseen", "=", "[", "]", "\n", "self", ".", "audio_hm", "=", "[", "]", "\n", "self", ".", "audio_recall", "=", "[", "]", "\n", "self", ".", "audio_beta", "=", "[", "]", "\n", "self", ".", "audio_zsl", "=", "[", "]", "\n", "\n", "self", ".", "video_seen", "=", "[", "]", "\n", "self", ".", "video_unseen", "=", "[", "]", "\n", "self", ".", "video_hm", "=", "[", "]", "\n", "self", ".", "video_recall", "=", "[", "]", "\n", "self", ".", "video_beta", "=", "[", "]", "\n", "self", ".", "video_zsl", "=", "[", "]", "\n", "\n", "self", ".", "both_seen", "=", "[", "]", "\n", "self", ".", "both_unseen", "=", "[", "]", "\n", "self", ".", "both_hm", "=", "[", "]", "\n", "self", ".", "both_recall", "=", "[", "]", "\n", "self", ".", "both_beta", "=", "[", "]", "\n", "self", ".", "both_zsl", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.value": [[273, 295], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"audio_seen\"", ":", "np", ".", "mean", "(", "self", ".", "audio_seen", ")", ",", "\n", "\"audio_unseen\"", ":", "np", ".", "mean", "(", "self", ".", "audio_unseen", ")", ",", "\n", "\"audio_hm\"", ":", "np", ".", "mean", "(", "self", ".", "audio_hm", ")", ",", "\n", "\"audio_recall\"", ":", "np", ".", "mean", "(", "self", ".", "audio_recall", ",", "axis", "=", "0", ")", ",", "\n", "\"audio_beta\"", ":", "np", ".", "mean", "(", "self", ".", "audio_beta", ")", ",", "\n", "\"audio_zsl\"", ":", "np", ".", "mean", "(", "self", ".", "audio_zsl", ")", ",", "\n", "\n", "\"video_seen\"", ":", "np", ".", "mean", "(", "self", ".", "video_seen", ")", ",", "\n", "\"video_unseen\"", ":", "np", ".", "mean", "(", "self", ".", "video_unseen", ")", ",", "\n", "\"video_hm\"", ":", "np", ".", "mean", "(", "self", ".", "video_hm", ")", ",", "\n", "\"video_recall\"", ":", "np", ".", "mean", "(", "self", ".", "video_recall", ",", "axis", "=", "0", ")", ",", "\n", "\"video_beta\"", ":", "np", ".", "mean", "(", "self", ".", "video_beta", ")", ",", "\n", "\"video_zsl\"", ":", "np", ".", "mean", "(", "self", ".", "video_zsl", ")", ",", "\n", "\n", "\"both_seen\"", ":", "np", ".", "mean", "(", "self", ".", "both_seen", ")", ",", "\n", "\"both_unseen\"", ":", "np", ".", "mean", "(", "self", ".", "both_unseen", ")", ",", "\n", "\"both_hm\"", ":", "np", ".", "mean", "(", "self", ".", "both_hm", ")", ",", "\n", "\"both_recall\"", ":", "np", ".", "mean", "(", "self", ".", "both_recall", ",", "axis", "=", "0", ")", ",", "\n", "\"both_beta\"", ":", "np", ".", "mean", "(", "self", ".", "both_beta", ")", ",", "\n", "\"both_zsl\"", ":", "np", ".", "mean", "(", "self", ".", "both_zsl", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.name": [[297, 299], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "\"Mean class accuracies per modality\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.LogFormatter.__init__": [[16, 18], ["time.time"], "methods", ["None"], ["", "def", "format", "(", "self", ",", "record", ")", ":", "\n", "        ", "elapsed_seconds", "=", "round", "(", "record", ".", "created", "-", "self", ".", "start_time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.LogFormatter.format": [[19, 30], ["round", "record.getMessage", "message.replace.replace.replace", "time.strftime", "datetime.timedelta", "len"], "methods", ["None"], ["prefix", "=", "\"%s - %s - %s\"", "%", "(", "\n", "record", ".", "levelname", ",", "\n", "time", ".", "strftime", "(", "\"%x %X\"", ")", ",", "\n", "timedelta", "(", "seconds", "=", "elapsed_seconds", ")", ",", "\n", ")", "\n", "message", "=", "record", ".", "getMessage", "(", ")", "\n", "message", "=", "message", ".", "replace", "(", "\"\\n\"", ",", "\"\\n\"", "+", "\" \"", "*", "(", "len", "(", "prefix", ")", "+", "3", ")", ")", "\n", "return", "\"%s - %s\"", "%", "(", "prefix", ",", "message", ")", "if", "message", "else", "\"\"", "\n", "\n", "\n", "", "", "def", "create_logger", "(", "filepath", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.PD_Stats.__init__": [[76, 88], ["os.path.isfile", "pandas.read_pickle", "pandas.DataFrame", "list", "list"], "methods", ["None"], ["            ", "self", ".", "stats", "=", "pd", ".", "read_pickle", "(", "self", ".", "path", ")", "\n", "\n", "# check that columns are the same", "\n", "assert", "list", "(", "self", ".", "stats", ".", "columns", ")", "==", "list", "(", "columns", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "stats", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "\n", "", "", "def", "update", "(", "self", ",", "row", ",", "save", "=", "True", ")", ":", "\n", "        ", "self", ".", "stats", ".", "loc", "[", "len", "(", "self", ".", "stats", ".", "index", ")", "]", "=", "row", "\n", "\n", "# save the statistics", "\n", "if", "save", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.PD_Stats.update": [[89, 95], ["logger.PD_Stats.stats.to_pickle", "len"], "methods", ["None"], ["            ", "self", ".", "stats", ".", "to_pickle", "(", "self", ".", "path", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.create_logger": [[32, 69], ["logger.LogFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "time.time"], "function", ["None"], ["\n", "# create log formatter", "\n", "log_formatter", "=", "LogFormatter", "(", ")", "\n", "\n", "# create file handler and set level to debug", "\n", "if", "filepath", "is", "not", "None", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "filepath", ",", "\"a\"", ")", "\n", "file_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_formatter", ")", "\n", "\n", "# create console handler and set level to info", "\n", "", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_formatter", ")", "\n", "\n", "# create logger and set level to debug", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "handlers", "=", "[", "]", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "propagate", "=", "False", "\n", "if", "filepath", "is", "not", "None", ":", "\n", "        ", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "", "logger", ".", "addHandler", "(", "console_handler", ")", "\n", "\n", "# reset logger elapsed time", "\n", "def", "reset_time", "(", ")", ":", "\n", "        ", "log_formatter", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "logger", ".", "reset_time", "=", "reset_time", "\n", "\n", "return", "logger", "\n", "\n", "\n", "", "class", "PD_Stats", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    Log stuff with pandas library\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.__init__": [[12, 45], ["_train_X.size", "classifier_fsl.LINEAR_LOGSOFTMAX", "classifier_fsl.CLASSIFIER.model.apply", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "classifier_fsl.CLASSIFIER.model.parameters", "classifier_fsl.CLASSIFIER.model.cuda", "classifier_fsl.CLASSIFIER.criterion.cuda", "classifier_fsl.CLASSIFIER.train_X.size", "classifier_fsl.CLASSIFIER.fit_gfsl", "classifier_fsl.CLASSIFIER.fit_fsl"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.fit_gfsl", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.fit_fsl"], ["    ", "def", "__init__", "(", "self", ",", "_train_X", ",", "_train_Y", ",", "mapping_dict", ",", "data_loader", ",", "target_classes", ",", "_cuda", ",", "_lr", "=", "0.001", ",", "_beta1", "=", "0.5", ",", "_nepoch", "=", "30", ",", "_batch_size", "=", "1024", ",", "generalized", "=", "False", ",", "classes_gzsl", "=", "None", ")", ":", "\n", "        ", "self", ".", "train_X", "=", "_train_X", "\n", "self", ".", "train_Y", "=", "_train_Y", "\n", "self", ".", "target_classes", "=", "target_classes", "\n", "self", ".", "mapping_dict", "=", "mapping_dict", "\n", "self", ".", "dataloader", "=", "data_loader", "\n", "self", ".", "batch_size", "=", "_batch_size", "\n", "self", ".", "nepoch", "=", "_nepoch", "\n", "self", ".", "input_dim", "=", "_train_X", ".", "size", "(", "1", ")", "\n", "self", ".", "cuda", "=", "_cuda", "\n", "self", ".", "model", "=", "LINEAR_LOGSOFTMAX", "(", "self", ".", "input_dim", ",", "target_classes", ".", "shape", "[", "0", "]", ")", "\n", "self", ".", "model", ".", "apply", "(", "src", ".", "util_fewshot", ".", "weights_init", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "if", "generalized", "==", "True", ":", "\n", "            ", "self", ".", "unseen_classes_gzsl", ",", "self", ".", "seen_classes_gzsl", "=", "classes_gzsl", "\n", "\n", "", "self", ".", "lr", "=", "_lr", "\n", "self", ".", "beta1", "=", "_beta1", "\n", "# setup optimizer", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "_lr", ",", "betas", "=", "(", "_beta1", ",", "0.999", ")", ")", "\n", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "self", ".", "criterion", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "index_in_epoch", "=", "0", "\n", "self", ".", "epochs_completed", "=", "0", "\n", "self", ".", "ntrain", "=", "self", ".", "train_X", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "if", "generalized", ":", "\n", "            ", "self", ".", "acc_all", ",", "self", ".", "acc_base", ",", "self", ".", "acc_novel", "=", "self", ".", "fit_gfsl", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "acc", "=", "self", ".", "fit_fsl", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.fit_fsl": [[47, 88], ["torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "copy.deepcopy", "range", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "test_Y_original[].item", "classifier_fsl.CLASSIFIER.train_Y.size", "classifier_fsl.CLASSIFIER.train_Y[].item", "range", "classifier_fsl.CLASSIFIER.val", "classifier_fsl.CLASSIFIER.model.zero_grad", "batch_input.cuda", "batch_label.cuda", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.criterion", "classifier_fsl.CLASSIFIER.backward", "classifier_fsl.CLASSIFIER.optimizer.step", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "", "def", "fit_fsl", "(", "self", ")", ":", "\n", "        ", "best_acc", "=", "0", "\n", "perm", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain", ")", "\n", "self", ".", "train_X", "=", "self", ".", "train_X", "[", "perm", "]", "\n", "self", ".", "train_Y", "=", "self", ".", "train_Y", "[", "perm", "]", "\n", "\n", "(", "test_audio", ",", "test_video", ",", "test_Y_original", ")", "=", "self", ".", "dataloader", "\n", "test_X", "=", "F", ".", "normalize", "(", "torch", ".", "cat", "(", "(", "test_audio", ",", "test_video", ")", ",", "axis", "=", "1", ")", ")", "\n", "test_Y", "=", "copy", ".", "deepcopy", "(", "test_Y_original", ")", "\n", "for", "i", "in", "range", "(", "test_Y_original", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "current_class", "=", "test_Y_original", "[", "i", "]", ".", "item", "(", ")", "\n", "new_class", "=", "self", ".", "mapping_dict", "[", "current_class", "]", "\n", "test_Y", "[", "i", "]", "=", "new_class", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "train_Y", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "current_class", "=", "self", ".", "train_Y", "[", "i", "]", ".", "item", "(", ")", "\n", "new_class", "=", "self", ".", "mapping_dict", "[", "current_class", "]", "\n", "self", ".", "train_Y", "[", "i", "]", "=", "new_class", "\n", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "nepoch", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "self", ".", "ntrain", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "batch_input", ",", "batch_label", "=", "F", ".", "normalize", "(", "self", ".", "train_X", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ",", "self", ".", "train_Y", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "\n", "inputv", "=", "batch_input", ".", "cuda", "(", ")", "\n", "labelv", "=", "batch_label", ".", "cuda", "(", ")", "\n", "#for j in range(labelv.size(0)):", "\n", "#    current_class=labelv[j].item()", "\n", "#    new_class=self.mapping_dict[current_class]", "\n", "#    labelv[j]=new_class", "\n", "output", "=", "self", ".", "model", "(", "inputv", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "output", ",", "labelv", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "", "acc", "=", "self", ".", "val", "(", "test_X", ",", "test_Y", ",", "self", ".", "target_classes", ")", "\n", "if", "best_acc", "<", "acc", ":", "\n", "                ", "best_acc", "=", "acc", "\n", "\n", "", "", "return", "best_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.fit_gfsl": [[89, 130], ["torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "copy.deepcopy", "range", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "test_Y_original[].item", "classifier_fsl.CLASSIFIER.train_Y.size", "classifier_fsl.CLASSIFIER.train_Y[].item", "range", "classifier_fsl.CLASSIFIER.val_gfsl", "classifier_fsl.CLASSIFIER.model.zero_grad", "batch_input.cuda", "batch_label.cuda", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.criterion", "classifier_fsl.CLASSIFIER.backward", "classifier_fsl.CLASSIFIER.optimizer.step", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val_gfsl", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "def", "fit_gfsl", "(", "self", ")", ":", "\n", "        ", "best_acc_all", "=", "0", "\n", "\n", "perm", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain", ")", "\n", "self", ".", "train_X", "=", "self", ".", "train_X", "[", "perm", "]", "\n", "self", ".", "train_Y", "=", "self", ".", "train_Y", "[", "perm", "]", "\n", "\n", "(", "test_audio", ",", "test_video", ",", "test_Y_original", ")", "=", "self", ".", "dataloader", "\n", "test_X", "=", "F", ".", "normalize", "(", "torch", ".", "cat", "(", "(", "test_audio", ",", "test_video", ")", ",", "axis", "=", "1", ")", ")", "\n", "test_Y", "=", "copy", ".", "deepcopy", "(", "test_Y_original", ")", "\n", "for", "i", "in", "range", "(", "test_Y_original", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "current_class", "=", "test_Y_original", "[", "i", "]", ".", "item", "(", ")", "\n", "new_class", "=", "self", ".", "mapping_dict", "[", "current_class", "]", "\n", "test_Y", "[", "i", "]", "=", "new_class", "\n", "", "for", "i", "in", "range", "(", "self", ".", "train_Y", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "current_class", "=", "self", ".", "train_Y", "[", "i", "]", ".", "item", "(", ")", "\n", "new_class", "=", "self", ".", "mapping_dict", "[", "current_class", "]", "\n", "self", ".", "train_Y", "[", "i", "]", "=", "new_class", "\n", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "nepoch", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "self", ".", "ntrain", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "batch_input", ",", "batch_label", "=", "F", ".", "normalize", "(", "self", ".", "train_X", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ",", "self", ".", "train_Y", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "\n", "inputv", "=", "batch_input", ".", "cuda", "(", ")", "\n", "labelv", "=", "batch_label", ".", "cuda", "(", ")", "\n", "#for j in range(labelv.size(0)):", "\n", "#    current_class = labelv[j].item()", "\n", "#    new_class = self.mapping_dict[current_class]", "\n", "#    labelv[j] = new_class", "\n", "output", "=", "self", ".", "model", "(", "inputv", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "output", ",", "labelv", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "acc_all", ",", "acc_novel", ",", "acc_base", "=", "self", ".", "val_gfsl", "(", "test_X", ",", "test_Y", ",", "self", ".", "seen_classes_gzsl", ",", "self", ".", "unseen_classes_gzsl", ")", "\n", "if", "best_acc_all", "<=", "acc_all", ":", "\n", "                ", "best_acc_all", "=", "acc_all", "\n", "best_acc_base", "=", "acc_base", "\n", "best_acc_novel", "=", "acc_novel", "\n", "", "", "return", "best_acc_all", ",", "best_acc_base", ",", "best_acc_novel", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.next_batch": [[131, 166], ["torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "start", "=", "self", ".", "index_in_epoch", "\n", "# shuffle the data at the first epoch", "\n", "if", "self", ".", "epochs_completed", "==", "0", "and", "start", "==", "0", ":", "\n", "            ", "perm", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain", ")", "\n", "self", ".", "train_X", "=", "self", ".", "train_X", "[", "perm", "]", "\n", "self", ".", "train_Y", "=", "self", ".", "train_Y", "[", "perm", "]", "\n", "# the last batch", "\n", "", "if", "start", "+", "batch_size", ">", "self", ".", "ntrain", ":", "\n", "            ", "self", ".", "epochs_completed", "+=", "1", "\n", "rest_num_examples", "=", "self", ".", "ntrain", "-", "start", "\n", "if", "rest_num_examples", ">", "0", ":", "\n", "                ", "X_rest_part", "=", "self", ".", "train_X", "[", "start", ":", "self", ".", "ntrain", "]", "\n", "Y_rest_part", "=", "self", ".", "train_Y", "[", "start", ":", "self", ".", "ntrain", "]", "\n", "# shuffle the data", "\n", "", "perm", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain", ")", "\n", "self", ".", "train_X", "=", "self", ".", "train_X", "[", "perm", "]", "\n", "self", ".", "train_Y", "=", "self", ".", "train_Y", "[", "perm", "]", "\n", "# start next epoch", "\n", "start", "=", "0", "\n", "self", ".", "index_in_epoch", "=", "batch_size", "-", "rest_num_examples", "\n", "end", "=", "self", ".", "index_in_epoch", "\n", "X_new_part", "=", "self", ".", "train_X", "[", "start", ":", "end", "]", "\n", "Y_new_part", "=", "self", ".", "train_Y", "[", "start", ":", "end", "]", "\n", "#print(start, end)", "\n", "if", "rest_num_examples", ">", "0", ":", "\n", "                ", "return", "torch", ".", "cat", "(", "(", "X_rest_part", ",", "X_new_part", ")", ",", "0", ")", ",", "torch", ".", "cat", "(", "(", "Y_rest_part", ",", "Y_new_part", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "return", "X_new_part", ",", "Y_new_part", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "index_in_epoch", "+=", "batch_size", "\n", "end", "=", "self", ".", "index_in_epoch", "\n", "#print(start, end)", "\n", "# from index start to index end-1", "\n", "return", "self", ".", "train_X", "[", "start", ":", "end", "]", ",", "self", ".", "train_Y", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.next_batch_uniform_class": [[167, 183], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "classifier_fsl.CLASSIFIER.train_X.size", "classifier_fsl.CLASSIFIER.train_Y.eq().nonzero().squeeze", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "classifier_fsl.CLASSIFIER.train_Y.eq().nonzero", "classifier_fsl.CLASSIFIER.size", "classifier_fsl.CLASSIFIER.train_Y.eq"], "methods", ["None"], ["", "", "def", "next_batch_uniform_class", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "batch_class", "=", "torch", ".", "LongTensor", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain_class", ")", "[", "0", "]", "\n", "batch_class", "[", "i", "]", "=", "self", ".", "train_class", "[", "idx", "]", "\n", "\n", "", "batch_feature", "=", "torch", ".", "FloatTensor", "(", "batch_size", ",", "self", ".", "train_X", ".", "size", "(", "1", ")", ")", "\n", "batch_label", "=", "torch", ".", "LongTensor", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "iclass", "=", "batch_class", "[", "i", "]", "\n", "idx_iclass", "=", "self", ".", "train_Y", ".", "eq", "(", "iclass", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "idx_in_iclass", "=", "torch", ".", "randperm", "(", "idx_iclass", ".", "size", "(", "0", ")", ")", "[", "0", "]", "\n", "idx_file", "=", "idx_iclass", "[", "idx_in_iclass", "]", "\n", "batch_feature", "[", "i", "]", "=", "self", ".", "train_X", "[", "idx_file", "]", "\n", "batch_label", "[", "i", "]", "=", "self", ".", "train_Y", "[", "idx_file", "]", "\n", "", "return", "batch_feature", ",", "batch_label", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val_gfsl_top1_top5": [[184, 214], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "numpy.in1d", "numpy.in1d", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.array", "test_X.size", "test_label.size", "min", "classifier_fsl.CLASSIFIER.perelement_accuracy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.concatenate", "numpy.concatenate", "test_label[].numpy", "numpy.concatenate", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.model", "test_X[].cuda", "test_label[].numpy"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.perelement_accuracy"], ["", "def", "val_gfsl_top1_top5", "(", "self", ",", "test_X", ",", "test_label", ",", "novelclasses", ",", "baseclasses", ")", ":", "\n", "        ", "start", "=", "0", "\n", "ntest", "=", "test_X", ".", "size", "(", ")", "[", "0", "]", "\n", "predicted_label", "=", "torch", ".", "LongTensor", "(", "test_label", ".", "size", "(", ")", ")", "\n", "top1", "=", "None", "\n", "top5", "=", "None", "\n", "all_labels", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "ntest", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "end", "=", "min", "(", "ntest", ",", "start", "+", "self", ".", "batch_size", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "cuda", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ")", "\n", "", "", "top1_this", ",", "top5_this", "=", "self", ".", "perelement_accuracy", "(", "output", ".", "data", ",", "test_label", "[", "start", ":", "end", "]", ")", "\n", "top1", "=", "top1_this", "if", "top1", "is", "None", "else", "np", ".", "concatenate", "(", "(", "top1", ",", "top1_this", ")", ")", "\n", "top5", "=", "top5_this", "if", "top5", "is", "None", "else", "np", ".", "concatenate", "(", "(", "top5", ",", "top5_this", ")", ")", "\n", "all_labels", "=", "test_label", "[", "start", ":", "end", "]", ".", "numpy", "(", ")", "if", "all_labels", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_labels", ",", "test_label", "[", "start", ":", "end", "]", ".", "numpy", "(", ")", ")", ")", "\n", "start", "=", "end", "\n", "\n", "", "is_novel", "=", "np", ".", "in1d", "(", "all_labels", ",", "novelclasses", ")", "\n", "is_base", "=", "np", ".", "in1d", "(", "all_labels", ",", "baseclasses", ")", "\n", "is_either", "=", "is_novel", "|", "is_base", "\n", "top1_novel", "=", "np", ".", "mean", "(", "top1", "[", "is_novel", "]", ")", "\n", "top1_base", "=", "np", ".", "mean", "(", "top1", "[", "is_base", "]", ")", "\n", "top1_all", "=", "np", ".", "mean", "(", "top1", "[", "is_either", "]", ")", "\n", "top5_novel", "=", "np", ".", "mean", "(", "top5", "[", "is_novel", "]", ")", "\n", "top5_base", "=", "np", ".", "mean", "(", "top5", "[", "is_base", "]", ")", "\n", "top5_all", "=", "np", ".", "mean", "(", "top5", "[", "is_either", "]", ")", "\n", "return", "np", ".", "array", "(", "[", "top1_novel", ",", "top5_novel", ",", "top1_base", ",", "top5_base", ",", "top1_all", ",", "top5_all", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val_gfsl": [[215, 233], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "classifier_fsl.CLASSIFIER.compute_per_class_acc_gfsl", "classifier_fsl.CLASSIFIER.compute_per_class_acc_gfsl", "test_X.size", "test_label.size", "min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.model", "numpy.finfo", "test_X[].cuda"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.compute_per_class_acc_gfsl", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.compute_per_class_acc_gfsl"], ["", "def", "val_gfsl", "(", "self", ",", "test_X", ",", "test_label", ",", "baseclasses", ",", "novelclasses", ")", ":", "\n", "        ", "start", "=", "0", "\n", "ntest", "=", "test_X", ".", "size", "(", ")", "[", "0", "]", "\n", "predicted_label", "=", "torch", ".", "LongTensor", "(", "test_label", ".", "size", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "ntest", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "end", "=", "min", "(", "ntest", ",", "start", "+", "self", ".", "batch_size", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "cuda", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ")", "\n", "", "", "_", ",", "predicted_label", "[", "start", ":", "end", "]", "=", "torch", ".", "max", "(", "output", ".", "data", ",", "1", ")", "\n", "start", "=", "end", "\n", "\n", "", "acc_base", "=", "self", ".", "compute_per_class_acc_gfsl", "(", "test_label", ",", "predicted_label", ",", "baseclasses", ")", "\n", "acc_novel", "=", "self", ".", "compute_per_class_acc_gfsl", "(", "test_label", ",", "predicted_label", ",", "novelclasses", ")", "\n", "acc_all", "=", "(", "2", "*", "acc_novel", "*", "acc_base", ")", "/", "(", "(", "acc_novel", "+", "acc_base", ")", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "return", "acc_all", ",", "acc_novel", ",", "acc_base", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.compute_per_class_acc_gfsl": [[234, 241], ["torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "compute_per_class_acc_gfsl", "(", "self", ",", "test_label", ",", "predicted_label", ",", "target_classes", ")", ":", "\n", "        ", "acc_per_class", "=", "0", "\n", "for", "i", "in", "target_classes", ":", "\n", "            ", "idx", "=", "(", "test_label", "==", "i", ")", "\n", "acc_per_class", "+=", "torch", ".", "sum", "(", "test_label", "[", "idx", "]", "==", "predicted_label", "[", "idx", "]", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "idx", ")", ".", "item", "(", ")", "\n", "", "acc_per_class", "/=", "target_classes", ".", "shape", "[", "0", "]", "\n", "return", "acc_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.perelement_accuracy": [[242, 249], ["scores.topk", "labels.cpu().numpy", "topk_labels.cpu().numpy", "numpy.sum", "top1_correct.astype", "numpy.sum.astype", "labels.cpu", "topk_labels.cpu", "labels.cpu().numpy.reshape"], "methods", ["None"], ["", "def", "perelement_accuracy", "(", "self", ",", "scores", ",", "labels", ")", ":", "\n", "        ", "topk_scores", ",", "topk_labels", "=", "scores", ".", "topk", "(", "5", ",", "1", ",", "True", ",", "True", ")", "\n", "label_ind", "=", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "topk_ind", "=", "topk_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "top1_correct", "=", "topk_ind", "[", ":", ",", "0", "]", "==", "label_ind", "\n", "top5_correct", "=", "np", ".", "sum", "(", "topk_ind", "==", "label_ind", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", ",", "axis", "=", "1", ")", "\n", "return", "top1_correct", ".", "astype", "(", "float", ")", ",", "top5_correct", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val_fsl_top1_top5": [[251, 274], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "numpy.mean", "numpy.mean", "test_X.size", "test_label.size", "min", "classifier_fsl.CLASSIFIER.perelement_accuracy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.concatenate", "numpy.concatenate", "test_label[].numpy", "numpy.concatenate", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.model", "test_X[].cuda", "test_label[].numpy"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.perelement_accuracy"], ["", "def", "val_fsl_top1_top5", "(", "self", ",", "test_X", ",", "test_label", ")", ":", "\n", "        ", "start", "=", "0", "\n", "ntest", "=", "test_X", ".", "size", "(", ")", "[", "0", "]", "\n", "predicted_label", "=", "torch", ".", "LongTensor", "(", "test_label", ".", "size", "(", ")", ")", "\n", "top1", "=", "None", "\n", "top5", "=", "None", "\n", "all_labels", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "ntest", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "end", "=", "min", "(", "ntest", ",", "start", "+", "self", ".", "batch_size", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "cuda", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ")", "\n", "", "", "top1_this", ",", "top5_this", "=", "self", ".", "perelement_accuracy", "(", "output", ".", "data", ",", "test_label", "[", "start", ":", "end", "]", ")", "\n", "top1", "=", "top1_this", "if", "top1", "is", "None", "else", "np", ".", "concatenate", "(", "(", "top1", ",", "top1_this", ")", ")", "\n", "top5", "=", "top5_this", "if", "top5", "is", "None", "else", "np", ".", "concatenate", "(", "(", "top5", ",", "top5_this", ")", ")", "\n", "all_labels", "=", "test_label", "[", "start", ":", "end", "]", ".", "numpy", "(", ")", "if", "all_labels", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_labels", ",", "test_label", "[", "start", ":", "end", "]", ".", "numpy", "(", ")", ")", ")", "\n", "start", "=", "end", "\n", "\n", "", "acc_top1", "=", "np", ".", "mean", "(", "top1", ")", "\n", "acc_top5", "=", "np", ".", "mean", "(", "top5", ")", "\n", "return", "acc_top1", ",", "acc_top5", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.val": [[276, 293], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "classifier_fsl.CLASSIFIER.compute_per_class_acc", "test_X.size", "test_label.size", "min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classifier_fsl.CLASSIFIER.model", "classifier_fsl.CLASSIFIER.model", "test_X[].cuda"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.compute_per_class_acc"], ["", "def", "val", "(", "self", ",", "test_X", ",", "test_label", ",", "target_classes", ")", ":", "\n", "        ", "start", "=", "0", "\n", "ntest", "=", "test_X", ".", "size", "(", ")", "[", "0", "]", "\n", "predicted_label", "=", "torch", ".", "LongTensor", "(", "test_label", ".", "size", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "ntest", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "end", "=", "min", "(", "ntest", ",", "start", "+", "self", ".", "batch_size", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "cuda", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "output", "=", "self", ".", "model", "(", "test_X", "[", "start", ":", "end", "]", ")", "\n", "", "", "_", ",", "predicted_label", "[", "start", ":", "end", "]", "=", "torch", ".", "max", "(", "output", ".", "data", ",", "1", ")", "\n", "start", "=", "end", "\n", "\n", "#acc = torch.sum(test_label == predicted_label).item() / test_label.size(0)", "\n", "", "acc", "=", "self", ".", "compute_per_class_acc", "(", "test_label", ",", "predicted_label", ",", "target_classes", ".", "shape", "[", "0", "]", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.CLASSIFIER.compute_per_class_acc": [[294, 300], ["torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "range", "torch.FloatTensor().fill_.mean().item", "torch.FloatTensor().fill_.mean().item", "torch.FloatTensor().fill_.mean().item", "torch.FloatTensor().fill_.mean().item", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.FloatTensor().fill_.mean", "torch.FloatTensor().fill_.mean", "torch.FloatTensor().fill_.mean", "torch.FloatTensor().fill_.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "compute_per_class_acc", "(", "self", ",", "test_label", ",", "predicted_label", ",", "nclass", ")", ":", "\n", "        ", "acc_per_class", "=", "torch", ".", "FloatTensor", "(", "nclass", ")", ".", "fill_", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "nclass", ")", ":", "\n", "            ", "idx", "=", "(", "test_label", "==", "i", ")", "\n", "acc_per_class", "[", "i", "]", "=", "torch", ".", "sum", "(", "test_label", "[", "idx", "]", "==", "predicted_label", "[", "idx", "]", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "idx", ")", ".", "item", "(", ")", "\n", "", "return", "acc_per_class", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.LINEAR_LOGSOFTMAX.__init__": [[302, 306], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "nclass", ")", ":", "\n", "        ", "super", "(", "LINEAR_LOGSOFTMAX", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "nclass", ")", "\n", "self", ".", "logic", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.classifier_fsl.LINEAR_LOGSOFTMAX.forward": [[306, 309], ["classifier_fsl.LINEAR_LOGSOFTMAX.logic", "classifier_fsl.LINEAR_LOGSOFTMAX.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "o", "=", "self", ".", "logic", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "return", "o", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_AC_D.__init__": [[15, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Sigmoid", "torch.Sigmoid", "model_gen.MLP_AC_D.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_AC_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "disc_linear", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "aux_linear", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "attSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_AC_D.forward": [[25, 30], ["model_gen.MLP_AC_D.lrelu", "model_gen.MLP_AC_D.sigmoid", "model_gen.MLP_AC_D.aux_linear", "model_gen.MLP_AC_D.fc1", "model_gen.MLP_AC_D.disc_linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "s", "=", "self", ".", "sigmoid", "(", "self", ".", "disc_linear", "(", "h", ")", ")", "\n", "a", "=", "self", ".", "aux_linear", "(", "h", ")", "\n", "return", "s", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_AC_2HL_D.__init__": [[32, 43], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Sigmoid", "torch.Sigmoid", "torch.Dropout", "torch.Dropout", "model_gen.MLP_AC_2HL_D.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_AC_2HL_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "disc_linear", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "aux_linear", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "attSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_AC_2HL_D.forward": [[44, 50], ["model_gen.MLP_AC_2HL_D.dropout", "model_gen.MLP_AC_2HL_D.dropout", "model_gen.MLP_AC_2HL_D.sigmoid", "model_gen.MLP_AC_2HL_D.aux_linear", "model_gen.MLP_AC_2HL_D.lrelu", "model_gen.MLP_AC_2HL_D.lrelu", "model_gen.MLP_AC_2HL_D.disc_linear", "model_gen.MLP_AC_2HL_D.fc1", "model_gen.MLP_AC_2HL_D.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "x", ")", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "s", "=", "self", ".", "sigmoid", "(", "self", ".", "disc_linear", "(", "h", ")", ")", "\n", "a", "=", "self", ".", "aux_linear", "(", "h", ")", "\n", "return", "s", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_3HL_CRITIC.__init__": [[52, 60], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_3HL_CRITIC.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_3HL_CRITIC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc4", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_3HL_CRITIC.forward": [[61, 68], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_3HL_CRITIC.lrelu", "model_gen.MLP_3HL_CRITIC.lrelu", "model_gen.MLP_3HL_CRITIC.lrelu", "model_gen.MLP_3HL_CRITIC.fc4", "model_gen.MLP_3HL_CRITIC.fc1", "model_gen.MLP_3HL_CRITIC.fc2", "model_gen.MLP_3HL_CRITIC.fc3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc3", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc4", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_CRITIC.__init__": [[70, 77], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_2HL_CRITIC.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_2HL_CRITIC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_CRITIC.forward": [[78, 84], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_2HL_CRITIC.lrelu", "model_gen.MLP_2HL_CRITIC.lrelu", "model_gen.MLP_2HL_CRITIC.fc3", "model_gen.MLP_2HL_CRITIC.fc1", "model_gen.MLP_2HL_CRITIC.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_Dropout_CRITIC.__init__": [[86, 94], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "model_gen.MLP_2HL_Dropout_CRITIC.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_2HL_Dropout_CRITIC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_Dropout_CRITIC.forward": [[95, 101], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_2HL_Dropout_CRITIC.dropout", "model_gen.MLP_2HL_Dropout_CRITIC.dropout", "model_gen.MLP_2HL_Dropout_CRITIC.fc3", "model_gen.MLP_2HL_Dropout_CRITIC.lrelu", "model_gen.MLP_2HL_Dropout_CRITIC.lrelu", "model_gen.MLP_2HL_Dropout_CRITIC.fc1", "model_gen.MLP_2HL_Dropout_CRITIC.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_S.__init__": [[103, 112], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_CRITIC_S.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_CRITIC_S", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#self.fc_reduce = nn.Linear(opt.resSize, opt.attSize)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "#self.fc2 = nn.Linear(opt.ndh, opt.ndh)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_S.forward": [[113, 119], ["model_gen.MLP_CRITIC_S.lrelu", "model_gen.MLP_CRITIC_S.fc2", "model_gen.MLP_CRITIC_S.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "att", ")", ":", "\n", "#h = torch.cat((, att), 1) ", "\n", "#h = self.lrelu(self.fc_reduce(att))", "\n", "        ", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "att", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_V.__init__": [[121, 129], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_CRITIC_V.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_CRITIC_V", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "#self.fc3 = nn.Linear(2048, 1)", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_V.forward": [[130, 136], ["model_gen.MLP_CRITIC_V.lrelu", "model_gen.MLP_CRITIC_V.fc2", "model_gen.MLP_CRITIC_V.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#h = torch.cat((x, att), 1) ", "\n", "        ", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "#h = self.lrelu(self.fc2(h))", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_VS.__init__": [[138, 146], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_CRITIC_VS.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_CRITIC_VS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "#self.fc2 = nn.Linear(opt.ndh, opt.ndh)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_VS.forward": [[147, 152], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_CRITIC_VS.lrelu", "model_gen.MLP_CRITIC_VS.fc2", "model_gen.MLP_CRITIC_VS.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_3layer.__init__": [[154, 162], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_CRITIC_3layer.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_CRITIC_3layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "2048", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "2048", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC_3layer.forward": [[163, 169], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_CRITIC_3layer.lrelu", "model_gen.MLP_CRITIC_3layer.lrelu", "model_gen.MLP_CRITIC_3layer.fc3", "model_gen.MLP_CRITIC_3layer.fc1", "model_gen.MLP_CRITIC_3layer.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SND.__init__": [[172, 180], ["torch.Module.__init__", "SpectralNorm", "SpectralNorm", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_SND.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_SND", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "SpectralNorm", "(", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", ",", "n_power_iterations", "=", "1", ")", "\n", "#self.fc2 = nn.Linear(opt.ndh, opt.ndh)", "\n", "self", ".", "fc2", "=", "SpectralNorm", "(", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", ",", "n_power_iterations", "=", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SND.forward": [[181, 186], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_SND.lrelu", "model_gen.MLP_SND.fc2", "model_gen.MLP_SND.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC.__init__": [[188, 196], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "model_gen.MLP_CRITIC.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_CRITIC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "#self.fc2 = nn.Linear(opt.ndh, opt.ndh)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_CRITIC.forward": [[197, 202], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_CRITIC.lrelu", "model_gen.MLP_CRITIC.fc2", "model_gen.MLP_CRITIC.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_D.__init__": [[204, 212], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Sigmoid", "torch.Sigmoid", "model_gen.MLP_D.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_D.forward": [[213, 218], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_D.lrelu", "model_gen.MLP_D.sigmoid", "model_gen.MLP_D.fc1", "model_gen.MLP_D.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "sigmoid", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_Dropout_G.__init__": [[220, 231], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "model_gen.MLP_2HL_Dropout_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_2HL_Dropout_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_Dropout_G.forward": [[232, 238], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_2HL_Dropout_G.dropout", "model_gen.MLP_2HL_Dropout_G.dropout", "model_gen.MLP_2HL_Dropout_G.relu", "model_gen.MLP_2HL_Dropout_G.lrelu", "model_gen.MLP_2HL_Dropout_G.lrelu", "model_gen.MLP_2HL_Dropout_G.fc3", "model_gen.MLP_2HL_Dropout_G.fc1", "model_gen.MLP_2HL_Dropout_G.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc3", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_3HL_G.__init__": [[240, 251], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_3HL_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_3HL_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc4", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_3HL_G.forward": [[252, 259], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_3HL_G.lrelu", "model_gen.MLP_3HL_G.lrelu", "model_gen.MLP_3HL_G.lrelu", "model_gen.MLP_3HL_G.relu", "model_gen.MLP_3HL_G.fc1", "model_gen.MLP_3HL_G.fc2", "model_gen.MLP_3HL_G.fc3", "model_gen.MLP_3HL_G.fc4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc3", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc4", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_G.__init__": [[261, 271], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_2HL_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_2HL_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2HL_G.forward": [[272, 278], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_2HL_G.lrelu", "model_gen.MLP_2HL_G.lrelu", "model_gen.MLP_2HL_G.relu", "model_gen.MLP_2HL_G.fc1", "model_gen.MLP_2HL_G.fc2", "model_gen.MLP_2HL_G.fc3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc3", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_Dropout_G.__init__": [[280, 289], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "model_gen.MLP_Dropout_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_Dropout_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_Dropout_G.forward": [[290, 295], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_Dropout_G.dropout", "model_gen.MLP_Dropout_G.relu", "model_gen.MLP_Dropout_G.lrelu", "model_gen.MLP_Dropout_G.fc2", "model_gen.MLP_Dropout_G.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_V_TO_S_LINEAR.__init__": [[297, 302], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "model_gen.MLP_V_TO_S_LINEAR.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_V_TO_S_LINEAR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", ",", "opt", ".", "attSize", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_V_TO_S_LINEAR.forward": [[303, 306], ["model_gen.MLP_V_TO_S_LINEAR.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "res", ")", ":", "\n", "        ", "h", "=", "self", ".", "fc", "(", "res", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_V_TO_S.__init__": [[308, 318], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_V_TO_S.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_V_TO_S", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#self.fc_reduce = nn.Linear(opt.resSize, opt.nz)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "attSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_V_TO_S.forward": [[319, 326], ["model_gen.MLP_V_TO_S.lrelu", "model_gen.MLP_V_TO_S.fc2", "model_gen.MLP_V_TO_S.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "res", ")", ":", "\n", "#h = self.lrelu(self.fc_reduce(res))", "\n", "#h = torch.cat((noise, h), 1)", "\n", "#h = torch.cat((noise, res), 1)", "\n", "        ", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "res", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G_S.__init__": [[328, 338], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_G_S.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_G_S", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#self.fc_reduce = nn.Linear(opt.resSize, opt.nz)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "nz", "+", "opt", ".", "resSize", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "attSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G_S.forward": [[339, 346], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_G_S.lrelu", "model_gen.MLP_G_S.fc2", "model_gen.MLP_G_S.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "res", ")", ":", "\n", "#h = self.lrelu(self.fc_reduce(res))", "\n", "#h = torch.cat((noise, h), 1)", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "res", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SNG.__init__": [[349, 358], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_SNG.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_SNG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SNG.forward": [[359, 364], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_SNG.lrelu", "model_gen.MLP_SNG.relu", "model_gen.MLP_SNG.fc1", "model_gen.MLP_SNG.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G.__init__": [[366, 375], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G.forward": [[376, 381], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_G.lrelu", "model_gen.MLP_G.relu", "model_gen.MLP_G.fc1", "model_gen.MLP_G.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G_V.__init__": [[383, 392], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_G_V.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_G_V", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_G_V.forward": [[393, 398], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_G_V.lrelu", "model_gen.MLP_G_V.relu", "model_gen.MLP_G_V.fc1", "model_gen.MLP_G_V.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2048_1024_Dropout_G.__init__": [[400, 412], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "model_gen.MLP_2048_1024_Dropout_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_2048_1024_Dropout_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "#self.fc2 = nn.Linear(opt.ngh, opt.ngh)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "1024", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "1024", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "#self.relu = nn.ReLU(True)", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_2048_1024_Dropout_G.forward": [[413, 419], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_2048_1024_Dropout_G.dropout", "model_gen.MLP_2048_1024_Dropout_G.dropout", "model_gen.MLP_2048_1024_Dropout_G.fc3", "model_gen.MLP_2048_1024_Dropout_G.lrelu", "model_gen.MLP_2048_1024_Dropout_G.lrelu", "model_gen.MLP_2048_1024_Dropout_G.fc1", "model_gen.MLP_2048_1024_Dropout_G.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "self", ".", "lrelu", "(", "self", ".", "fc2", "(", "h", ")", ")", ")", "\n", "h", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SKIP_G.__init__": [[422, 434], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReLU", "torch.ReLU", "model_gen.MLP_SKIP_G.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_SKIP_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", "+", "opt", ".", "nz", ",", "opt", ".", "ngh", ")", "\n", "#self.fc2 = nn.Linear(opt.ngh, opt.ngh)", "\n", "#self.fc2 = nn.Linear(opt.ngh, 1024)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ngh", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "fc_skip", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", ",", "opt", ".", "resSize", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "#self.prelu = nn.PReLU()", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SKIP_G.forward": [[435, 442], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_SKIP_G.lrelu", "model_gen.MLP_SKIP_G.relu", "model_gen.MLP_SKIP_G.fc_skip", "model_gen.MLP_SKIP_G.fc1", "model_gen.MLP_SKIP_G.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "noise", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "#h = self.lrelu(self.fc2(h))", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc2", "(", "h", ")", ")", "\n", "h2", "=", "self", ".", "fc_skip", "(", "att", ")", "\n", "return", "h", "+", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.Decoder.__init__": [[445, 460], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "enumerate", "zip", "model_gen.Decoder.MLP.add_module", "len", "model_gen.Decoder.MLP.add_module", "model_gen.Decoder.MLP.add_module", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layer_sizes", ",", "latent_size", ",", "attSize", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "MLP", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "input_size", "=", "latent_size", "+", "attSize", "\n", "\n", "for", "i", ",", "(", "in_size", ",", "out_size", ")", "in", "enumerate", "(", "zip", "(", "[", "input_size", "]", "+", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", ")", ")", ":", "\n", "            ", "self", ".", "MLP", ".", "add_module", "(", "name", "=", "\"L%i\"", "%", "(", "i", ")", ",", "module", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", ")", "\n", "if", "i", "+", "1", "<", "len", "(", "layer_sizes", ")", ":", "\n", "#self.MLP.add_module(name=\"A%i\"%(i), module=nn.LeakyReLU(0.2, True))", "\n", "                ", "self", ".", "MLP", ".", "add_module", "(", "name", "=", "\"A%i\"", "%", "(", "i", ")", ",", "module", "=", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "MLP", ".", "add_module", "(", "name", "=", "\"sigmoid\"", ",", "module", "=", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.Decoder.forward": [[461, 468], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.Decoder.MLP"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "z", ",", "c", ")", ":", "\n", "\n", "        ", "z", "=", "torch", ".", "cat", "(", "(", "z", ",", "c", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "self", ".", "MLP", "(", "z", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.Encoder.__init__": [[471, 487], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "enumerate", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "zip", "model_gen.Encoder.MLP.add_module", "model_gen.Encoder.MLP.add_module", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layer_sizes", ",", "latent_size", ",", "attSize", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "layer_sizes", "[", "0", "]", "+=", "attSize", "\n", "\n", "self", ".", "MLP", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "for", "i", ",", "(", "in_size", ",", "out_size", ")", "in", "enumerate", "(", "zip", "(", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", "[", "1", ":", "]", ")", ")", ":", "\n", "            ", "self", ".", "MLP", ".", "add_module", "(", "name", "=", "\"L%i\"", "%", "(", "i", ")", ",", "module", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", ")", "\n", "#self.MLP.add_module(name=\"A%i\"%(i), module=nn.LeakyReLU(0.2, True))", "\n", "self", ".", "MLP", ".", "add_module", "(", "name", "=", "\"A%i\"", "%", "(", "i", ")", ",", "module", "=", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "\n", "", "self", ".", "linear_means", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "latent_size", ")", "\n", "self", ".", "linear_log_var", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "latent_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.Encoder.forward": [[488, 498], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.Encoder.MLP", "model_gen.Encoder.linear_means", "model_gen.Encoder.linear_log_var"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "c", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "self", ".", "MLP", "(", "x", ")", "\n", "\n", "means", "=", "self", ".", "linear_means", "(", "x", ")", "\n", "log_vars", "=", "self", ".", "linear_log_var", "(", "x", ")", "\n", "\n", "return", "means", ",", "log_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SKIP_D.__init__": [[502, 511], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Sigmoid", "torch.Sigmoid", "model_gen.MLP_SKIP_D.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MLP_SKIP_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "opt", ".", "resSize", "+", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "opt", ".", "ndh", ",", "1", ")", "\n", "self", ".", "fc_skip", "=", "nn", ".", "Linear", "(", "opt", ".", "attSize", ",", "opt", ".", "ndh", ")", "\n", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.MLP_SKIP_D.forward": [[512, 518], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_gen.MLP_SKIP_D.lrelu", "model_gen.MLP_SKIP_D.lrelu", "model_gen.MLP_SKIP_D.sigmoid", "model_gen.MLP_SKIP_D.fc1", "model_gen.MLP_SKIP_D.fc_skip", "model_gen.MLP_SKIP_D.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "att", ")", ":", "\n", "        ", "h", "=", "torch", ".", "cat", "(", "(", "x", ",", "att", ")", ",", "1", ")", "\n", "h", "=", "self", ".", "lrelu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h2", "=", "self", ".", "lrelu", "(", "self", ".", "fc_skip", "(", "att", ")", ")", "\n", "h", "=", "self", ".", "sigmoid", "(", "self", ".", "fc2", "(", "h", "+", "h2", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.FC.__init__": [[520, 524], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "model_gen.FC.apply"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ")", ":", "\n", "        ", "super", "(", "FC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.FC.forward": [[524, 526], ["model_gen.FC.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_gen.weights_init": [[5, 13], ["classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_"], "function", ["None"], ["def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.train.train": [[9, 32], ["range", "train.train_step", "train.val_step", "src.utils.check_best_loss", "src.utils.check_best_score", "src.utils.save_best_model", "lr_scheduler.step", "model.optimize_scheduler"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.train.train_step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.train.val_step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.check_best_loss", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.check_best_score", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.optimize_scheduler"], ["def", "train", "(", "train_loader", ",", "val_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "lr_scheduler", ",", "epochs", ",", "device", ",", "writer", ",", "metrics", ",", "\n", "train_stats", ",", "val_stats", ",", "log_dir", ",", "new_model_attention", "=", "False", ",", "model_devise", "=", "False", ",", "apn", "=", "False", ",", "cjme", "=", "False", ",", "args", "=", "None", ")", ":", "\n", "    ", "best_loss", "=", "None", "\n", "best_score", "=", "None", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "train_loss", "=", "train_step", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "epochs", ",", "writer", ",", "device", ",", "metrics", ",", "\n", "train_stats", ",", "new_model_attention", ",", "model_devise", ",", "apn", ",", "cjme", ",", "args", ")", "\n", "val_loss", ",", "val_hm", "=", "val_step", "(", "val_loader", ",", "model", ",", "criterion", ",", "epoch", ",", "epochs", ",", "writer", ",", "device", ",", "metrics", ",", "val_stats", ",", "\n", "new_model_attention", ",", "model_devise", ",", "apn", ",", "cjme", ",", "args", ")", "\n", "\n", "best_loss", "=", "check_best_loss", "(", "epoch", ",", "best_loss", ",", "val_loss", ",", "model", ",", "optimizer", ",", "log_dir", ")", "\n", "best_score", "=", "check_best_score", "(", "epoch", ",", "best_score", ",", "val_hm", ",", "model", ",", "optimizer", ",", "log_dir", ")", "\n", "\n", "if", "args", ".", "save_checkpoints", ":", "\n", "# save_best_model(epoch, val_loss, model, optimizer, log_dir / \"checkpoints\", metric=\"loss\", checkpoint=True)", "\n", "            ", "save_best_model", "(", "epoch", ",", "val_hm", ",", "model", ",", "optimizer", ",", "log_dir", "/", "\"checkpoints\"", ",", "metric", "=", "\"score\"", ",", "checkpoint", "=", "True", ")", "\n", "\n", "", "if", "lr_scheduler", ":", "\n", "            ", "lr_scheduler", ".", "step", "(", "val_hm", ")", "\n", "", "if", "new_model_attention", "==", "True", ":", "\n", "            ", "model", ".", "optimize_scheduler", "(", "val_hm", ")", "\n", "", "", "return", "best_loss", ",", "best_score", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.train.train_step": [[33, 133], ["logging.getLogger", "model.train", "enumerate", "stats.update", "logging.getLogger.info", "metric.reset", "model.train", "p[].to", "p[].to", "p[].to", "target[].to", "q[].to", "q[].to", "q[].to", "loss.item", "target[].to", "target[].to", "tuple", "model", "model.get_classes_embedding", "criterion", "optimizer.zero_grad", "loss.backward", "optimizer.step", "model", "criterion", "optimizer.zero_grad", "loss.backward", "optimizer.step", "range", "torch.cat", "model", "criterion", "optimizer.zero_grad", "loss.backward", "optimizer.step", "len", "model.get_classes_embedding.detach", "range", "torch.cat", "model", "criterion", "optimizer.zero_grad", "loss.backward", "optimizer.step", "torch.sqrt", "model.optimize_params", "model.get_embeddings", "torch.stack", "torch.mean", "torch.var", "[].item", "[].item"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.reset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.get_classes_embedding", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.optimize_params", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.get_embeddings"], ["", "def", "train_step", "(", "data_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "epochs", ",", "writer", ",", "device", ",", "metrics", ",", "stats", ",", "\n", "new_model_attention", ",", "model_devise", ",", "apn", ",", "cjme", ",", "args", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "metric", ".", "reset", "(", ")", "\n", "\n", "", "batch_loss", "=", "0", "\n", "\n", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "p", "=", "data", "[", "\"positive\"", "]", "\n", "q", "=", "data", "[", "\"negative\"", "]", "\n", "\n", "x_p_a", "=", "p", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_v", "=", "p", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_t", "=", "p", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_num", "=", "target", "[", "\"positive\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "x_q_a", "=", "q", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "x_q_v", "=", "q", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "x_q_t", "=", "q", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "            ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_t", ",", "\n", "x_q_a", ",", "x_q_v", ",", "x_q_t", "\n", ")", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "            ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_num", ",", "x_p_t", ",", "x_q_a", ",", "x_q_v", ",", "x_q_t", "\n", ")", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_num", ",", "x_p_t", "\n", ")", "\n", "\n", "", "if", "args", ".", "z_score_inputs", ":", "\n", "            ", "inputs", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "inputs", "]", ")", "\n", "\n", "", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "            ", "if", "cjme", "==", "True", ":", "\n", "                ", "outputs", "=", "model", "(", "*", "inputs", ")", "\n", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "embeddings_projected", "=", "model", ".", "get_classes_embedding", "(", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "*", "outputs", ",", "embeddings_projected", ".", "detach", "(", ")", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "model", "(", "*", "inputs", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "*", "outputs", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "", "elif", "apn", "==", "True", ":", "\n", "            ", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "for", "i", "in", "range", "(", "inputs", "[", "2", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "inputs", "[", "2", "]", "[", "i", "]", "=", "mapping_dict", "[", "(", "inputs", "[", "2", "]", "[", "[", "i", "]", "]", ")", ".", "item", "(", ")", "]", "\n", "", "input_features", "=", "torch", ".", "cat", "(", "(", "inputs", "[", "1", "]", ",", "inputs", "[", "0", "]", ")", ",", "1", ")", "\n", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attribute", "=", "model", "(", "input_features", ",", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "model", ",", "output_final", ",", "pre_attri", ",", "pre_class", ",", "inputs", "[", "3", "]", ",", "inputs", "[", "2", "]", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "elif", "model_devise", "==", "True", ":", "\n", "            ", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "for", "i", "in", "range", "(", "inputs", "[", "2", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "inputs", "[", "2", "]", "[", "i", "]", "=", "mapping_dict", "[", "(", "inputs", "[", "2", "]", "[", "[", "i", "]", "]", ")", ".", "item", "(", ")", "]", "\n", "", "input_features", "=", "torch", ".", "cat", "(", "(", "inputs", "[", "1", "]", ",", "inputs", "[", "0", "]", ")", ",", "1", ")", "\n", "outputs", ",", "_", ",", "_", "=", "model", "(", "input_features", ",", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "outputs", ",", "inputs", "[", "2", "]", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "            ", "loss", ",", "loss_details", "=", "model", ".", "optimize_params", "(", "*", "inputs", ",", "optimize", "=", "True", ")", "\n", "audio_emb", ",", "video_emb", ",", "emb_cls", "=", "model", ".", "get_embeddings", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "inputs", "[", "3", "]", ")", "\n", "outputs", "=", "torch", ".", "stack", "(", "[", "video_emb", ",", "emb_cls", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "p_target", "=", "target", "[", "\"positive\"", "]", ".", "to", "(", "device", ")", "\n", "q_target", "=", "target", "[", "\"negative\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "# stats", "\n", "iteration", "=", "len", "(", "data_loader", ")", "*", "epoch", "+", "batch_idx", "\n", "\n", "\n", "", "batch_loss", "/=", "(", "batch_idx", "+", "1", ")", "\n", "stats", ".", "update", "(", "(", "epoch", ",", "batch_loss", ",", "None", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"TRAIN\\t\"", "\n", "f\"Epoch: {epoch}/{epochs}\\t\"", "\n", "f\"Iteration: {iteration}\\t\"", "\n", "f\"Loss: {batch_loss:.4f}\\t\"", "\n", ")", "\n", "return", "batch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.train.val_step": [[136, 240], ["logging.getLogger", "model.eval", "metric.reset", "torch.no_grad", "enumerate", "stats.update", "logging.getLogger.info", "p[].to", "p[].to", "p[].to", "target[].to", "q[].to", "q[].to", "q[].to", "loss.item", "target[].to", "target[].to", "tuple", "model", "model.get_classes_embedding", "criterion", "model", "criterion", "range", "torch.cat", "model", "criterion", "len", "len", "metric", "metric.value().items", "range", "torch.cat", "model", "criterion", "writer.add_scalar", "torch.sqrt", "model.optimize_params", "model.get_embeddings", "metric.value", "torch.mean", "torch.var", "[].item", "[].item"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.reset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.get_classes_embedding", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.optimize_params", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.get_embeddings", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.metrics.MeanClassAccuracy.value"], ["", "def", "val_step", "(", "data_loader", ",", "model", ",", "criterion", ",", "epoch", ",", "epochs", ",", "writer", ",", "device", ",", "metrics", ",", "stats", ",", "\n", "new_model_attention", ",", "model_devise", ",", "apn", ",", "cjme", ",", "args", "=", "None", ")", ":", "\n", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "metric", ".", "reset", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "batch_loss", "=", "0", "\n", "hm_score", "=", "0", "\n", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "p", "=", "data", "[", "\"positive\"", "]", "\n", "q", "=", "data", "[", "\"negative\"", "]", "\n", "\n", "x_p_a", "=", "p", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_v", "=", "p", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_t", "=", "p", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "x_p_num", "=", "target", "[", "\"positive\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "x_q_a", "=", "q", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "x_q_v", "=", "q", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "x_q_t", "=", "q", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "                ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_t", ",", "\n", "x_q_a", ",", "x_q_v", ",", "x_q_t", "\n", ")", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "                ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_num", ",", "x_p_t", ",", "x_q_a", ",", "x_q_v", ",", "x_q_t", "\n", ")", "\n", "", "else", ":", "\n", "                ", "inputs", "=", "(", "\n", "x_p_a", ",", "x_p_v", ",", "x_p_num", ",", "x_p_t", "\n", ")", "\n", "\n", "", "if", "args", ".", "z_score_inputs", ":", "\n", "                ", "inputs", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "inputs", "]", ")", "\n", "\n", "", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "                ", "if", "cjme", "==", "True", ":", "\n", "                    ", "outputs", "=", "model", "(", "*", "inputs", ")", "\n", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "embeddings_projected", "=", "model", ".", "get_classes_embedding", "(", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "*", "outputs", ",", "embeddings_projected", ")", "\n", "", "else", ":", "\n", "                    ", "outputs", "=", "model", "(", "*", "inputs", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "*", "outputs", ")", "\n", "", "", "elif", "model_devise", "==", "True", ":", "\n", "                ", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "for", "i", "in", "range", "(", "inputs", "[", "2", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "inputs", "[", "2", "]", "[", "i", "]", "=", "mapping_dict", "[", "(", "inputs", "[", "2", "]", "[", "[", "i", "]", "]", ")", ".", "item", "(", ")", "]", "\n", "", "input_features", "=", "torch", ".", "cat", "(", "(", "inputs", "[", "1", "]", ",", "inputs", "[", "0", "]", ")", ",", "1", ")", "\n", "outputs", ",", "_", ",", "_", "=", "model", "(", "input_features", ",", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "outputs", ",", "inputs", "[", "2", "]", ")", "\n", "", "elif", "apn", "==", "True", ":", "\n", "                ", "embeddings", ",", "mapping_dict", "=", "data_loader", ".", "dataset", ".", "zsl_dataset", ".", "map_embeddings_target", "\n", "for", "i", "in", "range", "(", "inputs", "[", "2", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "inputs", "[", "2", "]", "[", "i", "]", "=", "mapping_dict", "[", "(", "inputs", "[", "2", "]", "[", "[", "i", "]", "]", ")", ".", "item", "(", ")", "]", "\n", "", "input_features", "=", "torch", ".", "cat", "(", "(", "inputs", "[", "1", "]", ",", "inputs", "[", "0", "]", ")", ",", "1", ")", "\n", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attribute", "=", "model", "(", "input_features", ",", "embeddings", ")", "\n", "loss", ",", "loss_details", "=", "criterion", "(", "model", ",", "output_final", ",", "pre_attri", ",", "pre_class", ",", "inputs", "[", "3", "]", ",", "inputs", "[", "2", "]", ")", "\n", "outputs", "=", "output_final", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "                ", "loss", ",", "loss_details", "=", "model", ".", "optimize_params", "(", "*", "inputs", ")", "\n", "audio_emb", ",", "video_emb", ",", "emb_cls", "=", "model", ".", "get_embeddings", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "inputs", "[", "3", "]", ")", "\n", "outputs", "=", "(", "video_emb", ",", "emb_cls", ")", "\n", "\n", "", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "p_target", "=", "target", "[", "\"positive\"", "]", ".", "to", "(", "device", ")", "\n", "q_target", "=", "target", "[", "\"negative\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "# stats", "\n", "iteration", "=", "len", "(", "data_loader", ")", "*", "epoch", "+", "batch_idx", "\n", "if", "iteration", "%", "len", "(", "data_loader", ")", "==", "0", ":", "\n", "                ", "for", "metric", "in", "metrics", ":", "\n", "                    ", "metric", "(", "outputs", ",", "(", "p_target", ",", "q_target", ")", ",", "(", "loss", ",", "loss_details", ")", ")", "\n", "for", "key", ",", "value", "in", "metric", ".", "value", "(", ")", ".", "items", "(", ")", ":", "\n", "                        ", "if", "\"recall\"", "in", "key", ":", "\n", "                            ", "continue", "\n", "", "if", "\"both_hm\"", "in", "key", ":", "\n", "                            ", "hm_score", "=", "value", "\n", "", "if", "\"both_zsl\"", "in", "key", ":", "\n", "                            ", "zsl_score", "=", "value", "\n", "", "writer", ".", "add_scalar", "(", "\n", "f\"val_{key}\"", ",", "value", ",", "iteration", "\n", ")", "\n", "\n", "", "", "", "", "batch_loss", "/=", "(", "batch_idx", "+", "1", ")", "\n", "stats", ".", "update", "(", "(", "epoch", ",", "batch_loss", ",", "hm_score", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"VALID\\t\"", "\n", "f\"Epoch: {epoch}/{epochs}\\t\"", "\n", "f\"Iteration: {iteration}\\t\"", "\n", "f\"Loss: {batch_loss:.4f}\\t\"", "\n", "f\"ZSL score: {zsl_score:.4f}\\t\"", "\n", "f\"HM: {hm_score:.4f}\"", "\n", ")", "\n", "", "return", "batch_loss", ",", "hm_score", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils_improvements.get_model_params": [[20, 41], ["dict"], "function", ["None"], ["def", "get_model_params", "(", "lr", ",", "first_additional_triplet", ",", "second_additional_triplet", ",", "reg_loss", ",", "additional_triplets_loss", ",", "dropout_encoder", ",", "dropout_decoder", ",", "additional_dropout", ",", "encoder_hidden_size", ",", "decoder_hidden_size", ",", "depth_transformer", ",", "momentum", ")", ":", "\n", "# Model parameters", "\n", "    ", "params_model", "=", "dict", "(", ")", "\n", "params_model", "[", "'dim_out'", "]", "=", "64", "\n", "params_model", "[", "'lr'", "]", "=", "lr", "\n", "if", "encoder_hidden_size", "==", "0", ":", "\n", "        ", "encoder_hidden_size", "=", "None", "\n", "", "if", "decoder_hidden_size", "==", "0", ":", "\n", "        ", "decoder_hidden_size", "=", "None", "\n", "", "params_model", "[", "'first_additional_triplet'", "]", "=", "first_additional_triplet", "\n", "params_model", "[", "'second_additional_triplet'", "]", "=", "second_additional_triplet", "\n", "params_model", "[", "'additional_triplets_loss'", "]", "=", "additional_triplets_loss", "\n", "params_model", "[", "'additional_dropout'", "]", "=", "additional_dropout", "\n", "params_model", "[", "'reg_loss'", "]", "=", "reg_loss", "\n", "params_model", "[", "'depth_transformer'", "]", "=", "depth_transformer", "\n", "params_model", "[", "'dropout_encoder'", "]", "=", "dropout_encoder", "\n", "params_model", "[", "'dropout_decoder'", "]", "=", "dropout_decoder", "\n", "params_model", "[", "'encoder_hidden_size'", "]", "=", "encoder_hidden_size", "\n", "params_model", "[", "'decoder_hidden_size'", "]", "=", "decoder_hidden_size", "\n", "params_model", "[", "'momentum'", "]", "=", "momentum", "\n", "return", "params_model", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.training_file": [[15, 18], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "training_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"training{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.val_file": [[19, 22], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.train_val_file": [[23, 26], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"train_val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_file": [[27, 30], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"test{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.targets": [[31, 35], ["numpy.where", "numpy.isin"], "methods", ["None"], ["", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.all_data": [[36, 45], ["numpy.where", "numpy.isin", "sorted"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_data", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "{", "\n", "\"audio\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"video\"", ":", "self", ".", "data", "[", "\"video\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"text\"", ":", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ",", "\n", "\"target\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", ",", "\n", "\"url\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"url\"", "]", "[", "classes_mask", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.map_embeddings_target": [[47, 55], ["[].cuda", "sorted", "range", "len", "int", "sorted"], "methods", ["None"], ["", "@", "property", "\n", "def", "map_embeddings_target", "(", "self", ")", ":", "\n", "        ", "w2v_embedding", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ".", "cuda", "(", ")", "\n", "sorted_classes", "=", "sorted", "(", "self", ".", "classes", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "sorted_classes", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "int", "(", "sorted_classes", "[", "i", "]", ")", "]", "=", "i", "\n", "", "return", "w2v_embedding", ",", "mapping_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.features_processed_folder": [[56, 59], ["pathlib.Path().cwd", "pathlib.Path"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_processed_folder", "(", "self", ")", ":", "\n", "        ", "return", "Path", "(", ")", ".", "cwd", "(", ")", "/", "\"avgzsl_benchmark_datasets/VGGSound/_features_processed\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.all_class_ids": [[60, 63], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "all_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.train_train_ids": [[64, 67], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "train_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.val_seen_ids": [[68, 71], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "val_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.val_unseen_ids": [[72, 75], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "val_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_train_ids": [[76, 79], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "test_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_seen_ids": [[80, 83], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "test_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_unseen_ids": [[84, 87], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "test_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.text_label_mapping": [[88, 92], ["pandas.read_csv", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "text_label_mapping", "(", "self", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "self", ".", "root", "/", "\"class-split/vggsound_w2v_class_names.csv\"", ")", "\n", "return", "{", "val", ":", "df", ".", "original", "[", "idx", "]", "for", "idx", ",", "val", "in", "enumerate", "(", "df", ".", "manual", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.classes": [[93, 107], ["numpy.sort", "numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "classes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "zero_shot_split", ":", "\n", "            ", "return", "np", ".", "sort", "(", "np", ".", "concatenate", "(", "(", "self", ".", "seen_class_ids", ",", "self", ".", "unseen_class_ids", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "zero_shot_mode", "==", "\"all\"", ":", "\n", "                ", "return", "self", ".", "all_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"seen\"", ":", "\n", "                ", "return", "self", ".", "seen_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"unseen\"", ":", "\n", "                ", "return", "self", ".", "unseen_class_ids", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "f\"Zero shot mode has to be either all, seen or unseen. Is {self.zero_shot_mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.class_to_idx": [[108, 111], ["enumerate", "sorted"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "class_to_idx", "(", "self", ")", ":", "\n", "        ", "return", "{", "_class", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "sorted", "(", "self", ".", "all_class_names", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.all_class_names": [[112, 115], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "all_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "\"class-split/all_class.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.seen_class_names": [[116, 128], ["numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "seen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "self", ".", "train_train_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_seen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "(", "self", ".", "train_train_class_names", ",", "self", ".", "val_unseen_class_names", ")", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_seen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.unseen_class_names": [[129, 141], ["numpy.array", "numpy.array", "AttributeError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "unseen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_unseen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_unseen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.seen_class_ids": [[142, 146], ["numpy.asarray"], "methods", ["None"], ["", "", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "seen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.unseen_class_ids": [[147, 151], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "unseen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.train_train_class_names": [[152, 155], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "train_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.val_seen_class_names": [[156, 159], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.val_unseen_class_names": [[160, 163], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_train_class_names": [[164, 167], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_seen_class_names": [[168, 171], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.test_unseen_class_names": [[172, 175], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.__init__": [[176, 195], ["torch.utils.data.Dataset.__init__", "logging.getLogger", "dataset.VGGSoundDataset.logger.info", "dataset.VGGSoundDataset.preprocess", "dataset.VGGSoundDataset.get_data"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.preprocess", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dataset_split", ",", "zero_shot_mode", ",", "download", "=", "False", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "VGGSoundDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Initializing Dataset {self.__class__.__name__}\\t\"", "\n", "f\"Dataset split: {dataset_split}\\t\"", "\n", "f\"Zero shot mode: {zero_shot_mode}\"", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "root", "=", "args", ".", "root_dir", "\n", "self", ".", "dataset_name", "=", "args", ".", "dataset_name", "\n", "self", ".", "feature_extraction_method", "=", "args", ".", "feature_extraction_method", "\n", "self", ".", "dataset_split", "=", "dataset_split", "\n", "self", ".", "zero_shot_mode", "=", "zero_shot_mode", "\n", "self", ".", "zero_shot_split", "=", "args", ".", "zero_shot_split", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "self", ".", "preprocess", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.__getitem__": [[196, 198], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.__len__": [[199, 201], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset._check_exists": [[202, 204], ["dataset.VGGSoundDataset.training_file.exists", "dataset.VGGSoundDataset.val_file.exists", "dataset.VGGSoundDataset.test_file.exists", "dataset.VGGSoundDataset.train_val_file.exists"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "training_file", ".", "exists", "(", ")", "and", "self", ".", "val_file", ".", "exists", "(", ")", "and", "self", ".", "test_file", ".", "exists", "(", ")", "and", "self", ".", "train_val_file", ".", "exists", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.preprocess": [[205, 237], ["dataset.VGGSoundDataset._check_exists", "dataset.VGGSoundDataset.logger.info", "dataset.VGGSoundDataset.logger.info", "dataset.VGGSoundDataset.read_dataset", "dataset.VGGSoundDataset.read_dataset", "dataset.VGGSoundDataset.read_dataset", "dataset.VGGSoundDataset.read_dataset", "dataset.VGGSoundDataset.logger.info", "dataset.VGGSoundDataset.training_file.open", "dataset.VGGSoundDataset.logger.info", "pickle.dump", "dataset.VGGSoundDataset.val_file.open", "dataset.VGGSoundDataset.logger.info", "pickle.dump", "dataset.VGGSoundDataset.train_val_file.open", "dataset.VGGSoundDataset.logger.info", "pickle.dump", "dataset.VGGSoundDataset.test_file.open", "dataset.VGGSoundDataset.logger.info", "pickle.dump", "dataset.VGGSoundDataset._check_exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "(", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Processing extracted features for faster training (only done once)...'", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Processed files will be stored locally in {(self.features_processed_folder / self.feature_extraction_method).resolve()}\"", "\n", ")", "\n", "\n", "training_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train\"", ")", "\n", "val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"val\"", ")", "\n", "train_val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train_val\"", ")", "\n", "test_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"test\"", ")", "\n", "\n", "with", "self", ".", "training_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.training_file}\"", ")", "\n", "pickle", ".", "dump", "(", "training_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "train_val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.train_val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "train_val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "test_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.test_file}\"", ")", "\n", "pickle", ".", "dump", "(", "test_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Dataset not found after preprocessing!\"", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Successfully finished preprocessing.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.get_data": [[238, 254], ["dataset.VGGSoundDataset.logger.info", "load_path.open", "pickle.load", "AttributeError"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "data_file", "=", "self", ".", "training_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "train_val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "data_file", "=", "self", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val or test.\"", ")", "\n", "\n", "", "load_path", "=", "(", "self", ".", "features_processed_folder", "/", "data_file", ")", ".", "resolve", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Loading processed data from disk from {load_path}\"", ")", "\n", "with", "load_path", ".", "open", "(", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.read_dataset": [[255, 262], ["dataset.VGGSoundDataset.get_data_by_modality", "dataset.VGGSoundDataset.get_data_by_modality", "torch.equal", "numpy.array_equal", "dataset.VGGSoundDataset.get_data_by_modality"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality"], ["", "", "def", "read_dataset", "(", "self", ",", "dataset_type", ")", ":", "\n", "        ", "result_audio", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"audio\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "result_video", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"video\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "assert", "torch", ".", "equal", "(", "result_audio", "[", "\"target\"", "]", ",", "result_video", "[", "\"target\"", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "result_audio", "[", "\"url\"", "]", ",", "result_video", "[", "\"url\"", "]", ")", "\n", "result_text", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"text\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "return", "{", "\"audio\"", ":", "result_audio", ",", "\"video\"", ":", "result_video", ",", "\"text\"", ":", "result_text", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.VGGSoundDataset.get_data_by_modality": [[263, 311], ["torch.FloatTensor", "torch.LongTensor", "numpy.array", "numpy.load().item", "dict", "list", "sorted", "dict.values", "AttributeError", "numpy.load", "numpy.load().item.items", "list", "split_names.append", "modality_path.iterdir", "tqdm.tqdm.tqdm", "dict.keys", "split_names.append", "split_names.append", "src.utils.read_features", "enumerate", "split_names.append", "split_names.append", "split_names.append", "len", "result[].append", "result[].append", "result[].append", "split_names.append", "split_names.append", "AttributeError", "list", "modality_path.glob"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "def", "get_data_by_modality", "(", "self", ",", "modality", ",", "dataset_type", "=", "\"train\"", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "        ", "result", "=", "{", "\"data\"", ":", "[", "]", ",", "\"target\"", ":", "[", "]", ",", "\"url\"", ":", "[", "]", "}", "\n", "if", "modality", "==", "\"text\"", ":", "\n", "            ", "data_raw", "=", "np", ".", "load", "(", "\n", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "\"text/word_embeddings_vggsound_normed.npy\"", ")", ".", "resolve", "(", ")", ",", "\n", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data_raw_sorted", "=", "dict", "(", "sorted", "(", "data_raw", ".", "items", "(", ")", ")", ")", "\n", "result", "[", "\"data\"", "]", "=", "list", "(", "data_raw_sorted", ".", "values", "(", ")", ")", "\n", "result", "[", "\"target\"", "]", "=", "[", "self", ".", "class_to_idx", "[", "self", ".", "text_label_mapping", "[", "key", "]", "]", "for", "key", "in", "list", "(", "data_raw_sorted", ".", "keys", "(", ")", ")", "]", "\n", "\n", "", "elif", "modality", "==", "\"audio\"", "or", "modality", "==", "\"video\"", ":", "\n", "            ", "split_names", "=", "[", "]", "\n", "if", "dataset_type", "==", "\"train\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "", "elif", "dataset_type", "==", "\"val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"train_val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"test\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_2_test_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_2_test_unseen\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "\"Dataset type incompatible. Has to be either train, val or test.\"", ")", "\n", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "                ", "modality_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "f\"{modality}/{split_name}\"", ")", ".", "resolve", "(", ")", "\n", "files", "=", "modality_path", ".", "iterdir", "(", ")", "\n", "for", "file", "in", "tqdm", "(", "files", ",", "total", "=", "len", "(", "list", "(", "modality_path", ".", "glob", "(", "'*'", ")", ")", ")", ",", "\n", "desc", "=", "f\"{dataset_type}:{modality}:{split_name}\"", ")", ":", "\n", "                    ", "data", ",", "url", "=", "read_features", "(", "file", ")", "\n", "#assert len(data[", "\n", "#               0]) == self.args.input_size, f\"Feature size {len(data[0])} is not compatible with specified --input_size {self.args.input_size}\"", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "data", ")", ":", "\n", "                        ", "result", "[", "\"data\"", "]", ".", "append", "(", "d", ")", "\n", "result", "[", "\"target\"", "]", ".", "append", "(", "self", ".", "class_to_idx", "[", "file", ".", "stem", "]", ")", "\n", "result", "[", "\"url\"", "]", ".", "append", "(", "url", "[", "i", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Modality has to be either audio, video or text\"", ")", "\n", "", "result", "[", "\"data\"", "]", "=", "torch", ".", "FloatTensor", "(", "result", "[", "\"data\"", "]", ")", "\n", "result", "[", "\"target\"", "]", "=", "torch", ".", "LongTensor", "(", "result", "[", "\"target\"", "]", ")", "\n", "result", "[", "\"url\"", "]", "=", "np", ".", "array", "(", "result", "[", "\"url\"", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.training_file": [[318, 321], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "training_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "\"training.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.val_file": [[322, 325], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "\"val.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.train_val_file": [[326, 329], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "\"trn_val.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.test_file": [[330, 333], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "\"test.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.targets": [[334, 338], ["numpy.where", "numpy.isin"], "methods", ["None"], ["", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.all_data": [[339, 348], ["numpy.where", "numpy.isin", "sorted"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_data", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "{", "\n", "\"audio\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"video\"", ":", "self", ".", "data", "[", "\"video\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"text\"", ":", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ",", "\n", "\"target\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", ",", "\n", "\"url\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"url\"", "]", "[", "classes_mask", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.features_processed_folder": [[350, 353], ["pathlib.Path().cwd", "pathlib.Path"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_processed_folder", "(", "self", ")", ":", "\n", "        ", "return", "Path", "(", ")", ".", "cwd", "(", ")", "/", "\"avgzsl_benchmark_datasets/AudioSetZSL/_features_processed\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.all_class_ids": [[354, 358], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "all_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "all_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.seen_class_ids": [[359, 363], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "seen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.unseen_class_ids": [[364, 368], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "unseen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", "]", "for", "name", "in", "self", ".", "unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.classes": [[369, 379], ["AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "classes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "zero_shot_mode", "==", "\"all\"", ":", "\n", "            ", "return", "self", ".", "all_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"seen\"", ":", "\n", "            ", "return", "self", ".", "seen_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"unseen\"", ":", "\n", "            ", "return", "self", ".", "unseen_class_ids", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "f\"Zero shot mode has to be either all, seen or unseen. Is {self.zero_shot_mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.class_to_idx": [[380, 384], ["enumerate", "sorted"], "methods", ["None"], ["", "", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "class_to_idx", "(", "self", ")", ":", "\n", "        ", "return", "{", "_class", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "sorted", "(", "self", ".", "all_class_names", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.all_class_names": [[385, 391], ["numpy.loadtxt", "sorted", "s.replace().replace", "s.replace"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_class_names", "(", "self", ")", ":", "\n", "        ", "class_path", "=", "self", ".", "root", "/", "\"class-split/all_class.txt\"", "\n", "all_classes", "=", "np", ".", "loadtxt", "(", "class_path", ",", "dtype", "=", "str", ")", "\n", "all_classes", "=", "sorted", "(", "[", "s", ".", "replace", "(", "\"\\'\"", ",", "\"\"", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "for", "s", "in", "all_classes", "]", ")", "\n", "return", "all_classes", "\n", "# return get_class_names(self.root / \"class-split/all_class.txt\")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.seen_class_names": [[393, 399], ["numpy.loadtxt", "sorted", "s.replace().replace", "s.replace"], "methods", ["None"], ["", "@", "property", "\n", "def", "seen_class_names", "(", "self", ")", ":", "\n", "        ", "class_path", "=", "self", ".", "root", "/", "\"class-split/seen_class.txt\"", "\n", "seen_classes", "=", "np", ".", "loadtxt", "(", "class_path", ",", "dtype", "=", "str", ")", "\n", "seen_classes", "=", "sorted", "(", "[", "s", ".", "replace", "(", "\"\\'\"", ",", "\"\"", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "for", "s", "in", "seen_classes", "]", ")", "\n", "return", "seen_classes", "\n", "# return get_class_names(self.root / \"class-split/seen_class.txt\")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.unseen_class_names": [[401, 407], ["numpy.loadtxt", "sorted", "s.replace().replace", "s.replace"], "methods", ["None"], ["", "@", "property", "\n", "def", "unseen_class_names", "(", "self", ")", ":", "\n", "        ", "class_path", "=", "self", ".", "root", "/", "\"class-split/unseen_class.txt\"", "\n", "unseen_classes", "=", "np", ".", "loadtxt", "(", "class_path", ",", "dtype", "=", "str", ")", "\n", "unseen_classes", "=", "sorted", "(", "[", "s", ".", "replace", "(", "\"\\'\"", ",", "\"\"", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "for", "s", "in", "unseen_classes", "]", ")", "\n", "return", "unseen_classes", "\n", "# return get_class_names(self.root / \"class-split/unseen_class.txt\")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.__init__": [[409, 427], ["torch.utils.data.Dataset.__init__", "logging.getLogger", "dataset.AudioSetZSLDataset.logger.info", "dataset.AudioSetZSLDataset.preprocess", "dataset.AudioSetZSLDataset.get_data"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.preprocess", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dataset_split", ",", "zero_shot_mode", ",", "download", "=", "False", ",", "transform", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "AudioSetZSLDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Initializing Dataset {self.__class__.__name__}\\t\"", "\n", "f\"Dataset split: {dataset_split}\\t\"", "\n", "f\"Zero shot mode: {zero_shot_mode}\"", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "root", "=", "args", ".", "root_dir", "\n", "self", ".", "dataset_name", "=", "args", ".", "dataset_name", "\n", "self", ".", "feature_extraction_method", "=", "args", ".", "feature_extraction_method", "\n", "self", ".", "dataset_split", "=", "dataset_split", "\n", "self", ".", "zero_shot_mode", "=", "zero_shot_mode", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "self", ".", "preprocess", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.__getitem__": [[428, 443], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "\n", "audio", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"data\"", "]", "[", "index", "]", "\n", "video", "=", "self", ".", "data", "[", "\"video\"", "]", "[", "\"data\"", "]", "[", "index", "]", "\n", "text", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "target", "]", "\n", "url", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"url\"", "]", "[", "index", "]", "\n", "\n", "\n", "return", "{", "\n", "\"audio\"", ":", "audio", ",", "\n", "\"video\"", ":", "video", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"url\"", ":", "url", "\n", "}", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.__len__": [[444, 446], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset._check_exists": [[447, 449], ["dataset.AudioSetZSLDataset.training_file.exists", "dataset.AudioSetZSLDataset.val_file.exists", "dataset.AudioSetZSLDataset.train_val_file.exists", "dataset.AudioSetZSLDataset.test_file.exists"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "training_file", ".", "exists", "(", ")", "and", "self", ".", "val_file", ".", "exists", "(", ")", "and", "self", ".", "train_val_file", ".", "exists", "(", ")", "and", "self", ".", "test_file", ".", "exists", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.download": [[450, 455], ["dataset.AudioSetZSLDataset.logger.info", "NotImplementedError"], "methods", ["None"], ["", "def", "download", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Downloading dataset...\"", ")", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.preprocess": [[456, 489], ["dataset.AudioSetZSLDataset._check_exists", "dataset.AudioSetZSLDataset.logger.info", "dataset.AudioSetZSLDataset.logger.info", "dataset.AudioSetZSLDataset.read_dataset", "dataset.AudioSetZSLDataset.read_dataset", "dataset.AudioSetZSLDataset.read_dataset", "dataset.AudioSetZSLDataset.read_dataset", "dataset.AudioSetZSLDataset.logger.info", "dataset.AudioSetZSLDataset.training_file.open", "dataset.AudioSetZSLDataset.logger.info", "pickle.dump", "dataset.AudioSetZSLDataset.val_file.open", "dataset.AudioSetZSLDataset.logger.info", "pickle.dump", "dataset.AudioSetZSLDataset.train_val_file.open", "dataset.AudioSetZSLDataset.logger.info", "pickle.dump", "dataset.AudioSetZSLDataset.test_file.open", "dataset.AudioSetZSLDataset.logger.info", "pickle.dump", "dataset.AudioSetZSLDataset._check_exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "(", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Processing extracted features for faster training (only done once)...'", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Processed files will be stored locally in {(self.features_processed_folder / self.feature_extraction_method).resolve()}\"", "\n", ")", "\n", "\n", "training_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"trn\"", ")", "\n", "val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"val\"", ")", "\n", "train_val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"trn_val\"", ")", "\n", "test_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"tst\"", ")", "\n", "\n", "with", "self", ".", "training_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.training_file}\"", ")", "\n", "pickle", ".", "dump", "(", "training_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "train_val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.train_val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "train_val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "test_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.test_file}\"", ")", "\n", "pickle", ".", "dump", "(", "test_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Dataset not found after preprocessing!\"", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Successfully finished preprocessing.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.get_data": [[490, 506], ["dataset.AudioSetZSLDataset.logger.info", "load_path.open", "pickle.load", "AttributeError"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "data_file", "=", "self", ".", "training_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "train_val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "data_file", "=", "self", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val or test.\"", ")", "\n", "\n", "", "load_path", "=", "(", "self", ".", "features_processed_folder", "/", "data_file", ")", ".", "resolve", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Loading processed data from disk from {load_path}\"", ")", "\n", "with", "load_path", ".", "open", "(", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.read_dataset": [[507, 514], ["dataset.AudioSetZSLDataset.get_data_by_modality", "dataset.AudioSetZSLDataset.get_data_by_modality", "torch.equal", "numpy.array_equal", "dataset.AudioSetZSLDataset.get_data_by_modality"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality"], ["", "", "def", "read_dataset", "(", "self", ",", "dataset_type", ")", ":", "\n", "        ", "result_audio", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"audio\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "result_video", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"video\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "assert", "torch", ".", "equal", "(", "result_audio", "[", "\"target\"", "]", ",", "result_video", "[", "\"target\"", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "result_audio", "[", "\"url\"", "]", ",", "result_video", "[", "\"url\"", "]", ")", "\n", "result_text", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"text\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "return", "{", "\"audio\"", ":", "result_audio", ",", "\"video\"", ":", "result_video", ",", "\"text\"", ":", "result_text", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.AudioSetZSLDataset.get_data_by_modality": [[515, 565], ["torch.FloatTensor", "torch.LongTensor", "numpy.array", "numpy.load().item", "dict", "list", "sorted", "dict.values", "AttributeError", "numpy.load", "numpy.load().item.items", "list", "split_names.append", "modality_path.iterdir", "tqdm.tqdm.tqdm", "dict.keys", "split_names.append", "src.utils.read_features", "enumerate", "split_names.append", "split_names.append", "len", "len", "result[].append", "result[].append", "result[].append", "split_names.append", "AttributeError", "list", "len", "modality_path.glob"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "def", "get_data_by_modality", "(", "self", ",", "modality", ",", "dataset_type", "=", "\"trn\"", ")", ":", "\n", "        ", "result", "=", "{", "\"data\"", ":", "[", "]", ",", "\"target\"", ":", "[", "]", ",", "\"url\"", ":", "[", "]", "}", "\n", "if", "modality", "==", "\"text\"", ":", "\n", "            ", "if", "self", ".", "args", ".", "manual_text_word2vec", ":", "\n", "                ", "file_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "\"text/word_embeddings_audiosetzsl_normed.npy\"", "\n", ")", ".", "resolve", "(", ")", "\n", "", "else", ":", "\n", "                ", "file_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "\"text/word_embeddings-dict-33.npy\"", "\n", ")", ".", "resolve", "(", ")", "\n", "\n", "", "data_raw", "=", "np", ".", "load", "(", "file_path", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data_raw_sorted", "=", "dict", "(", "sorted", "(", "data_raw", ".", "items", "(", ")", ")", ")", "\n", "result", "[", "\"data\"", "]", "=", "list", "(", "data_raw_sorted", ".", "values", "(", ")", ")", "\n", "result", "[", "\"target\"", "]", "=", "[", "self", ".", "class_to_idx", "[", "key", "]", "for", "key", "in", "list", "(", "data_raw_sorted", ".", "keys", "(", ")", ")", "]", "\n", "\n", "", "elif", "modality", "==", "\"audio\"", "or", "modality", "==", "\"video\"", ":", "\n", "            ", "split_names", "=", "[", "]", "\n", "if", "dataset_type", "==", "\"trn\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"trn\"", ")", "\n", "", "elif", "dataset_type", "==", "\"val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"val\"", ")", "\n", "", "elif", "dataset_type", "==", "\"trn_val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"trn\"", ")", "\n", "split_names", ".", "append", "(", "\"val\"", ")", "\n", "", "elif", "dataset_type", "==", "\"tst\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"tst\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "\"Dataset type incompatible. Has to be either train, val or test.\"", ")", "\n", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "                ", "modality_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "f\"{modality}/{split_name}\"", ")", ".", "resolve", "(", ")", "\n", "files", "=", "modality_path", ".", "iterdir", "(", ")", "\n", "for", "file", "in", "tqdm", "(", "files", ",", "total", "=", "len", "(", "list", "(", "modality_path", ".", "glob", "(", "'*'", ")", ")", ")", ",", "\n", "desc", "=", "f\"{dataset_type}:{modality}:{split_name}\"", ")", ":", "\n", "                    ", "data", ",", "url", "=", "read_features", "(", "file", ")", "\n", "assert", "len", "(", "data", "[", "\n", "0", "]", ")", "==", "self", ".", "args", ".", "input_size", ",", "f\"Feature size {len(data[0])} is not compatible with specified --input_size {self.args.input_size}\"", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "data", ")", ":", "\n", "                        ", "result", "[", "\"data\"", "]", ".", "append", "(", "d", ")", "\n", "result", "[", "\"target\"", "]", ".", "append", "(", "self", ".", "class_to_idx", "[", "file", ".", "stem", "]", ")", "\n", "result", "[", "\"url\"", "]", ".", "append", "(", "url", "[", "i", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Modality has to be either audio, video or text\"", ")", "\n", "", "result", "[", "\"data\"", "]", "=", "torch", ".", "FloatTensor", "(", "result", "[", "\"data\"", "]", ")", "\n", "result", "[", "\"target\"", "]", "=", "torch", ".", "LongTensor", "(", "result", "[", "\"target\"", "]", ")", "\n", "result", "[", "\"url\"", "]", "=", "np", ".", "array", "(", "result", "[", "\"url\"", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ContrastiveDataset.__init__": [[568, 608], ["torch.utils.data.Dataset.__init__", "logging.getLogger", "dataset.ContrastiveDataset.logger.info", "set", "dataset.ContrastiveDataset.targets.tolist", "set", "numpy.random.RandomState", "AttributeError", "numpy.where", "dataset.ContrastiveDataset.targets.tolist", "numpy.where", "numpy.random.RandomState.choice", "range", "len", "numpy.random.choice", "list", "set", "dataset.ContrastiveDataset.targets[].item"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "zsl_dataset", ")", ":", "\n", "        ", "super", "(", "ContrastiveDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Initializing Dataset {self.__class__.__name__}\\t\"", "\n", "f\"Based on Dataset: {zsl_dataset.__class__.__name__}\\t\"", "\n", "f\"with split: {zsl_dataset.dataset_split}\"", ")", "\n", "self", ".", "zsl_dataset", "=", "zsl_dataset", "\n", "self", ".", "dataset_split", "=", "self", ".", "zsl_dataset", ".", "dataset_split", "\n", "self", ".", "classes", "=", "self", ".", "zsl_dataset", ".", "classes", "\n", "\n", "if", "self", ".", "dataset_split", "==", "\"train\"", "or", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "zsl_dataset", ".", "targets", "\n", "self", ".", "data", "=", "self", ".", "zsl_dataset", ".", "all_data", "\n", "self", ".", "targets_set", "=", "set", "(", "self", ".", "targets", ".", "tolist", "(", ")", ")", "\n", "self", ".", "target_to_indices", "=", "{", "target", ":", "np", ".", "where", "(", "self", ".", "zsl_dataset", ".", "targets", "==", "target", ")", "[", "0", "]", "\n", "for", "target", "in", "self", ".", "targets_set", "}", "\n", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", "or", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "zsl_dataset", ".", "targets", "\n", "self", ".", "data", "=", "self", ".", "zsl_dataset", ".", "all_data", "\n", "# generate fixed pairs for testing", "\n", "self", ".", "targets_set", "=", "set", "(", "self", ".", "targets", ".", "tolist", "(", ")", ")", "\n", "self", ".", "target_to_indices", "=", "{", "target", ":", "np", ".", "where", "(", "self", ".", "zsl_dataset", ".", "targets", "==", "target", ")", "[", "0", "]", "\n", "for", "target", "in", "self", ".", "targets_set", "}", "\n", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "29", ")", "\n", "\n", "# pos_neg_pairs = [i,j] -> list of all targets i with random respective negative index j", "\n", "pos_neg_pairs", "=", "[", "[", "i", ",", "\n", "random_state", ".", "choice", "(", "self", ".", "target_to_indices", "[", "\n", "np", ".", "random", ".", "choice", "(", "\n", "list", "(", "self", ".", "targets_set", "-", "set", "(", "[", "self", ".", "targets", "[", "i", "]", ".", "item", "(", ")", "]", ")", ")", "\n", ")", "\n", "]", ")", "\n", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "targets", ")", ")", "]", "\n", "self", ".", "val_pairs", "=", "pos_neg_pairs", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val, train_val or test.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ContrastiveDataset.__len__": [[609, 612], ["len", "numpy.where", "numpy.isin"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "zsl_dataset", ".", "targets", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "len", "(", "self", ".", "zsl_dataset", ".", "targets", "[", "classes_mask", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ContrastiveDataset.__getitem__": [[613, 660], ["dataset.ContrastiveDataset.targets[].item", "list().index", "numpy.random.choice", "numpy.random.choice", "list().index", "numpy.random.choice", "list", "dataset.ContrastiveDataset.targets[].item", "list().index", "dataset.ContrastiveDataset.targets[].item", "list().index", "AttributeError", "list", "list", "set", "list", "list"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", "or", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "positive_target", "=", "self", ".", "targets", "[", "index", "]", ".", "item", "(", ")", "\n", "pos_target_index", "=", "list", "(", "self", ".", "targets_set", ")", ".", "index", "(", "positive_target", ")", "\n", "x_a1", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "index", "]", "\n", "x_v1", "=", "self", ".", "data", "[", "\"video\"", "]", "[", "index", "]", "\n", "x_t1", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "pos_target_index", "]", "\n", "x_url1", "=", "self", ".", "data", "[", "\"url\"", "]", "[", "index", "]", "\n", "# x_numeric1=self.data[\"target\"][index].item()", "\n", "positive_index", "=", "index", "\n", "while", "positive_index", "==", "index", ":", "\n", "                ", "positive_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "target_to_indices", "[", "positive_target", "]", ")", "\n", "", "negative_target", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "self", ".", "targets_set", "-", "set", "(", "[", "positive_target", "]", ")", ")", ")", "\n", "negative_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "target_to_indices", "[", "negative_target", "]", ")", "\n", "neg_target_index", "=", "list", "(", "self", ".", "targets_set", ")", ".", "index", "(", "negative_target", ")", "\n", "x_a2", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "negative_index", "]", "\n", "x_v2", "=", "self", ".", "data", "[", "\"video\"", "]", "[", "negative_index", "]", "\n", "x_t2", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "neg_target_index", "]", "\n", "x_url2", "=", "self", ".", "data", "[", "\"url\"", "]", "[", "negative_index", "]", "\n", "# x_numeric2=self.data[\"target\"][negative_index].item()", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", "or", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "positive_target", "=", "self", ".", "targets", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "0", "]", "]", ".", "item", "(", ")", "\n", "pos_target_index", "=", "list", "(", "self", ".", "targets_set", ")", ".", "index", "(", "positive_target", ")", "\n", "x_a1", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "0", "]", "]", "\n", "x_v1", "=", "self", ".", "data", "[", "\"video\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "0", "]", "]", "\n", "x_t1", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "pos_target_index", "]", "\n", "# x_numeric1=self.data[\"target\"][self.val_pairs[index][0]].item()", "\n", "x_url1", "=", "self", ".", "data", "[", "\"url\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "0", "]", "]", "\n", "negative_target", "=", "self", ".", "targets", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "1", "]", "]", ".", "item", "(", ")", "\n", "neg_target_index", "=", "list", "(", "self", ".", "targets_set", ")", ".", "index", "(", "negative_target", ")", "\n", "x_a2", "=", "self", ".", "data", "[", "\"audio\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "1", "]", "]", "\n", "x_v2", "=", "self", ".", "data", "[", "\"video\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "1", "]", "]", "\n", "x_t2", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "neg_target_index", "]", "\n", "# x_numeric2=self.data[\"target\"][self.val_pairs[index][1]].item()", "\n", "x_url2", "=", "self", ".", "data", "[", "\"url\"", "]", "[", "self", ".", "val_pairs", "[", "index", "]", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val, train_val or test.\"", ")", "\n", "\n", "", "data", "=", "{", "\n", "\"positive\"", ":", "{", "\"audio\"", ":", "x_a1", ",", "\"video\"", ":", "x_v1", ",", "\"text\"", ":", "x_t1", ",", "\"url\"", ":", "x_url1", "}", ",", "\n", "\"negative\"", ":", "{", "\"audio\"", ":", "x_a2", ",", "\"video\"", ":", "x_v2", ",", "\"text\"", ":", "x_t2", ",", "\"url\"", ":", "x_url2", "}", "\n", "}", "\n", "target", "=", "{", "\n", "\"positive\"", ":", "positive_target", ",", "\n", "\"negative\"", ":", "negative_target", "\n", "}", "\n", "return", "data", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.map_embeddings_target": [[664, 672], ["[].cuda", "sorted", "range", "len", "int", "sorted"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "map_embeddings_target", "(", "self", ")", ":", "\n", "        ", "w2v_embedding", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ".", "cuda", "(", ")", "\n", "sorted_classes", "=", "sorted", "(", "self", ".", "classes", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "sorted_classes", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "int", "(", "sorted_classes", "[", "i", "]", ")", "]", "=", "i", "\n", "", "return", "w2v_embedding", ",", "mapping_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.training_file": [[673, 676], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "training_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"training{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.val_file": [[677, 680], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.train_val_file": [[681, 684], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"train_val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_file": [[685, 688], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"test{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.targets": [[689, 693], ["numpy.where", "numpy.isin"], "methods", ["None"], ["", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.all_data": [[694, 703], ["numpy.where", "numpy.isin", "sorted"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_data", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "{", "\n", "\"audio\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"video\"", ":", "self", ".", "data", "[", "\"video\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"text\"", ":", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ",", "\n", "\"target\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", ",", "\n", "\"url\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"url\"", "]", "[", "classes_mask", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.features_processed_folder": [[705, 708], ["pathlib.Path().cwd", "pathlib.Path"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_processed_folder", "(", "self", ")", ":", "\n", "        ", "return", "Path", "(", ")", ".", "cwd", "(", ")", "/", "\"avgzsl_benchmark_datasets/UCF/_features_processed\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.all_class_ids": [[709, 712], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "all_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.train_train_ids": [[713, 716], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "train_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.val_seen_ids": [[717, 720], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "val_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.val_unseen_ids": [[721, 724], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "val_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_train_ids": [[725, 728], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_seen_ids": [[729, 732], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_unseen_ids": [[733, 736], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.text_label_mapping": [[737, 741], ["pandas.read_csv", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "text_label_mapping", "(", "self", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "self", ".", "root", "/", "\"class-split/ucf_w2v_class_names.csv\"", ")", "\n", "return", "{", "val", ":", "df", ".", "original", "[", "idx", "]", "for", "idx", ",", "val", "in", "enumerate", "(", "df", ".", "manual", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.classes": [[742, 756], ["numpy.sort", "numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "classes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "zero_shot_split", ":", "\n", "            ", "return", "np", ".", "sort", "(", "np", ".", "concatenate", "(", "(", "self", ".", "seen_class_ids", ",", "self", ".", "unseen_class_ids", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "zero_shot_mode", "==", "\"all\"", ":", "\n", "                ", "return", "self", ".", "all_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"seen\"", ":", "\n", "                ", "return", "self", ".", "seen_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"unseen\"", ":", "\n", "                ", "return", "self", ".", "unseen_class_ids", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "f\"Zero shot mode has to be either all, seen or unseen. Is {self.zero_shot_mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.class_to_idx": [[757, 760], ["_class.lower", "enumerate", "sorted"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "class_to_idx", "(", "self", ")", ":", "\n", "        ", "return", "{", "_class", ".", "lower", "(", ")", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "sorted", "(", "self", ".", "all_class_names", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.all_class_names": [[761, 764], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "all_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "\"class-split/all_class.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.seen_class_names": [[765, 777], ["numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "seen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "self", ".", "train_train_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_seen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "(", "self", ".", "train_train_class_names", ",", "self", ".", "val_unseen_class_names", ")", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_seen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.unseen_class_names": [[778, 790], ["numpy.array", "numpy.array", "AttributeError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "unseen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_unseen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_unseen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.seen_class_ids": [[791, 795], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "seen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.unseen_class_ids": [[796, 800], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "unseen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.train_train_class_names": [[801, 804], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "train_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.val_seen_class_names": [[805, 808], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.val_unseen_class_names": [[809, 812], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_train_class_names": [[813, 816], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_seen_class_names": [[817, 820], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.test_unseen_class_names": [[821, 824], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.__init__": [[825, 844], ["torch.utils.data.Dataset.__init__", "logging.getLogger", "dataset.UCFDataset.logger.info", "dataset.UCFDataset.preprocess", "dataset.UCFDataset.get_data"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.preprocess", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dataset_split", ",", "zero_shot_mode", ",", "download", "=", "False", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "UCFDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Initializing Dataset {self.__class__.__name__}\\t\"", "\n", "f\"Dataset split: {dataset_split}\\t\"", "\n", "f\"Zero shot mode: {zero_shot_mode}\"", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "root", "=", "args", ".", "root_dir", "\n", "self", ".", "dataset_name", "=", "args", ".", "dataset_name", "\n", "self", ".", "feature_extraction_method", "=", "args", ".", "feature_extraction_method", "\n", "self", ".", "dataset_split", "=", "dataset_split", "\n", "self", ".", "zero_shot_mode", "=", "zero_shot_mode", "\n", "self", ".", "zero_shot_split", "=", "args", ".", "zero_shot_split", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "self", ".", "preprocess", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.__getitem__": [[845, 847], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.__len__": [[848, 850], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset._check_exists": [[851, 853], ["dataset.UCFDataset.training_file.exists", "dataset.UCFDataset.val_file.exists", "dataset.UCFDataset.test_file.exists", "dataset.UCFDataset.train_val_file.exists"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "training_file", ".", "exists", "(", ")", "and", "self", ".", "val_file", ".", "exists", "(", ")", "and", "self", ".", "test_file", ".", "exists", "(", ")", "and", "self", ".", "train_val_file", ".", "exists", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.preprocess": [[854, 887], ["dataset.UCFDataset._check_exists", "dataset.UCFDataset.logger.info", "dataset.UCFDataset.logger.info", "dataset.UCFDataset.read_dataset", "dataset.UCFDataset.read_dataset", "dataset.UCFDataset.read_dataset", "dataset.UCFDataset.read_dataset", "dataset.UCFDataset.logger.info", "dataset.UCFDataset.training_file.open", "dataset.UCFDataset.logger.info", "pickle.dump", "dataset.UCFDataset.val_file.open", "dataset.UCFDataset.logger.info", "pickle.dump", "dataset.UCFDataset.train_val_file.open", "dataset.UCFDataset.logger.info", "pickle.dump", "dataset.UCFDataset.test_file.open", "dataset.UCFDataset.logger.info", "pickle.dump", "dataset.UCFDataset._check_exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "(", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Processing extracted features for faster training (only done once)...'", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Processed files will be stored locally in {(self.features_processed_folder / self.feature_extraction_method).resolve()}\"", "\n", ")", "\n", "\n", "training_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train\"", ")", "\n", "val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"val\"", ")", "\n", "train_val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train_val\"", ")", "\n", "test_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"test\"", ")", "\n", "\n", "with", "self", ".", "training_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.training_file}\"", ")", "\n", "pickle", ".", "dump", "(", "training_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "train_val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.train_val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "train_val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "test_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.test_file}\"", ")", "\n", "pickle", ".", "dump", "(", "test_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Dataset not found after preprocessing!\"", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Successfully finished preprocessing.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.get_data": [[888, 904], ["dataset.UCFDataset.logger.info", "load_path.open", "pickle.load", "AttributeError"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "data_file", "=", "self", ".", "training_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "train_val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "data_file", "=", "self", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val or test.\"", ")", "\n", "\n", "", "load_path", "=", "(", "self", ".", "features_processed_folder", "/", "data_file", ")", ".", "resolve", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Loading processed data from disk from {load_path}\"", ")", "\n", "with", "load_path", ".", "open", "(", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.read_dataset": [[905, 912], ["dataset.UCFDataset.get_data_by_modality", "dataset.UCFDataset.get_data_by_modality", "torch.equal", "numpy.array_equal", "dataset.UCFDataset.get_data_by_modality"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality"], ["", "", "def", "read_dataset", "(", "self", ",", "dataset_type", ")", ":", "\n", "        ", "result_audio", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"audio\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "result_video", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"video\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "assert", "torch", ".", "equal", "(", "result_audio", "[", "\"target\"", "]", ",", "result_video", "[", "\"target\"", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "result_audio", "[", "\"url\"", "]", ",", "result_video", "[", "\"url\"", "]", ")", "\n", "result_text", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"text\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "return", "{", "\"audio\"", ":", "result_audio", ",", "\"video\"", ":", "result_video", ",", "\"text\"", ":", "result_text", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.UCFDataset.get_data_by_modality": [[913, 962], ["torch.FloatTensor", "torch.LongTensor", "numpy.array", "numpy.load().item", "dict", "list", "sorted", "dict.values", "AttributeError", "numpy.load", "numpy.load().item.items", "list", "split_names.append", "modality_path.iterdir", "tqdm.tqdm.tqdm", "dataset.UCFDataset.text_label_mapping[].lower", "dict.keys", "split_names.append", "split_names.append", "src.utils.read_features", "enumerate", "split_names.append", "split_names.append", "split_names.append", "len", "result[].append", "result[].append", "result[].append", "split_names.append", "split_names.append", "AttributeError", "list", "modality_path.glob", "file.stem.lower"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "def", "get_data_by_modality", "(", "self", ",", "modality", ",", "dataset_type", "=", "\"train\"", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "        ", "result", "=", "{", "\"data\"", ":", "[", "]", ",", "\"target\"", ":", "[", "]", ",", "\"url\"", ":", "[", "]", "}", "\n", "if", "modality", "==", "\"text\"", ":", "\n", "            ", "data_raw", "=", "np", ".", "load", "(", "\n", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "\"text/word_embeddings_ucf_normed.npy\"", ")", ".", "resolve", "(", ")", ",", "\n", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data_raw_sorted", "=", "dict", "(", "sorted", "(", "data_raw", ".", "items", "(", ")", ")", ")", "\n", "result", "[", "\"data\"", "]", "=", "list", "(", "data_raw_sorted", ".", "values", "(", ")", ")", "\n", "result", "[", "\"target\"", "]", "=", "[", "self", ".", "class_to_idx", "[", "self", ".", "text_label_mapping", "[", "key", "]", ".", "lower", "(", ")", "]", "for", "key", "in", "\n", "list", "(", "data_raw_sorted", ".", "keys", "(", ")", ")", "]", "\n", "\n", "", "elif", "modality", "==", "\"audio\"", "or", "modality", "==", "\"video\"", ":", "\n", "            ", "split_names", "=", "[", "]", "\n", "if", "dataset_type", "==", "\"train\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "", "elif", "dataset_type", "==", "\"val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"train_val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"test\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_2_test_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_2_test_unseen\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "\"Dataset type incompatible. Has to be either train, val or test.\"", ")", "\n", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "                ", "modality_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "f\"{modality}/{split_name}\"", ")", ".", "resolve", "(", ")", "\n", "files", "=", "modality_path", ".", "iterdir", "(", ")", "\n", "for", "file", "in", "tqdm", "(", "files", ",", "total", "=", "len", "(", "list", "(", "modality_path", ".", "glob", "(", "'*'", ")", ")", ")", ",", "\n", "desc", "=", "f\"{dataset_type}:{modality}:{split_name}\"", ")", ":", "\n", "                    ", "data", ",", "url", "=", "read_features", "(", "file", ")", "\n", "#assert len(data[", "\n", "#               0]) == self.args.input_size, f\"Feature size {len(data[0])} is not compatible with specified --input_size {self.args.input_size}\"", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "data", ")", ":", "\n", "                        ", "result", "[", "\"data\"", "]", ".", "append", "(", "d", ")", "\n", "result", "[", "\"target\"", "]", ".", "append", "(", "self", ".", "class_to_idx", "[", "file", ".", "stem", ".", "lower", "(", ")", "]", ")", "\n", "result", "[", "\"url\"", "]", ".", "append", "(", "url", "[", "i", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Modality has to be either audio, video or text\"", ")", "\n", "", "result", "[", "\"data\"", "]", "=", "torch", ".", "FloatTensor", "(", "result", "[", "\"data\"", "]", ")", "\n", "result", "[", "\"target\"", "]", "=", "torch", ".", "LongTensor", "(", "result", "[", "\"target\"", "]", ")", "\n", "result", "[", "\"url\"", "]", "=", "np", ".", "array", "(", "result", "[", "\"url\"", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.map_embeddings_target": [[966, 974], ["[].cuda", "sorted", "range", "len", "int", "sorted"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "map_embeddings_target", "(", "self", ")", ":", "\n", "        ", "w2v_embedding", "=", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ".", "cuda", "(", ")", "\n", "sorted_classes", "=", "sorted", "(", "self", ".", "classes", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "sorted_classes", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "int", "(", "sorted_classes", "[", "i", "]", ")", "]", "=", "i", "\n", "", "return", "w2v_embedding", ",", "mapping_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.training_file": [[975, 978], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "training_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"training{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.val_file": [[979, 982], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.train_val_file": [[983, 986], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_val_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"train_val{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_file": [[987, 990], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_file", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", "/", "f\"test{self.zero_shot_split}.pkl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.targets": [[991, 995], ["numpy.where", "numpy.isin"], "methods", ["None"], ["", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.all_data": [[996, 1005], ["numpy.where", "numpy.isin", "sorted"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_data", "(", "self", ")", ":", "\n", "        ", "classes_mask", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", ",", "self", ".", "classes", ")", ")", "[", "0", "]", "\n", "return", "{", "\n", "\"audio\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"video\"", ":", "self", ".", "data", "[", "\"video\"", "]", "[", "\"data\"", "]", "[", "classes_mask", "]", ",", "\n", "\"text\"", ":", "self", ".", "data", "[", "\"text\"", "]", "[", "\"data\"", "]", "[", "sorted", "(", "self", ".", "classes", ")", "]", ",", "\n", "\"target\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"target\"", "]", "[", "classes_mask", "]", ",", "\n", "\"url\"", ":", "self", ".", "data", "[", "\"audio\"", "]", "[", "\"url\"", "]", "[", "classes_mask", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.features_processed_folder": [[1007, 1010], ["pathlib.Path().cwd", "pathlib.Path"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_processed_folder", "(", "self", ")", ":", "\n", "        ", "return", "Path", "(", ")", ".", "cwd", "(", ")", "/", "\"avgzsl_benchmark_datasets/ActivityNet/_features_processed\"", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.all_class_ids": [[1011, 1014], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "all_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.train_train_ids": [[1015, 1018], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "train_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.val_seen_ids": [[1019, 1022], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "val_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.val_unseen_ids": [[1023, 1026], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "val_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_train_ids": [[1027, 1030], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_train_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_train_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_seen_ids": [[1031, 1034], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_seen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_unseen_ids": [[1035, 1038], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_unseen_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "test_unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.text_label_mapping": [[1039, 1043], ["pandas.read_csv", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "text_label_mapping", "(", "self", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "self", ".", "root", "/", "\"class-split/activitynet_w2v_class_names.csv\"", ")", "\n", "return", "{", "val", ":", "df", ".", "original", "[", "idx", "]", "for", "idx", ",", "val", "in", "enumerate", "(", "df", ".", "manual", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.classes": [[1044, 1058], ["numpy.sort", "numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "classes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "zero_shot_split", ":", "\n", "            ", "return", "np", ".", "sort", "(", "np", ".", "concatenate", "(", "(", "self", ".", "seen_class_ids", ",", "self", ".", "unseen_class_ids", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "zero_shot_mode", "==", "\"all\"", ":", "\n", "                ", "return", "self", ".", "all_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"seen\"", ":", "\n", "                ", "return", "self", ".", "seen_class_ids", "\n", "", "elif", "self", ".", "zero_shot_mode", "==", "\"unseen\"", ":", "\n", "                ", "return", "self", ".", "unseen_class_ids", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "f\"Zero shot mode has to be either all, seen or unseen. Is {self.zero_shot_mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.class_to_idx": [[1059, 1062], ["_class.lower", "enumerate", "sorted"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "class_to_idx", "(", "self", ")", ":", "\n", "        ", "return", "{", "_class", ".", "lower", "(", ")", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "sorted", "(", "self", ".", "all_class_names", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.all_class_names": [[1063, 1066], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "all_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "\"class-split/all_class.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.seen_class_names": [[1067, 1079], ["numpy.concatenate", "AttributeError"], "methods", ["None"], ["", "@", "property", "\n", "def", "seen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "self", ".", "train_train_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_seen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "(", "self", ".", "train_train_class_names", ",", "self", ".", "val_unseen_class_names", ")", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_seen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.unseen_class_names": [[1080, 1092], ["numpy.array", "numpy.array", "AttributeError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "unseen_class_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_unseen_class_names", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_unseen_class_names", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset split has to be in {train,val,train_val,test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.seen_class_ids": [[1093, 1097], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "seen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "seen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.unseen_class_ids": [[1098, 1102], ["numpy.asarray", "name.lower"], "methods", ["None"], ["", "@", "property", "\n", "# @lru_cache(maxsize=128)", "\n", "def", "unseen_class_ids", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "[", "self", ".", "class_to_idx", "[", "name", ".", "lower", "(", ")", "]", "for", "name", "in", "self", ".", "unseen_class_names", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.train_train_class_names": [[1103, 1106], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "train_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.val_seen_class_names": [[1107, 1110], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.val_unseen_class_names": [[1111, 1114], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "val_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_1_val_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_train_class_names": [[1115, 1118], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_train_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_train.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_seen_class_names": [[1119, 1122], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_seen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_seen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.test_unseen_class_names": [[1123, 1126], ["src.utils.get_class_names"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names"], ["", "@", "property", "\n", "def", "test_unseen_class_names", "(", "self", ")", ":", "\n", "        ", "return", "get_class_names", "(", "self", ".", "root", "/", "f\"class-split/{self.zero_shot_split}/stage_2_test_unseen.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.__init__": [[1127, 1146], ["torch.utils.data.Dataset.__init__", "logging.getLogger", "dataset.ActivityNetDataset.logger.info", "dataset.ActivityNetDataset.preprocess", "dataset.ActivityNetDataset.get_data"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.preprocess", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dataset_split", ",", "zero_shot_mode", ",", "download", "=", "False", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "ActivityNetDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Initializing Dataset {self.__class__.__name__}\\t\"", "\n", "f\"Dataset split: {dataset_split}\\t\"", "\n", "f\"Zero shot mode: {zero_shot_mode}\"", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "root", "=", "args", ".", "root_dir", "\n", "self", ".", "dataset_name", "=", "args", ".", "dataset_name", "\n", "self", ".", "feature_extraction_method", "=", "args", ".", "feature_extraction_method", "\n", "self", ".", "dataset_split", "=", "dataset_split", "\n", "self", ".", "zero_shot_mode", "=", "zero_shot_mode", "\n", "self", ".", "zero_shot_split", "=", "args", ".", "zero_shot_split", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "self", ".", "preprocess", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.__getitem__": [[1147, 1149], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.__len__": [[1150, 1152], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists": [[1153, 1155], ["dataset.ActivityNetDataset.training_file.exists", "dataset.ActivityNetDataset.val_file.exists", "dataset.ActivityNetDataset.test_file.exists", "dataset.ActivityNetDataset.train_val_file.exists"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "training_file", ".", "exists", "(", ")", "and", "self", ".", "val_file", ".", "exists", "(", ")", "and", "self", ".", "test_file", ".", "exists", "(", ")", "and", "self", ".", "train_val_file", ".", "exists", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.preprocess": [[1156, 1188], ["dataset.ActivityNetDataset._check_exists", "dataset.ActivityNetDataset.logger.info", "dataset.ActivityNetDataset.logger.info", "dataset.ActivityNetDataset.read_dataset", "dataset.ActivityNetDataset.read_dataset", "dataset.ActivityNetDataset.read_dataset", "dataset.ActivityNetDataset.read_dataset", "dataset.ActivityNetDataset.logger.info", "dataset.ActivityNetDataset.training_file.open", "dataset.ActivityNetDataset.logger.info", "pickle.dump", "dataset.ActivityNetDataset.val_file.open", "dataset.ActivityNetDataset.logger.info", "pickle.dump", "dataset.ActivityNetDataset.train_val_file.open", "dataset.ActivityNetDataset.logger.info", "pickle.dump", "dataset.ActivityNetDataset.test_file.open", "dataset.ActivityNetDataset.logger.info", "pickle.dump", "dataset.ActivityNetDataset._check_exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset._check_exists"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "(", "self", ".", "features_processed_folder", "/", "self", ".", "feature_extraction_method", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Processing extracted features for faster training (only done once)...'", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"Processed files will be stored locally in {(self.features_processed_folder / self.feature_extraction_method).resolve()}\"", "\n", ")", "\n", "\n", "training_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train\"", ")", "\n", "val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"val\"", ")", "\n", "train_val_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"train_val\"", ")", "\n", "test_set", "=", "self", ".", "read_dataset", "(", "dataset_type", "=", "\"test\"", ")", "\n", "\n", "with", "self", ".", "training_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.training_file}\"", ")", "\n", "pickle", ".", "dump", "(", "training_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "train_val_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.train_val_file}\"", ")", "\n", "pickle", ".", "dump", "(", "train_val_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "with", "self", ".", "test_file", ".", "open", "(", "'wb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Dumping to {self.test_file}\"", ")", "\n", "pickle", ".", "dump", "(", "test_set", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Dataset not found after preprocessing!\"", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Successfully finished preprocessing.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data": [[1189, 1205], ["dataset.ActivityNetDataset.logger.info", "load_path.open", "pickle.load", "AttributeError"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_split", "==", "\"train\"", ":", "\n", "            ", "data_file", "=", "self", ".", "training_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"train_val\"", ":", "\n", "            ", "data_file", "=", "self", ".", "train_val_file", "\n", "", "elif", "self", ".", "dataset_split", "==", "\"test\"", ":", "\n", "            ", "data_file", "=", "self", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset_split has to be either train, val or test.\"", ")", "\n", "\n", "", "load_path", "=", "(", "self", ".", "features_processed_folder", "/", "data_file", ")", ".", "resolve", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Loading processed data from disk from {load_path}\"", ")", "\n", "with", "load_path", ".", "open", "(", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.read_dataset": [[1206, 1213], ["dataset.ActivityNetDataset.get_data_by_modality", "dataset.ActivityNetDataset.get_data_by_modality", "torch.equal", "numpy.array_equal", "dataset.ActivityNetDataset.get_data_by_modality"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality"], ["", "", "def", "read_dataset", "(", "self", ",", "dataset_type", ")", ":", "\n", "        ", "result_audio", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"audio\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "result_video", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"video\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "assert", "torch", ".", "equal", "(", "result_audio", "[", "\"target\"", "]", ",", "result_video", "[", "\"target\"", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "result_audio", "[", "\"url\"", "]", ",", "result_video", "[", "\"url\"", "]", ")", "\n", "result_text", "=", "self", ".", "get_data_by_modality", "(", "modality", "=", "\"text\"", ",", "dataset_type", "=", "dataset_type", ")", "\n", "return", "{", "\"audio\"", ":", "result_audio", ",", "\"video\"", ":", "result_video", ",", "\"text\"", ":", "result_text", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.dataset.ActivityNetDataset.get_data_by_modality": [[1214, 1263], ["torch.FloatTensor", "torch.LongTensor", "numpy.array", "numpy.load().item", "dict", "list", "sorted", "dict.values", "AttributeError", "numpy.load", "numpy.load().item.items", "list", "split_names.append", "modality_path.iterdir", "tqdm.tqdm.tqdm", "dataset.ActivityNetDataset.text_label_mapping[].lower", "dict.keys", "split_names.append", "split_names.append", "src.utils.read_features", "enumerate", "split_names.append", "split_names.append", "split_names.append", "len", "result[].append", "result[].append", "result[].append", "split_names.append", "split_names.append", "AttributeError", "list", "modality_path.glob", "file.stem.lower"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "def", "get_data_by_modality", "(", "self", ",", "modality", ",", "dataset_type", "=", "\"train\"", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "        ", "result", "=", "{", "\"data\"", ":", "[", "]", ",", "\"target\"", ":", "[", "]", ",", "\"url\"", ":", "[", "]", "}", "\n", "if", "modality", "==", "\"text\"", ":", "\n", "            ", "data_raw", "=", "np", ".", "load", "(", "\n", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "\"text/word_embeddings_activity_normed.npy\"", ")", ".", "resolve", "(", ")", ",", "\n", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data_raw_sorted", "=", "dict", "(", "sorted", "(", "data_raw", ".", "items", "(", ")", ")", ")", "\n", "result", "[", "\"data\"", "]", "=", "list", "(", "data_raw_sorted", ".", "values", "(", ")", ")", "\n", "result", "[", "\"target\"", "]", "=", "[", "self", ".", "class_to_idx", "[", "self", ".", "text_label_mapping", "[", "key", "]", ".", "lower", "(", ")", "]", "for", "key", "in", "\n", "list", "(", "data_raw_sorted", ".", "keys", "(", ")", ")", "]", "\n", "\n", "", "elif", "modality", "==", "\"audio\"", "or", "modality", "==", "\"video\"", ":", "\n", "            ", "split_names", "=", "[", "]", "\n", "if", "dataset_type", "==", "\"train\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "", "elif", "dataset_type", "==", "\"val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"train_val\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_1_train\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_1_val_unseen\"", ")", "\n", "", "elif", "dataset_type", "==", "\"test\"", ":", "\n", "                ", "split_names", ".", "append", "(", "\"stage_2_test_seen\"", ")", "\n", "split_names", ".", "append", "(", "\"stage_2_test_unseen\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AttributeError", "(", "\"Dataset type incompatible. Has to be either train, val or test.\"", ")", "\n", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "                ", "modality_path", "=", "(", "\n", "self", ".", "root", "/", "\"features\"", "/", "self", ".", "feature_extraction_method", "/", "f\"{modality}/{split_name}\"", ")", ".", "resolve", "(", ")", "\n", "files", "=", "modality_path", ".", "iterdir", "(", ")", "\n", "for", "file", "in", "tqdm", "(", "files", ",", "total", "=", "len", "(", "list", "(", "modality_path", ".", "glob", "(", "'*'", ")", ")", ")", ",", "\n", "desc", "=", "f\"{dataset_type}:{modality}:{split_name}\"", ")", ":", "\n", "                    ", "data", ",", "url", "=", "read_features", "(", "file", ")", "\n", "#assert len(data[", "\n", "#               0]) == self.args.input_size, f\"Feature size {len(data[0])} is not compatible with specified --input_size {self.args.input_size}\"", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "data", ")", ":", "\n", "                        ", "result", "[", "\"data\"", "]", ".", "append", "(", "d", ")", "\n", "result", "[", "\"target\"", "]", ".", "append", "(", "self", ".", "class_to_idx", "[", "file", ".", "stem", ".", "lower", "(", ")", "]", ")", "\n", "result", "[", "\"url\"", "]", ".", "append", "(", "url", "[", "i", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Modality has to be either audio, video or text\"", ")", "\n", "", "result", "[", "\"data\"", "]", "=", "torch", ".", "FloatTensor", "(", "result", "[", "\"data\"", "]", ")", "\n", "result", "[", "\"target\"", "]", "=", "torch", ".", "LongTensor", "(", "result", "[", "\"target\"", "]", ")", "\n", "result", "[", "\"url\"", "]", "=", "np", ".", "array", "(", "result", "[", "\"url\"", "]", ")", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.__init__": [[11, 13], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "logger", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.get": [[14, 45], ["Exception", "sampler.SamplerFactory.random", "sampler.SamplerFactory.fixed"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.random", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.fixed"], ["", "def", "get", "(", "self", ",", "class_idxs", ",", "batch_size", ",", "n_batches", ",", "alpha", ",", "kind", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        class_idxs : 2D list of ints\n            List of sample indices for each class. Eg. [[0, 1], [2, 3]] implies indices 0, 1\n            belong to class 0, and indices 2, 3 belong to class 1.\n\n        batch_size : int\n            The batch size to use.\n\n        n_batches : int\n            The number of batches per epoch.\n\n        alpha : numeric in range [0, 1]\n            Weighting term used to determine weights of each class in each batch.\n            When `alpha` == 0, the batch class distribution will approximate the training population\n            class distribution.\n            When `alpha` == 1, the batch class distribution will approximate a uniform distribution,\n            with equal number of samples from each class.\n\n        kind : str ['fixed' | 'random']\n            The kind of sampler. `Fixed` will ensure each batch contains a constant proportion of\n            samples from each class. `Random` will simply sample with replacement according to the\n            calculated weights.\n        \"\"\"", "\n", "if", "kind", "==", "'random'", ":", "\n", "            ", "return", "self", ".", "random", "(", "class_idxs", ",", "batch_size", ",", "n_batches", ",", "alpha", ")", "\n", "", "if", "kind", "==", "'fixed'", ":", "\n", "            ", "return", "self", ".", "fixed", "(", "class_idxs", ",", "batch_size", ",", "n_batches", ",", "alpha", ")", "\n", "", "raise", "Exception", "(", "f'Received kind {kind}, must be `random` or `fixed`'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.random": [[46, 51], ["sampler.SamplerFactory.logger.info", "sampler.SamplerFactory._weight_classes", "sampler.SamplerFactory._sample_rates", "sampler.WeightedRandomBatchSampler"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._weight_classes", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._sample_rates"], ["", "def", "random", "(", "self", ",", "class_idxs", ",", "batch_size", ",", "n_batches", ",", "alpha", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "f'Creating WeightedRandomBatchSampler...'", ")", "\n", "class_sizes", ",", "weights", "=", "self", ".", "_weight_classes", "(", "class_idxs", ",", "alpha", ")", "\n", "sample_rates", "=", "self", ".", "_sample_rates", "(", "weights", ",", "class_sizes", ")", "\n", "return", "WeightedRandomBatchSampler", "(", "sample_rates", ",", "class_idxs", ",", "batch_size", ",", "n_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory.fixed": [[52, 57], ["sampler.SamplerFactory.logger.info", "sampler.SamplerFactory._weight_classes", "sampler.SamplerFactory._fix_batches", "sampler.WeightedFixedBatchSampler"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._weight_classes", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._fix_batches"], ["", "def", "fixed", "(", "self", ",", "class_idxs", ",", "batch_size", ",", "n_batches", ",", "alpha", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "f'Creating WeightedFixedBatchSampler...'", ")", "\n", "class_sizes", ",", "weights", "=", "self", ".", "_weight_classes", "(", "class_idxs", ",", "alpha", ")", "\n", "class_samples_per_batch", "=", "self", ".", "_fix_batches", "(", "weights", ",", "class_sizes", ",", "batch_size", ",", "n_batches", ")", "\n", "return", "WeightedFixedBatchSampler", "(", "class_samples_per_batch", ",", "class_idxs", ",", "n_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._weight_classes": [[58, 71], ["numpy.asarray", "numpy.asarray.sum", "len", "numpy.asarray", "numpy.repeat", "sampler.SamplerFactory.logger.info", "sampler.SamplerFactory.logger.info", "sampler.SamplerFactory._balance_weights", "len"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._balance_weights"], ["", "def", "_weight_classes", "(", "self", ",", "class_idxs", ",", "alpha", ")", ":", "\n", "        ", "class_sizes", "=", "np", ".", "asarray", "(", "[", "len", "(", "idxs", ")", "for", "idxs", "in", "class_idxs", "]", ")", "\n", "n_samples", "=", "class_sizes", ".", "sum", "(", ")", "\n", "n_classes", "=", "len", "(", "class_idxs", ")", "\n", "\n", "original_weights", "=", "np", ".", "asarray", "(", "[", "size", "/", "n_samples", "for", "size", "in", "class_sizes", "]", ")", "\n", "uniform_weights", "=", "np", ".", "repeat", "(", "1", "/", "n_classes", ",", "n_classes", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "f'Sample population absolute class sizes: {class_sizes}'", ")", "\n", "self", ".", "logger", ".", "info", "(", "f'Sample population relative class sizes: {original_weights}'", ")", "\n", "\n", "weights", "=", "self", ".", "_balance_weights", "(", "uniform_weights", ",", "original_weights", ",", "alpha", ")", "\n", "return", "class_sizes", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._balance_weights": [[72, 78], ["sampler.SamplerFactory.logger.info"], "methods", ["None"], ["", "def", "_balance_weights", "(", "self", ",", "weight_a", ",", "weight_b", ",", "alpha", ")", ":", "\n", "        ", "assert", "alpha", ">=", "0", "and", "alpha", "<=", "1", ",", "f'invalid alpha {alpha}, must be 0 <= alpha <= 1'", "\n", "beta", "=", "1", "-", "alpha", "\n", "weights", "=", "(", "alpha", "*", "weight_a", ")", "+", "(", "beta", "*", "weight_b", ")", "\n", "self", ".", "logger", ".", "info", "(", "f'Target batch class distribution {weights} using alpha={alpha}'", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._sample_rates": [[79, 81], ["None"], "methods", ["None"], ["", "def", "_sample_rates", "(", "self", ",", "weights", ",", "class_sizes", ")", ":", "\n", "        ", "return", "weights", "/", "class_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.SamplerFactory._fix_batches": [[82, 108], ["numpy.round().astype", "numpy.argmax", "sampler.SamplerFactory.logger.info", "sampler.SamplerFactory.logger.info", "sampler.SamplerFactory.logger.info", "numpy.round().astype.sum", "numpy.round().astype.sum", "numpy.round"], "methods", ["None"], ["", "def", "_fix_batches", "(", "self", ",", "weights", ",", "class_sizes", ",", "batch_size", ",", "n_batches", ")", ":", "\n", "        ", "\"\"\"\n        Calculates the number of samples of each class to include in each batch, and the number\n        of batches required to use all the data in an epoch.\n        \"\"\"", "\n", "class_samples_per_batch", "=", "np", ".", "round", "(", "(", "weights", "*", "batch_size", ")", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# cleanup rounding edge-cases", "\n", "remainder", "=", "batch_size", "-", "class_samples_per_batch", ".", "sum", "(", ")", "\n", "largest_class", "=", "np", ".", "argmax", "(", "class_samples_per_batch", ")", "\n", "class_samples_per_batch", "[", "largest_class", "]", "+=", "remainder", "\n", "\n", "assert", "class_samples_per_batch", ".", "sum", "(", ")", "==", "batch_size", "\n", "\n", "proportions_of_class_per_batch", "=", "class_samples_per_batch", "/", "batch_size", "\n", "self", ".", "logger", ".", "info", "(", "f'Rounded batch class distribution {proportions_of_class_per_batch}'", ")", "\n", "\n", "proportions_of_samples_per_batch", "=", "class_samples_per_batch", "/", "class_sizes", "\n", "\n", "self", ".", "logger", ".", "info", "(", "f'Expecting {class_samples_per_batch} samples of each class per batch, '", "\n", "f'over {n_batches} batches of size {batch_size}'", ")", "\n", "\n", "oversample_rates", "=", "proportions_of_samples_per_batch", "*", "n_batches", "\n", "self", ".", "logger", ".", "info", "(", "f'Sampling rates: {oversample_rates}'", ")", "\n", "\n", "return", "class_samples_per_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedRandomBatchSampler.__init__": [[129, 140], ["enumerate", "torch.utils.data.sampler.WeightedRandomSampler", "sampler.WeightedRandomBatchSampler.sample_idxs.extend", "sample_weights.extend", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "class_weights", ",", "class_idxs", ",", "batch_size", ",", "n_batches", ")", ":", "\n", "        ", "self", ".", "sample_idxs", "=", "[", "]", "\n", "for", "idxs", "in", "class_idxs", ":", "\n", "            ", "self", ".", "sample_idxs", ".", "extend", "(", "idxs", ")", "\n", "\n", "", "sample_weights", "=", "[", "]", "\n", "for", "c", ",", "weight", "in", "enumerate", "(", "class_weights", ")", ":", "\n", "            ", "sample_weights", ".", "extend", "(", "[", "weight", "]", "*", "len", "(", "class_idxs", "[", "c", "]", ")", ")", "\n", "\n", "", "self", ".", "sampler", "=", "WeightedRandomSampler", "(", "sample_weights", ",", "batch_size", ",", "replacement", "=", "True", ")", "\n", "self", ".", "n_batches", "=", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedRandomBatchSampler.__iter__": [[141, 147], ["range", "selected.append"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "bidx", "in", "range", "(", "self", ".", "n_batches", ")", ":", "\n", "            ", "selected", "=", "[", "]", "\n", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "                ", "selected", ".", "append", "(", "self", ".", "sample_idxs", "[", "idx", "]", ")", "\n", "", "yield", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedRandomBatchSampler.__len__": [[148, 150], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedFixedBatchSampler.__init__": [[170, 180], ["len", "sampler.WeightedFixedBatchSampler.class_samples_per_batch.sum", "isinstance", "sampler.CircularList", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "class_samples_per_batch", ",", "class_idxs", ",", "n_batches", ")", ":", "\n", "        ", "self", ".", "class_samples_per_batch", "=", "class_samples_per_batch", "\n", "self", ".", "class_idxs", "=", "[", "CircularList", "(", "idx", ")", "for", "idx", "in", "class_idxs", "]", "\n", "self", ".", "n_batches", "=", "n_batches", "\n", "\n", "self", ".", "n_classes", "=", "len", "(", "self", ".", "class_samples_per_batch", ")", "\n", "self", ".", "batch_size", "=", "self", ".", "class_samples_per_batch", ".", "sum", "(", ")", "\n", "\n", "assert", "len", "(", "self", ".", "class_samples_per_batch", ")", "==", "len", "(", "self", ".", "class_idxs", ")", "\n", "assert", "isinstance", "(", "self", ".", "n_batches", ",", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedFixedBatchSampler._get_batch": [[181, 187], ["enumerate", "numpy.random.shuffle", "selected.extend"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle"], ["", "def", "_get_batch", "(", "self", ",", "start_idxs", ")", ":", "\n", "        ", "selected", "=", "[", "]", "\n", "for", "c", ",", "size", "in", "enumerate", "(", "self", ".", "class_samples_per_batch", ")", ":", "\n", "            ", "selected", ".", "extend", "(", "self", ".", "class_idxs", "[", "c", "]", "[", "start_idxs", "[", "c", "]", ":", "start_idxs", "[", "c", "]", "+", "size", "]", ")", "\n", "", "np", ".", "random", ".", "shuffle", "(", "selected", ")", "\n", "return", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedFixedBatchSampler.__iter__": [[188, 194], ["numpy.zeros", "range", "cidx.shuffle", "sampler.WeightedFixedBatchSampler._get_batch"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedFixedBatchSampler._get_batch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "[", "cidx", ".", "shuffle", "(", ")", "for", "cidx", "in", "self", ".", "class_idxs", "]", "\n", "start_idxs", "=", "np", ".", "zeros", "(", "self", ".", "n_classes", ",", "dtype", "=", "int", ")", "\n", "for", "bidx", "in", "range", "(", "self", ".", "n_batches", ")", ":", "\n", "            ", "yield", "self", ".", "_get_batch", "(", "start_idxs", ")", "\n", "start_idxs", "+=", "self", ".", "class_samples_per_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.WeightedFixedBatchSampler.__len__": [[195, 197], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.__init__": [[204, 208], ["len", "sampler.CircularList.shuffle"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle"], ["def", "__init__", "(", "self", ",", "items", ")", ":", "\n", "        ", "self", ".", "_items", "=", "items", "\n", "self", ".", "_mod", "=", "len", "(", "self", ".", "_items", ")", "\n", "self", ".", "shuffle", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle": [[209, 211], ["numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.__getitem__": [[212, 216], ["isinstance", "range"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "isinstance", "(", "key", ",", "slice", ")", ":", "\n", "            ", "return", "[", "self", "[", "i", "]", "for", "i", "in", "range", "(", "key", ".", "start", ",", "key", ".", "stop", ")", "]", "\n", "", "return", "self", ".", "_items", "[", "key", "%", "self", ".", "_mod", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CJMELoss.__init__": [[6, 14], ["torch.nn.Module.__init__", "loss.CompositeCJMETripletLoss", "torch.nn.Softmax", "torch.nn.MSELoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "CJMELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "composite_triplet_loss", "=", "CompositeCJMETripletLoss", "(", "self", ".", "margin", ",", "self", ".", "distance_fn", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "epsilon", "=", "0.1", "\n", "self", ".", "loss_mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CJMELoss.forward": [[15, 38], ["loss.CJMELoss.softmax", "loss.CJMELoss.softmax", "torch.distributions.Categorical().entropy", "torch.distributions.Categorical().entropy", "torch.ones", "loss.CJMELoss.loss_mse", "loss.CJMELoss.composite_triplet_loss", "loss.CJMELoss.loss_mse", "ct_loss.mean.mean.mean", "torch.matmul", "torch.matmul", "torch.distributions.Categorical().entropy.size", "attention_weights.cuda", "torch.ones.unsqueeze().cuda", "a1.detach", "embeddings.t().detach", "v1.detach", "embeddings.t().detach", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.ones.unsqueeze", "embeddings.t", "embeddings.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ",", "attention_weights", ",", "threshold_attention", ",", "embeddings", ")", ":", "\n", "        ", "logits_audio", "=", "self", ".", "softmax", "(", "torch", ".", "matmul", "(", "a1", ".", "detach", "(", ")", ",", "embeddings", ".", "t", "(", ")", ".", "detach", "(", ")", ")", ")", "\n", "logits_video", "=", "self", ".", "softmax", "(", "torch", ".", "matmul", "(", "v1", ".", "detach", "(", ")", ",", "embeddings", ".", "t", "(", ")", ".", "detach", "(", ")", ")", ")", "\n", "entropy_audio", "=", "torch", ".", "distributions", ".", "Categorical", "(", "logits_audio", ")", ".", "entropy", "(", ")", "\n", "entropy_video", "=", "torch", ".", "distributions", ".", "Categorical", "(", "logits_video", ")", ".", "entropy", "(", ")", "\n", "entropy_resultant_video", "=", "entropy_video", "-", "entropy_audio", "-", "self", ".", "epsilon", "\n", "entropy_resultant_audio", "=", "entropy_audio", "-", "entropy_video", "-", "self", ".", "epsilon", "\n", "\n", "indices_entropy_resultant_video", "=", "entropy_resultant_video", ">", "0", "\n", "indices_entropy_resultant_audio", "=", "entropy_resultant_audio", ">", "0", "\n", "indices_neutral_audio", "=", "entropy_resultant_audio", "<=", "0", "\n", "indices_neutral_video", "=", "entropy_resultant_video", "<=", "0", "\n", "indices_neutral", "=", "indices_neutral_video", "==", "indices_neutral_audio", "\n", "supervision_attention", "=", "torch", ".", "ones", "(", "entropy_video", ".", "size", "(", ")", ")", "\n", "supervision_attention", "[", "indices_entropy_resultant_video", "]", "=", "0", "\n", "supervision_attention", "[", "indices_neutral", "]", "=", "0.5", "\n", "\n", "loss_supervision_attention", "=", "self", ".", "loss_mse", "(", "attention_weights", ".", "cuda", "(", ")", ",", "supervision_attention", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "ct_loss", ",", "ct_debug", "=", "self", ".", "composite_triplet_loss", "(", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ",", "attention_weights", ")", "\n", "L_av", "=", "self", ".", "loss_mse", "(", "a1", ",", "v1", ")", "\n", "ct_loss", "=", "ct_loss", ".", "mean", "(", ")", "\n", "return", "ct_loss", "+", "L_av", "+", "loss_supervision_attention", ",", "{", "\"ct\"", ":", "ct_debug", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.AVGZSLLoss.__init__": [[48, 54], ["torch.nn.Module.__init__", "loss.CrossModalDecoderLoss", "loss.CompositeTripletLoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "AVGZSLLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "cross_modal_loss", "=", "CrossModalDecoderLoss", "(", "self", ".", "margin", ",", "self", ".", "distance_fn", ")", "\n", "self", ".", "composite_triplet_loss", "=", "CompositeTripletLoss", "(", "self", ".", "margin", ",", "self", ".", "distance_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.AVGZSLLoss.forward": [[55, 59], ["loss.AVGZSLLoss.cross_modal_loss", "loss.AVGZSLLoss.composite_triplet_loss"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_t1", ",", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ",", "x_ta1", ",", "x_tv1", ",", "x_tt1", ",", "x_ta2", ",", "x_tv2", ")", ":", "\n", "        ", "cmd_loss", ",", "cmd_debug", "=", "self", ".", "cross_modal_loss", "(", "x_t1", ",", "x_ta1", ",", "x_tv1", ",", "x_tt1", ",", "x_ta2", ",", "x_tv2", ")", "\n", "ct_loss", ",", "ct_debug", "=", "self", ".", "composite_triplet_loss", "(", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ")", "\n", "return", "cmd_loss", "+", "ct_loss", ",", "{", "\"cmd\"", ":", "cmd_debug", ",", "\"ct\"", ":", "ct_debug", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.TripletLoss.__init__": [[67, 72], ["torch.nn.Module.__init__", "torch.nn.TripletMarginLoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "TripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "torch_l2_loss", "=", "nn", ".", "TripletMarginLoss", "(", "margin", "=", "self", ".", "margin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.TripletLoss.forward": [[73, 77], ["loss.TripletLoss.torch_l2_loss", "loss.TripletLoss.mean", "loss.TripletLoss.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "anchor", ",", "positive", ",", "negative", ",", "size_average", "=", "True", ")", ":", "\n", "\n", "        ", "losses", "=", "self", ".", "torch_l2_loss", "(", "anchor", "=", "anchor", ",", "positive", "=", "positive", ",", "negative", "=", "negative", ")", "\n", "return", "losses", ".", "mean", "(", ")", "if", "size_average", "else", "losses", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CrossModalDecoderLoss.__init__": [[84, 89], ["torch.nn.Module.__init__", "loss.TripletLoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "CrossModalDecoderLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "triplet_loss", "=", "TripletLoss", "(", "self", ".", "margin", ",", "self", ".", "distance_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CrossModalDecoderLoss.forward": [[90, 99], ["loss.CrossModalDecoderLoss.distance_fn", "loss.CrossModalDecoderLoss.distance_fn", "loss.CrossModalDecoderLoss.distance_fn", "loss.CrossModalDecoderLoss.triplet_loss", "loss.CrossModalDecoderLoss.triplet_loss", "loss.CrossModalDecoderLoss.mean", "loss.CrossModalDecoderLoss.mean", "loss.CrossModalDecoderLoss.mean", "l_rec.detach", "loss.CrossModalDecoderLoss.detach", "loss.CrossModalDecoderLoss.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_t1", ",", "x_ta1", ",", "x_tv1", ",", "x_tt1", ",", "x_ta2", ",", "x_tv2", ")", ":", "\n", "        ", "distance1", "=", "self", ".", "distance_fn", "(", "x_tt1", ",", "x_t1", ")", "\n", "distance2", "=", "self", ".", "distance_fn", "(", "x_ta1", ",", "x_t1", ")", "\n", "distance3", "=", "self", ".", "distance_fn", "(", "x_tv1", ",", "x_t1", ")", "\n", "\n", "l_rec", "=", "distance1", ".", "mean", "(", ")", "+", "distance2", ".", "mean", "(", ")", "+", "distance3", ".", "mean", "(", ")", "\n", "l_cta", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "x_tt1", ",", "positive", "=", "x_ta1", ",", "negative", "=", "x_ta2", ")", "\n", "l_ctv", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "x_tt1", ",", "positive", "=", "x_tv1", ",", "negative", "=", "x_tv2", ")", "\n", "return", "l_rec", "+", "l_cta", "+", "l_ctv", ",", "{", "\"l_rec\"", ":", "l_rec", ".", "detach", "(", ")", ",", "\"l_cta\"", ":", "l_cta", ".", "detach", "(", ")", ",", "\"l_ctv\"", ":", "l_ctv", ".", "detach", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CompositeCJMETripletLoss.__init__": [[103, 108], ["torch.nn.Module.__init__", "torch.nn.TripletMarginLoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "CompositeCJMETripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "triplet_loss", "=", "nn", ".", "TripletMarginLoss", "(", "margin", "=", "self", ".", "margin", ",", "reduction", "=", "\"none\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CompositeCJMETripletLoss.forward": [[110, 114], ["loss.CompositeCJMETripletLoss.triplet_loss", "loss.CompositeCJMETripletLoss.triplet_loss", "loss.CompositeCJMETripletLoss.detach", "loss.CompositeCJMETripletLoss.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ",", "attention_weights", ")", ":", "\n", "        ", "l_ta", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "t1", ",", "positive", "=", "a1", ",", "negative", "=", "a2", ")", "\n", "l_tv", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "t1", ",", "positive", "=", "v1", ",", "negative", "=", "v2", ")", "\n", "return", "(", "1", "-", "attention_weights", ")", "*", "l_ta", "+", "attention_weights", "*", "l_tv", ",", "{", "\"l_ta\"", ":", "l_ta", ".", "detach", "(", ")", ",", "\"l_tv\"", ":", "l_tv", ".", "detach", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CompositeTripletLoss.__init__": [[123, 128], ["torch.nn.Module.__init__", "loss.TripletLoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "margin", ",", "distance_fn", ")", ":", "\n", "        ", "super", "(", "CompositeTripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "distance_fn", "=", "distance_fn", "\n", "self", ".", "triplet_loss", "=", "TripletLoss", "(", "self", ".", "margin", ",", "self", ".", "distance_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.CompositeTripletLoss.forward": [[129, 136], ["loss.CompositeTripletLoss.triplet_loss", "loss.CompositeTripletLoss.triplet_loss", "loss.CompositeTripletLoss.triplet_loss", "loss.CompositeTripletLoss.triplet_loss", "loss.CompositeTripletLoss.detach", "loss.CompositeTripletLoss.detach", "loss.CompositeTripletLoss.detach", "loss.CompositeTripletLoss.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "a1", ",", "v1", ",", "t1", ",", "a2", ",", "v2", ",", "t2", ")", ":", "\n", "        ", "l_ta", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "t1", ",", "positive", "=", "a1", ",", "negative", "=", "a2", ")", "\n", "l_at", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "a1", ",", "positive", "=", "t1", ",", "negative", "=", "t2", ")", "\n", "l_tv", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "t1", ",", "positive", "=", "v1", ",", "negative", "=", "v2", ")", "\n", "l_vt", "=", "self", ".", "triplet_loss", "(", "anchor", "=", "v1", ",", "positive", "=", "t1", ",", "negative", "=", "t2", ")", "\n", "return", "l_ta", "+", "l_at", "+", "l_tv", "+", "l_vt", ",", "{", "\"l_ta\"", ":", "l_ta", ".", "detach", "(", ")", ",", "\"l_at\"", ":", "l_at", ".", "detach", "(", ")", ",", "\"l_tv\"", ":", "l_tv", ".", "detach", "(", ")", ",", "\n", "\"l_vt\"", ":", "l_vt", ".", "detach", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.DistanceLoss.__init__": [[138, 140], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DistanceLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.DistanceLoss.__repr__": [[141, 143], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.DistanceLoss.forward": [[144, 146], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.L2Loss.forward": [[149, 151], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", ".", "pow", "(", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.SquaredL2Loss.forward": [[154, 156], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.ClsContrastiveLoss.__init__": [[163, 173], ["torch.nn.Module.__init__", "torch.zeros", "torch.cumsum", "torch.arange().float", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "margin", "=", "0.2", ",", "max_violation", "=", "False", ",", "topk", "=", "1", ",", "reduction", "=", "'sum'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "max_violation", "=", "max_violation", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "reduction", "=", "reduction", "\n", "if", "self", ".", "reduction", "==", "'weighted'", ":", "\n", "            ", "self", ".", "betas", "=", "torch", ".", "zeros", "(", "701", ")", "\n", "self", ".", "betas", "[", "1", ":", "]", "=", "torch", ".", "cumsum", "(", "1", "/", "(", "torch", ".", "arange", "(", "700", ")", ".", "float", "(", ")", "+", "1", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.ClsContrastiveLoss.forward": [[174, 199], ["scores.size", "torch.gather", "torch.zeros_like().bool", "torch.zeros_like().bool.scatter_", "torch.gather.expand_as", "cost_s.masked_fill.masked_fill.masked_fill", "int_labels.unsqueeze", "int_labels.unsqueeze", "torch.topk", "torch.sum", "torch.zeros_like", "cost_s.masked_fill.masked_fill.detach", "torch.sum().unsqueeze", "loss.ClsContrastiveLoss.betas.to().unsqueeze().expand().gather", "scores.size", "torch.sum", "loss.ClsContrastiveLoss.betas.to().unsqueeze().expand", "loss.ClsContrastiveLoss.betas.to().unsqueeze", "loss.ClsContrastiveLoss.betas.to"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "scores", ",", "int_labels", ")", ":", "\n", "        ", "batch_size", "=", "scores", ".", "size", "(", "0", ")", "\n", "\n", "pos_scores", "=", "torch", ".", "gather", "(", "scores", ",", "1", ",", "int_labels", ".", "unsqueeze", "(", "1", ")", ")", "\n", "pos_masks", "=", "torch", ".", "zeros_like", "(", "scores", ")", ".", "bool", "(", ")", "\n", "pos_masks", ".", "scatter_", "(", "1", ",", "int_labels", ".", "unsqueeze", "(", "1", ")", ",", "True", ")", "\n", "\n", "d1", "=", "pos_scores", ".", "expand_as", "(", "scores", ")", "\n", "cost_s", "=", "(", "self", ".", "margin", "+", "scores", "-", "d1", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "cost_s", "=", "cost_s", ".", "masked_fill", "(", "pos_masks", ",", "0", ")", "\n", "if", "self", ".", "max_violation", ":", "\n", "            ", "cost_s", ",", "_", "=", "torch", ".", "topk", "(", "cost_s", ",", "self", ".", "topk", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "                ", "cost_s", "=", "cost_s", "/", "self", ".", "topk", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "                ", "cost_s", "=", "cost_s", "/", "(", "scores", ".", "size", "(", "1", ")", "-", "1", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'weighted'", ":", "\n", "                ", "gt_ranks", "=", "torch", ".", "sum", "(", "cost_s", ">", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "weights", "=", "self", ".", "betas", ".", "to", "(", "scores", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", ".", "gather", "(", "1", ",", "gt_ranks", ")", "\n", "weights", "=", "weights", "/", "(", "gt_ranks", "+", "1e-8", ")", "\n", "cost_s", "=", "cost_s", "*", "weights", "\n", "\n", "", "", "cost_s", "=", "torch", ".", "sum", "(", "cost_s", ")", "/", "batch_size", "\n", "return", "cost_s", ",", "{", "\"cost_s\"", ":", "cost_s", ".", "detach", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.APN_Loss.__init__": [[203, 207], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "criterion_regre", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.loss.APN_Loss.forward": [[209, 227], ["loss.APN_Loss.criterion", "loss.APN_Loss.criterion_regre", "loss.APN_Loss.criterion", "loss.APN_Loss.criterion_regre", "loss.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "model", ",", "output", ",", "pre_attri", ",", "pre_class", ",", "label_a", ",", "\n", "label_v", ")", ":", "\n", "\n", "        ", "loss_xe", "=", "self", ".", "criterion", "(", "output", ",", "label_v", ")", "\n", "loss", "=", "loss_xe", "\n", "\n", "loss_attri", "=", "self", ".", "criterion_regre", "(", "pre_attri", "[", "'final'", "]", ",", "label_a", ")", "\n", "loss", "+=", "loss_attri", "\n", "\n", "for", "name", "in", "model", ".", "extract", ":", "\n", "\n", "            ", "layer_xe", "=", "self", ".", "criterion", "(", "pre_class", "[", "name", "]", ",", "label_v", ")", "\n", "loss", "+=", "layer_xe", "\n", "\n", "loss_attri", "=", "self", ".", "criterion_regre", "(", "pre_attri", "[", "name", "]", ",", "label_a", ")", "\n", "loss", "+=", "loss_attri", "\n", "\n", "", "return", "loss", ",", "{", "\"loss\"", ":", "loss", ".", "detach", "(", ")", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.test.test": [[6, 31], ["logging.getLogger", "model_A.eval", "model_B.eval", "test._get_test_performance", "logging.getLogger.info", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.test._get_test_performance"], ["def", "test", "(", "eval_name", ",", "val_dataset", ",", "test_dataset", ",", "model_A", ",", "model_B", ",", "device", ",", "distance_fn", ",", "\n", "args", "=", "None", ",", "new_model_attention", "=", "False", ",", "devise_model", "=", "False", ",", "apn", "=", "False", ",", "save_performances", "=", "False", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "model_A", ".", "eval", "(", ")", "\n", "model_B", ".", "eval", "(", ")", "\n", "\n", "test_evaluation", "=", "_get_test_performance", "(", "val_dataset", "=", "val_dataset", ",", "test_dataset", "=", "test_dataset", ",", "model_A", "=", "model_A", ",", "\n", "model_B", "=", "model_B", ",", "device", "=", "device", ",", "distance_fn", "=", "distance_fn", ",", "\n", "args", "=", "args", ",", "\n", "new_model_attention", "=", "new_model_attention", ",", "\n", "devise_model", "=", "devise_model", ",", "\n", "apn", "=", "apn", ",", "save_performances", "=", "save_performances", ")", "\n", "\n", "if", "args", ".", "dataset_name", "==", "\"AudioSetZSL\"", ":", "\n", "        ", "output_string", "=", "fr\"\"\"\n            Seen performance={100*test_evaluation[\"both\"][\"seen\"]:.2f}, Unseen performance={100*test_evaluation[\"both\"][\"unseen\"]:.2f}, GZSL performance={100*test_evaluation[\"both\"][\"hm\"]:.2f}, ZSL performance={100*test_evaluation[\"both\"][\"zsl\"]:.2f} \n            \"\"\"", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"VGGSound\"", "or", "args", ".", "dataset_name", "==", "\"UCF\"", "or", "args", ".", "dataset_name", "==", "\"ActivityNet\"", ":", "\n", "        ", "output_string", "=", "fr\"\"\"\n            Seen performance={100*test_evaluation[\"both\"][\"seen\"]:.2f}, Unseen performance={100*test_evaluation[\"both\"][\"unseen\"]:.2f}, GZSL performance={100*test_evaluation[\"both\"][\"hm\"]:.2f}, ZSL performance={100*test_evaluation[\"both\"][\"zsl\"]:.2f} \n            \"\"\"", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "output_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.test._get_test_performance": [[33, 61], ["logging.getLogger", "logging.getLogger.info", "logging.getLogger.info", "src.utils.evaluate_dataset_baseline", "src.utils.evaluate_dataset", "src.utils.evaluate_dataset_baseline", "src.utils.evaluate_dataset"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset_baseline", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset_baseline", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset"], ["", "def", "_get_test_performance", "(", "val_dataset", ",", "test_dataset", ",", "model_A", ",", "model_B", ",", "device", ",", "distance_fn", ",", "args", ",", "new_model_attention", ",", "devise_model", ",", "apn", ",", "save_performances", "=", "False", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "if", "new_model_attention", "or", "devise_model", "or", "apn", ":", "\n", "        ", "val_evaluation", "=", "evaluate_dataset_baseline", "(", "val_dataset", ",", "model_A", ",", "device", ",", "distance_fn", ",", "\n", "args", "=", "args", ",", "\n", "new_model_attention", "=", "new_model_attention", ",", "\n", "model_devise", "=", "devise_model", ",", "\n", "apn", "=", "apn", ")", "\n", "", "else", ":", "\n", "        ", "val_evaluation", "=", "evaluate_dataset", "(", "val_dataset", ",", "model_A", ",", "device", ",", "distance_fn", ",", "args", "=", "args", ")", "\n", "", "best_beta_combined", "=", "1.", "/", "3", "*", "(", "\n", "val_evaluation", "[", "'audio'", "]", "[", "'beta'", "]", "+", "val_evaluation", "[", "'video'", "]", "[", "'beta'", "]", "+", "val_evaluation", "[", "'both'", "]", "[", "'beta'", "]", ")", "\n", "if", "best_beta_combined", "==", "0", ":", "\n", "        ", "best_beta_combined", "+=", "1e-10", "\n", "", "logger", ".", "info", "(", "\n", "f\"Validation betas:\\tAudio={val_evaluation['audio']['beta']}\\tVideo={val_evaluation['video']['beta']}\\tBoth={val_evaluation['both']['beta']}\"", ")", "\n", "logger", ".", "info", "(", "f\"Best beta combined: {best_beta_combined}\"", ")", "\n", "\n", "if", "new_model_attention", "or", "devise_model", "or", "apn", ":", "\n", "        ", "test_evaluation", "=", "evaluate_dataset_baseline", "(", "test_dataset", ",", "model_B", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "best_beta_combined", ",", "\n", "args", "=", "args", ",", "\n", "new_model_attention", "=", "new_model_attention", ",", "\n", "model_devise", "=", "devise_model", ",", "\n", "apn", "=", "apn", ",", "save_performances", "=", "save_performances", ")", "\n", "", "else", ":", "\n", "        ", "test_evaluation", "=", "evaluate_dataset", "(", "test_dataset", ",", "model_B", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "best_beta_combined", ",", "args", "=", "args", ")", "\n", "\n", "", "return", "test_evaluation", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LINEAR_SOFTMAX_ALE.__init__": [[20, 24], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "attri_dim", ")", ":", "\n", "        ", "super", "(", "LINEAR_SOFTMAX_ALE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "attri_dim", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LINEAR_SOFTMAX_ALE.forward": [[25, 29], ["model.LINEAR_SOFTMAX_ALE.fc", "model.LINEAR_SOFTMAX_ALE.softmax", "model.LINEAR_SOFTMAX_ALE.mm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attribute", ")", ":", "\n", "        ", "middle", "=", "self", ".", "fc", "(", "x", ")", "\n", "output", "=", "self", ".", "softmax", "(", "middle", ".", "mm", "(", "attribute", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LINEAR_SOFTMAX.__init__": [[32, 36], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ")", ":", "\n", "        ", "super", "(", "LINEAR_SOFTMAX", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LINEAR_SOFTMAX.forward": [[37, 41], ["model.LINEAR_SOFTMAX.fc", "model.LINEAR_SOFTMAX.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "self", ".", "softmax", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LAYER_ALE.__init__": [[44, 48], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "attri_dim", ")", ":", "\n", "        ", "super", "(", "LAYER_ALE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "attri_dim", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.LAYER_ALE.forward": [[49, 56], ["x.view.view.size", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x.view.view.view", "model.LAYER_ALE.fc", "model.LAYER_ALE.softmax", "model.LAYER_ALE.mm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attribute", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "middle", "=", "self", ".", "fc", "(", "x", ")", "\n", "output", "=", "self", ".", "softmax", "(", "middle", ".", "mm", "(", "attribute", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.APN.__init__": [[59, 87], ["torch.nn.Module.__init__", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax2d", "torch.nn.Softmax2d", "torch.nn.Softmax2d", "torch.nn.Softmax2d", "torch.nn.Softmax2d", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "dict", "torch.nn.ParameterDict", "torch.nn.ParameterDict", "torch.nn.ParameterDict", "torch.nn.ParameterDict", "torch.nn.ParameterDict", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "APN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# we left the entry for several layers, but here we only use layer4", "\n", "self", ".", "dim_dict", "=", "{", "'layer1'", ":", "56", "*", "56", ",", "'layer2'", ":", "28", "*", "28", ",", "'layer3'", ":", "14", "*", "14", ",", "'layer4'", ":", "1", "*", "1", ",", "'avg_pool'", ":", "1", "*", "1", "}", "\n", "if", "opt", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "channel_dict", "=", "{", "'layer1'", ":", "256", ",", "'layer2'", ":", "512", ",", "'layer3'", ":", "1024", ",", "'layer4'", ":", "2", "*", "opt", ".", "input_size", ",", "'avg_pool'", ":", "2048", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "channel_dict", "=", "{", "'layer1'", ":", "256", ",", "'layer2'", ":", "512", ",", "'layer3'", ":", "1024", ",", "'layer4'", ":", "opt", ".", "input_size_audio", "+", "opt", ".", "input_size_video", ",", "\n", "'avg_pool'", ":", "2048", "}", "\n", "", "self", ".", "kernel_size", "=", "{", "'layer1'", ":", "56", ",", "'layer2'", ":", "28", ",", "'layer3'", ":", "14", ",", "'layer4'", ":", "1", "*", "1", ",", "'avg_pool'", ":", "1", "}", "\n", "self", ".", "extract", "=", "[", "'layer4'", "]", "\n", "self", ".", "epsilon", "=", "1e-4", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "softmax2d", "=", "nn", ".", "Softmax2d", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "prototype_vectors", "=", "dict", "(", ")", "\n", "for", "name", "in", "self", ".", "extract", ":", "\n", "            ", "prototype_shape", "=", "[", "300", ",", "self", ".", "channel_dict", "[", "name", "]", ",", "1", ",", "1", "]", "\n", "self", ".", "prototype_vectors", "[", "name", "]", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "prototype_shape", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "prototype_vectors", "=", "nn", ".", "ParameterDict", "(", "self", ".", "prototype_vectors", ")", "\n", "if", "opt", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "ALE_vector", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "[", "300", ",", "2", "*", "opt", ".", "input_size", ",", "1", ",", "1", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ALE_vector", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "[", "300", ",", "opt", ".", "input_size_audio", "+", "opt", ".", "input_size_video", ",", "1", ",", "1", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.APN.forward": [[88, 107], ["torch.normalize.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "dict", "dict", "dict", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "model.APN.softmax", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "pre_attri[].mm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "model.APN.softmax", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "attribute.t", "pre_attri[].mm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "attribute.t"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "def", "forward", "(", "self", ",", "x", ",", "attribute", ",", "return_map", "=", "False", ")", ":", "\n", "        ", "\"\"\"out: predict class, predict attributes, maps, out_feature\"\"\"", "\n", "if", "self", ".", "opt", ".", "norm_inputs", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ")", "\n", "", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "2", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "3", ")", "\n", "attention", "=", "dict", "(", ")", "\n", "pre_attri", "=", "dict", "(", ")", "\n", "pre_class", "=", "dict", "(", ")", "\n", "\n", "pre_attri", "[", "'final'", "]", "=", "F", ".", "max_pool2d", "(", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "ALE_vector", ")", ",", "kernel_size", "=", "1", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "output_final", "=", "self", ".", "softmax", "(", "pre_attri", "[", "'final'", "]", ".", "mm", "(", "attribute", ".", "t", "(", ")", ")", ")", "\n", "\n", "for", "name", "in", "self", ".", "extract", ":", "\n", "            ", "attention", "[", "name", "]", "=", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "prototype_vectors", "[", "name", "]", ")", "\n", "pre_attri", "[", "name", "]", "=", "F", ".", "max_pool2d", "(", "attention", "[", "name", "]", ",", "kernel_size", "=", "self", ".", "kernel_size", "[", "name", "]", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "pre_class", "[", "name", "]", "=", "self", ".", "softmax", "(", "pre_attri", "[", "name", "]", ".", "mm", "(", "attribute", ".", "t", "(", ")", ")", ")", "\n", "", "return", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attribute", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.APN.fine_tune": [[108, 120], ["model.APN.resnet.parameters", "list", "c.parameters", "model.APN.resnet.children"], "methods", ["None"], ["", "def", "fine_tune", "(", "self", ",", "fine_tune", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n\n        :param fine_tune: Allow?\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "resnet", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "# If fine-tuning, only fine-tune convolutional blocks 2 through 4", "\n", "", "for", "c", "in", "list", "(", "self", ".", "resnet", ".", "children", "(", ")", ")", "[", "5", ":", "]", ":", "\n", "            ", "for", "p", "in", "c", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "fine_tune", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.APN._l2_convolution": [[121, 139], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "", "", "def", "_l2_convolution", "(", "self", ",", "x", ",", "prototype_vector", ",", "one", ")", ":", "\n", "        ", "'''\n        apply self.prototype_vectors as l2-convolution filters on input x\n        '''", "\n", "x2", "=", "x", "**", "2", "# [64, C, W, H]", "\n", "x2_patch_sum", "=", "F", ".", "conv2d", "(", "input", "=", "x2", ",", "weight", "=", "one", ")", "\n", "\n", "p2", "=", "prototype_vector", "**", "2", "\n", "p2", "=", "torch", ".", "sum", "(", "p2", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "# p2 is a vector of shape (num_prototypes,)", "\n", "# then we reshape it to (num_prototypes, 1, 1)", "\n", "p2_reshape", "=", "p2", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "xp", "=", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "prototype_vector", ")", "\n", "intermediate_result", "=", "-", "2", "*", "xp", "+", "p2_reshape", "# use broadcast  [64, 312,  W, H]", "\n", "# x2_patch_sum and intermediate_result are of the same shape", "\n", "distances", "=", "F", ".", "relu", "(", "x2_patch_sum", "+", "intermediate_result", ")", "# [64, 312,  W, H]", "\n", "return", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.DeviseModel.__init__": [[142, 150], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "        ", "self", ".", "bilinear", "=", "nn", ".", "Linear", "(", "self", ".", "args", ".", "input_size", "*", "2", ",", "300", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "bilinear", "=", "nn", ".", "Linear", "(", "self", ".", "args", ".", "input_size_audio", "+", "self", ".", "args", ".", "input_size_video", ",", "300", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "args", ".", "dropout_baselines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.DeviseModel.forward": [[151, 159], ["model.DeviseModel.dropout", "model.DeviseModel.dropout", "model.DeviseModel.bilinear", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "model.DeviseModel.bilinear", "model.DeviseModel.t"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "def", "forward", "(", "self", ",", "vis_fts", ",", "txt_fts", ")", ":", "\n", "    ", "if", "self", ".", "args", ".", "norm_inputs", ":", "\n", "        ", "vis_fts", "=", "F", ".", "normalize", "(", "vis_fts", ")", "\n", "", "vis_fts", "=", "self", ".", "dropout", "(", "vis_fts", ")", "\n", "txt_fts", "=", "self", ".", "dropout", "(", "txt_fts", ")", "\n", "projected_text_features", "=", "self", ".", "bilinear", "(", "vis_fts", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "self", ".", "bilinear", "(", "vis_fts", ")", ",", "txt_fts", ".", "t", "(", ")", ")", "\n", "return", "logits", ",", "projected_text_features", ",", "txt_fts", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.CJME.__init__": [[163, 171], ["torch.nn.Module.__init__", "model.CJME._triplet_net", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet._triplet_net"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "CJME", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout_baselines", "\n", "self", ".", "triplet_net", "=", "self", ".", "_triplet_net", "(", "args", ")", "\n", "self", ".", "attention_model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "args", ".", "input_size_video", "+", "args", ".", "input_size_audio", ")", ",", "\n", "nn", ".", "Linear", "(", "in_features", "=", "args", ".", "input_size_video", "+", "args", ".", "input_size_audio", ",", "out_features", "=", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.CJME.forward": [[173, 185], ["model.CJME.triplet_net", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.CJME.attention_model", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", "=", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "input_attention", "=", "torch", ".", "cat", "(", "(", "x_a_p", ",", "x_v_p", ")", ",", "axis", "=", "1", ")", "\n", "attention_weights", "=", "self", ".", "attention_model", "(", "input_attention", ")", "\n", "\n", "index_video", "=", "attention_weights", ">=", "0.5", "\n", "index_audio", "=", "attention_weights", "<", "0.5", "\n", "threshold_attention", "=", "torch", ".", "clone", "(", "attention_weights", ")", "\n", "threshold_attention", "[", "index_video", "]", "=", "1", "\n", "threshold_attention", "[", "index_audio", "]", "=", "0", "\n", "\n", "return", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "attention_weights", ",", "threshold_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.CJME._triplet_net": [[186, 226], ["model.EmbeddingNetCJME", "model.TripletNet", "model.EmbeddingNetCJME", "model.EmbeddingNetCJME", "model.EmbeddingNetCJME", "model.EmbeddingNetCJME"], "methods", ["None"], ["", "def", "_triplet_net", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "f_a", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "", "else", ":", "\n", "            ", "f_a", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size_audio", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size_video", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "\n", "", "f_t", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "300", ",", "\n", "hidden_size", "=", "300", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "return", "TripletNet", "(", "f_a", ",", "f_v", ",", "f_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.CJME.get_embedding": [[227, 229], ["model.CJME.triplet_net"], "methods", ["None"], ["", "def", "get_embedding", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.CJME.get_classes_embedding": [[230, 232], ["model.CJME.triplet_net.get_classes_embedding"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.get_classes_embedding"], ["", "def", "get_classes_embedding", "(", "self", ",", "x_t_p", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", ".", "get_classes_embedding", "(", "x_t_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetCJME.__init__": [[234, 248], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modules.append", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", ",", "use_bn", ",", "hidden_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "EmbeddingNetCJME", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "if", "hidden_size", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "hidden_size", ")", ")", "\n", "if", "use_bn", ":", "\n", "                ", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "hidden_size", ")", ")", "\n", "", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "hidden_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetCJME.forward": [[249, 252], ["model.EmbeddingNetCJME.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetCJME.get_embedding": [[253, 255], ["model.EmbeddingNetCJME.forward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward"], ["", "def", "get_embedding", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet.__init__": [[267, 271], ["torch.nn.Module.__init__", "model.AVGZSLNet._triplet_net", "model.AVGZSLNet._decoder_net"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet._triplet_net", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet._decoder_net"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "AVGZSLNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "triplet_net", "=", "self", ".", "_triplet_net", "(", "args", ")", "\n", "self", ".", "decoder_net", "=", "self", ".", "_decoder_net", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet.forward": [[272, 276], ["model.AVGZSLNet.triplet_net", "model.AVGZSLNet.decoder_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", "=", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "=", "self", ".", "decoder_net", "(", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ")", "\n", "return", "x_t_p", ",", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet._triplet_net": [[277, 317], ["model.EmbeddingNet", "model.TripletNet", "model.EmbeddingNet", "model.EmbeddingNet", "model.EmbeddingNet", "model.EmbeddingNet"], "methods", ["None"], ["", "def", "_triplet_net", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "f_a", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "args", ".", "embedding_dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "args", ".", "embedding_dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "", "else", ":", "\n", "            ", "f_a", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "args", ".", "input_size_audio", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "args", ".", "embedding_dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "args", ".", "input_size_video", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "args", ".", "embedding_dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "\n", "", "f_t", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "300", ",", "\n", "hidden_size", "=", "300", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "args", ".", "embedding_dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "return", "TripletNet", "(", "f_a", ",", "f_v", ",", "f_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet._decoder_net": [[318, 327], ["model.EmbeddingNet", "model.DecoderNet"], "methods", ["None"], ["", "def", "_decoder_net", "(", "self", ",", "args", ")", ":", "\n", "        ", "f_dec", "=", "EmbeddingNet", "(", "\n", "input_size", "=", "64", ",", "\n", "hidden_size", "=", "args", ".", "decoder_hidden_size", ",", "\n", "output_size", "=", "300", ",", "\n", "dropout", "=", "args", ".", "decoder_dropout", ",", "\n", "use_bn", "=", "args", ".", "decoder_use_bn", "\n", ")", "\n", "return", "DecoderNet", "(", "f_dec", ",", "args", ".", "normalize_decoder_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet.get_embedding": [[328, 330], ["model.AVGZSLNet.triplet_net"], "methods", ["None"], ["", "def", "get_embedding", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.AVGZSLNet.get_classes_embedding": [[331, 333], ["model.AVGZSLNet.triplet_net.get_classes_embedding"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.get_classes_embedding"], ["", "def", "get_classes_embedding", "(", "self", ",", "x_t_p", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", ".", "get_classes_embedding", "(", "x_t_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNet.__init__": [[336, 349], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.append", "modules.append", "modules.append", "modules.append", "modules.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modules.append", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", ",", "use_bn", ",", "hidden_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "EmbeddingNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "if", "hidden_size", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "hidden_size", ")", ")", "\n", "if", "use_bn", ":", "\n", "                ", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "hidden_size", ")", ")", "\n", "", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "hidden_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNet.forward": [[350, 353], ["model.EmbeddingNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNet.get_embedding": [[354, 356], ["model.EmbeddingNet.forward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward"], ["", "def", "get_embedding", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetL2.__init__": [[359, 361], ["model.EmbeddingNet.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "hidden_size", "=", "None", ",", "dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", "EmbeddingNetL2", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "output_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetL2.forward": [[362, 366], ["model.EmbeddingNet.forward", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "super", "(", "EmbeddingNetL2", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "output", "=", "F", ".", "normalize", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.EmbeddingNetL2.get_embedding": [[367, 369], ["model.EmbeddingNetL2.forward"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward"], ["", "def", "get_embedding", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.__init__": [[372, 377], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_net1", ",", "embedding_net2", ",", "embedding_net3", ")", ":", "\n", "        ", "super", "(", "TripletNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_net1", "=", "embedding_net1", "\n", "self", ".", "embedding_net2", "=", "embedding_net2", "\n", "self", ".", "embedding_net3", "=", "embedding_net3", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.forward": [[378, 388], ["model.TripletNet.embedding_net1", "model.TripletNet.embedding_net2", "model.TripletNet.embedding_net3", "model.TripletNet.embedding_net1", "model.TripletNet.embedding_net2", "model.TripletNet.embedding_net3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "\n", "        ", "a_p", "=", "self", ".", "embedding_net1", "(", "x_a_p", ")", "\n", "v_p", "=", "self", ".", "embedding_net2", "(", "x_v_p", ")", "\n", "t_p", "=", "self", ".", "embedding_net3", "(", "x_t_p", ")", "\n", "a_q", "=", "self", ".", "embedding_net1", "(", "x_a_q", ")", "\n", "v_q", "=", "self", ".", "embedding_net2", "(", "x_v_q", ")", "\n", "t_q", "=", "self", ".", "embedding_net3", "(", "x_t_q", ")", "\n", "\n", "return", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.TripletNet.get_classes_embedding": [[389, 391], ["model.TripletNet.embedding_net3"], "methods", ["None"], ["", "def", "get_classes_embedding", "(", "self", ",", "x_t_p", ")", ":", "\n", "        ", "return", "self", ".", "embedding_net3", "(", "x_t_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.DecoderNet.__init__": [[394, 398], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_net", ",", "normalize_decoder_outputs", ")", ":", "\n", "        ", "super", "(", "DecoderNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_net", "=", "embedding_net", "\n", "self", ".", "normalize_decoder_outputs", "=", "normalize_decoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.DecoderNet.forward": [[399, 414], ["model.DecoderNet.embedding_net", "model.DecoderNet.embedding_net", "model.DecoderNet.embedding_net", "model.DecoderNet.embedding_net", "model.DecoderNet.embedding_net", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "def", "forward", "(", "self", ",", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ")", ":", "\n", "        ", "x_ta_p", "=", "self", ".", "embedding_net", "(", "a_p", ")", "\n", "x_tv_p", "=", "self", ".", "embedding_net", "(", "v_p", ")", "\n", "x_tt_p", "=", "self", ".", "embedding_net", "(", "t_p", ")", "\n", "x_ta_q", "=", "self", ".", "embedding_net", "(", "a_q", ")", "\n", "x_tv_q", "=", "self", ".", "embedding_net", "(", "v_q", ")", "\n", "\n", "if", "self", ".", "normalize_decoder_outputs", ":", "\n", "            ", "x_ta_p", "=", "F", ".", "normalize", "(", "x_ta_p", ")", "\n", "x_tv_p", "=", "F", ".", "normalize", "(", "x_tv_p", ")", "\n", "x_tt_p", "=", "F", ".", "normalize", "(", "x_tt_p", ")", "\n", "x_ta_q", "=", "F", ".", "normalize", "(", "x_ta_q", ")", "\n", "x_tv_q", "=", "F", ".", "normalize", "(", "x_tv_q", ")", "\n", "\n", "", "return", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model.weights_init": [[9, 17], ["classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_"], "function", ["None"], ["def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args_gen.args_main": [[5, 404], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["def", "args_main", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Explainable Audio Visual Low Shot Learning\"", ")", "\n", "\n", "### Filesystem ###", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root_dir\"", ",", "\n", "help", "=", "\"Path to dataset directory. Expected subfolder structure: '{root_dir}/features/{feature_extraction_method}/{audio,video,text}'\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--feature_extraction_method\"", ",", "\n", "help", "=", "\"Name of folder containing respective extracted features. Has to match {feature_extraction_method} in --root_dir argument.\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "help", "=", "\"Name of the dataset to use\"", ",", "\n", "choices", "=", "[", "\"AudioSetZSL\"", ",", "\"VGGSound\"", ",", "\"UCF\"", ",", "\"ActivityNet\"", "]", ",", "\n", "default", "=", "\"AudioSetZSL\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--zero_shot_split\"", ",", "\n", "help", "=", "\"Name of zero shot split to use.\"", ",", "\n", "choices", "=", "[", "\"\"", ",", "\"main_split\"", ",", "\"cls_split\"", "]", ",", "\n", "default", "=", "\"\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--manual_text_word2vec\"", ",", "\n", "help", "=", "\"Flag to use the manual word2vec text embeddings. CARE: Need to create cache files again!\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val_all_loss\"", ",", "\n", "help", "=", "\"Validate loss with seen + unseen\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--additional_triplets_loss\"", ",", "\n", "help", "=", "\"Flag for using more triplets loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reg_loss\"", ",", "\n", "help", "=", "\"Flag for setting the regularization loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cycle_loss\"", ",", "\n", "help", "=", "\"Flag for using cycle loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--retrain_all\"", ",", "\n", "help", "=", "\"Retrain with all data from train and validation\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_checkpoints\"", ",", "\n", "help", "=", "\"Save checkpoints of the model every epoch\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "### Development options ###", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "help", "=", "\"Run the program in debug mode\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose\"", ",", "\n", "help", "=", "\"Run verbosely\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug_comment\"", ",", "\n", "help", "=", "\"Custom comment string for the summary writer\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--epochs\"", ",", "\n", "help", "=", "\"Number of epochs\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--norm_inputs\"", ",", "\n", "help", "=", "\"Normalize inputs before model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--z_score_inputs\"", ",", "\n", "help", "=", "\"Z-Score standardize inputs before model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "### Hyperparameters ###", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bs\"", ",", "\n", "help", "=", "\"Batch size\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_batches\"", ",", "\n", "help", "=", "\"Number of batches for the balanced batch sampler\"", ",", "\n", "default", "=", "250", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size\"", ",", "\n", "help", "=", "\"Dimension of the extracted features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size_audio\"", ",", "\n", "help", "=", "\"Dimension of the extracted audio features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size_video\"", ",", "\n", "help", "=", "\"Dimension of the extracted video features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embeddings_hidden_size\"", ",", "\n", "help", "=", "\"Hidden layer size for the embedding networks\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_hidden_size\"", ",", "\n", "help", "=", "\"Hidden layer size for the decoder loss network\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding_dropout\"", ",", "\n", "help", "=", "\"Dropout in the embedding networks\"", ",", "\n", "default", "=", "0.8", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_dropout\"", ",", "\n", "help", "=", "\"Dropout in the decoder loss network\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding_use_bn\"", ",", "\n", "help", "=", "\"Use batchnorm in the embedding networks\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_use_bn\"", ",", "\n", "help", "=", "\"Use batchnorm in the decoder network\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--normalize_decoder_outputs\"", ",", "\n", "help", "=", "\"L2 normalize the outputs of the decoder\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--margin\"", ",", "\n", "help", "=", "\"Margin for the contrastive loss calculation\"", ",", "\n", "default", "=", "1.", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--distance_fn\"", ",", "\n", "help", "=", "\"Distance function for the contrastive loss calculation\"", ",", "\n", "choices", "=", "[", "\"L2Loss\"", ",", "\"SquaredL2Loss\"", "]", ",", "\n", "default", "=", "\"L2Loss\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_scheduler\"", ",", "\n", "help", "=", "\"Use LR_scheduler\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "\n", "# defaults", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "help", "=", "\"Random seed\"", ",", "\n", "default", "=", "42", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dump_path\"", ",", "\n", "help", "=", "\"Path where to create experiment log dirs\"", ",", "\n", "default", "=", "pathlib", ".", "Path", "(", "\".\"", ")", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "help", "=", "\"Device to run on.\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "\n", "default", "=", "\"cuda\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--baseline\"", ",", "\n", "help", "=", "\"Flag to use the baseline where we have two ALEs, one for each modality and we just try to push the modalities to text embeddings\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--audio_baseline\"", ",", "\n", "help", "=", "\"Flag to use the audio baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--video_baseline\"", ",", "\n", "help", "=", "\"Flag to use the video baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--concatenated_baseline\"", ",", "\n", "help", "=", "\"Flag to use the concatenated baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model\"", ",", "\n", "help", "=", "\"Flag to use the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_early_fusion\"", ",", "\n", "help", "=", "\"Flag to use the early fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_middle_fusion\"", ",", "\n", "help", "=", "\"Flag to set the middle fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_attention\"", ",", "\n", "help", "=", "\"Flag to set the attention to the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_attention_both_heads\"", ",", "\n", "help", "=", "\"Flag to set if attention should provide output from both branches\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--depth_transformer\"", ",", "\n", "help", "=", "\"Flag to se the number of layers of the transformer\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exp_name\"", ",", "\n", "help", "=", "\"Flag to set the name of the experiment\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ale\"", ",", "\n", "help", "=", "\"Flag to set the ale\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--devise\"", ",", "\n", "help", "=", "\"Flag to set the devise model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sje\"", ",", "\n", "help", "=", "\"Flag to set the sje model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apn\"", ",", "\n", "help", "=", "\"Flag to set the apn model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--first_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the first pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--second_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the second pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--third_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the third pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--additional_dropout\"", ",", "\n", "help", "=", "\"flag to set the additional dropouts\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "float", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'FLO'", ",", "help", "=", "'FLO'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "default", "=", "'data/'", ",", "help", "=", "'path to dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--matdataset'", ",", "default", "=", "True", ",", "help", "=", "'Data in matlab format'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_embedding'", ",", "default", "=", "'res101'", ")", "\n", "parser", ".", "add_argument", "(", "'--class_embedding'", ",", "default", "=", "'att'", ")", "\n", "parser", ".", "add_argument", "(", "'--syn_num'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "'number features to generate per class'", ")", "\n", "parser", ".", "add_argument", "(", "'--gfsl'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_att10'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_att'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocessing'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'enbale MinMaxScaler on visual features'", ")", "\n", "parser", ".", "add_argument", "(", "'--standardization'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--validation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'enable cross validation mode'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "type", "=", "int", ",", "help", "=", "'number of data loading workers'", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--resSize'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "'size of visual features'", ")", "\n", "parser", ".", "add_argument", "(", "'--attSize'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'size of semantic features'", ")", "\n", "parser", ".", "add_argument", "(", "'--nz'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngh'", ",", "type", "=", "int", ",", "default", "=", "4096", ",", "help", "=", "'size of the hidden units in generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndh'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'size of the hidden units in discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepoch'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepoch_classifier'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--critic_iter'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'critic iteration, following WGAN-GP'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda1'", ",", "type", "=", "float", ",", "default", "=", "10", ",", "help", "=", "'gradient penalty regularizer, following WGAN-GP'", ")", "\n", "parser", ".", "add_argument", "(", "'--cls_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_weight'", ",", "type", "=", "float", ",", "default", "=", "100000", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate to train GANs '", ")", "\n", "parser", ".", "add_argument", "(", "'--classifier_lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate to train softmax classifier'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'beta1 for adam. default=0.5'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "help", "=", "'enables cuda'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngpu'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of GPUs to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_classifier'", ",", "default", "=", "''", ",", "help", "=", "\"path to pretrain classifier (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "default", "=", "''", ",", "help", "=", "\"path to netG (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netD2'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--Encoder'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netG_name'", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--netD_name'", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--outf'", ",", "default", "=", "'./checkpoint/'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--outname'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--save_after'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--val_every'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--manualSeed'", ",", "type", "=", "int", ",", "help", "=", "'manual seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--nclass_all'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder_layer_sizes'", ",", "type", "=", "list", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "1024", ",", "300", "]", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder_layer_sizes'", ",", "type", "=", "list", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "512", ",", "1024", "]", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--ud_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--vae_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--kshot'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--splitid'", ",", "default", "=", "'1'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--novel_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args_gen.args_eval": [[406, 623], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["", "def", "args_eval", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Explainable Audio Visual Low Shot Learning [Evaluation]\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load_path_stage_A\"", ",", "\n", "help", "=", "\"Path to experiment log folder of stage A\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load_path_stage_B\"", ",", "\n", "help", "=", "\"Path to experiment log folder of stage B\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "\n", "\"\"\"\n    parser.add_argument(\n        \"--weights_path\",\n        help=\"Path to trained model weights. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n\n    parser.add_argument(\n        \"--weights_path_stage_A\",\n        help=\"Path to trained model weights from stage A. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n\n    parser.add_argument(\n        \"--weights_path_stage_B\",\n        help=\"Path to trained model weights from stage B. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n    \"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_name\"", ",", "\n", "help", "=", "\"Evaluation name to be displayed in the final output string\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "help", "=", "\"Name of the dataset to use\"", ",", "\n", "choices", "=", "[", "\"AudioSetZSL\"", ",", "\"VGGSound\"", ",", "\"UCF\"", ",", "\"ActivityNet\"", "]", ",", "\n", "default", "=", "\"AudioSetZSL\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bs\"", ",", "\n", "help", "=", "\"Batch size\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_workers\"", ",", "\n", "help", "=", "\"Number of dataloader workers\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pin_memory\"", ",", "\n", "help", "=", "\"Flag for pin_memory in dataloader\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--drop_last\"", ",", "\n", "help", "=", "\"Drop last batch in dataloader\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "help", "=", "\"Device to run on.\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "\n", "default", "=", "\"cuda\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--baseline\"", ",", "\n", "help", "=", "\"Flag for setting baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--audio_baseline\"", ",", "\n", "help", "=", "\"Flag to use the audio baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--video_baseline\"", ",", "\n", "help", "=", "\"Flag to use the video baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--concatenated_baseline\"", ",", "\n", "help", "=", "\"Flag to use the concatenated baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model\"", ",", "\n", "help", "=", "\"Flag to use the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_early_fusion\"", ",", "\n", "help", "=", "\"Flag to use the early fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_middle_fusion\"", ",", "\n", "help", "=", "\"Flag to set the middle fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_attention\"", ",", "\n", "help", "=", "\"Flag to set the attention to the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ale\"", ",", "\n", "help", "=", "\"Flag to set the ale\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--devise\"", ",", "\n", "help", "=", "\"Flag to set the devise model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sje\"", ",", "\n", "help", "=", "\"Flag to se the sje model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apn\"", ",", "\n", "help", "=", "\"flag to set apn model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_performances\"", ",", "\n", "help", "=", "\"Save class performances to disk\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'FLO'", ",", "help", "=", "'FLO'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "default", "=", "'data/'", ",", "help", "=", "'path to dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--matdataset'", ",", "default", "=", "True", ",", "help", "=", "'Data in matlab format'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_embedding'", ",", "default", "=", "'res101'", ")", "\n", "parser", ".", "add_argument", "(", "'--class_embedding'", ",", "default", "=", "'att'", ")", "\n", "parser", ".", "add_argument", "(", "'--syn_num'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'number features to generate per class'", ")", "\n", "parser", ".", "add_argument", "(", "'--gfsl'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_att10'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_att'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'enable generalized zero-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocessing'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'enbale MinMaxScaler on visual features'", ")", "\n", "parser", ".", "add_argument", "(", "'--standardization'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--validation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'enable cross validation mode'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "type", "=", "int", ",", "help", "=", "'number of data loading workers'", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--resSize'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "'size of visual features'", ")", "\n", "parser", ".", "add_argument", "(", "'--attSize'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'size of semantic features'", ")", "\n", "parser", ".", "add_argument", "(", "'--nz'", ",", "type", "=", "int", ",", "default", "=", "312", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_size'", ",", "type", "=", "int", ",", "default", "=", "312", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngh'", ",", "type", "=", "int", ",", "default", "=", "4096", ",", "help", "=", "'size of the hidden units in generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndh'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "'size of the hidden units in discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepoch'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "'number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepoch_classifier'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--critic_iter'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'critic iteration, following WGAN-GP'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda1'", ",", "type", "=", "float", ",", "default", "=", "10", ",", "help", "=", "'gradient penalty regularizer, following WGAN-GP'", ")", "\n", "parser", ".", "add_argument", "(", "'--cls_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_weight'", ",", "type", "=", "float", ",", "default", "=", "100000", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate to train GANs '", ")", "\n", "parser", ".", "add_argument", "(", "'--classifier_lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate to train softmax classifier'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'beta1 for adam. default=0.5'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "help", "=", "'enables cuda'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngpu'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of GPUs to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_classifier'", ",", "default", "=", "''", ",", "help", "=", "\"path to pretrain classifier (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "default", "=", "''", ",", "help", "=", "\"path to netG (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netD2'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--Encoder'", ",", "default", "=", "''", ",", "help", "=", "\"path to netD (to continue training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--netG_name'", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--netD_name'", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--outf'", ",", "default", "=", "'./checkpoint/'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--outname'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--save_after'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--val_every'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--manualSeed'", ",", "type", "=", "int", ",", "help", "=", "'manual seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--nclass_all'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder_layer_sizes'", ",", "type", "=", "list", ",", "default", "=", "[", "2048", ",", "1024", "]", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder_layer_sizes'", ",", "type", "=", "list", ",", "default", "=", "[", "1024", ",", "2048", "]", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--ud_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--vae_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight of the classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--kshot'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of all classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--splitid'", ",", "default", "=", "'1'", ",", "help", "=", "'folder to output data and model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--novel_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'size of the latent z vector'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.__init__": [[29, 33], ["open", "open.close"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "filename", "=", "filename", "\n", "f", "=", "open", "(", "self", ".", "filename", "+", "'.log'", ",", "\"a\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write": [[34, 38], ["open", "open.write", "open.close"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write"], ["", "def", "write", "(", "self", ",", "message", ")", ":", "\n", "        ", "f", "=", "open", "(", "self", ".", "filename", "+", "'.log'", ",", "\"a\"", ")", "\n", "f", ".", "write", "(", "message", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.__init__": [[41, 50], ["util_fewshot.DATA_LOADER.read_matimagenet", "util_fewshot.DATA_LOADER.read_matdataset"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.read_matimagenet", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.read_matdataset"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "matdataset", ":", "\n", "            ", "if", "opt", ".", "dataset", "==", "'imageNet1K'", "or", "opt", ".", "dataset", "==", "'smallImageNet1K'", ":", "\n", "                ", "self", ".", "read_matimagenet", "(", "opt", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "read_matdataset", "(", "opt", ")", "\n", "", "", "self", ".", "index_in_epoch", "=", "0", "\n", "self", ".", "epochs_completed", "=", "0", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.read_h5dataset": [[52, 84], ["h5py.File", "h5py.File.close", "h5py.File", "h5py.File.close", "numpy.unique", "numpy.unique", "util_fewshot.DATA_LOADER.seenclasses.size"], "methods", ["None"], ["", "def", "read_h5dataset", "(", "self", ",", "opt", ")", ":", "\n", "# read image feature", "\n", "        ", "fid", "=", "h5py", ".", "File", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "image_embedding", "+", "\".hdf5\"", ",", "'r'", ")", "\n", "feature", "=", "fid", "[", "'feature'", "]", "[", "(", ")", "]", "\n", "label", "=", "fid", "[", "'label'", "]", "[", "(", ")", "]", "\n", "trainval_loc", "=", "fid", "[", "'trainval_loc'", "]", "[", "(", ")", "]", "\n", "train_loc", "=", "fid", "[", "'train_loc'", "]", "[", "(", ")", "]", "\n", "val_unseen_loc", "=", "fid", "[", "'val_unseen_loc'", "]", "[", "(", ")", "]", "\n", "test_seen_loc", "=", "fid", "[", "'test_seen_loc'", "]", "[", "(", ")", "]", "\n", "test_unseen_loc", "=", "fid", "[", "'test_unseen_loc'", "]", "[", "(", ")", "]", "\n", "fid", ".", "close", "(", ")", "\n", "# read attributes", "\n", "fid", "=", "h5py", ".", "File", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "class_embedding", "+", "\".hdf5\"", ",", "'r'", ")", "\n", "self", ".", "attribute", "=", "fid", "[", "'attribute'", "]", "[", "(", ")", "]", "\n", "fid", ".", "close", "(", ")", "\n", "\n", "if", "not", "opt", ".", "validation", ":", "\n", "            ", "self", ".", "train_feature", "=", "feature", "[", "trainval_loc", "]", "\n", "self", ".", "train_label", "=", "label", "[", "trainval_loc", "]", "\n", "self", ".", "test_unseen_feature", "=", "feature", "[", "test_unseen_loc", "]", "\n", "self", ".", "test_unseen_label", "=", "label", "[", "test_unseen_loc", "]", "\n", "self", ".", "test_seen_feature", "=", "feature", "[", "test_seen_loc", "]", "\n", "self", ".", "test_seen_label", "=", "label", "[", "test_seen_loc", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_feature", "=", "feature", "[", "train_loc", "]", "\n", "self", ".", "train_label", "=", "label", "[", "train_loc", "]", "\n", "self", ".", "test_unseen_feature", "=", "feature", "[", "val_unseen_loc", "]", "\n", "self", ".", "test_unseen_label", "=", "label", "[", "val_unseen_loc", "]", "\n", "\n", "", "self", ".", "seenclasses", "=", "np", ".", "unique", "(", "self", ".", "train_label", ")", "\n", "self", ".", "unseenclasses", "=", "np", ".", "unique", "(", "self", ".", "test_unseen_label", ")", "\n", "self", ".", "nclasses", "=", "self", ".", "seenclasses", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.read_matimagenet": [[85, 166], ["scipy.loadmat", "torch.from_numpy().float", "scipy.loadmat", "numpy.array().astype().squeeze", "numpy.sort", "numpy.array().astype", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "util_fewshot.DATA_LOADER.baseclasses.size", "util_fewshot.DATA_LOADER.novelclasses.size", "torch.cat", "util_fewshot.DATA_LOADER.train_class.size", "print", "sklearn.preprocessing.MinMaxScaler", "h5py.File", "sklearn.preprocessing.MinMaxScaler.fit_transform", "sklearn.preprocessing.MinMaxScaler.transform", "h5py.File.close", "h5py.File", "numpy.array", "numpy.array", "h5py.File.close", "torch.cat", "sample_idx_split[].reshape", "round", "numpy.concatenate", "util_fewshot.DATA_LOADER.train_feature.size", "util_fewshot.DATA_LOADER.test_novel_feature.size", "numpy.array", "numpy.array().astype().squeeze", "numpy.array", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "numpy.array().astype", "numpy.array", "numpy.where", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.in1d", "len", "numpy.concatenate", "numpy.concatenate", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array().astype().squeeze", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "read_matimagenet", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "preprocessing", ":", "\n", "            ", "print", "(", "'MinMaxScaler...'", ")", "\n", "scaler", "=", "preprocessing", ".", "MinMaxScaler", "(", ")", "\n", "matcontent", "=", "h5py", ".", "File", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "image_embedding", "+", "\".mat\"", ",", "'r'", ")", "\n", "train_feature_all", "=", "scaler", ".", "fit_transform", "(", "np", ".", "array", "(", "matcontent", "[", "'train_features'", "]", ")", ")", "\n", "train_label_all", "=", "np", ".", "array", "(", "matcontent", "[", "'train_labels'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "test_feature", "=", "scaler", ".", "transform", "(", "np", ".", "array", "(", "matcontent", "[", "'test_features'", "]", ")", ")", "\n", "test_label", "=", "np", ".", "array", "(", "matcontent", "[", "'test_labels'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "matcontent", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "matcontent", "=", "h5py", ".", "File", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "image_embedding", "+", "\".mat\"", ",", "'r'", ")", "\n", "train_feature_all", "=", "np", ".", "array", "(", "matcontent", "[", "'train_features'", "]", ")", "\n", "train_label_all", "=", "np", ".", "array", "(", "matcontent", "[", "'train_labels'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "test_feature", "=", "np", ".", "array", "(", "matcontent", "[", "'test_features'", "]", ")", "\n", "test_label", "=", "np", ".", "array", "(", "matcontent", "[", "'test_labels'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "matcontent", ".", "close", "(", ")", "\n", "\n", "", "matcontent", "=", "sio", ".", "loadmat", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "class_embedding", "+", "\"_fewshot_splits.mat\"", ")", "\n", "self", ".", "attribute", "=", "torch", ".", "from_numpy", "(", "matcontent", "[", "'w2v'", "]", ")", ".", "float", "(", ")", "\n", "if", "opt", ".", "validation", ":", "\n", "            ", "self", ".", "baseclasses", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "matcontent", "[", "'base_classes1'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "self", ".", "novelclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'novel_classes1'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "test_idx_baseclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'idx_baseclasses1'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "test_idx_novelclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'idx_novelclasses1'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "", "else", ":", "\n", "            ", "baseclasses2", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "matcontent", "[", "'base_classes2'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "self", ".", "baseclasses2", "=", "baseclasses2", "\n", "baseclasses1", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "matcontent", "[", "'base_classes1'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "self", ".", "baseclasses", "=", "torch", ".", "cat", "(", "(", "baseclasses1", ",", "baseclasses2", ")", ",", "0", ")", "\n", "self", ".", "test_baseclasses", "=", "baseclasses2", "\n", "self", ".", "novelclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'novel_classes2'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "test_idx_baseclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'test_base2_loc'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "test_idx_novelclasses", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "array", "(", "matcontent", "[", "'test_novel2_loc'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", ")", ".", "long", "(", ")", "-", "1", "\n", "\n", "", "matcontent", "=", "sio", ".", "loadmat", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/sample_idx_split\"", "+", "opt", ".", "splitid", "+", "\".mat\"", ")", "\n", "sample_idx_split", "=", "np", ".", "array", "(", "matcontent", "[", "'sample_idx_split'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "\n", "self", ".", "novel_idx", "=", "np", ".", "sort", "(", "sample_idx_split", "[", "self", ".", "novelclasses", ",", ":", "opt", ".", "kshot", "]", ".", "reshape", "(", "-", "1", ")", ")", "\n", "base_idx", "=", "np", ".", "array", "(", "[", "]", ")", ".", "astype", "(", "int", ")", "\n", "for", "c", "in", "self", ".", "baseclasses", ":", "\n", "            ", "cid", "=", "np", ".", "where", "(", "np", ".", "in1d", "(", "train_label_all", ",", "c", ")", ")", "[", "0", "]", "\n", "num_select", "=", "round", "(", "len", "(", "cid", ")", "*", "opt", ".", "data_portion", ")", "\n", "base_idx", "=", "np", ".", "concatenate", "(", "(", "base_idx", ",", "cid", "[", ":", "num_select", "]", ")", ")", "\n", "", "self", ".", "base_idx", "=", "base_idx", "\n", "# self.base_idx = np.where(np.in1d(train_label_all, self.baseclasses))[0]", "\n", "\n", "train_base_feature", "=", "train_feature_all", "[", "self", ".", "base_idx", ",", ":", "]", "\n", "train_novel_feature", "=", "train_feature_all", "[", "self", ".", "novel_idx", ",", ":", "]", "\n", "train_base_label", "=", "train_label_all", "[", "self", ".", "base_idx", "]", "\n", "train_novel_label", "=", "train_label_all", "[", "self", ".", "novel_idx", "]", "\n", "test_base_feature", "=", "test_feature", "[", "test_idx_baseclasses", ",", ":", "]", "\n", "test_base_label", "=", "test_label", "[", "test_idx_baseclasses", "]", "\n", "test_novel_feature", "=", "test_feature", "[", "test_idx_novelclasses", ",", ":", "]", "\n", "test_novel_label", "=", "test_label", "[", "test_idx_novelclasses", "]", "\n", "\n", "self", ".", "test_base_feature", "=", "torch", ".", "from_numpy", "(", "test_base_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "test_base_label", "=", "torch", ".", "from_numpy", "(", "test_base_label", ")", ".", "long", "(", ")", "\n", "self", ".", "test_novel_feature", "=", "torch", ".", "from_numpy", "(", "test_novel_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "test_novel_label", "=", "torch", ".", "from_numpy", "(", "test_novel_label", ")", ".", "long", "(", ")", "\n", "\n", "self", ".", "test_feature", "=", "torch", ".", "from_numpy", "(", "test_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "test_label", "=", "torch", ".", "from_numpy", "(", "test_label", ")", ".", "long", "(", ")", "\n", "\n", "self", ".", "train_feature", "=", "torch", ".", "from_numpy", "(", "np", ".", "concatenate", "(", "(", "train_base_feature", ",", "train_novel_feature", ")", ",", "axis", "=", "0", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "train_label", "=", "torch", ".", "from_numpy", "(", "np", ".", "concatenate", "(", "(", "train_base_label", ",", "train_novel_label", ")", ",", "axis", "=", "0", ")", ")", ".", "long", "(", ")", "\n", "self", ".", "train_base_feature", "=", "torch", ".", "from_numpy", "(", "train_base_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "train_base_label", "=", "torch", ".", "from_numpy", "(", "train_base_label", ")", ".", "long", "(", ")", "\n", "self", ".", "train_novel_feature", "=", "torch", ".", "from_numpy", "(", "train_novel_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "train_novel_label", "=", "torch", ".", "from_numpy", "(", "train_novel_label", ")", ".", "long", "(", ")", "\n", "self", ".", "ntrain", "=", "self", ".", "train_feature", ".", "size", "(", ")", "[", "0", "]", "\n", "self", ".", "ntest", "=", "self", ".", "test_novel_feature", ".", "size", "(", ")", "[", "0", "]", "\n", "self", ".", "total_baseclass", "=", "self", ".", "baseclasses", ".", "size", "(", "0", ")", "\n", "self", ".", "total_novelclass", "=", "self", ".", "novelclasses", ".", "size", "(", "0", ")", "\n", "self", ".", "train_class", "=", "torch", ".", "cat", "(", "(", "self", ".", "baseclasses", ",", "self", ".", "novelclasses", ")", ",", "0", ")", "\n", "self", ".", "ntrain_class", "=", "self", ".", "train_class", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.read_matdataset": [[167, 274], ["scipy.loadmat", "scipy.loadmat", "torch.from_numpy().float", "numpy.unique", "scipy.loadmat", "numpy.sort", "numpy.concatenate().astype", "torch.cat", "torch.cat", "torch.from_numpy", "torch.from_numpy", "torch.cat", "util_fewshot.DATA_LOADER.novelclasses.size", "matcontent[].astype().squeeze", "matcontent[].squeeze", "matcontent[].squeeze", "matcontent[].squeeze", "numpy.array().astype().squeeze", "sample_idx_split[].reshape", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "numpy.unique", "numpy.unique", "util_fewshot.DATA_LOADER.train_feature.size", "util_fewshot.DATA_LOADER.test_novel_feature.size", "util_fewshot.DATA_LOADER.baseclasses.size", "util_fewshot.DATA_LOADER.novelclasses.size", "torch.from_numpy", "numpy.concatenate", "sklearn.preprocessing.MinMaxScaler.fit_transform", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "torch.from_numpy().float", "util_fewshot.DATA_LOADER.train_feature.max", "util_fewshot.DATA_LOADER.train_feature.mul_", "torch.from_numpy().long", "torch.from_numpy().float", "util_fewshot.DATA_LOADER.test_novel_feature.mul_", "torch.from_numpy().long", "torch.from_numpy().float", "util_fewshot.DATA_LOADER.test_base_feature.mul_", "torch.from_numpy().long", "torch.from_numpy().float", "util_fewshot.DATA_LOADER.train_novel_feature.mul_", "torch.from_numpy().long", "torch.from_numpy().float", "util_fewshot.DATA_LOADER.train_base_feature.mul_", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().long", "util_fewshot.DATA_LOADER.train_base_label.numpy", "util_fewshot.DATA_LOADER.train_novel_label.numpy", "matcontent[].astype", "numpy.array().astype", "print", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.MinMaxScaler", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array"], "methods", ["None"], ["", "def", "read_matdataset", "(", "self", ",", "opt", ")", ":", "\n", "        ", "matcontent", "=", "sio", ".", "loadmat", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "image_embedding", "+", "\".mat\"", ")", "\n", "feature", "=", "matcontent", "[", "'features'", "]", ".", "T", "\n", "label", "=", "matcontent", "[", "'labels'", "]", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "matcontent", "=", "sio", ".", "loadmat", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/\"", "+", "opt", ".", "class_embedding", "+", "\"_splits.mat\"", ")", "\n", "self", ".", "attribute", "=", "torch", ".", "from_numpy", "(", "matcontent", "[", "'att'", "]", ".", "T", ")", ".", "float", "(", ")", "\n", "# numpy array index starts from 0, matlab starts from 1", "\n", "train_base_loc", "=", "matcontent", "[", "'train_base_loc'", "]", ".", "squeeze", "(", ")", "-", "1", "\n", "test_base_loc", "=", "matcontent", "[", "'test_base_loc'", "]", ".", "squeeze", "(", ")", "-", "1", "\n", "test_novel_loc", "=", "matcontent", "[", "'test_novel_loc'", "]", ".", "squeeze", "(", ")", "-", "1", "\n", "novelclasses", "=", "np", ".", "unique", "(", "label", "[", "test_novel_loc", "]", ")", "\n", "\n", "matcontent", "=", "sio", ".", "loadmat", "(", "opt", ".", "dataroot", "+", "\"/\"", "+", "opt", ".", "dataset", "+", "\"/sample_idx_split\"", "+", "opt", ".", "splitid", "+", "\".mat\"", ")", "\n", "sample_idx_split", "=", "np", ".", "array", "(", "matcontent", "[", "'sample_idx_split'", "]", ")", ".", "astype", "(", "int", ")", ".", "squeeze", "(", ")", "-", "1", "\n", "train_novel_loc", "=", "np", ".", "sort", "(", "sample_idx_split", "[", "novelclasses", ",", ":", "opt", ".", "kshot", "]", ".", "reshape", "(", "-", "1", ")", ")", "\n", "train_loc", "=", "np", ".", "concatenate", "(", "(", "train_base_loc", ",", "train_novel_loc", ")", ")", ".", "astype", "(", "int", ")", "\n", "num_train_base_loc", "=", "train_base_loc", ".", "shape", "[", "0", "]", "\n", "\n", "# if opt.kshot > 0:", "\n", "#     novelclasses = np.unique(label[test_unseen_loc])", "\n", "#     kshot_novel_loc = np.array([]);", "\n", "#     test_novel_loc = np.array([])", "\n", "#     for c in novelclasses:", "\n", "#         idx_c = np.where(label == c)", "\n", "#         idx_c = np.array(idx_c[0])", "\n", "#         perm = np.random.permutation(len(idx_c))", "\n", "#         kshot_novel_loc = np.concatenate((kshot_novel_loc, idx_c[perm[0:opt.kshot]])).astype(int);", "\n", "#         test_novel_loc = np.concatenate((test_novel_loc, idx_c[perm[opt.kshot:]])).astype(int);", "\n", "#", "\n", "#     trainval_loc = np.concatenate((trainval_loc, kshot_unseen_loc)).astype(int)", "\n", "\n", "# if opt.image_att10:", "\n", "#     fid = h5py.File(opt.dataroot + \"/\" + opt.dataset + \"/image_text10.h5\", 'r')", "\n", "#     image_att = fid['text_embedding'][()]", "\n", "#     image_att = torch.from_numpy(image_att)", "\n", "#     image_att = image_att.view(-1,10,opt.attSize)", "\n", "#     #idx = torch.LongTensor(len(trainval_loc)*10)", "\n", "#     #count = 0", "\n", "#     #for loc in trainval_loc:", "\n", "#     #    for i in range(10):", "\n", "#     #        idx[count] = loc.item()*10 + i", "\n", "#     #        count = count + 1", "\n", "#     loc = torch.LongTensor(len(trainval_loc))", "\n", "#     for i in range(len(trainval_loc)):", "\n", "#         loc[i] = trainval_loc[i].item()", "\n", "#     self.train_att = image_att[loc]", "\n", "#     loc2 = torch.LongTensor(len(test_unseen_loc))", "\n", "#     for i in range(len(test_unseen_loc)):", "\n", "#         loc2[i] = test_unseen_loc[i].item()", "\n", "#     self.test_att = image_att[loc2]", "\n", "#     fid.close()", "\n", "\n", "if", "not", "opt", ".", "validation", ":", "\n", "            ", "if", "opt", ".", "preprocessing", ":", "\n", "                ", "if", "opt", ".", "standardization", ":", "\n", "                    ", "print", "(", "'standardization...'", ")", "\n", "scaler", "=", "preprocessing", ".", "StandardScaler", "(", ")", "\n", "", "else", ":", "\n", "                    ", "scaler", "=", "preprocessing", ".", "MinMaxScaler", "(", ")", "\n", "\n", "", "_train_feature", "=", "scaler", ".", "fit_transform", "(", "feature", "[", "train_loc", "]", ")", "\n", "_train_novel_feature", "=", "scaler", ".", "transform", "(", "feature", "[", "train_novel_loc", "]", ")", "\n", "_train_base_feature", "=", "scaler", ".", "transform", "(", "feature", "[", "train_base_loc", "]", ")", "\n", "_test_base_feature", "=", "scaler", ".", "transform", "(", "feature", "[", "test_base_loc", "]", ")", "\n", "_test_novel_feature", "=", "scaler", ".", "transform", "(", "feature", "[", "test_novel_loc", "]", ")", "\n", "self", ".", "train_feature", "=", "torch", ".", "from_numpy", "(", "_train_feature", ")", ".", "float", "(", ")", "\n", "mx", "=", "self", ".", "train_feature", ".", "max", "(", ")", "\n", "self", ".", "train_feature", ".", "mul_", "(", "1", "/", "mx", ")", "\n", "self", ".", "train_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "train_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "test_novel_feature", "=", "torch", ".", "from_numpy", "(", "_test_novel_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "test_novel_feature", ".", "mul_", "(", "1", "/", "mx", ")", "\n", "self", ".", "test_novel_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "test_novel_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "test_base_feature", "=", "torch", ".", "from_numpy", "(", "_test_base_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "test_base_feature", ".", "mul_", "(", "1", "/", "mx", ")", "\n", "self", ".", "test_base_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "test_base_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "train_novel_feature", "=", "torch", ".", "from_numpy", "(", "_train_novel_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "train_novel_feature", ".", "mul_", "(", "1", "/", "mx", ")", "\n", "self", ".", "train_novel_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "train_novel_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "train_base_feature", "=", "torch", ".", "from_numpy", "(", "_train_base_feature", ")", ".", "float", "(", ")", "\n", "self", ".", "train_base_feature", ".", "mul_", "(", "1", "/", "mx", ")", "\n", "self", ".", "train_base_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "train_base_loc", "]", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "train_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "trainval_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "train_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "trainval_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "test_novel_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "test_unseen_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "test_novel_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "test_unseen_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "test_base_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "test_seen_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "test_base_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "test_seen_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "train_novel_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "kshot_unseen_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "train_novel_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "kshot_unseen_loc", "]", ")", ".", "long", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "train_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "train_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "train_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "train_loc", "]", ")", ".", "long", "(", ")", "\n", "self", ".", "test_novel_feature", "=", "torch", ".", "from_numpy", "(", "feature", "[", "val_unseen_loc", "]", ")", ".", "float", "(", ")", "\n", "self", ".", "test_novel_label", "=", "torch", ".", "from_numpy", "(", "label", "[", "val_unseen_loc", "]", ")", ".", "long", "(", ")", "\n", "\n", "", "self", ".", "train_feature", "[", "num_train_base_loc", ":", "]", "=", "opt", ".", "novel_weight", "*", "self", ".", "train_feature", "[", "num_train_base_loc", ":", "]", "\n", "self", ".", "test_feature", "=", "torch", ".", "cat", "(", "(", "self", ".", "test_base_feature", ",", "self", ".", "test_novel_feature", ")", ",", "0", ")", "\n", "self", ".", "test_label", "=", "torch", ".", "cat", "(", "(", "self", ".", "test_base_label", ",", "self", ".", "test_novel_label", ")", ",", "0", ")", "\n", "self", ".", "baseclasses", "=", "torch", ".", "from_numpy", "(", "np", ".", "unique", "(", "self", ".", "train_base_label", ".", "numpy", "(", ")", ")", ")", "\n", "self", ".", "test_baseclasses", "=", "self", ".", "baseclasses", "\n", "self", ".", "novelclasses", "=", "torch", ".", "from_numpy", "(", "np", ".", "unique", "(", "self", ".", "train_novel_label", ".", "numpy", "(", ")", ")", ")", "\n", "self", ".", "ntrain", "=", "self", ".", "train_feature", ".", "size", "(", ")", "[", "0", "]", "\n", "self", ".", "ntest", "=", "self", ".", "test_novel_feature", ".", "size", "(", ")", "[", "0", "]", "\n", "self", ".", "ntrain_class", "=", "self", ".", "baseclasses", ".", "size", "(", "0", ")", "+", "self", ".", "novelclasses", ".", "size", "(", "0", ")", "\n", "self", ".", "train_class", "=", "torch", ".", "cat", "(", "(", "self", ".", "baseclasses", ",", "self", ".", "novelclasses", ")", ",", "0", ")", "\n", "self", ".", "ntest_class", "=", "self", ".", "novelclasses", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch_one_class": [[275, 289], ["util_fewshot.DATA_LOADER.train_label.eq().nonzero().squeeze", "torch.randperm", "torch.randperm", "util_fewshot.DATA_LOADER.size", "util_fewshot.DATA_LOADER.train_label.eq().nonzero", "util_fewshot.DATA_LOADER.train_label.eq"], "methods", ["None"], ["", "def", "next_batch_one_class", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "index_in_epoch", "==", "self", ".", "ntrain_class", ":", "\n", "            ", "self", ".", "index_in_epoch", "=", "0", "\n", "perm", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain_class", ")", "\n", "self", ".", "train_class", "[", "perm", "]", "=", "self", ".", "train_class", "[", "perm", "]", "\n", "\n", "", "iclass", "=", "self", ".", "train_class", "[", "self", ".", "index_in_epoch", "]", "\n", "idx", "=", "self", ".", "train_label", ".", "eq", "(", "iclass", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "perm", "=", "torch", ".", "randperm", "(", "idx", ".", "size", "(", "0", ")", ")", "\n", "idx", "=", "idx", "[", "perm", "]", "\n", "iclass_feature", "=", "self", ".", "train_feature", "[", "idx", "]", "\n", "iclass_label", "=", "self", ".", "train_label", "[", "idx", "]", "\n", "self", ".", "index_in_epoch", "+=", "1", "\n", "return", "iclass_feature", "[", "0", ":", "batch_size", "]", ",", "iclass_label", "[", "0", ":", "batch_size", "]", ",", "self", ".", "attribute", "[", "iclass_label", "[", "0", ":", "batch_size", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch_unpair_test": [[290, 300], ["torch.randperm", "torch.randperm"], "methods", ["None"], ["", "def", "next_batch_unpair_test", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx1", "=", "torch", ".", "randperm", "(", "self", ".", "ntest", ")", "[", "0", ":", "batch_size", "]", "\n", "idx2", "=", "torch", ".", "randperm", "(", "self", ".", "ntest", ")", "[", "0", ":", "batch_size", "]", "\n", "batch_feature", "=", "self", ".", "test_novel_feature", "[", "idx1", "]", "\n", "batch_label", "=", "self", ".", "test_novel_label", "[", "idx2", "]", "\n", "if", "self", ".", "opt", ".", "image_att", ":", "\n", "            ", "batch_att", "=", "self", ".", "test_att", "[", "idx2", "]", "\n", "", "else", ":", "\n", "            ", "batch_att", "=", "self", ".", "attribute", "[", "batch_label", "]", "\n", "", "return", "batch_feature", ",", "batch_label", ",", "batch_att", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch": [[301, 316], ["torch.randperm", "torch.FloatTensor", "range", "torch.randperm", "batch_att[].norm"], "methods", ["None"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain", ")", "[", "0", ":", "batch_size", "]", "\n", "batch_feature", "=", "self", ".", "train_feature", "[", "idx", "]", "\n", "batch_label", "=", "self", ".", "train_label", "[", "idx", "]", "\n", "if", "self", ".", "opt", ".", "image_att", ":", "\n", "            ", "batch_att", "=", "self", ".", "train_att", "[", "idx", "]", "\n", "", "elif", "self", ".", "opt", ".", "image_att10", ":", "\n", "            ", "batch_att", "=", "torch", ".", "FloatTensor", "(", "batch_size", ",", "self", ".", "opt", ".", "attSize", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "idx2", "=", "torch", ".", "randperm", "(", "10", ")", "[", "0", "]", "\n", "batch_att", "[", "i", "]", "=", "self", ".", "train_att", "[", "idx", "[", "i", "]", "]", "[", "idx2", "]", "\n", "batch_att", "[", "i", "]", "=", "batch_att", "[", "i", "]", "/", "batch_att", "[", "i", "]", ".", "norm", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_att", "=", "self", ".", "attribute", "[", "batch_label", "]", "\n", "", "return", "batch_feature", ",", "batch_label", ",", "batch_att", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.DATA_LOADER.next_batch_uniform_class": [[318, 336], ["torch.LongTensor", "range", "torch.FloatTensor", "torch.LongTensor", "torch.FloatTensor", "range", "util_fewshot.DATA_LOADER.train_feature.size", "util_fewshot.DATA_LOADER.attribute.size", "util_fewshot.DATA_LOADER.train_label.eq().nonzero().squeeze", "torch.randperm", "torch.randperm", "util_fewshot.DATA_LOADER.train_label.eq().nonzero", "util_fewshot.DATA_LOADER.size", "util_fewshot.DATA_LOADER.train_label.eq"], "methods", ["None"], ["", "def", "next_batch_uniform_class", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "batch_class", "=", "torch", ".", "LongTensor", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "torch", ".", "randperm", "(", "self", ".", "ntrain_class", ")", "[", "0", "]", "\n", "batch_class", "[", "i", "]", "=", "self", ".", "train_class", "[", "idx", "]", "\n", "\n", "", "batch_feature", "=", "torch", ".", "FloatTensor", "(", "batch_size", ",", "self", ".", "train_feature", ".", "size", "(", "1", ")", ")", "\n", "batch_label", "=", "torch", ".", "LongTensor", "(", "batch_size", ")", "\n", "batch_att", "=", "torch", ".", "FloatTensor", "(", "batch_size", ",", "self", ".", "attribute", ".", "size", "(", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "iclass", "=", "batch_class", "[", "i", "]", "\n", "idx_iclass", "=", "self", ".", "train_label", ".", "eq", "(", "iclass", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "idx_in_iclass", "=", "torch", ".", "randperm", "(", "idx_iclass", ".", "size", "(", "0", ")", ")", "[", "0", "]", "\n", "idx_file", "=", "idx_iclass", "[", "idx_in_iclass", "]", "\n", "batch_feature", "[", "i", "]", "=", "self", ".", "train_feature", "[", "idx_file", "]", "\n", "batch_label", "[", "i", "]", "=", "self", ".", "train_label", "[", "idx_file", "]", "\n", "batch_att", "[", "i", "]", "=", "self", ".", "attribute", "[", "batch_label", "[", "i", "]", "]", "\n", "", "return", "batch_feature", ",", "batch_label", ",", "batch_att", "", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.weights_init": [[10, 18], ["classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_"], "function", ["None"], ["def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.map_label": [[20, 26], ["torch.LongTensor", "range", "label.size", "classes.size"], "function", ["None"], ["", "", "def", "map_label", "(", "label", ",", "classes", ")", ":", "\n", "    ", "mapped_label", "=", "torch", ".", "LongTensor", "(", "label", ".", "size", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "classes", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "mapped_label", "[", "label", "==", "classes", "[", "i", "]", "]", "=", "i", "\n", "\n", "", "return", "mapped_label", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features": [[17, 24], ["h5py.File", "str", "list"], "function", ["None"], ["def", "read_features", "(", "path", ")", ":", "\n", "    ", "hf", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "# keys = list(hf.keys())", "\n", "data", "=", "hf", "[", "'data'", "]", "\n", "url", "=", "[", "str", "(", "u", ",", "'utf-8'", ")", "for", "u", "in", "list", "(", "hf", "[", "'video_urls'", "]", ")", "]", "\n", "\n", "return", "data", ",", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.fix_seeds": [[26, 30], ["torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed"], "function", ["None"], ["", "def", "fix_seeds", "(", "seed", "=", "42", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.setup_experiment": [[32, 57], ["log_dir.mkdir", "pickle.dump", "src.logger.PD_Stats", "src.logger.PD_Stats", "src.logger.create_logger", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "str", "datetime.datetime.now().strftime", "socket.gethostname", "log_dir.resolve", "sorted", "datetime.datetime.now", "str", "dict().items", "dict", "vars"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.create_logger"], ["", "def", "setup_experiment", "(", "args", ",", "*", "stats", ")", ":", "\n", "    ", "if", "args", ".", "exp_name", "==", "\"\"", ":", "\n", "        ", "exp_name", "=", "f\"runs/{datetime.now().strftime('%b%d_%H-%M-%S')}_{socket.gethostname()}\"", "\n", "", "else", ":", "\n", "        ", "exp_name", "=", "\"runs/\"", "+", "str", "(", "args", ".", "exp_name", ")", "\n", "#exp_name = \"/mnt/store_runs/\" + str(args.exp_name)", "\n", "", "log_dir", "=", "(", "args", ".", "dump_path", "/", "exp_name", ")", "\n", "log_dir", ".", "mkdir", "(", "parents", "=", "True", ")", "\n", "(", "log_dir", "/", "\"checkpoints\"", ")", ".", "mkdir", "(", ")", "\n", "pickle", ".", "dump", "(", "args", ",", "(", "log_dir", "/", "\"args.pkl\"", ")", ".", "open", "(", "\"wb\"", ")", ")", "\n", "train_stats", "=", "PD_Stats", "(", "log_dir", "/", "\"train_stats.pkl\"", ",", "stats", ")", "\n", "val_stats", "=", "PD_Stats", "(", "log_dir", "/", "\"val_stats.pkl\"", ",", "stats", ")", "\n", "logger", "=", "create_logger", "(", "log_dir", "/", "\"train.log\"", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Start experiment {exp_name}\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"\\n\"", ".", "join", "(", "f\"{k}: {str(v)}\"", "for", "k", ",", "v", "in", "sorted", "(", "dict", "(", "vars", "(", "args", ")", ")", ".", "items", "(", ")", ")", ")", "\n", ")", "\n", "logger", ".", "info", "(", "f\"The experiment will be stored in {log_dir.resolve()}\\n\"", ")", "\n", "logger", ".", "info", "(", "\"\"", ")", "\n", "if", "args", ".", "exp_name", "==", "\"\"", ":", "\n", "        ", "writer", "=", "SummaryWriter", "(", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "exp_name", ")", "\n", "", "return", "logger", ",", "log_dir", ",", "writer", ",", "train_stats", ",", "val_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.setup_evaluation": [[59, 78], ["eval_dir.exists", "src.logger.PD_Stats", "src.logger.create_logger", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "list", "sorted", "eval_dir.resolve", "sorted", "sorted", "str", "dict().items", "str", "dict().items", "dict", "dict", "vars", "vars", "utils.load_args"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.create_logger", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_args"], ["", "def", "setup_evaluation", "(", "args", ",", "*", "stats", ")", ":", "\n", "    ", "eval_dir", "=", "args", ".", "load_path_stage_B", "\n", "assert", "eval_dir", ".", "exists", "(", ")", "\n", "# pickle.dump(args, (eval_dir / \"args.pkl\").open(\"wb\"))", "\n", "test_stats", "=", "PD_Stats", "(", "eval_dir", "/", "\"test_stats.pkl\"", ",", "list", "(", "sorted", "(", "stats", ")", ")", ")", "\n", "logger", "=", "create_logger", "(", "eval_dir", "/", "\"eval.log\"", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Start evaluation {eval_dir}\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"\\n\"", ".", "join", "(", "f\"{k}: {str(v)}\"", "for", "k", ",", "v", "in", "sorted", "(", "dict", "(", "vars", "(", "args", ")", ")", ".", "items", "(", ")", ")", ")", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Loaded configuration {args.load_path_stage_B / 'args.pkl'}\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"\\n\"", ".", "join", "(", "f\"{k}: {str(v)}\"", "for", "k", ",", "v", "in", "sorted", "(", "dict", "(", "vars", "(", "load_args", "(", "args", ".", "load_path_stage_B", ")", ")", ")", ".", "items", "(", ")", ")", ")", "\n", ")", "\n", "logger", ".", "info", "(", "f\"The evaluation will be stored in {eval_dir.resolve()}\\n\"", ")", "\n", "logger", ".", "info", "(", "\"\"", ")", "\n", "\n", "return", "logger", ",", "eval_dir", ",", "test_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model": [[80, 98], ["logging.getLogger", "logging.getLogger.info", "model.state_dict", "optimizer.state_dict", "torch.save", "torch.save"], "function", ["None"], ["", "def", "save_best_model", "(", "epoch", ",", "best_metric", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"\"", ",", "checkpoint", "=", "False", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "f\"Saving model to {log_dir} with {metric} = {best_metric:.4f}\"", ")", "\n", "save_dict", "=", "{", "\n", "\"epoch\"", ":", "epoch", "+", "1", ",", "\n", "\"model\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"metric\"", ":", "metric", "\n", "}", "\n", "if", "checkpoint", ":", "\n", "        ", "torch", ".", "save", "(", "\n", "save_dict", ",", "\n", "log_dir", "/", "f\"{model.__class__.__name__}_{metric}_ckpt_{epoch}.pt\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "save", "(", "\n", "save_dict", ",", "\n", "log_dir", "/", "f\"{model.__class__.__name__}_{metric}.pt\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.check_best_loss": [[101, 109], ["utils.save_best_model", "utils.save_best_model"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model"], ["", "", "def", "check_best_loss", "(", "epoch", ",", "best_loss", ",", "val_loss", ",", "model", ",", "optimizer", ",", "log_dir", ")", ":", "\n", "    ", "if", "not", "best_loss", ":", "\n", "        ", "save_best_model", "(", "epoch", ",", "val_loss", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"loss\"", ")", "\n", "return", "val_loss", "\n", "", "if", "val_loss", "<", "best_loss", ":", "\n", "        ", "best_loss", "=", "val_loss", "\n", "save_best_model", "(", "epoch", ",", "best_loss", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"loss\"", ")", "\n", "", "return", "best_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.check_best_score": [[111, 119], ["utils.save_best_model", "utils.save_best_model"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_best_model"], ["", "def", "check_best_score", "(", "epoch", ",", "best_score", ",", "hm_score", ",", "model", ",", "optimizer", ",", "log_dir", ")", ":", "\n", "    ", "if", "not", "best_score", ":", "\n", "        ", "save_best_model", "(", "epoch", ",", "hm_score", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"score\"", ")", "\n", "return", "hm_score", "\n", "", "if", "hm_score", ">", "best_score", ":", "\n", "        ", "best_score", "=", "hm_score", "\n", "save_best_model", "(", "epoch", ",", "best_score", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"score\"", ")", "\n", "", "return", "best_score", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_model_parameters": [[121, 133], ["logging.getLogger", "model.state_dict", "loaded_state.items", "name.replace.replace", "model.state_dict.keys", "utils..copy_", "logging.getLogger.info"], "function", ["None"], ["", "def", "load_model_parameters", "(", "model", ",", "model_weights", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "loaded_state", "=", "model_weights", "\n", "self_state", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "name", ",", "param", "in", "loaded_state", ".", "items", "(", ")", ":", "\n", "        ", "param", "=", "param", "\n", "if", "'module.'", "in", "name", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "'module.'", ",", "''", ")", "\n", "", "if", "name", "in", "self_state", ".", "keys", "(", ")", ":", "\n", "            ", "self_state", "[", "name", "]", ".", "copy_", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"didnt load \"", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_args": [[135, 137], ["pickle.load"], "function", ["None"], ["", "", "", "def", "load_args", "(", "path", ")", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "(", "path", "/", "\"args.pkl\"", ")", ".", "open", "(", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.cos_dist": [[139, 144], ["torch.mm", "b_norm.transpose", "a.norm", "b.norm"], "function", ["None"], ["", "def", "cos_dist", "(", "a", ",", "b", ")", ":", "\n", "    ", "a_norm", "=", "a", "/", "a", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "b_norm", "=", "b", "/", "b", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "res", "=", "torch", ".", "mm", "(", "a_norm", ",", "b_norm", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset_baseline": [[146, 211], ["data[].to", "data[].to", "data[].to", "data[].to", "dataset.targets.to", "model.eval", "model", "utils.get_best_evaluation", "utils.get_best_evaluation", "tuple", "print", "torch.cat", "model", "torch.cat", "model", "model.get_embeddings", "torch.sqrt", "torch.mean", "torch.var"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.get_embeddings"], ["", "def", "evaluate_dataset_baseline", "(", "dataset", ",", "model", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "\n", "new_model_attention", "=", "False", ",", "model_devise", "=", "False", ",", "apn", "=", "False", ",", "\n", "args", "=", "None", ",", "save_performances", "=", "False", ")", ":", "\n", "    ", "data", "=", "dataset", ".", "all_data", "\n", "data_a", "=", "data", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "data_v", "=", "data", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "data_t", "=", "data", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "data_num", "=", "data", "[", "\"target\"", "]", ".", "to", "(", "device", ")", "\n", "if", "new_model_attention", "==", "True", "or", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_num", ",", "data_t", "\n", ")", "\n", "", "else", ":", "\n", "        ", "all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_t", "\n", ")", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "z_score_inputs", ":", "\n", "            ", "all_data", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "all_data", "]", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Namespace has no fitting attribute. Continuing\"", ")", "\n", "\n", "", "all_targets", "=", "dataset", ".", "targets", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "        ", "outputs_all", "=", "model", "(", "*", "all_data", ")", "\n", "", "elif", "apn", "==", "True", ":", "\n", "        ", "input_features", "=", "torch", ".", "cat", "(", "(", "all_data", "[", "1", "]", ",", "all_data", "[", "0", "]", ")", ",", "1", ")", "\n", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attributes", "=", "model", "(", "input_features", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "pre_attri", "[", "\"final\"", "]", ",", "attributes", ")", "\n", "", "elif", "model_devise", "==", "True", ":", "\n", "        ", "input_features", "=", "torch", ".", "cat", "(", "(", "all_data", "[", "1", "]", ",", "all_data", "[", "0", "]", ")", ",", "1", ")", "\n", "outputs_all", ",", "projected_features", ",", "embeddings", "=", "model", "(", "input_features", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "projected_features", ",", "embeddings", ")", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "        ", "audio_emb", ",", "video_emb", ",", "emb_cls", "=", "model", ".", "get_embeddings", "(", "all_data", "[", "0", "]", ",", "all_data", "[", "1", "]", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "audio_emb", ",", "video_emb", ",", "emb_cls", ")", "\n", "\n", "", "if", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "a_p", ",", "t_p", "=", "outputs_all", "\n", "v_p", "=", "None", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", "=", "outputs_all", "\n", "# a_p = None", "\n", "\n", "", "if", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "audio_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"audio\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "save_performances", "=", "save_performances", ",", "args", "=", "args", ")", "\n", "", "if", "new_model_attention", "==", "True", ":", "\n", "        ", "video_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"video\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "save_performances", "=", "save_performances", ",", "args", "=", "args", ")", "\n", "\n", "", "if", "new_model_attention", "==", "True", ":", "\n", "        ", "return", "{", "\n", "\"audio\"", ":", "video_evaluation", ",", "\n", "\"video\"", ":", "video_evaluation", ",", "\n", "\"both\"", ":", "video_evaluation", "\n", "}", "\n", "", "elif", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "return", "{", "\n", "\"audio\"", ":", "audio_evaluation", ",", "\n", "\"video\"", ":", "audio_evaluation", ",", "\n", "\"both\"", ":", "audio_evaluation", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation": [[215, 328], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.linspace", "numpy.sort", "torch.no_grad", "numpy.argmax", "betas[].item", "numpy.concatenate", "torch.argmin", "torch.argmin.eq().nonzero().flatten", "torch.zeros", "seen_recall_dict.mean", "unseen_recall_dict.mean", "torch.argmin", "torch.argmin.eq().nonzero().flatten", "torch.zeros", "per_class_recall[].mean", "zsl_scores.append", "seen_scores.append", "unseen_scores.append", "hm_scores.append", "per_class_recalls.append", "torch.cdist", "torch.zeros", "torch.zeros", "torch.bincount", "torch.bincount", "len", "utils.save_class_performances", "torch.bincount", "torch.bincount", "len", "per_class_recall[].mean.item", "seen_recall_dict.mean.item", "unseen_recall_dict.mean.item", "hm.item", "torch.zeros.tolist", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "distance_mat[].pow", "distance_mat_zsl[].pow", "torch.cdist", "torch.zeros", "len", "torch.argmin.eq().nonzero", "torch.argmin.eq().nonzero", "len", "distance_mat[].pow", "distance_mat_zsl[].pow", "torch.cdist", "torch.cdist", "torch.zeros", "len", "len", "zip", "zip", "numpy.finfo", "len", "len", "len", "len", "len", "len", "audio_distance.pow.pow", "video_distance.pow.pow", "len", "torch.argmin.eq", "seen_recall_dict.cpu().numpy", "unseen_recall_dict.cpu().numpy", "torch.argmin.eq", "targets.int", "numpy.array", "numpy.array", "targets.int", "torch.tensor.cpu().numpy", "seen_recall_dict.cpu", "torch.tensor.cpu().numpy", "unseen_recall_dict.cpu", "torch.tensor.cpu", "torch.tensor.cpu"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_class_performances"], ["", "", "def", "get_best_evaluation", "(", "dataset", ",", "targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "save_performances", "=", "False", ",", "args", "=", "None", ",", "attention_weights", "=", "None", ")", ":", "\n", "    ", "seen_scores", "=", "[", "]", "\n", "zsl_scores", "=", "[", "]", "\n", "unseen_scores", "=", "[", "]", "\n", "hm_scores", "=", "[", "]", "\n", "per_class_recalls", "=", "[", "]", "\n", "start", "=", "0", "\n", "end", "=", "3", "\n", "steps", "=", "(", "end", "-", "start", ")", "*", "5", "+", "1", "\n", "betas", "=", "torch", ".", "tensor", "(", "[", "best_beta", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "if", "best_beta", "else", "torch", ".", "linspace", "(", "start", ",", "end", ",", "steps", ",", "\n", "device", "=", "device", ")", "\n", "seen_label_array", "=", "torch", ".", "tensor", "(", "dataset", ".", "seen_class_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "unseen_label_array", "=", "torch", ".", "tensor", "(", "dataset", ".", "unseen_class_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "seen_unseen_array", "=", "torch", ".", "tensor", "(", "np", ".", "sort", "(", "np", ".", "concatenate", "(", "(", "dataset", ".", "seen_class_ids", ",", "dataset", ".", "unseen_class_ids", ")", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "classes_embeddings", "=", "t_p", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "beta", "in", "betas", ":", "\n", "            ", "if", "a_p", "==", "None", ":", "\n", "                ", "distance_mat", "=", "torch", ".", "zeros", "(", "(", "v_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "distance_mat_zsl", "=", "torch", ".", "zeros", "(", "(", "v_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "", "else", ":", "\n", "                ", "distance_mat", "=", "torch", ".", "zeros", "(", "(", "a_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "distance_mat_zsl", "=", "torch", ".", "zeros", "(", "(", "a_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "", "if", "mode", "==", "\"audio\"", ":", "\n", "                ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "torch", ".", "cdist", "(", "a_p", ",", "classes_embeddings", ")", "# .pow(2)", "\n", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask", "[", "seen_label_array", "]", "=", "99999999999999", "\n", "distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", ".", "pow", "(", "2", ")", "\n", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", "=", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", ".", "pow", "(", "2", ")", "\n", "", "", "elif", "mode", "==", "\"video\"", ":", "\n", "                ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "torch", ".", "cdist", "(", "v_p", ",", "classes_embeddings", ")", "# .pow(2)", "\n", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask", "[", "seen_label_array", "]", "=", "99999999999999", "\n", "distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", ".", "pow", "(", "2", ")", "\n", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", "=", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", ".", "pow", "(", "2", ")", "\n", "", "", "elif", "mode", "==", "\"both\"", ":", "\n", "# L2", "\n", "                ", "audio_distance", "=", "torch", ".", "cdist", "(", "a_p", ",", "classes_embeddings", ",", "p", "=", "2", ")", "# .pow(2)", "\n", "video_distance", "=", "torch", ".", "cdist", "(", "v_p", ",", "classes_embeddings", ",", "p", "=", "2", ")", "# .pow(2)", "\n", "\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "audio_distance", "=", "audio_distance", ".", "pow", "(", "2", ")", "\n", "video_distance", "=", "video_distance", ".", "pow", "(", "2", ")", "\n", "\n", "# Sum", "\n", "", "if", "args", ".", "cjme", "==", "True", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "(", "1", "-", "attention_weights", ")", "*", "audio_distance", "+", "attention_weights", "*", "video_distance", "\n", "", "else", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "(", "audio_distance", "+", "video_distance", ")", "\n", "\n", "", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask", "[", "seen_label_array", "]", "=", "99999999999999", "\n", "distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "\n", "", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "+", "beta", "\n", "mask", "[", "unseen_label_array", "]", "=", "0", "\n", "neighbor_batch", "=", "torch", ".", "argmin", "(", "distance_mat", "+", "mask", ",", "dim", "=", "1", ")", "\n", "match_idx", "=", "neighbor_batch", ".", "eq", "(", "targets", ".", "int", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "match_counts", "=", "torch", ".", "bincount", "(", "neighbor_batch", "[", "match_idx", "]", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "\n", "seen_unseen_array", "]", "\n", "target_counts", "=", "torch", ".", "bincount", "(", "targets", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "seen_unseen_array", "]", "\n", "per_class_recall", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "per_class_recall", "[", "seen_unseen_array", "]", "=", "match_counts", "/", "target_counts", "\n", "seen_recall_dict", "=", "per_class_recall", "[", "seen_label_array", "]", "\n", "unseen_recall_dict", "=", "per_class_recall", "[", "unseen_label_array", "]", "\n", "s", "=", "seen_recall_dict", ".", "mean", "(", ")", "\n", "u", "=", "unseen_recall_dict", ".", "mean", "(", ")", "\n", "\n", "if", "save_performances", ":", "\n", "                ", "seen_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "np", ".", "array", "(", "dataset", ".", "all_class_names", ")", "[", "seen_label_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ",", "seen_recall_dict", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "}", "\n", "unseen_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "np", ".", "array", "(", "dataset", ".", "all_class_names", ")", "[", "unseen_label_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ",", "unseen_recall_dict", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "}", "\n", "save_class_performances", "(", "seen_dict", ",", "unseen_dict", ",", "dataset", ".", "dataset_name", ")", "\n", "\n", "", "hm", "=", "(", "2", "*", "u", "*", "s", ")", "/", "(", "(", "u", "+", "s", ")", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "\n", "neighbor_batch_zsl", "=", "torch", ".", "argmin", "(", "distance_mat_zsl", ",", "dim", "=", "1", ")", "\n", "match_idx", "=", "neighbor_batch_zsl", ".", "eq", "(", "targets", ".", "int", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "match_counts", "=", "torch", ".", "bincount", "(", "neighbor_batch_zsl", "[", "match_idx", "]", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "\n", "seen_unseen_array", "]", "\n", "target_counts", "=", "torch", ".", "bincount", "(", "targets", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "seen_unseen_array", "]", "\n", "per_class_recall", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "per_class_recall", "[", "seen_unseen_array", "]", "=", "match_counts", "/", "target_counts", "\n", "zsl", "=", "per_class_recall", "[", "unseen_label_array", "]", ".", "mean", "(", ")", "\n", "\n", "zsl_scores", ".", "append", "(", "zsl", ".", "item", "(", ")", ")", "\n", "seen_scores", ".", "append", "(", "s", ".", "item", "(", ")", ")", "\n", "unseen_scores", ".", "append", "(", "u", ".", "item", "(", ")", ")", "\n", "hm_scores", ".", "append", "(", "hm", ".", "item", "(", ")", ")", "\n", "per_class_recalls", ".", "append", "(", "per_class_recall", ".", "tolist", "(", ")", ")", "\n", "", "argmax_hm", "=", "np", ".", "argmax", "(", "hm_scores", ")", "\n", "max_seen", "=", "seen_scores", "[", "argmax_hm", "]", "\n", "max_zsl", "=", "zsl_scores", "[", "argmax_hm", "]", "\n", "max_unseen", "=", "unseen_scores", "[", "argmax_hm", "]", "\n", "max_hm", "=", "hm_scores", "[", "argmax_hm", "]", "\n", "max_recall", "=", "per_class_recalls", "[", "argmax_hm", "]", "\n", "best_beta", "=", "betas", "[", "argmax_hm", "]", ".", "item", "(", ")", "\n", "", "return", "{", "\n", "\"seen\"", ":", "max_seen", ",", "\n", "\"unseen\"", ":", "max_unseen", ",", "\n", "\"hm\"", ":", "max_hm", ",", "\n", "\"recall\"", ":", "max_recall", ",", "\n", "\"zsl\"", ":", "max_zsl", ",", "\n", "\"beta\"", ":", "best_beta", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.evaluate_dataset": [[331, 363], ["data[].to", "data[].to", "data[].to", "dataset.targets.to", "model.eval", "model", "utils.get_best_evaluation", "utils.get_best_evaluation", "utils.get_best_evaluation", "tuple", "print", "torch.sqrt", "torch.mean", "torch.var"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_best_evaluation"], ["", "def", "evaluate_dataset", "(", "dataset", ",", "model", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "    ", "data", "=", "dataset", ".", "all_data", "\n", "data_a", "=", "data", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "data_v", "=", "data", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "data_t", "=", "data", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_t", "\n", ")", "\n", "try", ":", "\n", "        ", "if", "args", ".", "z_score_inputs", ":", "\n", "            ", "all_data", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "all_data", "]", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Namespace has no fitting attribute. Continuing\"", ")", "\n", "\n", "", "all_targets", "=", "dataset", ".", "targets", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "outputs_all", "=", "model", "(", "*", "all_data", ",", "*", "all_data", ")", "\n", "if", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "attention_weights", ",", "threshold_attention", "=", "outputs_all", "\n", "", "else", ":", "\n", "        ", "x_t_p", ",", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "=", "outputs_all", "\n", "threshold_attention", "=", "None", "\n", "", "audio_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"audio\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ")", "\n", "video_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"video\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ")", "\n", "both_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"both\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ",", "attention_weights", "=", "threshold_attention", ")", "\n", "return", "{", "\n", "\"audio\"", ":", "audio_evaluation", ",", "\n", "\"video\"", ":", "video_evaluation", ",", "\n", "\"both\"", ":", "both_evaluation", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.get_class_names": [[366, 372], ["isinstance", "pathlib.Path", "pathlib.Path.open", "sorted", "line.strip"], "function", ["None"], ["", "def", "get_class_names", "(", "path", ")", ":", "\n", "    ", "if", "isinstance", "(", "path", ",", "str", ")", ":", "\n", "        ", "path", "=", "Path", "(", "path", ")", "\n", "", "with", "path", ".", "open", "(", "\"r\"", ")", "as", "f", ":", "\n", "        ", "classes", "=", "sorted", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", ")", "\n", "", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.load_model_weights": [[374, 382], ["logging.info", "torch.load", "logging.info", "utils.load_model_parameters"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.load_model_parameters"], ["", "def", "load_model_weights", "(", "weights_path", ",", "model", ")", ":", "\n", "    ", "logging", ".", "info", "(", "f\"Loading model weights from {weights_path}\"", ")", "\n", "load_dict", "=", "torch", ".", "load", "(", "weights_path", ")", "\n", "model_weights", "=", "load_dict", "[", "\"model\"", "]", "\n", "epoch", "=", "load_dict", "[", "\"epoch\"", "]", "\n", "logging", ".", "info", "(", "f\"Load from epoch: {epoch}\"", ")", "\n", "load_model_parameters", "(", "model", ",", "model_weights", ")", "\n", "return", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.plot_hist_from_dict": [[383, 388], ["matplotlib.bar", "matplotlib.xticks", "matplotlib.tight_layout", "matplotlib.show", "range", "list", "range", "list", "len", "dict.values", "len", "dict.keys"], "function", ["None"], ["", "def", "plot_hist_from_dict", "(", "dict", ")", ":", "\n", "    ", "plt", ".", "bar", "(", "range", "(", "len", "(", "dict", ")", ")", ",", "list", "(", "dict", ".", "values", "(", ")", ")", ",", "align", "=", "\"center\"", ")", "\n", "plt", ".", "xticks", "(", "range", "(", "len", "(", "dict", ")", ")", ",", "list", "(", "dict", ".", "keys", "(", ")", ")", ",", "rotation", "=", "'vertical'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.save_class_performances": [[389, 398], ["pathlib.Path", "pathlib.Path", "pathlib.Path.open", "pickle.dump", "logging.info", "pathlib.Path.open", "pickle.dump", "logging.info"], "function", ["None"], ["", "def", "save_class_performances", "(", "seen_dict", ",", "unseen_dict", ",", "dataset_name", ")", ":", "\n", "    ", "seen_path", "=", "Path", "(", "f\"doc/cvpr2022/fig/final/class_performance_{dataset_name}_seen.pkl\"", ")", "\n", "unseen_path", "=", "Path", "(", "f\"doc/cvpr2022/fig/final/class_performance_{dataset_name}_unseen.pkl\"", ")", "\n", "with", "seen_path", ".", "open", "(", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "seen_dict", ",", "f", ")", "\n", "logging", ".", "info", "(", "f\"Saving seen class performances to {seen_path}\"", ")", "\n", "", "with", "unseen_path", ".", "open", "(", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "unseen_dict", ",", "f", ")", "\n", "logging", ".", "info", "(", "f\"Saving unseen class performances to {unseen_path}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args.args_main": [[5, 370], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["def", "args_main", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Explainable Audio Visual Low Shot Learning\"", ")", "\n", "\n", "### Filesystem ###", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root_dir\"", ",", "\n", "help", "=", "\"Path to dataset directory. Expected subfolder structure: '{root_dir}/features/{feature_extraction_method}/{audio,video,text}'\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--feature_extraction_method\"", ",", "\n", "help", "=", "\"Name of folder containing respective extracted features. Has to match {feature_extraction_method} in --root_dir argument.\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout_baselines\"", ",", "\n", "help", "=", "\"Dropout to use for baselines\"", ",", "\n", "default", "=", "0.2", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "help", "=", "\"Name of the dataset to use\"", ",", "\n", "choices", "=", "[", "\"AudioSetZSL\"", ",", "\"VGGSound\"", ",", "\"UCF\"", ",", "\"ActivityNet\"", "]", ",", "\n", "default", "=", "\"AudioSetZSL\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--momentum\"", ",", "\n", "help", "=", "\"Momentum for batch norm\"", ",", "\n", "default", "=", "0.99", ",", "\n", "type", "=", "float", "\n", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--zero_shot_split\"", ",", "\n", "help", "=", "\"Name of zero shot split to use.\"", ",", "\n", "choices", "=", "[", "\"\"", ",", "\"main_split\"", ",", "\"cls_split\"", "]", ",", "\n", "default", "=", "\"\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--manual_text_word2vec\"", ",", "\n", "help", "=", "\"Flag to use the manual word2vec text embeddings. CARE: Need to create cache files again!\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val_all_loss\"", ",", "\n", "help", "=", "\"Validate loss with seen + unseen\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--additional_triplets_loss\"", ",", "\n", "help", "=", "\"Flag for using more triplets loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reg_loss\"", ",", "\n", "help", "=", "\"Flag for setting the regularization loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cycle_loss\"", ",", "\n", "help", "=", "\"Flag for using cycle loss\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--retrain_all\"", ",", "\n", "help", "=", "\"Retrain with all data from train and validation\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_checkpoints\"", ",", "\n", "help", "=", "\"Save checkpoints of the model every epoch\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "### Development options ###", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "help", "=", "\"Run the program in debug mode\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose\"", ",", "\n", "help", "=", "\"Run verbosely\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug_comment\"", ",", "\n", "help", "=", "\"Custom comment string for the summary writer\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--epochs\"", ",", "\n", "help", "=", "\"Number of epochs\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--norm_inputs\"", ",", "\n", "help", "=", "\"Normalize inputs before model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--z_score_inputs\"", ",", "\n", "help", "=", "\"Z-Score standardize inputs before model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "### Hyperparameters ###", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr\"", ",", "\n", "help", "=", "\"Learning rate\"", ",", "\n", "default", "=", "3e-4", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bs\"", ",", "\n", "help", "=", "\"Batch size\"", ",", "\n", "default", "=", "256", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_batches\"", ",", "\n", "help", "=", "\"Number of batches for the balanced batch sampler\"", ",", "\n", "default", "=", "250", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size\"", ",", "\n", "help", "=", "\"Dimension of the extracted features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size_audio\"", ",", "\n", "help", "=", "\"Dimension of the extracted audio features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input_size_video\"", ",", "\n", "help", "=", "\"Dimension of the extracted video features\"", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embeddings_hidden_size\"", ",", "\n", "help", "=", "\"Hidden layer size for the embedding networks\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_hidden_size\"", ",", "\n", "help", "=", "\"Hidden layer size for the decoder loss network\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding_dropout\"", ",", "\n", "help", "=", "\"Dropout in the embedding networks\"", ",", "\n", "default", "=", "0.8", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_dropout\"", ",", "\n", "help", "=", "\"Dropout in the decoder loss network\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding_use_bn\"", ",", "\n", "help", "=", "\"Use batchnorm in the embedding networks\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_use_bn\"", ",", "\n", "help", "=", "\"Use batchnorm in the decoder network\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--normalize_decoder_outputs\"", ",", "\n", "help", "=", "\"L2 normalize the outputs of the decoder\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--margin\"", ",", "\n", "help", "=", "\"Margin for the contrastive loss calculation\"", ",", "\n", "default", "=", "1.", ",", "\n", "type", "=", "float", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--distance_fn\"", ",", "\n", "help", "=", "\"Distance function for the contrastive loss calculation\"", ",", "\n", "choices", "=", "[", "\"L2Loss\"", ",", "\"SquaredL2Loss\"", "]", ",", "\n", "default", "=", "\"L2Loss\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_scheduler\"", ",", "\n", "help", "=", "\"Use LR_scheduler\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "\n", "# defaults", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "help", "=", "\"Random seed\"", ",", "\n", "default", "=", "42", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dump_path\"", ",", "\n", "help", "=", "\"Path where to create experiment log dirs\"", ",", "\n", "default", "=", "pathlib", ".", "Path", "(", "\".\"", ")", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "help", "=", "\"Device to run on.\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "\n", "default", "=", "\"cuda\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--baseline\"", ",", "\n", "help", "=", "\"Flag to use the baseline where we have two ALEs, one for each modality and we just try to push the modalities to text embeddings\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--audio_baseline\"", ",", "\n", "help", "=", "\"Flag to use the audio baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--video_baseline\"", ",", "\n", "help", "=", "\"Flag to use the video baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--concatenated_baseline\"", ",", "\n", "help", "=", "\"Flag to use the concatenated baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cjme\"", ",", "\n", "help", "=", "\"Flag to use the CJME baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model\"", ",", "\n", "help", "=", "\"Flag to use the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_early_fusion\"", ",", "\n", "help", "=", "\"Flag to use the early fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_middle_fusion\"", ",", "\n", "help", "=", "\"Flag to set the middle fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--AVCA\"", ",", "\n", "help", "=", "\"Flag to set the attention to the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_attention_both_heads\"", ",", "\n", "help", "=", "\"Flag to set if attention should provide output from both branches\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--depth_transformer\"", ",", "\n", "help", "=", "\"Flag to se the number of layers of the transformer\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exp_name\"", ",", "\n", "help", "=", "\"Flag to set the name of the experiment\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ale\"", ",", "\n", "help", "=", "\"Flag to set the ale\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--devise\"", ",", "\n", "help", "=", "\"Flag to set the devise model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sje\"", ",", "\n", "help", "=", "\"Flag to set the sje model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apn\"", ",", "\n", "help", "=", "\"Flag to set the apn model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--first_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the first pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--second_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the second pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--third_additional_triplet\"", ",", "\n", "help", "=", "\"flag to set the third pair of additional triplets\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--additional_dropout\"", ",", "\n", "help", "=", "\"flag to set the additional dropouts\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "float", "\n", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.args.args_eval": [[372, 541], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["", "def", "args_eval", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Explainable Audio Visual Low Shot Learning [Evaluation]\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load_path_stage_A\"", ",", "\n", "help", "=", "\"Path to experiment log folder of stage A\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root_dir\"", ",", "\n", "help", "=", "\"Path to dataset directory. Expected subfolder structure: '{root_dir}/features/{feature_extraction_method}/{audio,video,text}'\"", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load_path_stage_B\"", ",", "\n", "help", "=", "\"Path to experiment log folder of stage B\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "pathlib", ".", "Path", "\n", ")", "\n", "\n", "\"\"\"\n    parser.add_argument(\n        \"--weights_path\",\n        help=\"Path to trained model weights. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n\n    parser.add_argument(\n        \"--weights_path_stage_A\",\n        help=\"Path to trained model weights from stage A. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n\n    parser.add_argument(\n        \"--weights_path_stage_B\",\n        help=\"Path to trained model weights from stage B. If not stated, random weights will be used!\",\n        type=pathlib.Path\n    )\n    \"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_name\"", ",", "\n", "help", "=", "\"Evaluation name to be displayed in the final output string\"", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "help", "=", "\"Name of the dataset to use\"", ",", "\n", "choices", "=", "[", "\"AudioSetZSL\"", ",", "\"VGGSound\"", ",", "\"UCF\"", ",", "\"ActivityNet\"", "]", ",", "\n", "default", "=", "\"AudioSetZSL\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bs\"", ",", "\n", "help", "=", "\"Batch size\"", ",", "\n", "default", "=", "256", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_workers\"", ",", "\n", "help", "=", "\"Number of dataloader workers\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pin_memory\"", ",", "\n", "help", "=", "\"Flag for pin_memory in dataloader\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--drop_last\"", ",", "\n", "help", "=", "\"Drop last batch in dataloader\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "help", "=", "\"Device to run on.\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "\n", "default", "=", "\"cuda\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--baseline\"", ",", "\n", "help", "=", "\"Flag for setting baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--audio_baseline\"", ",", "\n", "help", "=", "\"Flag to use the audio baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--video_baseline\"", ",", "\n", "help", "=", "\"Flag to use the video baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--concatenated_baseline\"", ",", "\n", "help", "=", "\"Flag to use the concatenated baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model\"", ",", "\n", "help", "=", "\"Flag to use the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_early_fusion\"", ",", "\n", "help", "=", "\"Flag to use the early fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--new_model_middle_fusion\"", ",", "\n", "help", "=", "\"Flag to set the middle fusion new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--AVCA\"", ",", "\n", "help", "=", "\"Flag to set the attention to the new model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cjme\"", ",", "\n", "help", "=", "\"Flag to use the CJME baseline\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ale\"", ",", "\n", "help", "=", "\"Flag to set the ale\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--devise\"", ",", "\n", "help", "=", "\"Flag to set the devise model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sje\"", ",", "\n", "help", "=", "\"Flag to se the sje model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apn\"", ",", "\n", "help", "=", "\"flag to set apn model\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_performances\"", ",", "\n", "help", "=", "\"Save class performances to disk\"", ",", "\n", "action", "=", "\"store_true\"", "\n", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.collate_fn": [[22, 28], ["len", "torch.utils.data.dataloader.default_collate"], "function", ["None"], ["def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "batch", "=", "[", "(", "d", "[", "0", "]", ",", "d", "[", "1", "]", ",", "d", "[", "2", "]", ",", "d", "[", "3", "]", ",", "d", "[", "4", "]", ")", "for", "d", "in", "batch", "if", "d", "is", "not", "None", "]", "\n", "if", "len", "(", "batch", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "default_collate", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.save_pickle": [[30, 34], ["open", "print", "pickle.dump"], "function", ["None"], ["", "", "def", "save_pickle", "(", "obj", ",", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "print", "(", "\"Dumping data as pkl file\"", ",", "flush", "=", "True", ")", "\n", "pickle", ".", "dump", "(", "obj", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_pickle": [[36, 44], ["os.path.exists", "print", "open", "pickle.load"], "function", ["None"], ["", "", "def", "load_pickle", "(", "pkl_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "pkl_path", ")", ":", "\n", "        ", "print", "(", "f\"Loading pickle file: {pkl_path}\"", ",", "flush", "=", "True", ")", "\n", "with", "open", "(", "pkl_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "result", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "return", "result", "\n", "", "", "else", ":", "\n", "        ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.get_model": [[46, 104], ["model.load_model", "time.time", "type", "print", "torch.nn.DataParallel.eval", "torch.cuda.is_available", "print", "os.path.exists", "torch.nn.Sequential", "torch.nn.DataParallel.cuda", "torch.nn.DataParallel", "torch.load", "print", "utils.load_model_parameters", "torch.nn.MaxPool3d", "torch.nn.AvgPool3d", "time.time", "model.Flatten"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.load_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.load_model_parameters"], ["", "", "def", "get_model", "(", "args", ",", "get_video_encoder_only", "=", "True", ",", "logger", "=", "None", ")", ":", "\n", "\n", "# Load model", "\n", "    ", "model", "=", "load_model", "(", "\n", "vid_base_arch", "=", "args", ".", "vid_base_arch", ",", "\n", "aud_base_arch", "=", "args", ".", "aud_base_arch", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "\n", "num_classes", "=", "args", ".", "num_clusters", ",", "\n", "norm_feat", "=", "False", ",", "\n", "use_mlp", "=", "args", ".", "use_mlp", ",", "\n", "headcount", "=", "args", ".", "headcount", "\n", ")", "\n", "\n", "# Load model weights", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "weight_path_type", "=", "type", "(", "args", ".", "weights_path", ")", "\n", "if", "weight_path_type", "==", "str", ":", "\n", "        ", "weight_path_not_none", "=", "args", ".", "weights_path", "!=", "'None'", "\n", "", "else", ":", "\n", "        ", "weight_path_not_none", "=", "args", ".", "weights_path", "is", "not", "None", "\n", "", "if", "weight_path_not_none", ":", "\n", "        ", "print", "(", "\"Loading model weights\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "weights_path", ")", ":", "\n", "            ", "ckpt_dict", "=", "torch", ".", "load", "(", "args", ".", "weights_path", ")", "\n", "model_weights", "=", "ckpt_dict", "[", "\"model\"", "]", "\n", "args", ".", "ckpt_epoch", "=", "ckpt_dict", "[", "'epoch'", "]", "\n", "print", "(", "f\"Epoch checkpoint: {args.ckpt_epoch}\"", ",", "flush", "=", "True", ")", "\n", "utils", ".", "load_model_parameters", "(", "model", ",", "model_weights", ")", "\n", "", "", "print", "(", "f\"Time to load model weights: {time.time() - start}\"", ")", "\n", "\n", "# Put model in eval mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Get video encoder for video-only retrieval", "\n", "if", "get_video_encoder_only", ":", "\n", "        ", "model", "=", "model", ".", "video_network", ".", "base", "\n", "if", "args", ".", "pool_op", "==", "'max'", ":", "\n", "            ", "pool", "=", "torch", ".", "nn", ".", "MaxPool3d", "(", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "", "elif", "args", ".", "pool_op", "==", "'avg'", ":", "\n", "            ", "pool", "=", "torch", ".", "nn", ".", "AvgPool3d", "(", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\"Only 'max' and 'avg' pool operations allowed\"", ")", "\n", "\n", "# Set up model", "\n", "", "model", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "[", "\n", "model", ".", "stem", ",", "\n", "model", ".", "layer1", ",", "\n", "model", ".", "layer2", ",", "\n", "model", ".", "layer3", ",", "\n", "model", ".", "layer4", ",", "\n", "pool", ",", "\n", "Flatten", "(", ")", ",", "\n", "]", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.init": [[106, 149], ["print", "datasets.AVideoDataset.AVideoDataset", "print", "datasets.AVideoDataset.AVideoDataset", "retrieval_utils.get_model"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.get_model"], ["", "def", "init", "(", "args", ",", "get_video_encoder_only", "=", "True", ",", "logger", "=", "None", ")", ":", "\n", "\n", "# Loading Train data", "\n", "    ", "print", "(", "\"Loading training data\"", ")", "\n", "dataset", "=", "AVideoDataset", "(", "\n", "ds_name", "=", "args", ".", "dataset", ",", "\n", "root_dir", "=", "args", ".", "root_dir", ",", "\n", "mode", "=", "'train'", ",", "\n", "num_frames", "=", "args", ".", "clip_len", ",", "\n", "sample_rate", "=", "args", ".", "steps_bet_clips", ",", "\n", "num_train_clips", "=", "args", ".", "train_clips_per_video", ",", "\n", "train_crop_size", "=", "112", ",", "\n", "seed", "=", "None", ",", "\n", "fold", "=", "args", ".", "fold", ",", "\n", "colorjitter", "=", "False", ",", "\n", "temp_jitter", "=", "True", ",", "\n", "center_crop", "=", "False", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "False", ",", "\n", ")", "\n", "\n", "print", "(", "\"Loading validation data\"", ")", "\n", "dataset_test", "=", "AVideoDataset", "(", "\n", "ds_name", "=", "args", ".", "dataset", ",", "\n", "root_dir", "=", "args", ".", "root_dir", ",", "\n", "mode", "=", "'test'", ",", "\n", "num_frames", "=", "args", ".", "clip_len", ",", "\n", "sample_rate", "=", "args", ".", "steps_bet_clips", ",", "\n", "num_spatial_crops", "=", "1", ",", "\n", "num_ensemble_views", "=", "args", ".", "train_clips_per_video", ",", "\n", "test_crop_size", "=", "112", ",", "\n", "seed", "=", "None", ",", "\n", "fold", "=", "args", ".", "fold", ",", "\n", "colorjitter", "=", "False", ",", "\n", "temp_jitter", "=", "True", ",", "\n", "center_crop", "=", "False", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "False", ",", "\n", ")", "\n", "\n", "model", "=", "get_model", "(", "args", ",", "\n", "get_video_encoder_only", "=", "get_video_encoder_only", ",", "logger", "=", "logger", ")", "\n", "return", "model", ",", "dataset", ",", "dataset_test", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.get_features": [[151, 258], ["torch.cuda.empty_cache", "len", "print", "torch.utils.data.DataLoader", "print", "torch.no_grad", "enumerate", "print", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cuda.is_available", "model.cpu", "video_idx.cuda.cpu", "label.cuda.cpu", "model.numpy", "video_idx.cuda.numpy().astype", "label.cuda.numpy().astype", "PS_v_np.append", "indices_np.append", "labels_np.append", "print", "numpy.concatenate", "retrieval_utils.save_pickle", "retrieval_utils.save_pickle", "retrieval_utils.save_pickle", "len", "video.cuda.cuda", "label.cuda.cuda", "video_idx.cuda.cuda", "model", "model", "feat_a.cpu.cpu", "feat_a.cpu.numpy", "model.size", "PS_a_np.append", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "retrieval_utils.save_pickle", "audio.cuda.cuda", "video_idx.cuda.numpy", "label.cuda.numpy", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.save_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.save_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.save_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.save_pickle"], ["", "def", "get_features", "(", "\n", "args", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "get_audio", "=", "False", ",", "\n", "logger", "=", "None", ",", "\n", "mode", "=", "'train'", ",", "\n", "print_freq", "=", "250", ",", "\n", "pretext", "=", "None", "\n", ")", ":", "\n", "\n", "# clear cache at beginning", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# dtype", "\n", "dtype", "=", "np", ".", "float64", "\n", "N", "=", "len", "(", "dataset", ")", "\n", "print", "(", "f\"Size of DS: {N}\"", ")", "\n", "\n", "# we need a data loader", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "collate_fn", "if", "get_audio", "else", "None", ",", "\n", "drop_last", "=", "False", "\n", ")", "\n", "print", "(", "f\"Size of Dataloader: {len(dataloader)}\"", ")", "\n", "\n", "# 1. aggregate inputs:", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Get data", "\n", "            ", "if", "get_audio", ":", "\n", "                ", "video", ",", "audio", ",", "label", ",", "_", ",", "video_idx", "=", "batch", "\n", "", "else", ":", "\n", "                ", "video", ",", "label", ",", "_", ",", "video_idx", "=", "batch", "\n", "\n", "# Move to GPU", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "video", "=", "video", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "label", "=", "label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "video_idx", "=", "video_idx", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "if", "get_audio", ":", "\n", "                    ", "audio", "=", "audio", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "# Forward pass", "\n", "", "", "if", "get_audio", ":", "\n", "                ", "feat_v", ",", "feat_a", "=", "model", "(", "video", ",", "audio", ")", "\n", "", "else", ":", "\n", "                ", "feat_v", "=", "model", "(", "video", ")", "\n", "\n", "", "feat_v", "=", "feat_v", ".", "cpu", "(", ")", "\n", "video_idx", "=", "video_idx", ".", "cpu", "(", ")", "\n", "label", "=", "label", ".", "cpu", "(", ")", "\n", "all_feat_v", "=", "feat_v", ".", "numpy", "(", ")", "\n", "all_indices", "=", "video_idx", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "all_labels", "=", "label", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "if", "get_audio", ":", "\n", "                ", "feat_a", "=", "feat_a", ".", "cpu", "(", ")", "\n", "all_feat_a", "=", "feat_a", ".", "numpy", "(", ")", "\n", "\n", "", "if", "batch_idx", "==", "0", ":", "\n", "                ", "K", "=", "feat_v", ".", "size", "(", "1", ")", "\n", "PS_v_np", "=", "[", "]", "\n", "indices_np", "=", "[", "]", "\n", "labels_np", "=", "[", "]", "\n", "if", "get_audio", ":", "\n", "                    ", "PS_a_np", "=", "[", "]", "\n", "\n", "# fill in arrays on main node", "\n", "", "", "PS_v_np", ".", "append", "(", "all_feat_v", ")", "\n", "indices_np", ".", "append", "(", "all_indices", ")", "\n", "labels_np", ".", "append", "(", "all_labels", ")", "\n", "if", "get_audio", ":", "\n", "                ", "PS_a_np", ".", "append", "(", "all_feat_a", ")", "\n", "\n", "", "print", "(", "f'{batch_idx} / {len(dataloader)}'", ",", "end", "=", "'\\r'", ")", "\n", "", "print", "(", "\"Done collecting features\"", ")", "\n", "\n", "# Concat numpy errors", "\n", "PS_v", "=", "np", ".", "concatenate", "(", "PS_v_np", ",", "axis", "=", "0", ")", "\n", "indices", "=", "np", ".", "concatenate", "(", "indices_np", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels_np", ",", "axis", "=", "0", ")", "\n", "if", "get_audio", ":", "\n", "            ", "PS_a", "=", "np", ".", "concatenate", "(", "PS_a_np", ",", "axis", "=", "0", ")", "\n", "\n", "", "if", "args", ".", "save_pkl", ":", "\n", "            ", "if", "pretext", "is", "None", ":", "\n", "                ", "pretext", "=", "f\"{args.vid_base_arch}_{args.dataset}_{args.train_clips_per_video}_{mode}\"", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "save_pickle", "(", "PS_v", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_feats.pkl\"", ")", ")", "\n", "save_pickle", "(", "indices", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_indices.pkl\"", ")", ")", "\n", "save_pickle", "(", "labels", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_labels.pkl\"", ")", ")", "\n", "if", "get_audio", ":", "\n", "                ", "save_pickle", "(", "PS_a", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_feats_aud.pkl\"", ")", ")", "\n", "\n", "", "", "if", "get_audio", ":", "\n", "            ", "return", "PS_v", ",", "PS_a", ",", "indices", ",", "labels", "\n", "", "else", ":", "\n", "            ", "return", "PS_v", ",", "indices", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_or_get_features": [[260, 316], ["retrieval_utils.load_pickle", "retrieval_utils.load_pickle", "retrieval_utils.load_pickle", "retrieval_utils.get_features", "retrieval_utils.get_features", "os.path.join", "os.path.join", "os.path.join", "retrieval_utils.load_pickle", "os.path.join", "retrieval_utils.get_features", "retrieval_utils.get_features"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_pickle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "", "", "def", "load_or_get_features", "(", "\n", "args", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "get_audio", "=", "False", ",", "\n", "logger", "=", "None", ",", "\n", "mode", "=", "'train'", ",", "\n", "pretext", "=", "None", "\n", ")", ":", "\n", "# Get train features", "\n", "    ", "if", "pretext", "is", "None", ":", "\n", "        ", "pretext", "=", "f\"{args.vid_base_arch}_{args.dataset}_{args.train_clips_per_video}_{mode}\"", "\n", "", "if", "args", ".", "use_cache_feats", ":", "\n", "        ", "try", ":", "\n", "            ", "features", "=", "load_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_feats.pkl\"", ")", "\n", ")", "\n", "vid_indices", "=", "load_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_indices.pkl\"", ")", "\n", ")", "\n", "labels", "=", "load_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_labels.pkl\"", ")", "\n", ")", "\n", "if", "get_audio", ":", "\n", "                ", "aud_features", "=", "load_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f\"{pretext}_feats_aud.pkl\"", ")", "\n", ")", "\n", "return", "features", ",", "aud_features", ",", "vid_indices", ",", "labels", "\n", "", "else", ":", "\n", "                ", "return", "features", ",", "vid_indices", ",", "labels", "\n", "", "", "except", ":", "\n", "            ", "if", "get_audio", ":", "\n", "                ", "features", ",", "aud_features", ",", "vid_indices", ",", "labels", "=", "get_features", "(", "\n", "args", ",", "dataset", ",", "model", ",", "\n", "get_audio", "=", "get_audio", ",", "logger", "=", "logger", ",", "mode", "=", "mode", "\n", ")", "\n", "return", "features", ",", "aud_features", ",", "vid_indices", ",", "labels", "\n", "", "else", ":", "\n", "                ", "features", ",", "vid_indices", ",", "labels", "=", "get_features", "(", "\n", "args", ",", "dataset", ",", "model", ",", "\n", "get_audio", "=", "get_audio", ",", "logger", "=", "logger", ",", "mode", "=", "mode", "\n", ")", "\n", "return", "features", ",", "vid_indices", ",", "labels", "\n", "", "", "", "else", ":", "\n", "        ", "if", "get_audio", ":", "\n", "            ", "features", ",", "aud_features", ",", "vid_indices", ",", "labels", "=", "get_features", "(", "\n", "args", ",", "dataset", ",", "model", ",", "\n", "get_audio", "=", "get_audio", ",", "logger", "=", "logger", ",", "mode", "=", "mode", "\n", ")", "\n", "return", "features", ",", "aud_features", ",", "vid_indices", ",", "labels", "\n", "", "else", ":", "\n", "            ", "features", ",", "vid_indices", ",", "labels", "=", "get_features", "(", "\n", "args", ",", "dataset", ",", "model", ",", "\n", "get_audio", "=", "get_audio", ",", "logger", "=", "logger", ",", "mode", "=", "mode", "\n", ")", "\n", "return", "features", ",", "vid_indices", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.average_features": [[318, 377], ["collections.defaultdict", "collections.defaultdict", "print", "range", "numpy.stack", "numpy.stack", "numpy.stack", "collections.defaultdict", "len", "feat_dict[].append", "label_dict[].append", "print", "numpy.stack", "numpy.mean", "np.stack.append", "avg_vid_indices.append", "np.stack.append", "numpy.stack", "aud_feat_dict[].append", "numpy.mean", "np.stack.append", "len", "numpy.sqrt", "numpy.stack", "numpy.sum", "numpy.sqrt", "len", "numpy.sum"], "function", ["None"], ["", "", "", "def", "average_features", "(", "\n", "args", ",", "\n", "features", ",", "\n", "vid_indices", ",", "\n", "labels", ",", "\n", "get_audio", "=", "False", ",", "\n", "aud_features", "=", "None", ",", "\n", "logger", "=", "None", "\n", ")", ":", "\n", "    ", "feat_dict", "=", "defaultdict", "(", "list", ")", "\n", "label_dict", "=", "defaultdict", "(", "list", ")", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "        ", "aud_feat_dict", "=", "defaultdict", "(", "list", ")", "\n", "", "print", "(", "f\"Total Number of features: {len(features)}\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "        ", "if", "args", ".", "norm_feats", ":", "\n", "            ", "v", "=", "features", "[", "i", "]", "\n", "feat", "=", "v", "/", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "v", "**", "2", ")", ")", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "                ", "a", "=", "aud_features", "[", "i", "]", "\n", "feat_a", "=", "a", "/", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "a", "**", "2", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "feat", "=", "features", "[", "i", "]", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "                ", "feat_a", "=", "aud_features", "[", "i", "]", "\n", "", "", "label", "=", "labels", "[", "i", "]", "\n", "vid_idx", "=", "vid_indices", "[", "i", "]", "\n", "feat_dict", "[", "vid_idx", "]", ".", "append", "(", "feat", ")", "\n", "label_dict", "[", "vid_idx", "]", ".", "append", "(", "label", ")", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "            ", "aud_feat_dict", "[", "vid_idx", "]", ".", "append", "(", "feat_a", ")", "\n", "", "print", "(", "f'{i} / {len(features)}'", ",", "end", "=", "'\\r'", ")", "\n", "\n", "", "avg_features", ",", "avg_vid_indices", ",", "avg_labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "        ", "avg_features_aud", "=", "[", "]", "\n", "", "num_features", "=", "0", "\n", "for", "vid_idx", "in", "feat_dict", ":", "\n", "        ", "stcked_feats", "=", "np", ".", "stack", "(", "feat_dict", "[", "vid_idx", "]", ")", "\n", "feat", "=", "np", ".", "mean", "(", "stcked_feats", ",", "axis", "=", "0", ")", "\n", "vid_ix_feat_len", "=", "stcked_feats", ".", "shape", "[", "0", "]", "\n", "num_features", "+=", "vid_ix_feat_len", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "            ", "feat_a", "=", "np", ".", "mean", "(", "np", ".", "stack", "(", "aud_feat_dict", "[", "vid_idx", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "label", "=", "label_dict", "[", "vid_idx", "]", "[", "0", "]", "\n", "avg_features", ".", "append", "(", "feat", ")", "\n", "avg_vid_indices", ".", "append", "(", "vid_idx", ")", "\n", "avg_labels", ".", "append", "(", "label", ")", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "            ", "avg_features_aud", ".", "append", "(", "feat_a", ")", "\n", "", "", "avg_features", "=", "np", ".", "stack", "(", "avg_features", ",", "axis", "=", "0", ")", "\n", "avg_indices", "=", "np", ".", "stack", "(", "avg_vid_indices", ",", "axis", "=", "0", ")", "\n", "avg_labels", "=", "np", ".", "stack", "(", "avg_labels", ",", "axis", "=", "0", ")", "\n", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "        ", "avg_features_aud", "=", "np", ".", "stack", "(", "avg_features_aud", ",", "axis", "=", "0", ")", "\n", "", "if", "get_audio", "and", "aud_features", "is", "not", "None", ":", "\n", "        ", "return", "avg_features", ",", "avg_features_aud", ",", "avg_vid_indices", ",", "avg_labels", "\n", "", "else", ":", "\n", "        ", "return", "avg_features", ",", "avg_vid_indices", ",", "avg_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.retrieval": [[379, 444], ["sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "collections.defaultdict", "range", "len", "numpy.expand_dims", "print", "numpy.mean", "print", "sklearn.neighbors.NearestNeighbors.kneighbors", "neighbor_indices.flatten.flatten", "set", "recall_dict[].append", "len", "float", "len", "str", "str", "len"], "function", ["None"], ["", "", "def", "retrieval", "(", "\n", "train_features", ",", "\n", "train_labels", ",", "\n", "train_vid_indices", ",", "\n", "val_features", ",", "\n", "val_labels", ",", "\n", "val_vid_indices", ",", "\n", "train_aud_features", "=", "None", ",", "\n", "val_aud_features", "=", "None", ",", "\n", "task", "=", "'v-v'", "\n", ")", ":", "\n", "\n", "    ", "assert", "task", "in", "[", "'v-a'", ",", "'a-v'", ",", "'v-v'", ",", "'a-a'", "]", "\n", "if", "task", "in", "[", "'v-a'", ",", "'a-v'", ",", "'a-a'", "]", ":", "\n", "        ", "assert", "(", "train_aud_features", "is", "not", "None", ")", "\n", "assert", "(", "val_aud_features", "is", "not", "None", ")", "\n", "\n", "", "if", "task", "==", "'v-v'", ":", "\n", "        ", "feat_val", "=", "val_features", "\n", "feat_train", "=", "train_features", "\n", "", "elif", "task", "==", "'v-a'", ":", "\n", "        ", "feat_val", "=", "val_features", "\n", "feat_train", "=", "train_aud_features", "\n", "", "elif", "task", "==", "'a-v'", ":", "\n", "        ", "feat_val", "=", "val_aud_features", "\n", "feat_train", "=", "train_features", "\n", "", "elif", "task", "==", "'a-a'", ":", "\n", "        ", "feat_val", "=", "val_aud_features", "\n", "feat_train", "=", "train_aud_features", "\n", "\n", "# Create ", "\n", "", "neigh", "=", "NearestNeighbors", "(", "50", ")", "\n", "neigh", ".", "fit", "(", "feat_train", ")", "\n", "recall_dict", "=", "defaultdict", "(", "list", ")", "\n", "retrieval_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "feat_val", ")", ")", ":", "\n", "        ", "feat", "=", "np", ".", "expand_dims", "(", "feat_val", "[", "i", "]", ",", "0", ")", "\n", "vid_idx", "=", "val_vid_indices", "[", "i", "]", "\n", "vid_label", "=", "val_labels", "[", "i", "]", "\n", "retrieval_dict", "[", "vid_idx", "]", "=", "{", "\n", "'label'", ":", "vid_label", ",", "\n", "'recal_acc'", ":", "{", "\n", "'1'", ":", "0", ",", "'5'", ":", "0", ",", "'10'", ":", "0", ",", "'20'", ":", "0", ",", "'50'", ":", "0", "\n", "}", ",", "\n", "'neighbors'", ":", "{", "\n", "'1'", ":", "[", "]", ",", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'20'", ":", "[", "]", ",", "'50'", ":", "[", "]", "\n", "}", "\n", "}", "\n", "for", "recall_treshold", "in", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", "]", ":", "\n", "            ", "neighbors", "=", "neigh", ".", "kneighbors", "(", "feat", ",", "recall_treshold", ")", "\n", "neighbor_indices", "=", "neighbors", "[", "1", "]", "\n", "neighbor_indices", "=", "neighbor_indices", ".", "flatten", "(", ")", "\n", "neighbor_labels", "=", "set", "(", "[", "train_labels", "[", "vid_index", "]", "for", "vid_index", "in", "neighbor_indices", "]", ")", "\n", "recall_value", "=", "100", "if", "vid_label", "in", "neighbor_labels", "else", "0", "\n", "acc_value", "=", "len", "(", "[", "1", "for", "neigh_label", "in", "neighbor_labels", "if", "neigh_label", "==", "vid_label", "]", ")", "/", "float", "(", "len", "(", "neighbor_labels", ")", ")", "\n", "retrieval_dict", "[", "vid_idx", "]", "[", "'recal_acc'", "]", "[", "str", "(", "recall_treshold", ")", "]", "=", "acc_value", "\n", "retrieval_dict", "[", "vid_idx", "]", "[", "'neighbors'", "]", "[", "str", "(", "recall_treshold", ")", "]", "=", "neighbor_indices", "\n", "recall_dict", "[", "recall_treshold", "]", ".", "append", "(", "recall_value", ")", "\n", "", "print", "(", "f'{i} / {len(feat_val)}'", ",", "end", "=", "'\\r'", ")", "\n", "\n", "# Calculate mean recall values", "\n", "", "for", "recall_treshold", "in", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", "]", ":", "\n", "        ", "mean_recall", "=", "np", ".", "mean", "(", "recall_dict", "[", "recall_treshold", "]", ")", "\n", "print", "(", "f\"{task}: Recall @ {recall_treshold}: {mean_recall}\"", ")", "\n", "", "return", "retrieval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.parse_args": [[446, 520], ["argparse.ArgumentParser", "argparse.ArgumentParser.register", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "v.lower.lower", "ValueError"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "def", "str2bool", "(", "v", ")", ":", "\n", "        ", "v", "=", "v", ".", "lower", "(", ")", "\n", "if", "v", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'1'", ")", ":", "\n", "            ", "return", "True", "\n", "", "elif", "v", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'0'", ")", ":", "\n", "            ", "return", "False", "\n", "", "raise", "ValueError", "(", "'Boolean argument needs to be true or false. '", "\n", "'Instead, it is %s.'", "%", "v", ")", "\n", "\n", "", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Video Retrieval'", ")", "\n", "parser", ".", "register", "(", "'type'", ",", "'bool'", ",", "str2bool", ")", "\n", "\n", "### Retrieval params", "\n", "parser", ".", "add_argument", "(", "'--use_cache_feats'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'use cache features'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_pkl'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'save pickled feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--avg_feats'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Average features of video'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_feats'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'L2 normalize features of video'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_op'", ",", "default", "=", "'max'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'max'", ",", "'avg'", "]", ",", "\n", "help", "=", "'Type of pooling operation: [max, avg]'", ")", "\n", "parser", ".", "add_argument", "(", "'--get_audio'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Get audio features'", ")", "\n", "\n", "### Dataset params", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'hmdb51'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'kinetics'", ",", "'vggsound'", ",", "'kinetics_sound'", ",", "'ave'", ",", "'ucf101'", ",", "'hmdb51'", "]", ",", "\n", "help", "=", "'name of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\"--root_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/path/to/dataset\"", ",", "\n", "help", "=", "\"root dir of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "96", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of batch'", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "default", "=", "'1'", ",", "type", "=", "str", ",", "\n", "help", "=", "'name of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_len'", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of frames per clip'", ")", "\n", "parser", ".", "add_argument", "(", "'--augtype'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'augmentation type (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--steps_bet_clips'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of steps between clips in video'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_clips_per_video'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of clips per video for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_clips_per_video'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of clips per video for testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of data loading workers (default: 16)'", ")", "\n", "\n", "### MODEL", "\n", "parser", ".", "add_argument", "(", "'--weights_path'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to weights file'", ")", "\n", "parser", ".", "add_argument", "(", "'--vid_base_arch'", ",", "default", "=", "'r2plus1d_18'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Video Base Arch for A-V model'", ")", "\n", "parser", ".", "add_argument", "(", "'--aud_base_arch'", ",", "default", "=", "'resnet9'", ",", "\n", "help", "=", "'Audio Base Arch for A-V model'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "\"Use pre-trained models from the modelzoo\"", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mlp'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use MLP projection head'", ")", "\n", "parser", ".", "add_argument", "(", "'--headcount'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'how many heads each modality has'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_clusters'", ",", "default", "=", "309", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of clusters\"", ")", "\n", "\n", "# distributed training parameters", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "'./retrieval_results'", ",", "\n", "help", "=", "'path where to save'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.cluster": [[23, 135], ["get_cluster_assignments_gpu.clone", "sk_utils..cpu().numpy", "sklearn.metrics.cluster.normalized_mutual_info_score", "sklearn.metrics.cluster.adjusted_mutual_info_score", "torch.no_grad", "torch.no_grad", "sk_utils.get_cluster_assignments_gpu", "sklearn.metrics.cluster.normalized_mutual_info_score", "numpy.array", "logger.info", "logger.info", "writer.add_scalar", "writer.add_scalar", "numpy.unique", "logger.info", "logger.info", "torch.barrier", "torch.barrier", "sk_utils..cpu", "sk_utils..cpu().numpy", "logger.info", "writer.add_scalar", "writer.add_scalar", "of_this_cluster.sum", "writer.add_histogram", "writer.add_histogram", "writer.add_scalar", "writer.add_scalar", "logger.info", "utils.trigger_job_requeue", "numpy.unique", "purities.append", "entropies.append", "numpy.array", "numpy.array", "numpy.mean", "numpy.mean", "os.path.join", "sk_utils..cpu", "scipy.stats.entropy", "numpy.mean", "numpy.mean", "max", "sum", "sum"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.get_cluster_assignments_gpu", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.trigger_job_requeue"], ["def", "cluster", "(", "\n", "args", ",", "\n", "selflabels", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "sk_counter", ",", "\n", "logger", ",", "\n", "writer", ",", "\n", "group", ",", "\n", "iter_num", ")", ":", "\n", "    ", "selflabels_old", "=", "selflabels", ".", "clone", "(", ")", "\n", "\n", "# get cluster assignments", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "selflabels", "=", "get_cluster_assignments_gpu", "(", "\n", "args", ",", "dataset", ",", "model", ",", "logger", ",", "writer", ",", "group", ",", "iter_num", ")", "\n", "", "self_labels_np", "=", "selflabels", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# increment counter", "\n", "sk_counter", "+=", "1", "\n", "\n", "if", "selflabels", "is", "not", "None", ":", "\n", "        ", "nmi_v", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "selflabels_old", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "f'NMI_v: {nmi_v}'", ")", "\n", "", "if", "writer", ":", "\n", "            ", "writer", ".", "add_scalar", "(", "\n", "f'train/nmi_v/iter'", ",", "\n", "nmi_v", ",", "\n", "iter_num", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f'train/optim_count/iter'", ",", "\n", "sk_counter", ",", "\n", "iter_num", "\n", ")", "\n", "\n", "", "", "true_labels", "=", "np", ".", "array", "(", "dataset", ".", "_labels", ")", "[", "dataset", ".", "valid_indices", "]", "\n", "nmi_to_labels_v", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "anmi_to_labels_v", "=", "adjusted_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"NMI-tolabels: {nmi_to_labels_v}\"", ")", "\n", "logger", ".", "info", "(", "f\"aNMI-tolabels: {anmi_to_labels_v}\"", ")", "\n", "", "if", "writer", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "\n", "f'train/nmi-tolabels_v/iter'", ",", "\n", "nmi_to_labels_v", ",", "\n", "iter_num", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f'train/a-nmi-tolabels_v/iter'", ",", "\n", "anmi_to_labels_v", ",", "\n", "iter_num", "\n", ")", "\n", "", "if", "sk_counter", "%", "10", "==", "0", ":", "\n", "        ", "entropies", "=", "[", "]", "\n", "purities", "=", "[", "]", "\n", "for", "sk_label", "in", "np", ".", "unique", "(", "self_labels_np", ")", ":", "\n", "            ", "of_this_cluster", "=", "self_labels_np", "==", "sk_label", "\n", "size", "=", "of_this_cluster", ".", "sum", "(", ")", "\n", "if", "size", "!=", "0", ":", "\n", "                ", "uniq", ",", "counts", "=", "np", ".", "unique", "(", "\n", "true_labels", "[", "of_this_cluster", "]", ",", "return_counts", "=", "True", ")", "\n", "purities", ".", "append", "(", "max", "(", "counts", ")", "/", "sum", "(", "1.0", "*", "counts", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", "(", "counts", "/", "sum", "(", "1.0", "*", "counts", ")", ")", ")", "\n", "", "", "logger", ".", "info", "(", "f\"Avg entropy: {np.mean(entropies)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Avg purity: {np.mean(purities)}\"", ")", "\n", "if", "writer", ":", "\n", "            ", "writer", ".", "add_histogram", "(", "\n", "'train/entropies'", ",", "\n", "np", ".", "array", "(", "entropies", ")", ",", "\n", "iter_num", "\n", ")", "\n", "writer", ".", "add_histogram", "(", "\n", "'train/purities'", ",", "\n", "np", ".", "array", "(", "purities", ")", ",", "\n", "iter_num", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "'train/avg-entropy'", ",", "\n", "np", ".", "mean", "(", "entropies", ")", ",", "\n", "iter_num", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "'train/avg-purity'", ",", "\n", "np", ".", "mean", "(", "purities", ")", ",", "\n", "iter_num", "\n", ")", "\n", "# signal received, relaunch experiment", "\n", "", "", "if", "os", ".", "environ", "[", "'SIGNAL_RECEIVED'", "]", "==", "'True'", ":", "\n", "        ", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Beginning requeue\"", ",", "logger", "=", "logger", ")", "\n", "trigger_job_requeue", "(", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "dump_path", ",", "\"checkpoint.pth.tar\"", ")", ")", "\n", "# Ensure processes reach to end of optim clusters", "\n", "", "", "if", "group", "is", "not", "None", ":", "\n", "        ", "dist", ".", "barrier", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "", "return", "selflabels", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.get_cluster_assignments_gpu": [[137, 357], ["torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.eval", "len", "torch.arange().int", "torch.arange().int", "torch.utils.data.sampler.SubsetRandomSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.zeros", "torch.zeros", "list", "numpy.random.shuffle", "range", "torch.cuda.synchronize", "torch.cuda.synchronize", "model.train", "torch.barrier", "torch.barrier", "range", "enumerate", "torch.barrier", "torch.barrier", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.barrier", "torch.barrier", "torch.arange", "torch.arange", "video.cuda.cuda", "audio.cuda.cuda", "idx.cuda.cuda", "model", "torch.all_gather", "torch.all_gather", "torch.all_gather", "logger.info", "logger.info", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "aggregtensor", "aggregtensor", "torch.IntTensor().random_().cuda", "torch.IntTensor().random_().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().cpu", "torch.cat().cpu", "torch.nn.functional.softmax.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.barrier", "torch.barrier", "sk_utils.match_order", "torch.mul", "torch.mul", "time.time", "sk_utils.optimize_L_sk_gpu", "L_head.to", "logger.info", "writer.add_scalar", "torch.nn.functional.softmax.size", "range", "torch.nn.functional.softmax.size", "range", "range", "logger.info", "utils.trigger_job_requeue", "getattr", "getattr", "logger.info", "utils.trigger_job_requeue", "range", "range", "getattr", "getattr", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "time.time", "numpy.mean", "torch.IntTensor().random_", "torch.IntTensor().random_", "torch.cat", "torch.cat", "os.path.join", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "os.path.join", "getattr.forward", "getattr.forward", "numpy.mean", "numpy.mean", "getattr.forward", "getattr.forward", "list", "torch.IntTensor", "torch.IntTensor", "getattr.modules", "torch.nn.functional.softmax.size"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.match_order", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.optimize_L_sk_gpu", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.trigger_job_requeue", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.trigger_job_requeue", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward"], ["", "def", "get_cluster_assignments_gpu", "(", "\n", "args", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "logger", "=", "None", ",", "\n", "writer", "=", "None", ",", "\n", "group", "=", "None", ",", "\n", "iter_num", "=", "0", "\n", ")", ":", "\n", "# clear cache at beginning", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# Put model in eval mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Get length of dataset", "\n", "N", "=", "len", "(", "dataset", ")", "\n", "\n", "# this process deals only with a subset of the dataset", "\n", "sampler", "=", "None", "\n", "local_nmb_data", "=", "N", "//", "args", ".", "world_size", "\n", "train_indices", "=", "torch", ".", "arange", "(", "\n", "args", ".", "rank", "*", "local_nmb_data", ",", "\n", "(", "args", ".", "rank", "+", "1", ")", "*", "local_nmb_data", "\n", ")", ".", "int", "(", ")", "\n", "# create subset sampler", "\n", "sampler", "=", "SubsetRandomSampler", "(", "train_indices", ")", "\n", "\n", "# create data loader", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "64", ",", "\n", "sampler", "=", "sampler", ",", "\n", "shuffle", "=", "sampler", "is", "None", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "None", "\n", ")", "\n", "\n", "# Ensure processes reach to end of optim clusters", "\n", "if", "group", "is", "not", "None", ":", "\n", "        ", "dist", ".", "barrier", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "# can't have more independent head-groups than heads", "\n", "", "assert", "args", ".", "ind_groups", "<=", "args", ".", "headcount", "\n", "\n", "if", "args", ".", "headcount", ">", "1", ":", "\n", "# aggregate GAP features when using multi heads", "\n", "        ", "model", ".", "module", ".", "return_features", "=", "True", "\n", "", "aggregtensor", "=", "torch", ".", "cuda", ".", "DoubleTensor", "if", "args", ".", "headcount", "==", "1", "else", "torch", ".", "cuda", ".", "FloatTensor", "\n", "dtype", "=", "torch", ".", "float64", "if", "args", ".", "headcount", "==", "1", "else", "torch", ".", "float32", "\n", "L", "=", "torch", ".", "zeros", "(", "(", "N", ",", "args", ".", "headcount", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "\n", "order_heads", "=", "list", "(", "range", "(", "args", ".", "headcount", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "order_heads", ")", "# is inplace", "\n", "\n", "for", "hd_grp_idx", "in", "range", "(", "args", ".", "ind_groups", ")", ":", "\n", "# 1. aggregate inputs:", "\n", "        ", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Get data", "\n", "            ", "video", ",", "audio", ",", "_", ",", "idx", ",", "_", "=", "batch", "\n", "\n", "# Move to GPU", "\n", "video", "=", "video", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "audio", "=", "audio", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "idx", "=", "idx", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "# Forward pass", "\n", "feat_v", ",", "feat_a", "=", "model", "(", "video", ",", "audio", ")", "\n", "if", "args", ".", "headcount", "==", "1", ":", "\n", "                ", "feat_v", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "feat_v", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "feat_a", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "feat_a", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "\n", "# gather the features computed by all processes", "\n", "", "all_feat_v_list", "=", "[", "aggregtensor", "(", "feat_v", ".", "size", "(", ")", ")", "for", "src", "in", "range", "(", "args", ".", "world_size", ")", "]", "\n", "all_feat_a_list", "=", "[", "aggregtensor", "(", "feat_a", ".", "size", "(", ")", ")", "for", "src", "in", "range", "(", "args", ".", "world_size", ")", "]", "\n", "all_indices_list", "=", "[", "torch", ".", "IntTensor", "(", "feat_v", ".", "size", "(", "0", ")", ")", ".", "random_", "(", "0", ",", "N", ")", ".", "cuda", "(", ")", "for", "src", "in", "\n", "range", "(", "args", ".", "world_size", ")", "]", "\n", "\n", "dist", ".", "all_gather", "(", "all_feat_v_list", ",", "feat_v", ")", "\n", "dist", ".", "all_gather", "(", "all_feat_a_list", ",", "feat_a", ")", "\n", "dist", ".", "all_gather", "(", "all_indices_list", ",", "idx", ")", "\n", "\n", "# only main process stores all features", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "                ", "all_feat_v", "=", "torch", ".", "cat", "(", "all_feat_v_list", ")", "\n", "all_feat_a", "=", "torch", ".", "cat", "(", "all_feat_a_list", ")", "\n", "all_indices", "=", "torch", ".", "cat", "(", "all_indices_list", ")", ".", "cpu", "(", ")", "\n", "\n", "", "if", "batch_idx", "==", "0", "and", "(", "args", ".", "rank", "==", "0", ")", ":", "\n", "                ", "fr", "=", "0", "\n", "K", "=", "feat_v", ".", "size", "(", "1", ")", "\n", "PS_v", "=", "torch", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "'cuda'", ")", "\n", "PS_a", "=", "torch", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "'cuda'", ")", "\n", "indices", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# fill in arrays on main node", "\n", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "                ", "to", "=", "fr", "+", "all_feat_v", ".", "shape", "[", "0", "]", "\n", "PS_v", "[", "fr", ":", "to", "]", "=", "all_feat_v", "\n", "PS_a", "[", "fr", ":", "to", "]", "=", "all_feat_a", "\n", "indices", "[", "fr", ":", "to", "]", "=", "all_indices", "\n", "fr", "=", "to", "\n", "\n", "# signal received, relaunch experiment", "\n", "", "if", "os", ".", "environ", "[", "'SIGNAL_RECEIVED'", "]", "==", "'True'", ":", "\n", "                ", "if", "args", ".", "rank", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Beginning requeue\"", ",", "logger", "=", "logger", ")", "\n", "trigger_job_requeue", "(", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "dump_path", ",", "\"checkpoint.pth.tar\"", ")", ")", "\n", "\n", "", "", "if", "group", "is", "not", "None", ":", "\n", "                ", "dist", ".", "barrier", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "                ", "dist", ".", "barrier", "(", ")", "\n", "\n", "# 2. solve label assignment via sinkhorn-knopp:", "\n", "", "", "if", "args", ".", "match", "and", "(", "iter_num", "==", "0", ")", ":", "\n", "            ", "for", "head", "in", "order_heads", "[", "hd_grp_idx", ":", ":", "args", ".", "ind_groups", "]", ":", "\n", "# optimize to get labels", "\n", "                ", "if", "args", ".", "headcount", "==", "1", ":", "\n", "                    ", "if", "args", ".", "rank", "==", "0", ":", "\n", "                        ", "PS_a_sk", "=", "PS_a", "\n", "PS_v_sk", "=", "PS_v", "\n", "", "else", ":", "\n", "                        ", "PS_v_sk", ",", "PS_a_sk", "=", "None", ",", "None", "\n", "", "head_a", "=", "model", ".", "module", ".", "mlp_a", "\n", "\n", "", "else", ":", "\n", "                    ", "head_a", "=", "getattr", "(", "model", ".", "module", ",", "f'mlp_a{head}'", ")", "\n", "head_v", "=", "getattr", "(", "model", ".", "module", ",", "f'mlp_v{head}'", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "                        ", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "head_a", ".", "forward", "(", "PS_a", ")", ",", "\n", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "head_v", ".", "forward", "(", "PS_v", ")", ",", "\n", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "else", ":", "\n", "                        ", "PS_v_sk", ",", "PS_a_sk", "=", "None", ",", "None", "\n", "# align heads of audio and video:", "\n", "", "", "match_order", "(", "args", ",", "\n", "PS_v_sk", ",", "\n", "PS_a_sk", ",", "\n", "list", "(", "head_a", ".", "modules", "(", ")", ")", "[", "-", "1", "]", "if", "model", ".", "module", ".", "use_mlp", "else", "head_a", ",", "\n", "steps", "=", "50000", ",", "\n", "restarts", "=", "2", ",", "\n", "logger", "=", "logger", "\n", ")", "\n", "", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Optimizing via sinkhorn-knopp on master GPU\"", ")", "\n", "if", "os", ".", "environ", "[", "'SIGNAL_RECEIVED'", "]", "==", "'True'", ":", "\n", "                ", "if", "args", ".", "rank", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Beginning requeue\"", ")", "\n", "trigger_job_requeue", "(", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "dump_path", ",", "\"checkpoint.pth.tar\"", ")", ")", "\n", "\n", "", "", "_costs", "=", "[", "0", "for", "i", "in", "range", "(", "args", ".", "headcount", ")", "]", "\n", "_times", "=", "[", "0", "for", "i", "in", "range", "(", "args", ".", "headcount", ")", "]", "\n", "\n", "\n", "# optimize heads", "\n", "for", "head", "in", "order_heads", "[", "hd_grp_idx", ":", ":", "args", ".", "ind_groups", "]", ":", "\n", "# optimize to get labels", "\n", "                ", "if", "args", ".", "headcount", "==", "1", ":", "\n", "                    ", "PS_a_sk", "=", "PS_a", "\n", "PS_v_sk", "=", "PS_v", "\n", "head_a", "=", "model", ".", "module", ".", "mlp_a", "\n", "", "else", ":", "\n", "                    ", "head_a", "=", "getattr", "(", "model", ".", "module", ",", "f'mlp_a{head}'", ")", "\n", "head_v", "=", "getattr", "(", "model", ".", "module", ",", "f'mlp_v{head}'", ")", "\n", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "head_a", ".", "forward", "(", "PS_a", ")", ",", "\n", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "head_v", ".", "forward", "(", "PS_v", ")", ",", "\n", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "\n", "# move activations to PS_v_sk", "\n", "", "torch", ".", "mul", "(", "PS_v_sk", ",", "PS_a_sk", ",", "out", "=", "PS_v_sk", ")", "\n", "sk_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# optimize", "\n", "cost", ",", "L_head", "=", "optimize_L_sk_gpu", "(", "args", ",", "PS_v_sk", ",", "hc", "=", "head", ",", "logger", "=", "logger", ")", "\n", "# cost, L_head = optimize_L_sk_gpu_log(args, PS_v_sk, hc=head, logger=logger)", "\n", "\n", "# put it in correct order", "\n", "L", "[", "indices", ",", "head", "]", "=", "L_head", ".", "to", "(", "'cuda'", ")", "\n", "\n", "_costs", "[", "head", "]", "=", "cost", "\n", "_times", "[", "head", "]", "=", "time", ".", "time", "(", ")", "-", "sk_start", "\n", "logger", ".", "info", "(", "f\"Head {head}, Cost: (video): {_costs[head]:.3f}; time: {_times[head]:.3f}\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Final Cost: (video): {np.mean(_costs):.3f}; time: {np.mean(_times):.3f}\"", ")", "\n", "del", "PS_v", "\n", "del", "PS_a", "\n", "\n", "# processes wait on main process compute PS features", "\n", "# Write costs to log", "\n", "if", "writer", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'train/LP-cost'", ",", "np", ".", "mean", "(", "_costs", ")", ",", "iter_num", ")", "\n", "\n", "", "", "", "if", "group", "is", "not", "None", ":", "\n", "        ", "dist", ".", "barrier", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "if", "group", "is", "not", "None", ":", "\n", "        ", "torch", ".", "distributed", ".", "broadcast", "(", "L", ",", "0", ",", "group", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "distributed", ".", "broadcast", "(", "L", ",", "0", ")", "\n", "\n", "", "if", "group", "is", "not", "None", ":", "\n", "        ", "dist", ".", "barrier", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "", "model", ".", "module", ".", "return_features", "=", "False", "\n", "model", ".", "train", "(", ")", "\n", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.optimize_L_sk_gpu": [[359, 423], ["print", "PS.size", "PS.size", "time.time", "torch.ones", "torch.ones", "PS.pow_", "r.sum", "torch.ones", "torch.ones", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.argmax().cuda", "torch.argmax().cuda", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "numpy.nansum", "torch.argsort", "torch.argsort", "torch.ones", "torch.ones", "logger.info", "alpha.t", "torch.log().cpu().numpy", "torch.log().cpu().numpy", "logger.info", "PS.sum", "torch.sort", "torch.sort", "torch.matmul().t", "torch.matmul().t", "torch.matmul", "torch.matmul", "torch.sum().cpu().item", "torch.sum().cpu().item", "torch.argmax", "torch.argmax", "logger.info", "torch.log().cpu", "torch.log().cpu", "torch.clamp", "torch.clamp", "torch.matmul", "torch.matmul", "torch.sum().cpu", "torch.sum().cpu", "beta.t", "torch.log", "torch.log", "range", "torch.sum", "torch.sum", "time.time", "torch.abs", "torch.abs", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.arange().long", "torch.arange().long", "beta.squeeze", "beta_new.squeeze", "torch.arange", "torch.arange", "len"], "function", ["None"], ["", "def", "optimize_L_sk_gpu", "(", "args", ",", "PS", ",", "hc", ",", "logger", "=", "None", ")", ":", "\n", "    ", "print", "(", "'doing optimization now'", ",", "flush", "=", "True", ")", "\n", "\n", "# create L", "\n", "N", "=", "PS", ".", "size", "(", "0", ")", "\n", "K", "=", "PS", ".", "size", "(", "1", ")", "\n", "tt", "=", "time", ".", "time", "(", ")", "\n", "_K_dist", "=", "torch", ".", "ones", "(", "(", "K", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "# / K", "\n", "if", "args", ".", "distribution", "!=", "'default'", ":", "\n", "        ", "marginals_argsort", "=", "torch", ".", "argsort", "(", "PS", ".", "sum", "(", "0", ")", ")", "\n", "if", "(", "args", ".", "dist", "is", "None", ")", "or", "args", ".", "diff_dist_every", ":", "\n", "            ", "if", "args", ".", "distribution", "==", "'gauss'", ":", "\n", "                ", "if", "args", ".", "diff_dist_per_head", ":", "\n", "                    ", "_K_dists", "=", "[", "(", "torch", ".", "randn", "(", "size", "=", "(", "K", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "*", "args", ".", "gauss_sd", "+", "1", ")", "*", "N", "/", "K", "\n", "for", "_", "in", "range", "(", "args", ".", "headcount", ")", "]", "\n", "args", ".", "dist", "=", "_K_dists", "\n", "_K_dist", "=", "_K_dists", "[", "hc", "]", "\n", "", "else", ":", "\n", "                    ", "_K_dist", "=", "(", "torch", ".", "randn", "(", "size", "=", "(", "K", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "*", "args", ".", "gauss_sd", "+", "1", ")", "*", "N", "/", "K", "\n", "_K_dist", "=", "torch", ".", "clamp", "(", "_K_dist", ",", "min", "=", "1", ")", "\n", "args", ".", "dist", "=", "_K_dist", "\n", "", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "f\"distribution used: {_K_dist}\"", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "diff_dist_per_head", ":", "\n", "                ", "_K_dist", "=", "args", ".", "dist", "[", "hc", "]", "\n", "", "else", ":", "\n", "                ", "_K_dist", "=", "args", ".", "dist", "\n", "", "", "_K_dist", "[", "marginals_argsort", "]", "=", "torch", ".", "sort", "(", "_K_dist", ")", "[", "0", "]", "\n", "\n", "", "beta", "=", "torch", ".", "ones", "(", "(", "N", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "/", "N", "\n", "PS", ".", "pow_", "(", "0.5", "*", "args", ".", "lamb", ")", "\n", "r", "=", "1.", "/", "_K_dist", "\n", "r", "/=", "r", ".", "sum", "(", ")", "\n", "\n", "c", "=", "1.", "/", "N", "\n", "err", "=", "1e6", "\n", "_counter", "=", "0", "\n", "\n", "ones", "=", "torch", ".", "ones", "(", "N", ",", "device", "=", "'cuda:0'", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "while", "(", "err", ">", "1e-1", ")", "and", "(", "_counter", "<", "2000", ")", ":", "\n", "        ", "alpha", "=", "r", "/", "torch", ".", "matmul", "(", "beta", ".", "t", "(", ")", ",", "PS", ")", ".", "t", "(", ")", "\n", "beta_new", "=", "c", "/", "torch", ".", "matmul", "(", "PS", ",", "alpha", ")", "\n", "if", "_counter", "%", "10", "==", "0", ":", "\n", "            ", "err", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "(", "beta", ".", "squeeze", "(", ")", "/", "beta_new", ".", "squeeze", "(", ")", ")", "-", "ones", ")", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "", "beta", "=", "beta_new", "\n", "_counter", "+=", "1", "\n", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"error: {err}, step : {_counter}\"", ")", "\n", "\n", "# inplace calculations", "\n", "", "torch", ".", "mul", "(", "PS", ",", "beta", ",", "out", "=", "PS", ")", "\n", "torch", ".", "mul", "(", "alpha", ".", "t", "(", ")", ",", "PS", ",", "out", "=", "PS", ")", "\n", "newL", "=", "torch", ".", "argmax", "(", "PS", ",", "1", ")", ".", "cuda", "(", ")", "\n", "\n", "# return back to obtain cost (optional)", "\n", "torch", ".", "mul", "(", "(", "1.", "/", "alpha", ")", ".", "t", "(", ")", ",", "PS", ",", "out", "=", "PS", ")", "\n", "torch", ".", "mul", "(", "PS", ",", "1.", "/", "beta", ",", "out", "=", "PS", ")", "\n", "sol", "=", "np", ".", "nansum", "(", "torch", ".", "log", "(", "PS", "[", "torch", ".", "arange", "(", "0", ",", "len", "(", "newL", ")", ")", ".", "long", "(", ")", ",", "newL", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "cost", "=", "-", "(", "1.", "/", "args", ".", "lamb", ")", "*", "sol", "/", "N", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"opt took {(time.time() - tt) / 60.} min, {_counter} iters\"", ")", "\n", "", "return", "cost", ",", "newL", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.match_order": [[424, 468], ["torch.no_grad", "torch.no_grad", "torch.arange().cuda", "torch.arange().cuda", "torch.broadcast", "perm.cuda.cpu", "sk_utils.match_order.c"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "match_order", "(", "args", ",", "emb1", ",", "emb2_in", ",", "W2", ",", "steps", "=", "50000", ",", "restarts", "=", "2", ",", "logger", "=", "None", ")", ":", "\n", "    ", "fin_perm", "=", "torch", ".", "arange", "(", "0", ",", "len", "(", "W2", ".", "bias", ".", "data", ")", ")", ".", "cuda", "(", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "assert", "type", "(", "W2", ")", "==", "torch", ".", "nn", ".", "modules", ".", "linear", ".", "Linear", "\n", "K", "=", "emb1", ".", "shape", "[", "1", "]", "\n", "def", "c", "(", "a", ",", "b", ")", ":", "\n", "            ", "return", "(", "torch", ".", "abs", "(", "a", "-", "b", ")", ")", ".", "sum", "(", "0", ")", ".", "sum", "(", "0", ")", "\n", "", "last_iter", "=", "0", "\n", "cost", "=", "c", "(", "emb1", ",", "emb2_in", ")", "\n", "best_cost", "=", "cost", "\n", "logger", ".", "info", "(", "f'initial cost: {cost:.1f}'", ")", "\n", "for", "retries", "in", "range", "(", "restarts", ")", ":", "\n", "            ", "cost_try", "=", "cost", ".", "item", "(", ")", "\n", "perm", "=", "torch", ".", "arange", "(", "0", ",", "K", ")", "\n", "emb2", "=", "emb2_in", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "for", "_iter", "in", "range", "(", "steps", ")", ":", "\n", "# what would happen if we switch cluster i with j in emb2", "\n", "                ", "[", "i", ",", "j", "]", "=", "np", ".", "random", ".", "choice", "(", "K", ",", "2", ",", "replace", "=", "False", ")", "\n", "current", "=", "c", "(", "emb1", "[", ":", ",", "i", "]", ",", "emb2", "[", ":", ",", "i", "]", ")", "+", "c", "(", "emb1", "[", ":", ",", "j", "]", ",", "emb2", "[", ":", ",", "j", "]", ")", "\n", "future", "=", "c", "(", "emb1", "[", ":", ",", "i", "]", ",", "emb2", "[", ":", ",", "j", "]", ")", "+", "c", "(", "emb1", "[", ":", ",", "j", "]", ",", "emb2", "[", ":", ",", "i", "]", ")", "\n", "delta", "=", "current", "-", "future", "\n", "if", "delta", ">", "0", ":", "\n", "# switch i and j", "\n", "                    ", "emb2", "[", ":", ",", "j", "]", ",", "emb2", "[", ":", ",", "i", "]", "=", "emb2", "[", ":", ",", "i", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ",", "emb2", "[", ":", ",", "j", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "cost_try", "-=", "delta", "\n", "_i", "=", "int", "(", "perm", "[", "i", "]", ")", "\n", "perm", "[", "i", "]", "=", "int", "(", "perm", "[", "j", "]", ")", "\n", "perm", "[", "j", "]", "=", "_i", "\n", "last_iter", "=", "_iter", "\n", "", "if", "_iter", "-", "last_iter", ">", "1000", ":", "\n", "                    ", "break", "\n", "\n", "", "", "cost_try", "=", "c", "(", "emb1", ",", "emb2_in", "[", ":", ",", "perm", "]", ")", "\n", "logger", ".", "info", "(", "f\"cost of this try: {cost_try:.2f}\"", ")", "\n", "if", "cost_try", "<", "best_cost", ":", "\n", "                ", "best_cost", "=", "cost_try", "\n", "fin_perm", "=", "perm", ".", "cuda", "(", ")", "\n", "", "", "", "dist", ".", "broadcast", "(", "fin_perm", ",", "0", ")", "\n", "fin_perm", "=", "fin_perm", ".", "cpu", "(", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"final cost: {best_cost:.2f}\"", ")", "\n", "", "W2", ".", "bias", ".", "data", "=", "W2", ".", "bias", ".", "data", "[", "fin_perm", "]", "\n", "W2", ".", "weight", ".", "data", "=", "W2", ".", "weight", ".", "data", "[", "fin_perm", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.__init__": [[23, 31], ["torch.optim.lr_scheduler._LRScheduler.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "multiplier", ",", "total_epoch", ",", "after_scheduler", "=", "None", ")", ":", "\n", "        ", "self", ".", "multiplier", "=", "multiplier", "\n", "if", "self", ".", "multiplier", "<", "1.", ":", "\n", "            ", "raise", "ValueError", "(", "'multiplier should be greater thant or equal to 1.'", ")", "\n", "", "self", ".", "total_epoch", "=", "total_epoch", "\n", "self", ".", "after_scheduler", "=", "after_scheduler", "\n", "self", ".", "finished", "=", "False", "\n", "super", "(", "GradualWarmupScheduler", ",", "self", ")", ".", "__init__", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.get_lr": [[32, 45], ["warmup_scheduler.GradualWarmupScheduler.after_scheduler.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "last_epoch", ">", "self", ".", "total_epoch", ":", "\n", "            ", "if", "self", ".", "after_scheduler", ":", "\n", "                ", "if", "not", "self", ".", "finished", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "base_lrs", "=", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "self", ".", "finished", "=", "True", "\n", "", "return", "self", ".", "after_scheduler", ".", "get_lr", "(", ")", "\n", "", "return", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "if", "self", ".", "multiplier", "==", "1.0", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "total_epoch", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "(", "self", ".", "multiplier", "-", "1.", ")", "*", "self", ".", "last_epoch", "/", "self", ".", "total_epoch", "+", "1.", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau": [[46, 59], ["zip", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step"], ["", "", "def", "step_ReduceLROnPlateau", "(", "self", ",", "metrics", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "if", "epoch", "is", "None", ":", "\n", "            ", "epoch", "=", "self", ".", "last_epoch", "+", "1", "\n", "", "self", ".", "last_epoch", "=", "epoch", "if", "epoch", "!=", "0", "else", "1", "# ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning", "\n", "if", "self", ".", "last_epoch", "<=", "self", ".", "total_epoch", ":", "\n", "            ", "warmup_lr", "=", "[", "base_lr", "*", "(", "(", "self", ".", "multiplier", "-", "1.", ")", "*", "self", ".", "last_epoch", "/", "self", ".", "total_epoch", "+", "1.", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "for", "param_group", ",", "lr", "in", "zip", "(", "self", ".", "optimizer", ".", "param_groups", ",", "warmup_lr", ")", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "", "else", ":", "\n", "            ", "if", "epoch", "is", "None", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "metrics", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "metrics", ",", "epoch", "-", "self", ".", "total_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step": [[60, 72], ["type", "warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau", "super().step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step"], ["", "", "", "def", "step", "(", "self", ",", "epoch", "=", "None", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "after_scheduler", ")", "!=", "ReduceLROnPlateau", ":", "\n", "            ", "if", "self", ".", "finished", "and", "self", ".", "after_scheduler", ":", "\n", "                ", "if", "epoch", "is", "None", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "step", "(", "None", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "step", "(", "epoch", "-", "self", ".", "total_epoch", ")", "\n", "# self._last_lr = self.after_scheduler.get_last_lr()", "\n", "", "", "else", ":", "\n", "                ", "return", "super", "(", "GradualWarmupScheduler", ",", "self", ")", ".", "step", "(", "epoch", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "step_ReduceLROnPlateau", "(", "metrics", ",", "epoch", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.get_features": [[25, 35], ["pickle.load", "numpy.array", "path.open", "len", "len", "torch.device", "len", "len", "len", "len", "len", "numpy.unique"], "function", ["None"], ["def", "get_features", "(", "path", ")", ":", "\n", "    ", "features", "=", "pickle", ".", "load", "(", "path", ".", "open", "(", "\"rb\"", ")", ")", "\n", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", "\n", "diff_len", "=", "len", "(", "video", ")", "-", "len", "(", "filenames", ")", "\n", "assert", "diff_len", "==", "0", "\n", "assert", "video", ".", "device", "==", "labels", ".", "device", "==", "audio", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "filenames", "=", "np", ".", "array", "(", "filenames", ")", "\n", "assert", "len", "(", "video", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "audio", ")", "==", "len", "(", "filenames", ")", "==", "len", "(", "np", ".", "unique", "(", "filenames", ")", ")", "\n", "\n", "return", "{", "\"video\"", ":", "video", ",", "\"labels\"", ":", "labels", ",", "\"audio\"", ":", "audio", ",", "\"filenames\"", ":", "filenames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.get_features_supervised": [[37, 51], ["pickle.load", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "path.open", "len", "len", "torch.device", "len", "len", "len", "len", "f[].split"], "function", ["None"], ["", "def", "get_features_supervised", "(", "path", ")", ":", "\n", "    ", "features", "=", "pickle", ".", "load", "(", "path", ".", "open", "(", "\"rb\"", ")", ")", "\n", "video", "=", "torch", ".", "tensor", "(", "[", "f", "[", "0", "]", "for", "f", "in", "features", "]", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "[", "f", "[", "1", "]", "for", "f", "in", "features", "]", ")", "\n", "audio", "=", "torch", ".", "tensor", "(", "[", "f", "[", "2", "]", "for", "f", "in", "features", "]", ")", "\n", "filenames", "=", "np", ".", "array", "(", "[", "f", "[", "3", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "f", "in", "features", "]", ")", "\n", "\n", "diff_len", "=", "len", "(", "video", ")", "-", "len", "(", "filenames", ")", "\n", "assert", "diff_len", "==", "0", "\n", "assert", "video", ".", "device", "==", "labels", ".", "device", "==", "audio", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "filenames", "=", "np", ".", "array", "(", "filenames", ")", "\n", "assert", "len", "(", "video", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "audio", ")", "==", "len", "(", "filenames", ")", "\n", "\n", "return", "{", "\"video\"", ":", "video", ",", "\"labels\"", ":", "labels", ",", "\"audio\"", ":", "audio", ",", "\"filenames\"", ":", "filenames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.get_indices": [[53, 60], ["set", "numpy.array", "len", "len", "enumerate"], "function", ["None"], ["", "def", "get_indices", "(", "dataframe", ",", "features", ")", ":", "\n", "    ", "names", "=", "set", "(", "dataframe", ".", "filename", ".", "values", ")", "\n", "filenames", "=", "features", "[", "\"filenames\"", "]", "\n", "assert", "len", "(", "dataframe", ")", "==", "len", "(", "names", ")", "\n", "indices", "=", "np", ".", "array", "(", "[", "idx", "for", "idx", ",", "filename", "in", "enumerate", "(", "filenames", ")", "if", "filename", "in", "names", "]", ")", "\n", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.test_correct_labels": [[62, 89], ["activitynet_split_features.get_features", "pathlib.Path", "pandas.read_csv", "pd.read_csv.label_code.unique", "activitynet_split_features.get_features", "NotImplementedError", "sorted", "numpy.where", "set", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "def", "test_correct_labels", "(", "splits_name", ",", "features_path", ",", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "\"self_sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "elif", "mode", "==", "\"sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "# features = get_features_supervised(features_path)", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "splits", "=", "[", "\n", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\n", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "\n", "]", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "wrong_labels", "=", "0", "\n", "for", "category", "in", "df", ".", "label_code", ".", "unique", "(", ")", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "features", "[", "\"labels\"", "]", "==", "category", ")", "[", "0", "]", "\n", "feat_names", "=", "features", "[", "\"filenames\"", "]", "[", "idx", "]", "\n", "df_names", "=", "df", "[", "df", ".", "label_code", "==", "category", "]", "[", "\"filename\"", "]", ".", "values", "\n", "if", "df_names", "[", "0", "]", "not", "in", "set", "(", "feat_names", ")", ":", "\n", "                ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "wrong_labels", "+=", "1", "\n", "\n", "", "", "assert", "wrong_labels", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features._get_class_names": [[90, 96], ["isinstance", "pathlib.Path", "pathlib.Path.open", "sorted", "line.strip"], "function", ["None"], ["", "", "def", "_get_class_names", "(", "path", ")", ":", "\n", "    ", "if", "isinstance", "(", "path", ",", "str", ")", ":", "\n", "        ", "path", "=", "Path", "(", "path", ")", "\n", "", "with", "path", ".", "open", "(", "\"r\"", ")", "as", "f", ":", "\n", "        ", "classes", "=", "sorted", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", ")", "\n", "", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.main": [[98, 153], ["activitynet_split_features._get_class_names", "pathlib.Path", "pathlib.Path", "activitynet_split_features.get_features", "out_path_text.exists", "print", "shutil.copytree", "pathlib.Path", "df_path.exists", "pandas.read_csv", "sorted", "activitynet_split_features.get_indices", "print", "pathlib.Path().mkdir", "print", "pathlib.Path().mkdir", "activitynet_split_features.get_features", "NotImplementedError", "range", "sorted", "pd.read_csv.label.unique", "len", "len", "len", "len", "len", "len", "pathlib.Path", "pathlib.Path", "numpy.where", "h5py.File", "hf.create_dataset", "hf.create_dataset", "h5py.File", "hf.create_dataset", "hf.create_dataset", "out_path_text.resolve", "n.encode", "n.encode", "h5py.special_dtype", "h5py.special_dtype"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features._get_class_names", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_indices", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "def", "main", "(", "features_split_name", ",", "splits_name", ",", "features_path", ",", "mode", ")", ":", "\n", "    ", "out_path", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "\n", "if", "mode", "==", "\"self_sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "elif", "mode", "==", "\"sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "# features = get_features_supervised(features_path)", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", ",", "\n", "classes", "=", "_get_class_names", "(", "\"/home/lriesch29/ExplainableAudioVisualLowShotLearning/dat/ActivityNet/class-split/all_class.txt\"", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "\n", "path_text_emb", "=", "Path", "(", "path_to_text_embedding", ")", "\n", "# to_file = out_path", "\n", "out_path_text", "=", "out_path", "/", "'text/'", "\n", "if", "not", "out_path_text", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "f\"Copying text embedding to {out_path_text.resolve()}\"", ")", "\n", "shutil", ".", "copytree", "(", "path_text_emb", ",", "out_path_text", ")", "\n", "\n", "", "for", "split", "in", "[", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "]", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "assert", "df_path", ".", "exists", "(", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "\n", "split_classes", "=", "sorted", "(", "df", ".", "label", ".", "unique", "(", ")", ")", "\n", "split_indices", "=", "get_indices", "(", "df", ",", "features", ")", "\n", "video_split", ",", "labels_split", ",", "audio_split", ",", "filenames_split", "=", "video", "[", "split_indices", "]", ",", "labels", "[", "split_indices", "]", ",", "audio", "[", "split_indices", "]", ",", "filenames", "[", "split_indices", "]", "\n", "assert", "len", "(", "video_split", ")", "==", "len", "(", "labels_split", ")", "==", "len", "(", "audio_split", ")", "==", "len", "(", "filenames_split", ")", "==", "len", "(", "split_indices", ")", "\n", "\n", "audio_path", "=", "out_path", "/", "f\"audio/{split}\"", "\n", "print", "(", "audio_path", ")", "\n", "Path", "(", "audio_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "video_path", "=", "out_path", "/", "f\"video/{split}\"", "\n", "print", "(", "video_path", ")", "\n", "Path", "(", "video_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "for", "c", "in", "split_classes", ":", "\n", "            ", "idx", "=", "class_to_idx", "[", "c", "]", "\n", "class_indices", "=", "np", ".", "where", "(", "labels_split", "==", "idx", ")", "[", "0", "]", "\n", "file_name", "=", "f\"{c}.h5\"", "\n", "\n", "with", "h5py", ".", "File", "(", "audio_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "audio_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n", "", "with", "h5py", ".", "File", "(", "video_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "video_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.test": [[155, 191], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "print", "activitynet_split_features.test.read_features"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "", "", "", "def", "test", "(", "features_split_name", ",", "splits_name", ")", ":", "\n", "    ", "root", "=", "Path", "(", "class_split_path", ")", "/", "splits_name", "\n", "\n", "df_train_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_train.csv\"", ")", "\n", "df_val_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_seen.csv\"", ")", "\n", "df_val_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_unseen.csv\"", ")", "\n", "\n", "df_test_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_train.csv\"", ")", "\n", "df_test_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_seen.csv\"", ")", "\n", "df_test_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_unseen.csv\"", ")", "\n", "\n", "def", "read_features", "(", "path", ")", ":", "\n", "        ", "hf", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "# keys = list(hf.keys())", "\n", "data", "=", "hf", "[", "'data'", "]", "\n", "# url = [str(u, 'utf-8') for u in list(hf['video_urls'])]", "\n", "url", "=", "[", "str", "(", "u", ")", "for", "u", "in", "list", "(", "hf", "[", "'video_urls'", "]", ")", "]", "\n", "return", "data", ",", "url", "\n", "\n", "", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_1_train\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_1_train/{test_name}\"", ")", "\n", "video_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_1_train/{test_name}\"", ")", "\n", "assert", "len", "(", "audio_train_tmp", "[", "0", "]", ")", "==", "len", "(", "video_train_tmp", "[", "0", "]", ")", "\n", "assert", "audio_train_tmp", "[", "1", "]", "[", "0", "]", "==", "video_train_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_train_tmp", "[", "0", "]", "[", "0", "]", ",", "video_train_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_2_test_unseen/\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_2_test_unseen/{test_name}\"", ")", "\n", "video_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_2_test_unseen/{test_name}\"", ")", "\n", "assert", "len", "(", "audio_test_tmp", "[", "0", "]", ")", "==", "len", "(", "video_test_tmp", "[", "0", "]", ")", "\n", "assert", "audio_test_tmp", "[", "1", "]", "[", "0", "]", "==", "video_test_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_test_tmp", "[", "0", "]", "[", "0", "]", ",", "video_test_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.activitynet_split_features.copy_to_shared": [[193, 198], ["pathlib.Path", "pathlib.Path", "shutil.copytree"], "function", ["None"], ["", "def", "copy_to_shared", "(", ")", ":", "\n", "    ", "my_file", "=", "Path", "(", "\"/home/lriesch29/ExplainableAudioVisualLowShotLearning/dat/ActivityNet/\"", ")", "\n", "to_file", "=", "Path", "(", "'/home/lriesch29/akata-shared/shared/avzsl/ActivityNet/'", ")", "\n", "\n", "shutil", ".", "copytree", "(", "my_file", ",", "to_file", ",", "dirs_exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.get_features": [[24, 34], ["pickle.load", "numpy.array", "path.open", "len", "len", "torch.device", "len", "len", "len", "len"], "function", ["None"], ["def", "get_features", "(", "path", ")", ":", "\n", "    ", "features", "=", "pickle", ".", "load", "(", "path", ".", "open", "(", "\"rb\"", ")", ")", "\n", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", "\n", "diff_len", "=", "len", "(", "video", ")", "-", "len", "(", "filenames", ")", "\n", "assert", "diff_len", "==", "0", "\n", "assert", "video", ".", "device", "==", "labels", ".", "device", "==", "audio", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "filenames", "=", "np", ".", "array", "(", "filenames", ")", "\n", "assert", "len", "(", "video", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "audio", ")", "==", "len", "(", "filenames", ")", "\n", "\n", "return", "{", "\"video\"", ":", "video", ",", "\"labels\"", ":", "labels", ",", "\"audio\"", ":", "audio", ",", "\"filenames\"", ":", "filenames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.get_indices": [[36, 43], ["set", "numpy.array", "len", "len", "enumerate"], "function", ["None"], ["", "def", "get_indices", "(", "dataframe", ",", "features", ")", ":", "\n", "    ", "names", "=", "set", "(", "dataframe", ".", "filename", ".", "values", ")", "\n", "filenames", "=", "features", "[", "\"filenames\"", "]", "\n", "assert", "len", "(", "dataframe", ")", "==", "len", "(", "names", ")", "\n", "indices", "=", "np", ".", "array", "(", "[", "idx", "for", "idx", ",", "filename", "in", "enumerate", "(", "filenames", ")", "if", "filename", "in", "names", "]", ")", "\n", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.test_correct_labels": [[45, 66], ["pathlib.Path", "vggsound_split_features.get_features", "pathlib.Path", "pandas.read_csv", "pd.read_csv.label_code.unique", "sorted", "numpy.where", "set"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "def", "test_correct_labels", "(", "splits_name", ")", ":", "\n", "    ", "features_path", "=", "Path", "(", "path_to_features", ")", "\n", "features", "=", "get_features", "(", "features_path", ")", "\n", "\n", "splits", "=", "[", "\n", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\n", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "\n", "]", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "wrong_labels", "=", "0", "\n", "for", "category", "in", "df", ".", "label_code", ".", "unique", "(", ")", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "features", "[", "\"labels\"", "]", "==", "category", ")", "[", "0", "]", "\n", "feat_names", "=", "features", "[", "\"filenames\"", "]", "[", "idx", "]", "\n", "df_names", "=", "df", "[", "df", ".", "label_code", "==", "category", "]", "[", "\"filename\"", "]", ".", "values", "\n", "if", "df_names", "[", "0", "]", "not", "in", "set", "(", "feat_names", ")", ":", "\n", "                ", "wrong_labels", "+=", "1", "\n", "\n", "", "", "assert", "wrong_labels", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.get_vggsound_classes": [[71, 78], ["pandas.read_csv", "sorted", "pd.read_csv.label.unique", "len"], "function", ["None"], ["def", "get_vggsound_classes", "(", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "\"../dat/VGGSound/class-split/vggsound.csv\"", ",", "header", "=", "None", ",", "names", "=", "[", "\"youtube_id\"", ",", "\"start_seconds\"", ",", "\"label\"", ",", "\"split\"", "]", ")", "\n", "classes", "=", "sorted", "(", "df", ".", "label", ".", "unique", "(", ")", ")", "\n", "assert", "classes", "[", "36", "]", "==", "\"cattle mooing\"", "\n", "assert", "classes", "[", "37", "]", "==", "\"cattle, bovinae cowbell\"", "\n", "assert", "len", "(", "classes", ")", "==", "309", "\n", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.main": [[80, 122], ["pathlib.Path", "vggsound_split_features.get_features", "vggsound_split_features.get_vggsound_classes", "pathlib.Path", "pathlib.Path", "df_path.exists", "pandas.read_csv", "sorted", "vggsound_split_features.get_indices", "print", "pathlib.Path().mkdir", "print", "pathlib.Path().mkdir", "range", "sorted", "pd.read_csv.label.unique", "len", "len", "len", "len", "len", "len", "pathlib.Path", "pathlib.Path", "numpy.where", "h5py.File", "hf.create_dataset", "hf.create_dataset", "h5py.File", "hf.create_dataset", "hf.create_dataset", "n.encode", "n.encode", "h5py.special_dtype", "h5py.special_dtype"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.get_vggsound_classes", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_indices"], ["", "def", "main", "(", "features_split_name", ",", "splits_name", ")", ":", "\n", "    ", "out_path", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "features_path", "=", "Path", "(", "path_to_features", ")", "\n", "features", "=", "get_features", "(", "features_path", ")", "\n", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", ",", "\n", "classes", "=", "get_vggsound_classes", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "\n", "for", "split", "in", "[", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "]", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "assert", "df_path", ".", "exists", "(", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "\n", "split_classes", "=", "sorted", "(", "df", ".", "label", ".", "unique", "(", ")", ")", "\n", "split_indices", "=", "get_indices", "(", "df", ",", "features", ")", "\n", "video_split", ",", "labels_split", ",", "audio_split", ",", "filenames_split", "=", "video", "[", "split_indices", "]", ",", "labels", "[", "split_indices", "]", ",", "audio", "[", "\n", "split_indices", "]", ",", "filenames", "[", "split_indices", "]", "\n", "assert", "len", "(", "video_split", ")", "==", "len", "(", "labels_split", ")", "==", "len", "(", "audio_split", ")", "==", "len", "(", "filenames_split", ")", "==", "len", "(", "split_indices", ")", "\n", "\n", "audio_path", "=", "out_path", "/", "f\"audio/{split}\"", "\n", "print", "(", "audio_path", ")", "\n", "Path", "(", "audio_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "video_path", "=", "out_path", "/", "f\"video/{split}\"", "\n", "print", "(", "video_path", ")", "\n", "Path", "(", "video_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "for", "c", "in", "split_classes", ":", "\n", "            ", "idx", "=", "class_to_idx", "[", "c", "]", "\n", "class_indices", "=", "np", ".", "where", "(", "labels_split", "==", "idx", ")", "[", "0", "]", "\n", "file_name", "=", "f\"{c}.h5\"", "\n", "\n", "with", "h5py", ".", "File", "(", "audio_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "audio_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n", "", "with", "h5py", ".", "File", "(", "video_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "video_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.vggsound_split_features.test": [[127, 167], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "print", "vggsound_split_features.test.read_features"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["def", "test", "(", "features_split_name", ",", "splits_name", ")", ":", "\n", "    ", "root", "=", "Path", "(", "class_split_path", ")", "/", "splits_name", "\n", "\n", "df_train_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_train.csv\"", ")", "\n", "df_val_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_seen.csv\"", ")", "\n", "df_val_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_unseen.csv\"", ")", "\n", "\n", "df_test_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_train.csv\"", ")", "\n", "df_test_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_seen.csv\"", ")", "\n", "df_test_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_unseen.csv\"", ")", "\n", "\n", "def", "read_features", "(", "path", ")", ":", "\n", "        ", "hf", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "# keys = list(hf.keys())", "\n", "data", "=", "hf", "[", "'data'", "]", "\n", "# url = [str(u, 'utf-8') for u in list(hf['video_urls'])]", "\n", "url", "=", "[", "str", "(", "u", ")", "for", "u", "in", "list", "(", "hf", "[", "'video_urls'", "]", ")", "]", "\n", "return", "data", ",", "url", "\n", "\n", "", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_1_train\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_1_train/{test_name}\"", ")", "\n", "video_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_1_train/{test_name}\"", ")", "\n", "# audio_train_tmp = read_features(tmp_root / \"audio/train_train/air horn.h5\")", "\n", "# video_train_tmp = read_features(tmp_root / \"video/train_train/air horn.h5\")", "\n", "assert", "len", "(", "audio_train_tmp", "[", "0", "]", ")", "==", "len", "(", "video_train_tmp", "[", "0", "]", ")", "\n", "assert", "audio_train_tmp", "[", "1", "]", "[", "0", "]", "==", "video_train_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_train_tmp", "[", "0", "]", "[", "0", "]", ",", "video_train_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_2_test_unseen/\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_2_test_unseen/{test_name}\"", ")", "\n", "video_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_2_test_unseen/{test_name}\"", ")", "\n", "# audio_test_tmp = read_features(tmp_root / \"audio/test_unseen/bird chirping, tweeting.h5\")", "\n", "# video_test_tmp = read_features(tmp_root / \"video/test_unseen/bird chirping, tweeting.h5\")", "\n", "assert", "len", "(", "audio_test_tmp", "[", "0", "]", ")", "==", "len", "(", "video_test_tmp", "[", "0", "]", ")", "\n", "assert", "audio_test_tmp", "[", "1", "]", "[", "0", "]", "==", "video_test_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_test_tmp", "[", "0", "]", "[", "0", "]", ",", "video_test_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features": [[28, 38], ["pickle.load", "numpy.array", "path.open", "len", "len", "torch.device", "len", "len", "len", "len"], "function", ["None"], ["def", "get_features", "(", "path", ")", ":", "\n", "    ", "features", "=", "pickle", ".", "load", "(", "path", ".", "open", "(", "\"rb\"", ")", ")", "\n", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", "\n", "diff_len", "=", "len", "(", "video", ")", "-", "len", "(", "filenames", ")", "\n", "assert", "diff_len", "==", "0", "\n", "assert", "video", ".", "device", "==", "labels", ".", "device", "==", "audio", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "filenames", "=", "np", ".", "array", "(", "filenames", ")", "\n", "assert", "len", "(", "video", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "audio", ")", "==", "len", "(", "filenames", ")", "\n", "\n", "return", "{", "\"video\"", ":", "video", ",", "\"labels\"", ":", "labels", ",", "\"audio\"", ":", "audio", ",", "\"filenames\"", ":", "filenames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features_supervised": [[40, 54], ["pickle.load", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "path.open", "len", "len", "torch.device", "len", "len", "len", "len", "f[].split"], "function", ["None"], ["", "def", "get_features_supervised", "(", "path", ")", ":", "\n", "    ", "features", "=", "pickle", ".", "load", "(", "path", ".", "open", "(", "\"rb\"", ")", ")", "\n", "video", "=", "torch", ".", "tensor", "(", "[", "f", "[", "0", "]", "for", "f", "in", "features", "]", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "[", "f", "[", "1", "]", "for", "f", "in", "features", "]", ")", "\n", "audio", "=", "torch", ".", "tensor", "(", "[", "f", "[", "2", "]", "for", "f", "in", "features", "]", ")", "\n", "filenames", "=", "np", ".", "array", "(", "[", "f", "[", "3", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "f", "in", "features", "]", ")", "\n", "\n", "diff_len", "=", "len", "(", "video", ")", "-", "len", "(", "filenames", ")", "\n", "assert", "diff_len", "==", "0", "\n", "assert", "video", ".", "device", "==", "labels", ".", "device", "==", "audio", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "filenames", "=", "np", ".", "array", "(", "filenames", ")", "\n", "assert", "len", "(", "video", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "audio", ")", "==", "len", "(", "filenames", ")", "\n", "\n", "return", "{", "\"video\"", ":", "video", ",", "\"labels\"", ":", "labels", ",", "\"audio\"", ":", "audio", ",", "\"filenames\"", ":", "filenames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_indices": [[56, 63], ["set", "numpy.array", "len", "len", "enumerate"], "function", ["None"], ["", "def", "get_indices", "(", "dataframe", ",", "features", ")", ":", "\n", "    ", "names", "=", "set", "(", "dataframe", ".", "filename", ".", "values", ")", "\n", "filenames", "=", "features", "[", "\"filenames\"", "]", "\n", "assert", "len", "(", "dataframe", ")", "==", "len", "(", "names", ")", "\n", "indices", "=", "np", ".", "array", "(", "[", "idx", "for", "idx", ",", "filename", "in", "enumerate", "(", "filenames", ")", "if", "filename", "in", "names", "]", ")", "\n", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.test_correct_labels": [[65, 92], ["ucf_split_features.get_features", "pathlib.Path", "pandas.read_csv", "pd.read_csv.label_code.unique", "ucf_split_features.get_features", "NotImplementedError", "sorted", "numpy.where", "set"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "def", "test_correct_labels", "(", "splits_name", ",", "features_path", ",", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "\"self_sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "elif", "mode", "==", "\"sup\"", ":", "\n", "# features = get_features_supervised(features_path)", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "splits", "=", "[", "\n", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\n", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "\n", "]", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "wrong_labels", "=", "0", "\n", "for", "category", "in", "df", ".", "label_code", ".", "unique", "(", ")", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "features", "[", "\"labels\"", "]", "==", "category", ")", "[", "0", "]", "\n", "feat_names", "=", "features", "[", "\"filenames\"", "]", "[", "idx", "]", "\n", "df_names", "=", "df", "[", "df", ".", "label_code", "==", "category", "]", "[", "\"filename\"", "]", ".", "values", "\n", "if", "df_names", "[", "0", "]", "not", "in", "set", "(", "feat_names", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "                ", "wrong_labels", "+=", "1", "\n", "\n", "", "", "assert", "wrong_labels", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_ucf_classes": [[94, 99], ["pathlib.Path", "len", "sorted", "pathlib.Path.iterdir"], "function", ["None"], ["", "", "def", "get_ucf_classes", "(", ")", ":", "\n", "    ", "path", "=", "Path", "(", "\"/home/lriesch29/akata-shared/datasets/UCF101/UCF-101\"", ")", "\n", "classes", "=", "[", "p", ".", "stem", "for", "p", "in", "sorted", "(", "path", ".", "iterdir", "(", ")", ")", "]", "\n", "assert", "len", "(", "classes", ")", "==", "101", "\n", "return", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.main": [[101, 157], ["ucf_split_features.get_ucf_classes", "pathlib.Path", "pathlib.Path", "ucf_split_features.get_features", "classes[].lower", "out_path_text.exists", "print", "shutil.copytree", "pathlib.Path", "df_path.exists", "pandas.read_csv", "sorted", "ucf_split_features.get_indices", "print", "pathlib.Path().mkdir", "print", "pathlib.Path().mkdir", "ucf_split_features.get_features", "NotImplementedError", "range", "sorted", "pd.read_csv.label.unique", "len", "len", "len", "len", "len", "len", "pathlib.Path", "pathlib.Path", "numpy.where", "h5py.File", "hf.create_dataset", "hf.create_dataset", "h5py.File", "hf.create_dataset", "hf.create_dataset", "out_path_text.resolve", "c.lower", "n.encode", "n.encode", "h5py.special_dtype", "h5py.special_dtype"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_ucf_classes", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_indices", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.get_features"], ["", "def", "main", "(", "features_split_name", ",", "splits_name", ",", "features_path", ",", "mode", ")", ":", "\n", "    ", "out_path", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "\n", "if", "mode", "==", "\"self_sup\"", ":", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "elif", "mode", "==", "\"sup\"", ":", "\n", "# features = get_features_supervised(features_path)", "\n", "        ", "features", "=", "get_features", "(", "features_path", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "video", ",", "labels", ",", "audio", ",", "filenames", "=", "features", "[", "\"video\"", "]", ",", "features", "[", "\"labels\"", "]", ",", "features", "[", "\"audio\"", "]", ",", "features", "[", "\"filenames\"", "]", ",", "\n", "classes", "=", "get_ucf_classes", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ".", "lower", "(", ")", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "\n", "path_text_emb", "=", "Path", "(", "text_embedding_path", ")", "\n", "# to_file = out_path", "\n", "out_path_text", "=", "out_path", "/", "'text/'", "\n", "if", "not", "out_path_text", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "f\"Copying text embedding to {out_path_text.resolve()}\"", ")", "\n", "shutil", ".", "copytree", "(", "path_text_emb", ",", "out_path_text", ")", "\n", "\n", "", "for", "split", "in", "[", "\"stage_1_train\"", ",", "\"stage_1_val_seen\"", ",", "\"stage_1_val_unseen\"", ",", "\"stage_2_train\"", ",", "\"stage_2_test_seen\"", ",", "\"stage_2_test_unseen\"", "]", ":", "\n", "        ", "base_path", "=", "Path", "(", "class_split_path", ")", "\n", "df_path", "=", "sorted", "(", "(", "base_path", "/", "splits_name", ")", ".", "glob", "(", "f\"*{split}.csv\"", ")", ")", "[", "0", "]", "\n", "assert", "df_path", ".", "exists", "(", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ")", "\n", "\n", "split_classes", "=", "sorted", "(", "df", ".", "label", ".", "unique", "(", ")", ")", "\n", "split_indices", "=", "get_indices", "(", "df", ",", "features", ")", "\n", "video_split", ",", "labels_split", ",", "audio_split", ",", "filenames_split", "=", "video", "[", "split_indices", "]", ",", "labels", "[", "split_indices", "]", ",", "audio", "[", "\n", "split_indices", "]", ",", "filenames", "[", "split_indices", "]", "\n", "assert", "len", "(", "video_split", ")", "==", "len", "(", "labels_split", ")", "==", "len", "(", "audio_split", ")", "==", "len", "(", "filenames_split", ")", "==", "len", "(", "split_indices", ")", "\n", "\n", "audio_path", "=", "out_path", "/", "f\"audio/{split}\"", "\n", "print", "(", "audio_path", ")", "\n", "Path", "(", "audio_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "video_path", "=", "out_path", "/", "f\"video/{split}\"", "\n", "print", "(", "video_path", ")", "\n", "Path", "(", "video_path", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "for", "c", "in", "split_classes", ":", "\n", "            ", "idx", "=", "class_to_idx", "[", "c", ".", "lower", "(", ")", "]", "\n", "class_indices", "=", "np", ".", "where", "(", "labels_split", "==", "idx", ")", "[", "0", "]", "\n", "file_name", "=", "f\"{c}.h5\"", "\n", "\n", "with", "h5py", ".", "File", "(", "audio_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "audio_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n", "", "with", "h5py", ".", "File", "(", "video_path", "/", "file_name", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                ", "hf", ".", "create_dataset", "(", "\"data\"", ",", "data", "=", "video_split", "[", "class_indices", "]", ")", "\n", "tmp_names", "=", "[", "n", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "for", "n", "in", "filenames_split", "[", "class_indices", "]", "]", "\n", "hf", ".", "create_dataset", "(", "\"video_urls\"", ",", "dtype", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "str", ")", ",", "data", "=", "tmp_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.test": [[159, 195], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "print", "ucf_split_features.test.read_features"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.utils.read_features"], ["", "", "", "", "def", "test", "(", "features_split_name", ",", "splits_name", ")", ":", "\n", "    ", "root", "=", "Path", "(", "class_split_path", ")", "/", "splits_name", "\n", "\n", "df_train_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_train.csv\"", ")", "\n", "df_val_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_seen.csv\"", ")", "\n", "df_val_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_1_val_unseen.csv\"", ")", "\n", "\n", "df_test_train", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_train.csv\"", ")", "\n", "df_test_seen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_seen.csv\"", ")", "\n", "df_test_unseen", "=", "pd", ".", "read_csv", "(", "root", "/", "\"stage_2_test_unseen.csv\"", ")", "\n", "\n", "def", "read_features", "(", "path", ")", ":", "\n", "        ", "hf", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "# keys = list(hf.keys())", "\n", "data", "=", "hf", "[", "'data'", "]", "\n", "# url = [str(u, 'utf-8') for u in list(hf['video_urls'])]", "\n", "url", "=", "[", "str", "(", "u", ")", "for", "u", "in", "list", "(", "hf", "[", "'video_urls'", "]", ")", "]", "\n", "return", "data", ",", "url", "\n", "\n", "", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_1_train\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_1_train/{test_name}\"", ")", "\n", "video_train_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_1_train/{test_name}\"", ")", "\n", "assert", "len", "(", "audio_train_tmp", "[", "0", "]", ")", "==", "len", "(", "video_train_tmp", "[", "0", "]", ")", "\n", "assert", "audio_train_tmp", "[", "1", "]", "[", "0", "]", "==", "video_train_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_train_tmp", "[", "0", "]", "[", "0", "]", ",", "video_train_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "tmp_root", "=", "Path", "(", "output_path_features", ")", "/", "features_split_name", "\n", "test_name", "=", "sorted", "(", "(", "tmp_root", "/", "\"audio/stage_2_test_unseen/\"", ")", ".", "iterdir", "(", ")", ")", "[", "0", "]", ".", "name", "\n", "print", "(", "f\"Test name: {test_name}\"", ")", "\n", "audio_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"audio/stage_2_test_unseen/{test_name}\"", ")", "\n", "video_test_tmp", "=", "read_features", "(", "tmp_root", "/", "f\"video/stage_2_test_unseen/{test_name}\"", ")", "\n", "assert", "len", "(", "audio_test_tmp", "[", "0", "]", ")", "==", "len", "(", "video_test_tmp", "[", "0", "]", ")", "\n", "assert", "audio_test_tmp", "[", "1", "]", "[", "0", "]", "==", "video_test_tmp", "[", "1", "]", "[", "0", "]", "\n", "assert", "not", "np", ".", "array_equal", "(", "audio_test_tmp", "[", "0", "]", "[", "0", "]", ",", "video_test_tmp", "[", "0", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.splitting_scripts.ucf_split_features.copy_to_shared": [[197, 202], ["pathlib.Path", "pathlib.Path", "shutil.copytree"], "function", ["None"], ["", "def", "copy_to_shared", "(", ")", ":", "\n", "    ", "my_file", "=", "Path", "(", "\"/home/lriesch29/ExplainableAudioVisualLowShotLearning/dat/UCF/\"", ")", "\n", "to_file", "=", "Path", "(", "'/home/lriesch29/akata-shared/shared/avzsl/UCF/'", ")", "\n", "\n", "shutil", ".", "copytree", "(", "my_file", ",", "to_file", ",", "dirs_exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.CPU_Unpickler.find_class": [[180, 185], ["super().find_class", "torch.load", "io.BytesIO"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.CPU_Unpickler.find_class"], ["    ", "def", "find_class", "(", "self", ",", "module", ",", "name", ")", ":", "\n", "        ", "if", "module", "==", "'torch.storage'", "and", "name", "==", "'_load_from_bytes'", ":", "\n", "            ", "return", "lambda", "b", ":", "torch", ".", "load", "(", "io", ".", "BytesIO", "(", "b", ")", ",", "map_location", "=", "'cpu'", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "find_class", "(", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.normalize": [[20, 24], ["numpy.atleast_1d", "numpy.linalg.norm", "numpy.expand_dims"], "function", ["None"], ["def", "normalize", "(", "a", ",", "axis", "=", "-", "1", ",", "order", "=", "2", ")", ":", "\n", "    ", "l2", "=", "np", ".", "atleast_1d", "(", "np", ".", "linalg", ".", "norm", "(", "a", ",", "order", ",", "axis", ")", ")", "\n", "l2", "[", "l2", "==", "0", "]", "=", "1", "\n", "return", "a", "/", "np", ".", "expand_dims", "(", "l2", ",", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.accuracy": [[26, 39], ["torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics._hungarian_match": [[41, 67], ["numpy.zeros", "range", "linear_sum_assignment", "range", "isinstance", "isinstance", "range", "len", "res.append", "int"], "function", ["None"], ["", "", "def", "_hungarian_match", "(", "flat_preds", ",", "flat_targets", ",", "preds_k", ",", "targets_k", ")", ":", "\n", "    ", "from", "scipy", ".", "optimize", "import", "linear_sum_assignment", "\n", "\n", "assert", "(", "isinstance", "(", "flat_preds", ",", "torch", ".", "Tensor", ")", "and", "isinstance", "(", "flat_targets", ",", "torch", ".", "Tensor", ")", ")", "\n", "\n", "num_samples", "=", "flat_targets", ".", "shape", "[", "0", "]", "\n", "assert", "(", "preds_k", "==", "targets_k", ")", "# one to one", "\n", "num_k", "=", "preds_k", "\n", "num_correct", "=", "np", ".", "zeros", "(", "(", "num_k", ",", "num_k", ")", ")", "\n", "\n", "for", "c1", "in", "range", "(", "num_k", ")", ":", "\n", "        ", "for", "c2", "in", "range", "(", "num_k", ")", ":", "\n", "# elementwise, so each sample contributes once", "\n", "            ", "votes", "=", "int", "(", "(", "(", "flat_preds", "==", "c1", ")", "*", "(", "flat_targets", "==", "c2", ")", ")", ".", "sum", "(", ")", ")", "\n", "num_correct", "[", "c1", ",", "c2", "]", "=", "votes", "\n", "\n", "# num_correct is small", "\n", "", "", "match", "=", "linear_sum_assignment", "(", "num_samples", "-", "num_correct", ")", "\n", "\n", "# return as list of tuples, out_c to gt_c", "\n", "res", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "match", "[", "0", "]", ")", ")", ":", "\n", "        ", "out_c", ",", "gt_c", "=", "match", "[", "0", "]", "[", "i", "]", ",", "match", "[", "1", "]", "[", "i", "]", "\n", "res", ".", "append", "(", "(", "out_c", ",", "gt_c", ")", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics._acc": [[69, 81], ["isinstance", "isinstance", "print", "int", "float", "preds.max", "targets.max"], "function", ["None"], ["", "def", "_acc", "(", "preds", ",", "targets", ",", "num_k", ",", "verbose", "=", "0", ")", ":", "\n", "    ", "assert", "(", "isinstance", "(", "preds", ",", "torch", ".", "Tensor", ")", "and", "isinstance", "(", "targets", ",", "torch", ".", "Tensor", ")", ")", "\n", "\n", "if", "verbose", ">=", "2", ":", "\n", "        ", "print", "(", "\"calling acc...\"", ")", "\n", "\n", "", "assert", "(", "preds", ".", "shape", "==", "targets", ".", "shape", ")", "\n", "assert", "(", "preds", ".", "max", "(", ")", "<", "num_k", "and", "targets", ".", "max", "(", ")", "<", "num_k", ")", "\n", "\n", "acc", "=", "int", "(", "(", "preds", "==", "targets", ")", ".", "sum", "(", ")", ")", "/", "float", "(", "preds", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.cluster_acc": [[83, 93], ["numpy.zeros", "clustering_metrics._acc", "len", "torch.tensor().to", "print", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._acc"], ["", "def", "cluster_acc", "(", "match", ",", "preds", ",", "targets", ",", "num_k", "=", "309", ",", "verbose", "=", "1", ")", ":", "\n", "# reorder predictions to be same cluster assignments as gt_k", "\n", "    ", "reordered_preds", "=", "np", ".", "zeros", "(", "len", "(", "targets", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "pred_i", ",", "target_i", "in", "match", ":", "\n", "        ", "reordered_preds", "[", "preds", "==", "pred_i", "]", "=", "target_i", "\n", "if", "verbose", ">", "1", ":", "\n", "            ", "print", "(", "(", "pred_i", ",", "target_i", ")", ")", "\n", "\n", "", "", "acc", "=", "_acc", "(", "torch", ".", "tensor", "(", "reordered_preds", ")", ".", "to", "(", "torch", ".", "long", ")", ",", "targets", ",", "num_k", ",", "True", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics.k_means": [[95, 176], ["CPU_Unpickler().load", "sklearn.metrics.cluster.normalized_mutual_info_score", "sklearn.metrics.cluster.adjusted_mutual_info_score", "sklearn.metrics.cluster.adjusted_rand_score", "print", "print", "print", "numpy.unique", "print", "print", "print", "torch.tensor", "torch.tensor", "clustering_metrics._hungarian_match", "clustering_metrics.cluster_acc", "print", "PS[].cpu().numpy", "len", "range", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.mul", "torch.mul.argmax().cpu().numpy", "PS[].cpu().numpy", "of_this_cluster.sum", "clustering_metrics.CPU_Unpickler", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.mul", "torch.mul.argmax().cpu().numpy", "sklearn.metrics.cluster.normalized_mutual_info_score", "print", "numpy.unique", "purities.append", "entropies.append", "enumerate", "enumerate", "open", "PS[].cpu", "torch.mul.argmax().cpu", "PS[].cpu", "scipy.stats.entropy", "numpy.mean", "numpy.mean", "numpy.unique", "len", "torch.mul.argmax().cpu", "max", "sum", "numpy.unique", "torch.mul.argmax", "sum", "torch.mul.argmax"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._hungarian_match", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.cluster_acc"], ["", "def", "k_means", "(", "\n", "path", "=", "\"cluster_fit_PS_matrices_scratch_vgg_sound_train.pkl\"", ",", "\n", "ncentroids", "=", "512", ",", "\n", "use_all_heads", "=", "False", "\n", ")", ":", "\n", "# Load matrics", "\n", "# PS = pickle.load(open(path, 'rb'))", "\n", "    ", "PS", "=", "CPU_Unpickler", "(", "open", "(", "path", ",", "'rb'", ")", ")", ".", "load", "(", ")", "\n", "\n", "# SELAVI", "\n", "if", "use_all_heads", ":", "\n", "        ", "PS_v_all_heads", "=", "PS", "[", "0", "]", "\n", "PS_a_all_heads", "=", "PS", "[", "2", "]", "\n", "true_labels", "=", "PS", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "num_heads", "=", "len", "(", "PS_v_all_heads", ")", "\n", "best_nmi", "=", "0", "\n", "best_self_labels", "=", "None", "\n", "for", "h", "in", "range", "(", "num_heads", ")", ":", "\n", "            ", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "PS_v_all_heads", "[", "h", "]", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "PS_a_all_heads", "[", "h", "]", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_av", "=", "torch", ".", "mul", "(", "PS_v_sk", ",", "PS_a_sk", ")", "\n", "self_labels_np", "=", "PS_av", ".", "argmax", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "nmi", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "true_labels", ",", "average_method", "=", "'arithmetic'", ")", "\n", "print", "(", "f\"Head {h}: {nmi}\"", ")", "\n", "if", "nmi", ">", "best_nmi", ":", "\n", "                ", "best_nmi", "=", "nmi", "\n", "best_self_labels", "=", "self_labels_np", "\n", "", "", "self_labels_np", "=", "best_self_labels", "\n", "", "else", ":", "\n", "        ", "PS_v", "=", "PS", "[", "0", "]", "\n", "PS_a", "=", "PS", "[", "2", "]", "\n", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "PS_v", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "PS_a", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_av", "=", "torch", ".", "mul", "(", "PS_v_sk", ",", "PS_a_sk", ")", "\n", "self_labels_np", "=", "PS_av", ".", "argmax", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "true_labels", "=", "PS", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Get NMI and a-NMI values", "\n", "", "nmi_to_labels_v", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "anmi_to_labels_v", "=", "adjusted_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "ari_to_labels_v", "=", "adjusted_rand_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", ")", "\n", "print", "(", "f\"NMI-tolabels: {nmi_to_labels_v}\"", ")", "\n", "print", "(", "f\"aNMI-tolabels: {anmi_to_labels_v}\"", ")", "\n", "print", "(", "f\"aRI-tolabels: {ari_to_labels_v}\"", ")", "\n", "\n", "# Get entropy and purtiy values", "\n", "purities", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "for", "sk_label", "in", "np", ".", "unique", "(", "self_labels_np", ")", ":", "\n", "        ", "of_this_cluster", "=", "self_labels_np", "==", "sk_label", "\n", "size", "=", "of_this_cluster", ".", "sum", "(", ")", "\n", "if", "size", "!=", "0", ":", "\n", "            ", "uniq", ",", "counts", "=", "np", ".", "unique", "(", "true_labels", "[", "of_this_cluster", "]", ",", "return_counts", "=", "True", ")", "\n", "purities", ".", "append", "(", "max", "(", "counts", ")", "/", "sum", "(", "1.0", "*", "counts", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", "(", "counts", "/", "sum", "(", "1.0", "*", "counts", ")", ")", ")", "\n", "", "", "print", "(", "f'Avg entropy: {np.mean(entropies)}   avg purity: {np.mean(purities)}'", ")", "\n", "\n", "translate_to_low_classes", "=", "{", "n", ":", "a", "for", "a", ",", "n", "in", "enumerate", "(", "np", ".", "unique", "(", "true_labels", ")", ")", "}", "\n", "true_labels", "=", "[", "translate_to_low_classes", "[", "n", "]", "for", "_", ",", "n", "in", "enumerate", "(", "true_labels", ")", "]", "\n", "print", "(", "f\"Number of unique classes: {len(np.unique(true_labels))}\"", ")", "\n", "print", "(", "f\"Number of centroids: {ncentroids}\"", ")", "\n", "\n", "self_labels", "=", "torch", ".", "tensor", "(", "self_labels_np", ")", "\n", "true_labels", "=", "torch", ".", "tensor", "(", "true_labels", ")", "\n", "match", "=", "_hungarian_match", "(", "self_labels", ",", "true_labels", ",", "ncentroids", ",", "ncentroids", ")", "\n", "clust_acc", "=", "cluster_acc", "(", "match", ",", "self_labels", ",", "true_labels", ",", "ncentroids", ")", "\n", "print", "(", "f'Clustering Acc: {clust_acc * 100}%'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.opt.parse_arguments": [[10, 154], ["argparse.ArgumentParser", "argparse.ArgumentParser.register", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "v.lower.lower", "ValueError"], "function", ["None"], ["def", "parse_arguments", "(", ")", ":", "\n", "    ", "def", "str2bool", "(", "v", ")", ":", "\n", "        ", "v", "=", "v", ".", "lower", "(", ")", "\n", "if", "v", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'1'", ")", ":", "\n", "            ", "return", "True", "\n", "", "elif", "v", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'0'", ")", ":", "\n", "            ", "return", "False", "\n", "", "raise", "ValueError", "(", "'Boolean argument needs to be true or false. '", "\n", "'Instead, it is %s.'", "%", "v", ")", "\n", "\n", "", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Implementation of SwAV\"", ")", "\n", "parser", ".", "register", "(", "'type'", ",", "'bool'", ",", "str2bool", ")", "\n", "\n", "#########################", "\n", "#### data parameters ####", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "\"--ds_name\"", ",", "type", "=", "str", ",", "default", "=", "\"kinetics\"", ",", "\n", "choices", "=", "[", "'kinetics'", ",", "'vggsound'", ",", "'kinetics_sound'", ",", "'ave'", ",", "'ucf101'", ",", "'hmdb51'", ",", "\"audioset_zsl\"", "]", ",", "\n", "help", "=", "\"name of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--root_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/path/to/dataset\"", ",", "\n", "help", "=", "\"root dir of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_path\"", ",", "type", "=", "str", ",", "default", "=", "\"datasets/data\"", ",", "\n", "help", "=", "\"path to store dataset pkl files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_data_samples\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"number of dataset samples\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_frames\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"number of frames to sample per clip\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--target_fps\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"video fps\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample_rate\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"rate to sample frames\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_clips\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"number of clips to sample per videos\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_crop_size\"", ",", "type", "=", "int", ",", "default", "=", "112", ",", "\n", "help", "=", "\"train crop size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_crop_size\"", ",", "type", "=", "int", ",", "default", "=", "112", ",", "\n", "help", "=", "\"test crop size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--colorjitter'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use color jitter'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_grayscale'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use grayscale augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_gaussian'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use gaussian augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_sec_aud\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"number of seconds of audio\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_sample_rate\"", ",", "type", "=", "int", ",", "default", "=", "48000", ",", "\n", "help", "=", "\"audio sample rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_spec_type\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "\"audio spec type\"", ")", "\n", "parser", ".", "add_argument", "(", "'--use_volume_jittering'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use volume jittering'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_audio_temp_jittering'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use audio temporal jittering'", ")", "\n", "parser", ".", "add_argument", "(", "'--z_normalize'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'z-normalize the audio'", ")", "\n", "parser", ".", "add_argument", "(", "'--dual_data'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'sample two clips per video'", ")", "\n", "\n", "#########################", "\n", "#### optim parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of total epochs to run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "16", ",", "type", "=", "int", ",", "\n", "help", "=", "\"batch size per gpu, i.e. how many unique instances per gpu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base_lr\"", ",", "default", "=", "4.8", ",", "type", "=", "float", ",", "help", "=", "\"base learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wd\"", ",", "default", "=", "1e-6", ",", "type", "=", "float", ",", "help", "=", "\"weight decay\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"number of warmup epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_warmup_scheduler\"", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "\"use warmup scheduler\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_lr_scheduler\"", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "\"use cosine LR scheduler\"", ")", "\n", "\n", "#########################", "\n", "#### SK parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "'--schedulepower'", ",", "default", "=", "1.5", ",", "type", "=", "float", ",", "\n", "help", "=", "'SK schedule power compared to linear (default: 1.5)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nopts'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of pseudo-opts (default: 100)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lamb'", ",", "default", "=", "20", ",", "type", "=", "int", ",", "\n", "help", "=", "'for pseudoopt: lambda (default:25) '", ")", "\n", "parser", ".", "add_argument", "(", "'--dist'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "'use for distribution'", ")", "\n", "parser", ".", "add_argument", "(", "'--diff_dist_every'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'use a different Gaussian at every SK-iter?'", ")", "\n", "parser", ".", "add_argument", "(", "'--diff_dist_per_head'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'use a different Gaussian for every head?'", ")", "\n", "\n", "#########################", "\n", "#### Selavi parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "'--ind_groups'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of independent groups (default: 100)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gauss_sd'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "\n", "help", "=", "'sd'", ")", "\n", "parser", ".", "add_argument", "(", "'--match'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'match distributions at beginning of training'", ")", "\n", "parser", ".", "add_argument", "(", "'--distribution'", ",", "default", "=", "'default'", ",", "type", "=", "str", ",", "\n", "help", "=", "'distribution of SK-clustering'", ",", "choices", "=", "[", "'gauss'", ",", "'default'", ",", "'zipf'", "]", ")", "\n", "\n", "#########################", "\n", "#### dist parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "\"--dist_url\"", ",", "default", "=", "\"env://\"", ",", "type", "=", "str", ",", "help", "=", "\"\"\"url used to set up distributed\n                        training; see https://pytorch.org/docs/stable/distributed.html\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--world_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"\"\"\n                        number of processes: it is set automatically and\n                        should not be passed as argument\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"\"\"rank of this process:\n                        it is set automatically and should not be passed as argument\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"this argument is not used and should be ignored\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bash\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"slrum bash mode\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume\"", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "help", "=", "\"slrum bash mode\"", ")", "\n", "\n", "#########################", "\n", "#### model parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "\"--vid_base_arch\"", ",", "default", "=", "\"r2plus1d_18\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"video architecture\"", ",", "choices", "=", "[", "'r2plus1d_18'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_base_arch\"", ",", "default", "=", "\"resnet9\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"audio architecture\"", ",", "choices", "=", "[", "'resnet9'", ",", "'resnet18'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mlp'", ",", "type", "=", "'bool'", ",", "default", "=", "'True'", ",", "\n", "help", "=", "'use MLP head'", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlp_dim\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"final layer dimension in projection head\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--headcount\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of heads\"", ")", "\n", "\n", "#########################", "\n", "#### other parameters ###", "\n", "#########################", "\n", "parser", ".", "add_argument", "(", "\"--workers\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of data loading workers\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_freq\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Save the model periodically\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_fp16\"", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "\"whether to train with mixed precision or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sync_bn\"", ",", "type", "=", "str", ",", "default", "=", "\"pytorch\"", ",", "help", "=", "\"synchronize bn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dump_path\"", ",", "type", "=", "str", ",", "default", "=", "\".\"", ",", "\n", "help", "=", "\"experiment dump path for checkpoints and log\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "31", ",", "help", "=", "\"seed\"", ")", "\n", "return", "parser", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.main.main": [[50, 243], ["opt.parse_arguments", "opt.parse_arguments.parse_args", "utils.init_distributed_mode", "utils.init_signal_handler", "utils.fix_random_seeds", "utils.initialize_exp", "datasets.AVideoDataset.AVideoDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logger.info", "model.load_model", "apex.parallel.convert_syncbn_model.cuda", "logger.info", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "logger.info", "torch.parallel.DistributedDataParallel", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "logger.info", "utils.restart_from_checkpoint", "range", "torch.utils.tensorboard.SummaryWriter", "torch.SyncBatchNorm.convert_sync_batchnorm", "logger.info", "apex.parallel.convert_syncbn_model.parameters", "src.warmup_scheduler.GradualWarmupScheduler", "apex.amp.initialize", "logger.info", "os.path.join", "[].tolist", "torch.utils.data.DataLoader.sampler.set_epoch", "utils.warmup_batchnorm", "logger.info", "torch.utils.data.DataLoader.sampler.set_epoch", "main.train", "training_stats.update", "len", "apex.parallel.convert_syncbn_model", "len", "sum", "torch.utils.tensorboard.SummaryWriter.add_scalar", "src.warmup_scheduler.GradualWarmupScheduler.step", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "apex.parallel.create_syncbn_process_group", "src.warmup_scheduler.GradualWarmupScheduler.step", "apex.parallel.convert_syncbn_model.state_dict", "torch.optim.SGD.state_dict", "apex.amp.state_dict", "os.path.join", "shutil.copyfile", "numpy.round", "numpy.array", "range", "os.path.join", "os.path.join", "numpy.linspace", "str"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.opt.parse_arguments", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.init_distributed_mode", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.init_signal_handler", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.fix_random_seeds", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.initialize_exp", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.load_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.restart_from_checkpoint", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.warmup_batchnorm", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step"], [")", "\n", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"VGGSound\"", ":", "\n", "        ", "train_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "VGGSoundDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"UCF\"", ":", "\n", "        ", "train_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "UCFDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "elif", "args", ".", "dataset_name", "==", "\"ActivityNet\"", ":", "\n", "        ", "train_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train\"", ",", "\n", "zero_shot_mode", "=", "\"train\"", ",", "\n", ")", "\n", "val_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "train_val_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"train_val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "\n", "val_all_dataset", "=", "ActivityNetDataset", "(", "\n", "args", "=", "args", ",", "\n", "dataset_split", "=", "\"val\"", ",", "\n", "zero_shot_mode", "=", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "contrastive_train_dataset", "=", "ContrastiveDataset", "(", "train_dataset", ")", "\n", "contrastive_val_dataset", "=", "ContrastiveDataset", "(", "val_dataset", ")", "\n", "contrastive_train_val_dataset", "=", "ContrastiveDataset", "(", "train_val_dataset", ")", "\n", "contrastive_val_all_dataset", "=", "ContrastiveDataset", "(", "val_all_dataset", ")", "\n", "\n", "train_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_train_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "val_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_val_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "train_val_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_train_val_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "val_all_sampler", "=", "SamplerFactory", "(", "logger", ")", ".", "get", "(", "\n", "class_idxs", "=", "list", "(", "contrastive_val_all_dataset", ".", "target_to_indices", ".", "values", "(", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "n_batches", "=", "args", ".", "n_batches", ",", "\n", "alpha", "=", "1", ",", "\n", "kind", "=", "'random'", "\n", ")", "\n", "\n", "train_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_train_dataset", ",", "\n", "batch_sampler", "=", "train_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "val_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_val_dataset", ",", "\n", "batch_sampler", "=", "val_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "train_val_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_train_val_dataset", ",", "\n", "batch_sampler", "=", "train_val_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "val_all_loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "contrastive_val_all_dataset", ",", "\n", "batch_sampler", "=", "val_all_sampler", ",", "\n", "num_workers", "=", "8", "\n", ")", "\n", "\n", "if", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model_params", "=", "get_model_params", "(", "args", ".", "lr", ",", "args", ".", "first_additional_triplet", ",", "args", ".", "second_additional_triplet", ",", "args", ".", "reg_loss", ",", "args", ".", "additional_triplets_loss", ",", "args", ".", "embedding_dropout", ",", "args", ".", "decoder_dropout", ",", "args", ".", "additional_dropout", ",", "args", ".", "embeddings_hidden_size", ",", "args", ".", "decoder_hidden_size", ",", "args", ".", "depth_transformer", ",", "args", ".", "momentum", ")", "\n", "\n", "\n", "", "if", "args", ".", "ale", "==", "True", "or", "args", ".", "devise", "==", "True", "or", "args", ".", "sje", "==", "True", ":", "\n", "        ", "model", "=", "DeviseModel", "(", "args", ")", "\n", "", "elif", "args", ".", "apn", "==", "True", ":", "\n", "        ", "model", "=", "APN", "(", "args", ")", "\n", "", "elif", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "model", "=", "CJME", "(", "args", ")", "\n", "", "elif", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "model", "=", "AVCA", "(", "model_params", ",", "input_size_audio", "=", "args", ".", "input_size_audio", ",", "input_size_video", "=", "args", ".", "input_size_video", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "AVGZSLNet", "(", "args", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "distance_fn", "=", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "args", ".", "distance_fn", ")", "(", ")", "\n", "if", "args", ".", "ale", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "False", ",", "topk", "=", "None", ",", "reduction", "=", "\"weighted\"", ")", "\n", "", "elif", "args", ".", "devise", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "False", ",", "topk", "=", "None", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "elif", "args", ".", "sje", "==", "True", ":", "\n", "        ", "criterion", "=", "ClsContrastiveLoss", "(", "margin", "=", "0.1", ",", "max_violation", "=", "True", ",", "topk", "=", "1", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "elif", "args", ".", "apn", "==", "True", ":", "\n", "        ", "criterion", "=", "APN_Loss", "(", ")", "\n", "", "elif", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "criterion", "=", "CJMELoss", "(", "margin", "=", "args", ".", "margin", ",", "distance_fn", "=", "distance_fn", ")", "\n", "", "elif", "args", ".", "AVCA", "==", "True", ":", "\n", "        ", "criterion", "=", "None", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "AVGZSLLoss", "(", "margin", "=", "args", ".", "margin", ",", "distance_fn", "=", "distance_fn", ")", "\n", "\n", "", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "\n", "lr_scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "'max'", ",", "patience", "=", "3", ",", "verbose", "=", "True", ")", "if", "args", ".", "lr_scheduler", "else", "None", "\n", "\n", "metrics", "=", "[", "\n", "MeanClassAccuracy", "(", "model", "=", "model", ",", "dataset", "=", "val_all_dataset", ",", "device", "=", "args", ".", "device", ",", "distance_fn", "=", "distance_fn", ",", "\n", "model_devise", "=", "args", ".", "ale", "or", "args", ".", "sje", "or", "args", ".", "devise", ",", "\n", "new_model_attention", "=", "args", ".", "AVCA", ",", "\n", "apn", "=", "args", ".", "apn", ",", "\n", "args", "=", "args", ")", "\n", "]", "\n", "\n", "\n", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "criterion", ")", "\n", "logger", ".", "info", "(", "optimizer", ")", "\n", "logger", ".", "info", "(", "lr_scheduler", ")", "\n", "logger", ".", "info", "(", "[", "metric", ".", "__class__", ".", "__name__", "for", "metric", "in", "metrics", "]", ")", "\n", "\n", "if", "args", ".", "val_all_loss", ":", "\n", "        ", "v_loader", "=", "val_all_loader", "\n", "", "elif", "args", ".", "retrain_all", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.main.train": [[246, 347], ["model.train", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "time.time", "enumerate", "torch.barrier", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "len", "utils.AverageMeter.update", "model", "utils.get_loss", "utils.get_loss", "optimizer.zero_grad", "optimizer.step", "utils.AverageMeter.update", "utils.AverageMeter.update", "time.time", "video.cuda", "audio.cuda", "loss.backward", "loss.item", "inputs[].size", "logger.info", "time.time", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sk_schedule.pop", "src.sk_utils.cluster", "apex.amp.scale_loss", "scaled_loss.backward", "time.time", "len", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "utils.trigger_job_requeue", "loss.item", "os.path.join"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.get_loss", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.get_loss", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sk_utils.cluster", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.trigger_job_requeue"], ["        ", "v_loader", "=", "val_loader", "\n", "\n", "", "best_loss", ",", "best_score", "=", "train", "(", "\n", "train_loader", "=", "train_val_loader", "if", "args", ".", "retrain_all", "else", "train_loader", ",", "\n", "val_loader", "=", "v_loader", ",", "\n", "model", "=", "model", ",", "\n", "criterion", "=", "criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "epochs", "=", "args", ".", "epochs", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "writer", "=", "writer", ",", "\n", "metrics", "=", "metrics", ",", "\n", "train_stats", "=", "train_stats", ",", "\n", "new_model_attention", "=", "args", ".", "AVCA", ",", "\n", "val_stats", "=", "val_stats", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "model_devise", "=", "args", ".", "ale", "or", "args", ".", "sje", "or", "args", ".", "devise", ",", "\n", "apn", "=", "args", ".", "apn", ",", "\n", "cjme", "=", "args", ".", "cjme", ",", "\n", "args", "=", "args", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"FINISHED. Run is stored at {log_dir}\"", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.Subset_Sampler.__init__": [[35, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.Subset_Sampler.__iter__": [[38, 40], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.Subset_Sampler.__len__": [[41, 43], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.accuracy": [[45, 58], ["torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.get_cluster_assignments_gpu": [[60, 220], ["torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.eval", "len", "torch.arange().int", "torch.arange().int", "get_clusters.Subset_Sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "enumerate", "torch.barrier", "tqdm.tqdm", "video.cuda.cuda", "audio.cuda.cuda", "label.cuda.cuda", "range", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "os.makedirs", "os.path.join", "print", "torch.barrier", "torch.arange", "torch.arange", "len", "model", "f_v.append", "f_a.append", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.barrier", "open", "pickle.dump", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "aggregtensor", "aggregtensor", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "len", "torch.stack().mean.size", "torch.stack().mean.size", "len", "torch.stack().mean.size", "range", "torch.stack().mean.size", "range", "range", "range", "torch.stack().mean.size", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "label.cuda.size", "filename.size"], "function", ["None"], ["", "", "def", "get_cluster_assignments_gpu", "(", "\n", "args", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "logger", "=", "None", ",", "\n", "device", "=", "'cuda'", "\n", ")", ":", "\n", "# clear cache at beginning", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "N", "=", "len", "(", "dataset", ")", "\n", "# this process deals only with a subset of the dataset", "\n", "local_nmb_data", "=", "N", "//", "args", ".", "world_size", "\n", "train_indices", "=", "torch", ".", "arange", "(", "\n", "args", ".", "rank", "*", "local_nmb_data", ",", "\n", "(", "args", ".", "rank", "+", "1", ")", "*", "local_nmb_data", "\n", ")", ".", "int", "(", ")", "\n", "# create subset sampler", "\n", "sampler", "=", "Subset_Sampler", "(", "train_indices", ")", "\n", "\n", "# we need a data loader", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "#drop_last=True  # New", "\n", ")", "\n", "\n", "# Ensure processes reach to end of optim clusters", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "# use GAP features", "\n", "", "if", "args", ".", "headcount", ">", "1", ":", "\n", "        ", "model", ".", "module", ".", "return_features", "=", "True", "\n", "", "aggregtensor", "=", "torch", ".", "cuda", ".", "DoubleTensor", "if", "args", ".", "headcount", "==", "1", "else", "torch", ".", "cuda", ".", "FloatTensor", "\n", "dtype", "=", "torch", ".", "float64", "if", "args", ".", "headcount", "==", "1", "else", "torch", ".", "float32", "\n", "\n", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "dataloader", ")", ")", ":", "\n", "# print(f\"{batch_idx}/{len(dataloader)}\", end='\\r', flush=True)", "\n", "# if batch_idx > 1:", "\n", "#     break", "\n", "# print(f\"{batch_idx}/{len(dataloader)}\", flush=True)", "\n", "# Get data", "\n", "# if batch_idx > len(dataloader)//10:", "\n", "#    break", "\n", "        ", "video", ",", "audio", ",", "label", ",", "_", ",", "_", ",", "filename", "=", "batch", "\n", "\n", "# Move to GPU", "\n", "video", "=", "video", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "audio", "=", "audio", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "label", "=", "label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "# Forward pass", "\n", "# feat_v, feat_a = model(video, audio) # OLD", "\n", "\n", "# Slow", "\n", "f_v", ",", "f_a", "=", "[", "]", ",", "[", "]", "\n", "for", "sec", "in", "range", "(", "len", "(", "video", "[", "0", "]", ")", ")", ":", "\n", "            ", "vid", ",", "aud", "=", "model", "(", "video", "[", ":", ",", "sec", "]", ",", "audio", "[", ":", ",", "sec", "]", ")", "\n", "f_v", ".", "append", "(", "vid", ")", "\n", "f_a", ".", "append", "(", "aud", ")", "\n", "", "feat_v", "=", "torch", ".", "stack", "(", "f_v", ",", "dim", "=", "0", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "feat_a", "=", "torch", ".", "stack", "(", "f_a", ",", "dim", "=", "0", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "\"\"\"\n        video_splits = torch.squeeze(video, dim=0).split(32)\n        audio_splits = torch.squeeze(audio, dim=0).split(32)\n        vids = torch.zeros((video.shape[1], 512), dtype=dtype, device=device)\n        auds = torch.zeros((audio.shape[1], 512), dtype=dtype, device=device)\n        f = 0\n        for idx in range(len(video_splits)):\n            vid, aud = model(video_splits[idx], audio_splits[idx])\n            t = f + video_splits[idx].shape[0]\n            vids[f:t] = vid\n            auds[f:t] = aud\n            f = t\n        #f_v_fast, f_a_fast = model(torch.squeeze(video, dim=0), torch.squeeze(audio, dim=0))\n        #feat_v = f_v_fast.mean(dim=0)\n        #feat_a = f_a_fast.mean(dim=0)\n        feat_v = vids.mean(dim=0)\n        feat_a = auds.mean(dim=0)\n        \"\"\"", "\n", "\n", "# gather the features computed by all processes", "\n", "if", "args", ".", "distributed", ":", "\n", "            ", "all_feat_v_list", "=", "[", "aggregtensor", "(", "feat_v", ".", "size", "(", ")", ")", "for", "src", "in", "range", "(", "args", ".", "world_size", ")", "]", "\n", "all_feat_a_list", "=", "[", "aggregtensor", "(", "feat_a", ".", "size", "(", ")", ")", "for", "src", "in", "range", "(", "args", ".", "world_size", ")", "]", "\n", "all_labels_list", "=", "[", "torch", ".", "zeros", "(", "label", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "for", "_", "in", "range", "(", "args", ".", "world_size", ")", "]", "\n", "all_filenames_list", "=", "[", "torch", ".", "zeros", "(", "filename", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "for", "_", "in", "\n", "range", "(", "args", ".", "world_size", ")", "]", "\n", "\n", "dist", ".", "all_gather", "(", "all_feat_v_list", ",", "feat_v", ")", "\n", "dist", ".", "all_gather", "(", "all_feat_a_list", ",", "feat_a", ")", "\n", "dist", ".", "all_gather", "(", "all_labels_list", ",", "label", ")", "\n", "dist", ".", "all_gather", "(", "all_filenames_list", ",", "filename", ")", "\n", "", "else", ":", "\n", "            ", "all_feat_v_list", "=", "[", "feat_v", "]", "\n", "all_feat_a_list", "=", "[", "feat_a", "]", "\n", "all_labels_list", "=", "[", "label", "]", "\n", "all_filenames_list", "=", "[", "filename", "]", "\n", "\n", "# only main process stores all features", "\n", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "all_feat_v", "=", "torch", ".", "cat", "(", "all_feat_v_list", ")", "\n", "all_feat_a", "=", "torch", ".", "cat", "(", "all_feat_a_list", ")", "\n", "all_labels", "=", "torch", ".", "cat", "(", "all_labels_list", ")", "#.cpu()", "\n", "all_filenames", "=", "np", ".", "concatenate", "(", "all_filenames_list", ")", "\n", "\n", "", "if", "batch_idx", "==", "0", "and", "(", "args", ".", "rank", "==", "0", ")", ":", "\n", "            ", "fr", "=", "0", "\n", "if", "len", "(", "feat_v", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "K", "=", "feat_v", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "K", "=", "feat_v", ".", "size", "(", "0", ")", "\n", "", "PS_v", "=", "torch", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "PS_a", "=", "torch", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "labels", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "filenames", "=", "[", "]", "\n", "\n", "# fill in arrays on main node", "\n", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "if", "len", "(", "all_feat_v", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "to", "=", "fr", "+", "all_feat_v", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "to", "=", "fr", "+", "1", "\n", "", "PS_v", "[", "fr", ":", "to", "]", "=", "all_feat_v", "\n", "PS_a", "[", "fr", ":", "to", "]", "=", "all_feat_a", "\n", "labels", "[", "fr", ":", "to", "]", "=", "all_labels", "\n", "filenames", "[", "fr", ":", "to", "]", "=", "all_filenames", "\n", "fr", "=", "to", "\n", "\n", "", "if", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "# Dump results", "\n", "", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "# PS_v_heads, PS_a_heads = [], []", "\n", "# for h in range(args.headcount):", "\n", "#     head_a = getattr(model.module, f'mlp_a{h}')", "\n", "#     head_v = getattr(model.module, f'mlp_v{h}')", "\n", "#     PS_v_heads.append(head_v.forward(PS_v))", "\n", "#     PS_a_heads.append(head_a.forward(PS_a))", "\n", "# PS = [PS_v_heads, labels, PS_a_heads]", "\n", "        ", "PS", "=", "[", "PS_v", ",", "labels", ",", "PS_a", ",", "filenames", "]", "# only save pre-mlp 512 dim features", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f'{args.exp_desc}.pkl'", ")", "\n", "with", "open", "(", "save_path", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "PS", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "print", "(", "f\"Finished Dumping!\"", ")", "\n", "\n", "# Make other processes wait", "\n", "", "if", "args", ".", "distributed", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.parse_args": [[222, 308], ["argparse.ArgumentParser", "argparse.ArgumentParser.register", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "v.lower.lower", "ValueError"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "def", "str2bool", "(", "v", ")", ":", "\n", "        ", "v", "=", "v", ".", "lower", "(", ")", "\n", "if", "v", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'1'", ")", ":", "\n", "            ", "return", "True", "\n", "", "elif", "v", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'0'", ")", ":", "\n", "            ", "return", "False", "\n", "", "raise", "ValueError", "(", "'Boolean argument needs to be true or false. '", "\n", "'Instead, it is %s.'", "%", "v", ")", "\n", "\n", "", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Video Cluster Fit'", ")", "\n", "parser", ".", "register", "(", "'type'", ",", "'bool'", ",", "str2bool", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "'.'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path where to save'", ")", "\n", "parser", ".", "add_argument", "(", "'--weights_path'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to weights file'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_desc'", ",", "default", "=", "'vggsound_clusters'", ",", "type", "=", "str", ",", "\n", "help", "=", "'desc of exp'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "\"Use pre-trained models from the modelzoo\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'vggsound'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'kinetics'", ",", "'vggsound'", ",", "'kinetics_sound'", ",", "'ave'", ",", "\"audioset_zsl\"", ",", "\"ucf\"", ",", "\"activity\"", "]", ",", "\n", "help", "=", "'name of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\"--root_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/path/to/dataset\"", ",", "\n", "help", "=", "\"root dir of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "default", "=", "'val'", ",", "type", "=", "str", ",", "\n", "help", "=", "'mode of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_data_samples'", ",", "default", "=", "14032", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of samples in dataset'", ")", "\n", "\n", "# AUDIO UTILS", "\n", "parser", ".", "add_argument", "(", "\"--num_sec_aud\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"number of seconds of audio\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_sample_rate\"", ",", "type", "=", "int", ",", "default", "=", "24000", ",", "\n", "help", "=", "\"audio sample rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_spec_type\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "\"audio spec type\"", ")", "\n", "parser", ".", "add_argument", "(", "'--use_volume_jittering'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use volume jittering'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_audio_temp_jittering'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'use audio temporal jittering'", ")", "\n", "parser", ".", "add_argument", "(", "'--z_normalize'", ",", "type", "=", "'bool'", ",", "default", "=", "'True'", ",", "\n", "help", "=", "'z-normalize the audio'", ")", "\n", "\n", "### DATA", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "96", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of data loading workers (default: 16)'", ")", "\n", "\n", "### MODEL", "\n", "parser", ".", "add_argument", "(", "\"--vid_base_arch\"", ",", "default", "=", "\"r2plus1d_18\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"video architecture\"", ",", "choices", "=", "[", "'r2plus1d_18'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--aud_base_arch\"", ",", "default", "=", "\"resnet9\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"audio architecture\"", ",", "choices", "=", "[", "'resnet9'", ",", "'resnet18'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mlp'", ",", "type", "=", "'bool'", ",", "default", "=", "'True'", ",", "\n", "help", "=", "'use MLP head'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_feat'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'normalize pre-mlp features'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_clusters\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"final layer dimension in projection head\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--headcount\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of heads\"", ")", "\n", "\n", "# distributed training parameters", "\n", "parser", ".", "add_argument", "(", "\"--dist_url\"", ",", "default", "=", "\"env://\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"url used to set up distributed\n                        training; see https://pytorch.org/docs/stable/distributed.html\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--world_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"\"\"\n                        number of processes: it is set automatically and\n                        should not be passed as argument\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"\"\"rank of this process:\n                        it is set automatically and should not be passed as argument\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"this argument is not used and should be ignored\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--distributed\"", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "\"in distributed mode\"", ")", "\n", "\n", "# own arguments", "\n", "parser", ".", "add_argument", "(", "\"--run\"", ",", "choices", "=", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", "]", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of runs (out of 7) for parallel evaluation.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.valid_audio": [[310, 340], ["datasets.AVideoDataset.AVideoDataset", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "valid_audio", "(", "index", ",", "args", ")", ":", "\n", "    ", "dataset", "=", "AVideoDataset", "(", "\n", "ds_name", "=", "args", ".", "dataset", ",", "\n", "root_dir", "=", "args", ".", "root_dir", ",", "\n", "mode", "=", "args", ".", "mode", ",", "\n", "num_frames", "=", "30", ",", "\n", "sample_rate", "=", "1", ",", "\n", "train_crop_size", "=", "112", ",", "\n", "num_data_samples", "=", "args", ".", "num_data_samples", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "True", ",", "\n", "num_sec", "=", "args", ".", "num_sec_aud", ",", "\n", "aud_sample_rate", "=", "args", ".", "aud_sample_rate", ",", "\n", "aud_spec_type", "=", "args", ".", "aud_spec_type", ",", "\n", "use_volume_jittering", "=", "args", ".", "use_volume_jittering", ",", "\n", "use_temporal_jittering", "=", "args", ".", "use_audio_temp_jittering", ",", "\n", "z_normalize", "=", "args", ".", "z_normalize", ",", "\n", "center_crop", "=", "True", ",", "\n", "temp_jitter", "=", "False", ",", "\n", ")", "\n", "try", ":", "\n", "        ", "tmp", "=", "dataset", "[", "index", "]", "\n", "print", "(", "f\"{index}: True\"", ",", "end", "=", "'\\r'", ",", "flush", "=", "True", ")", "\n", "return", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "f\"Index: {index}\"", ")", "\n", "print", "(", "f\"{dataset._path_to_videos[index]}\"", ")", "\n", "print", "(", "e", ")", "\n", "print", "(", "\"-------------------------------------------------------------------\"", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.get_clusters.filter_audios": [[342, 349], ["print", "print", "joblib.Parallel", "enumerate", "joblib.delayed", "range", "len"], "function", ["None"], ["", "", "def", "filter_audios", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"START FILTER AUDIOS\"", ")", "\n", "all_indices", "=", "Parallel", "(", "n_jobs", "=", "30", ")", "(", "\n", "delayed", "(", "valid_audio", ")", "(", "aud_idx", ",", "args", ")", "for", "aud_idx", "in", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "invalid_indices", "=", "[", "i", "for", "i", ",", "val", "in", "enumerate", "(", "all_indices", ")", "if", "not", "val", "]", "\n", "print", "(", "invalid_indices", ")", "\n", "return", "dataset", ".", "_path_to_videos", "[", "invalid_indices", "]", "\n", "# return valid_indices", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.video_retrieval.main": [[17, 57], ["src.retrieval_utils.init", "src.retrieval_utils.load_or_get_features", "src.retrieval_utils.load_or_get_features", "print", "src.retrieval_utils.average_features", "src.retrieval_utils.average_features", "src.retrieval_utils.retrieval"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.init", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_or_get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.load_or_get_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.average_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.average_features", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.retrieval_utils.retrieval"], ["def", "main", "(", "args", ",", "logger", "=", "None", ")", ":", "\n", "\n", "# Get model and datasets", "\n", "    ", "model", ",", "dataset", ",", "dataset_test", "=", "init", "(", "args", ",", "\n", "get_video_encoder_only", "=", "True", ",", "logger", "=", "logger", ")", "\n", "\n", "# Get train features", "\n", "train_features", ",", "train_vid_indices", ",", "train_labels", "=", "load_or_get_features", "(", "\n", "args", ",", "dataset", ",", "model", ",", "\n", "logger", "=", "logger", ",", "mode", "=", "'train'", ",", "get_audio", "=", "args", ".", "get_audio", "\n", ")", "\n", "\n", "# Get val features", "\n", "val_features", ",", "val_vid_indices", ",", "val_labels", "=", "load_or_get_features", "(", "\n", "args", ",", "dataset_test", ",", "model", ",", "\n", "logger", "=", "logger", ",", "mode", "=", "'test'", ",", "get_audio", "=", "args", ".", "get_audio", "\n", ")", "\n", "\n", "# Average features to get mean feat per video", "\n", "print", "(", "\"Averaging features\"", ")", "\n", "train_features", ",", "train_vid_indices", ",", "train_labels", "=", "average_features", "(", "\n", "args", ",", "train_features", ",", "train_vid_indices", ",", "train_labels", ",", "\n", "get_audio", "=", "args", ".", "get_audio", ",", "aud_features", "=", "None", ",", "logger", "=", "logger", "\n", ")", "\n", "val_features", ",", "val_vid_indices", ",", "val_labels", "=", "average_features", "(", "\n", "args", ",", "val_features", ",", "val_vid_indices", ",", "val_labels", ",", "\n", "get_audio", "=", "args", ".", "get_audio", ",", "aud_features", "=", "None", ",", "logger", "=", "logger", "\n", ")", "\n", "\n", "# Get retrieval benchmarks", "\n", "retrieval", "(", "\n", "train_features", ",", "\n", "train_labels", ",", "\n", "train_vid_indices", ",", "\n", "val_features", ",", "\n", "val_labels", ",", "\n", "val_vid_indices", ",", "\n", "train_aud_features", "=", "None", ",", "\n", "val_aud_features", "=", "None", ",", "\n", "task", "=", "'v-v'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Normalize.__init__": [[15, 18], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Normalize.forward": [[19, 23], ["x.pow().sum().pow", "x.div", "x.pow().sum", "x.pow"], "methods", ["None"], ["", "", "class", "LINEAR_SOFTMAX_ALE", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "attri_dim", ")", ":", "\n", "        ", "super", "(", "LINEAR_SOFTMAX_ALE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "attri_dim", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Flatten.__init__": [[27, 29], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["output", "=", "self", ".", "softmax", "(", "middle", ".", "mm", "(", "attribute", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Flatten.forward": [[30, 32], ["x.view"], "methods", ["None"], ["\n", "", "", "class", "LINEAR_SOFTMAX", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Unsqueeze.__init__": [[36, 38], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Unsqueeze.forward": [[39, 41], ["x.unsqueeze"], "methods", ["None"], ["x", "=", "self", ".", "softmax", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Identity.__init__": [[44, 46], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "attri_dim", ")", ":", "\n", "        ", "super", "(", "LAYER_ALE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "attri_dim", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.Identity.forward": [[47, 49], ["None"], "methods", ["None"], ["self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "attribute", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.MLPv2.__init__": [[63, 87], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "model.Flatten", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "model.Flatten", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "model.Unsqueeze", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "model.Flatten", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["self", ".", "dim_dict", "=", "{", "'layer1'", ":", "56", "*", "56", ",", "'layer2'", ":", "28", "*", "28", ",", "'layer3'", ":", "14", "*", "14", ",", "'layer4'", ":", "1", "*", "1", ",", "'avg_pool'", ":", "1", "*", "1", "}", "\n", "if", "opt", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "channel_dict", "=", "{", "'layer1'", ":", "256", ",", "'layer2'", ":", "512", ",", "'layer3'", ":", "1024", ",", "'layer4'", ":", "2", "*", "opt", ".", "input_size", ",", "'avg_pool'", ":", "2048", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "channel_dict", "=", "{", "'layer1'", ":", "256", ",", "'layer2'", ":", "512", ",", "'layer3'", ":", "1024", ",", "'layer4'", ":", "opt", ".", "input_size_audio", "+", "opt", ".", "input_size_video", ",", "\n", "'avg_pool'", ":", "2048", "}", "\n", "", "self", ".", "kernel_size", "=", "{", "'layer1'", ":", "56", ",", "'layer2'", ":", "28", ",", "'layer3'", ":", "14", ",", "'layer4'", ":", "1", "*", "1", ",", "'avg_pool'", ":", "1", "}", "\n", "self", ".", "extract", "=", "[", "'layer4'", "]", "\n", "self", ".", "epsilon", "=", "1e-4", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "softmax2d", "=", "nn", ".", "Softmax2d", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "self", ".", "prototype_vectors", "=", "dict", "(", ")", "\n", "for", "name", "in", "self", ".", "extract", ":", "\n", "            ", "prototype_shape", "=", "[", "300", ",", "self", ".", "channel_dict", "[", "name", "]", ",", "1", ",", "1", "]", "\n", "self", ".", "prototype_vectors", "[", "name", "]", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "prototype_shape", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "prototype_vectors", "=", "nn", ".", "ParameterDict", "(", "self", ".", "prototype_vectors", ")", "\n", "if", "opt", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "ALE_vector", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "[", "300", ",", "2", "*", "opt", ".", "input_size", ",", "1", ",", "1", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ALE_vector", "=", "nn", ".", "Parameter", "(", "2e-4", "*", "torch", ".", "rand", "(", "[", "300", ",", "opt", ".", "input_size_audio", "+", "opt", ".", "input_size_video", ",", "1", ",", "1", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.MLPv2.forward": [[89, 91], ["model.MLPv2.block_forward"], "methods", ["None"], ["        ", "\"\"\"out: predict class, predict attributes, maps, out_feature\"\"\"", "\n", "if", "self", ".", "opt", ".", "norm_inputs", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.VideoBaseNetwork.__init__": [[136, 144], ["torch.nn.Module.__init__", "model.get_video_feature_extractor"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_video_feature_extractor"], ["# x2_patch_sum and intermediate_result are of the same shape", "\n", "distances", "=", "F", ".", "relu", "(", "x2_patch_sum", "+", "intermediate_result", ")", "# [64, 312,  W, H]", "\n", "return", "distances", "\n", "\n", "\n", "", "", "class", "DeviseModel", "(", "nn", ".", "Module", ")", ":", "\n", "  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.VideoBaseNetwork.forward": [[145, 150], ["model.VideoBaseNetwork.base().squeeze", "torch.normalize", "torch.normalize", "model.VideoBaseNetwork.base"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "        ", "self", ".", "bilinear", "=", "nn", ".", "Linear", "(", "self", ".", "args", ".", "input_size", "*", "2", ",", "300", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "bilinear", "=", "nn", ".", "Linear", "(", "self", ".", "args", ".", "input_size_audio", "+", "self", ".", "args", ".", "input_size_video", ",", "300", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "args", ".", "dropout_baselines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.AudioBaseNetwork.__init__": [[153, 161], ["torch.nn.Module.__init__", "model.get_audio_feature_extractor"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_audio_feature_extractor"], ["        ", "vis_fts", "=", "F", ".", "normalize", "(", "vis_fts", ")", "\n", "", "vis_fts", "=", "self", ".", "dropout", "(", "vis_fts", ")", "\n", "txt_fts", "=", "self", ".", "dropout", "(", "txt_fts", ")", "\n", "projected_text_features", "=", "self", ".", "bilinear", "(", "vis_fts", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "self", ".", "bilinear", "(", "vis_fts", ")", ",", "txt_fts", ".", "t", "(", ")", ")", "\n", "return", "logits", ",", "projected_text_features", ",", "txt_fts", "\n", "\n", "\n", "", "", "class", "CJME", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.AudioBaseNetwork.forward": [[162, 167], ["model.AudioBaseNetwork.base().squeeze", "torch.normalize", "torch.normalize", "model.AudioBaseNetwork.base"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["\n", "    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "CJME", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout_baselines", "\n", "self", ".", "triplet_net", "=", "self", ".", "_triplet_net", "(", "args", ")", "\n", "self", ".", "attention_model", "=", "nn", ".", "Sequential", "(", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.AVModel.__init__": [[170, 220], ["torch.nn.Module.__init__", "model.VideoBaseNetwork", "model.AudioBaseNetwork", "print", "model.MLPv2", "model.MLPv2", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "enumerate", "enumerate", "range", "setattr", "setattr", "range", "setattr", "setattr", "model.MLPv2", "model.MLPv2", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["nn", ".", "Sigmoid", "(", ")", "\n", "\n", ")", "\n", "", "def", "forward", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", "=", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "input_attention", "=", "torch", ".", "cat", "(", "(", "x_a_p", ",", "x_v_p", ")", ",", "axis", "=", "1", ")", "\n", "attention_weights", "=", "self", ".", "attention_model", "(", "input_attention", ")", "\n", "\n", "index_video", "=", "attention_weights", ">=", "0.5", "\n", "index_audio", "=", "attention_weights", "<", "0.5", "\n", "threshold_attention", "=", "torch", ".", "clone", "(", "attention_weights", ")", "\n", "threshold_attention", "[", "index_video", "]", "=", "1", "\n", "threshold_attention", "[", "index_audio", "]", "=", "0", "\n", "\n", "return", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "attention_weights", ",", "threshold_attention", "\n", "\n", "", "def", "_triplet_net", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "args", ".", "input_size", "is", "not", "None", ":", "\n", "            ", "f_a", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "", "else", ":", "\n", "            ", "f_a", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size_audio", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "f_v", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "args", ".", "input_size_video", ",", "\n", "hidden_size", "=", "args", ".", "embeddings_hidden_size", ",", "\n", "output_size", "=", "64", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "\n", "", "f_t", "=", "EmbeddingNetCJME", "(", "\n", "input_size", "=", "300", ",", "\n", "hidden_size", "=", "300", ",", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.AVModel.forward": [[222, 253], ["model.AVModel.video_network().squeeze", "model.AVModel.audio_network().squeeze", "len", "aud_features.unsqueeze.unsqueeze.unsqueeze", "len", "img_features.unsqueeze.unsqueeze.unsqueeze", "model.AVModel.mlp_v", "model.AVModel.mlp_a", "model.AVModel.video_network", "model.AVModel.audio_network", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "range", "outs1.append", "outs2.append", "getattr", "getattr", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["dropout", "=", "self", ".", "dropout", ",", "\n", "use_bn", "=", "args", ".", "embedding_use_bn", "\n", ")", "\n", "return", "TripletNet", "(", "f_a", ",", "f_v", ",", "f_t", ")", "\n", "\n", "", "def", "get_embedding", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "\n", "", "def", "get_classes_embedding", "(", "self", ",", "x_t_p", ")", ":", "\n", "        ", "return", "self", ".", "triplet_net", ".", "get_classes_embedding", "(", "x_t_p", ")", "\n", "\n", "", "", "class", "EmbeddingNetCJME", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", ",", "use_bn", ",", "hidden_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "EmbeddingNetCJME", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "if", "hidden_size", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "hidden_size", ")", ")", "\n", "if", "use_bn", ":", "\n", "                ", "modules", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "hidden_size", ")", ")", "\n", "", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "hidden_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "output_size", ")", ")", "\n", "", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "output", "\n", "\n", "", "def", "get_embedding", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.random_weight_init": [[51, 60], ["model.modules", "isinstance", "torch.nn.init.kaiming_normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "function", ["None"], ["x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "middle", "=", "self", ".", "fc", "(", "x", ")", "\n", "output", "=", "self", ".", "softmax", "(", "middle", ".", "mm", "(", "attribute", ")", ")", "\n", "return", "output", "\n", "\n", "\n", "", "", "class", "APN", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "APN", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_video_feature_extractor": [[93, 101], ["model.Identity", "print", "model.random_weight_init"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.random_weight_init"], ["x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "2", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "3", ")", "\n", "attention", "=", "dict", "(", ")", "\n", "pre_attri", "=", "dict", "(", ")", "\n", "pre_class", "=", "dict", "(", ")", "\n", "\n", "pre_attri", "[", "'final'", "]", "=", "F", ".", "max_pool2d", "(", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "ALE_vector", ")", ",", "kernel_size", "=", "1", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "output_final", "=", "self", ".", "softmax", "(", "pre_attri", "[", "'final'", "]", ".", "mm", "(", "attribute", ".", "t", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_audio_feature_extractor": [[103, 122], ["torch.nn.Conv2d", "torch.nn.Conv2d", "model.Identity", "print", "torchvision.models.resnet._resnet", "torch.nn.Conv2d", "torch.nn.Conv2d", "model.Identity"], "function", ["None"], ["            ", "attention", "[", "name", "]", "=", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "prototype_vectors", "[", "name", "]", ")", "\n", "pre_attri", "[", "name", "]", "=", "F", ".", "max_pool2d", "(", "attention", "[", "name", "]", ",", "kernel_size", "=", "self", ".", "kernel_size", "[", "name", "]", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "pre_class", "[", "name", "]", "=", "self", ".", "softmax", "(", "pre_attri", "[", "name", "]", ".", "mm", "(", "attribute", ".", "t", "(", ")", ")", ")", "\n", "", "return", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attribute", "\n", "\n", "", "def", "fine_tune", "(", "self", ",", "fine_tune", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n\n        :param fine_tune: Allow?\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "resnet", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "# If fine-tuning, only fine-tune convolutional blocks 2 through 4", "\n", "", "for", "c", "in", "list", "(", "self", ".", "resnet", ".", "children", "(", ")", ")", "[", "5", ":", "]", ":", "\n", "            ", "for", "p", "in", "c", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "fine_tune", "\n", "\n", "", "", "", "def", "_l2_convolution", "(", "self", ",", "x", ",", "prototype_vector", ",", "one", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_video_dim": [[124, 133], ["None"], "function", ["None"], ["\n", "x2", "=", "x", "**", "2", "# [64, C, W, H]", "\n", "x2_patch_sum", "=", "F", ".", "conv2d", "(", "input", "=", "x2", ",", "weight", "=", "one", ")", "\n", "\n", "p2", "=", "prototype_vector", "**", "2", "\n", "p2", "=", "torch", ".", "sum", "(", "p2", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "# p2 is a vector of shape (num_prototypes,)", "\n", "# then we reshape it to (num_prototypes, 1, 1)", "\n", "p2_reshape", "=", "p2", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.load_model": [[255, 276], ["model.AVModel"], "function", ["None"], ["\n", "\n", "\n", "\n", "", "", "class", "AVGZSLNet", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Network class for the whole model. This combines the embedding layers .. math:: F_A, F_V, F_T.\n    As well as the cross modal decoder network .. math:: F_{DEC}.\n    This calculates two triplets for the positive class p and q, respectively which get fed forward into\n    the cross-modal decoder. The relevant data which is needed for the TotalLoss is returned.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "AVGZSLNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "triplet_net", "=", "self", ".", "_triplet_net", "(", "args", ")", "\n", "self", ".", "decoder_net", "=", "self", ".", "_decoder_net", "(", "args", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", "=", "self", ".", "triplet_net", "(", "x_a_p", ",", "x_v_p", ",", "x_t_p", ",", "x_a_q", ",", "x_v_q", ",", "x_t_q", ")", "\n", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "=", "self", ".", "decoder_net", "(", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ")", "\n", "return", "x_t_p", ",", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.Finetune_Model.__init__": [[45, 75], ["super().__init__", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "finetune_video.Finetune_Model._initialize_weights", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "finetune_video.Finetune_Model.final_bn.weight.data.fill_", "finetune_video.Finetune_Model.final_bn.bias.data.zero_", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.Finetune_Model._initialize_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "base_arch", ",", "\n", "num_ftrs", "=", "512", ",", "\n", "num_classes", "=", "101", ",", "\n", "use_dropout", "=", "False", ",", "\n", "use_bn", "=", "False", ",", "\n", "use_l2_norm", "=", "False", ",", "\n", "dropout", "=", "0.9", "\n", ")", ":", "\n", "        ", "super", "(", "Finetune_Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base", "=", "base_arch", "\n", "self", ".", "use_bn", "=", "use_bn", "\n", "self", ".", "use_dropout", "=", "use_dropout", "\n", "self", ".", "use_l2_norm", "=", "use_l2_norm", "\n", "\n", "message", "=", "'Classifier to %d classes;'", "%", "(", "num_classes", ")", "\n", "if", "use_dropout", ":", "message", "+=", "' + dropout %f'", "%", "dropout", "\n", "if", "use_l2_norm", ":", "message", "+=", "' + L2Norm'", "\n", "if", "use_bn", ":", "message", "+=", "' + final BN'", "\n", "print", "(", "message", ")", "\n", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "self", ".", "final_bn", "=", "nn", ".", "BatchNorm1d", "(", "num_ftrs", ")", "\n", "self", ".", "final_bn", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "final_bn", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "if", "self", ".", "use_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "num_ftrs", ",", "num_classes", ")", "\n", "self", ".", "_initialize_weights", "(", "self", ".", "classifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.Finetune_Model._initialize_weights": [[76, 82], ["module.named_parameters", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'bias'", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "param", ",", "0.0", ")", "\n", "", "elif", "'weight'", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "param", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.Finetune_Model.forward": [[83, 93], ["finetune_video.Finetune_Model.base().squeeze", "finetune_video.Finetune_Model.classifier", "torch.normalize", "torch.normalize", "torch.normalize", "finetune_video.Finetune_Model.final_bn", "finetune_video.Finetune_Model.dropout", "finetune_video.Finetune_Model.base"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "base", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "if", "self", ".", "use_l2_norm", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "", "if", "self", ".", "use_bn", ":", "\n", "            ", "x", "=", "self", ".", "final_bn", "(", "x", ")", "\n", "", "if", "self", ".", "use_dropout", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.main": [[95, 331], ["utils.initialize_exp", "logger.info", "model.load_model", "type", "logger.info", "finetune_video.Finetune_Model", "torch.nn.DataParallel.cuda", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "logger.info", "datasets.AVideoDataset.AVideoDataset", "datasets.AVideoDataset.AVideoDataset", "logger.info", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "time.time", "range", "str", "logger.info", "logger.info", "os.path.exists", "model.get_video_dim", "model_without_ddp.classifier.named_parameters", "model_without_ddp.classifier.named_parameters", "model_without_ddp.base.named_parameters", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "args.lr_milestones.split", "os.path.join", "torch.load", "torch.load", "torch.load", "model_without_ddp.load_state_dict", "torch.optim.Adam.load_state_dict", "logger.info", "finetune_video.evaluate", "logger.info", "finetune_video.train", "logger.info", "torch.optim.lr_scheduler.MultiStepLR.step", "finetune_video.evaluate", "training_stats.update", "time.time", "datetime.timedelta", "torch.load", "torch.load", "torch.load", "logger.info", "utils.load_model_parameters", "logger.info", "params.append", "logger.info", "params.append", "logger.info", "params.append", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "src.warmup_scheduler.GradualWarmupScheduler", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR.load_state_dict", "logger.info", "utils.save_checkpoint", "int", "int"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.initialize_exp", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.load_model", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.model.get_video_dim", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.evaluate", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.evaluate", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.load_model_parameters", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.save_checkpoint"], ["", "", "def", "main", "(", "args", ",", "writer", ")", ":", "\n", "\n", "# Create Logger", "\n", "    ", "logger", ",", "training_stats", "=", "initialize_exp", "(", "\n", "args", ",", "\"epoch\"", ",", "\"loss\"", ",", "\"prec1\"", ",", "\"prec5\"", ",", "\n", "\"loss_val\"", ",", "\"prec1_val\"", ",", "\"prec5_val\"", "\n", ")", "\n", "\n", "# Set CudNN benchmark", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Load model", "\n", "logger", ".", "info", "(", "\"Loading model\"", ")", "\n", "model", "=", "load_model", "(", "\n", "vid_base_arch", "=", "args", ".", "vid_base_arch", ",", "\n", "aud_base_arch", "=", "args", ".", "aud_base_arch", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "\n", "num_classes", "=", "args", ".", "num_clusters", ",", "\n", "norm_feat", "=", "False", ",", "\n", "use_mlp", "=", "args", ".", "use_mlp", ",", "\n", "headcount", "=", "args", ".", "headcount", ",", "\n", ")", "\n", "\n", "# Load model weights", "\n", "weight_path_type", "=", "type", "(", "args", ".", "weights_path", ")", "\n", "if", "weight_path_type", "==", "str", ":", "\n", "        ", "weight_path_not_none", "=", "args", ".", "weights_path", "!=", "'None'", "\n", "", "else", ":", "\n", "        ", "weight_path_not_none", "=", "args", ".", "weights_path", "is", "not", "None", "\n", "", "if", "not", "args", ".", "pretrained", "and", "weight_path_not_none", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading model weights\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "weights_path", ")", ":", "\n", "            ", "ckpt_dict", "=", "torch", ".", "load", "(", "args", ".", "weights_path", ")", "\n", "model_weights", "=", "ckpt_dict", "[", "\"model\"", "]", "\n", "logger", ".", "info", "(", "f\"Epoch checkpoint: {args.ckpt_epoch}\"", ")", "\n", "load_model_parameters", "(", "model", ",", "model_weights", ")", "\n", "", "", "logger", ".", "info", "(", "f\"Loading model done\"", ")", "\n", "\n", "# Add FC layer to model for fine-tuning or feature extracting", "\n", "model", "=", "Finetune_Model", "(", "\n", "model", ".", "video_network", ".", "base", ",", "\n", "get_video_dim", "(", "vid_base_arch", "=", "args", ".", "vid_base_arch", ")", ",", "\n", "NUM_CLASSES", "[", "args", ".", "dataset", "]", ",", "\n", "use_dropout", "=", "args", ".", "use_dropout", ",", "\n", "use_bn", "=", "args", ".", "use_bn", ",", "\n", "use_l2_norm", "=", "args", ".", "use_l2_norm", ",", "\n", "dropout", "=", "0.7", "\n", ")", "\n", "\n", "# Create DataParallel model", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model_without_ddp", "=", "model", ".", "module", "\n", "\n", "# Get params for optimization", "\n", "params", "=", "[", "]", "\n", "if", "args", ".", "feature_extract", ":", "# feature_extract only classifer", "\n", "        ", "for", "name", ",", "param", "in", "model_without_ddp", ".", "classifier", ".", "named_parameters", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "(", "name", ",", "param", ".", "shape", ")", ")", "\n", "params", ".", "append", "(", "\n", "{", "'params'", ":", "param", ",", "\n", "'lr'", ":", "args", ".", "head_lr", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "\n", "}", ")", "\n", "", "", "else", ":", "# finetune", "\n", "        ", "for", "name", ",", "param", "in", "model_without_ddp", ".", "classifier", ".", "named_parameters", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "(", "name", ",", "param", ".", "shape", ")", ")", "\n", "params", ".", "append", "(", "\n", "{", "'params'", ":", "param", ",", "\n", "'lr'", ":", "args", ".", "head_lr", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "\n", "}", ")", "\n", "", "for", "name", ",", "param", "in", "model_without_ddp", ".", "base", ".", "named_parameters", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "(", "name", ",", "param", ".", "shape", ")", ")", "\n", "params", ".", "append", "(", "\n", "{", "'params'", ":", "param", ",", "\n", "'lr'", ":", "args", ".", "base_lr", ",", "\n", "'weight_decay'", ":", "args", ".", "wd_base", "\n", "}", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Creating AV Datasets\"", ")", "\n", "dataset", "=", "AVideoDataset", "(", "\n", "ds_name", "=", "args", ".", "dataset", ",", "\n", "root_dir", "=", "args", ".", "root_dir", ",", "\n", "mode", "=", "'train'", ",", "\n", "num_frames", "=", "args", ".", "clip_len", ",", "\n", "sample_rate", "=", "args", ".", "steps_bet_clips", ",", "\n", "num_train_clips", "=", "args", ".", "train_clips_per_video", ",", "\n", "train_crop_size", "=", "128", "if", "args", ".", "augtype", "==", "1", "else", "224", ",", "\n", "seed", "=", "None", ",", "\n", "fold", "=", "args", ".", "fold", ",", "\n", "colorjitter", "=", "args", ".", "colorjitter", ",", "\n", "temp_jitter", "=", "True", ",", "\n", "center_crop", "=", "False", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "False", ",", "\n", ")", "\n", "dataset_test", "=", "AVideoDataset", "(", "\n", "ds_name", "=", "args", ".", "dataset", ",", "\n", "root_dir", "=", "args", ".", "root_dir", ",", "\n", "mode", "=", "'test'", ",", "\n", "num_frames", "=", "args", ".", "clip_len", ",", "\n", "sample_rate", "=", "args", ".", "steps_bet_clips", ",", "\n", "test_crop_size", "=", "128", "if", "args", ".", "augtype", "==", "1", "else", "224", ",", "\n", "num_spatial_crops", "=", "args", ".", "num_spatial_crops", ",", "\n", "num_ensemble_views", "=", "args", ".", "val_clips_per_video", ",", "\n", "seed", "=", "None", ",", "\n", "fold", "=", "args", ".", "fold", ",", "\n", "colorjitter", "=", "args", ".", "test_time_cj", ",", "\n", "temp_jitter", "=", "True", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "False", ",", "\n", ")", "\n", "\n", "# Creating dataloaders", "\n", "logger", ".", "info", "(", "\"Creating data loaders\"", ")", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "sampler", "=", "None", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "data_loader_test", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_test", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "sampler", "=", "None", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "False", "\n", ")", "\n", "\n", "# linearly scale LR and set up optimizer", "\n", "if", "args", ".", "optim_name", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "params", ",", "\n", "lr", "=", "args", ".", "head_lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", "\n", ")", "\n", "", "elif", "args", ".", "optim_name", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "params", ",", "\n", "lr", "=", "args", ".", "head_lr", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", "\n", ")", "\n", "\n", "# Multi-step LR scheduler", "\n", "", "if", "args", ".", "use_scheduler", ":", "\n", "        ", "lr_milestones", "=", "args", ".", "lr_milestones", ".", "split", "(", "','", ")", "\n", "milestones", "=", "[", "int", "(", "lr", ")", "-", "args", ".", "lr_warmup_epochs", "for", "lr", "in", "lr_milestones", "]", "\n", "if", "args", ".", "lr_warmup_epochs", ">", "0", ":", "\n", "            ", "scheduler_step", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "\n", "optimizer", ",", "\n", "milestones", "=", "milestones", ",", "\n", "gamma", "=", "args", ".", "lr_gamma", "\n", ")", "\n", "multiplier", "=", "8", "\n", "lr_scheduler", "=", "GradualWarmupScheduler", "(", "\n", "optimizer", ",", "\n", "multiplier", "=", "multiplier", ",", "\n", "total_epoch", "=", "args", ".", "lr_warmup_epochs", ",", "\n", "after_scheduler", "=", "scheduler_step", "\n", ")", "\n", "", "else", ":", "# no warmp, just multi-step", "\n", "            ", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "\n", "optimizer", ",", "\n", "milestones", "=", "milestones", ",", "\n", "gamma", "=", "args", ".", "lr_gamma", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "lr_scheduler", "=", "None", "\n", "\n", "# Checkpointing", "\n", "", "if", "args", ".", "resume", ":", "\n", "        ", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'checkpoints'", ",", "'checkpoint.pth'", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "'cpu'", ")", "\n", "model_without_ddp", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "lr_scheduler", ".", "load_state_dict", "(", "checkpoint", "[", "'lr_scheduler'", "]", ")", "\n", "", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "logger", ".", "info", "(", "f\"Resuming from epoch: {args.start_epoch}\"", ")", "\n", "\n", "# Only perform evalaution", "\n", "", "if", "args", ".", "test_only", ":", "\n", "        ", "scores_val", "=", "evaluate", "(", "\n", "model", ",", "\n", "data_loader_test", ",", "\n", "epoch", "=", "args", ".", "start_epoch", ",", "\n", "writer", "=", "writer", ",", "\n", "ds", "=", "args", ".", "dataset", ",", "\n", ")", "\n", "_", ",", "vid_acc1", ",", "vid_acc5", "=", "scores_val", "\n", "return", "vid_acc1", ",", "vid_acc5", ",", "args", ".", "start_epoch", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "best_vid_acc_1", "=", "-", "1", "\n", "best_vid_acc_5", "=", "-", "1", "\n", "best_epoch", "=", "0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f'Start training epoch: {epoch}'", ")", "\n", "scores", "=", "train", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "data_loader", ",", "\n", "epoch", ",", "\n", "writer", "=", "writer", ",", "\n", "ds", "=", "args", ".", "dataset", ",", "\n", ")", "\n", "logger", ".", "info", "(", "f'Start evaluating epoch: {epoch}'", ")", "\n", "lr_scheduler", ".", "step", "(", ")", "\n", "scores_val", "=", "evaluate", "(", "\n", "model", ",", "\n", "data_loader_test", ",", "\n", "epoch", "=", "epoch", ",", "\n", "writer", "=", "writer", ",", "\n", "ds", "=", "args", ".", "dataset", ",", "\n", ")", "\n", "_", ",", "vid_acc1", ",", "vid_acc5", "=", "scores_val", "\n", "training_stats", ".", "update", "(", "scores", "+", "scores_val", ")", "\n", "if", "vid_acc1", ">", "best_vid_acc_1", ":", "\n", "            ", "best_vid_acc_1", "=", "vid_acc1", "\n", "best_vid_acc_5", "=", "vid_acc5", "\n", "best_epoch", "=", "epoch", "\n", "", "if", "args", ".", "output_dir", ":", "\n", "            ", "logger", ".", "info", "(", "f'Saving checkpoint to: {args.output_dir}'", ")", "\n", "save_checkpoint", "(", "args", ",", "epoch", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "\n", "ckpt_freq", "=", "1", ")", "\n", "", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "f'Training time {total_time_str}'", ")", "\n", "return", "best_vid_acc_1", ",", "best_vid_acc_5", ",", "best_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train": [[333, 419], ["model.train", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "time.perf_counter", "torch.CrossEntropyLoss().cuda", "enumerate", "utils.AverageMeter.update", "model", "nn.CrossEntropyLoss().cuda.", "utils.accuracy", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "time.perf_counter", "utils.AverageMeter.avg.item", "utils.AverageMeter.avg.item", "torch.CrossEntropyLoss", "video.cuda", "target.cuda", "criterion.item", "video.size", "video.size", "video.size", "logger.info", "writer.add_scalar", "writer.add_scalar", "time.time", "len", "time.perf_counter", "len"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.accuracy", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.model_improvements.AVCA.backward", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.warmup_scheduler.GradualWarmupScheduler.step", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.accuracy", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update"], ["", "def", "train", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loader", ",", "\n", "epoch", ",", "\n", "writer", "=", "None", ",", "\n", "ds", "=", "'hmdb51'", ",", "\n", ")", ":", "\n", "# Put model in train mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "# running statistics", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "\n", "# training statistics", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "it", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "#\u00a0update iteration", "\n", "iteration", "=", "epoch", "*", "len", "(", "loader", ")", "+", "it", "\n", "\n", "# forward", "\n", "video", ",", "target", ",", "_", ",", "_", "=", "batch", "\n", "video", ",", "target", "=", "video", ".", "cuda", "(", ")", ",", "target", ".", "cuda", "(", ")", "\n", "output", "=", "model", "(", "video", ")", "\n", "\n", "# compute cross entropy loss", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "# compute the gradients", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# step", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# update stats", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "\n", "batch_time", ".", "update", "(", "time", ".", "perf_counter", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "# verbose", "\n", "if", "args", ".", "rank", "==", "0", "and", "it", "%", "50", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Epoch[{0}] - Iter: [{1}/{2}]\\t\"", "\n", "\"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"", "\n", "\"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"", "\n", "\"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"", "\n", "\"Prec {top1.val:.3f} ({top1.avg:.3f})\\t\"", "\n", "\"LR {lr}\"", ".", "format", "(", "\n", "epoch", ",", "\n", "it", ",", "\n", "len", "(", "loader", ")", ",", "\n", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ",", "\n", "loss", "=", "losses", ",", "\n", "top1", "=", "top1", ",", "\n", "lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "\n", ")", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\n", "f'{ds}/train/loss/iter'", ",", "\n", "losses", ".", "val", ",", "\n", "iteration", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f'{ds}/train/clip_acc1/iter'", ",", "\n", "top1", ".", "val", ",", "\n", "iteration", "\n", ")", "\n", "", "", "return", "epoch", ",", "losses", ".", "avg", ",", "top1", ".", "avg", ".", "item", "(", ")", ",", "top5", ".", "avg", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.evaluate": [[421, 501], ["utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "model.eval", "torch.CrossEntropyLoss().cuda", "utils.aggregrate_video_accuracy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.perf_counter", "enumerate", "logger.info", "writer.add_scalar", "writer.add_scalar", "video_acc1.item", "video_acc5.item", "torch.CrossEntropyLoss", "video.cuda.cuda", "target.cuda.cuda", "model", "nn.CrossEntropyLoss().cuda.", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "time.perf_counter", "range", "video_acc1.item", "video_acc5.item", "model.view", "criterion.item", "video.cuda.size", "video.cuda.size", "video.cuda.size", "len", "video_idx[].item", "softmaxes.setdefault().append", "video.cuda.size", "time.perf_counter", "video_acc1.item", "softmaxes.setdefault"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.aggregrate_video_accuracy", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.accuracy", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update"], ["", "def", "evaluate", "(", "model", ",", "val_loader", ",", "epoch", "=", "0", ",", "writer", "=", "None", ",", "ds", "=", "'hmdb51'", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# dicts to store labels and softmaxes", "\n", "softmaxes", "=", "{", "}", "\n", "labels", "=", "{", "}", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "\n", "            ", "(", "video", ",", "target", ",", "_", ",", "video_idx", ")", "=", "batch", "\n", "\n", "# move to gpu", "\n", "video", "=", "video", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "target", "=", "target", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output and loss", "\n", "output", "=", "model", "(", "video", ")", "\n", "loss", "=", "criterion", "(", "output", ".", "view", "(", "video", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "target", ")", "\n", "\n", "# Clip level accuracy", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "video", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "perf_counter", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "# Video Level accuracy", "\n", "for", "j", "in", "range", "(", "len", "(", "video_idx", ")", ")", ":", "\n", "                ", "video_id", "=", "video_idx", "[", "j", "]", ".", "item", "(", ")", "\n", "sm", "=", "output", "[", "j", "]", "\n", "label", "=", "target", "[", "j", "]", "\n", "\n", "# append it to video dict", "\n", "softmaxes", ".", "setdefault", "(", "video_id", ",", "[", "]", ")", ".", "append", "(", "sm", ")", "\n", "labels", "[", "video_id", "]", "=", "label", "\n", "\n", "# Get video acc@1 and acc@5 and output to tb writer", "\n", "", "", "", "video_acc1", ",", "video_acc5", "=", "aggregrate_video_accuracy", "(", "\n", "softmaxes", ",", "labels", ",", "topk", "=", "(", "1", ",", "5", ")", "\n", ")", "\n", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Test:\\t\"", "\n", "\"Time {batch_time.avg:.3f}\\t\"", "\n", "\"Loss {loss.avg:.4f}\\t\"", "\n", "\"ClipAcc@1 {top1.avg:.3f}\\t\"", "\n", "\"VidAcc@1 {video_acc1:.3f}\"", ".", "format", "(", "\n", "batch_time", "=", "batch_time", ",", "\n", "loss", "=", "losses", ",", "\n", "top1", "=", "top1", ",", "\n", "video_acc1", "=", "video_acc1", ".", "item", "(", ")", ")", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\n", "f'{ds}/val/vid_acc1/epoch'", ",", "\n", "video_acc1", ".", "item", "(", ")", ",", "\n", "epoch", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f'{ds}/val/vid_acc5/epoch'", ",", "\n", "video_acc5", ".", "item", "(", ")", ",", "\n", "epoch", "\n", ")", "\n", "\n", "# Log final results to terminal", "\n", "", "return", "losses", ".", "avg", ",", "video_acc1", ".", "item", "(", ")", ",", "video_acc5", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args": [[503, 614], ["argparse.ArgumentParser", "argparse.ArgumentParser.register", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "v.lower.lower", "ValueError"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "def", "str2bool", "(", "v", ")", ":", "\n", "        ", "v", "=", "v", ".", "lower", "(", ")", "\n", "if", "v", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'1'", ")", ":", "\n", "            ", "return", "True", "\n", "", "elif", "v", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'0'", ")", ":", "\n", "            ", "return", "False", "\n", "", "raise", "ValueError", "(", "'Boolean argument needs to be true or false. '", "\n", "'Instead, it is %s.'", "%", "v", ")", "\n", "\n", "", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Finetuning'", ")", "\n", "parser", ".", "register", "(", "'type'", ",", "'bool'", ",", "str2bool", ")", "\n", "\n", "### DATA", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'ucf101'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'kinetics'", ",", "'vggsound'", ",", "'kinetics_sound'", ",", "'ave'", ",", "'ucf101'", ",", "'hmdb51'", "]", ",", "\n", "help", "=", "'name of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\"--root_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/path/to/dataset\"", ",", "\n", "help", "=", "\"root dir of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "default", "=", "'1,2,3'", ",", "type", "=", "str", ",", "\n", "help", "=", "'fold number'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_len'", ",", "default", "=", "32", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of frames per clip'", ")", "\n", "parser", ".", "add_argument", "(", "'--augtype'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'augmentation type (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--colorjitter'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'color jittering as augmentations'", ")", "\n", "parser", ".", "add_argument", "(", "'--steps_bet_clips'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of steps between clips in video'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_data_samples'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of samples in dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_clips_per_video'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of clips per video for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_clips_per_video'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of clips per video for testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_spatial_crops'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of spatial clips for testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_time_cj'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'test time CJ augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of data loading workers (default: 16)'", ")", "\n", "\n", "### MODEL", "\n", "parser", ".", "add_argument", "(", "'--weights_path'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to weights file'", ",", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_epoch'", ",", "default", "=", "'0'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Epoch of model checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--vid_base_arch'", ",", "default", "=", "'r2plus1d_18'", ",", "\n", "help", "=", "'Video Base Arch for A-V model'", ")", "\n", "parser", ".", "add_argument", "(", "'--aud_base_arch'", ",", "default", "=", "'resnet9'", ",", "\n", "help", "=", "'Audio Base Arch for A-V model'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use pre-trained models from the modelzoo'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mlp'", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use MLP projection head'", ")", "\n", "parser", ".", "add_argument", "(", "'--mlptype'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'MLP type (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--headcount'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'how many heads each modality has'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_clusters'", ",", "default", "=", "309", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of clusters in last dimension'", ")", "\n", "\n", "### FINETUNE", "\n", "parser", ".", "add_argument", "(", "'--feature_extract'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "\"Use model as feature extractor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_dropout\"", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use dropout in classifier'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_bn'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use BN in classifier'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_l2_norm'", ",", "default", "=", "'False'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use L2-Norm in classifier'", ")", "\n", "\n", "### TRAINING", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "12", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_name'", ",", "default", "=", "'sgd'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Name of optimizer'", ",", "choices", "=", "[", "'sgd'", ",", "'adam'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--head_lr'", ",", "default", "=", "0.0025", ",", "type", "=", "float", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--base_lr'", ",", "default", "=", "0.00025", ",", "type", "=", "float", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "\n", "help", "=", "'momentum'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "default", "=", "0.005", ",", "type", "=", "float", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--wd_base'", ",", "default", "=", "5e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_scheduler\"", ",", "default", "=", "'True'", ",", "type", "=", "'bool'", ",", "\n", "help", "=", "'Use LR scheduler'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_warmup_epochs'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of warmup epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_milestones'", ",", "default", "=", "'6,10'", ",", "type", "=", "str", ",", "\n", "help", "=", "'decrease lr on milestones (epochs)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_gamma'", ",", "default", "=", "0.05", ",", "type", "=", "float", ",", "\n", "help", "=", "'decrease lr by a factor of lr-gamma'", ")", "\n", "\n", "### LOGGING", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "'.'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path where to save'", ")", "\n", "\n", "### CHECKPOINTING", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'resume from checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'start epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_only'", ",", "type", "=", "'bool'", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'Only test the model'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.plot_distributions.main": [[12, 36], ["torch.load", "range", "numpy.array", "numpy.unique", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.clf", "plot_distributions..cpu().numpy", "sorted", "sorted", "range", "plot_distributions..cpu", "numpy.random.randn"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "N", "=", "170752", "\n", "K", "=", "309", "\n", "gauss_path", "=", "\"path_gauss_ckp-100.pth\"", "\n", "uniform_path", "=", "\"path_uniform_ckp-100.pth\"", "\n", "ckpt_dir_dict", "=", "{", "'uniform'", ":", "uniform_path", ",", "'gaussian'", ":", "gauss_path", "}", "\n", "for", "distribtion", "in", "[", "'uniform'", ",", "'gaussian'", "]", ":", "\n", "        ", "path", "=", "ckpt_dir_dict", "[", "distribtion", "]", "\n", "ckpt", "=", "torch", ".", "load", "(", "path", ")", "\n", "selflabels", "=", "ckpt", "[", "'selflabels'", "]", "\n", "if", "distribtion", "==", "'uniform'", ":", "\n", "            ", "target_counts", "=", "np", ".", "array", "(", "[", "N", "/", "K", "for", "i", "in", "range", "(", "K", ")", "]", ")", "\n", "", "else", ":", "#\u00a0gaussian", "\n", "            ", "gauss_sd", "=", "0.05", "\n", "target_counts", "=", "(", "np", ".", "random", ".", "randn", "(", "K", ",", "1", ")", "*", "gauss_sd", "+", "1", ")", "*", "N", "/", "K", "\n", "", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "u", ",", "counts", "=", "np", ".", "unique", "(", "selflabels", "[", ":", ",", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "return_counts", "=", "True", ")", "\n", "plt", ".", "plot", "(", "sorted", "(", "counts", ")", "[", ":", ":", "-", "1", "]", ",", "label", "=", "\"SK\"", ")", "\n", "plt", ".", "plot", "(", "sorted", "(", "target_counts", ")", "[", ":", ":", "-", "1", "]", ",", "label", "=", "\"Target\"", ")", "\n", "plt", ".", "xlabel", "(", "'cluster-ID'", ")", "\n", "plt", ".", "ylabel", "(", "'#Assigned images'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "f\"cluster_vis/{distribtion}_hist_{i}.png\"", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.normalize": [[19, 23], ["numpy.atleast_1d", "numpy.linalg.norm", "numpy.expand_dims"], "function", ["None"], ["def", "normalize", "(", "a", ",", "axis", "=", "-", "1", ",", "order", "=", "2", ")", ":", "\n", "    ", "l2", "=", "np", ".", "atleast_1d", "(", "np", ".", "linalg", ".", "norm", "(", "a", ",", "order", ",", "axis", ")", ")", "\n", "l2", "[", "l2", "==", "0", "]", "=", "1", "\n", "return", "a", "/", "np", ".", "expand_dims", "(", "l2", ",", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.accuracy": [[26, 39], ["torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._hungarian_match": [[41, 67], ["numpy.zeros", "range", "linear_sum_assignment", "range", "isinstance", "isinstance", "range", "len", "res.append", "int"], "function", ["None"], ["", "", "def", "_hungarian_match", "(", "flat_preds", ",", "flat_targets", ",", "preds_k", ",", "targets_k", ")", ":", "\n", "    ", "from", "scipy", ".", "optimize", "import", "linear_sum_assignment", "\n", "\n", "assert", "(", "isinstance", "(", "flat_preds", ",", "torch", ".", "Tensor", ")", "and", "isinstance", "(", "flat_targets", ",", "torch", ".", "Tensor", ")", ")", "\n", "\n", "num_samples", "=", "flat_targets", ".", "shape", "[", "0", "]", "\n", "assert", "(", "preds_k", "==", "targets_k", ")", "# one to one", "\n", "num_k", "=", "preds_k", "\n", "num_correct", "=", "np", ".", "zeros", "(", "(", "num_k", ",", "num_k", ")", ")", "\n", "\n", "for", "c1", "in", "range", "(", "num_k", ")", ":", "\n", "        ", "for", "c2", "in", "range", "(", "num_k", ")", ":", "\n", "# elementwise, so each sample contributes once", "\n", "            ", "votes", "=", "int", "(", "(", "(", "flat_preds", "==", "c1", ")", "*", "(", "flat_targets", "==", "c2", ")", ")", ".", "sum", "(", ")", ")", "\n", "num_correct", "[", "c1", ",", "c2", "]", "=", "votes", "\n", "\n", "# num_correct is small", "\n", "", "", "match", "=", "linear_sum_assignment", "(", "num_samples", "-", "num_correct", ")", "\n", "\n", "# return as list of tuples, out_c to gt_c", "\n", "res", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "match", "[", "0", "]", ")", ")", ":", "\n", "        ", "out_c", ",", "gt_c", "=", "match", "[", "0", "]", "[", "i", "]", ",", "match", "[", "1", "]", "[", "i", "]", "\n", "res", ".", "append", "(", "(", "out_c", ",", "gt_c", ")", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._acc": [[69, 81], ["isinstance", "isinstance", "print", "int", "float", "preds.max", "targets.max"], "function", ["None"], ["", "def", "_acc", "(", "preds", ",", "targets", ",", "num_k", ",", "verbose", "=", "0", ")", ":", "\n", "    ", "assert", "(", "isinstance", "(", "preds", ",", "torch", ".", "Tensor", ")", "and", "isinstance", "(", "targets", ",", "torch", ".", "Tensor", ")", ")", "\n", "\n", "if", "verbose", ">=", "2", ":", "\n", "        ", "print", "(", "\"calling acc...\"", ")", "\n", "\n", "", "assert", "(", "preds", ".", "shape", "==", "targets", ".", "shape", ")", "\n", "assert", "(", "preds", ".", "max", "(", ")", "<", "num_k", "and", "targets", ".", "max", "(", ")", "<", "num_k", ")", "\n", "\n", "acc", "=", "int", "(", "(", "preds", "==", "targets", ")", ".", "sum", "(", ")", ")", "/", "float", "(", "preds", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.cluster_acc": [[83, 93], ["numpy.zeros", "clustering_metrics_old._acc", "len", "torch.tensor().to", "print", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._acc"], ["", "def", "cluster_acc", "(", "match", ",", "preds", ",", "targets", ",", "num_k", "=", "309", ",", "verbose", "=", "1", ")", ":", "\n", "# reorder predictions to be same cluster assignments as gt_k", "\n", "    ", "reordered_preds", "=", "np", ".", "zeros", "(", "len", "(", "targets", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "pred_i", ",", "target_i", "in", "match", ":", "\n", "      ", "reordered_preds", "[", "preds", "==", "pred_i", "]", "=", "target_i", "\n", "if", "verbose", ">", "1", ":", "\n", "        ", "print", "(", "(", "pred_i", ",", "target_i", ")", ")", "\n", "\n", "", "", "acc", "=", "_acc", "(", "torch", ".", "tensor", "(", "reordered_preds", ")", ".", "to", "(", "torch", ".", "long", ")", ",", "targets", ",", "num_k", ",", "True", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.k_means": [[95, 176], ["pickle.load", "sklearn.metrics.cluster.normalized_mutual_info_score", "sklearn.metrics.cluster.adjusted_mutual_info_score", "sklearn.metrics.cluster.adjusted_rand_score", "print", "print", "print", "numpy.unique", "print", "print", "print", "torch.tensor", "torch.tensor", "clustering_metrics_old._hungarian_match", "clustering_metrics_old.cluster_acc", "print", "open", "PS[].cpu().numpy", "len", "range", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.mul", "torch.mul.argmax().cpu().numpy", "PS[].cpu().numpy", "of_this_cluster.sum", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.mul", "torch.mul.argmax().cpu().numpy", "sklearn.metrics.cluster.normalized_mutual_info_score", "print", "numpy.unique", "purities.append", "entropies.append", "enumerate", "enumerate", "PS[].cpu", "torch.mul.argmax().cpu", "PS[].cpu", "scipy.stats.entropy", "numpy.mean", "numpy.mean", "numpy.unique", "len", "torch.mul.argmax().cpu", "max", "sum", "numpy.unique", "torch.mul.argmax", "sum", "torch.mul.argmax"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old._hungarian_match", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.clustering_metrics_old.cluster_acc"], ["", "def", "k_means", "(", "\n", "path", "=", "\"cluster_fit_PS_matrices_scratch_vgg_sound_train.pkl\"", ",", "\n", "ncentroids", "=", "512", ",", "\n", "use_all_heads", "=", "False", "\n", ")", ":", "\n", "\n", "# Load matrics", "\n", "    ", "PS", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "'rb'", ")", ")", "\n", "\n", "# SELAVI", "\n", "if", "use_all_heads", ":", "\n", "        ", "PS_v_all_heads", "=", "PS", "[", "0", "]", "\n", "PS_a_all_heads", "=", "PS", "[", "2", "]", "\n", "true_labels", "=", "PS", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "num_heads", "=", "len", "(", "PS_v_all_heads", ")", "\n", "best_nmi", "=", "0", "\n", "best_self_labels", "=", "None", "\n", "for", "h", "in", "range", "(", "num_heads", ")", ":", "\n", "            ", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "PS_v_all_heads", "[", "h", "]", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "PS_a_all_heads", "[", "h", "]", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_av", "=", "torch", ".", "mul", "(", "PS_v_sk", ",", "PS_a_sk", ")", "\n", "self_labels_np", "=", "PS_av", ".", "argmax", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "nmi", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "true_labels", ",", "average_method", "=", "'arithmetic'", ")", "\n", "print", "(", "f\"Head {h}: {nmi}\"", ")", "\n", "if", "nmi", ">", "best_nmi", ":", "\n", "                ", "best_nmi", "=", "nmi", "\n", "best_self_labels", "=", "self_labels_np", "\n", "", "", "self_labels_np", "=", "best_self_labels", "\n", "", "else", ":", "\n", "        ", "PS_v", "=", "PS", "[", "0", "]", "\n", "PS_a", "=", "PS", "[", "2", "]", "\n", "PS_v_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "PS_v", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_a_sk", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "PS_a", ",", "dim", "=", "1", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "PS_av", "=", "torch", ".", "mul", "(", "PS_v_sk", ",", "PS_a_sk", ")", "\n", "self_labels_np", "=", "PS_av", ".", "argmax", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "true_labels", "=", "PS", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Get NMI and a-NMI values", "\n", "", "nmi_to_labels_v", "=", "normalized_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "anmi_to_labels_v", "=", "adjusted_mutual_info_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", "average_method", "=", "'arithmetic'", "\n", ")", "\n", "ari_to_labels_v", "=", "adjusted_rand_score", "(", "\n", "self_labels_np", ",", "\n", "true_labels", ",", "\n", ")", "\n", "print", "(", "f\"NMI-tolabels: {nmi_to_labels_v}\"", ")", "\n", "print", "(", "f\"aNMI-tolabels: {anmi_to_labels_v}\"", ")", "\n", "print", "(", "f\"aRI-tolabels: {ari_to_labels_v}\"", ")", "\n", "\n", "# Get entropy and purtiy values", "\n", "purities", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "for", "sk_label", "in", "np", ".", "unique", "(", "self_labels_np", ")", ":", "\n", "        ", "of_this_cluster", "=", "self_labels_np", "==", "sk_label", "\n", "size", "=", "of_this_cluster", ".", "sum", "(", ")", "\n", "if", "size", "!=", "0", ":", "\n", "            ", "uniq", ",", "counts", "=", "np", ".", "unique", "(", "true_labels", "[", "of_this_cluster", "]", ",", "return_counts", "=", "True", ")", "\n", "purities", ".", "append", "(", "max", "(", "counts", ")", "/", "sum", "(", "1.0", "*", "counts", ")", ")", "\n", "entropies", ".", "append", "(", "entropy", "(", "counts", "/", "sum", "(", "1.0", "*", "counts", ")", ")", ")", "\n", "", "", "print", "(", "f'Avg entropy: {np.mean(entropies)}   avg purity: {np.mean(purities)}'", ")", "\n", "\n", "translate_to_low_classes", "=", "{", "n", ":", "a", "for", "a", ",", "n", "in", "enumerate", "(", "np", ".", "unique", "(", "true_labels", ")", ")", "}", "\n", "true_labels", "=", "[", "translate_to_low_classes", "[", "n", "]", "for", "_", ",", "n", "in", "enumerate", "(", "true_labels", ")", "]", "\n", "print", "(", "f\"Number of unique classes: {len(np.unique(true_labels))}\"", ")", "\n", "print", "(", "f\"Number of centroids: {ncentroids}\"", ")", "\n", "\n", "self_labels", "=", "torch", ".", "tensor", "(", "self_labels_np", ")", "\n", "true_labels", "=", "torch", ".", "tensor", "(", "true_labels", ")", "\n", "match", "=", "_hungarian_match", "(", "self_labels", ",", "true_labels", ",", "ncentroids", ",", "ncentroids", ")", "\n", "clust_acc", "=", "cluster_acc", "(", "match", ",", "self_labels", ",", "true_labels", ",", "ncentroids", ")", "\n", "print", "(", "f'Clustering Acc: {clust_acc * 100}%'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.AverageMeter.__init__": [[289, 291], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.reset"], ["unseen_recall_dict", "=", "per_class_recall", "[", "unseen_label_array", "]", "\n", "s", "=", "seen_recall_dict", ".", "mean", "(", ")", "\n", "u", "=", "unseen_recall_dict", ".", "mean", "(", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.AverageMeter.reset": [[292, 297], ["None"], "methods", ["None"], ["\n", "if", "save_performances", ":", "\n", "                ", "seen_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "np", ".", "array", "(", "dataset", ".", "all_class_names", ")", "[", "seen_label_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ",", "seen_recall_dict", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "}", "\n", "unseen_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "np", ".", "array", "(", "dataset", ".", "all_class_names", ")", "[", "unseen_label_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ",", "unseen_recall_dict", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "}", "\n", "save_class_performances", "(", "seen_dict", ",", "unseen_dict", ",", "dataset", ".", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.AverageMeter.update": [[298, 303], ["None"], "methods", ["None"], ["", "hm", "=", "(", "2", "*", "u", "*", "s", ")", "/", "(", "(", "u", "+", "s", ")", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "\n", "neighbor_batch_zsl", "=", "torch", ".", "argmin", "(", "distance_mat_zsl", ",", "dim", "=", "1", ")", "\n", "match_idx", "=", "neighbor_batch_zsl", ".", "eq", "(", "targets", ".", "int", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "match_counts", "=", "torch", ".", "bincount", "(", "neighbor_batch_zsl", "[", "match_idx", "]", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "\n", "seen_unseen_array", "]", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.QueueAverage.__init__": [[306, 309], ["None"], "methods", ["None"], ["per_class_recall", "[", "seen_unseen_array", "]", "=", "match_counts", "/", "target_counts", "\n", "zsl", "=", "per_class_recall", "[", "unseen_label_array", "]", ".", "mean", "(", ")", "\n", "\n", "zsl_scores", ".", "append", "(", "zsl", ".", "item", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.QueueAverage.update": [[310, 321], ["len", "utils.QueueAverage.queue.append", "len", "utils.QueueAverage.queue.append", "len", "utils.QueueAverage.queue.pop", "utils.QueueAverage.queue.append"], "methods", ["None"], ["seen_scores", ".", "append", "(", "s", ".", "item", "(", ")", ")", "\n", "unseen_scores", ".", "append", "(", "u", ".", "item", "(", ")", ")", "\n", "hm_scores", ".", "append", "(", "hm", ".", "item", "(", ")", ")", "\n", "per_class_recalls", ".", "append", "(", "per_class_recall", ".", "tolist", "(", ")", ")", "\n", "", "argmax_hm", "=", "np", ".", "argmax", "(", "hm_scores", ")", "\n", "max_seen", "=", "seen_scores", "[", "argmax_hm", "]", "\n", "max_zsl", "=", "zsl_scores", "[", "argmax_hm", "]", "\n", "max_unseen", "=", "unseen_scores", "[", "argmax_hm", "]", "\n", "max_hm", "=", "hm_scores", "[", "argmax_hm", "]", "\n", "max_recall", "=", "per_class_recalls", "[", "argmax_hm", "]", "\n", "best_beta", "=", "betas", "[", "argmax_hm", "]", ".", "item", "(", ")", "\n", "", "return", "{", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.__init__": [[324, 327], ["utils.MovingAverage.reset"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.reset"], ["\"hm\"", ":", "max_hm", ",", "\n", "\"recall\"", ":", "max_recall", ",", "\n", "\"zsl\"", ":", "max_zsl", ",", "\n", "\"beta\"", ":", "best_beta", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.reset": [[328, 330], ["None"], "methods", ["None"], ["}", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.MovingAverage.update": [[331, 334], ["None"], "methods", ["None"], ["", "def", "evaluate_dataset", "(", "dataset", ",", "model", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "    ", "data", "=", "dataset", ".", "all_data", "\n", "data_a", "=", "data", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "data_v", "=", "data", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.bool_flag": [[28, 38], ["s.lower", "s.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "", "def", "setup_experiment", "(", "args", ",", "*", "stats", ")", ":", "\n", "    ", "if", "args", ".", "exp_name", "==", "\"\"", ":", "\n", "        ", "exp_name", "=", "f\"runs/{datetime.now().strftime('%b%d_%H-%M-%S')}_{socket.gethostname()}\"", "\n", "", "else", ":", "\n", "        ", "exp_name", "=", "\"runs/\"", "+", "str", "(", "args", ".", "exp_name", ")", "\n", "#exp_name = \"/mnt/store_runs/\" + str(args.exp_name)", "\n", "", "log_dir", "=", "(", "args", ".", "dump_path", "/", "exp_name", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.dist_collect": [[40, 52], ["x.contiguous.contiguous", "torch.all_gather", "torch.stack", "torch.stack", "torch.zeros_like", "torch.zeros_like", "range", "torch.get_world_size"], "function", ["None"], ["(", "log_dir", "/", "\"checkpoints\"", ")", ".", "mkdir", "(", ")", "\n", "pickle", ".", "dump", "(", "args", ",", "(", "log_dir", "/", "\"args.pkl\"", ")", ".", "open", "(", "\"wb\"", ")", ")", "\n", "train_stats", "=", "PD_Stats", "(", "log_dir", "/", "\"train_stats.pkl\"", ",", "stats", ")", "\n", "val_stats", "=", "PD_Stats", "(", "log_dir", "/", "\"val_stats.pkl\"", ",", "stats", ")", "\n", "logger", "=", "create_logger", "(", "log_dir", "/", "\"train.log\"", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Start experiment {exp_name}\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"\\n\"", ".", "join", "(", "f\"{k}: {str(v)}\"", "for", "k", ",", "v", "in", "sorted", "(", "dict", "(", "vars", "(", "args", ")", ")", ".", "items", "(", ")", ")", ")", "\n", ")", "\n", "logger", ".", "info", "(", "f\"The experiment will be stored in {log_dir.resolve()}\\n\"", ")", "\n", "logger", ".", "info", "(", "\"\"", ")", "\n", "if", "args", ".", "exp_name", "==", "\"\"", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.dist_collect_other": [[54, 71], ["x.contiguous.contiguous", "torch.all_gather", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "range", "range", "torch.get_world_size", "torch.get_world_size", "torch.get_rank"], "function", ["None"], ["", "else", ":", "\n", "        ", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "exp_name", ")", "\n", "", "return", "logger", ",", "log_dir", ",", "writer", ",", "train_stats", ",", "val_stats", "\n", "\n", "\n", "", "def", "setup_evaluation", "(", "args", ",", "*", "stats", ")", ":", "\n", "    ", "eval_dir", "=", "args", ".", "load_path_stage_B", "\n", "assert", "eval_dir", ".", "exists", "(", ")", "\n", "# pickle.dump(args, (eval_dir / \"args.pkl\").open(\"wb\"))", "\n", "test_stats", "=", "PD_Stats", "(", "eval_dir", "/", "\"test_stats.pkl\"", ",", "list", "(", "sorted", "(", "stats", ")", ")", ")", "\n", "logger", "=", "create_logger", "(", "eval_dir", "/", "\"eval.log\"", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Start evaluation {eval_dir}\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"\\n\"", ".", "join", "(", "f\"{k}: {str(v)}\"", "for", "k", ",", "v", "in", "sorted", "(", "dict", "(", "vars", "(", "args", ")", ")", ".", "items", "(", ")", ")", ")", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Loaded configuration {args.load_path_stage_B / 'args.pkl'}\"", ")", "\n", "logger", ".", "info", "(", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.SIGTERMHandler": [[73, 76], ["print"], "function", ["None"], [")", "\n", "logger", ".", "info", "(", "f\"The evaluation will be stored in {eval_dir.resolve()}\\n\"", ")", "\n", "logger", ".", "info", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.signalHandler": [[78, 82], ["print", "time.time"], "function", ["None"], ["\n", "\n", "", "def", "save_best_model", "(", "epoch", ",", "best_metric", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"\"", ",", "checkpoint", "=", "False", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "f\"Saving model to {log_dir} with {metric} = {best_metric:.4f}\"", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.init_signal_handler": [[84, 94], ["str", "signal.signal", "signal.signal", "print", "os.getpid"], "function", ["None"], ["\"epoch\"", ":", "epoch", "+", "1", ",", "\n", "\"model\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"metric\"", ":", "metric", "\n", "}", "\n", "if", "checkpoint", ":", "\n", "        ", "torch", ".", "save", "(", "\n", "save_dict", ",", "\n", "log_dir", "/", "f\"{model.__class__.__name__}_{metric}_ckpt_{epoch}.pt\"", "\n", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.trigger_job_requeue": [[96, 109], ["exit", "os.path.isfile", "print", "print", "os.system", "print", "int", "str", "RuntimeError", "os.getpid"], "function", ["None"], ["save_dict", ",", "\n", "log_dir", "/", "f\"{model.__class__.__name__}_{metric}.pt\"", "\n", ")", "\n", "\n", "\n", "", "", "def", "check_best_loss", "(", "epoch", ",", "best_loss", ",", "val_loss", ",", "model", ",", "optimizer", ",", "log_dir", ")", ":", "\n", "    ", "if", "not", "best_loss", ":", "\n", "        ", "save_best_model", "(", "epoch", ",", "val_loss", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"loss\"", ")", "\n", "return", "val_loss", "\n", "", "if", "val_loss", "<", "best_loss", ":", "\n", "        ", "best_loss", "=", "val_loss", "\n", "save_best_model", "(", "epoch", ",", "best_loss", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"loss\"", ")", "\n", "", "return", "best_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.init_distributed_mode": [[111, 153], ["int", "int", "int", "torch.init_process_group", "print", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "print", "torch.cuda.set_device", "torch.cuda.set_device", "int", "int", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["None"], ["", "def", "check_best_score", "(", "epoch", ",", "best_score", ",", "hm_score", ",", "model", ",", "optimizer", ",", "log_dir", ")", ":", "\n", "    ", "if", "not", "best_score", ":", "\n", "        ", "save_best_model", "(", "epoch", ",", "hm_score", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"score\"", ")", "\n", "return", "hm_score", "\n", "", "if", "hm_score", ">", "best_score", ":", "\n", "        ", "best_score", "=", "hm_score", "\n", "save_best_model", "(", "epoch", ",", "best_score", ",", "model", ",", "optimizer", ",", "log_dir", ",", "metric", "=", "\"score\"", ")", "\n", "", "return", "best_score", "\n", "\n", "\n", "", "def", "load_model_parameters", "(", "model", ",", "model_weights", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "loaded_state", "=", "model_weights", "\n", "self_state", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "name", ",", "param", "in", "loaded_state", ".", "items", "(", ")", ":", "\n", "        ", "param", "=", "param", "\n", "if", "'module.'", "in", "name", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "'module.'", ",", "''", ")", "\n", "", "if", "name", "in", "self_state", ".", "keys", "(", ")", ":", "\n", "            ", "self_state", "[", "name", "]", ".", "copy_", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"didnt load \"", ",", "name", ")", "\n", "\n", "\n", "", "", "", "def", "load_args", "(", "path", ")", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "(", "path", "/", "\"args.pkl\"", ")", ".", "open", "(", "\"rb\"", ")", ")", "\n", "\n", "\n", "", "def", "cos_dist", "(", "a", ",", "b", ")", ":", "\n", "    ", "a_norm", "=", "a", "/", "a", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "b_norm", "=", "b", "/", "b", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "res", "=", "torch", ".", "mm", "(", "a_norm", ",", "b_norm", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "return", "res", "\n", "\n", "\n", "", "def", "evaluate_dataset_baseline", "(", "dataset", ",", "model", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "\n", "new_model_attention", "=", "False", ",", "model_devise", "=", "False", ",", "apn", "=", "False", ",", "\n", "args", "=", "None", ",", "save_performances", "=", "False", ")", ":", "\n", "    ", "data", "=", "dataset", ".", "all_data", "\n", "data_a", "=", "data", "[", "\"audio\"", "]", ".", "to", "(", "device", ")", "\n", "data_v", "=", "data", "[", "\"video\"", "]", ".", "to", "(", "device", ")", "\n", "data_t", "=", "data", "[", "\"text\"", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.initialize_exp": [[155, 189], ["os.path.join", "src.logger.PD_Stats", "src.logger.create_logger", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "src.logger.create_logger.info", "pickle.dump", "os.mkdir", "os.path.join", "os.path.join", "open", "os.path.isdir", "os.path.join", "str", "sorted", "str", "dict().items", "dict", "vars"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.logger.create_logger"], ["if", "new_model_attention", "==", "True", "or", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_num", ",", "data_t", "\n", ")", "\n", "", "else", ":", "\n", "        ", "all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_t", "\n", ")", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "z_score_inputs", ":", "\n", "            ", "all_data", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "all_data", "]", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Namespace has no fitting attribute. Continuing\"", ")", "\n", "\n", "", "all_targets", "=", "dataset", ".", "targets", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "new_model_attention", "==", "False", "and", "model_devise", "==", "False", "and", "apn", "==", "False", ":", "\n", "        ", "outputs_all", "=", "model", "(", "*", "all_data", ")", "\n", "", "elif", "apn", "==", "True", ":", "\n", "        ", "input_features", "=", "torch", ".", "cat", "(", "(", "all_data", "[", "1", "]", ",", "all_data", "[", "0", "]", ")", ",", "1", ")", "\n", "output_final", ",", "pre_attri", ",", "attention", ",", "pre_class", ",", "attributes", "=", "model", "(", "input_features", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "pre_attri", "[", "\"final\"", "]", ",", "attributes", ")", "\n", "", "elif", "model_devise", "==", "True", ":", "\n", "        ", "input_features", "=", "torch", ".", "cat", "(", "(", "all_data", "[", "1", "]", ",", "all_data", "[", "0", "]", ")", ",", "1", ")", "\n", "outputs_all", ",", "projected_features", ",", "embeddings", "=", "model", "(", "input_features", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "projected_features", ",", "embeddings", ")", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n", "        ", "audio_emb", ",", "video_emb", ",", "emb_cls", "=", "model", ".", "get_embeddings", "(", "all_data", "[", "0", "]", ",", "all_data", "[", "1", "]", ",", "all_data", "[", "3", "]", ")", "\n", "outputs_all", "=", "(", "audio_emb", ",", "video_emb", ",", "emb_cls", ")", "\n", "\n", "", "if", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "a_p", ",", "t_p", "=", "outputs_all", "\n", "v_p", "=", "None", "\n", "", "elif", "new_model_attention", "==", "True", ":", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.save_checkpoint": [[191, 217], ["os.makedirs", "os.makedirs", "torch.save", "torch.save", "print", "print", "model.module.state_dict", "optimizer.state_dict", "lr_scheduler.state_dict", "os.path.join", "os.path.join", "torch.save", "torch.save", "os.path.join", "torch.save", "torch.save", "os.path.join", "os.path.join"], "function", ["None"], ["# a_p = None", "\n", "\n", "", "if", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "audio_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"audio\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "save_performances", "=", "save_performances", ",", "args", "=", "args", ")", "\n", "", "if", "new_model_attention", "==", "True", ":", "\n", "        ", "video_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"video\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "save_performances", "=", "save_performances", ",", "args", "=", "args", ")", "\n", "\n", "", "if", "new_model_attention", "==", "True", ":", "\n", "        ", "return", "{", "\n", "\"audio\"", ":", "video_evaluation", ",", "\n", "\"video\"", ":", "video_evaluation", ",", "\n", "\"both\"", ":", "video_evaluation", "\n", "}", "\n", "", "elif", "model_devise", "==", "True", "or", "apn", "==", "True", ":", "\n", "        ", "return", "{", "\n", "\"audio\"", ":", "audio_evaluation", ",", "\n", "\"video\"", ":", "audio_evaluation", ",", "\n", "\"both\"", ":", "audio_evaluation", "\n", "}", "\n", "\n", "\n", "\n", "", "", "def", "get_best_evaluation", "(", "dataset", ",", "targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", ",", "device", ",", "distance_fn", ",", "best_beta", "=", "None", ",", "save_performances", "=", "False", ",", "args", "=", "None", ",", "attention_weights", "=", "None", ")", ":", "\n", "    ", "seen_scores", "=", "[", "]", "\n", "zsl_scores", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.restart_from_checkpoint": [[219, 262], ["isinstance", "logger.info", "torch.load", "torch.load", "kwargs.items", "os.path.isfile", "os.path.isfile", "logger.info", "logger.warning", "str", "value.load_state_dict", "print", "value.load_state_dict", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["None"], ["hm_scores", "=", "[", "]", "\n", "per_class_recalls", "=", "[", "]", "\n", "start", "=", "0", "\n", "end", "=", "3", "\n", "steps", "=", "(", "end", "-", "start", ")", "*", "5", "+", "1", "\n", "betas", "=", "torch", ".", "tensor", "(", "[", "best_beta", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "if", "best_beta", "else", "torch", ".", "linspace", "(", "start", ",", "end", ",", "steps", ",", "\n", "device", "=", "device", ")", "\n", "seen_label_array", "=", "torch", ".", "tensor", "(", "dataset", ".", "seen_class_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "unseen_label_array", "=", "torch", ".", "tensor", "(", "dataset", ".", "unseen_class_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "seen_unseen_array", "=", "torch", ".", "tensor", "(", "np", ".", "sort", "(", "np", ".", "concatenate", "(", "(", "dataset", ".", "seen_class_ids", ",", "dataset", ".", "unseen_class_ids", ")", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "classes_embeddings", "=", "t_p", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "beta", "in", "betas", ":", "\n", "            ", "if", "a_p", "==", "None", ":", "\n", "                ", "distance_mat", "=", "torch", ".", "zeros", "(", "(", "v_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "distance_mat_zsl", "=", "torch", ".", "zeros", "(", "(", "v_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "", "else", ":", "\n", "                ", "distance_mat", "=", "torch", ".", "zeros", "(", "(", "a_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "distance_mat_zsl", "=", "torch", ".", "zeros", "(", "(", "a_p", ".", "shape", "[", "0", "]", ",", "len", "(", "dataset", ".", "all_class_ids", ")", ")", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "device", ")", "+", "99999999999999", "\n", "", "if", "mode", "==", "\"audio\"", ":", "\n", "                ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "torch", ".", "cdist", "(", "a_p", ",", "classes_embeddings", ")", "# .pow(2)", "\n", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask", "[", "seen_label_array", "]", "=", "99999999999999", "\n", "distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", ".", "pow", "(", "2", ")", "\n", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", "=", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", ".", "pow", "(", "2", ")", "\n", "", "", "elif", "mode", "==", "\"video\"", ":", "\n", "                ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "torch", ".", "cdist", "(", "v_p", ",", "classes_embeddings", ")", "# .pow(2)", "\n", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask", "[", "seen_label_array", "]", "=", "99999999999999", "\n", "distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", ".", "pow", "(", "2", ")", "\n", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", "=", "distance_mat_zsl", "[", ":", ",", "unseen_label_array", "]", ".", "pow", "(", "2", ")", "\n", "", "", "elif", "mode", "==", "\"both\"", ":", "\n", "# L2", "\n", "                ", "audio_distance", "=", "torch", ".", "cdist", "(", "a_p", ",", "classes_embeddings", ",", "p", "=", "2", ")", "# .pow(2)", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.load_model_parameters": [[264, 275], ["model.state_dict", "loaded_state.items", "name.replace.replace", "model.state_dict.keys", "utils..copy_", "print"], "function", ["None"], ["\n", "if", "distance_fn", "==", "\"SquaredL2Loss\"", ":", "\n", "                    ", "audio_distance", "=", "audio_distance", ".", "pow", "(", "2", ")", "\n", "video_distance", "=", "video_distance", ".", "pow", "(", "2", ")", "\n", "\n", "# Sum", "\n", "", "if", "args", ".", "cjme", "==", "True", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "(", "1", "-", "attention_weights", ")", "*", "audio_distance", "+", "attention_weights", "*", "video_distance", "\n", "", "else", ":", "\n", "                    ", "distance_mat", "[", ":", ",", "seen_unseen_array", "]", "=", "(", "audio_distance", "+", "video_distance", ")", "\n", "\n", "", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.fix_random_seeds": [[277, 284], ["torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "numpy.random.seed"], "function", ["None"], ["distance_mat_zsl", "=", "distance_mat", "+", "mask", "\n", "\n", "", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "dataset", ".", "all_class_ids", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "+", "beta", "\n", "mask", "[", "unseen_label_array", "]", "=", "0", "\n", "neighbor_batch", "=", "torch", ".", "argmin", "(", "distance_mat", "+", "mask", ",", "dim", "=", "1", ")", "\n", "match_idx", "=", "neighbor_batch", ".", "eq", "(", "targets", ".", "int", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "match_counts", "=", "torch", ".", "bincount", "(", "neighbor_batch", "[", "match_idx", "]", ",", "minlength", "=", "len", "(", "dataset", ".", "all_class_ids", ")", ")", "[", "\n", "seen_unseen_array", "]", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.accuracy": [[336, 351], ["torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["all_data", "=", "(", "\n", "data_a", ",", "data_v", ",", "data_t", "\n", ")", "\n", "try", ":", "\n", "        ", "if", "args", ".", "z_score_inputs", ":", "\n", "            ", "all_data", "=", "tuple", "(", "[", "(", "x", "-", "torch", ".", "mean", "(", "x", ")", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "x", ")", ")", "for", "x", "in", "all_data", "]", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Namespace has no fitting attribute. Continuing\"", ")", "\n", "\n", "", "all_targets", "=", "dataset", ".", "targets", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "outputs_all", "=", "model", "(", "*", "all_data", ",", "*", "all_data", ")", "\n", "if", "args", ".", "cjme", "==", "True", ":", "\n", "        ", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "attention_weights", ",", "threshold_attention", "=", "outputs_all", "\n", "", "else", ":", "\n", "        ", "x_t_p", ",", "a_p", ",", "v_p", ",", "t_p", ",", "a_q", ",", "v_q", ",", "t_q", ",", "x_ta_p", ",", "x_tv_p", ",", "x_tt_p", ",", "x_ta_q", ",", "x_tv_q", "=", "outputs_all", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.aggregrate_video_accuracy": [[354, 375], ["max", "torch.stack", "torch.stack", "torch.stack.size", "torch.stack", "torch.stack", "torch.stack.topk", "pred.t.t", "pred.t.eq", "torch.stack.expand_as", "correct[].view().float().sum", "res.append", "torch.mean", "torch.mean", "correct[].view().float().sum.mul_", "torch.stack", "torch.stack", "softmaxes.keys", "softmaxes.keys", "correct[].view().float", "correct[].view"], "function", ["None"], ["distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ")", "\n", "video_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"video\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ")", "\n", "both_evaluation", "=", "get_best_evaluation", "(", "dataset", ",", "all_targets", ",", "a_p", ",", "v_p", ",", "t_p", ",", "mode", "=", "\"both\"", ",", "device", "=", "device", ",", "\n", "distance_fn", "=", "distance_fn", ",", "best_beta", "=", "best_beta", ",", "args", "=", "args", ",", "attention_weights", "=", "threshold_attention", ")", "\n", "return", "{", "\n", "\"audio\"", ":", "audio_evaluation", ",", "\n", "\"video\"", ":", "video_evaluation", ",", "\n", "\"both\"", ":", "both_evaluation", "\n", "}", "\n", "\n", "\n", "", "def", "get_class_names", "(", "path", ")", ":", "\n", "    ", "if", "isinstance", "(", "path", ",", "str", ")", ":", "\n", "        ", "path", "=", "Path", "(", "path", ")", "\n", "", "with", "path", ".", "open", "(", "\"r\"", ")", "as", "f", ":", "\n", "        ", "classes", "=", "sorted", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", ")", "\n", "", "return", "classes", "\n", "\n", "\n", "", "def", "load_model_weights", "(", "weights_path", ",", "model", ")", ":", "\n", "    ", "logging", ".", "info", "(", "f\"Loading model weights from {weights_path}\"", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.get_loss": [[377, 388], ["torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.mean", "torch.mean", "torch.stack", "torch.stack", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "range"], "function", ["None"], ["model_weights", "=", "load_dict", "[", "\"model\"", "]", "\n", "epoch", "=", "load_dict", "[", "\"epoch\"", "]", "\n", "logging", ".", "info", "(", "f\"Load from epoch: {epoch}\"", ")", "\n", "load_model_parameters", "(", "model", ",", "model_weights", ")", "\n", "return", "epoch", "\n", "\n", "", "def", "plot_hist_from_dict", "(", "dict", ")", ":", "\n", "    ", "plt", ".", "bar", "(", "range", "(", "len", "(", "dict", ")", ")", ",", "list", "(", "dict", ".", "values", "(", ")", ")", ",", "align", "=", "\"center\"", ")", "\n", "plt", ".", "xticks", "(", "range", "(", "len", "(", "dict", ")", ")", ",", "list", "(", "dict", ".", "keys", "(", ")", ")", ",", "rotation", "=", "'vertical'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.utils.warmup_batchnorm": [[390, 421], ["print", "time.time", "print", "torch.no_grad", "torch.no_grad", "model.train", "enumerate", "video.cuda.cuda", "audio.cuda.cuda", "model", "torch.barrier", "torch.barrier", "time.time"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.selavi_feature_extraction.finetune_video.train"], ["    ", "seen_path", "=", "Path", "(", "f\"doc/cvpr2022/fig/final/class_performance_{dataset_name}_seen.pkl\"", ")", "\n", "unseen_path", "=", "Path", "(", "f\"doc/cvpr2022/fig/final/class_performance_{dataset_name}_unseen.pkl\"", ")", "\n", "with", "seen_path", ".", "open", "(", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "seen_dict", ",", "f", ")", "\n", "logging", ".", "info", "(", "f\"Saving seen class performances to {seen_path}\"", ")", "\n", "", "with", "unseen_path", ".", "open", "(", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "unseen_dict", ",", "f", ")", "\n", "logging", ".", "info", "(", "f\"Saving unseen class performances to {unseen_path}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.normalize": [[17, 22], ["torch.as_tensor().reshape", "torch.as_tensor().reshape", "torch.as_tensor", "torch.as_tensor", "vid.dim"], "function", ["None"], ["def", "normalize", "(", "vid", ",", "mean", ",", "std", ")", ":", "\n", "    ", "shape", "=", "(", "-", "1", ",", ")", "+", "(", "1", ",", ")", "*", "(", "vid", ".", "dim", "(", ")", "-", "1", ")", "\n", "mean", "=", "torch", ".", "as_tensor", "(", "mean", ")", ".", "reshape", "(", "shape", ")", "\n", "std", "=", "torch", ".", "as_tensor", "(", "std", ")", ".", "reshape", "(", "shape", ")", "\n", "return", "(", "vid", "-", "mean", ")", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.resize": [[24, 33], ["isinstance", "torch.nn.functional.interpolate", "float", "min"], "function", ["None"], ["", "def", "resize", "(", "vid", ",", "size", ",", "interpolation", "=", "'bilinear'", ")", ":", "\n", "# NOTE: using bilinear interpolation because we don't work on minibatches", "\n", "# at this level", "\n", "    ", "scale", "=", "None", "\n", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "        ", "scale", "=", "float", "(", "size", ")", "/", "min", "(", "vid", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "size", "=", "None", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "vid", ",", "size", "=", "size", ",", "scale_factor", "=", "scale", ",", "mode", "=", "interpolation", ",", "align_corners", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.random_short_side_scale_jitter": [[35, 79], ["int", "round", "int", "int", "torch.nn.functional.interpolate", "numpy.random.uniform", "math.floor", "math.floor", "float", "float", "float", "float"], "function", ["None"], ["", "def", "random_short_side_scale_jitter", "(", "images", ",", "min_size", ",", "max_size", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform a spatial short scale jittering on the given images and\n    corresponding boxes.\n    Args:\n        images (tensor): images to perform scale jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        min_size (int): the minimal size to scale the frames.\n        max_size (int): the maximal size to scale the frames.\n        boxes (ndarray): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        (tensor): the scaled images with dimension of\n            `num frames` x `channel` x `new height` x `new width`.\n        (ndarray or None): the scaled boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "size", "=", "int", "(", "round", "(", "np", ".", "random", ".", "uniform", "(", "min_size", ",", "max_size", ")", ")", ")", "\n", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "if", "(", "width", "<=", "height", "and", "width", "==", "size", ")", "or", "(", "\n", "height", "<=", "width", "and", "height", "==", "size", "\n", ")", ":", "\n", "        ", "return", "images", ",", "boxes", "\n", "", "new_width", "=", "size", "\n", "new_height", "=", "size", "\n", "if", "width", "<", "height", ":", "\n", "        ", "new_height", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "height", ")", "/", "width", ")", "*", "size", ")", ")", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "boxes", "*", "float", "(", "new_height", ")", "/", "height", "\n", "", "", "else", ":", "\n", "        ", "new_width", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "width", ")", "/", "height", ")", "*", "size", ")", ")", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "boxes", "*", "float", "(", "new_width", ")", "/", "width", "\n", "\n", "", "", "return", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "images", ",", "\n", "size", "=", "(", "new_height", ",", "new_width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ",", "\n", "boxes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.crop_boxes": [[82, 99], ["boxes.copy"], "function", ["None"], ["", "def", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", ":", "\n", "    ", "\"\"\"\n    Peform crop on the bounding boxes given the offsets.\n    Args:\n        boxes (ndarray or None): bounding boxes to peform crop. The dimension\n            is `num boxes` x 4.\n        x_offset (int): cropping offset in the x axis.\n        y_offset (int): cropping offset in the y axis.\n    Returns:\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "cropped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "cropped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "-", "x_offset", "\n", "cropped_boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "-", "y_offset", "\n", "\n", "return", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.random_crop": [[101, 135], ["int", "int", "video_transforms.crop_boxes", "numpy.random.randint", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.crop_boxes"], ["", "def", "random_crop", "(", "images", ",", "size", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform random spatial crop on the given images and corresponding boxes.\n    Args:\n        images (tensor): images to perform random crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): the size of height and width to crop on the image.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        cropped (tensor): cropped images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "if", "images", ".", "shape", "[", "2", "]", "==", "size", "and", "images", ".", "shape", "[", "3", "]", "==", "size", ":", "\n", "        ", "return", "images", "\n", "", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "y_offset", "=", "0", "\n", "if", "height", ">", "size", ":", "\n", "        ", "y_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "height", "-", "size", ")", ")", "\n", "", "x_offset", "=", "0", "\n", "if", "width", ">", "size", ":", "\n", "        ", "x_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "width", "-", "size", ")", ")", "\n", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "\n", "cropped_boxes", "=", "(", "\n", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", "if", "boxes", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "return", "cropped", ",", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.horizontal_flip": [[137, 165], ["boxes.copy", "numpy.random.uniform", "images.flip.flip"], "function", ["None"], ["", "def", "horizontal_flip", "(", "prob", ",", "images", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform horizontal flip on the given images and corresponding boxes.\n    Args:\n        prob (float): probility to flip the images.\n        images (tensor): images to perform horizontal flip, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        images (tensor): images with dimension of\n            `num frames` x `channel` x `height` x `width`.\n        flipped_boxes (ndarray or None): the flipped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "if", "boxes", "is", "None", ":", "\n", "        ", "flipped_boxes", "=", "None", "\n", "", "else", ":", "\n", "        ", "flipped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "\n", "", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "prob", ":", "\n", "        ", "images", "=", "images", ".", "flip", "(", "(", "-", "1", ")", ")", "\n", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "flipped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "width", "-", "boxes", "[", ":", ",", "[", "2", ",", "0", "]", "]", "-", "1", "\n", "\n", "", "", "return", "images", ",", "flipped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.uniform_crop": [[167, 211], ["int", "int", "math.ceil", "math.ceil", "video_transforms.crop_boxes"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.crop_boxes"], ["", "def", "uniform_crop", "(", "images", ",", "size", ",", "spatial_idx", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform uniform spatial sampling on the images and corresponding boxes.\n    Args:\n        images (tensor): images to perform uniform crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): size of height and weight to crop the images.\n        spatial_idx (int): 0, 1, or 2 for left, center, and right crop if width\n            is larger than height. Or 0, 1, or 2 for top, center, and bottom\n            crop if height is larger than width.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        cropped (tensor): images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "0", ",", "1", ",", "2", "]", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "\n", "y_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "height", "-", "size", ")", "/", "2", ")", ")", "\n", "x_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "width", "-", "size", ")", "/", "2", ")", ")", "\n", "\n", "if", "height", ">", "width", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "y_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "y_offset", "=", "height", "-", "size", "\n", "", "", "else", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "x_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "x_offset", "=", "width", "-", "size", "\n", "", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "\n", "cropped_boxes", "=", "(", "\n", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", "if", "boxes", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "return", "cropped", ",", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.clip_boxes_to_image": [[213, 233], ["boxes.copy", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum"], "function", ["None"], ["", "def", "clip_boxes_to_image", "(", "boxes", ",", "height", ",", "width", ")", ":", "\n", "    ", "\"\"\"\n    Clip an array of boxes to an image with the given height and width.\n    Args:\n        boxes (ndarray): bounding boxes to perform clipping.\n            Dimension is `num boxes` x 4.\n        height (int): given image height.\n        width (int): given image width.\n    Returns:\n        clipped_boxes (ndarray): the clipped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "clipped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "clipped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "np", ".", "minimum", "(", "\n", "width", "-", "1.0", ",", "np", ".", "maximum", "(", "0.0", ",", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ")", "\n", ")", "\n", "clipped_boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "np", ".", "minimum", "(", "\n", "height", "-", "1.0", ",", "np", ".", "maximum", "(", "0.0", ",", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ")", "\n", ")", "\n", "return", "clipped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.blend": [[235, 249], ["None"], "function", ["None"], ["", "def", "blend", "(", "images1", ",", "images2", ",", "alpha", ")", ":", "\n", "    ", "\"\"\"\n    Blend two images with a given weight alpha.\n    Args:\n        images1 (tensor): the first images to be blended, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        images2 (tensor): the second images to be blended, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        alpha (float): the blending weight.\n    Returns:\n        (tensor): blended images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "return", "images1", "*", "alpha", "+", "images2", "*", "(", "1", "-", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.grayscale": [[251, 271], ["torch.zeros_like"], "function", ["None"], ["", "def", "grayscale", "(", "images", ")", ":", "\n", "    ", "\"\"\"\n    Get the grayscale for the input images. The channels of images should be\n    in order BGR.\n    Args:\n        images (tensor): the input images for getting grayscale. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        img_gray (tensor): blended images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "# R -> 0.299, G -> 0.587, B -> 0.114.", "\n", "img_gray", "=", "torch", ".", "zeros_like", "(", "images", ")", "\n", "gray_channel", "=", "(", "\n", "0.299", "*", "images", "[", ":", ",", "2", "]", "+", "0.587", "*", "images", "[", ":", ",", "1", "]", "+", "0.114", "*", "images", "[", ":", ",", "0", "]", "\n", ")", "\n", "img_gray", "[", ":", ",", "0", "]", "=", "gray_channel", "\n", "img_gray", "[", ":", ",", "1", "]", "=", "gray_channel", "\n", "img_gray", "[", ":", ",", "2", "]", "=", "gray_channel", "\n", "return", "img_gray", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.color_jitter": [[273, 306], ["jitter.append", "jitter.append", "jitter.append", "len", "numpy.random.permutation", "range", "numpy.arange", "len", "len", "video_transforms.brightness_jitter", "video_transforms.contrast_jitter", "video_transforms.saturation_jitter"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.brightness_jitter", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.contrast_jitter", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.saturation_jitter"], ["", "def", "color_jitter", "(", "images", ",", "img_brightness", "=", "0", ",", "img_contrast", "=", "0", ",", "img_saturation", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom a color jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        img_brightness (float): jitter ratio for brightness.\n        img_contrast (float): jitter ratio for contrast.\n        img_saturation (float): jitter ratio for saturation.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "\n", "jitter", "=", "[", "]", "\n", "if", "img_brightness", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"brightness\"", ")", "\n", "", "if", "img_contrast", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"contrast\"", ")", "\n", "", "if", "img_saturation", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"saturation\"", ")", "\n", "\n", "", "if", "len", "(", "jitter", ")", ">", "0", ":", "\n", "        ", "order", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "jitter", ")", ")", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "len", "(", "jitter", ")", ")", ":", "\n", "            ", "if", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"brightness\"", ":", "\n", "                ", "images", "=", "brightness_jitter", "(", "img_brightness", ",", "images", ")", "\n", "", "elif", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"contrast\"", ":", "\n", "                ", "images", "=", "contrast_jitter", "(", "img_contrast", ",", "images", ")", "\n", "", "elif", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"saturation\"", ":", "\n", "                ", "images", "=", "saturation_jitter", "(", "img_saturation", ",", "images", ")", "\n", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.brightness_jitter": [[308, 325], ["torch.zeros", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.blend"], ["", "def", "brightness_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom brightness jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for brightness.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "\n", "img_bright", "=", "torch", ".", "zeros", "(", "images", ".", "shape", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_bright", ",", "alpha", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.contrast_jitter": [[327, 345], ["video_transforms.grayscale", "torch.mean", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.grayscale", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.blend"], ["", "def", "contrast_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom contrast jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for contrast.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "\n", "img_gray", "=", "grayscale", "(", "images", ")", "\n", "img_gray", "[", ":", "]", "=", "torch", ".", "mean", "(", "img_gray", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_gray", ",", "alpha", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.saturation_jitter": [[347, 364], ["video_transforms.grayscale", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.grayscale", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.blend"], ["", "def", "saturation_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom saturation jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for saturation.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "img_gray", "=", "grayscale", "(", "images", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_gray", ",", "alpha", ")", "\n", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.lighting_jitter": [[366, 394], ["numpy.random.normal", "numpy.array", "numpy.reshape", "numpy.sum", "torch.zeros_like", "range", "numpy.repeat", "numpy.repeat"], "function", ["None"], ["", "def", "lighting_jitter", "(", "images", ",", "alphastd", ",", "eigval", ",", "eigvec", ")", ":", "\n", "    ", "\"\"\"\n    Perform AlexNet-style PCA jitter on the given images.\n    Args:\n        images (tensor): images to perform lighting jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        alphastd (float): jitter ratio for PCA jitter.\n        eigval (list): eigenvalues for PCA jitter.\n        eigvec (list[list]): eigenvectors for PCA jitter.\n    Returns:\n        out_images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "if", "alphastd", "==", "0", ":", "\n", "        ", "return", "images", "\n", "# generate alpha1, alpha2, alpha3.", "\n", "", "alpha", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "alphastd", ",", "size", "=", "(", "1", ",", "3", ")", ")", "\n", "eig_vec", "=", "np", ".", "array", "(", "eigvec", ")", "\n", "eig_val", "=", "np", ".", "reshape", "(", "eigval", ",", "(", "1", ",", "3", ")", ")", "\n", "rgb", "=", "np", ".", "sum", "(", "\n", "eig_vec", "*", "np", ".", "repeat", "(", "alpha", ",", "3", ",", "axis", "=", "0", ")", "*", "np", ".", "repeat", "(", "eig_val", ",", "3", ",", "axis", "=", "0", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "out_images", "=", "torch", ".", "zeros_like", "(", "images", ")", "\n", "for", "idx", "in", "range", "(", "images", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "out_images", "[", ":", ",", "idx", "]", "=", "images", "[", ":", ",", "idx", "]", "+", "rgb", "[", "2", "-", "idx", "]", "\n", "\n", "", "return", "out_images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.color_normalization": [[396, 418], ["torch.zeros_like", "range", "len", "len", "len"], "function", ["None"], ["", "def", "color_normalization", "(", "images", ",", "mean", ",", "stddev", ")", ":", "\n", "    ", "\"\"\"\n    Perform color nomration on the given images.\n    Args:\n        images (tensor): images to perform color normalization. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        mean (list): mean values for normalization.\n        stddev (list): standard deviations for normalization.\n    Returns:\n        out_images (tensor): the noramlized images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "assert", "len", "(", "mean", ")", "==", "images", ".", "shape", "[", "1", "]", ",", "\"channel mean not computed properly\"", "\n", "assert", "(", "\n", "len", "(", "stddev", ")", "==", "images", ".", "shape", "[", "1", "]", "\n", ")", ",", "\"channel stddev not computed properly\"", "\n", "\n", "out_images", "=", "torch", ".", "zeros_like", "(", "images", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "mean", ")", ")", ":", "\n", "        ", "out_images", "[", ":", ",", "idx", "]", "=", "(", "images", "[", ":", ",", "idx", "]", "-", "mean", "[", "idx", "]", ")", "/", "stddev", "[", "idx", "]", "\n", "\n", "", "return", "out_images", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.spatial_sampling": [[420, 460], ["video_transforms.random_short_side_scale_jitter", "video_transforms.random_crop", "video_transforms.horizontal_flip", "video_transforms.random_short_side_scale_jitter", "video_transforms.uniform_crop", "video_transforms.horizontal_flip"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.random_crop", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.horizontal_flip", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.uniform_crop", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.horizontal_flip"], ["", "def", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform spatial sampling on the given video frames. If spatial_idx is\n    -1, perform random scale, random crop, and random flip on the given\n    frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n    with the given spatial_idx.\n    Args:\n        frames (tensor): frames of images sampled from the video. The\n            dimension is `num frames` x `height` x `width` x `channel`.\n        spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n            or 2, perform left, center, right crop if width is larger than\n            height, and perform top, center, buttom crop if height is larger\n            than width.\n        min_scale (int): the minimal size of scaling.\n        max_scale (int): the maximal size of scaling.\n        crop_size (int): the size of height and width used to crop the\n            frames.\n    Returns:\n        frames (tensor): spatially sampled frames.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "if", "spatial_idx", "==", "-", "1", ":", "\n", "        ", "frames", ",", "_", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", ",", "_", "=", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "frames", ",", "_", "=", "horizontal_flip", "(", "0.5", ",", "frames", ")", "\n", "", "else", ":", "\n", "        ", "frames", ",", "_", "=", "random_short_side_scale_jitter", "(", "frames", ",", "min_scale", ",", "max_scale", ")", "\n", "idx_mapping", "=", "{", "0", ":", "0", ",", "1", ":", "1", ",", "2", ":", "2", ",", "3", ":", "0", ",", "4", ":", "1", ",", "5", ":", "2", "}", "\n", "frames", ",", "_", "=", "uniform_crop", "(", "frames", ",", "crop_size", ",", "idx_mapping", "[", "spatial_idx", "]", ")", "\n", "if", "spatial_idx", "in", "[", "3", ",", "4", ",", "5", "]", ":", "\n", "            ", "frames", ",", "_", "=", "horizontal_flip", "(", "1", ",", "frames", ")", "\n", "", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.clip_augmentation": [[462, 505], ["grayscale.float", "grayscale.permute().contiguous", "video_transforms.spatial_sampling", "grayscale.permute", "torch.tensor", "torch.tensor", "grayscale.permute", "numpy.random.uniform", "video_transforms.color_jitter", "numpy.random.uniform", "video_transforms.grayscale"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.spatial_sampling", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.color_jitter", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.grayscale"], ["", "def", "clip_augmentation", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", "colorjitter", "=", "False", ",", "\n", "use_grayscale", "=", "False", ",", "\n", "use_gaussian", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# Convert to Float", "\n", "    ", "frames", "=", "frames", ".", "float", "(", ")", "\n", "frames", "=", "frames", "/", "255.0", "\n", "frames", "=", "frames", "-", "torch", ".", "tensor", "(", "MEAN", ")", "\n", "frames", "=", "frames", "/", "torch", ".", "tensor", "(", "STD", ")", "\n", "\n", "# T H W C -> T C H W.", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Spatial Augmentation", "\n", "frames", "=", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "spatial_idx", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", "crop_size", "=", "crop_size", ",", "\n", ")", "\n", "\n", "# Perform color jitter with prob=0.8", "\n", "if", "colorjitter", ":", "\n", "        ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">=", "0.2", ":", "\n", "# frames = color_jitter(frames, 0.6, 0.6, 0.6)", "\n", "            ", "frames", "=", "color_jitter", "(", "frames", ",", "0.4", ",", "0.4", ",", "0.4", ")", "\n", "\n", "# Perform gray-scale with prob=0.2", "\n", "", "", "if", "use_grayscale", ":", "\n", "        ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">=", "0.8", ":", "\n", "            ", "frames", "=", "grayscale", "(", "frames", ")", "\n", "\n", "# T C H W -> C T H W", "\n", "", "", "frames", "=", "frames", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "return", "frames", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.temporal_sampling": [[21, 39], ["torch.linspace", "torch.clamp().long", "torch.index_select", "torch.clamp"], "function", ["None"], ["", "def", "temporal_sampling", "(", "frames", ",", "start_idx", ",", "end_idx", ",", "num_samples", ")", ":", "\n", "    ", "\"\"\"\n    Given the start and end frame index, sample num_samples frames between\n    the start and end with equal interval.\n    Args:\n        frames (tensor): a tensor of video frames, dimension is\n            `num video frames` x `channel` x `height` x `width`.\n        start_idx (int): the index of the start frame.\n        end_idx (int): the index of the end frame.\n        num_samples (int): number of frames to sample.\n    Returns:\n        frames (tersor): a tensor of temporal sampled video frames, dimension is\n            `num clip frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "index", "=", "torch", ".", "linspace", "(", "start_idx", ",", "end_idx", ",", "num_samples", ")", "\n", "index", "=", "torch", ".", "clamp", "(", "index", ",", "0", ",", "frames", ".", "shape", "[", "0", "]", "-", "1", ")", ".", "long", "(", ")", "\n", "frames", "=", "torch", ".", "index_select", "(", "frames", ",", "0", ",", "index", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.get_start_end_idx": [[41, 70], ["max", "random.uniform", "int"], "function", ["None"], ["", "def", "get_start_end_idx", "(", "video_size", ",", "clip_size", ",", "clip_idx", ",", "num_clips", ")", ":", "\n", "    ", "\"\"\"\n    Sample a clip of size clip_size from a video of size video_size and\n    return the indices of the first and last frame of the clip. If clip_idx is\n    -1, the clip is randomly sampled, otherwise uniformly split the video to\n    num_clips clips, and select the start and end index of clip_idx-th video\n    clip.\n    Args:\n        video_size (int): number of overall frames.\n        clip_size (int): size of the clip to sample from the frames.\n        clip_idx (int): if clip_idx is -1, perform random jitter sampling. If\n            clip_idx is larger than -1, uniformly split the video to num_clips\n            clips, and select the start and end index of the clip_idx-th video\n            clip.\n        num_clips (int): overall number of clips to uniformly sample from the\n            given video for testing.\n    Returns:\n        start_idx (int): the start frame index.\n        end_idx (int): the end frame index.\n    \"\"\"", "\n", "delta", "=", "max", "(", "video_size", "-", "clip_size", ",", "0", ")", "\n", "if", "clip_idx", "==", "-", "1", ":", "\n", "# Random temporal sampling.", "\n", "        ", "start_idx", "=", "random", ".", "uniform", "(", "0", ",", "delta", ")", "\n", "", "else", ":", "\n", "# Uniformly sample the clip with the given index.", "\n", "        ", "start_idx", "=", "int", "(", "delta", "*", "clip_idx", "/", "num_clips", ")", "\n", "", "end_idx", "=", "start_idx", "+", "clip_size", "-", "1", "\n", "return", "start_idx", ",", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.pyav_decode_stream": [[72, 112], ["max", "container.seek", "container.decode", "max", "sorted"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.decode"], ["", "def", "pyav_decode_stream", "(", "\n", "container", ",", "start_pts", ",", "end_pts", ",", "stream", ",", "stream_name", ",", "buffer_size", "=", "0", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Decode the video with PyAV decoder.\n    Args:\n        container (container): PyAV container.\n        start_pts (int): the starting Presentation TimeStamp to fetch the\n            video frames.\n        end_pts (int): the ending Presentation TimeStamp of the decoded frames.\n        stream (stream): PyAV stream.\n        stream_name (dict): a dictionary of streams. For example, {\"video\": 0}\n            means video stream at stream index 0.\n        buffer_size (int): number of additional frames to decode beyond end_pts.\n    Returns:\n        result (list): list of frames decoded.\n        max_pts (int): max Presentation TimeStamp of the video sequence.\n    \"\"\"", "\n", "# Seeking in the stream is imprecise. Thus, seek to an ealier PTS by a", "\n", "# margin pts.", "\n", "margin", "=", "1024", "\n", "seek_offset", "=", "max", "(", "start_pts", "-", "margin", ",", "0", ")", "\n", "\n", "container", ".", "seek", "(", "seek_offset", ",", "any_frame", "=", "False", ",", "backward", "=", "True", ",", "stream", "=", "stream", ")", "\n", "frames", "=", "{", "}", "\n", "buffer_count", "=", "0", "\n", "max_pts", "=", "0", "\n", "for", "frame", "in", "container", ".", "decode", "(", "**", "stream_name", ")", ":", "\n", "        ", "max_pts", "=", "max", "(", "max_pts", ",", "frame", ".", "pts", ")", "\n", "if", "frame", ".", "pts", "<", "start_pts", ":", "\n", "            ", "continue", "\n", "", "if", "frame", ".", "pts", "<=", "end_pts", ":", "\n", "            ", "frames", "[", "frame", ".", "pts", "]", "=", "frame", "\n", "", "else", ":", "\n", "            ", "buffer_count", "+=", "1", "\n", "frames", "[", "frame", ".", "pts", "]", "=", "frame", "\n", "if", "buffer_count", ">=", "buffer_size", ":", "\n", "                ", "break", "\n", "", "", "", "result", "=", "[", "frames", "[", "pts", "]", "for", "pts", "in", "sorted", "(", "frames", ")", "]", "\n", "return", "result", ",", "max_pts", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.torchvision_decode": [[114, 188], ["torch.from_numpy", "torchvision.read_video_from_memory", "numpy.frombuffer", "len", "torchvision.read_video_meta_data_from_memory"], "function", ["None"], ["", "def", "torchvision_decode", "(", "\n", "video_handle", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", ",", "\n", "video_meta", ",", "\n", "num_clips", "=", "10", ",", "\n", "target_fps", "=", "30", ",", "\n", "modalities", "=", "(", "\"visual\"", ",", ")", ",", "\n", "max_spatial_scale", "=", "0", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    If video_meta is not empty, perform temporal selective decoding to sample a\n    clip from the video with TorchVision decoder. If video_meta is empty, decode\n    the entire video and update the video_meta.\n    Args:\n        video_handle (bytes): raw bytes of the video file.\n        sampling_rate (int): frame sampling rate (interval between two sampled\n            frames).\n        num_frames (int): number of frames to sample.\n        clip_idx (int): if clip_idx is -1, perform random temporal\n            sampling. If clip_idx is larger than -1, uniformly split the\n            video to num_clips clips, and select the clip_idx-th video clip.\n        video_meta (dict): a dict contains VideoMetaData. Details can be found\n            at `pytorch/vision/torchvision/io/_video_opt.py`.\n        num_clips (int): overall number of clips to uniformly sample from the\n            given video.\n        target_fps (int): the input video may has different fps, convert it to\n            the target video fps.\n        modalities (tuple): tuple of modalities to decode. Currently only\n            support `visual`, planning to support `acoustic` soon.\n        max_spatial_scale (int): the maximal resolution of the spatial shorter\n            edge size during decoding.\n    Returns:\n        frames (tensor): decoded frames from the video.\n        fps (float): the number of frames per second of the video.\n        decode_all_video (bool): if True, the entire video was decoded.\n    \"\"\"", "\n", "# Convert the bytes to a tensor.", "\n", "video_tensor", "=", "torch", ".", "from_numpy", "(", "np", ".", "frombuffer", "(", "video_handle", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "\n", "decode_all_video", "=", "True", "\n", "video_start_pts", ",", "video_end_pts", "=", "0", ",", "-", "1", "\n", "# The video_meta is empty, fetch the meta data from the raw video.", "\n", "if", "len", "(", "video_meta", ")", "==", "0", ":", "\n", "# Tracking the meta info for selective decoding in the future.", "\n", "        ", "meta", "=", "io", ".", "read_video_meta_data_from_memory", "(", "video_tensor", ")", "\n", "# Using the information from video_meta to perform selective decoding.", "\n", "video_meta", "[", "\"video_timebase\"", "]", "=", "meta", ".", "video_timebase", "\n", "video_meta", "[", "\"video_numerator\"", "]", "=", "meta", ".", "video_timebase", ".", "numerator", "\n", "video_meta", "[", "\"video_denominator\"", "]", "=", "meta", ".", "video_timebase", ".", "denominator", "\n", "video_meta", "[", "\"has_video\"", "]", "=", "meta", ".", "has_video", "\n", "video_meta", "[", "\"video_duration\"", "]", "=", "meta", ".", "video_duration", "\n", "video_meta", "[", "\"video_fps\"", "]", "=", "meta", ".", "video_fps", "\n", "video_meta", "[", "\"audio_timebas\"", "]", "=", "meta", ".", "audio_timebase", "\n", "video_meta", "[", "\"audio_numerator\"", "]", "=", "meta", ".", "audio_timebase", ".", "numerator", "\n", "video_meta", "[", "\"audio_denominator\"", "]", "=", "meta", ".", "audio_timebase", ".", "denominator", "\n", "video_meta", "[", "\"has_audio\"", "]", "=", "meta", ".", "has_audio", "\n", "video_meta", "[", "\"audio_duration\"", "]", "=", "meta", ".", "audio_duration", "\n", "video_meta", "[", "\"audio_sample_rate\"", "]", "=", "meta", ".", "audio_sample_rate", "\n", "\n", "# Decode the raw video with the tv decoder.", "\n", "", "v_frames", ",", "_", "=", "io", ".", "read_video_from_memory", "(", "\n", "video_tensor", ",", "\n", "seek_frame_margin", "=", "1.0", ",", "\n", "read_video_stream", "=", "\"visual\"", "in", "modalities", ",", "\n", "video_width", "=", "0", ",", "\n", "video_height", "=", "0", ",", "\n", "video_min_dimension", "=", "max_spatial_scale", ",", "\n", "video_pts_range", "=", "(", "video_start_pts", ",", "video_end_pts", ")", ",", "\n", "video_timebase_numerator", "=", "video_meta", "[", "\"video_numerator\"", "]", ",", "\n", "video_timebase_denominator", "=", "video_meta", "[", "\"video_denominator\"", "]", ",", "\n", ")", "\n", "return", "v_frames", ",", "video_meta", "[", "\"video_fps\"", "]", ",", "decode_all_video", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.pyav_decode": [[190, 303], ["float", "decoder.get_start_end_idx", "int", "int", "decoder.pyav_decode_stream", "torch.as_tensor", "frame.to_rgb().to_ndarray", "numpy.stack", "load_audio", "print", "frame.to_rgb", "print"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.get_start_end_idx", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.pyav_decode_stream", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.audio_utils.load_audio"], ["", "def", "pyav_decode", "(", "\n", "vid_path", ",", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", ",", "\n", "num_clips", "=", "10", ",", "\n", "target_fps", "=", "30", ",", "\n", "aug_audio", "=", "[", "]", ",", "\n", "decode_audio", "=", "True", ",", "\n", "num_sec", "=", "1", ",", "\n", "aud_sample_rate", "=", "48000", ",", "\n", "aud_spec_type", "=", "1", ",", "\n", "use_volume_jittering", "=", "False", ",", "\n", "use_temporal_jittering", "=", "False", ",", "\n", "z_normalize", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Convert the video from its original fps to the target_fps. If the video\n    support selective decoding (contain decoding information in the video head),\n    the perform temporal selective decoding and sample a clip from the video\n    with the PyAV decoder. If the video does not support selective decoding,\n    decode the entire video.\n    Args:\n        container (container): pyav container.\n        sampling_rate (int): frame sampling rate (interval between two sampled\n            frames.\n        num_frames (int): number of frames to sample.\n        clip_idx (int): if clip_idx is -1, perform random temporal sampling. If\n            clip_idx is larger than -1, uniformly split the video to num_clips\n            clips, and select the clip_idx-th video clip.\n        num_clips (int): overall number of clips to uniformly sample from the\n            given video.\n        target_fps (int): the input video may has different fps, convert it to\n            the target video fps before frame sampling.\n    Returns:\n        frames (tensor): decoded frames from the video. Return None if the no\n            video stream was found.\n        fps (float): the number of frames per second of the video.\n        decode_all_video (bool): If True, the entire video was decoded.\n    \"\"\"", "\n", "# Try to fetch the decoding information from the video head. Some of the", "\n", "# videos does not support fetching the decoding information, for that case", "\n", "# it will get None duration.", "\n", "fps", "=", "float", "(", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "average_rate", ")", "\n", "frames_length", "=", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "frames", "\n", "duration", "=", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "duration", "\n", "\n", "if", "duration", "is", "None", ":", "\n", "# If failed to fetch the decoding information, decode the entire video.", "\n", "        ", "decode_all_video", "=", "True", "\n", "video_start_pts", ",", "video_end_pts", "=", "0", ",", "math", ".", "inf", "\n", "", "else", ":", "\n", "# Perform selective decoding.", "\n", "        ", "decode_all_video", "=", "False", "\n", "start_idx", ",", "end_idx", "=", "get_start_end_idx", "(", "\n", "frames_length", ",", "\n", "sampling_rate", "*", "num_frames", "/", "target_fps", "*", "fps", ",", "\n", "clip_idx", ",", "\n", "num_clips", ",", "\n", ")", "\n", "\n", "timebase", "=", "duration", "/", "frames_length", "\n", "video_start_pts", "=", "int", "(", "start_idx", "*", "timebase", ")", "\n", "video_end_pts", "=", "int", "(", "end_idx", "*", "timebase", ")", "\n", "\n", "", "frames", "=", "None", "\n", "# If video stream was found, fetch video frames from the video.", "\n", "if", "container", ".", "streams", ".", "video", ":", "\n", "        ", "video_frames", ",", "max_pts", "=", "pyav_decode_stream", "(", "\n", "container", ",", "\n", "video_start_pts", ",", "\n", "video_end_pts", ",", "\n", "container", ".", "streams", ".", "video", "[", "0", "]", ",", "\n", "{", "\"video\"", ":", "0", "}", ",", "\n", ")", "\n", "# container.close()", "\n", "\n", "frames", "=", "[", "frame", ".", "to_rgb", "(", ")", ".", "to_ndarray", "(", ")", "for", "frame", "in", "video_frames", "]", "\n", "frames", "=", "torch", ".", "as_tensor", "(", "np", ".", "stack", "(", "frames", ")", ")", "\n", "\n", "# Get wav", "\n", "", "if", "decode_audio", ":", "\n", "        ", "try", ":", "\n", "# Get spectogram", "\n", "            ", "fr_sec", "=", "start_idx", "/", "fps", "\n", "spec", "=", "load_audio", "(", "\n", "vid_path", ",", "\n", "fr_sec", ",", "\n", "num_sec", "=", "num_sec", ",", "\n", "sample_rate", "=", "aud_sample_rate", ",", "\n", "aug_audio", "=", "aug_audio", ",", "\n", "aud_spec_type", "=", "aud_spec_type", ",", "\n", "use_volume_jittering", "=", "use_volume_jittering", ",", "\n", "use_temporal_jittering", "=", "use_temporal_jittering", ",", "\n", "z_normalize", "=", "z_normalize", ",", "\n", ")", "\n", "# if spec.shape[-1] < num_sec * 100 - 1:", "\n", "# print(\"OH NO IT HAPPENED\")", "\n", "# raise AttributeError()", "\n", "", "except", ":", "\n", "            ", "print", "(", "f\"Bad audio of video: {vid_path}\"", ",", "flush", "=", "True", ")", "\n", "# print(f\"Bad audio of video: {vid_path}\")", "\n", "if", "spec", "is", "not", "None", ":", "\n", "                ", "print", "(", "f\"Bad spec shape of {vid_path}: {spec.shape}\"", ",", "flush", "=", "True", ")", "\n", "# print(f\"Bad spec shape of {vid_path}: {spec.shape}\")", "\n", "# if wav is not None:", "\n", "#     print(f\"Bad wav shape of {vid_path}: {wav.shape}\", flush=True)", "\n", "", "return", "None", ",", "None", ",", "None", ",", "None", "\n", "#print(vid_path, frames.shape,  spec.shape)", "\n", "", "return", "frames", ",", "spec", ",", "fps", ",", "decode_all_video", "\n", "", "else", ":", "\n", "        ", "return", "frames", ",", "None", ",", "fps", ",", "decode_all_video", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.decode": [[305, 404], ["decoder.get_start_end_idx", "decoder.temporal_sampling", "decoder.pyav_decode", "print", "temporal_sampling.size", "decoder.torchvision_decode", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.get_start_end_idx", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.temporal_sampling", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.pyav_decode", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.torchvision_decode"], ["", "", "def", "decode", "(", "\n", "vid_path", ",", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", "=", "-", "1", ",", "\n", "num_clips", "=", "10", ",", "\n", "video_meta", "=", "None", ",", "\n", "target_fps", "=", "30", ",", "\n", "backend", "=", "\"pyav\"", ",", "\n", "max_spatial_scale", "=", "0", ",", "\n", "decode_audio", "=", "True", ",", "\n", "aug_audio", "=", "[", "]", ",", "\n", "num_sec", "=", "1", ",", "\n", "aud_sample_rate", "=", "48000", ",", "\n", "aud_spec_type", "=", "1", ",", "\n", "use_volume_jittering", "=", "False", ",", "\n", "use_temporal_jittering", "=", "False", ",", "\n", "z_normalize", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Decode the video and perform temporal sampling.\n    Args:\n        container (container): pyav container.\n        sampling_rate (int): frame sampling rate (interval between two sampled\n            frames).\n        num_frames (int): number of frames to sample.\n        clip_idx (int): if clip_idx is -1, perform random temporal\n            sampling. If clip_idx is larger than -1, uniformly split the\n            video to num_clips clips, and select the\n            clip_idx-th video clip.\n        num_clips (int): overall number of clips to uniformly\n            sample from the given video.\n        video_meta (dict): a dict contains VideoMetaData. Details can be find\n            at `pytorch/vision/torchvision/io/_video_opt.py`.\n        target_fps (int): the input video may have different fps, convert it to\n            the target video fps before frame sampling.\n        backend (str): decoding backend includes `pyav` and `torchvision`. The\n            default one is `pyav`.\n        max_spatial_scale (int): keep the aspect ratio and resize the frame so\n            that shorter edge size is max_spatial_scale. Only used in\n            `torchvision` backend.\n    Returns:\n        frames (tensor): decoded frames from the video.\n    \"\"\"", "\n", "# Currently support two decoders: 1) PyAV, and 2) TorchVision.", "\n", "assert", "clip_idx", ">=", "-", "1", ",", "\"Not valied clip_idx {}\"", ".", "format", "(", "clip_idx", ")", "\n", "try", ":", "\n", "        ", "if", "backend", "==", "\"pyav\"", ":", "\n", "            ", "frames", ",", "spec", ",", "fps", ",", "decode_all_video", "=", "pyav_decode", "(", "\n", "vid_path", ",", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", ",", "\n", "num_clips", ",", "\n", "target_fps", ",", "\n", "aug_audio", "=", "aug_audio", ",", "\n", "decode_audio", "=", "decode_audio", ",", "\n", "num_sec", "=", "num_sec", ",", "\n", "aud_sample_rate", "=", "aud_sample_rate", ",", "\n", "aud_spec_type", "=", "aud_spec_type", ",", "\n", "use_volume_jittering", "=", "use_volume_jittering", ",", "\n", "use_temporal_jittering", "=", "use_temporal_jittering", ",", "\n", "z_normalize", "=", "z_normalize", ",", "\n", ")", "\n", "", "elif", "backend", "==", "\"torchvision\"", ":", "\n", "            ", "frames", ",", "fps", ",", "decode_all_video", "=", "torchvision_decode", "(", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", ",", "\n", "video_meta", ",", "\n", "num_clips", ",", "\n", "target_fps", ",", "\n", "(", "\"visual\"", ",", ")", ",", "\n", "max_spatial_scale", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Unknown decoding backend {}\"", ".", "format", "(", "backend", ")", "\n", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Failed to decode by {} with exception: {}\"", ".", "format", "(", "backend", ",", "e", ")", ")", "\n", "return", "None", "\n", "\n", "# Return None if the frames was not decoded successfully.", "\n", "", "if", "frames", "is", "None", "or", "frames", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "start_idx", ",", "end_idx", "=", "get_start_end_idx", "(", "\n", "frames", ".", "shape", "[", "0", "]", ",", "\n", "num_frames", "*", "sampling_rate", "*", "fps", "/", "target_fps", ",", "\n", "clip_idx", "if", "decode_all_video", "else", "0", ",", "\n", "num_clips", "if", "decode_all_video", "else", "1", ",", "\n", ")", "\n", "# Perform temporal sampling from the decoded video.", "\n", "frames", "=", "temporal_sampling", "(", "frames", ",", "start_idx", ",", "end_idx", ",", "num_frames", ")", "\n", "return", "frames", ",", "spec", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.audio_utils.get_spec": [[14, 75], ["int", "int", "python_speech_features.logfbank.astype", "numpy.expand_dims", "torch.as_tensor", "numpy.round", "len", "len", "python_speech_features.logfbank", "python_speech_features.logfbank", "numpy.random.uniform", "numpy.round", "len", "numpy.random.uniform"], "function", ["None"], ["def", "get_spec", "(", "\n", "wav", ",", "\n", "fr_sec", ",", "\n", "num_sec", "=", "1", ",", "\n", "sample_rate", "=", "48000", ",", "\n", "aug_audio", "=", "[", "]", ",", "\n", "aud_spec_type", "=", "1", ",", "\n", "use_volume_jittering", "=", "False", ",", "\n", "use_temporal_jittering", "=", "False", ",", "\n", "z_normalize", "=", "False", "\n", ")", ":", "\n", "# Temporal  jittering - get audio with 0.5 s of video clip", "\n", "    ", "if", "use_temporal_jittering", ":", "\n", "        ", "fr_sec", "=", "fr_sec", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.5", ",", "0.5", ")", "\n", "\n", "# Get to and from indices num seconds of audio", "\n", "", "fr_aud", "=", "int", "(", "np", ".", "round", "(", "fr_sec", "*", "sample_rate", ")", ")", "\n", "to_aud", "=", "int", "(", "np", ".", "round", "(", "fr_sec", "*", "sample_rate", ")", "+", "sample_rate", "*", "num_sec", ")", "\n", "\n", "# Check to ensure that we never get clip longer than wav", "\n", "if", "fr_aud", "+", "(", "to_aud", "-", "fr_aud", ")", ">", "len", "(", "wav", ")", ":", "\n", "        ", "fr_aud", "=", "len", "(", "wav", ")", "-", "sample_rate", "*", "num_sec", "\n", "to_aud", "=", "len", "(", "wav", ")", "\n", "\n", "# Get subset of wav", "\n", "", "wav", "=", "wav", "[", "fr_aud", ":", "to_aud", "]", "\n", "\n", "# Volume  jittering - scale volume by factor in range (0.9, 1.1)", "\n", "if", "use_volume_jittering", ":", "\n", "        ", "wav", "=", "wav", "*", "np", ".", "random", ".", "uniform", "(", "0.9", ",", "1.1", ")", "\n", "\n", "# Convert to log filterbank", "\n", "", "if", "aud_spec_type", "==", "1", ":", "\n", "        ", "spec", "=", "logfbank", "(", "\n", "wav", ",", "\n", "sample_rate", ",", "\n", "winlen", "=", "0.02", ",", "\n", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "40", ",", "\n", "nfft", "=", "1024", "\n", ")", "\n", "", "else", ":", "\n", "        ", "spec", "=", "logfbank", "(", "\n", "wav", ",", "\n", "sample_rate", ",", "\n", "winlen", "=", "0.02", ",", "\n", "winstep", "=", "0.01", ",", "#if num_sec==1 else 0.01,", "\n", "nfilt", "=", "257", ",", "\n", "nfft", "=", "1024", "\n", ")", "\n", "\n", "# Convert to 32-bit float and expand dim", "\n", "", "spec", "=", "spec", ".", "astype", "(", "'float32'", ")", "\n", "spec", "=", "spec", ".", "T", "\n", "spec", "=", "np", ".", "expand_dims", "(", "spec", ",", "axis", "=", "0", ")", "\n", "spec", "=", "torch", ".", "as_tensor", "(", "spec", ")", "\n", "\n", "if", "z_normalize", ":", "\n", "        ", "spec", "=", "(", "spec", "-", "1.93", ")", "/", "17.89", "\n", "\n", "", "return", "spec", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.audio_utils.load_audio": [[77, 112], ["ffmpeg.input().output().run", "numpy.frombuffer", "audio_utils.get_spec", "ffmpeg.input().output", "ffmpeg.input"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.audio_utils.get_spec"], ["", "def", "load_audio", "(", "\n", "vid_path", ",", "fr_sec", ",", "\n", "num_sec", "=", "1", ",", "\n", "sample_rate", "=", "48000", ",", "\n", "aug_audio", "=", "[", "]", ",", "\n", "aud_spec_type", "=", "1", ",", "\n", "use_volume_jittering", "=", "False", ",", "\n", "use_temporal_jittering", "=", "False", ",", "\n", "z_normalize", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# Load wav file @ sample_rate", "\n", "    ", "out", ",", "_", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "vid_path", ")", "\n", ".", "output", "(", "'-'", ",", "format", "=", "'s16le'", ",", "acodec", "=", "'pcm_s16le'", ",", "ac", "=", "1", ",", "ar", "=", "sample_rate", ")", "\n", ".", "run", "(", "quiet", "=", "True", ",", "cmd", "=", "\"/home/lriesch29/miniconda3/envs/lab_vid/bin/ffmpeg\"", ")", "\n", ")", "\n", "wav", "=", "(", "\n", "np", "\n", ".", "frombuffer", "(", "out", ",", "np", ".", "int16", ")", "\n", ")", "\n", "# Get spectogram", "\n", "spec", "=", "get_spec", "(", "\n", "wav", ",", "\n", "fr_sec", ",", "\n", "num_sec", "=", "num_sec", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "aug_audio", "=", "aug_audio", ",", "\n", "aud_spec_type", "=", "aud_spec_type", ",", "\n", "use_volume_jittering", "=", "use_volume_jittering", ",", "\n", "use_temporal_jittering", "=", "use_temporal_jittering", ",", "\n", "z_normalize", "=", "z_normalize", ",", "\n", ")", "\n", "return", "spec", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset.__init__": [[189, 330], ["list", "multiprocessing.Manager", "print", "AVideoDataset.AVideoDataset._construct_loader", "os.path.join", "sorted", "os.path.basename", "glob.glob", "range", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset._construct_loader"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ds_name", "=", "'kinetics'", ",", "\n", "root_dir", "=", "'/path/to/kinetics/train'", ",", "\n", "mode", "=", "'train'", ",", "\n", "num_frames", "=", "30", ",", "\n", "sample_rate", "=", "1", ",", "\n", "num_train_clips", "=", "1", ",", "\n", "train_crop_size", "=", "112", ",", "\n", "test_crop_size", "=", "112", ",", "\n", "num_spatial_crops", "=", "3", ",", "\n", "num_ensemble_views", "=", "10", ",", "\n", "path_to_data_dir", "=", "'datasets/data'", ",", "\n", "seed", "=", "None", ",", "\n", "num_data_samples", "=", "None", ",", "\n", "fold", "=", "1", ",", "\n", "colorjitter", "=", "False", ",", "\n", "use_grayscale", "=", "False", ",", "\n", "use_gaussian", "=", "False", ",", "\n", "dual_data", "=", "False", ",", "\n", "temp_jitter", "=", "True", ",", "\n", "center_crop", "=", "False", ",", "\n", "target_fps", "=", "30", ",", "\n", "decode_audio", "=", "True", ",", "\n", "aug_audio", "=", "[", "]", ",", "\n", "num_sec", "=", "1", ",", "\n", "aud_sample_rate", "=", "48000", ",", "\n", "aud_spec_type", "=", "1", ",", "\n", "use_volume_jittering", "=", "False", ",", "\n", "use_temporal_jittering", "=", "False", ",", "\n", "z_normalize", "=", "False", ",", "\n", "run", "=", "None", "\n", ")", ":", "\n", "# Only support train, val, and test mode.", "\n", "        ", "assert", "mode", "in", "[", "\n", "\"train\"", ",", "\n", "\"val\"", ",", "\n", "\"test\"", ",", "\n", "]", ",", "\"Split '{}' not supported for '{}'\"", ".", "format", "(", "mode", ",", "ds_name", ")", "\n", "\n", "# Set up dataset hyper-params", "\n", "if", "ds_name", "==", "'vggsound'", ":", "\n", "            ", "if", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "199177", "# 170752 is the old value. 199177 is all videos combined", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "14032", "\n", "", "", "elif", "ds_name", "==", "'kinetics'", ":", "\n", "            ", "if", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "230976", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "18968", "\n", "", "", "elif", "ds_name", "==", "'kinetics_sound'", ":", "\n", "            ", "if", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "22408", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "22408", "\n", "", "", "elif", "ds_name", "==", "'ave'", ":", "\n", "            ", "if", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "3328", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "3328", "\n", "", "", "elif", "ds_name", "==", "\"audioset_zsl\"", ":", "\n", "            ", "if", "mode", "==", "\"train\"", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "93865", "\n", "", "elif", "mode", "==", "\"val\"", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "31271", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_data_samples", "=", "31280", "\n", "", "", "elif", "ds_name", "==", "\"ucf\"", ":", "\n", "            ", "self", ".", "num_data_samples", "=", "13521", "\n", "", "elif", "ds_name", "==", "\"activity\"", ":", "\n", "            ", "self", ".", "num_data_samples", "=", "20694", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_data_samples", "=", "num_data_samples", "\n", "\n", "", "self", ".", "ds_name", "=", "ds_name", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "train_crop_size", "=", "train_crop_size", "\n", "self", ".", "test_crop_size", "=", "test_crop_size", "\n", "if", "train_crop_size", "in", "[", "112", ",", "128", "]", ":", "\n", "            ", "train_jitter_scles", "=", "(", "128", ",", "160", ")", "\n", "", "else", ":", "\n", "            ", "train_jitter_scles", "=", "(", "256", ",", "320", ")", "\n", "", "self", ".", "train_jitter_scles", "=", "train_jitter_scles", "\n", "self", ".", "num_ensemble_views", "=", "num_ensemble_views", "\n", "self", ".", "num_spatial_crops", "=", "num_spatial_crops", "\n", "self", ".", "num_train_clips", "=", "num_train_clips", "\n", "self", ".", "data_prefix", "=", "root_dir", "if", "ds_name", "in", "[", "'ucf101'", ",", "'hmdb51'", "]", "else", "os", ".", "path", ".", "join", "(", "root_dir", ",", "mode", ")", "\n", "self", ".", "path_to_data_dir", "=", "path_to_data_dir", "\n", "self", ".", "colorjitter", "=", "colorjitter", "\n", "self", ".", "use_grayscale", "=", "use_grayscale", "\n", "self", ".", "use_gaussian", "=", "use_gaussian", "\n", "self", ".", "temp_jitter", "=", "temp_jitter", "\n", "self", ".", "center_crop", "=", "center_crop", "\n", "self", ".", "target_fps", "=", "target_fps", "\n", "self", ".", "decode_audio", "=", "decode_audio", "\n", "self", ".", "aug_audio", "=", "aug_audio", "\n", "self", ".", "num_sec", "=", "num_sec", "\n", "self", ".", "aud_sample_rate", "=", "aud_sample_rate", "\n", "self", ".", "aud_spec_type", "=", "aud_spec_type", "\n", "self", ".", "use_volume_jittering", "=", "use_volume_jittering", "\n", "self", ".", "use_temporal_jittering", "=", "use_temporal_jittering", "\n", "self", ".", "z_normalize", "=", "z_normalize", "\n", "self", ".", "_video_meta", "=", "{", "}", "\n", "self", ".", "fold", "=", "fold", "# ucf101 and hmdb51", "\n", "self", ".", "dual_data", "=", "dual_data", "\n", "\n", "self", ".", "run", "=", "run", "\n", "\n", "# Get classes", "\n", "classes", "=", "list", "(", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_prefix", ",", "'*'", ")", ")", ")", ")", "\n", "classes", "=", "[", "os", ".", "path", ".", "basename", "(", "i", ")", "for", "i", "in", "classes", "]", "\n", "self", ".", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "\n", "self", ".", "sound_only_classes_kinetics", "=", "[", "\"blowing_nose\"", ",", "\"blowing_out_candles\"", ",", "\"bowling\"", ",", "\n", "\"chopping_wood\"", ",", "\"dribbling_basketball\"", ",", "\"laughing\"", ",", "\"mowing_lawn\"", ",", "\n", "\"playing_accordion\"", ",", "\"playing_bagpipes\"", ",", "\"playing_bass_guitar\"", ",", "\n", "\"playing_clarinet\"", ",", "\"playing_drums\"", ",", "\"playing_guitar\"", ",", "\"playing_harmonica\"", ",", "\n", "\"playing_keyboard\"", ",", "\"playing_organ\"", ",", "\"playing_piano\"", ",", "\"playing_saxophone\"", ",", "\n", "\"playing_trombone\"", ",", "\"playing_trumpet\"", ",", "\"playing_violin\"", ",", "\n", "\"playing_xylophone\"", ",", "\n", "\"ripping_paper\"", ",", "\"shoveling_snow\"", ",", "\"shuffling_cards\"", ",", "\"singing\"", ",", "\n", "\"stomping_grapes\"", ",", "\"strumming_guitar\"", ",", "\"tap_dancing\"", ",", "\"tapping_guitar\"", ",", "\n", "\"tapping_pen\"", ",", "\"tickling\"", "\n", "]", "\n", "# For training or validation mode, one single clip is sampled from every video. ", "\n", "# For testing, NUM_ENSEMBLE_VIEWS clips are sampled from every video. ", "\n", "# For every clip, NUM_SPATIAL_CROPS is cropped spatially from the frames.", "\n", "if", "self", ".", "mode", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "            ", "self", ".", "_num_clips", "=", "self", ".", "num_train_clips", "\n", "", "elif", "self", ".", "mode", "in", "[", "\"test\"", "]", ":", "\n", "# self._num_clips = (", "\n", "#     self.num_ensemble_views * self.num_spatial_crops", "\n", "# )", "\n", "            ", "self", ".", "_num_clips", "=", "self", ".", "num_train_clips", "\n", "\n", "", "self", ".", "manager", "=", "Manager", "(", ")", "\n", "print", "(", "f\"Constructing {self.ds_name} {self.mode}...\"", ")", "\n", "self", ".", "_construct_loader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset._construct_loader": [[331, 430], ["os.makedirs", "os.path.join", "print", "AVideoDataset.AVideoDataset.manager.list", "AVideoDataset.AVideoDataset.manager.list", "os.path.exists", "list", "open", "len", "int", "open", "enumerate", "len", "os.path.exists", "print", "print", "sorted", "open", "g.read().splitlines", "int", "f.read().splitlines", "range", "len", "AVideoDataset.filter_videos", "AVideoDataset.select_fold_ucf101", "glob.glob", "AVideoDataset.AVideoDataset._path_to_videos.append", "AVideoDataset.AVideoDataset._labels.append", "AVideoDataset.AVideoDataset._spatial_temporal_idx.append", "AVideoDataset.AVideoDataset._vid_indices.append", "open", "open", "pickle.dump", "AVideoDataset.select_fold_hmdb51", "os.path.join", "f.write", "g.read", "f.read", "os.path.join", "path.split", "int", "pickle.load", "len", "len", "len", "len", "item.split", "f.write"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.filter_videos", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.select_fold_ucf101", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.select_fold_hmdb51", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write"], ["", "def", "_construct_loader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Construct the video loader.\n        \"\"\"", "\n", "# Get list of paths", "\n", "os", ".", "makedirs", "(", "self", ".", "path_to_data_dir", ",", "exist_ok", "=", "True", ")", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "path_to_data_dir", ",", "f\"{self.ds_name}_{self.mode}.txt\"", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path_to_file", ")", ":", "\n", "            ", "files", "=", "list", "(", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_prefix", ",", "'*'", ",", "'*'", ")", ")", ")", ")", "\n", "with", "open", "(", "path_to_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "for", "item", "in", "files", ":", "\n", "                    ", "if", "self", ".", "ds_name", "==", "'kinetics_sound'", ":", "\n", "                        ", "class_name", "=", "item", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "if", "class_name", "in", "self", ".", "sound_only_classes_kinetics", ":", "\n", "                            ", "f", ".", "write", "(", "\"%s\\n\"", "%", "item", ")", "\n", "", "", "else", ":", "\n", "                        ", "f", ".", "write", "(", "\"%s\\n\"", "%", "item", ")", "\n", "\n", "# Get list of indices and labels", "\n", "", "", "", "", "self", ".", "_path_to_videos", "=", "[", "]", "\n", "self", ".", "_labels", "=", "[", "]", "\n", "self", ".", "_spatial_temporal_idx", "=", "[", "]", "\n", "self", ".", "_vid_indices", "=", "[", "]", "\n", "\n", "with", "open", "(", "path_to_file", ",", "\"r\"", ")", "as", "g", ":", "\n", "            ", "self", ".", "n_clips", "=", "len", "(", "g", ".", "read", "(", ")", ".", "splitlines", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "run", "!=", "-", "1", ":", "\n", "            ", "self", ".", "p_data", "=", "1.", "/", "20", "\n", "# offset = 10347", "\n", "self", ".", "start", "=", "int", "(", "self", ".", "run", "*", "self", ".", "n_clips", "*", "self", ".", "p_data", ")", "\n", "#self.end = int(self.run * self.n_clips * self.p_data + self.n_clips * self.p_data)", "\n", "self", ".", "end", "=", "self", ".", "start", "+", "int", "(", "self", ".", "n_clips", "*", "self", ".", "p_data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "start", "=", "0", "\n", "self", ".", "end", "=", "self", ".", "n_clips", "\n", "\n", "", "with", "open", "(", "path_to_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "clip_idx", ",", "path", "in", "enumerate", "(", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ")", ":", "\n", "                ", "for", "idx", "in", "range", "(", "self", ".", "_num_clips", ")", ":", "\n", "                    ", "self", ".", "_path_to_videos", ".", "append", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_prefix", ",", "path", ")", "\n", ")", "\n", "class_name", "=", "path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "label", "=", "self", ".", "class_to_idx", "[", "class_name", "]", "\n", "self", ".", "_labels", ".", "append", "(", "int", "(", "label", ")", ")", "\n", "self", ".", "_spatial_temporal_idx", ".", "append", "(", "idx", ")", "\n", "self", ".", "_vid_indices", ".", "append", "(", "clip_idx", ")", "\n", "self", ".", "_video_meta", "[", "clip_idx", "*", "self", ".", "_num_clips", "+", "idx", "]", "=", "{", "}", "\n", "", "", "", "assert", "(", "\n", "len", "(", "self", ".", "_path_to_videos", ")", ">", "0", "\n", ")", ",", "\"Failed to load {} from {}\"", ".", "format", "(", "\n", "self", ".", "ds_name", ",", "path_to_file", "\n", ")", "\n", "print", "(", "\n", "\"Constructing {} dataloader (size: {}) from {}\"", ".", "format", "(", "\n", "self", ".", "ds_name", ",", "len", "(", "self", ".", "_path_to_videos", ")", ",", "path_to_file", "\n", ")", "\n", ")", "\n", "\n", "# Create / Load valid indices (has audio)", "\n", "if", "self", ".", "ds_name", "in", "[", "'kinetics'", ",", "'vggsound'", ",", "'ave'", ",", "'kinetics_sound'", ",", "\"audioset_zsl\"", ",", "\"ucf\"", ",", "\"activity\"", "]", ":", "\n", "            ", "vid_valid_file", "=", "f'{self.path_to_data_dir}/{self.ds_name}_valid.pkl'", "\n", "if", "os", ".", "path", ".", "exists", "(", "vid_valid_file", ")", ":", "\n", "                ", "with", "open", "(", "vid_valid_file", ",", "'rb'", ")", "as", "handle", ":", "\n", "                    ", "self", ".", "valid_indices", "=", "pickle", ".", "load", "(", "handle", ")", "[", "self", ".", "start", ":", "self", ".", "end", "]", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "valid_indices", "=", "filter_videos", "(", "self", ".", "_path_to_videos", ")", "\n", "with", "open", "(", "vid_valid_file", ",", "'wb'", ")", "as", "handle", ":", "\n", "                    ", "pickle", ".", "dump", "(", "\n", "self", ".", "valid_indices", ",", "\n", "handle", ",", "\n", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", "\n", ")", "\n", "", "", "if", "self", ".", "num_data_samples", "is", "not", "None", ":", "\n", "                ", "self", ".", "valid_indices", "=", "self", ".", "valid_indices", "[", ":", "self", ".", "num_data_samples", "]", "\n", "", "print", "(", "f\"Total number of videos: {len(self._path_to_videos)}, Valid videos: {len(self.valid_indices)}\"", ",", "\n", "flush", "=", "True", ")", "\n", "", "else", ":", "# ucf101 and hmdb-51", "\n", "            ", "if", "self", ".", "ds_name", "==", "'ucf101'", ":", "\n", "                ", "train", "=", "True", "if", "self", ".", "mode", "==", "'train'", "else", "False", "\n", "annotation_path", "=", "'/datasets01_101/ucf101/112018/ucfTrainTestlist/'", "\n", "self", ".", "valid_indices", "=", "select_fold_ucf101", "(", "\n", "self", ".", "data_prefix", ",", "self", ".", "_path_to_videos", ",", "annotation_path", ",", "self", ".", "fold", ",", "train", ")", "\n", "", "elif", "self", ".", "ds_name", "==", "'hmdb51'", ":", "\n", "                ", "train", "=", "True", "if", "self", ".", "mode", "==", "'train'", "else", "False", "\n", "annotation_path", "=", "'/datasets01_101/hmdb51/112018/splits/'", "\n", "self", ".", "valid_indices", "=", "select_fold_hmdb51", "(", "\n", "self", ".", "_path_to_videos", ",", "annotation_path", ",", "self", ".", "fold", ",", "train", ")", "\n", "", "else", ":", "\n", "                ", "assert", "(", "f\"Dataset is not supported\"", ")", "\n", "", "print", "(", "f\"Total number of videos: {len(self._path_to_videos)}, Valid videos: {len(self.valid_indices)}\"", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "# Make lists a Manager objects", "\n", "", "self", ".", "_path_to_videos", "=", "self", ".", "manager", ".", "list", "(", "self", ".", "_path_to_videos", ")", "\n", "self", ".", "valid_indices", "=", "self", ".", "manager", ".", "list", "(", "self", ".", "valid_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset.__getitem__": [[431, 566], ["AVideoDataset.get_video_container", "range", "get_video_container.close", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "float", "clip_augmentation", "V.append", "A.append", "print", "print", "print", "numpy.random.choice", "print", "AVideoDataset.AVideoDataset.__getitem__", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "NotImplementedError", "int", "decode", "len", "len", "print", "print", "print", "numpy.random.choice", "print", "get_video_container.close", "AVideoDataset.AVideoDataset.__getitem__", "pathlib.Path", "pathlib.Path", "int", "int", "len"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.get_video_container", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.video_transforms.clip_augmentation", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset.__getitem__", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.decoder.decode", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "index_capped", "=", "index", "\n", "index", "=", "self", ".", "valid_indices", "[", "index_capped", "]", "\n", "if", "self", ".", "mode", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "# -1 indicates random sampling.", "\n", "            ", "temporal_sample_index", "=", "-", "1", "\n", "spatial_sample_index", "=", "-", "1", "\n", "min_scale", "=", "self", ".", "train_jitter_scles", "[", "0", "]", "\n", "max_scale", "=", "self", ".", "train_jitter_scles", "[", "1", "]", "\n", "crop_size", "=", "self", ".", "train_crop_size", "\n", "if", "self", ".", "center_crop", ":", "\n", "                ", "spatial_sample_index", "=", "1", "\n", "min_scale", "=", "self", ".", "train_crop_size", "\n", "max_scale", "=", "self", ".", "train_crop_size", "\n", "crop_size", "=", "self", ".", "train_crop_size", "\n", "", "", "elif", "self", ".", "mode", "in", "[", "\"test\"", "]", ":", "\n", "            ", "temporal_sample_index", "=", "(", "\n", "self", ".", "_spatial_temporal_idx", "[", "index", "]", "//", "self", ".", "num_spatial_crops", "\n", ")", "\n", "# spatial_sample_index is in [0, 1, 2]. Corresponding to left,", "\n", "# center, or right if width is larger than height, and top, middle,", "\n", "# or bottom if height is larger than width.", "\n", "spatial_sample_index", "=", "(", "\n", "self", ".", "_spatial_temporal_idx", "[", "index", "]", "%", "self", ".", "num_spatial_crops", "\n", ")", "\n", "min_scale", ",", "max_scale", ",", "crop_size", "=", "[", "self", ".", "test_crop_size", "]", "*", "3", "\n", "# The testing is deterministic and no jitter should be performed.", "\n", "# min_scale, max_scale, and crop_size are expect to be the same.", "\n", "assert", "len", "(", "{", "min_scale", ",", "max_scale", ",", "crop_size", "}", ")", "==", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Does not support {} mode\"", ".", "format", "(", "self", ".", "mode", ")", "\n", ")", "\n", "\n", "", "video_container", "=", "get_video_container", "(", "\n", "self", ".", "_path_to_videos", "[", "index", "]", ",", "\n", "ENABLE_MULTI_THREAD_DECODE", ",", "\n", "DECODING_BACKEND", ",", "\n", ")", "\n", "# Get number of clips", "\n", "if", "self", ".", "mode", "in", "[", "\"train\"", ",", "\"val\"", "]", "and", "self", ".", "dual_data", ":", "\n", "            ", "num_clips", "=", "2", "\n", "", "else", ":", "\n", "            ", "fps", "=", "float", "(", "video_container", ".", "streams", ".", "video", "[", "0", "]", ".", "average_rate", ")", "\n", "frames_length", "=", "video_container", ".", "streams", ".", "video", "[", "0", "]", ".", "frames", "\n", "num_clips", "=", "int", "(", "frames_length", "/", "fps", ")", "-", "1", "\n", "\n", "# num_clips = 9 # old: 1", "\n", "", "V", "=", "[", "]", "\n", "A", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_clips", ")", ":", "\n", "# Try to decode and sample a clip from a video.", "\n", "            ", "\"\"\"\n            video_container = get_video_container(\n                self._path_to_videos[index],\n                ENABLE_MULTI_THREAD_DECODE,\n                DECODING_BACKEND,\n            )\n            \"\"\"", "\n", "\n", "# Decode video. Meta info is used to perform selective decoding.", "\n", "try", ":", "\n", "                ", "frames", ",", "audio", "=", "decode", "(", "# --num_sec_aud 10 --aud_sample_rate 44100", "\n", "self", ".", "_path_to_videos", "[", "index", "]", ",", "\n", "video_container", ",", "\n", "self", ".", "sample_rate", ",", "\n", "self", ".", "num_frames", ",", "\n", "temporal_sample_index", "if", "self", ".", "temp_jitter", "else", "i", "*", "100", ",", "# old: 500", "\n", "self", ".", "num_ensemble_views", "if", "self", ".", "temp_jitter", "else", "(", "(", "num_clips", "//", "10", ")", "+", "1", ")", "*", "1000", ",", "# old: 1000", "\n", "video_meta", "=", "self", ".", "_video_meta", "[", "index", "]", ",", "\n", "target_fps", "=", "int", "(", "self", ".", "target_fps", ")", ",", "\n", "backend", "=", "DECODING_BACKEND", ",", "\n", "max_spatial_scale", "=", "max_scale", ",", "\n", "decode_audio", "=", "self", ".", "decode_audio", ",", "\n", "aug_audio", "=", "self", ".", "aug_audio", ",", "\n", "num_sec", "=", "int", "(", "self", ".", "num_sec", ")", ",", "\n", "aud_sample_rate", "=", "self", ".", "aud_sample_rate", ",", "\n", "aud_spec_type", "=", "self", ".", "aud_spec_type", ",", "\n", "use_volume_jittering", "=", "self", ".", "use_volume_jittering", ",", "\n", "use_temporal_jittering", "=", "self", ".", "use_temporal_jittering", ",", "\n", "z_normalize", "=", "self", ".", "z_normalize", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "e", ")", "\n", "print", "(", "f\"Index: {index}.\"", ")", "\n", "print", "(", "f\"Path: {self._path_to_videos[index]}\"", ")", "\n", "new_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ")", ")", "\n", "print", "(", "f\"Trying new index: {new_idx}\"", ")", "\n", "video_container", ".", "close", "(", ")", "\n", "return", "self", ".", "__getitem__", "(", "new_idx", ")", "\n", "#continue", "\n", "\n", "# Perform data augmentation on video clip.", "\n", "", "frames", "=", "clip_augmentation", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "spatial_sample_index", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", "crop_size", "=", "crop_size", ",", "\n", "colorjitter", "=", "self", ".", "colorjitter", ",", "\n", "use_grayscale", "=", "self", ".", "use_grayscale", ",", "\n", "use_gaussian", "=", "self", ".", "use_gaussian", ",", "\n", ")", "\n", "V", ".", "append", "(", "frames", ")", "\n", "A", ".", "append", "(", "audio", ")", "\n", "\n", "", "video_container", ".", "close", "(", ")", "\n", "if", "V", "==", "[", "]", "or", "A", "==", "[", "]", ":", "\n", "            ", "print", "(", "f\"Can not stack empty frames or audio!\\nV:{V}\\nA:{A}\"", ")", "\n", "print", "(", "f\"Index: {index}.\"", ")", "\n", "print", "(", "f\"Path: {self._path_to_videos[index]}\"", ")", "\n", "new_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ")", ")", "\n", "print", "(", "f\"Trying new index: {new_idx}\"", ")", "# video_container.close()", "\n", "return", "self", ".", "__getitem__", "(", "new_idx", ")", "\n", "# Stack video frames", "\n", "# frames = torch.cat(V, dim=0) # OLD", "\n", "# frames = torch.cat([v.unsqueeze(dim=0) for v in V], dim=0).mean(dim=0)", "\n", "", "frames", "=", "torch", ".", "stack", "(", "V", ",", "dim", "=", "0", ")", "\n", "\n", "# Get labels and indices", "\n", "label", "=", "self", ".", "_labels", "[", "index", "]", "\n", "vid_idx", "=", "self", ".", "_vid_indices", "[", "index", "]", "\n", "idx", "=", "index", "\n", "\n", "# return results", "\n", "if", "self", ".", "decode_audio", ":", "\n", "# audio = torch.cat(A, dim=0) # OLD", "\n", "# audio = torch.cat([a.unsqueeze(dim=0) for a in A], dim=0).mean(dim=0)", "\n", "            ", "audio", "=", "torch", ".", "stack", "(", "A", ",", "dim", "=", "0", ")", "\n", "# if audio.shape[-1] != 999:", "\n", "#     print(\"OH NO\")", "\n", "return", "frames", ",", "audio", ",", "label", ",", "index_capped", ",", "vid_idx", ",", "Path", "(", "self", ".", "_path_to_videos", "[", "vid_idx", "]", ")", ".", "stem", "\n", "", "else", ":", "\n", "            ", "return", "frames", ",", "label", ",", "index_capped", ",", "vid_idx", ",", "Path", "(", "self", ".", "_path_to_videos", "[", "vid_idx", "]", ")", ".", "stem", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.AVideoDataset.__len__": [[567, 573], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            (int): the number of videos in the dataset.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "valid_indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.select_fold_hmdb51": [[40, 60], ["print", "glob.glob", "set", "os.path.join", "few_shot_setup", "print", "open", "fid.readlines", "set.extend", "x.strip().split", "range", "range", "len", "os.path.basename", "len", "len", "os.path.basename", "x.strip", "int"], "function", ["None"], ["def", "select_fold_hmdb51", "(", "video_list", ",", "annotation_path", ",", "fold", ",", "train", ",", "num_shots", "=", "-", "1", ")", ":", "\n", "    ", "print", "(", "f\"Getting HMDB51 dataset. Train Mode: {train}, fold: {fold}\"", ",", "flush", "=", "True", ")", "\n", "target_tag", "=", "1", "if", "train", "else", "2", "\n", "name", "=", "\"*test_split{}.txt\"", ".", "format", "(", "fold", ")", "\n", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "annotation_path", ",", "name", ")", ")", "\n", "selected_files", "=", "[", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "with", "open", "(", "f", ",", "\"r\"", ")", "as", "fid", ":", "\n", "            ", "data", "=", "fid", ".", "readlines", "(", ")", "\n", "data", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "x", "in", "data", "]", "\n", "data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "data", "if", "int", "(", "x", "[", "1", "]", ")", "==", "target_tag", "]", "\n", "selected_files", ".", "extend", "(", "data", ")", "\n", "", "", "selected_files", "=", "set", "(", "selected_files", ")", "\n", "if", "num_shots", "!=", "-", "1", "and", "num_shots", ">", "0", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "video_list", ")", ")", "if", "os", ".", "path", ".", "basename", "(", "video_list", "[", "i", "]", ")", "in", "selected_files", "]", "\n", "indices", "=", "few_shot_setup", "(", "self", ".", "samples", ",", "indices", ",", "num_shots", "=", "self", ".", "num_shots", ")", "\n", "print", "(", "f\"Number of videos: {len(indices)}\"", ")", "\n", "", "else", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "video_list", ")", ")", "if", "os", ".", "path", ".", "basename", "(", "video_list", "[", "i", "]", ")", "in", "selected_files", "]", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.select_fold_ucf101": [[62, 81], ["os.path.join", "print", "set", "open", "fid.readlines", "set.extend", "few_shot_setup", "print", "x.strip().split", "range", "range", "x.strip", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "select_fold_ucf101", "(", "root", ",", "video_list", ",", "annotation_path", ",", "fold", ",", "train", ",", "num_shots", "=", "-", "1", ")", ":", "\n", "    ", "name", "=", "\"train\"", "if", "train", "else", "\"test\"", "\n", "name", "=", "\"{}list{:02d}.txt\"", ".", "format", "(", "name", ",", "fold", ")", "\n", "f", "=", "os", ".", "path", ".", "join", "(", "annotation_path", ",", "name", ")", "\n", "print", "(", "f", ")", "\n", "selected_files", "=", "[", "]", "\n", "with", "open", "(", "f", ",", "\"r\"", ")", "as", "fid", ":", "\n", "        ", "data", "=", "fid", ".", "readlines", "(", ")", "\n", "data", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "x", "in", "data", "]", "\n", "data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "data", "]", "\n", "selected_files", ".", "extend", "(", "data", ")", "\n", "", "selected_files", "=", "set", "(", "selected_files", ")", "\n", "if", "num_shots", "!=", "-", "1", "and", "num_shots", ">", "0", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "video_list", ")", ")", "if", "video_list", "[", "i", "]", "[", "len", "(", "root", ")", ":", "]", "in", "selected_files", "]", "\n", "indices", "=", "few_shot_setup", "(", "self", ".", "samples", ",", "indices", ",", "num_shots", "=", "self", ".", "num_shots", ")", "\n", "print", "(", "f\"Number of videos: {len(indices)}\"", ")", "\n", "", "else", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "video_list", ")", ")", "if", "video_list", "[", "i", "]", "[", "len", "(", "root", ")", ":", "]", "in", "selected_files", "]", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.valid_video": [[113, 138], ["ffmpeg.probe", "next", "next", "print", "print", "print", "float", "float", "float"], "function", ["None"], ["", "def", "valid_video", "(", "vid_idx", ",", "vid_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "probe", "=", "ffmpeg", ".", "probe", "(", "vid_path", ")", "\n", "video_stream", "=", "next", "(", "(", "\n", "stream", "for", "stream", "in", "probe", "[", "'streams'", "]", "if", "stream", "[", "'codec_type'", "]", "==", "'video'", ")", ",", "\n", "None", "\n", ")", "\n", "audio_stream", "=", "next", "(", "(", "\n", "stream", "for", "stream", "in", "probe", "[", "'streams'", "]", "if", "stream", "[", "'codec_type'", "]", "==", "'audio'", ")", ",", "\n", "None", "\n", ")", "\n", "if", "audio_stream", "and", "video_stream", "and", "float", "(", "video_stream", "[", "'duration'", "]", ")", ">", "1.1", "and", "float", "(", "\n", "audio_stream", "[", "'duration'", "]", ")", ">", "1.1", ":", "\n", "# if audio_stream and video_stream and float(video_stream['duration']) > 9.1 and float(audio_stream['duration']) > 9.1:", "\n", "            ", "print", "(", "f\"{vid_idx}: True\"", ",", "end", "=", "'\\r'", ",", "flush", "=", "True", ")", "\n", "return", "True", "\n", "", "else", ":", "\n", "            ", "print", "(", "\n", "f\"{vid_idx}: False (duration short/ no audio). {vid_path}. Duration_A: {float(audio_stream['duration'])}\"", ",", "\n", "flush", "=", "True", ")", "\n", "return", "False", "\n", "", "", "except", "Exception", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "        ", "print", "(", "f\"{vid_idx}: False. {vid_path}\"", ",", "flush", "=", "True", ")", "# 92634", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.filter_videos": [[140, 148], ["joblib.Parallel", "enumerate", "joblib.delayed", "range", "len"], "function", ["None"], ["", "", "def", "filter_videos", "(", "vid_paths", ")", ":", "\n", "    ", "all_indices", "=", "Parallel", "(", "n_jobs", "=", "30", ")", "(", "\n", "delayed", "(", "valid_video", ")", "(", "vid_idx", ",", "vid_paths", "[", "vid_idx", "]", ")", "for", "vid_idx", "in", "range", "(", "len", "(", "vid_paths", ")", ")", ")", "\n", "# all_indices = []", "\n", "# for vid_idx in range(len(vid_paths)):", "\n", "#    all_indices.append(valid_video(vid_idx, vid_paths[vid_idx]))", "\n", "valid_indices", "=", "[", "i", "for", "i", ",", "val", "in", "enumerate", "(", "all_indices", ")", "if", "val", "]", "\n", "return", "valid_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.datasets.AVideoDataset.get_video_container": [[150, 176], ["open", "fp.read", "NotImplementedError", "av.open", "av.open"], "function", ["None"], ["", "def", "get_video_container", "(", "path_to_vid", ",", "multi_thread_decode", "=", "False", ",", "backend", "=", "\"pyav\"", ")", ":", "\n", "    ", "\"\"\"\n    Given the path to the video, return the pyav video container.\n    Args:\n        path_to_vid (str): path to the video.\n        multi_thread_decode (bool): if True, perform multi-thread decoding.\n        backend (str): decoder backend, options include `pyav` and\n            `torchvision`, default is `pyav`.\n    Returns:\n        container (container): video container.\n    \"\"\"", "\n", "if", "backend", "==", "\"torchvision\"", ":", "\n", "        ", "with", "open", "(", "path_to_vid", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "container", "=", "fp", ".", "read", "(", ")", "\n", "", "return", "container", "\n", "", "elif", "backend", "==", "\"pyav\"", ":", "\n", "        ", "try", ":", "\n", "            ", "container", "=", "av", ".", "open", "(", "path_to_vid", ")", "\n", "", "except", ":", "\n", "            ", "container", "=", "av", ".", "open", "(", "path_to_vid", ",", "metadata_errors", "=", "\"ignore\"", ")", "\n", "", "if", "multi_thread_decode", ":", "\n", "# Enable multiple threads for decoding.", "\n", "            ", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "thread_type", "=", "\"AUTO\"", "\n", "", "return", "container", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Unknown backend {}\"", ".", "format", "(", "backend", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.get_clusters_kinetics.get_clusters": [[14, 53], ["os.path.exists", "torch.load", "range", "open", "f.readlines", "final_kinetics_paths.append", "print", "full_list.append", "open", "pickle.dump", "open", "pickle.load", "cluster_list.append", "str", "[].split", "[].split", "vid_name.split", "vid_name.split", "int", "int", "vid_name.split", "path.split", "path.split"], "function", ["None"], ["def", "get_clusters", "(", "ckpt_path", "=", "''", ",", "num_clusters", "=", "400", ")", ":", "\n", "    ", "result_dict", "=", "{", "}", "\n", "\n", "kinetic_train_path", "=", "'datasets/data/kinetics_train.txt'", "\n", "with", "open", "(", "kinetic_train_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "kinetics_paths", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "vid_valid_file", "=", "f'datasets/data/kinetics_valid.pkl'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "vid_valid_file", ")", ":", "\n", "        ", "with", "open", "(", "vid_valid_file", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "valid_indices", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "", "final_kinetics_paths", "=", "[", "]", "\n", "for", "ix", "in", "valid_indices", ":", "\n", "        ", "final_kinetics_paths", ".", "append", "(", "kinetics_paths", "[", "ix", "]", ")", "\n", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ")", "\n", "self_labels", "=", "ckpt", "[", "'selflabels'", "]", "[", ":", ",", "0", "]", "\n", "epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "full_list", "=", "[", "]", "\n", "for", "cluster_i", "in", "range", "(", "num_clusters", ")", ":", "\n", "        ", "print", "(", "f\"Epoch: {epoch}, cluster: {cluster_i}\"", ")", "\n", "cluster_indices", "=", "(", "self_labels", "==", "cluster_i", ")", ".", "nonzero", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cluster_list", "=", "[", "]", "\n", "for", "index", "in", "cluster_indices", "[", ":", ",", "0", "]", ":", "\n", "            ", "path", "=", "final_kinetics_paths", "[", "index", "]", "\n", "vid_name", "=", "path", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "gt_class", "=", "path", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "youtube_id", "=", "'_'", ".", "join", "(", "vid_name", ".", "split", "(", "'_'", ")", "[", "0", ":", "-", "2", "]", ")", "\n", "start_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", "\n", "end_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "res_tuple", "=", "(", "youtube_id", ",", "int", "(", "start_time", ")", ",", "int", "(", "end_time", ")", ",", "gt_class", ")", "\n", "cluster_list", ".", "append", "(", "res_tuple", ")", "\n", "", "full_list", ".", "append", "(", "cluster_list", ")", "\n", "", "result_dict", "[", "str", "(", "epoch", ")", "]", "=", "full_list", "\n", "\n", "with", "open", "(", "f'cluster_vis/selavi_kinetics.pkl'", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "result_dict", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.get_clusters_audioset_zsl.get_clusters": [[14, 53], ["os.path.exists", "torch.load", "range", "open", "f.readlines", "final_aszsl_paths.append", "print", "full_list.append", "open", "pickle.dump", "open", "pickle.load", "os.path.basename().strip().strip", "cluster_list.append", "str", "path.split", "os.path.basename().strip().strip.split", "os.path.basename().strip().strip.split", "int", "int", "os.path.basename().strip", "os.path.basename().strip().strip.split", "os.path.basename"], "function", ["None"], ["def", "get_clusters", "(", "ckpt_path", "=", "''", ",", "num_clusters", "=", "256", ")", ":", "\n", "    ", "result_dict", "=", "{", "}", "\n", "\n", "aszsl_train_path", "=", "'datasets/data/audioset_zsl_train.txt'", "\n", "with", "open", "(", "aszsl_train_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "vggsound_paths", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "vid_valid_file", "=", "f'datasets/data/audioset_zsl_valid.pkl'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "vid_valid_file", ")", ":", "\n", "        ", "with", "open", "(", "vid_valid_file", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "valid_indices", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "", "final_aszsl_paths", "=", "[", "]", "\n", "for", "ix", "in", "valid_indices", ":", "\n", "        ", "final_aszsl_paths", ".", "append", "(", "vggsound_paths", "[", "ix", "]", ")", "\n", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ")", "\n", "epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "self_labels", "=", "ckpt", "[", "'selflabels'", "]", "[", ":", ",", "0", "]", "\n", "full_list", "=", "[", "]", "\n", "for", "cluster_i", "in", "range", "(", "num_clusters", ")", ":", "\n", "        ", "print", "(", "f\"Epoch: {epoch}, cluster: {cluster_i}\"", ")", "\n", "cluster_indices", "=", "(", "self_labels", "==", "cluster_i", ")", ".", "nonzero", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cluster_list", "=", "[", "]", "\n", "for", "index", "in", "cluster_indices", "[", ":", ",", "0", "]", ":", "\n", "            ", "path", "=", "final_aszsl_paths", "[", "index", "]", "\n", "vid_name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'.mp4'", ")", "\n", "gt_class", "=", "path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "youtube_id", "=", "'_'", ".", "join", "(", "vid_name", ".", "split", "(", "'_'", ")", "[", "0", ":", "-", "2", "]", ")", "\n", "start_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", "\n", "end_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "res_tuple", "=", "(", "youtube_id", ",", "int", "(", "start_time", ")", ",", "int", "(", "end_time", ")", ",", "gt_class", ")", "\n", "cluster_list", ".", "append", "(", "res_tuple", ")", "\n", "", "full_list", ".", "append", "(", "cluster_list", ")", "\n", "", "result_dict", "[", "str", "(", "epoch", ")", "]", "=", "full_list", "\n", "\n", "with", "open", "(", "f'cluster_vis/selavi_aszsl_sounds.pkl'", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "result_dict", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data": [[14, 41], ["epochs.sort", "range", "print", "open", "pickle.load", "int", "len", "random.shuffle", "list", "set", "pickle.load.keys", "open", "json.load", "json.load.keys", "json.load.pop", "json.load.values"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.sampler.CircularList.shuffle"], ["def", "get_data", "(", "filename", ",", "meta_filename", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "handle", ":", "\n", "        ", "clusters", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "epochs", "=", "[", "int", "(", "epoch", ")", "for", "epoch", "in", "clusters", ".", "keys", "(", ")", "]", "\n", "epochs", ".", "sort", "(", ")", "\n", "\n", "last_epoch", "=", "clusters", "[", "f'{epochs[-1]}'", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "last_epoch", ")", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "last_epoch", "[", "i", "]", ")", "\n", "\n", "", "if", "meta_filename", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "\"meta-classes.json\"", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "meta", "=", "json", ".", "load", "(", "handle", ")", "\n", "", "keys", "=", "list", "(", "meta", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "keys", ":", "\n", "            ", "new_key", "=", "(", "''", "+", "k", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "meta", "[", "new_key", "]", "=", "meta", ".", "pop", "(", "k", ")", "\n", "", "", "else", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "for", "c", "in", "last_epoch", ":", "\n", "            ", "for", "v", "in", "c", ":", "\n", "                ", "meta", "[", "v", "[", "3", "]", "]", "=", "\"people\"", "\n", "", "", "", "print", "(", "set", "(", "meta", ".", "values", "(", ")", ")", ")", "\n", "data", "=", "{", "\"clusters\"", ":", "last_epoch", ",", "\"metaclasses\"", ":", "meta", "}", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.main": [[43, 53], ["preprocess.get_data", "preprocess.get_data", "open", "handle.write", "handle.write", "json.dumps", "json.dumps"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.preprocess.get_data", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.src.util_fewshot.Logger.write"], ["", "def", "main", "(", "vgg_sound_path", "=", "None", ",", "kinetics_path", "=", "None", ")", ":", "\n", "    ", "vgg_sound", "=", "None", "\n", "kinetics", "=", "None", "\n", "vgg_sound", "=", "get_data", "(", "vgg_sound_path", ",", "'meta-classes.json'", ")", "\n", "kinetics", "=", "get_data", "(", "kinetics_path", ",", "None", ")", "\n", "assert", "(", "vgg_sound", "is", "not", "None", "and", "kinetics", "is", "not", "None", ")", "\n", "\n", "with", "open", "(", "'./data/clusters.js'", ",", "'w'", ")", "as", "handle", ":", "\n", "        ", "handle", ".", "write", "(", "\"function getVGGSoundClusterData() { return \"", "+", "json", ".", "dumps", "(", "vgg_sound", ")", "+", "\"; }\\n\"", ")", "\n", "handle", ".", "write", "(", "\"function getKineticsClusterData() { return \"", "+", "json", ".", "dumps", "(", "kinetics", ")", "+", "\"; }\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.cluster_vis.get_clusters_vggsounds.get_clusters": [[14, 53], ["os.path.exists", "torch.load", "range", "open", "f.readlines", "final_vggsounds_paths.append", "print", "full_list.append", "open", "pickle.dump", "open", "pickle.load", "os.path.basename().strip().strip", "cluster_list.append", "str", "path.split", "os.path.basename().strip().strip.split", "os.path.basename().strip().strip.split", "int", "int", "os.path.basename().strip", "os.path.basename().strip().strip.split", "os.path.basename"], "function", ["None"], ["def", "get_clusters", "(", "ckpt_path", "=", "''", ",", "num_clusters", "=", "256", ")", ":", "\n", "    ", "result_dict", "=", "{", "}", "\n", "\n", "vggsound_train_path", "=", "'datasets/data/vggsound_train.txt'", "\n", "with", "open", "(", "vggsound_train_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "vggsound_paths", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "vid_valid_file", "=", "f'datasets/data/vggsound_valid.pkl'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "vid_valid_file", ")", ":", "\n", "        ", "with", "open", "(", "vid_valid_file", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "valid_indices", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "", "final_vggsounds_paths", "=", "[", "]", "\n", "for", "ix", "in", "valid_indices", ":", "\n", "        ", "final_vggsounds_paths", ".", "append", "(", "vggsound_paths", "[", "ix", "]", ")", "\n", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ")", "\n", "epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "self_labels", "=", "ckpt", "[", "'selflabels'", "]", "[", ":", ",", "0", "]", "\n", "full_list", "=", "[", "]", "\n", "for", "cluster_i", "in", "range", "(", "num_clusters", ")", ":", "\n", "        ", "print", "(", "f\"Epoch: {epoch}, cluster: {cluster_i}\"", ")", "\n", "cluster_indices", "=", "(", "self_labels", "==", "cluster_i", ")", ".", "nonzero", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cluster_list", "=", "[", "]", "\n", "for", "index", "in", "cluster_indices", "[", ":", ",", "0", "]", ":", "\n", "            ", "path", "=", "final_vggsounds_paths", "[", "index", "]", "\n", "vid_name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'.mp4'", ")", "\n", "gt_class", "=", "path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "youtube_id", "=", "'_'", ".", "join", "(", "vid_name", ".", "split", "(", "'_'", ")", "[", "0", ":", "-", "2", "]", ")", "\n", "start_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", "\n", "end_time", "=", "vid_name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "res_tuple", "=", "(", "youtube_id", ",", "int", "(", "start_time", ")", ",", "int", "(", "end_time", ")", ",", "gt_class", ")", "\n", "cluster_list", ".", "append", "(", "res_tuple", ")", "\n", "", "full_list", ".", "append", "(", "cluster_list", ")", "\n", "", "result_dict", "[", "str", "(", "epoch", ")", "]", "=", "full_list", "\n", "\n", "with", "open", "(", "f'cluster_vis/selavi_vgg_sounds.pkl'", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "result_dict", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.vggish.VGGish.__init__": [[14, 44], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Conv2d", "torch.ReLU", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Conv2d", "torch.ReLU", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.ReLU", "torch.Linear", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "VGGish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "24", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.vggish.VGGish.forward": [[46, 51], ["vggish.VGGish.features().permute().contiguous", "vggish.VGGish.view", "vggish.VGGish.fc", "vggish.VGGish.size", "vggish.VGGish.features().permute", "vggish.VGGish.features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.vggish.main": [[53, 55], ["None"], "function", ["None"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.xeno_canto_to_seconds.main": [[11, 90], ["vggish.VGGish", "pytorch_model.to.load_state_dict", "pytorch_model.to.to", "pytorch_model.to.eval", "pathlib.Path", "pathlib.Path", "tqdm.tqdm", "torch.load", "pathlib.Path.glob", "open", "json.dump", "soundfile.read", "int", "range", "str", "audioset.vggish_input.waveform_to_examples", "str", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "numpy.save", "print", "exception_dict.append", "numpy.ceil", "file.relative_to", "os.makedirs", "file.relative_to", "str().split", "pathlib.Path", "str", "str", "file.relative_to", "str", "len", "str"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.waveform_to_examples"], ["def", "main", "(", ")", ":", "\n", "# Initialize the PyTorch model.", "\n", "\n", "    ", "exception_dict", "=", "[", "]", "\n", "device", "=", "'cuda:0'", "\n", "pytorch_model", "=", "VGGish", "(", ")", "\n", "pytorch_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'pytorch_vggish.pth'", ")", ")", "\n", "pytorch_model", "=", "pytorch_model", ".", "to", "(", "device", ")", "\n", "pytorch_model", ".", "eval", "(", ")", "\n", "path", "=", "Path", "(", "\"/home/omercea19/akata-shared/omercea19/full_ebird_download\"", ")", "\n", "\n", "root_saved", "=", "Path", "(", "\"/home/omercea19/akata-shared/omercea19/seconds_waveform_full_ebird_5seconds\"", ")", "\n", "\n", "dict", "=", "{", "}", "\n", "for", "file", "in", "tqdm", "(", "path", ".", "glob", "(", "'**/*.wav'", ")", ")", ":", "\n", "        ", "try", ":", "\n", "\n", "            ", "data", ",", "sr", "=", "sf", ".", "read", "(", "str", "(", "file", ")", ",", "dtype", "=", "'int16'", ")", "\n", "assert", "data", ".", "dtype", "==", "np", ".", "int16", ",", "'Bad sample type: %r'", "%", "data", ".", "dtype", "\n", "# split", "\n", "split", "=", "[", "]", "\n", "noSections", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "data", ")", "/", "sr", ")", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "noSections", ")", ":", "\n", "# get 1 second", "\n", "                ", "temp", "=", "data", "[", "i", "*", "sr", ":", "i", "*", "sr", "+", "sr", "]", "# this is for mono audio", "\n", "# temp = data[i*sr:i*sr + sr, :] # this is for stereo audio; uncomment and comment line above", "\n", "# add to list", "\n", "temp", "=", "temp", "/", "32768.0", "\n", "temp", "=", "vggish_input", ".", "waveform_to_examples", "(", "temp", ",", "sr", ")", "\n", "new_path", "=", "str", "(", "file", ".", "relative_to", "(", "path", ")", ")", "\n", "new_directory", "=", "Path", ".", "joinpath", "(", "root_saved", ",", "file", ".", "relative_to", "(", "path", ")", ".", "parent", ")", "\n", "try", ":", "\n", "                    ", "os", ".", "makedirs", "(", "new_directory", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "", "new_path", "=", "Path", ".", "joinpath", "(", "root_saved", ",", "file", ".", "relative_to", "(", "path", ")", ")", "\n", "name", "=", "str", "(", "new_path", ".", "name", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "name", "=", "name", "+", "\"sec\"", "+", "str", "(", "i", ")", "+", "\".npy\"", "\n", "new_path", "=", "Path", ".", "joinpath", "(", "new_path", ".", "parent", ",", "Path", "(", "name", ")", ")", "\n", "np", ".", "save", "(", "new_path", ",", "temp", ")", "\n", "# zz=np.load(new_path)", "\n", "# print(zz)", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "\"Exception\"", ",", "str", "(", "file", ")", ")", "\n", "exception_dict", ".", "append", "(", "str", "(", "file", ")", ")", "\n", "\n", "", "", "with", "open", "(", "\"./exception.json\"", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "json", ".", "dump", "(", "exception_dict", ",", "g", ")", "\n", "\n", "", "''' \n\n    THIS IS THE VARIANT WITH THE BATCHES, WHICH WILL MOST LIKELY WE USED DURING THE TRAINING/INFERENCE\n\n    # Generate a sample input (as in the AudioSet repo smoke test).\n    x=['../altele/5bS607UKT2U.wav','../altele/5bS607UKT2U.wav']\n    input_batch=[]\n    for i in x:\n        input_batch.append(torch.from_numpy(vggish_input.wavfile_to_examples(i)))\n\n    input_batch=torch.stack(input_batch)\n\n    # Produce a batch of log mel spectrogram examples.\n    input_batch = input_batch.float().to(device)\n    input_batch=input_batch.unsqueeze(dim=2)\n    input_batch=input_batch.view(-1,input_batch.shape[2],input_batch.shape[3],input_batch.shape[4])\n\n    # Run the PyTorch model.\n    pytorch_output = pytorch_model(input_batch)\n    pytorch_output = pytorch_output.detach().cpu().numpy()\n    print('Input Shape:', tuple(input_batch.shape))\n    print('Output Shape:', tuple(pytorch_output.shape))\n\n    # Post-processing.\n    post_processor = vggish_postprocess.Postprocessor('vggish_pca_params.npz')\n    postprocessed_output = post_processor.postprocess(pytorch_output)\n    postprocessed_output=np.reshape(postprocessed_output,(len(x),-1,postprocessed_output.shape[1]))\n    print(\"final\")\n    '''", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.convert_to_pytorch.main": [[15, 125], ["tensorflow.Graph().as_default", "tensorflow.Session", "audioset.vggish_slim.define_vggish_slim", "audioset.vggish_slim.load_vggish_slim_checkpoint", "tensorflow.all_variables", "sess.run", "dict", "vggish.VGGish", "pytorch_model.to.features.state_dict", "pytorch_model.to.fc.state_dict", "zip", "zip", "pytorch_model.to.features.load_state_dict", "pytorch_model.to.fc.load_state_dict", "numpy.linspace", "numpy.sin", "audioset.vggish_input.waveform_to_examples", "sess.graph.get_tensor_by_name", "sess.graph.get_tensor_by_name", "sess.run", "pytorch_model.to.to", "pytorch_model.to.", "pytorch_output.detach().numpy.detach().numpy", "print", "numpy.testing.assert_allclose", "numpy.testing.assert_allclose", "print", "torch.save", "zip", "list", "list", "pytorch_model.features.state_dict.keys", "print", "convert_to_pytorch.main.to_pytorch_tensor"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_slim.define_vggish_slim", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_slim.load_vggish_slim_checkpoint", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.waveform_to_examples"], ["def", "main", "(", ")", ":", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# -------------------", "\n", "# Step 1", "\n", "# -------------------", "\n", "# Load the model.", "\n", "        ", "vggish_slim", ".", "define_vggish_slim", "(", "training", "=", "False", ")", "\n", "vggish_slim", ".", "load_vggish_slim_checkpoint", "(", "sess", ",", "'vggish_model.ckpt'", ")", "\n", "\n", "# Get all of the variables, and use this to construct a dictionary which maps", "\n", "# the name of the variables to their values.", "\n", "variables", "=", "tf", ".", "all_variables", "(", ")", "\n", "variables", "=", "[", "x", ".", "name", "for", "x", "in", "variables", "]", "\n", "variable_values", "=", "sess", ".", "run", "(", "variables", ")", "\n", "variable_dict", "=", "dict", "(", "zip", "(", "variables", ",", "variable_values", ")", ")", "\n", "\n", "# Create a new state dictionary which maps the TensorFlow version of the weights", "\n", "# to those in in the new PyTorch model.", "\n", "pytorch_model", "=", "VGGish", "(", ")", "\n", "pytorch_feature_dict", "=", "pytorch_model", ".", "features", ".", "state_dict", "(", ")", "\n", "pytorch_fc_dict", "=", "pytorch_model", ".", "fc", ".", "state_dict", "(", ")", "\n", "\n", "# -------------------", "\n", "# Step 2", "\n", "# -------------------", "\n", "# There is a bias and weight vector for each convolution layer. The weights are not necessarily stored", "\n", "# in the same format and order between the two frameworks; for the TensorFlow model, the 12 vectors for the", "\n", "# convolution layers are first, followed by the 6 FC layers.", "\n", "tf_feature_names", "=", "list", "(", "variable_dict", ".", "keys", "(", ")", ")", "[", ":", "-", "6", "]", "\n", "tf_fc_names", "=", "list", "(", "variable_dict", ".", "keys", "(", ")", ")", "[", "-", "6", ":", "]", "\n", "\n", "def", "to_pytorch_tensor", "(", "weights", ")", ":", "\n", "            ", "if", "len", "(", "weights", ".", "shape", ")", "==", "4", ":", "\n", "                ", "tensor", "=", "torch", ".", "from_numpy", "(", "weights", ".", "transpose", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "tensor", "=", "torch", ".", "from_numpy", "(", "weights", ".", "T", ")", ".", "float", "(", ")", "\n", "", "return", "tensor", "\n", "\n", "# Convert the weights for the convolution layers.", "\n", "", "for", "tf_name", ",", "pytorch_name", "in", "zip", "(", "tf_feature_names", ",", "pytorch_feature_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "print", "(", "f'Converting [{tf_name}] ---------->  [feature.{pytorch_name}]'", ")", "\n", "pytorch_feature_dict", "[", "pytorch_name", "]", "=", "to_pytorch_tensor", "(", "variable_dict", "[", "tf_name", "]", ")", "\n", "\n", "# Convert the weights for the FC layers.", "\n", "", "for", "tf_name", ",", "pytorch_name", "in", "zip", "(", "tf_fc_names", ",", "pytorch_fc_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "print", "(", "f'Converting [{tf_name}] ---------->  [fc.{pytorch_name}]'", ")", "\n", "pytorch_fc_dict", "[", "pytorch_name", "]", "=", "to_pytorch_tensor", "(", "variable_dict", "[", "tf_name", "]", ")", "\n", "\n", "# -------------------", "\n", "# Step 3", "\n", "# -------------------", "\n", "# Load the new state dictionaries into the PyTorch model.", "\n", "", "pytorch_model", ".", "features", ".", "load_state_dict", "(", "pytorch_feature_dict", ")", "\n", "pytorch_model", ".", "fc", ".", "load_state_dict", "(", "pytorch_fc_dict", ")", "\n", "\n", "# -------------------", "\n", "# Step 4", "\n", "# -------------------", "\n", "# Generate a sample input (as in the AudioSet repo smoke test).", "\n", "num_secs", "=", "3", "\n", "freq", "=", "1000", "\n", "sr", "=", "44100", "\n", "t", "=", "np", ".", "linspace", "(", "0", ",", "num_secs", ",", "int", "(", "num_secs", "*", "sr", ")", ")", "\n", "x", "=", "np", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "freq", "*", "t", ")", "\n", "\n", "# Produce a batch of log mel spectrogram examples.", "\n", "input_batch", "=", "vggish_input", ".", "waveform_to_examples", "(", "x", ",", "sr", ")", "\n", "\n", "# Run inference on the TensorFlow model.", "\n", "features_tensor", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "\n", "vggish_params", ".", "INPUT_TENSOR_NAME", ")", "\n", "embedding_tensor", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "\n", "vggish_params", ".", "OUTPUT_TENSOR_NAME", ")", "\n", "[", "tf_output", "]", "=", "sess", ".", "run", "(", "[", "embedding_tensor", "]", ",", "\n", "feed_dict", "=", "{", "features_tensor", ":", "input_batch", "}", ")", "\n", "\n", "# Run on the PyTorch model.", "\n", "pytorch_model", "=", "pytorch_model", ".", "to", "(", "'cpu'", ")", "\n", "pytorch_output", "=", "pytorch_model", "(", "torch", ".", "from_numpy", "(", "input_batch", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "float", "(", ")", ")", "\n", "pytorch_output", "=", "pytorch_output", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# -------------------", "\n", "# Step 5", "\n", "# -------------------", "\n", "# Compare the difference between the outputs.", "\n", "diff", "=", "np", ".", "linalg", ".", "norm", "(", "pytorch_output", "-", "tf_output", ")", "**", "2", "\n", "print", "(", "f'Distance between TensorFlow and PyTorch outputs: [{diff}]'", ")", "\n", "assert", "diff", "<", "1e-6", "\n", "\n", "# Run a smoke test.", "\n", "expected_embedding_mean", "=", "0.131", "\n", "expected_embedding_std", "=", "0.238", "\n", "\n", "# Verify the TF output.", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "\n", "[", "np", ".", "mean", "(", "tf_output", ")", ",", "np", ".", "std", "(", "tf_output", ")", "]", ",", "\n", "[", "expected_embedding_mean", ",", "expected_embedding_std", "]", ",", "\n", "rtol", "=", "0.001", ")", "\n", "\n", "# Verify the PyTorch output.", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "\n", "[", "np", ".", "mean", "(", "pytorch_output", ")", ",", "np", ".", "std", "(", "pytorch_output", ")", "]", ",", "\n", "[", "expected_embedding_mean", ",", "expected_embedding_std", "]", ",", "\n", "rtol", "=", "0.001", ")", "\n", "\n", "# -------------------", "\n", "# Step 6", "\n", "# -------------------", "\n", "print", "(", "'Smoke test passed! Saving PyTorch weights to \"pytorch_vggish.pth\".'", ")", "\n", "torch", ".", "save", "(", "pytorch_model", ".", "state_dict", "(", ")", ",", "'pytorch_vggish.pth'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset_vggish_tensorflow_to_pytorch.example_usage.main": [[11, 88], ["vggish.VGGish", "pytorch_model.to.load_state_dict", "pytorch_model.to.to", "pytorch_model.to.eval", "pathlib.Path", "pathlib.Path", "tqdm.tqdm", "torch.load", "torch.load", "pathlib.Path.glob", "open", "json.dump", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.float().to", "input_batch.unsqueeze.unsqueeze", "pytorch_model.to.", "pytorch_output.detach().cpu().numpy.detach().cpu().numpy", "audioset.vggish_postprocess.Postprocessor", "vggish_postprocess.Postprocessor.postprocess", "str", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "numpy.save", "audioset.vggish_input.wavfile_to_examples", "file.relative_to", "os.makedirs", "file.relative_to", "str().split", "pathlib.Path", "print", "exception_dict.append", "str", "torch.from_numpy.float", "pytorch_output.detach().cpu().numpy.detach().cpu", "file.relative_to", "str", "str", "str", "pytorch_output.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_postprocess.Postprocessor.postprocess", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.wavfile_to_examples"], ["def", "main", "(", ")", ":", "\n", "# Initialize the PyTorch model.", "\n", "\n", "    ", "exception_dict", "=", "[", "]", "\n", "device", "=", "'cuda:0'", "\n", "\n", "pytorch_model", "=", "VGGish", "(", ")", "\n", "pytorch_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'pytorch_vggish.pth'", ")", ")", "\n", "pytorch_model", "=", "pytorch_model", ".", "to", "(", "device", ")", "\n", "pytorch_model", ".", "eval", "(", ")", "\n", "path", "=", "Path", "(", "\"/home/omercea19/akata-shared/omercea19/full_ebird_download\"", ")", "\n", "\n", "root_saved", "=", "Path", "(", "\"/home/omercea19/akata-shared/omercea19/full_ebird_download_embeddings_new_model\"", ")", "\n", "\n", "dict", "=", "{", "}", "\n", "for", "file", "in", "tqdm", "(", "path", ".", "glob", "(", "'**/*.wav'", ")", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "dict", "[", "file", "]", "=", "0", "\n", "loaded_wav", "=", "torch", ".", "from_numpy", "(", "vggish_input", ".", "wavfile_to_examples", "(", "str", "(", "file", ")", ")", ")", "\n", "input_batch", "=", "loaded_wav", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "input_batch", "=", "input_batch", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "pytorch_output", "=", "pytorch_model", "(", "input_batch", ")", "\n", "pytorch_output", "=", "pytorch_output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "post_processor", "=", "vggish_postprocess", ".", "Postprocessor", "(", "'vggish_pca_params.npz'", ")", "\n", "postprocessed_output", "=", "post_processor", ".", "postprocess", "(", "pytorch_output", ")", "\n", "#postprocessed_output=postprocessed_output.mean(axis=0)", "\n", "new_path", "=", "str", "(", "file", ".", "relative_to", "(", "path", ")", ")", "\n", "new_directory", "=", "Path", ".", "joinpath", "(", "root_saved", ",", "file", ".", "relative_to", "(", "path", ")", ".", "parent", ")", "\n", "try", ":", "\n", "                ", "os", ".", "makedirs", "(", "new_directory", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "new_path", "=", "Path", ".", "joinpath", "(", "root_saved", ",", "file", ".", "relative_to", "(", "path", ")", ")", "\n", "name", "=", "str", "(", "new_path", ".", "name", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "name", "=", "name", "+", "\".npy\"", "\n", "new_path", "=", "Path", ".", "joinpath", "(", "new_path", ".", "parent", ",", "Path", "(", "name", ")", ")", "\n", "np", ".", "save", "(", "new_path", ",", "postprocessed_output", ")", "\n", "#zz=np.load(new_path)", "\n", "#print(zz)", "\n", "", "except", ":", "\n", "            ", "print", "(", "str", "(", "file", ")", ")", "\n", "exception_dict", ".", "append", "(", "str", "(", "file", ")", ")", "\n", "\n", "", "", "with", "open", "(", "\"./exception.json\"", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "json", ".", "dump", "(", "exception_dict", ",", "g", ")", "\n", "\n", "\n", "\n", "", "''' \n    \n    THIS IS THE VARIANT WITH THE BATCHES, WHICH WILL MOST LIKELY WE USED DURING THE TRAINING/INFERENCE\n    \n    # Generate a sample input (as in the AudioSet repo smoke test).\n    x=['../altele/5bS607UKT2U.wav','../altele/5bS607UKT2U.wav']\n    input_batch=[]\n    for i in x:\n        input_batch.append(torch.from_numpy(vggish_input.wavfile_to_examples(i)))\n\n    input_batch=torch.stack(input_batch)\n\n    # Produce a batch of log mel spectrogram examples.\n    input_batch = input_batch.float().to(device)\n    input_batch=input_batch.unsqueeze(dim=2)\n    input_batch=input_batch.view(-1,input_batch.shape[2],input_batch.shape[3],input_batch.shape[4])\n\n    # Run the PyTorch model.\n    pytorch_output = pytorch_model(input_batch)\n    pytorch_output = pytorch_output.detach().cpu().numpy()\n    print('Input Shape:', tuple(input_batch.shape))\n    print('Output Shape:', tuple(pytorch_output.shape))\n\n    # Post-processing.\n    post_processor = vggish_postprocess.Postprocessor('vggish_pca_params.npz')\n    postprocessed_output = post_processor.postprocess(pytorch_output)\n    postprocessed_output=np.reshape(postprocessed_output,(len(x),-1,postprocessed_output.shape[1]))\n    print(\"final\")\n    '''", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_postprocess.Postprocessor.__init__": [[35, 51], ["numpy.load", "params[].reshape"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pca_params_npz_path", ")", ":", "\n", "    ", "\"\"\"Constructs a postprocessor.\n\n    Args:\n      pca_params_npz_path: Path to a NumPy-format .npz file that\n        contains the PCA parameters used in postprocessing.\n    \"\"\"", "\n", "params", "=", "np", ".", "load", "(", "pca_params_npz_path", ")", "\n", "self", ".", "_pca_matrix", "=", "params", "[", "vggish_params", ".", "PCA_EIGEN_VECTORS_NAME", "]", "\n", "# Load means into a column vector for easier broadcasting later.", "\n", "self", ".", "_pca_means", "=", "params", "[", "vggish_params", ".", "PCA_MEANS_NAME", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "assert", "self", ".", "_pca_matrix", ".", "shape", "==", "(", "\n", "vggish_params", ".", "EMBEDDING_SIZE", ",", "vggish_params", ".", "EMBEDDING_SIZE", ")", ",", "(", "\n", "'Bad PCA matrix shape: %r'", "%", "(", "self", ".", "_pca_matrix", ".", "shape", ",", ")", ")", "\n", "assert", "self", ".", "_pca_means", ".", "shape", "==", "(", "vggish_params", ".", "EMBEDDING_SIZE", ",", "1", ")", ",", "(", "\n", "'Bad PCA means shape: %r'", "%", "(", "self", ".", "_pca_means", ".", "shape", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_postprocess.Postprocessor.postprocess": [[52, 92], ["numpy.clip", "quantized_embeddings.astype.astype.astype", "len", "numpy.dot"], "methods", ["None"], ["", "def", "postprocess", "(", "self", ",", "embeddings_batch", ")", ":", "\n", "    ", "\"\"\"Applies postprocessing to a batch of embeddings.\n\n    Args:\n      embeddings_batch: An nparray of shape [batch_size, embedding_size]\n        containing output from the embedding layer of VGGish.\n\n    Returns:\n      An nparray of the same shape as the input but of type uint8,\n      containing the PCA-transformed and quantized version of the input.\n    \"\"\"", "\n", "assert", "len", "(", "embeddings_batch", ".", "shape", ")", "==", "2", ",", "(", "\n", "'Expected 2-d batch, got %r'", "%", "(", "embeddings_batch", ".", "shape", ",", ")", ")", "\n", "assert", "embeddings_batch", ".", "shape", "[", "1", "]", "==", "vggish_params", ".", "EMBEDDING_SIZE", ",", "(", "\n", "'Bad batch shape: %r'", "%", "(", "embeddings_batch", ".", "shape", ",", ")", ")", "\n", "\n", "# Apply PCA.", "\n", "# - Embeddings come in as [batch_size, embedding_size].", "\n", "# - Transpose to [embedding_size, batch_size].", "\n", "# - Subtract pca_means column vector from each column.", "\n", "# - Premultiply by PCA matrix of shape [output_dims, input_dims]", "\n", "#   where both are are equal to embedding_size in our case.", "\n", "# - Transpose result back to [batch_size, embedding_size].", "\n", "pca_applied", "=", "np", ".", "dot", "(", "self", ".", "_pca_matrix", ",", "\n", "(", "embeddings_batch", ".", "T", "-", "self", ".", "_pca_means", ")", ")", ".", "T", "\n", "\n", "# Quantize by:", "\n", "# - clipping to [min, max] range", "\n", "clipped_embeddings", "=", "np", ".", "clip", "(", "\n", "pca_applied", ",", "vggish_params", ".", "QUANTIZE_MIN_VAL", ",", "\n", "vggish_params", ".", "QUANTIZE_MAX_VAL", ")", "\n", "# - convert to 8-bit in range [0.0, 255.0]", "\n", "quantized_embeddings", "=", "(", "\n", "(", "clipped_embeddings", "-", "vggish_params", ".", "QUANTIZE_MIN_VAL", ")", "*", "\n", "(", "255.0", "/", "\n", "(", "vggish_params", ".", "QUANTIZE_MAX_VAL", "-", "vggish_params", ".", "QUANTIZE_MIN_VAL", ")", ")", ")", "\n", "# - cast 8-bit float to uint8", "\n", "quantized_embeddings", "=", "quantized_embeddings", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "return", "quantized_embeddings", "\n", "", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.waveform_to_examples": [[27, 72], ["audioset_vggish_tensorflow_to_pytorch.audioset.mel_features.log_mel_spectrogram", "int", "int", "audioset_vggish_tensorflow_to_pytorch.audioset.mel_features.frame", "len", "numpy.mean", "resampy.resample", "round", "round"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.log_mel_spectrogram", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.frame"], ["def", "waveform_to_examples", "(", "data", ",", "sample_rate", ")", ":", "\n", "  ", "\"\"\"Converts audio waveform into an array of examples for VGGish.\n\n  Args:\n    data: np.array of either one dimension (mono) or two dimensions\n      (multi-channel, with the outer dimension representing channels).\n      Each sample is generally expected to lie in the range [-1.0, +1.0],\n      although this is not required.\n    sample_rate: Sample rate of data.\n\n  Returns:\n    3-D np.array of shape [num_examples, num_frames, num_bands] which represents\n    a sequence of examples, each of which contains a patch of log mel\n    spectrogram, covering num_frames frames of audio and num_bands mel frequency\n    bands, where the frame length is vggish_params.STFT_HOP_LENGTH_SECONDS.\n  \"\"\"", "\n", "# Convert to mono.", "\n", "if", "len", "(", "data", ".", "shape", ")", ">", "1", ":", "\n", "    ", "data", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "1", ")", "\n", "# Resample to the rate assumed by VGGish.", "\n", "", "if", "sample_rate", "!=", "vggish_params", ".", "SAMPLE_RATE", ":", "\n", "    ", "data", "=", "resampy", ".", "resample", "(", "data", ",", "sample_rate", ",", "vggish_params", ".", "SAMPLE_RATE", ")", "\n", "\n", "# Compute log mel spectrogram features.", "\n", "", "log_mel", "=", "mel_features", ".", "log_mel_spectrogram", "(", "\n", "data", ",", "\n", "audio_sample_rate", "=", "vggish_params", ".", "SAMPLE_RATE", ",", "\n", "log_offset", "=", "vggish_params", ".", "LOG_OFFSET", ",", "\n", "window_length_secs", "=", "vggish_params", ".", "STFT_WINDOW_LENGTH_SECONDS", ",", "\n", "hop_length_secs", "=", "vggish_params", ".", "STFT_HOP_LENGTH_SECONDS", ",", "\n", "num_mel_bins", "=", "vggish_params", ".", "NUM_MEL_BINS", ",", "\n", "lower_edge_hertz", "=", "vggish_params", ".", "MEL_MIN_HZ", ",", "\n", "upper_edge_hertz", "=", "vggish_params", ".", "MEL_MAX_HZ", ")", "\n", "\n", "# Frame features into examples.", "\n", "features_sample_rate", "=", "1.0", "/", "vggish_params", ".", "STFT_HOP_LENGTH_SECONDS", "\n", "example_window_length", "=", "int", "(", "round", "(", "\n", "vggish_params", ".", "EXAMPLE_WINDOW_SECONDS", "*", "features_sample_rate", ")", ")", "\n", "example_hop_length", "=", "int", "(", "round", "(", "\n", "vggish_params", ".", "EXAMPLE_HOP_SECONDS", "*", "features_sample_rate", ")", ")", "\n", "log_mel_examples", "=", "mel_features", ".", "frame", "(", "\n", "log_mel", ",", "\n", "window_length", "=", "example_window_length", ",", "\n", "hop_length", "=", "example_hop_length", ")", "\n", "return", "log_mel_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.wavfile_to_examples": [[74, 88], ["soundfile.read", "vggish_input.waveform_to_examples"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_input.waveform_to_examples"], ["", "def", "wavfile_to_examples", "(", "wav_file", ")", ":", "\n", "  ", "\"\"\"Convenience wrapper around waveform_to_examples() for a common WAV format.\n\n  Args:\n    wav_file: String path to a file, or a file-like object. The file\n    is assumed to contain WAV audio data with signed 16-bit PCM samples.\n\n  Returns:\n    See waveform_to_examples.\n  \"\"\"", "\n", "wav_data", ",", "sr", "=", "sf", ".", "read", "(", "wav_file", ",", "dtype", "=", "'int16'", ")", "\n", "assert", "wav_data", ".", "dtype", "==", "np", ".", "int16", ",", "'Bad sample type: %r'", "%", "wav_data", ".", "dtype", "\n", "samples", "=", "wav_data", "/", "32768.0", "# Convert to [-1.0, +1.0]", "\n", "return", "waveform_to_examples", "(", "samples", ",", "sr", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.frame": [[21, 46], ["numpy.lib.stride_tricks.as_strided", "int", "numpy.floor"], "function", ["None"], ["def", "frame", "(", "data", ",", "window_length", ",", "hop_length", ")", ":", "\n", "  ", "\"\"\"Convert array into a sequence of successive possibly overlapping frames.\n\n  An n-dimensional array of shape (num_samples, ...) is converted into an\n  (n+1)-D array of shape (num_frames, window_length, ...), where each frame\n  starts hop_length points after the preceding one.\n\n  This is accomplished using stride_tricks, so the original data is not\n  copied.  However, there is no zero-padding, so any incomplete frames at the\n  end are not included.\n\n  Args:\n    data: np.array of dimension N >= 1.\n    window_length: Number of samples in each frame.\n    hop_length: Advance (in samples) between each window.\n\n  Returns:\n    (N+1)-D np.array with as many rows as there are complete frames that can be\n    extracted.\n  \"\"\"", "\n", "num_samples", "=", "data", ".", "shape", "[", "0", "]", "\n", "num_frames", "=", "1", "+", "int", "(", "np", ".", "floor", "(", "(", "num_samples", "-", "window_length", ")", "/", "hop_length", ")", ")", "\n", "shape", "=", "(", "num_frames", ",", "window_length", ")", "+", "data", ".", "shape", "[", "1", ":", "]", "\n", "strides", "=", "(", "data", ".", "strides", "[", "0", "]", "*", "hop_length", ",", ")", "+", "data", ".", "strides", "\n", "return", "np", ".", "lib", ".", "stride_tricks", ".", "as_strided", "(", "data", ",", "shape", "=", "shape", ",", "strides", "=", "strides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.periodic_hann": [[48, 69], ["numpy.cos", "numpy.arange"], "function", ["None"], ["", "def", "periodic_hann", "(", "window_length", ")", ":", "\n", "  ", "\"\"\"Calculate a \"periodic\" Hann window.\n\n  The classic Hann window is defined as a raised cosine that starts and\n  ends on zero, and where every value appears twice, except the middle\n  point for an odd-length window.  Matlab calls this a \"symmetric\" window\n  and np.hanning() returns it.  However, for Fourier analysis, this\n  actually represents just over one cycle of a period N-1 cosine, and\n  thus is not compactly expressed on a length-N Fourier basis.  Instead,\n  it's better to use a raised cosine that ends just before the final\n  zero value - i.e. a complete cycle of a period-N cosine.  Matlab\n  calls this a \"periodic\" window. This routine calculates it.\n\n  Args:\n    window_length: The number of points in the returned window.\n\n  Returns:\n    A 1D np.array containing the periodic hann window.\n  \"\"\"", "\n", "return", "0.5", "-", "(", "0.5", "*", "np", ".", "cos", "(", "2", "*", "np", ".", "pi", "/", "window_length", "*", "\n", "np", ".", "arange", "(", "window_length", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.stft_magnitude": [[71, 93], ["mel_features.frame", "mel_features.periodic_hann", "numpy.abs", "numpy.fft.rfft", "int"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.frame", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.periodic_hann"], ["", "def", "stft_magnitude", "(", "signal", ",", "fft_length", ",", "\n", "hop_length", "=", "None", ",", "\n", "window_length", "=", "None", ")", ":", "\n", "  ", "\"\"\"Calculate the short-time Fourier transform magnitude.\n\n  Args:\n    signal: 1D np.array of the input time-domain signal.\n    fft_length: Size of the FFT to apply.\n    hop_length: Advance (in samples) between each frame passed to FFT.\n    window_length: Length of each block of samples to pass to FFT.\n\n  Returns:\n    2D np.array where each row contains the magnitudes of the fft_length/2+1\n    unique values of the FFT for the corresponding frame of input samples.\n  \"\"\"", "\n", "frames", "=", "frame", "(", "signal", ",", "window_length", ",", "hop_length", ")", "\n", "# Apply frame window to each frame. We use a periodic Hann (cosine of period", "\n", "# window_length) instead of the symmetric Hann of np.hanning (period", "\n", "# window_length-1).", "\n", "window", "=", "periodic_hann", "(", "window_length", ")", "\n", "windowed_frames", "=", "frames", "*", "window", "\n", "return", "np", ".", "abs", "(", "np", ".", "fft", ".", "rfft", "(", "windowed_frames", ",", "int", "(", "fft_length", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.hertz_to_mel": [[100, 112], ["numpy.log"], "function", ["None"], ["def", "hertz_to_mel", "(", "frequencies_hertz", ")", ":", "\n", "  ", "\"\"\"Convert frequencies to mel scale using HTK formula.\n\n  Args:\n    frequencies_hertz: Scalar or np.array of frequencies in hertz.\n\n  Returns:\n    Object of same size as frequencies_hertz containing corresponding values\n    on the mel scale.\n  \"\"\"", "\n", "return", "_MEL_HIGH_FREQUENCY_Q", "*", "np", ".", "log", "(", "\n", "1.0", "+", "(", "frequencies_hertz", "/", "_MEL_BREAK_FREQUENCY_HERTZ", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.spectrogram_to_mel_matrix": [[114, 190], ["numpy.linspace", "mel_features.hertz_to_mel", "numpy.linspace", "numpy.empty", "range", "ValueError", "ValueError", "ValueError", "mel_features.hertz_to_mel", "mel_features.hertz_to_mel", "numpy.maximum", "numpy.minimum"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.hertz_to_mel", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.hertz_to_mel", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.hertz_to_mel"], ["", "def", "spectrogram_to_mel_matrix", "(", "num_mel_bins", "=", "20", ",", "\n", "num_spectrogram_bins", "=", "129", ",", "\n", "audio_sample_rate", "=", "8000", ",", "\n", "lower_edge_hertz", "=", "125.0", ",", "\n", "upper_edge_hertz", "=", "3800.0", ")", ":", "\n", "  ", "\"\"\"Return a matrix that can post-multiply spectrogram rows to make mel.\n\n  Returns a np.array matrix A that can be used to post-multiply a matrix S of\n  spectrogram values (STFT magnitudes) arranged as frames x bins to generate a\n  \"mel spectrogram\" M of frames x num_mel_bins.  M = S A.\n\n  The classic HTK algorithm exploits the complementarity of adjacent mel bands\n  to multiply each FFT bin by only one mel weight, then add it, with positive\n  and negative signs, to the two adjacent mel bands to which that bin\n  contributes.  Here, by expressing this operation as a matrix multiply, we go\n  from num_fft multiplies per frame (plus around 2*num_fft adds) to around\n  num_fft^2 multiplies and adds.  However, because these are all presumably\n  accomplished in a single call to np.dot(), it's not clear which approach is\n  faster in Python.  The matrix multiplication has the attraction of being more\n  general and flexible, and much easier to read.\n\n  Args:\n    num_mel_bins: How many bands in the resulting mel spectrum.  This is\n      the number of columns in the output matrix.\n    num_spectrogram_bins: How many bins there are in the source spectrogram\n      data, which is understood to be fft_size/2 + 1, i.e. the spectrogram\n      only contains the nonredundant FFT bins.\n    audio_sample_rate: Samples per second of the audio at the input to the\n      spectrogram. We need this to figure out the actual frequencies for\n      each spectrogram bin, which dictates how they are mapped into mel.\n    lower_edge_hertz: Lower bound on the frequencies to be included in the mel\n      spectrum.  This corresponds to the lower edge of the lowest triangular\n      band.\n    upper_edge_hertz: The desired top edge of the highest frequency band.\n\n  Returns:\n    An np.array with shape (num_spectrogram_bins, num_mel_bins).\n\n  Raises:\n    ValueError: if frequency edges are incorrectly ordered or out of range.\n  \"\"\"", "\n", "nyquist_hertz", "=", "audio_sample_rate", "/", "2.", "\n", "if", "lower_edge_hertz", "<", "0.0", ":", "\n", "    ", "raise", "ValueError", "(", "\"lower_edge_hertz %.1f must be >= 0\"", "%", "lower_edge_hertz", ")", "\n", "", "if", "lower_edge_hertz", ">=", "upper_edge_hertz", ":", "\n", "    ", "raise", "ValueError", "(", "\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\"", "%", "\n", "(", "lower_edge_hertz", ",", "upper_edge_hertz", ")", ")", "\n", "", "if", "upper_edge_hertz", ">", "nyquist_hertz", ":", "\n", "    ", "raise", "ValueError", "(", "\"upper_edge_hertz %.1f is greater than Nyquist %.1f\"", "%", "\n", "(", "upper_edge_hertz", ",", "nyquist_hertz", ")", ")", "\n", "", "spectrogram_bins_hertz", "=", "np", ".", "linspace", "(", "0.0", ",", "nyquist_hertz", ",", "num_spectrogram_bins", ")", "\n", "spectrogram_bins_mel", "=", "hertz_to_mel", "(", "spectrogram_bins_hertz", ")", "\n", "# The i'th mel band (starting from i=1) has center frequency", "\n", "# band_edges_mel[i], lower edge band_edges_mel[i-1], and higher edge", "\n", "# band_edges_mel[i+1].  Thus, we need num_mel_bins + 2 values in", "\n", "# the band_edges_mel arrays.", "\n", "band_edges_mel", "=", "np", ".", "linspace", "(", "hertz_to_mel", "(", "lower_edge_hertz", ")", ",", "\n", "hertz_to_mel", "(", "upper_edge_hertz", ")", ",", "num_mel_bins", "+", "2", ")", "\n", "# Matrix to post-multiply feature arrays whose rows are num_spectrogram_bins", "\n", "# of spectrogram values.", "\n", "mel_weights_matrix", "=", "np", ".", "empty", "(", "(", "num_spectrogram_bins", ",", "num_mel_bins", ")", ")", "\n", "for", "i", "in", "range", "(", "num_mel_bins", ")", ":", "\n", "    ", "lower_edge_mel", ",", "center_mel", ",", "upper_edge_mel", "=", "band_edges_mel", "[", "i", ":", "i", "+", "3", "]", "\n", "# Calculate lower and upper slopes for every spectrogram bin.", "\n", "# Line segments are linear in the *mel* domain, not hertz.", "\n", "lower_slope", "=", "(", "(", "spectrogram_bins_mel", "-", "lower_edge_mel", ")", "/", "\n", "(", "center_mel", "-", "lower_edge_mel", ")", ")", "\n", "upper_slope", "=", "(", "(", "upper_edge_mel", "-", "spectrogram_bins_mel", ")", "/", "\n", "(", "upper_edge_mel", "-", "center_mel", ")", ")", "\n", "# .. then intersect them with each other and zero.", "\n", "mel_weights_matrix", "[", ":", ",", "i", "]", "=", "np", ".", "maximum", "(", "0.0", ",", "np", ".", "minimum", "(", "lower_slope", ",", "\n", "upper_slope", ")", ")", "\n", "# HTK excludes the spectrogram DC bin; make sure it always gets a zero", "\n", "# coefficient.", "\n", "", "mel_weights_matrix", "[", "0", ",", ":", "]", "=", "0.0", "\n", "return", "mel_weights_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.log_mel_spectrogram": [[192, 224], ["int", "int", "mel_features.stft_magnitude", "numpy.dot", "numpy.log", "round", "round", "int", "mel_features.spectrogram_to_mel_matrix", "numpy.ceil", "numpy.log", "numpy.log"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.stft_magnitude", "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.mel_features.spectrogram_to_mel_matrix"], ["", "def", "log_mel_spectrogram", "(", "data", ",", "\n", "audio_sample_rate", "=", "8000", ",", "\n", "log_offset", "=", "0.0", ",", "\n", "window_length_secs", "=", "0.025", ",", "\n", "hop_length_secs", "=", "0.010", ",", "\n", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"Convert waveform to a log magnitude mel-frequency spectrogram.\n\n  Args:\n    data: 1D np.array of waveform data.\n    audio_sample_rate: The sampling rate of data.\n    log_offset: Add this to values when taking log to avoid -Infs.\n    window_length_secs: Duration of each window to analyze.\n    hop_length_secs: Advance between successive analysis windows.\n    **kwargs: Additional arguments to pass to spectrogram_to_mel_matrix.\n\n  Returns:\n    2D np.array of (num_frames, num_mel_bins) consisting of log mel filterbank\n    magnitudes for successive frames.\n  \"\"\"", "\n", "window_length_samples", "=", "int", "(", "round", "(", "audio_sample_rate", "*", "window_length_secs", ")", ")", "\n", "hop_length_samples", "=", "int", "(", "round", "(", "audio_sample_rate", "*", "hop_length_secs", ")", ")", "\n", "fft_length", "=", "2", "**", "int", "(", "np", ".", "ceil", "(", "np", ".", "log", "(", "window_length_samples", ")", "/", "np", ".", "log", "(", "2.0", ")", ")", ")", "\n", "spectrogram", "=", "stft_magnitude", "(", "\n", "data", ",", "\n", "fft_length", "=", "fft_length", ",", "\n", "hop_length", "=", "hop_length_samples", ",", "\n", "window_length", "=", "window_length_samples", ")", "\n", "mel_spectrogram", "=", "np", ".", "dot", "(", "spectrogram", ",", "spectrogram_to_mel_matrix", "(", "\n", "num_spectrogram_bins", "=", "spectrogram", ".", "shape", "[", "1", "]", ",", "\n", "audio_sample_rate", "=", "audio_sample_rate", ",", "**", "kwargs", ")", ")", "\n", "return", "np", ".", "log", "(", "mel_spectrogram", "+", "log_offset", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_slim.define_vggish_slim": [[39, 100], ["slim.arg_scope", "slim.arg_scope", "slim.arg_scope", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.reshape", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.flatten", "slim.repeat", "slim.fully_connected", "tensorflow.identity", "tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer"], "function", ["None"], ["def", "define_vggish_slim", "(", "training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Defines the VGGish TensorFlow model.\n\n  All ops are created in the current default graph, under the scope 'vggish/'.\n\n  The input is a placeholder named 'vggish/input_features' of type float32 and\n  shape [batch_size, num_frames, num_bands] where batch_size is variable and\n  num_frames and num_bands are constants, and [num_frames, num_bands] represents\n  a log-mel-scale spectrogram patch covering num_bands frequency bands and\n  num_frames time frames (where each frame step is usually 10ms). This is\n  produced by computing the stabilized log(mel-spectrogram + params.LOG_OFFSET).\n  The output is an op named 'vggish/embedding' which produces the activations of\n  a 128-D embedding layer, which is usually the penultimate layer when used as\n  part of a full model with a final classifier layer.\n\n  Args:\n    training: If true, all parameters are marked trainable.\n\n  Returns:\n    The op 'vggish/embeddings'.\n  \"\"\"", "\n", "# Defaults:", "\n", "# - All weights are initialized to N(0, INIT_STDDEV).", "\n", "# - All biases are initialized to 0.", "\n", "# - All activations are ReLU.", "\n", "# - All convolutions are 3x3 with stride 1 and SAME padding.", "\n", "# - All max-pools are 2x2 with stride 2 and SAME padding.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "\n", "stddev", "=", "params", ".", "INIT_STDDEV", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "trainable", "=", "training", ")", ",", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "\n", "kernel_size", "=", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ",", "slim", ".", "arg_scope", "(", "[", "slim", ".", "max_pool2d", "]", ",", "\n", "kernel_size", "=", "[", "2", ",", "2", "]", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ")", ",", "tf", ".", "variable_scope", "(", "'vggish'", ")", ":", "\n", "# Input: a batch of 2-D log-mel-spectrogram patches.", "\n", "    ", "features", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "params", ".", "NUM_FRAMES", ",", "params", ".", "NUM_BANDS", ")", ",", "\n", "name", "=", "'input_features'", ")", "\n", "# Reshape to 4-D so that we can convolve a batch with conv2d().", "\n", "net", "=", "tf", ".", "reshape", "(", "features", ",", "[", "-", "1", ",", "params", ".", "NUM_FRAMES", ",", "params", ".", "NUM_BANDS", ",", "1", "]", ")", "\n", "\n", "# The VGG stack of alternating convolutions and max-pools.", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "256", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "scope", "=", "'pool3'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "512", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "scope", "=", "'pool4'", ")", "\n", "\n", "# Flatten before entering fully-connected layers", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "fully_connected", ",", "4096", ",", "scope", "=", "'fc1'", ")", "\n", "# The embedding layer.", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "params", ".", "EMBEDDING_SIZE", ",", "scope", "=", "'fc2'", ")", "\n", "return", "tf", ".", "identity", "(", "net", ",", "name", "=", "'embedding'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_slim.load_vggish_slim_checkpoint": [[102, 130], ["tensorflow.train.Saver", "tf.train.Saver.restore", "tensorflow.Graph().as_default", "vggish_slim.define_vggish_slim", "tensorflow.global_variables", "tensorflow.Graph", "tensorflow.global_variables"], "function", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.audioset.vggish_slim.define_vggish_slim"], ["", "", "def", "load_vggish_slim_checkpoint", "(", "session", ",", "checkpoint_path", ")", ":", "\n", "  ", "\"\"\"Loads a pre-trained VGGish-compatible checkpoint.\n\n  This function can be used as an initialization function (referred to as\n  init_fn in TensorFlow documentation) which is called in a Session after\n  initializating all variables. When used as an init_fn, this will load\n  a pre-trained checkpoint that is compatible with the VGGish model\n  definition. Only variables defined by VGGish will be loaded.\n\n  Args:\n    session: an active TensorFlow session.\n    checkpoint_path: path to a file containing a checkpoint that is\n      compatible with the VGGish model definition.\n  \"\"\"", "\n", "# Get the list of names of all VGGish variables that exist in", "\n", "# the checkpoint (i.e., all inference-mode VGGish variables).", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "define_vggish_slim", "(", "training", "=", "False", ")", "\n", "vggish_var_names", "=", "[", "v", ".", "name", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "]", "\n", "\n", "# Get the list of all currently existing variables that match", "\n", "# the list of variable names we just computed.", "\n", "", "vggish_vars", "=", "[", "v", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "if", "v", ".", "name", "in", "vggish_var_names", "]", "\n", "\n", "# Use a Saver to restore just the variables selected above.", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vggish_vars", ",", "name", "=", "'vggish_load_pretrained'", ",", "\n", "write_version", "=", "1", ")", "\n", "saver", ".", "restore", "(", "session", ",", "checkpoint_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__": [[9, 38], ["torch.Module.__init__", "torch.Conv3d", "torch.MaxPool3d", "torch.Conv3d", "torch.MaxPool3d", "torch.Conv3d", "torch.Conv3d", "torch.MaxPool3d", "torch.Conv3d", "torch.Conv3d", "torch.MaxPool3d", "torch.Conv3d", "torch.Conv3d", "torch.MaxPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.ReLU", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "C3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv3a", "=", "nn", ".", "Conv3d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "conv3b", "=", "nn", ".", "Conv3d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "pool3", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv4a", "=", "nn", ".", "Conv3d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "conv4b", "=", "nn", ".", "Conv3d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "pool4", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv5a", "=", "nn", ".", "Conv3d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "conv5b", "=", "nn", ".", "Conv3d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "pool5", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "fc6", "=", "nn", ".", "Linear", "(", "8192", ",", "4096", ")", "\n", "self", ".", "fc7", "=", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", "\n", "self", ".", "fc8", "=", "nn", ".", "Linear", "(", "4096", ",", "487", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.explainableml_avca-gzsl.c3d.c3d.C3D.forward": [[39, 71], ["c3d.C3D.relu", "c3d.C3D.pool1", "c3d.C3D.relu", "c3d.C3D.pool2", "c3d.C3D.relu", "c3d.C3D.relu", "c3d.C3D.pool3", "c3d.C3D.relu", "c3d.C3D.relu", "c3d.C3D.pool4", "c3d.C3D.relu", "c3d.C3D.relu", "c3d.C3D.pool5", "c3d.C3D.view", "c3d.C3D.relu", "c3d.C3D.dropout", "c3d.C3D.relu", "c3d.C3D.dropout", "c3d.C3D.fc8", "c3d.C3D.softmax", "c3d.C3D.conv1", "c3d.C3D.conv2", "c3d.C3D.conv3a", "c3d.C3D.conv3b", "c3d.C3D.conv4a", "c3d.C3D.conv4b", "c3d.C3D.conv5a", "c3d.C3D.conv5b", "c3d.C3D.fc6", "c3d.C3D.fc7"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "h", "=", "self", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "h", "=", "self", ".", "pool1", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv2", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "pool2", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv3a", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv3b", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "pool3", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv4a", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv4b", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "pool4", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv5a", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "conv5b", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "pool5", "(", "h", ")", "\n", "\n", "h", "=", "h", ".", "view", "(", "-", "1", ",", "8192", ")", "\n", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc6", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "h", "=", "self", ".", "relu", "(", "self", ".", "fc7", "(", "h", ")", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "return", "h", "\n", "\n", "logits", "=", "self", ".", "fc8", "(", "h", ")", "\n", "probs", "=", "self", ".", "softmax", "(", "logits", ")", "\n", "\n", "return", "probs", "\n", "\n"]]}