{"home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.None.fc_synthesizer_train.prepare_run": [[8, 16], ["feedback_synthesizer.hparams.hparams.parse", "str", "os.path.join", "os.makedirs", "feedback_synthesizer.infolog.init", "os.path.join"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.init"], ["def", "prepare_run", "(", "args", ")", ":", "\n", "    ", "modified_hp", "=", "hparams", ".", "parse", "(", "args", ".", "hparams", ")", "\n", "os", ".", "environ", "[", "\"TF_CPP_MIN_LOG_LEVEL\"", "]", "=", "str", "(", "args", ".", "tf_log_level", ")", "\n", "run_name", "=", "args", ".", "name", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "\"logs-{}\"", ".", "format", "(", "run_name", ")", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "infolog", ".", "init", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"Terminal_train_log\"", ")", ",", "run_name", ",", "args", ".", "slack_url", ")", "\n", "return", "log_dir", ",", "modified_hp", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.None.synthesizer_train.prepare_run": [[9, 17], ["synthesizer.hparams.hparams.parse", "str", "os.path.join", "os.makedirs", "synthesizer.infolog.init", "os.path.join"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.init"], ["def", "prepare_run", "(", "args", ")", ":", "\n", "    ", "modified_hp", "=", "hparams", ".", "parse", "(", "args", ".", "hparams", ")", "\n", "os", ".", "environ", "[", "\"TF_CPP_MIN_LOG_LEVEL\"", "]", "=", "str", "(", "args", ".", "tf_log_level", ")", "\n", "run_name", "=", "args", ".", "name", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "\"logs-{}\"", ".", "format", "(", "run_name", ")", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "infolog", ".", "init", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"Terminal_train_log\"", ")", ",", "run_name", ",", "args", ".", "slack_url", ")", "\n", "return", "log_dir", ",", "modified_hp", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.progbar": [[7, 13], ["range"], "function", ["None"], ["def", "progbar", "(", "i", ",", "n", ",", "size", "=", "16", ")", ":", "\n", "    ", "done", "=", "(", "i", "*", "size", ")", "//", "n", "\n", "bar", "=", "''", "\n", "for", "i", "in", "range", "(", "size", ")", ":", "\n", "        ", "bar", "+=", "'\u2588'", "if", "i", "<=", "done", "else", "'\u2591'", "\n", "", "return", "bar", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.stream": [[15, 17], ["sys.stdout.write"], "function", ["None"], ["", "def", "stream", "(", "message", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "\"\\r{%s}\"", "%", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.simple_table": [[19, 68], ["range", "print", "print", "print", "print", "print", "print", "abs", "len", "str", "str", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "simple_table", "(", "item_tuples", ")", ":", "\n", "\n", "    ", "border_pattern", "=", "'+---------------------------------------'", "\n", "whitespace", "=", "'                                            '", "\n", "\n", "headings", ",", "cells", ",", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "item", "in", "item_tuples", ":", "\n", "\n", "        ", "heading", ",", "cell", "=", "str", "(", "item", "[", "0", "]", ")", ",", "str", "(", "item", "[", "1", "]", ")", "\n", "\n", "pad_head", "=", "True", "if", "len", "(", "heading", ")", "<", "len", "(", "cell", ")", "else", "False", "\n", "\n", "pad", "=", "abs", "(", "len", "(", "heading", ")", "-", "len", "(", "cell", ")", ")", "\n", "pad", "=", "whitespace", "[", ":", "pad", "]", "\n", "\n", "pad_left", "=", "pad", "[", ":", "len", "(", "pad", ")", "//", "2", "]", "\n", "pad_right", "=", "pad", "[", "len", "(", "pad", ")", "//", "2", ":", "]", "\n", "\n", "if", "pad_head", ":", "\n", "            ", "heading", "=", "pad_left", "+", "heading", "+", "pad_right", "\n", "", "else", ":", "\n", "            ", "cell", "=", "pad_left", "+", "cell", "+", "pad_right", "\n", "\n", "", "headings", "+=", "[", "heading", "]", "\n", "cells", "+=", "[", "cell", "]", "\n", "\n", "", "border", ",", "head", ",", "body", "=", "''", ",", "''", ",", "''", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "item_tuples", ")", ")", ":", "\n", "\n", "        ", "temp_head", "=", "f'| {headings[i]} '", "\n", "temp_body", "=", "f'| {cells[i]} '", "\n", "\n", "border", "+=", "border_pattern", "[", ":", "len", "(", "temp_head", ")", "]", "\n", "head", "+=", "temp_head", "\n", "body", "+=", "temp_body", "\n", "\n", "if", "i", "==", "len", "(", "item_tuples", ")", "-", "1", ":", "\n", "            ", "head", "+=", "'|'", "\n", "body", "+=", "'|'", "\n", "border", "+=", "'+'", "\n", "\n", "", "", "print", "(", "border", ")", "\n", "print", "(", "head", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "body", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.time_since": [[70, 80], ["int", "int", "time.time", "int"], "function", ["None"], ["", "def", "time_since", "(", "started", ")", ":", "\n", "    ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "started", "\n", "m", "=", "int", "(", "elapsed", "//", "60", ")", "\n", "s", "=", "int", "(", "elapsed", "%", "60", ")", "\n", "if", "m", ">=", "60", ":", "\n", "        ", "h", "=", "int", "(", "m", "//", "60", ")", "\n", "m", "=", "m", "%", "60", "\n", "return", "f'{h}h {m}m {s}s'", "\n", "", "else", ":", "\n", "        ", "return", "f'{m}m {s}s'", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.save_attention": [[82, 87], ["matplotlib.figure", "matplotlib.imshow", "plt.figure.savefig", "matplotlib.close"], "function", ["None"], ["", "", "def", "save_attention", "(", "attn", ",", "path", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "plt", ".", "imshow", "(", "attn", ".", "T", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "fig", ".", "savefig", "(", "f'{path}.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.save_spectrogram": [[89, 96], ["numpy.flip", "matplotlib.figure", "matplotlib.imshow", "plt.figure.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "save_spectrogram", "(", "M", ",", "path", ",", "length", "=", "None", ")", ":", "\n", "    ", "M", "=", "np", ".", "flip", "(", "M", ",", "axis", "=", "0", ")", "\n", "if", "length", ":", "M", "=", "M", "[", ":", ",", ":", "length", "]", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "plt", ".", "imshow", "(", "M", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "fig", ".", "savefig", "(", "f'{path}.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.plot": [[98, 108], ["matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.xaxis.label.set_color", "fig.add_subplot.yaxis.label.set_color", "fig.add_subplot.xaxis.label.set_fontsize", "fig.add_subplot.yaxis.label.set_fontsize", "fig.add_subplot.tick_params", "fig.add_subplot.tick_params", "matplotlib.plot"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.plot"], ["", "def", "plot", "(", "array", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "30", ",", "5", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax", ".", "xaxis", ".", "label", ".", "set_color", "(", "'grey'", ")", "\n", "ax", ".", "yaxis", ".", "label", ".", "set_color", "(", "'grey'", ")", "\n", "ax", ".", "xaxis", ".", "label", ".", "set_fontsize", "(", "23", ")", "\n", "ax", ".", "yaxis", ".", "label", ".", "set_fontsize", "(", "23", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'x'", ",", "colors", "=", "'grey'", ",", "labelsize", "=", "23", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'y'", ",", "colors", "=", "'grey'", ",", "labelsize", "=", "23", ")", "\n", "plt", ".", "plot", "(", "array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.plot_spec": [[110, 115], ["numpy.flip", "matplotlib.figure", "matplotlib.imshow", "matplotlib.show"], "function", ["None"], ["", "def", "plot_spec", "(", "M", ")", ":", "\n", "    ", "M", "=", "np", ".", "flip", "(", "M", ",", "axis", "=", "0", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "18", ",", "4", ")", ")", "\n", "plt", ".", "imshow", "(", "M", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.inference.load_model": [[8, 33], ["vocoder.models.fatchord_version.WaveRNN().cuda", "torch.load", "WaveRNN().cuda.load_state_dict", "WaveRNN().cuda.eval", "print", "print", "vocoder.models.fatchord_version.WaveRNN"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["def", "load_model", "(", "weights_fpath", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "global", "_model", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Building Wave-RNN\"", ")", "\n", "", "_model", "=", "WaveRNN", "(", "\n", "rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Loading model weights at %s\"", "%", "weights_fpath", ")", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "weights_fpath", ")", "\n", "_model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state'", "]", ")", "\n", "_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.inference.is_loaded": [[35, 37], ["None"], "function", ["None"], ["", "def", "is_loaded", "(", ")", ":", "\n", "    ", "return", "_model", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.inference.infer_waveform": [[39, 59], ["torch.from_numpy", "_model.generate", "Exception"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.generate"], ["", "def", "infer_waveform", "(", "mel", ",", "normalize", "=", "True", ",", "batched", "=", "True", ",", "target", "=", "8000", ",", "overlap", "=", "800", ",", "\n", "progress_callback", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Infers the waveform of a mel spectrogram output by the synthesizer (the format must match \n    that of the synthesizer!)\n    \n    :param normalize:  \n    :param batched: \n    :param target: \n    :param overlap: \n    :return: \n    \"\"\"", "\n", "if", "_model", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"Please load Wave-RNN in memory before using it\"", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "mel", "=", "mel", "/", "hp", ".", "mel_max_abs_value", "\n", "", "mel", "=", "torch", ".", "from_numpy", "(", "mel", "[", "None", ",", "...", "]", ")", "\n", "wav", "=", "_model", ".", "generate", "(", "mel", ",", "batched", ",", "target", ",", "overlap", ",", "hp", ".", "mu_law", ",", "progress_callback", ")", "\n", "return", "wav", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.vocoder_dataset.VocoderDataset.__init__": [[10, 23], ["print", "list", "print", "metadata_fpath.open", "mel_dir.joinpath", "wav_dir.joinpath", "zip", "line.split", "int", "int", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "metadata_fpath", ":", "Path", ",", "mel_dir", ":", "Path", ",", "wav_dir", ":", "Path", ")", ":", "\n", "        ", "print", "(", "\"Using inputs from:\\n\\t%s\\n\\t%s\\n\\t%s\"", "%", "(", "metadata_fpath", ",", "mel_dir", ",", "wav_dir", ")", ")", "\n", "\n", "with", "metadata_fpath", ".", "open", "(", "\"r\"", ")", "as", "metadata_file", ":", "\n", "            ", "metadata", "=", "[", "line", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "metadata_file", "]", "\n", "\n", "", "gta_fnames", "=", "[", "x", "[", "1", "]", "for", "x", "in", "metadata", "if", "int", "(", "x", "[", "4", "]", ")", "]", "\n", "gta_fpaths", "=", "[", "mel_dir", ".", "joinpath", "(", "fname", ")", "for", "fname", "in", "gta_fnames", "]", "\n", "wav_fnames", "=", "[", "x", "[", "0", "]", "for", "x", "in", "metadata", "if", "int", "(", "x", "[", "4", "]", ")", "]", "\n", "wav_fpaths", "=", "[", "wav_dir", ".", "joinpath", "(", "fname", ")", "for", "fname", "in", "wav_fnames", "]", "\n", "self", ".", "samples_fpaths", "=", "list", "(", "zip", "(", "gta_fpaths", ",", "wav_fpaths", ")", ")", "\n", "\n", "print", "(", "\"Found %d samples\"", "%", "len", "(", "self", ".", "samples_fpaths", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.vocoder_dataset.VocoderDataset.__getitem__": [[24, 53], ["numpy.load", "numpy.clip", "numpy.pad", "numpy.load().T.astype", "vocoder.audio.pre_emphasis", "len", "len", "mel.astype", "vocoder.audio.float_2_label.astype", "len", "vocoder.audio.encode_mu_law", "vocoder.audio.float_2_label", "vocoder.audio.float_2_label", "numpy.load", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.pre_emphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.encode_mu_law", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.float_2_label", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.float_2_label", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "mel_path", ",", "wav_path", "=", "self", ".", "samples_fpaths", "[", "index", "]", "\n", "\n", "# Load the mel spectrogram and adjust its range to [-1, 1]", "\n", "mel", "=", "np", ".", "load", "(", "mel_path", ")", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", "/", "hp", ".", "mel_max_abs_value", "\n", "\n", "# Load the wav", "\n", "wav", "=", "np", ".", "load", "(", "wav_path", ")", "\n", "if", "hp", ".", "apply_preemphasis", ":", "\n", "            ", "wav", "=", "audio", ".", "pre_emphasis", "(", "wav", ")", "\n", "", "wav", "=", "np", ".", "clip", "(", "wav", ",", "-", "1", ",", "1", ")", "\n", "\n", "# Fix for missing padding   # TODO: settle on whether this is any useful", "\n", "r_pad", "=", "(", "len", "(", "wav", ")", "//", "hp", ".", "hop_length", "+", "1", ")", "*", "hp", ".", "hop_length", "-", "len", "(", "wav", ")", "\n", "wav", "=", "np", ".", "pad", "(", "wav", ",", "(", "0", ",", "r_pad", ")", ",", "mode", "=", "'constant'", ")", "\n", "assert", "len", "(", "wav", ")", ">=", "mel", ".", "shape", "[", "1", "]", "*", "hp", ".", "hop_length", "\n", "wav", "=", "wav", "[", ":", "mel", ".", "shape", "[", "1", "]", "*", "hp", ".", "hop_length", "]", "\n", "assert", "len", "(", "wav", ")", "%", "hp", ".", "hop_length", "==", "0", "\n", "\n", "# Quantize the wav", "\n", "if", "hp", ".", "voc_mode", "==", "'RAW'", ":", "\n", "            ", "if", "hp", ".", "mu_law", ":", "\n", "                ", "quant", "=", "audio", ".", "encode_mu_law", "(", "wav", ",", "mu", "=", "2", "**", "hp", ".", "bits", ")", "\n", "", "else", ":", "\n", "                ", "quant", "=", "audio", ".", "float_2_label", "(", "wav", ",", "bits", "=", "hp", ".", "bits", ")", "\n", "", "", "elif", "hp", ".", "voc_mode", "==", "'MOL'", ":", "\n", "            ", "quant", "=", "audio", ".", "float_2_label", "(", "wav", ",", "bits", "=", "16", ")", "\n", "\n", "", "return", "mel", ".", "astype", "(", "np", ".", "float32", ")", ",", "quant", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.vocoder_dataset.VocoderDataset.__len__": [[54, 56], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples_fpaths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.vocoder_dataset.collate_vocoder": [[58, 85], ["numpy.stack().astype", "numpy.stack().astype", "torch.tensor", "torch.tensor().long", "vocoder.audio.label_2_float", "numpy.random.randint", "audio.label_2_float.float", "vocoder.audio.label_2_float", "enumerate", "enumerate", "numpy.stack", "numpy.stack", "torch.tensor", "audio.label_2_float.float"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.label_2_float", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.label_2_float"], ["", "", "def", "collate_vocoder", "(", "batch", ")", ":", "\n", "    ", "mel_win", "=", "hp", ".", "voc_seq_len", "//", "hp", ".", "hop_length", "+", "2", "*", "hp", ".", "voc_pad", "\n", "max_offsets", "=", "[", "x", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "-", "2", "-", "(", "mel_win", "+", "2", "*", "hp", ".", "voc_pad", ")", "for", "x", "in", "batch", "]", "\n", "mel_offsets", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "offset", ")", "for", "offset", "in", "max_offsets", "]", "\n", "sig_offsets", "=", "[", "(", "offset", "+", "hp", ".", "voc_pad", ")", "*", "hp", ".", "hop_length", "for", "offset", "in", "mel_offsets", "]", "\n", "\n", "mels", "=", "[", "x", "[", "0", "]", "[", ":", ",", "mel_offsets", "[", "i", "]", ":", "mel_offsets", "[", "i", "]", "+", "mel_win", "]", "for", "i", ",", "x", "in", "enumerate", "(", "batch", ")", "]", "\n", "\n", "labels", "=", "[", "x", "[", "1", "]", "[", "sig_offsets", "[", "i", "]", ":", "sig_offsets", "[", "i", "]", "+", "hp", ".", "voc_seq_len", "+", "1", "]", "for", "i", ",", "x", "in", "enumerate", "(", "batch", ")", "]", "\n", "\n", "mels", "=", "np", ".", "stack", "(", "mels", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels", "=", "np", ".", "stack", "(", "labels", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "mels", "=", "torch", ".", "tensor", "(", "mels", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", ".", "long", "(", ")", "\n", "\n", "x", "=", "labels", "[", ":", ",", ":", "hp", ".", "voc_seq_len", "]", "\n", "y", "=", "labels", "[", ":", ",", "1", ":", "]", "\n", "\n", "bits", "=", "16", "if", "hp", ".", "voc_mode", "==", "'MOL'", "else", "hp", ".", "bits", "\n", "\n", "x", "=", "audio", ".", "label_2_float", "(", "x", ".", "float", "(", ")", ",", "bits", ")", "\n", "\n", "if", "hp", ".", "voc_mode", "==", "'MOL'", ":", "\n", "        ", "y", "=", "audio", ".", "label_2_float", "(", "y", ".", "float", "(", ")", ",", "bits", ")", "\n", "\n", "", "return", "x", ",", "y", ",", "mels", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.label_2_float": [[8, 10], ["None"], "function", ["None"], ["def", "label_2_float", "(", "x", ",", "bits", ")", ":", "\n", "    ", "return", "2", "*", "x", "/", "(", "2", "**", "bits", "-", "1.", ")", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.float_2_label": [[12, 16], ["x.clip", "abs().max", "abs"], "function", ["None"], ["", "def", "float_2_label", "(", "x", ",", "bits", ")", ":", "\n", "    ", "assert", "abs", "(", "x", ")", ".", "max", "(", ")", "<=", "1.0", "\n", "x", "=", "(", "x", "+", "1.", ")", "*", "(", "2", "**", "bits", "-", "1", ")", "/", "2", "\n", "return", "x", ".", "clip", "(", "0", ",", "2", "**", "bits", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.load_wav": [[18, 20], ["librosa.load"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["", "def", "load_wav", "(", "path", ")", ":", "\n", "    ", "return", "librosa", ".", "load", "(", "path", ",", "sr", "=", "hp", ".", "sample_rate", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.save_wav": [[22, 24], ["librosa.output.write_wav", "x.astype"], "function", ["None"], ["", "def", "save_wav", "(", "x", ",", "path", ")", ":", "\n", "    ", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "x", ".", "astype", "(", "np", ".", "float32", ")", ",", "sr", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.split_signal": [[26, 31], ["None"], "function", ["None"], ["", "def", "split_signal", "(", "x", ")", ":", "\n", "    ", "unsigned", "=", "x", "+", "2", "**", "15", "\n", "coarse", "=", "unsigned", "//", "256", "\n", "fine", "=", "unsigned", "%", "256", "\n", "return", "coarse", ",", "fine", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.combine_signal": [[33, 35], ["None"], "function", ["None"], ["", "def", "combine_signal", "(", "coarse", ",", "fine", ")", ":", "\n", "    ", "return", "coarse", "*", "256", "+", "fine", "-", "2", "**", "15", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.encode_16bits": [[37, 39], ["numpy.clip().astype", "numpy.clip"], "function", ["None"], ["", "def", "encode_16bits", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "x", "*", "2", "**", "15", ",", "-", "2", "**", "15", ",", "2", "**", "15", "-", "1", ")", ".", "astype", "(", "np", ".", "int16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.linear_to_mel": [[44, 49], ["numpy.dot", "audio.build_mel_basis"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.build_mel_basis"], ["def", "linear_to_mel", "(", "spectrogram", ")", ":", "\n", "    ", "global", "mel_basis", "\n", "if", "mel_basis", "is", "None", ":", "\n", "        ", "mel_basis", "=", "build_mel_basis", "(", ")", "\n", "", "return", "np", ".", "dot", "(", "mel_basis", ",", "spectrogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.build_mel_basis": [[51, 53], ["librosa.filters.mel"], "function", ["None"], ["", "def", "build_mel_basis", "(", ")", ":", "\n", "    ", "return", "librosa", ".", "filters", ".", "mel", "(", "hp", ".", "sample_rate", ",", "hp", ".", "n_fft", ",", "n_mels", "=", "hp", ".", "num_mels", ",", "fmin", "=", "hp", ".", "fmin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.normalize": [[55, 57], ["numpy.clip"], "function", ["None"], ["", "def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "-", "hp", ".", "min_level_db", ")", "/", "-", "hp", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.denormalize": [[59, 61], ["numpy.clip"], "function", ["None"], ["", "def", "denormalize", "(", "S", ")", ":", "\n", "    ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "hp", ".", "min_level_db", ")", "+", "hp", ".", "min_level_db", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.amp_to_db": [[63, 65], ["numpy.log10", "numpy.maximum"], "function", ["None"], ["", "def", "amp_to_db", "(", "x", ")", ":", "\n", "    ", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.db_to_amp": [[67, 69], ["numpy.power"], "function", ["None"], ["", "def", "db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.spectrogram": [[71, 75], ["audio.stft", "audio.normalize", "audio.amp_to_db", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.normalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.amp_to_db"], ["", "def", "spectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "np", ".", "abs", "(", "D", ")", ")", "-", "hp", ".", "ref_level_db", "\n", "return", "normalize", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.melspectrogram": [[77, 81], ["audio.stft", "audio.amp_to_db", "audio.normalize", "audio.linear_to_mel", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.normalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.linear_to_mel"], ["", "def", "melspectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "\n", "return", "normalize", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft": [[83, 85], ["librosa.stft"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft"], ["", "def", "stft", "(", "y", ")", ":", "\n", "    ", "return", "librosa", ".", "stft", "(", "y", "=", "y", ",", "n_fft", "=", "hp", ".", "n_fft", ",", "hop_length", "=", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.pre_emphasis": [[87, 89], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "pre_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "[", "1", "]", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.de_emphasis": [[91, 93], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "de_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.encode_mu_law": [[95, 99], ["numpy.floor", "numpy.log", "numpy.sign", "numpy.log", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log"], ["", "def", "encode_mu_law", "(", "x", ",", "mu", ")", ":", "\n", "    ", "mu", "=", "mu", "-", "1", "\n", "fx", "=", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "x", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "return", "np", ".", "floor", "(", "(", "fx", "+", "1", ")", "/", "2", "*", "mu", "+", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.decode_mu_law": [[101, 107], ["audio.label_2_float", "math.log2", "numpy.sign", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.label_2_float"], ["", "def", "decode_mu_law", "(", "y", ",", "mu", ",", "from_labels", "=", "True", ")", ":", "\n", "    ", "if", "from_labels", ":", "\n", "        ", "y", "=", "label_2_float", "(", "y", ",", "math", ".", "log2", "(", "mu", ")", ")", "\n", "", "mu", "=", "mu", "-", "1", "\n", "x", "=", "np", ".", "sign", "(", "y", ")", "/", "mu", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "y", ")", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.train.train": [[15, 120], ["print", "vocoder.models.fatchord_version.WaveRNN().cuda", "torch.optim.Adam", "models_dir.joinpath", "models_dir.joinpath.mkdir", "models_dir.joinpath.joinpath", "syn_dir.joinpath", "vocoder.vocoder_dataset.VocoderDataset", "torch.utils.data.DataLoader", "vocoder.display.simple_table", "range", "WaveRNN().cuda.parameters", "print", "WaveRNN().cuda.save", "print", "WaveRNN().cuda.load", "print", "syn_dir.joinpath", "voc_dir.joinpath", "syn_dir.joinpath", "voc_dir.joinpath", "torch.utils.data.DataLoader", "time.time", "enumerate", "vocoder.gen_wavernn.gen_testset", "print", "numpy.cumprod", "vocoder.models.fatchord_version.WaveRNN", "model_dir.joinpath.exists", "WaveRNN().cuda.", "y.float.unsqueeze", "loss_func", "optim.Adam.zero_grad", "loss_func.backward", "optim.Adam.step", "loss_func.item", "WaveRNN().cuda.get_step", "vocoder.display.stream", "x.cuda", "m.cuda", "y.float.cuda", "y_hat.transpose().unsqueeze.transpose().unsqueeze", "WaveRNN().cuda.checkpoint", "WaveRNN().cuda.save", "y.float.float", "time.time", "len", "y_hat.transpose().unsqueeze.transpose"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.simple_table", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.gen_wavernn.gen_testset", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.step", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_step", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.stream", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.checkpoint", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save"], ["def", "train", "(", "run_id", ":", "str", ",", "syn_dir", ":", "Path", ",", "voc_dir", ":", "Path", ",", "models_dir", ":", "Path", ",", "ground_truth", ":", "bool", ",", "\n", "save_every", ":", "int", ",", "backup_every", ":", "int", ",", "force_restart", ":", "bool", ")", ":", "\n", "# Check to make sure the hop length is correctly factorised", "\n", "    ", "assert", "np", ".", "cumprod", "(", "hp", ".", "voc_upsample_factors", ")", "[", "-", "1", "]", "==", "hp", ".", "hop_length", "\n", "\n", "# Instantiate the model", "\n", "print", "(", "\"Initializing the model...\"", ")", "\n", "model", "=", "WaveRNN", "(", "\n", "rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "# Initialize the optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "for", "p", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "p", "[", "\"lr\"", "]", "=", "hp", ".", "voc_lr", "\n", "", "loss_func", "=", "F", ".", "cross_entropy", "if", "model", ".", "mode", "==", "\"RAW\"", "else", "discretized_mix_logistic_loss", "\n", "\n", "# Load the weights", "\n", "model_dir", "=", "models_dir", ".", "joinpath", "(", "run_id", ")", "\n", "model_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "weights_fpath", "=", "model_dir", ".", "joinpath", "(", "run_id", "+", "\".pt\"", ")", "\n", "if", "force_restart", "or", "not", "weights_fpath", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "\"\\nStarting the training of WaveRNN from scratch\\n\"", ")", "\n", "model", ".", "save", "(", "weights_fpath", ",", "optimizer", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"\\nLoading weights at %s\"", "%", "weights_fpath", ")", "\n", "model", ".", "load", "(", "weights_fpath", ",", "optimizer", ")", "\n", "print", "(", "\"WaveRNN weights loaded from step %d\"", "%", "model", ".", "step", ")", "\n", "\n", "# Initialize the dataset", "\n", "", "metadata_fpath", "=", "syn_dir", ".", "joinpath", "(", "\"train.txt\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"synthesized.txt\"", ")", "\n", "mel_dir", "=", "syn_dir", ".", "joinpath", "(", "\"mels\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"mels_gta\"", ")", "\n", "wav_dir", "=", "syn_dir", ".", "joinpath", "(", "\"audio\"", ")", "\n", "dataset", "=", "VocoderDataset", "(", "metadata_fpath", ",", "mel_dir", ",", "wav_dir", ")", "\n", "test_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "# Begin the training", "\n", "simple_table", "(", "[", "(", "'Batch size'", ",", "hp", ".", "voc_batch_size", ")", ",", "\n", "(", "'LR'", ",", "hp", ".", "voc_lr", ")", ",", "\n", "(", "'Sequence Len'", ",", "hp", ".", "voc_seq_len", ")", "]", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "350", ")", ":", "\n", "        ", "data_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "collate_fn", "=", "collate_vocoder", ",", "\n", "batch_size", "=", "hp", ".", "voc_batch_size", ",", "\n", "num_workers", "=", "2", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "running_loss", "=", "0.", "\n", "\n", "for", "i", ",", "(", "x", ",", "y", ",", "m", ")", "in", "enumerate", "(", "data_loader", ",", "1", ")", ":", "\n", "            ", "x", ",", "m", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "m", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "\n", "# Forward pass", "\n", "y_hat", "=", "model", "(", "x", ",", "m", ")", "\n", "if", "model", ".", "mode", "==", "'RAW'", ":", "\n", "                ", "y_hat", "=", "y_hat", ".", "transpose", "(", "1", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "elif", "model", ".", "mode", "==", "'MOL'", ":", "\n", "                ", "y", "=", "y", ".", "float", "(", ")", "\n", "", "y", "=", "y", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Backward pass", "\n", "loss", "=", "loss_func", "(", "y_hat", ",", "y", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "speed", "=", "i", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "avg_loss", "=", "running_loss", "/", "i", "\n", "\n", "step", "=", "model", ".", "get_step", "(", ")", "\n", "k", "=", "step", "//", "1000", "\n", "\n", "if", "backup_every", "!=", "0", "and", "step", "%", "backup_every", "==", "0", ":", "\n", "                ", "model", ".", "checkpoint", "(", "model_dir", ",", "optimizer", ")", "\n", "\n", "", "if", "save_every", "!=", "0", "and", "step", "%", "save_every", "==", "0", ":", "\n", "                ", "model", ".", "save", "(", "weights_fpath", ",", "optimizer", ")", "\n", "\n", "", "msg", "=", "f\"| Epoch: {epoch} ({i}/{len(data_loader)}) | \"", "f\"Loss: {avg_loss:.4f} | {speed:.1f} \"", "f\"steps/s | Step: {k}k | \"", "\n", "stream", "(", "msg", ")", "\n", "\n", "\n", "", "gen_testset", "(", "model", ",", "test_loader", ",", "hp", ".", "voc_gen_at_checkpoint", ",", "hp", ".", "voc_gen_batched", ",", "\n", "hp", ".", "voc_target", ",", "hp", ".", "voc_overlap", ",", "model_dir", ")", "\n", "print", "(", "\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.gen_wavernn.gen_testset": [[5, 31], ["enumerate", "model.get_step", "print", "x[].numpy", "save_wav", "save_path.joinpath", "model.generate", "save_wav", "decode_mu_law", "label_2_float", "save_path.joinpath"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_step", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.generate", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.decode_mu_law", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.label_2_float"], ["def", "gen_testset", "(", "model", ":", "WaveRNN", ",", "test_set", ",", "samples", ",", "batched", ",", "target", ",", "overlap", ",", "save_path", ")", ":", "\n", "    ", "k", "=", "model", ".", "get_step", "(", ")", "//", "1000", "\n", "\n", "for", "i", ",", "(", "m", ",", "x", ")", "in", "enumerate", "(", "test_set", ",", "1", ")", ":", "\n", "        ", "if", "i", ">", "samples", ":", "\n", "            ", "break", "\n", "\n", "", "print", "(", "'\\n| Generating: %i/%i'", "%", "(", "i", ",", "samples", ")", ")", "\n", "\n", "x", "=", "x", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "bits", "=", "16", "if", "hp", ".", "voc_mode", "==", "'MOL'", "else", "hp", ".", "bits", "\n", "\n", "if", "hp", ".", "mu_law", "and", "hp", ".", "voc_mode", "!=", "'MOL'", ":", "\n", "            ", "x", "=", "decode_mu_law", "(", "x", ",", "2", "**", "bits", ",", "from_labels", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "label_2_float", "(", "x", ",", "bits", ")", "\n", "\n", "", "save_wav", "(", "x", ",", "save_path", ".", "joinpath", "(", "\"%dk_steps_%d_target.wav\"", "%", "(", "k", ",", "i", ")", ")", ")", "\n", "\n", "batch_str", "=", "\"gen_batched_target%d_overlap%d\"", "%", "(", "target", ",", "overlap", ")", "if", "batched", "else", "\"gen_not_batched\"", "\n", "save_str", "=", "save_path", ".", "joinpath", "(", "\"%dk_steps_%d_%s.wav\"", "%", "(", "k", ",", "i", ",", "batch_str", ")", ")", "\n", "\n", "wav", "=", "model", ".", "generate", "(", "m", ",", "batched", ",", "target", ",", "overlap", ",", "hp", ".", "mu_law", ")", "\n", "save_wav", "(", "wav", ",", "save_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.log_sum_exp": [[6, 13], ["torch.max", "torch.max", "torch.max", "torch.max", "len", "torch.log", "torch.log", "x.size", "torch.sum", "torch.sum", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["def", "log_sum_exp", "(", "x", ")", ":", "\n", "    ", "\"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"", "\n", "# TF ordering", "\n", "axis", "=", "len", "(", "x", ".", "size", "(", ")", ")", "-", "1", "\n", "m", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "axis", ")", "\n", "m2", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "axis", ",", "keepdim", "=", "True", ")", "\n", "return", "m", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "x", "-", "m2", ")", ",", "dim", "=", "axis", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.discretized_mix_logistic_loss": [[16, 85], ["y_hat.transpose.permute", "y_hat.transpose.transpose", "torch.clamp", "torch.clamp", "y.expand_as.expand_as", "torch.exp", "torch.exp", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "float", "y_hat.transpose.dim", "y_hat.transpose.size", "torch.softplus", "torch.softplus", "torch.log_softmax", "numpy.log", "y_hat.transpose.size", "torch.softplus", "torch.log", "torch.log", "torch.mean", "torch.mean", "log_sum_exp().unsqueeze", "torch.clamp", "torch.clamp", "numpy.log", "distribution.log_sum_exp", "distribution.log_sum_exp"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.log_sum_exp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.log_sum_exp"], ["", "def", "discretized_mix_logistic_loss", "(", "y_hat", ",", "y", ",", "num_classes", "=", "65536", ",", "\n", "log_scale_min", "=", "None", ",", "reduce", "=", "True", ")", ":", "\n", "    ", "if", "log_scale_min", "is", "None", ":", "\n", "        ", "log_scale_min", "=", "float", "(", "np", ".", "log", "(", "1e-14", ")", ")", "\n", "", "y_hat", "=", "y_hat", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "assert", "y_hat", ".", "dim", "(", ")", "==", "3", "\n", "assert", "y_hat", ".", "size", "(", "1", ")", "%", "3", "==", "0", "\n", "nr_mix", "=", "y_hat", ".", "size", "(", "1", ")", "//", "3", "\n", "\n", "# (B x T x C)", "\n", "y_hat", "=", "y_hat", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# unpack parameters. (B, T, num_mixtures) x 3", "\n", "logit_probs", "=", "y_hat", "[", ":", ",", ":", ",", ":", "nr_mix", "]", "\n", "means", "=", "y_hat", "[", ":", ",", ":", ",", "nr_mix", ":", "2", "*", "nr_mix", "]", "\n", "log_scales", "=", "torch", ".", "clamp", "(", "y_hat", "[", ":", ",", ":", ",", "2", "*", "nr_mix", ":", "3", "*", "nr_mix", "]", ",", "min", "=", "log_scale_min", ")", "\n", "\n", "# B x T x 1 -> B x T x num_mixtures", "\n", "y", "=", "y", ".", "expand_as", "(", "means", ")", "\n", "\n", "centered_y", "=", "y", "-", "means", "\n", "inv_stdv", "=", "torch", ".", "exp", "(", "-", "log_scales", ")", "\n", "plus_in", "=", "inv_stdv", "*", "(", "centered_y", "+", "1.", "/", "(", "num_classes", "-", "1", ")", ")", "\n", "cdf_plus", "=", "torch", ".", "sigmoid", "(", "plus_in", ")", "\n", "min_in", "=", "inv_stdv", "*", "(", "centered_y", "-", "1.", "/", "(", "num_classes", "-", "1", ")", ")", "\n", "cdf_min", "=", "torch", ".", "sigmoid", "(", "min_in", ")", "\n", "\n", "# log probability for edge case of 0 (before scaling)", "\n", "# equivalent: torch.log(F.sigmoid(plus_in))", "\n", "log_cdf_plus", "=", "plus_in", "-", "F", ".", "softplus", "(", "plus_in", ")", "\n", "\n", "# log probability for edge case of 255 (before scaling)", "\n", "# equivalent: (1 - F.sigmoid(min_in)).log()", "\n", "log_one_minus_cdf_min", "=", "-", "F", ".", "softplus", "(", "min_in", ")", "\n", "\n", "# probability for all other cases", "\n", "cdf_delta", "=", "cdf_plus", "-", "cdf_min", "\n", "\n", "mid_in", "=", "inv_stdv", "*", "centered_y", "\n", "# log probability in the center of the bin, to be used in extreme cases", "\n", "# (not actually used in our code)", "\n", "log_pdf_mid", "=", "mid_in", "-", "log_scales", "-", "2.", "*", "F", ".", "softplus", "(", "mid_in", ")", "\n", "\n", "# tf equivalent", "\n", "\"\"\"\n    log_probs = tf.where(x < -0.999, log_cdf_plus,\n                         tf.where(x > 0.999, log_one_minus_cdf_min,\n                                  tf.where(cdf_delta > 1e-5,\n                                           tf.log(tf.maximum(cdf_delta, 1e-12)),\n                                           log_pdf_mid - np.log(127.5))))\n    \"\"\"", "\n", "# TODO: cdf_delta <= 1e-5 actually can happen. How can we choose the value", "\n", "# for num_classes=65536 case? 1e-7? not sure..", "\n", "inner_inner_cond", "=", "(", "cdf_delta", ">", "1e-5", ")", ".", "float", "(", ")", "\n", "\n", "inner_inner_out", "=", "inner_inner_cond", "*", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "cdf_delta", ",", "min", "=", "1e-12", ")", ")", "+", "(", "1.", "-", "inner_inner_cond", ")", "*", "(", "log_pdf_mid", "-", "np", ".", "log", "(", "(", "num_classes", "-", "1", ")", "/", "2", ")", ")", "\n", "inner_cond", "=", "(", "y", ">", "0.999", ")", ".", "float", "(", ")", "\n", "inner_out", "=", "inner_cond", "*", "log_one_minus_cdf_min", "+", "(", "1.", "-", "inner_cond", ")", "*", "inner_inner_out", "\n", "cond", "=", "(", "y", "<", "-", "0.999", ")", ".", "float", "(", ")", "\n", "log_probs", "=", "cond", "*", "log_cdf_plus", "+", "(", "1.", "-", "cond", ")", "*", "inner_out", "\n", "\n", "log_probs", "=", "log_probs", "+", "F", ".", "log_softmax", "(", "logit_probs", ",", "-", "1", ")", "\n", "\n", "if", "reduce", ":", "\n", "        ", "return", "-", "torch", ".", "mean", "(", "log_sum_exp", "(", "log_probs", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "-", "log_sum_exp", "(", "log_probs", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.sample_from_discretized_mix_logistic": [[87, 124], ["y.transpose.transpose", "logit_probs.data.new().uniform_", "logit_probs.data.new().uniform_.max", "distribution.to_one_hot", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.sum.data.new().uniform_", "torch.clamp", "torch.clamp", "float", "y.transpose.size", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "numpy.log", "y.transpose.size", "logit_probs.data.new", "torch.sum.data.new", "torch.exp", "torch.exp", "logit_probs.size", "torch.log", "torch.log", "torch.sum.size", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.to_one_hot", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log"], ["", "", "def", "sample_from_discretized_mix_logistic", "(", "y", ",", "log_scale_min", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Sample from discretized mixture of logistic distributions\n    Args:\n        y (Tensor): B x C x T\n        log_scale_min (float): Log scale minimum value\n    Returns:\n        Tensor: sample in range of [-1, 1].\n    \"\"\"", "\n", "if", "log_scale_min", "is", "None", ":", "\n", "        ", "log_scale_min", "=", "float", "(", "np", ".", "log", "(", "1e-14", ")", ")", "\n", "", "assert", "y", ".", "size", "(", "1", ")", "%", "3", "==", "0", "\n", "nr_mix", "=", "y", ".", "size", "(", "1", ")", "//", "3", "\n", "\n", "# B x T x C", "\n", "y", "=", "y", ".", "transpose", "(", "1", ",", "2", ")", "\n", "logit_probs", "=", "y", "[", ":", ",", ":", ",", ":", "nr_mix", "]", "\n", "\n", "# sample mixture indicator from softmax", "\n", "temp", "=", "logit_probs", ".", "data", ".", "new", "(", "logit_probs", ".", "size", "(", ")", ")", ".", "uniform_", "(", "1e-5", ",", "1.0", "-", "1e-5", ")", "\n", "temp", "=", "logit_probs", ".", "data", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "temp", ")", ")", "\n", "_", ",", "argmax", "=", "temp", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "\n", "# (B, T) -> (B, T, nr_mix)", "\n", "one_hot", "=", "to_one_hot", "(", "argmax", ",", "nr_mix", ")", "\n", "# select logistic parameters", "\n", "means", "=", "torch", ".", "sum", "(", "y", "[", ":", ",", ":", ",", "nr_mix", ":", "2", "*", "nr_mix", "]", "*", "one_hot", ",", "dim", "=", "-", "1", ")", "\n", "log_scales", "=", "torch", ".", "clamp", "(", "torch", ".", "sum", "(", "\n", "y", "[", ":", ",", ":", ",", "2", "*", "nr_mix", ":", "3", "*", "nr_mix", "]", "*", "one_hot", ",", "dim", "=", "-", "1", ")", ",", "min", "=", "log_scale_min", ")", "\n", "# sample from logistic & clip to interval", "\n", "# we don't actually round to the nearest 8bit value when sampling", "\n", "u", "=", "means", ".", "data", ".", "new", "(", "means", ".", "size", "(", ")", ")", ".", "uniform_", "(", "1e-5", ",", "1.0", "-", "1e-5", ")", "\n", "x", "=", "means", "+", "torch", ".", "exp", "(", "log_scales", ")", "*", "(", "torch", ".", "log", "(", "u", ")", "-", "torch", ".", "log", "(", "1.", "-", "u", ")", ")", "\n", "\n", "x", "=", "torch", ".", "clamp", "(", "torch", ".", "clamp", "(", "x", ",", "min", "=", "-", "1.", ")", ",", "max", "=", "1.", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.to_one_hot": [[126, 133], ["torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "one_hot.cuda.scatter_", "one_hot.cuda.cuda", "len", "tensor.unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "tensor.size", "tensor.size"], "function", ["None"], ["", "def", "to_one_hot", "(", "tensor", ",", "n", ",", "fill_with", "=", "1.", ")", ":", "\n", "# we perform one hot encore with respect to the last axis", "\n", "    ", "one_hot", "=", "torch", ".", "FloatTensor", "(", "tensor", ".", "size", "(", ")", "+", "(", "n", ",", ")", ")", ".", "zero_", "(", ")", "\n", "if", "tensor", ".", "is_cuda", ":", "\n", "        ", "one_hot", "=", "one_hot", ".", "cuda", "(", ")", "\n", "", "one_hot", ".", "scatter_", "(", "len", "(", "tensor", ".", "size", "(", ")", ")", ",", "tensor", ".", "unsqueeze", "(", "-", "1", ")", ",", "fill_with", ")", "\n", "return", "one_hot", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.__init__": [[9, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "deepmind_version.WaveRNN.num_params", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.num_params"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", "=", "896", ",", "quantisation", "=", "256", ")", ":", "\n", "        ", "super", "(", "WaveRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "split_size", "=", "hidden_size", "//", "2", "\n", "\n", "# The main matmul", "\n", "self", ".", "R", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "3", "*", "self", ".", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "# Output fc layers", "\n", "self", ".", "O1", "=", "nn", ".", "Linear", "(", "self", ".", "split_size", ",", "self", ".", "split_size", ")", "\n", "self", ".", "O2", "=", "nn", ".", "Linear", "(", "self", ".", "split_size", ",", "quantisation", ")", "\n", "self", ".", "O3", "=", "nn", ".", "Linear", "(", "self", ".", "split_size", ",", "self", ".", "split_size", ")", "\n", "self", ".", "O4", "=", "nn", ".", "Linear", "(", "self", ".", "split_size", ",", "quantisation", ")", "\n", "\n", "# Input fc layers", "\n", "self", ".", "I_coarse", "=", "nn", ".", "Linear", "(", "2", ",", "3", "*", "self", ".", "split_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "I_fine", "=", "nn", ".", "Linear", "(", "3", ",", "3", "*", "self", ".", "split_size", ",", "bias", "=", "False", ")", "\n", "\n", "# biases for the gates", "\n", "self", ".", "bias_u", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "bias_r", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "bias_e", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n", "# display num params", "\n", "self", ".", "num_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.forward": [[37, 73], ["deepmind_version.WaveRNN.R", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "deepmind_version.WaveRNN.I_coarse", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "deepmind_version.WaveRNN.I_fine", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "deepmind_version.WaveRNN.O2", "deepmind_version.WaveRNN.O4", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "deepmind_version.WaveRNN.O1", "deepmind_version.WaveRNN.O3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_y", ",", "prev_hidden", ",", "current_coarse", ")", ":", "\n", "\n", "# Main matmul - the projection is split 3 ways", "\n", "        ", "R_hidden", "=", "self", ".", "R", "(", "prev_hidden", ")", "\n", "R_u", ",", "R_r", ",", "R_e", ",", "=", "torch", ".", "split", "(", "R_hidden", ",", "self", ".", "hidden_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Project the prev input ", "\n", "coarse_input_proj", "=", "self", ".", "I_coarse", "(", "prev_y", ")", "\n", "I_coarse_u", ",", "I_coarse_r", ",", "I_coarse_e", "=", "torch", ".", "split", "(", "coarse_input_proj", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Project the prev input and current coarse sample", "\n", "fine_input", "=", "torch", ".", "cat", "(", "[", "prev_y", ",", "current_coarse", "]", ",", "dim", "=", "1", ")", "\n", "fine_input_proj", "=", "self", ".", "I_fine", "(", "fine_input", ")", "\n", "I_fine_u", ",", "I_fine_r", ",", "I_fine_e", "=", "torch", ".", "split", "(", "fine_input_proj", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# concatenate for the gates", "\n", "I_u", "=", "torch", ".", "cat", "(", "[", "I_coarse_u", ",", "I_fine_u", "]", ",", "dim", "=", "1", ")", "\n", "I_r", "=", "torch", ".", "cat", "(", "[", "I_coarse_r", ",", "I_fine_r", "]", ",", "dim", "=", "1", ")", "\n", "I_e", "=", "torch", ".", "cat", "(", "[", "I_coarse_e", ",", "I_fine_e", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute all gates for coarse and fine ", "\n", "u", "=", "F", ".", "sigmoid", "(", "R_u", "+", "I_u", "+", "self", ".", "bias_u", ")", "\n", "r", "=", "F", ".", "sigmoid", "(", "R_r", "+", "I_r", "+", "self", ".", "bias_r", ")", "\n", "e", "=", "F", ".", "tanh", "(", "r", "*", "R_e", "+", "I_e", "+", "self", ".", "bias_e", ")", "\n", "hidden", "=", "u", "*", "prev_hidden", "+", "(", "1.", "-", "u", ")", "*", "e", "\n", "\n", "# Split the hidden state", "\n", "hidden_coarse", ",", "hidden_fine", "=", "torch", ".", "split", "(", "hidden", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute outputs ", "\n", "out_coarse", "=", "self", ".", "O2", "(", "F", ".", "relu", "(", "self", ".", "O1", "(", "hidden_coarse", ")", ")", ")", "\n", "out_fine", "=", "self", ".", "O4", "(", "F", ".", "relu", "(", "self", ".", "O3", "(", "hidden_fine", ")", ")", ")", "\n", "\n", "return", "out_coarse", ",", "out_fine", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.generate": [[75, 163], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "deepmind_version.WaveRNN.init_hidden", "time.time", "range", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "torch.stack().squeeze().cpu().data.numpy", "combine_signal", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "deepmind_version.WaveRNN.I_coarse", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "deepmind_version.WaveRNN.R", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "deepmind_version.WaveRNN.O2", "torch.softmax", "torch.softmax", "torch.softmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "c_outputs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "deepmind_version.WaveRNN.I_fine", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "deepmind_version.WaveRNN.O4", "torch.softmax", "torch.softmax", "torch.softmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "f_outputs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "stream", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.distributions.Categorical.sample.unsqueeze().float", "torch.distributions.Categorical.sample.unsqueeze().float", "deepmind_version.WaveRNN.O1", "torch.distributions.Categorical.sample.float", "coarse_pred.unsqueeze", "deepmind_version.WaveRNN.O3", "time.time", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.stack().squeeze().cpu", "torch.distributions.Categorical.sample.unsqueeze", "torch.distributions.Categorical.sample.unsqueeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.init_hidden", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.combine_signal", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.stream"], ["", "def", "generate", "(", "self", ",", "seq_len", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# First split up the biases for the gates ", "\n", "            ", "b_coarse_u", ",", "b_fine_u", "=", "torch", ".", "split", "(", "self", ".", "bias_u", ",", "self", ".", "split_size", ")", "\n", "b_coarse_r", ",", "b_fine_r", "=", "torch", ".", "split", "(", "self", ".", "bias_r", ",", "self", ".", "split_size", ")", "\n", "b_coarse_e", ",", "b_fine_e", "=", "torch", ".", "split", "(", "self", ".", "bias_e", ",", "self", ".", "split_size", ")", "\n", "\n", "# Lists for the two output seqs", "\n", "c_outputs", ",", "f_outputs", "=", "[", "]", ",", "[", "]", "\n", "\n", "# Some initial inputs", "\n", "out_coarse", "=", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", ".", "cuda", "(", ")", "\n", "out_fine", "=", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "# We'll meed a hidden state", "\n", "hidden", "=", "self", ".", "init_hidden", "(", ")", "\n", "\n", "# Need a clock for display", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Loop for generation", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "\n", "# Split into two hidden states", "\n", "                ", "hidden_coarse", ",", "hidden_fine", "=", "torch", ".", "split", "(", "hidden", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Scale and concat previous predictions", "\n", "out_coarse", "=", "out_coarse", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", "/", "127.5", "-", "1.", "\n", "out_fine", "=", "out_fine", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", "/", "127.5", "-", "1.", "\n", "prev_outputs", "=", "torch", ".", "cat", "(", "[", "out_coarse", ",", "out_fine", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Project input ", "\n", "coarse_input_proj", "=", "self", ".", "I_coarse", "(", "prev_outputs", ")", "\n", "I_coarse_u", ",", "I_coarse_r", ",", "I_coarse_e", "=", "torch", ".", "split", "(", "coarse_input_proj", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Project hidden state and split 6 ways", "\n", "R_hidden", "=", "self", ".", "R", "(", "hidden", ")", "\n", "R_coarse_u", ",", "R_fine_u", ",", "R_coarse_r", ",", "R_fine_r", ",", "R_coarse_e", ",", "R_fine_e", "=", "torch", ".", "split", "(", "R_hidden", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute the coarse gates", "\n", "u", "=", "F", ".", "sigmoid", "(", "R_coarse_u", "+", "I_coarse_u", "+", "b_coarse_u", ")", "\n", "r", "=", "F", ".", "sigmoid", "(", "R_coarse_r", "+", "I_coarse_r", "+", "b_coarse_r", ")", "\n", "e", "=", "F", ".", "tanh", "(", "r", "*", "R_coarse_e", "+", "I_coarse_e", "+", "b_coarse_e", ")", "\n", "hidden_coarse", "=", "u", "*", "hidden_coarse", "+", "(", "1.", "-", "u", ")", "*", "e", "\n", "\n", "# Compute the coarse output", "\n", "out_coarse", "=", "self", ".", "O2", "(", "F", ".", "relu", "(", "self", ".", "O1", "(", "hidden_coarse", ")", ")", ")", "\n", "posterior", "=", "F", ".", "softmax", "(", "out_coarse", ",", "dim", "=", "1", ")", "\n", "distrib", "=", "torch", ".", "distributions", ".", "Categorical", "(", "posterior", ")", "\n", "out_coarse", "=", "distrib", ".", "sample", "(", ")", "\n", "c_outputs", ".", "append", "(", "out_coarse", ")", "\n", "\n", "# Project the [prev outputs and predicted coarse sample]", "\n", "coarse_pred", "=", "out_coarse", ".", "float", "(", ")", "/", "127.5", "-", "1.", "\n", "fine_input", "=", "torch", ".", "cat", "(", "[", "prev_outputs", ",", "coarse_pred", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "1", ")", "\n", "fine_input_proj", "=", "self", ".", "I_fine", "(", "fine_input", ")", "\n", "I_fine_u", ",", "I_fine_r", ",", "I_fine_e", "=", "torch", ".", "split", "(", "fine_input_proj", ",", "self", ".", "split_size", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute the fine gates", "\n", "u", "=", "F", ".", "sigmoid", "(", "R_fine_u", "+", "I_fine_u", "+", "b_fine_u", ")", "\n", "r", "=", "F", ".", "sigmoid", "(", "R_fine_r", "+", "I_fine_r", "+", "b_fine_r", ")", "\n", "e", "=", "F", ".", "tanh", "(", "r", "*", "R_fine_e", "+", "I_fine_e", "+", "b_fine_e", ")", "\n", "hidden_fine", "=", "u", "*", "hidden_fine", "+", "(", "1.", "-", "u", ")", "*", "e", "\n", "\n", "# Compute the fine output", "\n", "out_fine", "=", "self", ".", "O4", "(", "F", ".", "relu", "(", "self", ".", "O3", "(", "hidden_fine", ")", ")", ")", "\n", "posterior", "=", "F", ".", "softmax", "(", "out_fine", ",", "dim", "=", "1", ")", "\n", "distrib", "=", "torch", ".", "distributions", ".", "Categorical", "(", "posterior", ")", "\n", "out_fine", "=", "distrib", ".", "sample", "(", ")", "\n", "f_outputs", ".", "append", "(", "out_fine", ")", "\n", "\n", "# Put the hidden state back together", "\n", "hidden", "=", "torch", ".", "cat", "(", "[", "hidden_coarse", ",", "hidden_fine", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Display progress", "\n", "speed", "=", "(", "i", "+", "1", ")", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "stream", "(", "'Gen: %i/%i -- Speed: %i'", ",", "(", "i", "+", "1", ",", "seq_len", ",", "speed", ")", ")", "\n", "\n", "", "coarse", "=", "torch", ".", "stack", "(", "c_outputs", ")", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "fine", "=", "torch", ".", "stack", "(", "f_outputs", ")", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "output", "=", "combine_signal", "(", "coarse", ",", "fine", ")", "\n", "\n", "", "return", "output", ",", "coarse", ",", "fine", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.init_hidden": [[164, 166], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.deepmind_version.WaveRNN.num_params": [[167, 171], ["filter", "print", "deepmind_version.WaveRNN.parameters", "sum", "np.prod", "p.size"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "def", "num_params", "(", "self", ")", ":", "\n", "        ", "parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n", "parameters", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "parameters", "]", ")", "/", "1_000_000", "\n", "print", "(", "'Trainable Parameters: %.3f million'", "%", "parameters", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.ResBlock.__init__": [[10, 16], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dims", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "dims", ",", "dims", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "dims", ",", "dims", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm1d", "(", "dims", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm1d", "(", "dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.ResBlock.forward": [[17, 25], ["fatchord_version.ResBlock.conv1", "fatchord_version.ResBlock.batch_norm1", "torch.relu", "torch.relu", "torch.relu", "fatchord_version.ResBlock.conv2", "fatchord_version.ResBlock.batch_norm2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "batch_norm1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "batch_norm2", "(", "x", ")", "\n", "return", "x", "+", "residual", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.MelResNet.__init__": [[28, 37], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "fatchord_version.MelResNet.layers.append", "fatchord_version.ResBlock"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["    ", "def", "__init__", "(", "self", ",", "res_blocks", ",", "in_dims", ",", "compute_dims", ",", "res_out_dims", ",", "pad", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "k_size", "=", "pad", "*", "2", "+", "1", "\n", "self", ".", "conv_in", "=", "nn", ".", "Conv1d", "(", "in_dims", ",", "compute_dims", ",", "kernel_size", "=", "k_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "batch_norm", "=", "nn", ".", "BatchNorm1d", "(", "compute_dims", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "res_blocks", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "ResBlock", "(", "compute_dims", ")", ")", "\n", "", "self", ".", "conv_out", "=", "nn", ".", "Conv1d", "(", "compute_dims", ",", "res_out_dims", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.MelResNet.forward": [[38, 45], ["fatchord_version.MelResNet.conv_in", "fatchord_version.MelResNet.batch_norm", "torch.relu", "torch.relu", "torch.relu", "fatchord_version.MelResNet.conv_out", "f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_in", "(", "x", ")", "\n", "x", "=", "self", ".", "batch_norm", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "for", "f", "in", "self", ".", "layers", ":", "x", "=", "f", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_out", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.Stretch2d.__init__": [[48, 52], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["    ", "def", "__init__", "(", "self", ",", "x_scale", ",", "y_scale", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "x_scale", "=", "x_scale", "\n", "self", ".", "y_scale", "=", "y_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.Stretch2d.forward": [[53, 58], ["x.repeat.repeat.size", "x.repeat.repeat.unsqueeze().unsqueeze", "x.repeat.repeat.repeat", "x.repeat.repeat.view", "x.repeat.repeat.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "x", "=", "x", ".", "repeat", "(", "1", ",", "1", ",", "1", ",", "self", ".", "y_scale", ",", "1", ",", "self", ".", "x_scale", ")", "\n", "return", "x", ".", "view", "(", "b", ",", "c", ",", "h", "*", "self", ".", "y_scale", ",", "w", "*", "self", ".", "x_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.UpsampleNetwork.__init__": [[61, 77], ["torch.Module.__init__", "fatchord_version.MelResNet", "fatchord_version.Stretch2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "np.cumproduct", "fatchord_version.Stretch2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d.weight.data.fill_", "fatchord_version.UpsampleNetwork.up_layers.append", "fatchord_version.UpsampleNetwork.up_layers.append"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["    ", "def", "__init__", "(", "self", ",", "feat_dims", ",", "upsample_scales", ",", "compute_dims", ",", "\n", "res_blocks", ",", "res_out_dims", ",", "pad", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "total_scale", "=", "np", ".", "cumproduct", "(", "upsample_scales", ")", "[", "-", "1", "]", "\n", "self", ".", "indent", "=", "pad", "*", "total_scale", "\n", "self", ".", "resnet", "=", "MelResNet", "(", "res_blocks", ",", "feat_dims", ",", "compute_dims", ",", "res_out_dims", ",", "pad", ")", "\n", "self", ".", "resnet_stretch", "=", "Stretch2d", "(", "total_scale", ",", "1", ")", "\n", "self", ".", "up_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "scale", "in", "upsample_scales", ":", "\n", "            ", "k_size", "=", "(", "1", ",", "scale", "*", "2", "+", "1", ")", "\n", "padding", "=", "(", "0", ",", "scale", ")", "\n", "stretch", "=", "Stretch2d", "(", "scale", ",", "1", ")", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "1", ",", "1", ",", "kernel_size", "=", "k_size", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "conv", ".", "weight", ".", "data", ".", "fill_", "(", "1.", "/", "k_size", "[", "1", "]", ")", "\n", "self", ".", "up_layers", ".", "append", "(", "stretch", ")", "\n", "self", ".", "up_layers", ".", "append", "(", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.UpsampleNetwork.forward": [[78, 86], ["fatchord_version.UpsampleNetwork.resnet().unsqueeze", "fatchord_version.UpsampleNetwork.resnet_stretch", "aux.squeeze.squeeze.squeeze", "f.unsqueeze", "f", "f.squeeze", "f.transpose", "aux.squeeze.squeeze.transpose", "fatchord_version.UpsampleNetwork.resnet"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "m", ")", ":", "\n", "        ", "aux", "=", "self", ".", "resnet", "(", "m", ")", ".", "unsqueeze", "(", "1", ")", "\n", "aux", "=", "self", ".", "resnet_stretch", "(", "aux", ")", "\n", "aux", "=", "aux", ".", "squeeze", "(", "1", ")", "\n", "m", "=", "m", ".", "unsqueeze", "(", "1", ")", "\n", "for", "f", "in", "self", ".", "up_layers", ":", "m", "=", "f", "(", "m", ")", "\n", "m", "=", "m", ".", "squeeze", "(", "1", ")", "[", ":", ",", ":", ",", "self", ".", "indent", ":", "-", "self", ".", "indent", "]", "\n", "return", "m", ".", "transpose", "(", "1", ",", "2", ")", ",", "aux", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.__init__": [[89, 117], ["torch.Module.__init__", "fatchord_version.UpsampleNetwork", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "fatchord_version.WaveRNN.num_params", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "RuntimeError", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.num_params"], ["    ", "def", "__init__", "(", "self", ",", "rnn_dims", ",", "fc_dims", ",", "bits", ",", "pad", ",", "upsample_factors", ",", "\n", "feat_dims", ",", "compute_dims", ",", "res_out_dims", ",", "res_blocks", ",", "\n", "hop_length", ",", "sample_rate", ",", "mode", "=", "'RAW'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "pad", "=", "pad", "\n", "if", "self", ".", "mode", "==", "'RAW'", ":", "\n", "            ", "self", ".", "n_classes", "=", "2", "**", "bits", "\n", "", "elif", "self", ".", "mode", "==", "'MOL'", ":", "\n", "            ", "self", ".", "n_classes", "=", "30", "\n", "", "else", ":", "\n", "            ", "RuntimeError", "(", "\"Unknown model mode value - \"", ",", "self", ".", "mode", ")", "\n", "\n", "", "self", ".", "rnn_dims", "=", "rnn_dims", "\n", "self", ".", "aux_dims", "=", "res_out_dims", "//", "4", "\n", "self", ".", "hop_length", "=", "hop_length", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n", "self", ".", "upsample", "=", "UpsampleNetwork", "(", "feat_dims", ",", "upsample_factors", ",", "compute_dims", ",", "res_blocks", ",", "res_out_dims", ",", "pad", ")", "\n", "self", ".", "I", "=", "nn", ".", "Linear", "(", "feat_dims", "+", "self", ".", "aux_dims", "+", "1", ",", "rnn_dims", ")", "\n", "self", ".", "rnn1", "=", "nn", ".", "GRU", "(", "rnn_dims", ",", "rnn_dims", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "rnn2", "=", "nn", ".", "GRU", "(", "rnn_dims", "+", "self", ".", "aux_dims", ",", "rnn_dims", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "rnn_dims", "+", "self", ".", "aux_dims", ",", "fc_dims", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "fc_dims", "+", "self", ".", "aux_dims", ",", "fc_dims", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "fc_dims", ",", "self", ".", "n_classes", ")", "\n", "\n", "self", ".", "step", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ".", "long", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "num_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.forward": [[118, 148], ["torch.relu.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "fatchord_version.WaveRNN.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fatchord_version.WaveRNN.I", "fatchord_version.WaveRNN.rnn1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fatchord_version.WaveRNN.rnn2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "fatchord_version.WaveRNN.fc3", "fatchord_version.WaveRNN.fc1", "fatchord_version.WaveRNN.fc2", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.relu.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mels", ")", ":", "\n", "        ", "self", ".", "step", "+=", "1", "\n", "bsize", "=", "x", ".", "size", "(", "0", ")", "\n", "h1", "=", "torch", ".", "zeros", "(", "1", ",", "bsize", ",", "self", ".", "rnn_dims", ")", ".", "cuda", "(", ")", "\n", "h2", "=", "torch", ".", "zeros", "(", "1", ",", "bsize", ",", "self", ".", "rnn_dims", ")", ".", "cuda", "(", ")", "\n", "mels", ",", "aux", "=", "self", ".", "upsample", "(", "mels", ")", "\n", "\n", "aux_idx", "=", "[", "self", ".", "aux_dims", "*", "i", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "a1", "=", "aux", "[", ":", ",", ":", ",", "aux_idx", "[", "0", "]", ":", "aux_idx", "[", "1", "]", "]", "\n", "a2", "=", "aux", "[", ":", ",", ":", ",", "aux_idx", "[", "1", "]", ":", "aux_idx", "[", "2", "]", "]", "\n", "a3", "=", "aux", "[", ":", ",", ":", ",", "aux_idx", "[", "2", "]", ":", "aux_idx", "[", "3", "]", "]", "\n", "a4", "=", "aux", "[", ":", ",", ":", ",", "aux_idx", "[", "3", "]", ":", "aux_idx", "[", "4", "]", "]", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "unsqueeze", "(", "-", "1", ")", ",", "mels", ",", "a1", "]", ",", "dim", "=", "2", ")", "\n", "x", "=", "self", ".", "I", "(", "x", ")", "\n", "res", "=", "x", "\n", "x", ",", "_", "=", "self", ".", "rnn1", "(", "x", ",", "h1", ")", "\n", "\n", "x", "=", "x", "+", "res", "\n", "res", "=", "x", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "a2", "]", ",", "dim", "=", "2", ")", "\n", "x", ",", "_", "=", "self", ".", "rnn2", "(", "x", ",", "h2", ")", "\n", "\n", "x", "=", "x", "+", "res", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "a3", "]", ",", "dim", "=", "2", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "a4", "]", ",", "dim", "=", "2", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "return", "self", ".", "fc3", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.generate": [[149, 243], ["fatchord_version.WaveRNN.eval", "time.time", "fatchord_version.WaveRNN.get_gru_cell", "fatchord_version.WaveRNN.get_gru_cell", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "de_emphasis.cpu().numpy", "de_emphasis.astype", "np.linspace", "fatchord_version.WaveRNN.train", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fatchord_version.WaveRNN.cuda", "fatchord_version.WaveRNN.pad_tensor", "fatchord_version.WaveRNN.upsample", "fatchord_version.WaveRNN.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "fatchord_version.WaveRNN.xfade_and_unfold", "decode_mu_law", "de_emphasis", "fatchord_version.WaveRNN.transpose", "fatchord_version.WaveRNN.transpose", "fatchord_version.WaveRNN.fold_with_overlap", "fatchord_version.WaveRNN.fold_with_overlap", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fatchord_version.WaveRNN.I", "fatchord_version.WaveRNN.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fatchord_version.WaveRNN.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "fatchord_version.WaveRNN.fc3", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "de_emphasis.cpu", "fatchord_version.WaveRNN.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "fatchord_version.WaveRNN.fc1", "fatchord_version.WaveRNN.fc2", "vocoder.distribution.sample_from_discretized_mix_logistic", "de_emphasis.append", "vocoder.distribution.sample_from_discretized_mix_logistic.transpose().cuda", "progress_callback", "fatchord_version.WaveRNN.unsqueeze().transpose", "vocoder.distribution.sample_from_discretized_mix_logistic.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "de_emphasis.append", "vocoder.distribution.sample_from_discretized_mix_logistic.unsqueeze", "RuntimeError", "vocoder.distribution.sample_from_discretized_mix_logistic.transpose", "fatchord_version.WaveRNN.unsqueeze", "torch.distributions.Categorical.sample().float", "torch.distributions.Categorical.sample().float", "torch.distributions.Categorical.sample().float", "time.time", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_gru_cell", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_gru_cell", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.train", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.pad_tensor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.xfade_and_unfold", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.decode_mu_law", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.de_emphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.fold_with_overlap", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.fold_with_overlap", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.distribution.sample_from_discretized_mix_logistic", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample"], ["", "def", "generate", "(", "self", ",", "mels", ",", "batched", ",", "target", ",", "overlap", ",", "mu_law", ",", "progress_callback", "=", "None", ")", ":", "\n", "        ", "mu_law", "=", "mu_law", "if", "self", ".", "mode", "==", "'RAW'", "else", "False", "\n", "progress_callback", "=", "progress_callback", "or", "self", ".", "gen_display", "\n", "\n", "self", ".", "eval", "(", ")", "\n", "output", "=", "[", "]", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "rnn1", "=", "self", ".", "get_gru_cell", "(", "self", ".", "rnn1", ")", "\n", "rnn2", "=", "self", ".", "get_gru_cell", "(", "self", ".", "rnn2", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "mels", "=", "mels", ".", "cuda", "(", ")", "\n", "wave_len", "=", "(", "mels", ".", "size", "(", "-", "1", ")", "-", "1", ")", "*", "self", ".", "hop_length", "\n", "mels", "=", "self", ".", "pad_tensor", "(", "mels", ".", "transpose", "(", "1", ",", "2", ")", ",", "pad", "=", "self", ".", "pad", ",", "side", "=", "'both'", ")", "\n", "mels", ",", "aux", "=", "self", ".", "upsample", "(", "mels", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "if", "batched", ":", "\n", "                ", "mels", "=", "self", ".", "fold_with_overlap", "(", "mels", ",", "target", ",", "overlap", ")", "\n", "aux", "=", "self", ".", "fold_with_overlap", "(", "aux", ",", "target", ",", "overlap", ")", "\n", "\n", "", "b_size", ",", "seq_len", ",", "_", "=", "mels", ".", "size", "(", ")", "\n", "\n", "h1", "=", "torch", ".", "zeros", "(", "b_size", ",", "self", ".", "rnn_dims", ")", ".", "cuda", "(", ")", "\n", "h2", "=", "torch", ".", "zeros", "(", "b_size", ",", "self", ".", "rnn_dims", ")", ".", "cuda", "(", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "b_size", ",", "1", ")", ".", "cuda", "(", ")", "\n", "\n", "d", "=", "self", ".", "aux_dims", "\n", "aux_split", "=", "[", "aux", "[", ":", ",", ":", ",", "d", "*", "i", ":", "d", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "\n", "                ", "m_t", "=", "mels", "[", ":", ",", "i", ",", ":", "]", "\n", "\n", "a1_t", ",", "a2_t", ",", "a3_t", ",", "a4_t", "=", "(", "a", "[", ":", ",", "i", ",", ":", "]", "for", "a", "in", "aux_split", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "m_t", ",", "a1_t", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "I", "(", "x", ")", "\n", "h1", "=", "rnn1", "(", "x", ",", "h1", ")", "\n", "\n", "x", "=", "x", "+", "h1", "\n", "inp", "=", "torch", ".", "cat", "(", "[", "x", ",", "a2_t", "]", ",", "dim", "=", "1", ")", "\n", "h2", "=", "rnn2", "(", "inp", ",", "h2", ")", "\n", "\n", "x", "=", "x", "+", "h2", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "a3_t", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "a4_t", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "\n", "logits", "=", "self", ".", "fc3", "(", "x", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'MOL'", ":", "\n", "                    ", "sample", "=", "sample_from_discretized_mix_logistic", "(", "logits", ".", "unsqueeze", "(", "0", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "output", ".", "append", "(", "sample", ".", "view", "(", "-", "1", ")", ")", "\n", "# x = torch.FloatTensor([[sample]]).cuda()", "\n", "x", "=", "sample", ".", "transpose", "(", "0", ",", "1", ")", ".", "cuda", "(", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'RAW'", ":", "\n", "                    ", "posterior", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "distrib", "=", "torch", ".", "distributions", ".", "Categorical", "(", "posterior", ")", "\n", "\n", "sample", "=", "2", "*", "distrib", ".", "sample", "(", ")", ".", "float", "(", ")", "/", "(", "self", ".", "n_classes", "-", "1.", ")", "-", "1.", "\n", "output", ".", "append", "(", "sample", ")", "\n", "x", "=", "sample", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Unknown model mode value - \"", ",", "self", ".", "mode", ")", "\n", "\n", "", "if", "i", "%", "100", "==", "0", ":", "\n", "                    ", "gen_rate", "=", "(", "i", "+", "1", ")", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "*", "b_size", "/", "1000", "\n", "progress_callback", "(", "i", ",", "seq_len", ",", "b_size", ",", "gen_rate", ")", "\n", "\n", "", "", "", "output", "=", "torch", ".", "stack", "(", "output", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "output", "=", "output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "output", ".", "astype", "(", "np", ".", "float64", ")", "\n", "\n", "if", "batched", ":", "\n", "            ", "output", "=", "self", ".", "xfade_and_unfold", "(", "output", ",", "target", ",", "overlap", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "output", "[", "0", "]", "\n", "\n", "", "if", "mu_law", ":", "\n", "            ", "output", "=", "decode_mu_law", "(", "output", ",", "self", ".", "n_classes", ",", "False", ")", "\n", "", "if", "hp", ".", "apply_preemphasis", ":", "\n", "            ", "output", "=", "de_emphasis", "(", "output", ")", "\n", "\n", "# Fade-out at the end to avoid signal cutting out suddenly", "\n", "", "fade_out", "=", "np", ".", "linspace", "(", "1", ",", "0", ",", "20", "*", "self", ".", "hop_length", ")", "\n", "output", "=", "output", "[", ":", "wave_len", "]", "\n", "output", "[", "-", "20", "*", "self", ".", "hop_length", ":", "]", "*=", "fade_out", "\n", "\n", "self", ".", "train", "(", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.gen_display": [[245, 249], ["progbar", "stream"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.progbar", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.display.stream"], ["", "def", "gen_display", "(", "self", ",", "i", ",", "seq_len", ",", "b_size", ",", "gen_rate", ")", ":", "\n", "        ", "pbar", "=", "progbar", "(", "i", ",", "seq_len", ")", "\n", "msg", "=", "f'| {pbar} {i*b_size}/{seq_len*b_size} | Batch Size: {b_size} | Gen Rate: {gen_rate:.1f}kHz | '", "\n", "stream", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_gru_cell": [[250, 257], ["torch.GRUCell", "torch.GRUCell", "torch.GRUCell"], "methods", ["None"], ["", "def", "get_gru_cell", "(", "self", ",", "gru", ")", ":", "\n", "        ", "gru_cell", "=", "nn", ".", "GRUCell", "(", "gru", ".", "input_size", ",", "gru", ".", "hidden_size", ")", "\n", "gru_cell", ".", "weight_hh", ".", "data", "=", "gru", ".", "weight_hh_l0", ".", "data", "\n", "gru_cell", ".", "weight_ih", ".", "data", "=", "gru", ".", "weight_ih_l0", ".", "data", "\n", "gru_cell", ".", "bias_hh", ".", "data", "=", "gru", ".", "bias_hh_l0", ".", "data", "\n", "gru_cell", ".", "bias_ih", ".", "data", "=", "gru", ".", "bias_ih_l0", ".", "data", "\n", "return", "gru_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.pad_tensor": [[258, 269], ["x.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "pad_tensor", "(", "self", ",", "x", ",", "pad", ",", "side", "=", "'both'", ")", ":", "\n", "# NB - this is just a quick method i need right now", "\n", "# i.e., it won't generalise to other shapes/dims", "\n", "        ", "b", ",", "t", ",", "c", "=", "x", ".", "size", "(", ")", "\n", "total", "=", "t", "+", "2", "*", "pad", "if", "side", "==", "'both'", "else", "t", "+", "pad", "\n", "padded", "=", "torch", ".", "zeros", "(", "b", ",", "total", ",", "c", ")", ".", "cuda", "(", ")", "\n", "if", "side", "==", "'before'", "or", "side", "==", "'both'", ":", "\n", "            ", "padded", "[", ":", ",", "pad", ":", "pad", "+", "t", ",", ":", "]", "=", "x", "\n", "", "elif", "side", "==", "'after'", ":", "\n", "            ", "padded", "[", ":", ",", ":", "t", ",", ":", "]", "=", "x", "\n", "", "return", "padded", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.fold_with_overlap": [[270, 318], ["fatchord_version.WaveRNN.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "fatchord_version.WaveRNN.pad_tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.pad_tensor"], ["", "def", "fold_with_overlap", "(", "self", ",", "x", ",", "target", ",", "overlap", ")", ":", "\n", "\n", "        ", "''' Fold the tensor with overlap for quick batched inference.\n            Overlap will be used for crossfading in xfade_and_unfold()\n\n        Args:\n            x (tensor)    : Upsampled conditioning features.\n                            shape=(1, timesteps, features)\n            target (int)  : Target timesteps for each index of batch\n            overlap (int) : Timesteps for both xfade and rnn warmup\n\n        Return:\n            (tensor) : shape=(num_folds, target + 2 * overlap, features)\n\n        Details:\n            x = [[h1, h2, ... hn]]\n\n            Where each h is a vector of conditioning features\n\n            Eg: target=2, overlap=1 with x.size(1)=10\n\n            folded = [[h1, h2, h3, h4],\n                      [h4, h5, h6, h7],\n                      [h7, h8, h9, h10]]\n        '''", "\n", "\n", "_", ",", "total_len", ",", "features", "=", "x", ".", "size", "(", ")", "\n", "\n", "# Calculate variables needed", "\n", "num_folds", "=", "(", "total_len", "-", "overlap", ")", "//", "(", "target", "+", "overlap", ")", "\n", "extended_len", "=", "num_folds", "*", "(", "overlap", "+", "target", ")", "+", "overlap", "\n", "remaining", "=", "total_len", "-", "extended_len", "\n", "\n", "# Pad if some time steps poking out", "\n", "if", "remaining", "!=", "0", ":", "\n", "            ", "num_folds", "+=", "1", "\n", "padding", "=", "target", "+", "2", "*", "overlap", "-", "remaining", "\n", "x", "=", "self", ".", "pad_tensor", "(", "x", ",", "padding", ",", "side", "=", "'after'", ")", "\n", "\n", "", "folded", "=", "torch", ".", "zeros", "(", "num_folds", ",", "target", "+", "2", "*", "overlap", ",", "features", ")", ".", "cuda", "(", ")", "\n", "\n", "# Get the values for the folded tensor", "\n", "for", "i", "in", "range", "(", "num_folds", ")", ":", "\n", "            ", "start", "=", "i", "*", "(", "target", "+", "overlap", ")", "\n", "end", "=", "start", "+", "target", "+", "2", "*", "overlap", "\n", "folded", "[", "i", "]", "=", "x", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "\n", "", "return", "folded", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.xfade_and_unfold": [[319, 382], ["np.zeros", "np.linspace", "np.sqrt", "np.sqrt", "np.concatenate", "np.concatenate", "np.zeros", "range"], "methods", ["None"], ["", "def", "xfade_and_unfold", "(", "self", ",", "y", ",", "target", ",", "overlap", ")", ":", "\n", "\n", "        ", "''' Applies a crossfade and unfolds into a 1d array.\n\n        Args:\n            y (ndarry)    : Batched sequences of audio samples\n                            shape=(num_folds, target + 2 * overlap)\n                            dtype=np.float64\n            overlap (int) : Timesteps for both xfade and rnn warmup\n\n        Return:\n            (ndarry) : audio samples in a 1d array\n                       shape=(total_len)\n                       dtype=np.float64\n\n        Details:\n            y = [[seq1],\n                 [seq2],\n                 [seq3]]\n\n            Apply a gain envelope at both ends of the sequences\n\n            y = [[seq1_in, seq1_target, seq1_out],\n                 [seq2_in, seq2_target, seq2_out],\n                 [seq3_in, seq3_target, seq3_out]]\n\n            Stagger and add up the groups of samples:\n\n            [seq1_in, seq1_target, (seq1_out + seq2_in), seq2_target, ...]\n\n        '''", "\n", "\n", "num_folds", ",", "length", "=", "y", ".", "shape", "\n", "target", "=", "length", "-", "2", "*", "overlap", "\n", "total_len", "=", "num_folds", "*", "(", "target", "+", "overlap", ")", "+", "overlap", "\n", "\n", "# Need some silence for the rnn warmup", "\n", "silence_len", "=", "overlap", "//", "2", "\n", "fade_len", "=", "overlap", "-", "silence_len", "\n", "silence", "=", "np", ".", "zeros", "(", "(", "silence_len", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "# Equal power crossfade", "\n", "t", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "fade_len", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "fade_in", "=", "np", ".", "sqrt", "(", "0.5", "*", "(", "1", "+", "t", ")", ")", "\n", "fade_out", "=", "np", ".", "sqrt", "(", "0.5", "*", "(", "1", "-", "t", ")", ")", "\n", "\n", "# Concat the silence to the fades", "\n", "fade_in", "=", "np", ".", "concatenate", "(", "[", "silence", ",", "fade_in", "]", ")", "\n", "fade_out", "=", "np", ".", "concatenate", "(", "[", "fade_out", ",", "silence", "]", ")", "\n", "\n", "# Apply the gain to the overlap samples", "\n", "y", "[", ":", ",", ":", "overlap", "]", "*=", "fade_in", "\n", "y", "[", ":", ",", "-", "overlap", ":", "]", "*=", "fade_out", "\n", "\n", "unfolded", "=", "np", ".", "zeros", "(", "(", "total_len", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "# Loop to add up all the samples", "\n", "for", "i", "in", "range", "(", "num_folds", ")", ":", "\n", "            ", "start", "=", "i", "*", "(", "target", "+", "overlap", ")", "\n", "end", "=", "start", "+", "target", "+", "2", "*", "overlap", "\n", "unfolded", "[", "start", ":", "end", "]", "+=", "y", "[", "i", "]", "\n", "\n", "", "return", "unfolded", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_step": [[383, 385], ["fatchord_version.WaveRNN.step.data.item"], "methods", ["None"], ["", "def", "get_step", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "step", ".", "data", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.checkpoint": [[386, 389], ["fatchord_version.WaveRNN.save", "fatchord_version.WaveRNN.get_step", "model_dir.joinpath"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.get_step"], ["", "def", "checkpoint", "(", "self", ",", "model_dir", ",", "optimizer", ")", ":", "\n", "        ", "k_steps", "=", "self", ".", "get_step", "(", ")", "//", "1000", "\n", "self", ".", "save", "(", "model_dir", ".", "joinpath", "(", "\"checkpoint_%dk_steps.pt\"", "%", "k_steps", ")", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.log": [[390, 393], ["open", "print"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "path", ",", "msg", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "print", "(", "msg", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.load": [[394, 402], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "fatchord_version.WaveRNN.load_state_dict", "optimizer.load_state_dict", "fatchord_version.WaveRNN.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["", "", "def", "load", "(", "self", ",", "path", ",", "optimizer", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "if", "\"optimizer_state\"", "in", "checkpoint", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state\"", "]", ")", "\n", "", "else", ":", "\n", "# Backwards compatibility", "\n", "            ", "self", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save": [[403, 408], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "fatchord_version.WaveRNN.state_dict", "optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save"], ["", "", "def", "save", "(", "self", ",", "path", ",", "optimizer", ")", ":", "\n", "        ", "torch", ".", "save", "(", "{", "\n", "\"model_state\"", ":", "self", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.num_params": [[409, 414], ["filter", "fatchord_version.WaveRNN.parameters", "sum", "print", "np.prod", "p.size"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "def", "num_params", "(", "self", ",", "print_out", "=", "True", ")", ":", "\n", "        ", "parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n", "parameters", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "parameters", "]", ")", "/", "1_000_000", "\n", "if", "print_out", ":", "\n", "            ", "print", "(", "'Trainable Parameters: %.3fM'", "%", "parameters", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronEncoderCell.__init__": [[22, 33], ["tensorflow.contrib.rnn.RNNCell.__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "convolutional_layers", ",", "lstm_layer", ")", ":", "\n", "\t\t", "\"\"\"Initialize encoder parameters\n\n\t\tArgs:\n\t\t\tconvolutional_layers: Encoder convolutional block class\n\t\t\tlstm_layer: encoder bidirectional lstm layer class\n\t\t\"\"\"", "\n", "super", "(", "TacotronEncoderCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#Initialize encoder layers", "\n", "self", ".", "_convolutions", "=", "convolutional_layers", "\n", "self", ".", "_cell", "=", "lstm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronEncoderCell.__call__": [[34, 44], ["architecture_wrappers.TacotronEncoderCell._convolutions", "architecture_wrappers.TacotronEncoderCell._cell"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "input_lengths", "=", "None", ")", ":", "\n", "#Pass input sequence through a stack of convolutional layers", "\n", "\t\t", "conv_output", "=", "self", ".", "_convolutions", "(", "inputs", ")", "\n", "\n", "#Extract hidden representation from encoder lstm cells", "\n", "hidden_representation", "=", "self", ".", "_cell", "(", "conv_output", ",", "input_lengths", ")", "\n", "\n", "#For shape visualization", "\n", "self", ".", "conv_output_shape", "=", "conv_output", ".", "shape", "\n", "return", "hidden_representation", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCellState.replace": [[62, 66], ["super()._replace"], "methods", ["None"], ["def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "\"\"\"Clones the current state while overwriting components provided by kwargs.\n\t\t\"\"\"", "\n", "return", "super", "(", "TacotronDecoderCellState", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.__init__": [[85, 107], ["tensorflow.contrib.rnn.RNNCell.__init__", "architecture_wrappers.TacotronDecoderCell._attention_mechanism.values.get_shape"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "prenet", ",", "attention_mechanism", ",", "rnn_cell", ",", "frame_projection", ",", "stop_projection", ")", ":", "\n", "\t\t", "\"\"\"Initialize decoder parameters\n\n\t\tArgs:\n\t\t    prenet: A tensorflow fully connected layer acting as the decoder pre-net\n\t\t    attention_mechanism: A _BaseAttentionMechanism instance, usefull to\n\t\t\t    learn encoder-decoder alignments\n\t\t    rnn_cell: Instance of RNNCell, main body of the decoder\n\t\t    frame_projection: tensorflow fully connected layer with r * num_mels output units\n\t\t    stop_projection: tensorflow fully connected layer, expected to project to a scalar\n\t\t\t    and through a sigmoid activation\n\t\t\tmask_finished: Boolean, Whether to mask decoder frames after the <stop_token>\n\t\t\"\"\"", "\n", "super", "(", "TacotronDecoderCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#Initialize decoder layers", "\n", "self", ".", "_prenet", "=", "prenet", "\n", "self", ".", "_attention_mechanism", "=", "attention_mechanism", "\n", "self", ".", "_cell", "=", "rnn_cell", "\n", "self", ".", "_frame_projection", "=", "frame_projection", "\n", "self", ".", "_stop_projection", "=", "stop_projection", "\n", "\n", "self", ".", "_attention_layer_size", "=", "self", ".", "_attention_mechanism", ".", "values", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell._batch_size_checks": [[108, 112], ["tensorflow.python.ops.check_ops.assert_equal"], "methods", ["None"], ["", "def", "_batch_size_checks", "(", "self", ",", "batch_size", ",", "error_message", ")", ":", "\n", "\t\t", "return", "[", "check_ops", ".", "assert_equal", "(", "batch_size", ",", "\n", "self", ".", "_attention_mechanism", ".", "batch_size", ",", "\n", "message", "=", "error_message", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.output_size": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_frame_projection", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.state_size": [[117, 130], ["architecture_wrappers.TacotronDecoderCellState", "tensorflow.python.framework.tensor_shape.TensorShape"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"The `state_size` property of `TacotronDecoderCell`.\n\n\t\tReturns:\n\t\t  An `TacotronDecoderCell` tuple containing shapes used by this object.\n\t\t\"\"\"", "\n", "return", "TacotronDecoderCellState", "(", "\n", "cell_state", "=", "self", ".", "_cell", ".", "_cell", ".", "state_size", ",", "\n", "time", "=", "tensor_shape", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "attention", "=", "self", ".", "_attention_layer_size", ",", "\n", "alignments", "=", "self", ".", "_attention_mechanism", ".", "alignments_size", ",", "\n", "alignment_history", "=", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.zero_state": [[131, 164], ["tensorflow.python.framework.ops.name_scope", "architecture_wrappers.TacotronDecoderCell._cell._cell.zero_state", "architecture_wrappers.TacotronDecoderCellState", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.util.nest.map_structure", "architecture_wrappers.TacotronDecoderCell._batch_size_checks", "tensorflow.python.ops.array_ops.zeros", "_zero_state_tensors", "architecture_wrappers.TacotronDecoderCell._attention_mechanism.initial_alignments", "tensorflow.python.ops.tensor_array_ops.TensorArray", "type", "tensorflow.python.ops.array_ops.identity"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.zero_state", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell._batch_size_checks"], ["", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "\t\t", "\"\"\"Return an initial (zero) state tuple for this `AttentionWrapper`.\n\n\t\tArgs:\n\t\t  batch_size: `0D` integer tensor: the batch size.\n\t\t  dtype: The internal state data type.\n\t\tReturns:\n\t\t  An `TacotronDecoderCellState` tuple containing zeroed out tensors and,\n\t\t  possibly, empty `TensorArray` objects.\n\t\tRaises:\n\t\t  ValueError: (or, possibly at runtime, InvalidArgument), if\n\t\t\t`batch_size` does not match the output size of the encoder passed\n\t\t\tto the wrapper object at initialization time.\n\t\t\"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "type", "(", "self", ")", ".", "__name__", "+", "\"ZeroState\"", ",", "values", "=", "[", "batch_size", "]", ")", ":", "\n", "\t\t\t", "cell_state", "=", "self", ".", "_cell", ".", "_cell", ".", "zero_state", "(", "batch_size", ",", "dtype", ")", "\n", "error_message", "=", "(", "\n", "\"When calling zero_state of TacotronDecoderCell %s: \"", "%", "self", ".", "_base_name", "+", "\n", "\"Non-matching batch sizes between the memory \"", "\n", "\"(encoder output) and the requested batch size.\"", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "\n", "self", ".", "_batch_size_checks", "(", "batch_size", ",", "error_message", ")", ")", ":", "\n", "\t\t\t\t", "cell_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "array_ops", ".", "identity", "(", "s", ",", "name", "=", "\"checked_cell_state\"", ")", ",", "\n", "cell_state", ")", "\n", "", "return", "TacotronDecoderCellState", "(", "\n", "cell_state", "=", "cell_state", ",", "\n", "time", "=", "array_ops", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "attention", "=", "_zero_state_tensors", "(", "self", ".", "_attention_layer_size", ",", "batch_size", ",", "\n", "dtype", ")", ",", "\n", "alignments", "=", "self", ".", "_attention_mechanism", ".", "initial_alignments", "(", "batch_size", ",", "dtype", ")", ",", "\n", "alignment_history", "=", "tensor_array_ops", ".", "TensorArray", "(", "dtype", "=", "dtype", ",", "size", "=", "0", ",", "\n", "dynamic_size", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.__call__": [[165, 208], ["architecture_wrappers.TacotronDecoderCell._prenet", "tensorflow.concat", "architecture_wrappers.TacotronDecoderCell._cell", "synthesizer.models.attention._compute_attention", "tensorflow.concat", "architecture_wrappers.TacotronDecoderCell._frame_projection", "architecture_wrappers.TacotronDecoderCell._stop_projection", "previous_alignment_history.write", "architecture_wrappers.TacotronDecoderCellState"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention._compute_attention"], ["", "", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "#Information bottleneck (essential for learning attention)", "\n", "\t\t", "prenet_output", "=", "self", ".", "_prenet", "(", "inputs", ")", "\n", "\n", "#Concat context vector and prenet output to form LSTM cells input (input feeding)", "\n", "LSTM_input", "=", "tf", ".", "concat", "(", "[", "prenet_output", ",", "state", ".", "attention", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "#Unidirectional LSTM layers", "\n", "LSTM_output", ",", "next_cell_state", "=", "self", ".", "_cell", "(", "LSTM_input", ",", "state", ".", "cell_state", ")", "\n", "\n", "\n", "#Compute the attention (context) vector and alignments using", "\n", "#the new decoder cell hidden state as query vector", "\n", "#and cumulative alignments to extract location features", "\n", "#The choice of the new cell hidden state (s_{i}) of the last", "\n", "#decoder RNN Cell is based on Luong et Al. (2015):", "\n", "#https://arxiv.org/pdf/1508.04025.pdf", "\n", "previous_alignments", "=", "state", ".", "alignments", "\n", "previous_alignment_history", "=", "state", ".", "alignment_history", "\n", "context_vector", ",", "alignments", ",", "cumulated_alignments", "=", "_compute_attention", "(", "self", ".", "_attention_mechanism", ",", "\n", "LSTM_output", ",", "\n", "previous_alignments", ",", "\n", "attention_layer", "=", "None", ")", "\n", "\n", "#Concat LSTM outputs and context vector to form projections inputs", "\n", "projections_input", "=", "tf", ".", "concat", "(", "[", "LSTM_output", ",", "context_vector", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "#Compute predicted frames and predicted <stop_token>", "\n", "cell_outputs", "=", "self", ".", "_frame_projection", "(", "projections_input", ")", "\n", "stop_tokens", "=", "self", ".", "_stop_projection", "(", "projections_input", ")", "\n", "\n", "#Save alignment history", "\n", "alignment_history", "=", "previous_alignment_history", ".", "write", "(", "state", ".", "time", ",", "alignments", ")", "\n", "\n", "#Prepare next decoder state", "\n", "next_state", "=", "TacotronDecoderCellState", "(", "\n", "time", "=", "state", ".", "time", "+", "1", ",", "\n", "cell_state", "=", "next_cell_state", ",", "\n", "attention", "=", "context_vector", ",", "\n", "alignments", "=", "cumulated_alignments", ",", "\n", "alignment_history", "=", "alignment_history", ")", "\n", "\n", "return", "(", "cell_outputs", ",", "stop_tokens", ")", ",", "next_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.HighwayNet.__init__": [[5, 12], ["tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.constant_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "units", ",", "name", "=", "None", ")", ":", "\n", "        ", "self", ".", "units", "=", "units", "\n", "self", ".", "scope", "=", "\"HighwayNet\"", "if", "name", "is", "None", "else", "name", "\n", "\n", "self", ".", "H_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "self", ".", "units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"H\"", ")", "\n", "self", ".", "T_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "self", ".", "units", ",", "activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "name", "=", "\"T\"", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "-", "1.", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.HighwayNet.__call__": [[13, 18], ["tensorflow.variable_scope", "modules.HighwayNet.H_layer", "modules.HighwayNet.T_layer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "H", "=", "self", ".", "H_layer", "(", "inputs", ")", "\n", "T", "=", "self", ".", "T_layer", "(", "inputs", ")", "\n", "return", "H", "*", "T", "+", "inputs", "*", "(", "1.", "-", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.CBHG.__init__": [[21, 39], ["tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.rnn_cell.GRUCell", "modules.HighwayNet", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "K", ",", "conv_channels", ",", "pool_size", ",", "projections", ",", "projection_kernel_size", ",", "\n", "n_highwaynet_layers", ",", "highway_units", ",", "rnn_units", ",", "is_training", ",", "name", "=", "None", ")", ":", "\n", "        ", "self", ".", "K", "=", "K", "\n", "self", ".", "conv_channels", "=", "conv_channels", "\n", "self", ".", "pool_size", "=", "pool_size", "\n", "\n", "self", ".", "projections", "=", "projections", "\n", "self", ".", "projection_kernel_size", "=", "projection_kernel_size", "\n", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "scope", "=", "\"CBHG\"", "if", "name", "is", "None", "else", "name", "\n", "\n", "self", ".", "highway_units", "=", "highway_units", "\n", "self", ".", "highwaynet_layers", "=", "[", "\n", "HighwayNet", "(", "highway_units", ",", "name", "=", "\"{}_highwaynet_{}\"", ".", "format", "(", "self", ".", "scope", ",", "i", "+", "1", ")", ")", "for", "i", "in", "\n", "range", "(", "n_highwaynet_layers", ")", "]", "\n", "self", ".", "_fw_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "rnn_units", ",", "name", "=", "\"{}_forward_RNN\"", ".", "format", "(", "self", ".", "scope", ")", ")", "\n", "self", ".", "_bw_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "rnn_units", ",", "name", "=", "\"{}_backward_RNN\"", ".", "format", "(", "self", ".", "scope", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.CBHG.__call__": [[40, 89], ["tensorflow.variable_scope", "tensorflow.layers.max_pooling1d", "modules.conv1d", "modules.conv1d", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.layers.dense", "highwaynet", "modules.conv1d", "range"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "input_lengths", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"conv_bank\"", ")", ":", "\n", "# Convolution bank: concatenate on the last axis to stack channels from all ", "\n", "# convolutions", "\n", "# The convolution bank uses multiple different kernel sizes to have many insights ", "\n", "# of the input sequence", "\n", "# This makes one of the strengths of the CBHG block on sequences.", "\n", "                ", "conv_outputs", "=", "tf", ".", "concat", "(", "\n", "[", "conv1d", "(", "inputs", ",", "k", ",", "self", ".", "conv_channels", ",", "tf", ".", "nn", ".", "relu", ",", "self", ".", "is_training", ",", "0.", ",", "\n", "\"conv1d_{}\"", ".", "format", "(", "k", ")", ")", "for", "k", "in", "range", "(", "1", ",", "self", ".", "K", "+", "1", ")", "]", ",", "\n", "axis", "=", "-", "1", "\n", ")", "\n", "\n", "# Maxpooling (dimension reduction, Using max instead of average helps finding \"Edges\" ", "\n", "# in mels)", "\n", "", "maxpool_output", "=", "tf", ".", "layers", ".", "max_pooling1d", "(", "\n", "conv_outputs", ",", "\n", "pool_size", "=", "self", ".", "pool_size", ",", "\n", "strides", "=", "1", ",", "\n", "padding", "=", "\"same\"", ")", "\n", "\n", "# Two projection layers", "\n", "proj1_output", "=", "conv1d", "(", "maxpool_output", ",", "self", ".", "projection_kernel_size", ",", "self", ".", "projections", "[", "0", "]", ",", "\n", "tf", ".", "nn", ".", "relu", ",", "self", ".", "is_training", ",", "0.", ",", "\"proj1\"", ")", "\n", "proj2_output", "=", "conv1d", "(", "proj1_output", ",", "self", ".", "projection_kernel_size", ",", "self", ".", "projections", "[", "1", "]", ",", "\n", "lambda", "_", ":", "_", ",", "self", ".", "is_training", ",", "0.", ",", "\"proj2\"", ")", "\n", "\n", "# Residual connection", "\n", "highway_input", "=", "proj2_output", "+", "inputs", "\n", "\n", "# Additional projection in case of dimension mismatch (for HighwayNet \"residual\" ", "\n", "# connection)", "\n", "if", "highway_input", ".", "shape", "[", "2", "]", "!=", "self", ".", "highway_units", ":", "\n", "                ", "highway_input", "=", "tf", ".", "layers", ".", "dense", "(", "highway_input", ",", "self", ".", "highway_units", ")", "\n", "\n", "# 4-layer HighwayNet", "\n", "", "for", "highwaynet", "in", "self", ".", "highwaynet_layers", ":", "\n", "                ", "highway_input", "=", "highwaynet", "(", "highway_input", ")", "\n", "", "rnn_input", "=", "highway_input", "\n", "\n", "# Bidirectional RNN", "\n", "outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "self", ".", "_fw_cell", ",", "\n", "self", ".", "_bw_cell", ",", "\n", "rnn_input", ",", "\n", "sequence_length", "=", "input_lengths", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "concat", "(", "outputs", ",", "axis", "=", "2", ")", "# Concat forward and backward outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.ZoneoutLSTMCell.__init__": [[102, 117], ["min", "max", "tensorflow.nn.rnn_cell.LSTMCell", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "is_training", ",", "zoneout_factor_cell", "=", "0.", ",", "zoneout_factor_output", "=", "0.", ",", "\n", "state_is_tuple", "=", "True", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializer with possibility to set different zoneout values for cell/hidden states.\n        \"\"\"", "\n", "zm", "=", "min", "(", "zoneout_factor_output", ",", "zoneout_factor_cell", ")", "\n", "zs", "=", "max", "(", "zoneout_factor_output", ",", "zoneout_factor_cell", ")", "\n", "\n", "if", "zm", "<", "0.", "or", "zs", ">", "1.", ":", "\n", "            ", "raise", "ValueError", "(", "\"One/both provided Zoneout factors are not in [0, 1]\"", ")", "\n", "\n", "", "self", ".", "_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "num_units", ",", "state_is_tuple", "=", "state_is_tuple", ",", "name", "=", "name", ")", "\n", "self", ".", "_zoneout_cell", "=", "zoneout_factor_cell", "\n", "self", ".", "_zoneout_outputs", "=", "zoneout_factor_output", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "state_is_tuple", "=", "state_is_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.ZoneoutLSTMCell.state_size": [[118, 121], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.ZoneoutLSTMCell.output_size": [[122, 125], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.ZoneoutLSTMCell.__call__": [[126, 160], ["modules.ZoneoutLSTMCell._cell", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "tensorflow.nn.rnn_cell.LSTMStateTuple", "tensorflow.concat", "tensorflow.nn.dropout", "tensorflow.nn.dropout"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Runs vanilla LSTM Cell and applies zoneout.\n        \"\"\"", "\n", "# Apply vanilla LSTM", "\n", "output", ",", "new_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ",", "scope", ")", "\n", "\n", "if", "self", ".", "state_is_tuple", ":", "\n", "            ", "(", "prev_c", ",", "prev_h", ")", "=", "state", "\n", "(", "new_c", ",", "new_h", ")", "=", "new_state", "\n", "", "else", ":", "\n", "            ", "num_proj", "=", "self", ".", "_cell", ".", "_num_units", "if", "self", ".", "_cell", ".", "_num_proj", "is", "None", "else", "self", ".", "_cell", ".", "_num_proj", "\n", "prev_c", "=", "tf", ".", "slice", "(", "state", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "self", ".", "_cell", ".", "_num_units", "]", ")", "\n", "prev_h", "=", "tf", ".", "slice", "(", "state", ",", "[", "0", ",", "self", ".", "_cell", ".", "_num_units", "]", ",", "[", "-", "1", ",", "num_proj", "]", ")", "\n", "new_c", "=", "tf", ".", "slice", "(", "new_state", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "self", ".", "_cell", ".", "_num_units", "]", ")", "\n", "new_h", "=", "tf", ".", "slice", "(", "new_state", ",", "[", "0", ",", "self", ".", "_cell", ".", "_num_units", "]", ",", "[", "-", "1", ",", "num_proj", "]", ")", "\n", "\n", "# Apply zoneout", "\n", "", "if", "self", ".", "is_training", ":", "\n", "# nn.dropout takes keep_prob (probability to keep activations) not drop_prob (", "\n", "# probability to mask activations)!", "\n", "            ", "c", "=", "(", "1", "-", "self", ".", "_zoneout_cell", ")", "*", "tf", ".", "nn", ".", "dropout", "(", "new_c", "-", "prev_c", ",", "\n", "(", "1", "-", "self", ".", "_zoneout_cell", ")", ")", "+", "prev_c", "\n", "h", "=", "(", "1", "-", "self", ".", "_zoneout_outputs", ")", "*", "tf", ".", "nn", ".", "dropout", "(", "new_h", "-", "prev_h", ",", "\n", "(", "1", "-", "self", ".", "_zoneout_outputs", ")", ")", "+", "prev_h", "\n", "\n", "", "else", ":", "\n", "            ", "c", "=", "(", "1", "-", "self", ".", "_zoneout_cell", ")", "*", "new_c", "+", "self", ".", "_zoneout_cell", "*", "prev_c", "\n", "h", "=", "(", "1", "-", "self", ".", "_zoneout_outputs", ")", "*", "new_h", "+", "self", ".", "_zoneout_outputs", "*", "prev_h", "\n", "\n", "", "new_state", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMStateTuple", "(", "c", ",", "h", ")", "if", "self", ".", "state_is_tuple", "else", "tf", ".", "concat", "(", "1", ",", "[", "c", ",", "\n", "h", "]", ")", "\n", "\n", "return", "output", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.EncoderConvolutions.__init__": [[166, 185], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "hparams", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            is_training: Boolean, determines if the model is training or in inference to control \n            dropout\n            kernel_size: tuple or integer, The size of convolution kernels\n            channels: integer, number of convolutional kernels\n            activation: callable, postnet activation function for each convolutional layer\n            scope: Postnet scope.\n        \"\"\"", "\n", "super", "(", "EncoderConvolutions", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "kernel_size", "=", "hparams", ".", "enc_conv_kernel_size", "\n", "self", ".", "channels", "=", "hparams", ".", "enc_conv_channels", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "scope", "=", "\"enc_conv_layers\"", "if", "scope", "is", "None", "else", "scope", "\n", "self", ".", "drop_rate", "=", "hparams", ".", "tacotron_dropout_rate", "\n", "self", ".", "enc_conv_num_layers", "=", "hparams", ".", "enc_conv_num_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.EncoderConvolutions.__call__": [[186, 194], ["tensorflow.variable_scope", "range", "modules.conv1d"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "x", "=", "inputs", "\n", "for", "i", "in", "range", "(", "self", ".", "enc_conv_num_layers", ")", ":", "\n", "                ", "x", "=", "conv1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "channels", ",", "self", ".", "activation", ",", "\n", "self", ".", "is_training", ",", "self", ".", "drop_rate", ",", "\n", "\"conv_layer_{}_\"", ".", "format", "(", "i", "+", "1", ")", "+", "self", ".", "scope", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.EncoderRNN.__init__": [[200, 227], ["super().__init__", "modules.ZoneoutLSTMCell", "modules.ZoneoutLSTMCell"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "size", "=", "256", ",", "zoneout", "=", "0.1", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            is_training: Boolean, determines if the model is training or in inference to control \n            zoneout\n            size: integer, the number of LSTM units for each direction\n            zoneout: the zoneout factor\n            scope: EncoderRNN scope.\n        \"\"\"", "\n", "super", "(", "EncoderRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "zoneout", "=", "zoneout", "\n", "self", ".", "scope", "=", "\"encoder_LSTM\"", "if", "scope", "is", "None", "else", "scope", "\n", "\n", "# Create forward LSTM Cell", "\n", "self", ".", "_fw_cell", "=", "ZoneoutLSTMCell", "(", "size", ",", "is_training", ",", "\n", "zoneout_factor_cell", "=", "zoneout", ",", "\n", "zoneout_factor_output", "=", "zoneout", ",", "\n", "name", "=", "\"encoder_fw_LSTM\"", ")", "\n", "\n", "# Create backward LSTM Cell", "\n", "self", ".", "_bw_cell", "=", "ZoneoutLSTMCell", "(", "size", ",", "is_training", ",", "\n", "zoneout_factor_cell", "=", "zoneout", ",", "\n", "zoneout_factor_output", "=", "zoneout", ",", "\n", "name", "=", "\"encoder_bw_LSTM\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.EncoderRNN.__call__": [[228, 239], ["tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "input_lengths", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "outputs", ",", "(", "fw_state", ",", "bw_state", ")", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "self", ".", "_fw_cell", ",", "\n", "self", ".", "_bw_cell", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "input_lengths", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "return", "tf", ".", "concat", "(", "outputs", ",", "axis", "=", "2", ")", "# Concat and return forward + backward outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.Prenet.__init__": [[245, 262], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "layers_sizes", "=", "[", "256", ",", "256", "]", ",", "drop_rate", "=", "0.5", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            layers_sizes: list of integers, the length of the list represents the number of pre-net\n                layers and the list values represent the layers number of units\n            activation: callable, activation functions of the prenet layers.\n            scope: Prenet scope.\n        \"\"\"", "\n", "super", "(", "Prenet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "\n", "self", ".", "layers_sizes", "=", "layers_sizes", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "scope", "=", "\"prenet\"", "if", "scope", "is", "None", "else", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.Prenet.__call__": [[263, 275], ["tensorflow.variable_scope", "enumerate", "tensorflow.layers.dense", "tensorflow.layers.dropout"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "for", "i", ",", "size", "in", "enumerate", "(", "self", ".", "layers_sizes", ")", ":", "\n", "                ", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "units", "=", "size", ",", "activation", "=", "self", ".", "activation", ",", "\n", "name", "=", "\"dense_{}\"", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "# The paper discussed introducing diversity in generation at inference time", "\n", "# by using a dropout of 0.5 only in prenet layers (in both training and inference).", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "dense", ",", "rate", "=", "self", ".", "drop_rate", ",", "training", "=", "True", ",", "\n", "name", "=", "\"dropout_{}\"", ".", "format", "(", "i", "+", "1", ")", "+", "self", ".", "scope", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.DecoderRNN.__init__": [[281, 306], ["super().__init__", "tensorflow.contrib.rnn.MultiRNNCell", "modules.ZoneoutLSTMCell", "range"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "layers", "=", "2", ",", "size", "=", "1024", ",", "zoneout", "=", "0.1", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            is_training: Boolean, determines if the model is in training or inference to control \n            zoneout\n            layers: integer, the number of LSTM layers in the decoder\n            size: integer, the number of LSTM units in each layer\n            zoneout: the zoneout factor\n        \"\"\"", "\n", "super", "(", "DecoderRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "zoneout", "=", "zoneout", "\n", "self", ".", "scope", "=", "\"decoder_rnn\"", "if", "scope", "is", "None", "else", "scope", "\n", "\n", "# Create a set of LSTM layers", "\n", "self", ".", "rnn_layers", "=", "[", "ZoneoutLSTMCell", "(", "size", ",", "is_training", ",", "\n", "zoneout_factor_cell", "=", "zoneout", ",", "\n", "zoneout_factor_output", "=", "zoneout", ",", "\n", "name", "=", "\"decoder_LSTM_{}\"", ".", "format", "(", "i", "+", "1", ")", ")", "for", "i", "in", "\n", "range", "(", "layers", ")", "]", "\n", "\n", "self", ".", "_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "self", ".", "rnn_layers", ",", "state_is_tuple", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.DecoderRNN.__call__": [[307, 310], ["tensorflow.variable_scope", "modules.DecoderRNN._cell"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "states", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "return", "self", ".", "_cell", "(", "inputs", ",", "states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.FrameProjection.__init__": [[316, 332], ["super().__init__", "tensorflow.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "shape", "=", "80", ",", "activation", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            shape: integer, dimensionality of output space (r*n_mels for decoder or n_mels for \n            postnet)\n            activation: callable, activation function\n            scope: FrameProjection scope.\n        \"\"\"", "\n", "super", "(", "FrameProjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "scope", "=", "\"Linear_projection\"", "if", "scope", "is", "None", "else", "scope", "\n", "self", ".", "dense", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "shape", ",", "activation", "=", "activation", ",", "\n", "name", "=", "\"projection_{}\"", ".", "format", "(", "self", ".", "scope", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.FrameProjection.__call__": [[333, 342], ["tensorflow.variable_scope", "modules.FrameProjection.dense"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "# If activation==None, this returns a simple Linear projection", "\n", "# else the projection will be passed through an activation function", "\n", "# output = tf.layers.dense(inputs, units=self.shape, activation=self.activation,", "\n", "# \tname=\"projection_{}\".format(self.scope))", "\n", "            ", "output", "=", "self", ".", "dense", "(", "inputs", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.StopProjection.__init__": [[348, 363], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "shape", "=", "1", ",", "activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            is_training: Boolean, to control the use of sigmoid function as it is useless to use it\n                during training since it is integrate inside the sigmoid_crossentropy loss\n            shape: integer, dimensionality of output space. Defaults to 1 (scalar)\n            activation: callable, activation function. only used during inference\n            scope: StopProjection scope.\n        \"\"\"", "\n", "super", "(", "StopProjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "scope", "=", "\"stop_token_projection\"", "if", "scope", "is", "None", "else", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.StopProjection.__call__": [[364, 374], ["tensorflow.variable_scope", "tensorflow.layers.dense", "modules.StopProjection.activation"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "output", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "units", "=", "self", ".", "shape", ",", "\n", "activation", "=", "None", ",", "name", "=", "\"projection_{}\"", ".", "format", "(", "self", ".", "scope", ")", ")", "\n", "\n", "# During training, don\"t use activation as it is integrated inside the ", "\n", "# sigmoid_cross_entropy loss function", "\n", "if", "self", ".", "is_training", ":", "\n", "                ", "return", "output", "\n", "", "return", "self", ".", "activation", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.Postnet.__init__": [[381, 400], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "is_training", ",", "hparams", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            is_training: Boolean, determines if the model is training or in inference to control \n            dropout\n            kernel_size: tuple or integer, The size of convolution kernels\n            channels: integer, number of convolutional kernels\n            activation: callable, postnet activation function for each convolutional layer\n            scope: Postnet scope.\n        \"\"\"", "\n", "super", "(", "Postnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "kernel_size", "=", "hparams", ".", "postnet_kernel_size", "\n", "self", ".", "channels", "=", "hparams", ".", "postnet_channels", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "scope", "=", "\"postnet_convolutions\"", "if", "scope", "is", "None", "else", "scope", "\n", "self", ".", "postnet_num_layers", "=", "hparams", ".", "postnet_num_layers", "\n", "self", ".", "drop_rate", "=", "hparams", ".", "tacotron_dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.Postnet.__call__": [[401, 412], ["tensorflow.variable_scope", "range", "modules.conv1d", "modules.conv1d"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "x", "=", "inputs", "\n", "for", "i", "in", "range", "(", "self", ".", "postnet_num_layers", "-", "1", ")", ":", "\n", "                ", "x", "=", "conv1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "channels", ",", "self", ".", "activation", ",", "\n", "self", ".", "is_training", ",", "self", ".", "drop_rate", ",", "\n", "\"conv_layer_{}_\"", ".", "format", "(", "i", "+", "1", ")", "+", "self", ".", "scope", ")", "\n", "", "x", "=", "conv1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "channels", ",", "lambda", "_", ":", "_", ",", "self", ".", "is_training", ",", "\n", "self", ".", "drop_rate", ",", "\n", "\"conv_layer_{}_\"", ".", "format", "(", "5", ")", "+", "self", ".", "scope", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d": [[414, 426], ["tensorflow.variable_scope", "tensorflow.layers.conv1d", "tensorflow.layers.batch_normalization", "tensorflow.layers.dropout", "tensorflow.tf.nn.relu", "tensorflow.tf.nn.relu"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.conv1d"], ["", "", "def", "conv1d", "(", "inputs", ",", "kernel_size", ",", "channels", ",", "activation", ",", "is_training", ",", "drop_rate", ",", "scope", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "conv1d_output", "=", "tf", ".", "layers", ".", "conv1d", "(", "\n", "inputs", ",", "\n", "filters", "=", "channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "activation", "=", "None", ",", "\n", "padding", "=", "\"same\"", ")", "\n", "batched", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv1d_output", ",", "training", "=", "is_training", ")", "\n", "activated", "=", "activation", "(", "batched", ")", "\n", "return", "tf", ".", "layers", ".", "dropout", "(", "activated", ",", "rate", "=", "drop_rate", ",", "training", "=", "is_training", ",", "\n", "name", "=", "\"dropout_{}\"", ".", "format", "(", "scope", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules._round_up_tf": [[428, 437], ["tensorflow.mod", "tensorflow.cond", "tensorflow.equal", "tensorflow.zeros", "tensorflow.shape"], "function", ["None"], ["", "", "def", "_round_up_tf", "(", "x", ",", "multiple", ")", ":", "\n", "# Tf version of remainder = x % multiple", "\n", "    ", "remainder", "=", "tf", ".", "mod", "(", "x", ",", "multiple", ")", "\n", "# Tf version of return x if remainder == 0 else x + multiple - remainder", "\n", "x_round", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "remainder", ",", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "remainder", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ")", ",", "\n", "lambda", ":", "x", ",", "\n", "lambda", ":", "x", "+", "multiple", "-", "remainder", ")", "\n", "\n", "return", "x_round", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask": [[439, 447], ["tensorflow.reduce_max", "modules._round_up_tf", "tensorflow.sequence_mask", "tensorflow.convert_to_tensor", "tensorflow.expand_dims", "tensorflow.sequence_mask"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules._round_up_tf", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask"], ["", "def", "sequence_mask", "(", "lengths", ",", "r", ",", "expand", "=", "True", ")", ":", "\n", "    ", "\"\"\"Returns a 2-D or 3-D tensorflow sequence mask depending on the argument \"expand\"\n    \"\"\"", "\n", "max_len", "=", "tf", ".", "reduce_max", "(", "lengths", ")", "\n", "max_len", "=", "_round_up_tf", "(", "max_len", ",", "tf", ".", "convert_to_tensor", "(", "r", ")", ")", "\n", "if", "expand", ":", "\n", "        ", "return", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "lengths", ",", "maxlen", "=", "max_len", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "return", "tf", ".", "sequence_mask", "(", "lengths", ",", "maxlen", "=", "max_len", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedMSE": [[449, 470], ["tensorflow.ones", "modules.sequence_mask", "tensorflow.control_dependencies", "tensorflow.losses.mean_squared_error", "tensorflow.assert_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask"], ["", "def", "MaskedMSE", "(", "targets", ",", "outputs", ",", "targets_lengths", ",", "hparams", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes a masked Mean Squared Error\n    \"\"\"", "\n", "\n", "# [batch_size, time_dimension, 1]", "\n", "# example:", "\n", "# sequence_mask([1, 3, 2], 5) = [[[1., 0., 0., 0., 0.]],", "\n", "#\t\t\t\t\t\t\t    [[1., 1., 1., 0., 0.]],", "\n", "#\t\t\t\t\t\t\t    [[1., 1., 0., 0., 0.]]]", "\n", "# Note the maxlen argument that ensures mask shape is compatible with r>1", "\n", "# This will by default mask the extra paddings caused by r>1", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "mask", "=", "sequence_mask", "(", "targets_lengths", ",", "hparams", ".", "outputs_per_step", ",", "True", ")", "\n", "\n", "# [batch_size, time_dimension, channel_dimension(mels)]", "\n", "", "ones", "=", "tf", ".", "ones", "(", "shape", "=", "[", "tf", ".", "shape", "(", "mask", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "mask", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "targets", ")", "[", "-", "1", "]", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "mask_", "=", "mask", "*", "ones", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "targets", ")", ",", "tf", ".", "shape", "(", "mask_", ")", ")", "]", ")", ":", "\n", "        ", "return", "tf", ".", "losses", ".", "mean_squared_error", "(", "labels", "=", "targets", ",", "predictions", "=", "outputs", ",", "weights", "=", "mask_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedSigmoidCrossEntropy": [[472, 497], ["modules.sequence_mask", "tensorflow.control_dependencies", "tensorflow.nn.weighted_cross_entropy_with_logits", "tensorflow.control_dependencies", "tensorflow.reduce_sum", "tensorflow.count_nonzero", "tensorflow.assert_equal", "tensorflow.assert_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask"], ["", "", "def", "MaskedSigmoidCrossEntropy", "(", "targets", ",", "outputs", ",", "targets_lengths", ",", "hparams", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes a masked SigmoidCrossEntropy with logits\n    \"\"\"", "\n", "\n", "# [batch_size, time_dimension]", "\n", "# example:", "\n", "# sequence_mask([1, 3, 2], 5) = [[1., 0., 0., 0., 0.],", "\n", "#\t\t\t\t\t\t\t    [1., 1., 1., 0., 0.],", "\n", "#\t\t\t\t\t\t\t    [1., 1., 0., 0., 0.]]", "\n", "# Note the maxlen argument that ensures mask shape is compatible with r>1", "\n", "# This will by default mask the extra paddings caused by r>1", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "mask", "=", "sequence_mask", "(", "targets_lengths", ",", "hparams", ".", "outputs_per_step", ",", "False", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "targets", ")", ",", "tf", ".", "shape", "(", "mask", ")", ")", "]", ")", ":", "\n", "# Use a weighted sigmoid cross entropy to measure the <stop_token> loss. Set ", "\n", "# hparams.cross_entropy_pos_weight to 1", "\n", "# will have the same effect as  vanilla tf.nn.sigmoid_cross_entropy_with_logits.", "\n", "        ", "losses", "=", "tf", ".", "nn", ".", "weighted_cross_entropy_with_logits", "(", "targets", "=", "targets", ",", "logits", "=", "outputs", ",", "\n", "pos_weight", "=", "hparams", ".", "cross_entropy_pos_weight", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "mask", ")", ",", "tf", ".", "shape", "(", "losses", ")", ")", "]", ")", ":", "\n", "        ", "masked_loss", "=", "losses", "*", "mask", "\n", "\n", "", "return", "tf", ".", "reduce_sum", "(", "masked_loss", ")", "/", "tf", ".", "count_nonzero", "(", "masked_loss", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedLinearLoss": [[499, 529], ["tensorflow.ones", "tensorflow.abs", "int", "modules.sequence_mask", "tensorflow.control_dependencies", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.assert_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.sequence_mask"], ["", "def", "MaskedLinearLoss", "(", "targets", ",", "outputs", ",", "targets_lengths", ",", "hparams", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes a masked MAE loss with priority to low frequencies\n    \"\"\"", "\n", "\n", "# [batch_size, time_dimension, 1]", "\n", "# example:", "\n", "# sequence_mask([1, 3, 2], 5) = [[[1., 0., 0., 0., 0.]],", "\n", "#\t\t\t\t\t\t\t    [[1., 1., 1., 0., 0.]],", "\n", "#\t\t\t\t\t\t\t    [[1., 1., 0., 0., 0.]]]", "\n", "# Note the maxlen argument that ensures mask shape is compatible with r>1", "\n", "# This will by default mask the extra paddings caused by r>1", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "mask", "=", "sequence_mask", "(", "targets_lengths", ",", "hparams", ".", "outputs_per_step", ",", "True", ")", "\n", "\n", "# [batch_size, time_dimension, channel_dimension(freq)]", "\n", "", "ones", "=", "tf", ".", "ones", "(", "shape", "=", "[", "tf", ".", "shape", "(", "mask", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "mask", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "targets", ")", "[", "-", "1", "]", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "mask_", "=", "mask", "*", "ones", "\n", "\n", "l1", "=", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", "\n", "n_priority_freq", "=", "int", "(", "2000", "/", "(", "hparams", ".", "sample_rate", "*", "0.5", ")", "*", "hparams", ".", "num_freq", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "targets", ")", ",", "tf", ".", "shape", "(", "mask_", ")", ")", "]", ")", ":", "\n", "        ", "masked_l1", "=", "l1", "*", "mask_", "\n", "masked_l1_low", "=", "masked_l1", "[", ":", ",", ":", ",", "0", ":", "n_priority_freq", "]", "\n", "\n", "", "mean_l1", "=", "tf", ".", "reduce_sum", "(", "masked_l1", ")", "/", "tf", ".", "reduce_sum", "(", "mask_", ")", "\n", "mean_l1_low", "=", "tf", ".", "reduce_sum", "(", "masked_l1_low", ")", "/", "tf", ".", "reduce_sum", "(", "mask_", ")", "\n", "\n", "return", "0.5", "*", "mean_l1", "+", "0.5", "*", "mean_l1_low", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.__init__": [[28, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hparams", ",", "resnet_scope", ",", "resnet_hp", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "resnet_scope", "=", "resnet_scope", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.initialize": [[31, 310], ["range", "tensorflow.trainable_variables", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "range", "ValueError", "ValueError", "ValueError", "ValueError", "RuntimeError", "RuntimeError", "tensorflow.device", "tensorflow.split", "tensorflow.split", "tensorflow.py_func", "range", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "synthesizer.infolog.log", "tensorflow.split", "tensorflow.py_func", "tensorflow.py_func", "tensorflow.shape", "tower_inputs.append", "range", "tensorflow.device", "synthesizer.infolog.log", "tensorflow.reshape", "tower_mel_targets.append", "tower_stop_token_targets.append", "tensorflow.train.replica_device_setter", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "synthesizer.models.architecture_wrappers.TacotronEncoderCell", "synthesizer.models.architecture_wrappers.TacotronEncoderCell.", "tensorflow.reshape", "tensorflow.tile", "tensorflow.concat", "Prenet", "synthesizer.models.attention.LocationSensitiveAttention", "DecoderRNN", "FrameProjection", "StopProjection", "synthesizer.models.architecture_wrappers.TacotronDecoderCell", "synthesizer.models.architecture_wrappers.TacotronDecoderCell.zero_state", "tensorflow.contrib.seq2seq.dynamic_decode", "tensorflow.reshape", "tensorflow.reshape", "Postnet", "Postnet.", "FrameProjection", "FrameProjection.", "tensorflow.transpose", "tacotron.Tacotron.tower_decoder_output.append", "tacotron.Tacotron.tower_alignments.append", "tacotron.Tacotron.tower_stop_token_prediction.append", "tacotron.Tacotron.tower_mel_outputs.append", "tower_embedded_inputs.append", "tower_enc_conv_output_shape.append", "tower_encoder_cond_outputs.append", "tower_residual.append", "tower_projected_residual.append", "tensorflow.reshape", "tensorflow.reshape", "EncoderConvolutions", "EncoderRNN", "synthesizer.models.helpers.TacoTrainingHelper", "synthesizer.models.helpers.TacoTestHelper", "synthesizer.models.custom_decoder.CustomDecoder", "CBHG", "CBHG.", "FrameProjection", "FrameProjection.", "final_decoder_state.alignment_history.stack", "tacotron.Tacotron.tower_linear_outputs.append", "numpy.sum", "len", "tensorflow.reshape", "tensorflow.shape", "numpy.prod", "v.get_shape().as_list", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.architecture_wrappers.TacotronDecoderCell.zero_state", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["self", ".", "resnet", "=", "ResNet", "(", "resnet_hp", ",", "'eval'", ")", "\n", "self", ".", "embed_loss_scale", "=", "hparams", ".", "embed_loss_scale", "\n", "", "''' \n    def __init__(self, hparams, embed_net):\n        self._hparams = hparams\n        self.resnet = embed_net\n    '''", "\n", "def", "initialize", "(", "self", ",", "inputs", ",", "input_lengths", ",", "embed_targets", ",", "mel_targets", "=", "None", ",", "\n", "stop_token_targets", "=", "None", ",", "embedding_masks", "=", "None", ",", "linear_targets", "=", "None", ",", "targets_lengths", "=", "None", ",", "gta", "=", "False", ",", "\n", "global_step", "=", "None", ",", "is_training", "=", "False", ",", "is_evaluating", "=", "False", ",", "split_infos", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the model for inference sets \"mel_outputs\" and \"alignments\" fields.\n        Args:\n            - inputs: int32 Tensor with shape [N, T_in] where N is batch size, T_in is number of\n              steps in the input time series, and values are character IDs\n            - input_lengths: int32 Tensor with shape [N] where N is batch size and values are the \n            lengths of each sequence in inputs.\n            - embed_targets: float32 Tensor with shape [N, E] where E is the speaker \n            embedding size.\n            - mel_targets: float32 Tensor with shape [N, T_out, M] where N is batch size, \n            T_out is number of steps in the output time series, M is num_mels, and values are \n            entries in the mel spectrogram. Only needed for training.\n        \"\"\"", "\n", "if", "mel_targets", "is", "None", "and", "stop_token_targets", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"no multi targets were provided but token_targets were given\"", ")", "\n", "", "if", "mel_targets", "is", "not", "None", "and", "stop_token_targets", "is", "None", "and", "not", "gta", ":", "\n", "            ", "raise", "ValueError", "(", "\"Mel targets are provided without corresponding token_targets\"", ")", "\n", "", "if", "not", "gta", "and", "self", ".", "_hparams", ".", "predict_linear", "==", "True", "and", "linear_targets", "is", "None", "and", "is_training", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Model is set to use post processing to predict linear spectrograms in training \"", "\n", "\"but no linear targets given!\"", ")", "\n", "", "if", "gta", "and", "linear_targets", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Linear spectrogram prediction is not supported in GTA mode!\"", ")", "\n", "", "if", "is_training", "and", "self", ".", "_hparams", ".", "mask_decoder", "and", "targets_lengths", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Model set to mask paddings but no targets lengths provided for the mask!\"", ")", "\n", "", "if", "is_training", "and", "is_evaluating", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Model can not be in training and evaluation modes at the same time!\"", ")", "\n", "\n", "", "split_device", "=", "\"/cpu:0\"", "if", "self", ".", "_hparams", ".", "tacotron_num_gpus", ">", "1", "or", "self", ".", "_hparams", ".", "split_on_cpu", "else", "\"/gpu:{}\"", ".", "format", "(", "\n", "self", ".", "_hparams", ".", "tacotron_gpu_start_idx", ")", "\n", "with", "tf", ".", "device", "(", "split_device", ")", ":", "\n", "            ", "hp", "=", "self", ".", "_hparams", "\n", "lout_int", "=", "[", "tf", ".", "int32", "]", "*", "hp", ".", "tacotron_num_gpus", "\n", "lout_float", "=", "[", "tf", ".", "float32", "]", "*", "hp", ".", "tacotron_num_gpus", "\n", "\n", "tower_input_lengths", "=", "tf", ".", "split", "(", "input_lengths", ",", "num_or_size_splits", "=", "hp", ".", "tacotron_num_gpus", ",", "\n", "axis", "=", "0", ")", "\n", "tower_targets_lengths", "=", "tf", ".", "split", "(", "targets_lengths", ",", "num_or_size_splits", "=", "hp", ".", "tacotron_num_gpus", ",", "axis", "=", "0", ")", "if", "targets_lengths", "is", "not", "None", "else", "targets_lengths", "\n", "\n", "### SV2TTS ###", "\n", "p_embedding_masks", "=", "tf", ".", "py_func", "(", "split_func", ",", "[", "embedding_masks", ",", "split_infos", "[", ":", ",", "3", "]", "]", ",", "\n", "lout_float", ")", "if", "embedding_masks", "is", "not", "None", "else", "embedding_masks", "\n", "\n", "tower_embed_targets", "=", "tf", ".", "split", "(", "embed_targets", ",", "num_or_size_splits", "=", "hp", ".", "tacotron_num_gpus", ",", "\n", "axis", "=", "0", ")", "\n", "\n", "##############", "\n", "\n", "p_inputs", "=", "tf", ".", "py_func", "(", "split_func", ",", "[", "inputs", ",", "split_infos", "[", ":", ",", "0", "]", "]", ",", "lout_int", ")", "\n", "p_mel_targets", "=", "tf", ".", "py_func", "(", "split_func", ",", "[", "mel_targets", ",", "split_infos", "[", ":", ",", "1", "]", "]", ",", "\n", "lout_float", ")", "if", "mel_targets", "is", "not", "None", "else", "mel_targets", "\n", "p_stop_token_targets", "=", "tf", ".", "py_func", "(", "split_func", ",", "[", "stop_token_targets", ",", "split_infos", "[", ":", ",", "2", "]", "]", ",", "\n", "lout_float", ")", "if", "stop_token_targets", "is", "not", "None", "else", "stop_token_targets", "\n", "\n", "tower_inputs", "=", "[", "]", "\n", "tower_mel_targets", "=", "[", "]", "\n", "tower_stop_token_targets", "=", "[", "]", "\n", "tower_embedding_masks", "=", "[", "]", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "mel_channels", "=", "hp", ".", "num_mels", "\n", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", ")", ":", "\n", "                ", "tower_inputs", ".", "append", "(", "tf", ".", "reshape", "(", "p_inputs", "[", "i", "]", ",", "[", "batch_size", ",", "-", "1", "]", ")", ")", "\n", "if", "p_mel_targets", "is", "not", "None", ":", "\n", "                    ", "tower_mel_targets", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "p_mel_targets", "[", "i", "]", ",", "[", "batch_size", ",", "-", "1", ",", "mel_channels", "]", ")", ")", "\n", "", "if", "p_stop_token_targets", "is", "not", "None", ":", "\n", "                    ", "tower_stop_token_targets", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "p_stop_token_targets", "[", "i", "]", ",", "[", "batch_size", ",", "-", "1", "]", ")", ")", "\n", "", "if", "p_embedding_masks", "is", "not", "None", ":", "\n", "                    ", "tower_embedding_masks", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "p_embedding_masks", "[", "i", "]", ",", "[", "batch_size", ",", "-", "1", ",", "(", "hp", ".", "num_mels", "+", "7", ")", "//", "8", ",", "hp", ".", "speaker_embedding_size", "//", "2", "]", ")", ")", "\n", "\n", "", "", "", "self", ".", "tower_decoder_output", "=", "[", "]", "\n", "self", ".", "tower_alignments", "=", "[", "]", "\n", "self", ".", "tower_stop_token_prediction", "=", "[", "]", "\n", "self", ".", "tower_mel_outputs", "=", "[", "]", "\n", "self", ".", "tower_gvectors", "=", "[", "]", "\n", "\n", "tower_embedded_inputs", "=", "[", "]", "\n", "tower_spkembed_targets", "=", "[", "]", "\n", "tower_enc_conv_output_shape", "=", "[", "]", "\n", "tower_encoder_cond_outputs", "=", "[", "]", "\n", "tower_residual", "=", "[", "]", "\n", "tower_projected_residual", "=", "[", "]", "\n", "\n", "# 1. Declare GPU Devices", "\n", "gpus", "=", "[", "\"/gpu:{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "\n", "range", "(", "hp", ".", "tacotron_gpu_start_idx", ",", "hp", ".", "tacotron_gpu_start_idx", "+", "hp", ".", "tacotron_num_gpus", ")", "]", "\n", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "\"/cpu:0\"", ",", "\n", "worker_device", "=", "gpus", "[", "i", "]", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"inference\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "                    ", "assert", "hp", ".", "tacotron_teacher_forcing_mode", "in", "(", "\"constant\"", ",", "\"scheduled\"", ")", "\n", "if", "hp", ".", "tacotron_teacher_forcing_mode", "==", "\"scheduled\"", "and", "is_training", ":", "\n", "                        ", "assert", "global_step", "is", "not", "None", "\n", "\n", "# GTA is only used for predicting mels to train Wavenet vocoder, so we ommit ", "\n", "# post processing when doing GTA synthesis", "\n", "", "post_condition", "=", "hp", ".", "predict_linear", "and", "not", "gta", "\n", "\n", "# Embeddings ==> [batch_size, sequence_length, embedding_dim]", "\n", "self", ".", "embedding_table", "=", "tf", ".", "get_variable", "(", "\n", "\"inputs_embedding\"", ",", "[", "len", "(", "symbols", ")", ",", "hp", ".", "embedding_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "embedded_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "embedding_table", ",", "tower_inputs", "[", "i", "]", ")", "\n", "\n", "# Encoder Cell ==> [batch_size, encoder_steps, encoder_lstm_units]", "\n", "encoder_cell", "=", "TacotronEncoderCell", "(", "\n", "EncoderConvolutions", "(", "is_training", ",", "hparams", "=", "hp", ",", "scope", "=", "\"encoder_convolutions\"", ")", ",", "\n", "EncoderRNN", "(", "is_training", ",", "size", "=", "hp", ".", "encoder_lstm_units", ",", "\n", "zoneout", "=", "hp", ".", "tacotron_zoneout_rate", ",", "scope", "=", "\"encoder_LSTM\"", ")", ")", "\n", "\n", "encoder_outputs", "=", "encoder_cell", "(", "embedded_inputs", ",", "tower_input_lengths", "[", "i", "]", ")", "\n", "\n", "# For shape visualization purpose", "\n", "enc_conv_output_shape", "=", "encoder_cell", ".", "conv_output_shape", "\n", "\n", "\n", "### SV2TT2 ###", "\n", "\n", "# Append the speaker embedding to the encoder output at each timestep", "\n", "tileable_shape", "=", "[", "-", "1", ",", "1", ",", "self", ".", "_hparams", ".", "speaker_embedding_size", "]", "\n", "tileable_embed_targets", "=", "tf", ".", "reshape", "(", "tower_embed_targets", "[", "i", "]", ",", "tileable_shape", ")", "\n", "tiled_embed_targets", "=", "tf", ".", "tile", "(", "tileable_embed_targets", ",", "\n", "[", "1", ",", "tf", ".", "shape", "(", "encoder_outputs", ")", "[", "1", "]", ",", "1", "]", ")", "\n", "encoder_cond_outputs", "=", "tf", ".", "concat", "(", "(", "encoder_outputs", ",", "tiled_embed_targets", ")", ",", "2", ")", "\n", "\n", "##############", "\n", "\n", "\n", "# Decoder Parts", "\n", "# Attention Decoder Prenet", "\n", "prenet", "=", "Prenet", "(", "is_training", ",", "layers_sizes", "=", "hp", ".", "prenet_layers", ",", "\n", "drop_rate", "=", "hp", ".", "tacotron_dropout_rate", ",", "scope", "=", "\"decoder_prenet\"", ")", "\n", "# Attention Mechanism", "\n", "attention_mechanism", "=", "LocationSensitiveAttention", "(", "hp", ".", "attention_dim", ",", "\n", "encoder_cond_outputs", ",", "\n", "hparams", "=", "hp", ",", "\n", "mask_encoder", "=", "hp", ".", "mask_encoder", ",", "\n", "memory_sequence_length", "=", "tf", ".", "reshape", "(", "\n", "tower_input_lengths", "[", "i", "]", ",", "\n", "[", "-", "1", "]", ")", ",", "\n", "smoothing", "=", "hp", ".", "smoothing", ",", "\n", "cumulate_weights", "=", "hp", ".", "cumulative_weights", ")", "\n", "# Decoder LSTM Cells", "\n", "decoder_lstm", "=", "DecoderRNN", "(", "is_training", ",", "layers", "=", "hp", ".", "decoder_layers", ",", "\n", "size", "=", "hp", ".", "decoder_lstm_units", ",", "\n", "zoneout", "=", "hp", ".", "tacotron_zoneout_rate", ",", "\n", "scope", "=", "\"decoder_LSTM\"", ")", "\n", "# Frames Projection layer", "\n", "frame_projection", "=", "FrameProjection", "(", "hp", ".", "num_mels", "*", "hp", ".", "outputs_per_step", ",", "\n", "scope", "=", "\"linear_transform_projection\"", ")", "\n", "# <stop_token> projection layer", "\n", "stop_projection", "=", "StopProjection", "(", "is_training", "or", "is_evaluating", ",", "shape", "=", "hp", "\n", ".", "outputs_per_step", ",", "\n", "scope", "=", "\"stop_token_projection\"", ")", "\n", "\n", "# Decoder Cell ==> [batch_size, decoder_steps, num_mels * r] (after decoding)", "\n", "decoder_cell", "=", "TacotronDecoderCell", "(", "\n", "prenet", ",", "\n", "attention_mechanism", ",", "\n", "decoder_lstm", ",", "\n", "frame_projection", ",", "\n", "stop_projection", ")", "\n", "\n", "# Define the helper for our decoder", "\n", "if", "is_training", "or", "is_evaluating", "or", "gta", ":", "\n", "                        ", "self", ".", "helper", "=", "TacoTrainingHelper", "(", "batch_size", ",", "tower_mel_targets", "[", "i", "]", ",", "hp", ",", "gta", ",", "\n", "is_evaluating", ",", "global_step", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "helper", "=", "TacoTestHelper", "(", "batch_size", ",", "hp", ")", "\n", "\n", "# initial decoder state", "\n", "", "decoder_init_state", "=", "decoder_cell", ".", "zero_state", "(", "batch_size", "=", "batch_size", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Only use max iterations at synthesis time", "\n", "max_iters", "=", "hp", ".", "max_iters", "if", "not", "(", "is_training", "or", "is_evaluating", ")", "else", "None", "\n", "\n", "# Decode", "\n", "(", "frames_prediction", ",", "stop_token_prediction", ",", "\n", "_", ")", ",", "final_decoder_state", ",", "_", "=", "dynamic_decode", "(", "\n", "CustomDecoder", "(", "decoder_cell", ",", "self", ".", "helper", ",", "decoder_init_state", ")", ",", "\n", "impute_finished", "=", "False", ",", "\n", "maximum_iterations", "=", "max_iters", ",", "\n", "swap_memory", "=", "hp", ".", "tacotron_swap_with_cpu", ")", "\n", "\n", "# Reshape outputs to be one output per entry ", "\n", "# ==> [batch_size, non_reduced_decoder_steps (decoder_steps * r), num_mels]", "\n", "decoder_output", "=", "tf", ".", "reshape", "(", "frames_prediction", ",", "[", "batch_size", ",", "-", "1", ",", "hp", ".", "num_mels", "]", ")", "\n", "stop_token_prediction", "=", "tf", ".", "reshape", "(", "stop_token_prediction", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "\n", "# Postnet", "\n", "postnet", "=", "Postnet", "(", "is_training", ",", "hparams", "=", "hp", ",", "scope", "=", "\"postnet_convolutions\"", ")", "\n", "\n", "# Compute residual using post-net ==> [batch_size, decoder_steps * r, ", "\n", "# postnet_channels]", "\n", "residual", "=", "postnet", "(", "decoder_output", ")", "\n", "\n", "# Project residual to same dimension as mel spectrogram ", "\n", "# ==> [batch_size, decoder_steps * r, num_mels]", "\n", "residual_projection", "=", "FrameProjection", "(", "hp", ".", "num_mels", ",", "scope", "=", "\"postnet_projection\"", ")", "\n", "projected_residual", "=", "residual_projection", "(", "residual", ")", "\n", "\n", "# Compute the mel spectrogram", "\n", "mel_outputs", "=", "decoder_output", "+", "projected_residual", "\n", "\n", "# Compute the embedding", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "resnet_scope", ",", "auxiliary_name_scope", "=", "False", ")", "as", "resnet_scope", ":", "\n", "                        ", "with", "tf", ".", "name_scope", "(", "resnet_scope", ".", "original_name_scope", ")", ":", "\n", "                            ", "if", "tower_targets_lengths", "==", "None", ":", "\n", "                                ", "gvectors", "=", "self", ".", "resnet", "(", "mel_outputs", ",", "None", ")", "\n", "", "else", ":", "\n", "                                ", "max_len", "=", "tf", ".", "reduce_max", "(", "tower_targets_lengths", "[", "i", "]", ")", "\n", "resInput", "=", "mel_outputs", "[", ":", ",", ":", "max_len", ",", ":", "]", "\n", "gvectors", "=", "self", ".", "resnet", "(", "resInput", ",", "tower_embedding_masks", "[", "i", "]", ")", "\n", "\n", "", "", "", "if", "post_condition", ":", "\n", "# Add post-processing CBHG. This does a great job at extracting features ", "\n", "# from mels before projection to Linear specs.", "\n", "                        ", "post_cbhg", "=", "CBHG", "(", "hp", ".", "cbhg_kernels", ",", "hp", ".", "cbhg_conv_channels", ",", "hp", ".", "cbhg_pool_size", ",", "\n", "[", "hp", ".", "cbhg_projection", ",", "hp", ".", "num_mels", "]", ",", "\n", "hp", ".", "cbhg_projection_kernel_size", ",", "hp", ".", "cbhg_highwaynet_layers", ",", "\n", "hp", ".", "cbhg_highway_units", ",", "hp", ".", "cbhg_rnn_units", ",", "is_training", ",", "\n", "name", "=", "\"CBHG_postnet\"", ")", "\n", "\n", "# [batch_size, decoder_steps(mel_frames), cbhg_channels]", "\n", "post_outputs", "=", "post_cbhg", "(", "mel_outputs", ",", "None", ")", "\n", "\n", "# Linear projection of extracted features to make linear spectrogram", "\n", "linear_specs_projection", "=", "FrameProjection", "(", "hp", ".", "num_freq", ",", "\n", "scope", "=", "\"cbhg_linear_specs_projection\"", ")", "\n", "\n", "# [batch_size, decoder_steps(linear_frames), num_freq]", "\n", "linear_outputs", "=", "linear_specs_projection", "(", "post_outputs", ")", "\n", "\n", "# Grab alignments from the final decoder state", "\n", "", "alignments", "=", "tf", ".", "transpose", "(", "final_decoder_state", ".", "alignment_history", ".", "stack", "(", ")", ",", "\n", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "\n", "self", ".", "tower_decoder_output", ".", "append", "(", "decoder_output", ")", "\n", "self", ".", "tower_alignments", ".", "append", "(", "alignments", ")", "\n", "self", ".", "tower_stop_token_prediction", ".", "append", "(", "stop_token_prediction", ")", "\n", "self", ".", "tower_mel_outputs", ".", "append", "(", "mel_outputs", ")", "\n", "self", ".", "tower_gvectors", ".", "append", "(", "gvectors", ")", "\n", "\n", "tower_spkembed_targets", ".", "append", "(", "tower_embed_targets", "[", "i", "]", ")", "\n", "tower_embedded_inputs", ".", "append", "(", "embedded_inputs", ")", "\n", "tower_enc_conv_output_shape", ".", "append", "(", "enc_conv_output_shape", ")", "\n", "tower_encoder_cond_outputs", ".", "append", "(", "encoder_cond_outputs", ")", "\n", "tower_residual", ".", "append", "(", "residual", ")", "\n", "tower_projected_residual", ".", "append", "(", "projected_residual", ")", "\n", "\n", "if", "post_condition", ":", "\n", "                        ", "self", ".", "tower_linear_outputs", ".", "append", "(", "linear_outputs", ")", "\n", "", "", "", "log", "(", "\"initialisation done {}\"", ".", "format", "(", "gpus", "[", "i", "]", ")", ")", "\n", "\n", "\n", "", "if", "is_training", ":", "\n", "            ", "self", ".", "ratio", "=", "self", ".", "helper", ".", "_ratio", "\n", "", "self", ".", "tower_inputs", "=", "tower_inputs", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_loss": [[312, 426], ["range", "range", "range", "tensorflow.device", "tensorflow.train.replica_device_setter", "tensorflow.variable_scope", "tacotron.Tacotron.tower_before_loss.append", "tacotron.Tacotron.tower_after_loss.append", "tacotron.Tacotron.tower_stop_token_loss.append", "tacotron.Tacotron.tower_regularization_loss.append", "tacotron.Tacotron.tower_linear_loss.append", "tacotron.Tacotron.tower_loss.append", "MaskedMSE", "MaskedMSE", "MaskedSigmoidCrossEntropy", "tensorflow.losses.mean_squared_error", "tensorflow.losses.mean_squared_error", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.reduce_mean", "tensorflow.add_n", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedMSE", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedMSE", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.modules.MaskedSigmoidCrossEntropy"], ["self", ".", "tower_mel_targets", "=", "tower_mel_targets", "\n", "self", ".", "tower_spkembed_targets", "=", "tower_spkembed_targets", "\n", "# self.tower_linear_targets = tower_linear_targets", "\n", "self", ".", "tower_targets_lengths", "=", "tower_targets_lengths", "\n", "self", ".", "tower_stop_token_targets", "=", "tower_stop_token_targets", "\n", "\n", "self", ".", "all_vars", "=", "[", "v", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "if", "not", "(", "\"resnet\"", "in", "v", ".", "name", ")", "]", "\n", "print", "(", "[", "v", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "if", "(", "\"vector\"", "in", "v", ".", "name", ")", "]", ")", "\n", "log", "(", "\"Initialized Tacotron model. Dimensions (? = dynamic shape): \"", ")", "\n", "log", "(", "\"  Train mode:               {}\"", ".", "format", "(", "is_training", ")", ")", "\n", "log", "(", "\"  Eval mode:                {}\"", ".", "format", "(", "is_evaluating", ")", ")", "\n", "log", "(", "\"  GTA mode:                 {}\"", ".", "format", "(", "gta", ")", ")", "\n", "log", "(", "\"  Synthesis mode:           {}\"", ".", "format", "(", "not", "(", "is_training", "or", "is_evaluating", ")", ")", ")", "\n", "log", "(", "\"  Input:                    {}\"", ".", "format", "(", "inputs", ".", "shape", ")", ")", "\n", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", "+", "hp", ".", "tacotron_gpu_start_idx", ")", ":", "\n", "            ", "log", "(", "\"  device:                   {}\"", ".", "format", "(", "i", ")", ")", "\n", "log", "(", "\"  embedding:                {}\"", ".", "format", "(", "tower_embedded_inputs", "[", "i", "]", ".", "shape", ")", ")", "\n", "log", "(", "\"  enc conv out:             {}\"", ".", "format", "(", "tower_enc_conv_output_shape", "[", "i", "]", ")", ")", "\n", "log", "(", "\"  encoder out (cond):       {}\"", ".", "format", "(", "tower_encoder_cond_outputs", "[", "i", "]", ".", "shape", ")", ")", "\n", "log", "(", "\"  decoder out:              {}\"", ".", "format", "(", "self", ".", "tower_decoder_output", "[", "i", "]", ".", "shape", ")", ")", "\n", "log", "(", "\"  residual out:             {}\"", ".", "format", "(", "tower_residual", "[", "i", "]", ".", "shape", ")", ")", "\n", "log", "(", "\"  projected residual out:   {}\"", ".", "format", "(", "tower_projected_residual", "[", "i", "]", ".", "shape", ")", ")", "\n", "log", "(", "\"  mel out:                  {}\"", ".", "format", "(", "self", ".", "tower_mel_outputs", "[", "i", "]", ".", "shape", ")", ")", "\n", "if", "post_condition", ":", "\n", "                ", "log", "(", "\"  linear out:               {}\"", ".", "format", "(", "self", ".", "tower_linear_outputs", "[", "i", "]", ".", "shape", ")", ")", "\n", "", "log", "(", "\"  <stop_token> out:         {}\"", ".", "format", "(", "self", ".", "tower_stop_token_prediction", "[", "i", "]", ".", "shape", ")", ")", "\n", "\n", "# 1_000_000 is causing syntax problems for some people?! Python please :)", "\n", "log", "(", "\"  Tacotron Parameters       {:.3f} Million.\"", ".", "format", "(", "\n", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "for", "v", "in", "self", ".", "all_vars", "]", ")", "/", "1000000.0", ")", ")", "\n", "\n", "\n", "", "", "def", "add_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"Adds loss to the model. Sets \"loss\" field. initialize must have been called.\"\"\"", "\n", "hp", "=", "self", ".", "_hparams", "\n", "\n", "self", ".", "tower_before_loss", "=", "[", "]", "\n", "self", ".", "tower_after_loss", "=", "[", "]", "\n", "self", ".", "tower_stop_token_loss", "=", "[", "]", "\n", "self", ".", "tower_regularization_loss", "=", "[", "]", "\n", "self", ".", "tower_linear_loss", "=", "[", "]", "\n", "self", ".", "tower_loss", "=", "[", "]", "\n", "self", ".", "tower_embedding_loss", "=", "[", "]", "\n", "\n", "total_before_loss", "=", "0", "\n", "total_after_loss", "=", "0", "\n", "total_stop_token_loss", "=", "0", "\n", "total_regularization_loss", "=", "0", "\n", "total_linear_loss", "=", "0", "\n", "total_embedding_loss", "=", "0", "\n", "total_loss", "=", "0", "\n", "\n", "gpus", "=", "[", "\"/gpu:{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "\n", "range", "(", "hp", ".", "tacotron_gpu_start_idx", ",", "hp", ".", "tacotron_gpu_start_idx", "+", "hp", ".", "tacotron_num_gpus", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "\"/cpu:0\"", ",", "\n", "worker_device", "=", "gpus", "[", "i", "]", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"loss\"", ")", "as", "scope", ":", "\n", "                    ", "if", "hp", ".", "mask_decoder", ":", "\n", "# Compute loss of predictions before postnet", "\n", "                        ", "before", "=", "MaskedMSE", "(", "self", ".", "tower_mel_targets", "[", "i", "]", ",", "self", ".", "tower_decoder_output", "[", "i", "]", ",", "\n", "self", ".", "tower_targets_lengths", "[", "i", "]", ",", "\n", "hparams", "=", "self", ".", "_hparams", ")", "\n", "# Compute loss after postnet", "\n", "after", "=", "MaskedMSE", "(", "self", ".", "tower_mel_targets", "[", "i", "]", ",", "self", ".", "tower_mel_outputs", "[", "i", "]", ",", "\n", "self", ".", "tower_targets_lengths", "[", "i", "]", ",", "\n", "hparams", "=", "self", ".", "_hparams", ")", "\n", "# Compute <stop_token> loss (for learning dynamic generation stop)", "\n", "stop_token_loss", "=", "MaskedSigmoidCrossEntropy", "(", "\n", "self", ".", "tower_stop_token_targets", "[", "i", "]", ",", "\n", "self", ".", "tower_stop_token_prediction", "[", "i", "]", ",", "self", ".", "tower_targets_lengths", "[", "i", "]", ",", "\n", "hparams", "=", "self", ".", "_hparams", ")", "\n", "\n", "if", "hp", ".", "embed_loss_func", "==", "'cos'", ":", "\n", "                            ", "loss_func", "=", "tf", ".", "keras", ".", "losses", ".", "CosineSimilarity", "(", "axis", "=", "-", "1", ")", "\n", "embedding_loss", "=", "1.0", "-", "loss_func", "(", "tf", ".", "math", ".", "l2_normalize", "(", "self", ".", "tower_spkembed_targets", "[", "i", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "math", ".", "l2_normalize", "(", "self", ".", "tower_gvectors", "[", "i", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "", "if", "hp", ".", "embed_loss_func", "==", "'mse'", ":", "\n", "                            ", "embedding_loss", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "labels", "=", "self", ".", "tower_spkembed_targets", "[", "i", "]", ",", "\n", "predictions", "=", "self", ".", "tower_gvectors", "[", "i", "]", ")", "\n", "# SV2TTS extra L1 loss (disabled for now)", "\n", "# linear_loss = MaskedLinearLoss(self.tower_mel_targets[i],", "\n", "#                                self.tower_decoder_output[i],", "\n", "#                                self.tower_targets_lengths[i],", "\n", "#                                hparams=self._hparams)", "\n", "", "linear_loss", "=", "0.", "\n", "", "else", ":", "\n", "# Compute loss of predictions before postnet", "\n", "                        ", "before", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "self", ".", "tower_mel_targets", "[", "i", "]", ",", "\n", "self", ".", "tower_decoder_output", "[", "i", "]", ")", "\n", "# Compute loss after postnet", "\n", "after", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "self", ".", "tower_mel_targets", "[", "i", "]", ",", "\n", "self", ".", "tower_mel_outputs", "[", "i", "]", ")", "\n", "# Compute <stop_token> loss (for learning dynamic generation stop)", "\n", "stop_token_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "self", ".", "tower_stop_token_targets", "[", "i", "]", ",", "\n", "logits", "=", "self", ".", "tower_stop_token_prediction", "[", "i", "]", ")", ")", "\n", "\n", "if", "hp", ".", "embed_loss_func", "==", "'cos'", ":", "\n", "                            ", "loss_func", "=", "tf", ".", "keras", ".", "losses", ".", "CosineSimilarity", "(", "axis", "=", "-", "1", ")", "\n", "embedding_loss", "=", "1.0", "-", "loss_func", "(", "tf", ".", "math", ".", "l2_normalize", "(", "self", ".", "tower_spkembed_targets", "[", "i", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "math", ".", "l2_normalize", "(", "self", ".", "tower_gvectors", "[", "i", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "", "if", "hp", ".", "embed_loss_func", "==", "'mse'", ":", "\n", "                            ", "embedding_loss", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "labels", "=", "self", ".", "tower_spkembed_targets", "[", "i", "]", ",", "\n", "predictions", "=", "self", ".", "tower_gvectors", "[", "i", "]", ")", "\n", "\n", "# SV2TTS extra L1 loss", "\n", "", "l1", "=", "tf", ".", "abs", "(", "self", ".", "tower_mel_targets", "[", "i", "]", "-", "self", ".", "tower_decoder_output", "[", "i", "]", ")", "\n", "linear_loss", "=", "tf", ".", "reduce_mean", "(", "l1", ")", "\n", "\n", "# if hp.predict_linear:", "\n", "#     # Compute linear loss", "\n", "#     # From https://github.com/keithito/tacotron/blob/tacotron2-work-in", "\n", "# \t# -progress/models/tacotron.py", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_optimizer": [[427, 496], ["range", "tensorflow.device", "tensorflow.device", "zip", "range", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer", "tensorflow.device", "tensorflow.concat", "tensorflow.reduce_mean", "avg_grads.append", "vars.append", "tensorflow.clip_by_global_norm", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer.apply_gradients", "tacotron.Tacotron._learning_rate_decay", "tensorflow.convert_to_tensor", "tensorflow.train.replica_device_setter", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer.compute_gradients", "tower_gradients.append", "tensorflow.expand_dims", "grads.append", "tensorflow.get_collection", "zip"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["#     # Prioritize loss for frequencies under 2000 Hz.", "\n", "#     l1 = tf.abs(self.tower_linear_targets[i] - self.tower_linear_outputs[i])", "\n", "#     n_priority_freq = int(2000 / (hp.sample_rate * 0.5) * hp.num_freq)", "\n", "#     linear_loss = 0.5 * tf.reduce_mean(l1) + 0.5 * tf.reduce_mean(", "\n", "#         l1[:, :, 0:n_priority_freq])", "\n", "# else:", "\n", "#     linear_loss = 0.", "\n", "\n", "# Compute the regularization weight", "\n", "", "if", "hp", ".", "tacotron_scale_regularization", ":", "\n", "                        ", "reg_weight_scaler", "=", "1.", "/", "(", "\n", "2", "*", "hp", ".", "max_abs_value", ")", "if", "hp", ".", "symmetric_mels", "else", "1.", "/", "(", "\n", "hp", ".", "max_abs_value", ")", "\n", "reg_weight", "=", "hp", ".", "tacotron_reg_weight", "*", "reg_weight_scaler", "\n", "", "else", ":", "\n", "                        ", "reg_weight", "=", "hp", ".", "tacotron_reg_weight", "\n", "\n", "## Compute the embedding loss", "\n", "\n", "\n", "# Regularize variables", "\n", "# Exclude all types of bias, RNN (Bengio et al. On the difficulty of training recurrent neural networks), embeddings and prediction projection layers.", "\n", "# Note that we consider attention mechanism v_a weights as a prediction projection layer and we don\"t regularize it. (This gave better stability)", "\n", "", "regularization", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "for", "v", "in", "self", ".", "all_vars", "\n", "if", "not", "(", "\n", "\"bias\"", "in", "v", ".", "name", "or", "\"Bias\"", "in", "v", ".", "name", "or", "\"_projection\"", "in", "v", ".", "name", "or", "\"inputs_embedding\"", "in", "v", ".", "name", "\n", "or", "\"RNN\"", "in", "v", ".", "name", "or", "\"LSTM\"", "in", "v", ".", "name", ")", "]", ")", "*", "reg_weight", "\n", "\n", "# Compute final loss term", "\n", "self", ".", "tower_before_loss", ".", "append", "(", "before", ")", "\n", "self", ".", "tower_after_loss", ".", "append", "(", "after", ")", "\n", "self", ".", "tower_stop_token_loss", ".", "append", "(", "stop_token_loss", ")", "\n", "self", ".", "tower_embedding_loss", ".", "append", "(", "embedding_loss", ")", "\n", "self", ".", "tower_regularization_loss", ".", "append", "(", "regularization", ")", "\n", "self", ".", "tower_linear_loss", ".", "append", "(", "linear_loss", ")", "\n", "\n", "loss", "=", "before", "+", "after", "+", "stop_token_loss", "+", "regularization", "+", "linear_loss", "\n", "loss", "=", "loss", "+", "self", ".", "embed_loss_scale", "*", "embedding_loss", "\n", "self", ".", "tower_loss", ".", "append", "(", "loss", ")", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", ")", ":", "\n", "            ", "total_before_loss", "+=", "self", ".", "tower_before_loss", "[", "i", "]", "\n", "total_after_loss", "+=", "self", ".", "tower_after_loss", "[", "i", "]", "\n", "total_stop_token_loss", "+=", "self", ".", "tower_stop_token_loss", "[", "i", "]", "\n", "total_regularization_loss", "+=", "self", ".", "tower_regularization_loss", "[", "i", "]", "\n", "total_linear_loss", "+=", "self", ".", "tower_linear_loss", "[", "i", "]", "\n", "total_embedding_loss", "+=", "self", ".", "tower_embedding_loss", "[", "i", "]", "\n", "total_loss", "+=", "self", ".", "tower_loss", "[", "i", "]", "\n", "\n", "", "self", ".", "before_loss", "=", "total_before_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "after_loss", "=", "total_after_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "stop_token_loss", "=", "total_stop_token_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "embedding_loss", "=", "total_embedding_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "regularization_loss", "=", "total_regularization_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "linear_loss", "=", "total_linear_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "self", ".", "loss", "=", "total_loss", "/", "hp", ".", "tacotron_num_gpus", "\n", "\n", "", "def", "add_optimizer", "(", "self", ",", "global_step", ")", ":", "\n", "        ", "\"\"\"Adds optimizer. Sets \"gradients\" and \"optimize\" fields. add_loss must have been called.\n        Args:\n            global_step: int32 scalar Tensor representing current global step in training\n        \"\"\"", "\n", "hp", "=", "self", ".", "_hparams", "\n", "tower_gradients", "=", "[", "]", "\n", "\n", "# 1. Declare GPU Devices", "\n", "gpus", "=", "[", "\"/gpu:{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "\n", "range", "(", "hp", ".", "tacotron_gpu_start_idx", ",", "hp", ".", "tacotron_gpu_start_idx", "+", "hp", ".", "tacotron_num_gpus", ")", "]", "\n", "\n", "grad_device", "=", "\"/cpu:0\"", "if", "hp", ".", "tacotron_num_gpus", ">", "1", "else", "gpus", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron._learning_rate_decay": [[497, 522], ["tensorflow.train.exponential_decay", "tensorflow.minimum", "tensorflow.maximum"], "methods", ["None"], ["\n", "with", "tf", ".", "device", "(", "grad_device", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"optimizer\"", ")", "as", "scope", ":", "\n", "                ", "if", "hp", ".", "tacotron_decay_learning_rate", ":", "\n", "                    ", "self", ".", "decay_steps", "=", "hp", ".", "tacotron_decay_steps", "\n", "self", ".", "decay_rate", "=", "hp", ".", "tacotron_decay_rate", "\n", "self", ".", "learning_rate", "=", "self", ".", "_learning_rate_decay", "(", "\n", "hp", ".", "tacotron_initial_learning_rate", ",", "global_step", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "learning_rate", "=", "tf", ".", "convert_to_tensor", "(", "hp", ".", "tacotron_initial_learning_rate", ")", "\n", "\n", "", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "learning_rate", ",", "hp", ".", "tacotron_adam_beta1", ",", "\n", "hp", ".", "tacotron_adam_beta2", ",", "hp", ".", "tacotron_adam_epsilon", ")", "\n", "\n", "# 2. Compute Gradient", "\n", "", "", "for", "i", "in", "range", "(", "hp", ".", "tacotron_num_gpus", ")", ":", "\n", "#  Device placement", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "\"/cpu:0\"", ",", "\n", "worker_device", "=", "gpus", "[", "i", "]", ")", ")", ":", "\n", "# agg_loss += self.tower_loss[i]", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"optimizer\"", ")", "as", "scope", ":", "\n", "                    ", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "self", ".", "tower_loss", "[", "i", "]", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "\n", "# 3. Average Gradient", "\n", "", "", "", "with", "tf", ".", "device", "(", "grad_device", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.split_func": [[14, 22], ["range", "rst.append"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["def", "split_func", "(", "x", ",", "split_pos", ")", ":", "\n", "    ", "rst", "=", "[", "]", "\n", "start", "=", "0", "\n", "# x will be a numpy array with the contents of the placeholder below", "\n", "for", "i", "in", "range", "(", "split_pos", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "rst", ".", "append", "(", "x", "[", ":", ",", "start", ":", "start", "+", "split_pos", "[", "i", "]", "]", ")", "\n", "start", "+=", "split_pos", "[", "i", "]", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.__init__": [[28, 52], ["tensorflow.python.ops.rnn_cell_impl.assert_like_rnncell", "type", "isinstance", "TypeError", "TypeError", "isinstance", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "helper", ",", "initial_state", ",", "output_layer", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"Initialize CustomDecoder.\n\t\tArgs:\n\t\t\tcell: An `RNNCell` instance.\n\t\t\thelper: A `Helper` instance.\n\t\t\tinitial_state: A (possibly nested tuple of...) tensors and TensorArrays.\n\t\t\t\tThe initial state of the RNNCell.\n\t\t\toutput_layer: (Optional) An instance of `tf.layers.Layer`, i.e.,\n\t\t\t\t`tf.layers.Dense`. Optional layer to apply to the RNN output prior\n\t\t\t\tto storing the result or sampling.\n\t\tRaises:\n\t\t\tTypeError: if `cell`, `helper` or `output_layer` have an incorrect type.\n\t\t\"\"\"", "\n", "rnn_cell_impl", ".", "assert_like_rnncell", "(", "type", "(", "cell", ")", ",", "cell", ")", "\n", "if", "not", "isinstance", "(", "helper", ",", "helper_py", ".", "Helper", ")", ":", "\n", "\t\t\t", "raise", "TypeError", "(", "\"helper must be a Helper, received: %s\"", "%", "type", "(", "helper", ")", ")", "\n", "", "if", "(", "output_layer", "is", "not", "None", "\n", "and", "not", "isinstance", "(", "output_layer", ",", "layers_base", ".", "Layer", ")", ")", ":", "\n", "\t\t\t", "raise", "TypeError", "(", "\n", "\"output_layer must be a Layer, received: %s\"", "%", "type", "(", "output_layer", ")", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_helper", "=", "helper", "\n", "self", ".", "_initial_state", "=", "initial_state", "\n", "self", ".", "_output_layer", "=", "output_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.batch_size": [[53, 56], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_helper", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder._rnn_output_size": [[57, 74], ["tensorflow.python.util.nest.map_structure", "custom_decoder.CustomDecoder._output_layer._compute_output_shape", "tensorflow.python.util.nest.map_structure", "tensorflow.python.framework.tensor_shape.TensorShape().concatenate", "tensorflow.python.framework.tensor_shape.TensorShape"], "methods", ["None"], ["", "def", "_rnn_output_size", "(", "self", ")", ":", "\n", "\t\t", "size", "=", "self", ".", "_cell", ".", "output_size", "\n", "if", "self", ".", "_output_layer", "is", "None", ":", "\n", "\t\t\t", "return", "size", "\n", "", "else", ":", "\n", "# To use layer\"s compute_output_shape, we need to convert the", "\n", "# RNNCell\"s output_size entries into shapes with an unknown", "\n", "# batch size.  We then pass this through the layer\"s", "\n", "# compute_output_shape and read off all but the first (batch)", "\n", "# dimensions to get the output size of the rnn with the layer", "\n", "# applied to the top.", "\n", "\t\t\t", "output_shape_with_unknown_batch", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tensor_shape", ".", "TensorShape", "(", "[", "None", "]", ")", ".", "concatenate", "(", "s", ")", ",", "\n", "size", ")", "\n", "layer_output_shape", "=", "self", ".", "_output_layer", ".", "_compute_output_shape", "(", "# pylint: disable=protected-access", "\n", "output_shape_with_unknown_batch", ")", "\n", "return", "nest", ".", "map_structure", "(", "lambda", "s", ":", "s", "[", "1", ":", "]", ",", "layer_output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.output_size": [[75, 82], ["custom_decoder.CustomDecoderOutput", "custom_decoder.CustomDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder._rnn_output_size"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "# Return the cell output and the id", "\n", "\t\t", "return", "CustomDecoderOutput", "(", "\n", "rnn_output", "=", "self", ".", "_rnn_output_size", "(", ")", ",", "\n", "token_output", "=", "self", ".", "_helper", ".", "token_output_size", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.output_dtype": [[83, 93], ["custom_decoder.CustomDecoderOutput", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.flatten", "custom_decoder.CustomDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder._rnn_output_size"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "# Assume the dtype of the cell is the output_size structure", "\n", "# containing the input_state\"s first component's dtype.", "\n", "# Return that structure and the sample_ids_dtype from the helper.", "\n", "\t\t", "dtype", "=", "nest", ".", "flatten", "(", "self", ".", "_initial_state", ")", "[", "0", "]", ".", "dtype", "\n", "return", "CustomDecoderOutput", "(", "\n", "nest", ".", "map_structure", "(", "lambda", "_", ":", "dtype", ",", "self", ".", "_rnn_output_size", "(", ")", ")", ",", "\n", "tf", ".", "float32", ",", "\n", "self", ".", "_helper", ".", "sample_ids_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.initialize": [[94, 102], ["custom_decoder.CustomDecoder._helper.initialize"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"Initialize the decoder.\n\t\tArgs:\n\t\t\tname: Name scope for any created operations.\n\t\tReturns:\n\t\t\t`(finished, first_inputs, initial_state)`.\n\t\t\"\"\"", "\n", "return", "self", ".", "_helper", ".", "initialize", "(", ")", "+", "(", "self", ".", "_initial_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.custom_decoder.CustomDecoder.step": [[103, 133], ["custom_decoder.CustomDecoderOutput", "tensorflow.python.framework.ops.name_scope", "custom_decoder.CustomDecoder._cell", "custom_decoder.CustomDecoder._helper.sample", "custom_decoder.CustomDecoder._helper.next_inputs", "custom_decoder.CustomDecoder._output_layer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.next_inputs"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"Perform a custom decoding step.\n\t\tEnables for dyanmic <stop_token> prediction\n\t\tArgs:\n\t\t\ttime: scalar `int32` tensor.\n\t\t\tinputs: A (structure of) input tensors.\n\t\t\tstate: A (structure of) state tensors and TensorArrays.\n\t\t\tname: Name scope for any created operations.\n\t\tReturns:\n\t\t\t`(outputs, next_state, next_inputs, finished)`.\n\t\t\"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "name", ",", "\"CustomDecoderStep\"", ",", "(", "time", ",", "inputs", ",", "state", ")", ")", ":", "\n", "#Call outputprojection wrapper cell", "\n", "\t\t\t", "(", "cell_outputs", ",", "stop_token", ")", ",", "cell_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ")", "\n", "\n", "#apply output_layer (if existant)", "\n", "if", "self", ".", "_output_layer", "is", "not", "None", ":", "\n", "\t\t\t\t", "cell_outputs", "=", "self", ".", "_output_layer", "(", "cell_outputs", ")", "\n", "", "sample_ids", "=", "self", ".", "_helper", ".", "sample", "(", "\n", "time", "=", "time", ",", "outputs", "=", "cell_outputs", ",", "state", "=", "cell_state", ")", "\n", "\n", "(", "finished", ",", "next_inputs", ",", "next_state", ")", "=", "self", ".", "_helper", ".", "next_inputs", "(", "\n", "time", "=", "time", ",", "\n", "outputs", "=", "cell_outputs", ",", "\n", "state", "=", "cell_state", ",", "\n", "sample_ids", "=", "sample_ids", ",", "\n", "stop_token_prediction", "=", "stop_token", ")", "\n", "\n", "", "outputs", "=", "CustomDecoderOutput", "(", "cell_outputs", ",", "stop_token", ",", "sample_ids", ")", "\n", "return", "(", "outputs", ",", "next_state", ",", "next_inputs", ",", "finished", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention.LocationSensitiveAttention.__init__": [[111, 164], ["tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__", "tensorflow.layers.Conv1D", "tensorflow.layers.Dense", "tensorflow.zeros_initializer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_units", ",", "\n", "memory", ",", "\n", "hparams", ",", "\n", "mask_encoder", "=", "True", ",", "\n", "memory_sequence_length", "=", "None", ",", "\n", "smoothing", "=", "False", ",", "\n", "cumulate_weights", "=", "True", ",", "\n", "name", "=", "\"LocationSensitiveAttention\"", ")", ":", "\n", "\t\t", "\"\"\"Construct the Attention mechanism.\n\t\tArgs:\n\t\t\tnum_units: The depth of the query mechanism.\n\t\t\tmemory: The memory to query; usually the output of an RNN encoder.  This\n\t\t\t\ttensor should be shaped `[batch_size, max_time, ...]`.\n\t\t\tmask_encoder (optional): Boolean, whether to mask encoder paddings.\n\t\t\tmemory_sequence_length (optional): Sequence lengths for the batch entries\n\t\t\t\tin memory.  If provided, the memory tensor rows are masked with zeros\n\t\t\t\tfor values past the respective sequence lengths. Only relevant if mask_encoder = True.\n\t\t\tsmoothing (optional): Boolean. Determines which normalization function to use.\n\t\t\t\tDefault normalization function (probablity_fn) is softmax. If smoothing is\n\t\t\t\tenabled, we replace softmax with:\n\t\t\t\t\t\ta_{i, j} = sigmoid(e_{i, j}) / sum_j(sigmoid(e_{i, j}))\n\t\t\t\tIntroduced in:\n\t\t\t\t\tJ. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Ben-\n\t\t\t\t  gio, \u201cAttention-based models for speech recognition,\u201d in Ad-\n\t\t\t\t  vances in Neural Information Processing Systems, 2015, pp.\n\t\t\t\t  577\u2013585.\n\t\t\t\tThis is mainly used if the model wants to attend to multiple input parts\n\t\t\t\tat the same decoding step. We probably won\"t be using it since multiple sound\n\t\t\t\tframes may depend on the same character/phone, probably not the way around.\n\t\t\t\tNote:\n\t\t\t\t\tWe still keep it implemented in case we want to test it. They used it in the\n\t\t\t\t\tpaper in the context of speech recognition, where one phoneme may depend on\n\t\t\t\t\tmultiple subsequent sound frames.\n\t\t\tname: Name to use when creating ops.\n\t\t\"\"\"", "\n", "#Create normalization function", "\n", "#Setting it to None defaults in using softmax", "\n", "normalization_function", "=", "_smoothing_normalization", "if", "(", "smoothing", "==", "True", ")", "else", "None", "\n", "memory_length", "=", "memory_sequence_length", "if", "(", "mask_encoder", "==", "True", ")", "else", "None", "\n", "super", "(", "LocationSensitiveAttention", ",", "self", ")", ".", "__init__", "(", "\n", "num_units", "=", "num_units", ",", "\n", "memory", "=", "memory", ",", "\n", "memory_sequence_length", "=", "memory_length", ",", "\n", "probability_fn", "=", "normalization_function", ",", "\n", "name", "=", "name", ")", "\n", "\n", "self", ".", "location_convolution", "=", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "hparams", ".", "attention_filters", ",", "\n", "kernel_size", "=", "hparams", ".", "attention_kernel", ",", "padding", "=", "\"same\"", ",", "use_bias", "=", "True", ",", "\n", "bias_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "name", "=", "\"location_features_convolution\"", ")", "\n", "self", ".", "location_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "num_units", ",", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"location_features_layer\"", ")", "\n", "self", ".", "_cumulate", "=", "cumulate_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention.LocationSensitiveAttention.__call__": [[165, 208], ["attention.LocationSensitiveAttention._probability_fn", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.expand_dims", "tensorflow.expand_dims", "attention.LocationSensitiveAttention.location_convolution", "attention.LocationSensitiveAttention.location_layer", "attention._location_sensitive_score", "attention.LocationSensitiveAttention.query_layer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention._location_sensitive_score"], ["", "def", "__call__", "(", "self", ",", "query", ",", "state", ")", ":", "\n", "\t\t", "\"\"\"Score the query based on the keys and values.\n\t\tArgs:\n\t\t\tquery: Tensor of dtype matching `self.values` and shape\n\t\t\t\t`[batch_size, query_depth]`.\n\t\t\tstate (previous alignments): Tensor of dtype matching `self.values` and shape\n\t\t\t\t`[batch_size, alignments_size]`\n\t\t\t\t(`alignments_size` is memory\"s `max_time`).\n\t\tReturns:\n\t\t\talignments: Tensor of dtype matching `self.values` and shape\n\t\t\t\t`[batch_size, alignments_size]` (`alignments_size` is memory's\n\t\t\t\t`max_time`).\n\t\t\"\"\"", "\n", "previous_alignments", "=", "state", "\n", "with", "variable_scope", ".", "variable_scope", "(", "None", ",", "\"Location_Sensitive_Attention\"", ",", "[", "query", "]", ")", ":", "\n", "\n", "# processed_query shape [batch_size, query_depth] -> [batch_size, attention_dim]", "\n", "\t\t\t", "processed_query", "=", "self", ".", "query_layer", "(", "query", ")", "if", "self", ".", "query_layer", "else", "query", "\n", "# -> [batch_size, 1, attention_dim]", "\n", "processed_query", "=", "tf", ".", "expand_dims", "(", "processed_query", ",", "1", ")", "\n", "\n", "# processed_location_features shape [batch_size, max_time, attention dimension]", "\n", "# [batch_size, max_time] -> [batch_size, max_time, 1]", "\n", "expanded_alignments", "=", "tf", ".", "expand_dims", "(", "previous_alignments", ",", "axis", "=", "2", ")", "\n", "# location features [batch_size, max_time, filters]", "\n", "f", "=", "self", ".", "location_convolution", "(", "expanded_alignments", ")", "\n", "# Projected location features [batch_size, max_time, attention_dim]", "\n", "processed_location_features", "=", "self", ".", "location_layer", "(", "f", ")", "\n", "\n", "# energy shape [batch_size, max_time]", "\n", "energy", "=", "_location_sensitive_score", "(", "processed_query", ",", "processed_location_features", ",", "self", ".", "keys", ")", "\n", "\n", "\n", "# alignments shape = energy shape = [batch_size, max_time]", "\n", "", "alignments", "=", "self", ".", "_probability_fn", "(", "energy", ",", "previous_alignments", ")", "\n", "\n", "# Cumulate alignments", "\n", "if", "self", ".", "_cumulate", ":", "\n", "\t\t\t", "next_state", "=", "alignments", "+", "previous_alignments", "\n", "", "else", ":", "\n", "\t\t\t", "next_state", "=", "alignments", "\n", "\n", "", "return", "alignments", ",", "next_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention._compute_attention": [[10, 36], ["attention_mechanism", "tensorflow.python.ops.array_ops.expand_dims", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.array_ops.squeeze", "attention_layer", "tensorflow.python.ops.array_ops.concat"], "function", ["None"], ["def", "_compute_attention", "(", "attention_mechanism", ",", "cell_output", ",", "attention_state", ",", "\n", "attention_layer", ")", ":", "\n", "\t", "\"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"", "\n", "alignments", ",", "next_attention_state", "=", "attention_mechanism", "(", "\n", "cell_output", ",", "state", "=", "attention_state", ")", "\n", "\n", "# Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]", "\n", "expanded_alignments", "=", "array_ops", ".", "expand_dims", "(", "alignments", ",", "1", ")", "\n", "# Context is the inner product of alignments and values along the", "\n", "# memory time dimension.", "\n", "# alignments shape is", "\n", "#   [batch_size, 1, memory_time]", "\n", "# attention_mechanism.values shape is", "\n", "#   [batch_size, memory_time, memory_size]", "\n", "# the batched matmul is over memory_time, so the output shape is", "\n", "#   [batch_size, 1, memory_size].", "\n", "# we then squeeze out the singleton dim.", "\n", "context", "=", "math_ops", ".", "matmul", "(", "expanded_alignments", ",", "attention_mechanism", ".", "values", ")", "\n", "context", "=", "array_ops", ".", "squeeze", "(", "context", ",", "[", "1", "]", ")", "\n", "\n", "if", "attention_layer", "is", "not", "None", ":", "\n", "\t\t", "attention", "=", "attention_layer", "(", "array_ops", ".", "concat", "(", "[", "cell_output", ",", "context", "]", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "attention", "=", "context", "\n", "\n", "", "return", "attention", ",", "alignments", ",", "next_attention_state", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention._location_sensitive_score": [[38, 71], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.python.ops.array_ops.shape", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.zeros_initializer", "tensorflow.tanh"], "function", ["None"], ["", "def", "_location_sensitive_score", "(", "W_query", ",", "W_fil", ",", "W_keys", ")", ":", "\n", "\t", "\"\"\"Impelements Bahdanau-style (cumulative) scoring function.\n\tThis attention is described in:\n\t\tJ. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Ben-\n\t  gio, \u201cAttention-based models for speech recognition,\u201d in Ad-\n\t  vances in Neural Information Processing Systems, 2015, pp.\n\t  577\u2013585.\n\n\t#############################################################################\n\t\t\t  hybrid attention (content-based + location-based)\n\t\t\t\t\t\t\t   f = F * \u03b1_{i-1}\n\t   energy = dot(v_a, tanh(W_keys(h_enc) + W_query(h_dec) + W_fil(f) + b_a))\n\t#############################################################################\n\n\tArgs:\n\t\tW_query: Tensor, shape \"[batch_size, 1, attention_dim]\" to compare to location features.\n\t\tW_location: processed previous alignments into location features, shape \"[batch_size, max_time, attention_dim]\"\n\t\tW_keys: Tensor, shape \"[batch_size, max_time, attention_dim]\", typically the encoder outputs.\n\tReturns:\n\t\tA \"[batch_size, max_time]\" attention score (energy)\n\t\"\"\"", "\n", "# Get the number of hidden units from the trailing dimension of keys", "\n", "dtype", "=", "W_query", ".", "dtype", "\n", "num_units", "=", "W_keys", ".", "shape", "[", "-", "1", "]", ".", "value", "or", "array_ops", ".", "shape", "(", "W_keys", ")", "[", "-", "1", "]", "\n", "\n", "v_a", "=", "tf", ".", "get_variable", "(", "\n", "\"attention_variable_projection\"", ",", "shape", "=", "[", "num_units", "]", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "b_a", "=", "tf", ".", "get_variable", "(", "\n", "\"attention_bias\"", ",", "shape", "=", "[", "num_units", "]", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "return", "tf", ".", "reduce_sum", "(", "v_a", "*", "tf", ".", "tanh", "(", "W_keys", "+", "W_query", "+", "W_fil", "+", "b_a", ")", ",", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.attention._smoothing_normalization": [[72, 93], ["tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.nn.sigmoid"], "function", ["None"], ["", "def", "_smoothing_normalization", "(", "e", ")", ":", "\n", "\t", "\"\"\"Applies a smoothing normalization function instead of softmax\n\tIntroduced in:\n\t\tJ. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Ben-\n\t  gio, \u201cAttention-based models for speech recognition,\u201d in Ad-\n\t  vances in Neural Information Processing Systems, 2015, pp.\n\t  577\u2013585.\n\n\t############################################################################\n\t\t\t\t\t\tSmoothing normalization function\n\t\t\t\ta_{i, j} = sigmoid(e_{i, j}) / sum_j(sigmoid(e_{i, j}))\n\t############################################################################\n\n\tArgs:\n\t\te: matrix [batch_size, max_time(memory_time)]: expected to be energy (score)\n\t\t\tvalues of an attention mechanism\n\tReturns:\n\t\tmatrix [batch_size, max_time]: [0, 1] normalized alignments with possible\n\t\t\tattendance to multiple memory time steps.\n\t\"\"\"", "\n", "return", "tf", ".", "nn", ".", "sigmoid", "(", "e", ")", "/", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid", "(", "e", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.__init__": [[7, 13], ["tensorflow.name_scope"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "batch_size", ",", "hparams", ")", ":", "\n", "\t\t", "with", "tf", ".", "name_scope", "(", "\"TacoTestHelper\"", ")", ":", "\n", "\t\t\t", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_output_dim", "=", "hparams", ".", "num_mels", "\n", "self", ".", "_reduction_factor", "=", "hparams", ".", "outputs_per_step", "\n", "self", ".", "stop_at_any", "=", "hparams", ".", "stop_at_any", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.batch_size": [[14, 17], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.token_output_size": [[18, 21], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "token_output_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_reduction_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.sample_ids_shape": [[22, 25], ["tensorflow.TensorShape"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_shape", "(", "self", ")", ":", "\n", "\t\t", "return", "tf", ".", "TensorShape", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.sample_ids_dtype": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_dtype", "(", "self", ")", ":", "\n", "\t\t", "return", "np", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.initialize": [[30, 32], ["tensorflow.tile", "helpers._go_frames"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers._go_frames"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "return", "(", "tf", ".", "tile", "(", "[", "False", "]", ",", "[", "self", ".", "_batch_size", "]", ")", ",", "_go_frames", "(", "self", ".", "_batch_size", ",", "self", ".", "_output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.sample": [[33, 35], ["tensorflow.tile"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "return", "tf", ".", "tile", "(", "[", "0", "]", ",", "[", "self", ".", "_batch_size", "]", ")", "# Return all 0; we ignore them", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTestHelper.next_inputs": [[36, 60], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.round", "tensorflow.reduce_any", "tensorflow.reduce_all", "tensorflow.reduce_all", "tensorflow.reduce_all"], "methods", ["None"], ["", "def", "next_inputs", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "sample_ids", ",", "stop_token_prediction", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"Stop on EOS. Otherwise, pass the last output as the next input and pass through state.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"TacoTestHelper\"", ")", ":", "\n", "#A sequence is finished when the output probability is > 0.5", "\n", "\t\t\t", "finished", "=", "tf", ".", "cast", "(", "tf", ".", "round", "(", "stop_token_prediction", ")", ",", "tf", ".", "bool", ")", "\n", "\n", "#Since we are predicting r frames at each step, two modes are", "\n", "#then possible:", "\n", "#\tStop when the model outputs a p > 0.5 for any frame between r frames (Recommended)", "\n", "#\tStop when the model outputs a p > 0.5 for all r frames (Safer)", "\n", "#Note:", "\n", "#\tWith enough training steps, the model should be able to predict when to stop correctly", "\n", "#\tand the use of stop_at_any = True would be recommended. If however the model didn\"t", "\n", "#\tlearn to stop correctly yet, (stops too soon) one could choose to use the safer option", "\n", "#\tto get a correct synthesis", "\n", "if", "self", ".", "stop_at_any", ":", "\n", "\t\t\t\t", "finished", "=", "tf", ".", "reduce_any", "(", "tf", ".", "reduce_all", "(", "finished", ",", "axis", "=", "0", ")", ")", "#Recommended", "\n", "", "else", ":", "\n", "\t\t\t\t", "finished", "=", "tf", ".", "reduce_all", "(", "tf", ".", "reduce_all", "(", "finished", ",", "axis", "=", "0", ")", ")", "#Safer option", "\n", "\n", "# Feed last output frame as next input. outputs is [N, output_dim * r]", "\n", "", "next_inputs", "=", "outputs", "[", ":", ",", "-", "self", ".", "_output_dim", ":", "]", "\n", "next_state", "=", "state", "\n", "return", "(", "finished", ",", "next_inputs", ",", "next_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.__init__": [[63, 81], ["tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.tile", "tensorflow.shape"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "batch_size", ",", "targets", ",", "hparams", ",", "gta", ",", "evaluating", ",", "global_step", ")", ":", "\n", "# inputs is [N, T_in], targets is [N, T_out, D]", "\n", "\t\t", "with", "tf", ".", "name_scope", "(", "\"TacoTrainingHelper\"", ")", ":", "\n", "\t\t\t", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_output_dim", "=", "hparams", ".", "num_mels", "\n", "self", ".", "_reduction_factor", "=", "hparams", ".", "outputs_per_step", "\n", "self", ".", "_ratio", "=", "tf", ".", "convert_to_tensor", "(", "hparams", ".", "tacotron_teacher_forcing_ratio", ")", "\n", "self", ".", "gta", "=", "gta", "\n", "self", ".", "eval", "=", "evaluating", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "global_step", "=", "global_step", "\n", "\n", "r", "=", "self", ".", "_reduction_factor", "\n", "# Feed every r-th target frame as input", "\n", "self", ".", "_targets", "=", "targets", "[", ":", ",", "r", "-", "1", ":", ":", "r", ",", ":", "]", "\n", "\n", "#Maximal sequence length", "\n", "self", ".", "_lengths", "=", "tf", ".", "tile", "(", "[", "tf", ".", "shape", "(", "self", ".", "_targets", ")", "[", "1", "]", "]", ",", "[", "self", ".", "_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.batch_size": [[82, 85], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.token_output_size": [[86, 89], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "token_output_size", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "_reduction_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample_ids_shape": [[90, 93], ["tensorflow.TensorShape"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_shape", "(", "self", ")", ":", "\n", "\t\t", "return", "tf", ".", "TensorShape", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample_ids_dtype": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_dtype", "(", "self", ")", ":", "\n", "\t\t", "return", "np", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize": [[98, 111], ["tensorflow.convert_to_tensor", "tensorflow.tile", "helpers._go_frames", "tensorflow.convert_to_tensor", "helpers._teacher_forcing_ratio_decay"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers._go_frames", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers._teacher_forcing_ratio_decay"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "#Compute teacher forcing ratio for this global step.", "\n", "#In GTA mode, override teacher forcing scheme to work with full teacher forcing", "\n", "\t\t", "if", "self", ".", "gta", ":", "\n", "\t\t\t", "self", ".", "_ratio", "=", "tf", ".", "convert_to_tensor", "(", "1.", ")", "#Force GTA model to always feed ground-truth", "\n", "", "elif", "self", ".", "eval", "and", "self", ".", "_hparams", ".", "natural_eval", ":", "\n", "\t\t\t", "self", ".", "_ratio", "=", "tf", ".", "convert_to_tensor", "(", "0.", ")", "#Force eval model to always feed predictions", "\n", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "_hparams", ".", "tacotron_teacher_forcing_mode", "==", "\"scheduled\"", ":", "\n", "\t\t\t\t", "self", ".", "_ratio", "=", "_teacher_forcing_ratio_decay", "(", "self", ".", "_hparams", ".", "tacotron_teacher_forcing_init_ratio", ",", "\n", "self", ".", "global_step", ",", "self", ".", "_hparams", ")", "\n", "\n", "", "", "return", "(", "tf", ".", "tile", "(", "[", "False", "]", ",", "[", "self", ".", "_batch_size", "]", ")", ",", "_go_frames", "(", "self", ".", "_batch_size", ",", "self", ".", "_output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.sample": [[112, 114], ["tensorflow.tile"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "return", "tf", ".", "tile", "(", "[", "0", "]", ",", "[", "self", ".", "_batch_size", "]", ")", "# Return all 0; we ignore them", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.next_inputs": [[115, 129], ["tensorflow.name_scope", "tensorflow.cond", "tensorflow.less", "tensorflow.random_uniform"], "methods", ["None"], ["", "def", "next_inputs", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "sample_ids", ",", "stop_token_prediction", ",", "name", "=", "None", ")", ":", "\n", "\t\t", "with", "tf", ".", "name_scope", "(", "name", "or", "\"TacoTrainingHelper\"", ")", ":", "\n", "#synthesis stop (we let the model see paddings as we mask them when computing loss functions)", "\n", "\t\t\t", "finished", "=", "(", "time", "+", "1", ">=", "self", ".", "_lengths", ")", "\n", "\n", "#Pick previous outputs randomly with respect to teacher forcing ratio", "\n", "next_inputs", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "less", "(", "tf", ".", "random_uniform", "(", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "1", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "self", ".", "_ratio", ")", ",", "\n", "lambda", ":", "self", ".", "_targets", "[", ":", ",", "time", ",", ":", "]", ",", "#Teacher-forcing: return true frame", "\n", "lambda", ":", "outputs", "[", ":", ",", "-", "self", ".", "_output_dim", ":", "]", ")", "\n", "\n", "#Pass on state", "\n", "next_state", "=", "state", "\n", "return", "(", "finished", ",", "next_inputs", ",", "next_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers._go_frames": [[131, 134], ["tensorflow.tile"], "function", ["None"], ["", "", "", "def", "_go_frames", "(", "batch_size", ",", "output_dim", ")", ":", "\n", "\t", "\"\"\"Returns all-zero <GO> frames for a given batch size and output dimension\"\"\"", "\n", "return", "tf", ".", "tile", "(", "[", "[", "0.0", "]", "]", ",", "[", "batch_size", ",", "output_dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers._teacher_forcing_ratio_decay": [[135, 162], ["tensorflow.train.cosine_decay", "tensorflow.cond", "tensorflow.less", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "function", ["None"], ["", "def", "_teacher_forcing_ratio_decay", "(", "init_tfr", ",", "global_step", ",", "hparams", ")", ":", "\n", "#################################################################", "\n", "# Narrow Cosine Decay:", "\n", "\n", "# Phase 1: tfr = 1", "\n", "# We only start learning rate decay after 10k steps", "\n", "\n", "# Phase 2: tfr in ]0, 1[", "\n", "# decay reach minimal value at step ~280k", "\n", "\n", "# Phase 3: tfr = 0", "\n", "# clip by minimal teacher forcing ratio value (step >~ 280k)", "\n", "#################################################################", "\n", "#Compute natural cosine decay", "\n", "\t\t", "tfr", "=", "tf", ".", "train", ".", "cosine_decay", "(", "init_tfr", ",", "\n", "global_step", "=", "global_step", "-", "hparams", ".", "tacotron_teacher_forcing_start_decay", ",", "#tfr = 1 at step 10k", "\n", "decay_steps", "=", "hparams", ".", "tacotron_teacher_forcing_decay_steps", ",", "#tfr = 0 at step ~280k", "\n", "alpha", "=", "hparams", ".", "tacotron_teacher_forcing_decay_alpha", ",", "#tfr = 0% of init_tfr as final value", "\n", "name", "=", "\"tfr_cosine_decay\"", ")", "\n", "\n", "#force teacher forcing ratio to take initial value when global step < start decay step.", "\n", "narrow_tfr", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "less", "(", "global_step", ",", "tf", ".", "convert_to_tensor", "(", "hparams", ".", "tacotron_teacher_forcing_start_decay", ")", ")", ",", "\n", "lambda", ":", "tf", ".", "convert_to_tensor", "(", "init_tfr", ")", ",", "\n", "lambda", ":", "tfr", ")", "\n", "\n", "return", "narrow_tfr", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.__init__.create_model": [[4, 9], ["tacotron.Tacotron", "Exception"], "function", ["None"], ["self", ".", "_values", "=", "[", "]", "\n", "\n", "", "def", "append", "(", "self", ",", "x", ")", ":", "\n", "    ", "self", ".", "_values", "=", "self", ".", "_values", "[", "-", "(", "self", ".", "_window_size", "-", "1", ")", ":", "]", "+", "[", "x", "]", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers._remove_commas": [[13, 15], ["m.group().replace", "m.group"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["def", "_remove_commas", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers._expand_decimal_point": [[17, 19], ["m.group().replace", "m.group"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "_expand_decimal_point", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "\".\"", ",", "\" point \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers._expand_dollars": [[21, 40], ["m.group", "m.group.split", "len", "int", "int", "len"], "function", ["None"], ["", "def", "_expand_dollars", "(", "m", ")", ":", "\n", "  ", "match", "=", "m", ".", "group", "(", "1", ")", "\n", "parts", "=", "match", ".", "split", "(", "\".\"", ")", "\n", "if", "len", "(", "parts", ")", ">", "2", ":", "\n", "    ", "return", "match", "+", "\" dollars\"", "# Unexpected format", "\n", "", "dollars", "=", "int", "(", "parts", "[", "0", "]", ")", "if", "parts", "[", "0", "]", "else", "0", "\n", "cents", "=", "int", "(", "parts", "[", "1", "]", ")", "if", "len", "(", "parts", ")", ">", "1", "and", "parts", "[", "1", "]", "else", "0", "\n", "if", "dollars", "and", "cents", ":", "\n", "    ", "dollar_unit", "=", "\"dollar\"", "if", "dollars", "==", "1", "else", "\"dollars\"", "\n", "cent_unit", "=", "\"cent\"", "if", "cents", "==", "1", "else", "\"cents\"", "\n", "return", "\"%s %s, %s %s\"", "%", "(", "dollars", ",", "dollar_unit", ",", "cents", ",", "cent_unit", ")", "\n", "", "elif", "dollars", ":", "\n", "    ", "dollar_unit", "=", "\"dollar\"", "if", "dollars", "==", "1", "else", "\"dollars\"", "\n", "return", "\"%s %s\"", "%", "(", "dollars", ",", "dollar_unit", ")", "\n", "", "elif", "cents", ":", "\n", "    ", "cent_unit", "=", "\"cent\"", "if", "cents", "==", "1", "else", "\"cents\"", "\n", "return", "\"%s %s\"", "%", "(", "cents", ",", "cent_unit", ")", "\n", "", "else", ":", "\n", "    ", "return", "\"zero dollars\"", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers._expand_ordinal": [[42, 44], ["_inflect.number_to_words", "m.group"], "function", ["None"], ["", "", "def", "_expand_ordinal", "(", "m", ")", ":", "\n", "  ", "return", "_inflect", ".", "number_to_words", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers._expand_number": [[46, 59], ["int", "m.group", "_inflect.number_to_words", "_inflect.number_to_words", "_inflect.number_to_words().replace", "_inflect.number_to_words", "_inflect.number_to_words"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "_expand_number", "(", "m", ")", ":", "\n", "  ", "num", "=", "int", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "if", "num", ">", "1000", "and", "num", "<", "3000", ":", "\n", "    ", "if", "num", "==", "2000", ":", "\n", "      ", "return", "\"two thousand\"", "\n", "", "elif", "num", ">", "2000", "and", "num", "<", "2010", ":", "\n", "      ", "return", "\"two thousand \"", "+", "_inflect", ".", "number_to_words", "(", "num", "%", "100", ")", "\n", "", "elif", "num", "%", "100", "==", "0", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", "//", "100", ")", "+", "\" hundred\"", "\n", "", "else", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "\"\"", ",", "zero", "=", "\"oh\"", ",", "group", "=", "2", ")", ".", "replace", "(", "\", \"", ",", "\" \"", ")", "\n", "", "", "else", ":", "\n", "    ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers.normalize_numbers": [[61, 69], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["None"], ["", "", "def", "normalize_numbers", "(", "text", ")", ":", "\n", "  ", "text", "=", "re", ".", "sub", "(", "_comma_number_re", ",", "_remove_commas", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_pounds_re", ",", "r\"\\1 pounds\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_dollars_re", ",", "_expand_dollars", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_decimal_number_re", ",", "_expand_decimal_point", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_ordinal_re", ",", "_expand_ordinal", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_number_re", ",", "_expand_number", ",", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.profile_noise": [[36, 70], ["logmmse.to_float", "int", "int", "numpy.hanning", "numpy.zeros", "range", "NoiseProfile", "numpy.finfo", "int", "math.floor", "numpy.sum", "len", "numpy.absolute", "math.floor", "numpy.fft.fft"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.to_float", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["def", "profile_noise", "(", "noise", ",", "sampling_rate", ",", "window_size", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Creates a profile of the noise in a given waveform.\n    \n    :param noise: a waveform containing noise ONLY, as a numpy array of floats or ints. \n    :param sampling_rate: the sampling rate of the audio\n    :param window_size: the size of the window the logmmse algorithm operates on. A default value \n    will be picked if left as 0.\n    :return: a NoiseProfile object\n    \"\"\"", "\n", "noise", ",", "dtype", "=", "to_float", "(", "noise", ")", "\n", "noise", "+=", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", "\n", "\n", "if", "window_size", "==", "0", ":", "\n", "        ", "window_size", "=", "int", "(", "math", ".", "floor", "(", "0.02", "*", "sampling_rate", ")", ")", "\n", "\n", "", "if", "window_size", "%", "2", "==", "1", ":", "\n", "        ", "window_size", "=", "window_size", "+", "1", "\n", "\n", "", "perc", "=", "50", "\n", "len1", "=", "int", "(", "math", ".", "floor", "(", "window_size", "*", "perc", "/", "100", ")", ")", "\n", "len2", "=", "int", "(", "window_size", "-", "len1", ")", "\n", "\n", "win", "=", "np", ".", "hanning", "(", "window_size", ")", "\n", "win", "=", "win", "*", "len2", "/", "np", ".", "sum", "(", "win", ")", "\n", "n_fft", "=", "2", "*", "window_size", "\n", "\n", "noise_mean", "=", "np", ".", "zeros", "(", "n_fft", ")", "\n", "n_frames", "=", "len", "(", "noise", ")", "//", "window_size", "\n", "for", "j", "in", "range", "(", "0", ",", "window_size", "*", "n_frames", ",", "window_size", ")", ":", "\n", "        ", "noise_mean", "+=", "np", ".", "absolute", "(", "np", ".", "fft", ".", "fft", "(", "win", "*", "noise", "[", "j", ":", "j", "+", "window_size", "]", ",", "n_fft", ",", "axis", "=", "0", ")", ")", "\n", "", "noise_mu2", "=", "(", "noise_mean", "/", "n_frames", ")", "**", "2", "\n", "\n", "return", "NoiseProfile", "(", "sampling_rate", ",", "window_size", ",", "len1", ",", "len2", ",", "win", ",", "n_fft", ",", "noise_mu2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.denoise": [[72, 134], ["logmmse.to_float", "int", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "logmmse.from_float", "numpy.pad", "numpy.finfo", "numpy.fft.fft", "numpy.absolute", "numpy.minimum", "numpy.fft.ifft", "numpy.real", "math.floor", "math.floor", "np.zeros.all", "numpy.maximum", "numpy.log", "numpy.sum", "scipy.special.expn", "numpy.exp", "numpy.maximum", "len", "len", "len", "numpy.maximum", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.to_float", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.from_float", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "def", "denoise", "(", "wav", ",", "noise_profile", ":", "NoiseProfile", ",", "eta", "=", "0.15", ")", ":", "\n", "    ", "\"\"\"\n    Cleans the noise from a speech waveform given a noise profile. The waveform must have the \n    same sampling rate as the one used to create the noise profile. \n    \n    :param wav: a speech waveform as a numpy array of floats or ints.\n    :param noise_profile: a NoiseProfile object that was created from a similar (or a segment of \n    the same) waveform.\n    :param eta: voice threshold for noise update. While the voice activation detection value is \n    below this threshold, the noise profile will be continuously updated throughout the audio. \n    Set to 0 to disable updating the noise profile.\n    :return: the clean wav as a numpy array of floats or ints of the same length.\n    \"\"\"", "\n", "wav", ",", "dtype", "=", "to_float", "(", "wav", ")", "\n", "wav", "+=", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", "\n", "p", "=", "noise_profile", "\n", "\n", "nframes", "=", "int", "(", "math", ".", "floor", "(", "len", "(", "wav", ")", "/", "p", ".", "len2", ")", "-", "math", ".", "floor", "(", "p", ".", "window_size", "/", "p", ".", "len2", ")", ")", "\n", "x_final", "=", "np", ".", "zeros", "(", "nframes", "*", "p", ".", "len2", ")", "\n", "\n", "aa", "=", "0.98", "\n", "mu", "=", "0.98", "\n", "ksi_min", "=", "10", "**", "(", "-", "25", "/", "10", ")", "\n", "\n", "x_old", "=", "np", ".", "zeros", "(", "p", ".", "len1", ")", "\n", "xk_prev", "=", "np", ".", "zeros", "(", "p", ".", "len1", ")", "\n", "noise_mu2", "=", "p", ".", "noise_mu2", "\n", "for", "k", "in", "range", "(", "0", ",", "nframes", "*", "p", ".", "len2", ",", "p", ".", "len2", ")", ":", "\n", "        ", "insign", "=", "p", ".", "win", "*", "wav", "[", "k", ":", "k", "+", "p", ".", "window_size", "]", "\n", "\n", "spec", "=", "np", ".", "fft", ".", "fft", "(", "insign", ",", "p", ".", "n_fft", ",", "axis", "=", "0", ")", "\n", "sig", "=", "np", ".", "absolute", "(", "spec", ")", "\n", "sig2", "=", "sig", "**", "2", "\n", "\n", "gammak", "=", "np", ".", "minimum", "(", "sig2", "/", "noise_mu2", ",", "40", ")", "\n", "\n", "if", "xk_prev", ".", "all", "(", ")", "==", "0", ":", "\n", "            ", "ksi", "=", "aa", "+", "(", "1", "-", "aa", ")", "*", "np", ".", "maximum", "(", "gammak", "-", "1", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "ksi", "=", "aa", "*", "xk_prev", "/", "noise_mu2", "+", "(", "1", "-", "aa", ")", "*", "np", ".", "maximum", "(", "gammak", "-", "1", ",", "0", ")", "\n", "ksi", "=", "np", ".", "maximum", "(", "ksi_min", ",", "ksi", ")", "\n", "\n", "", "log_sigma_k", "=", "gammak", "*", "ksi", "/", "(", "1", "+", "ksi", ")", "-", "np", ".", "log", "(", "1", "+", "ksi", ")", "\n", "vad_decision", "=", "np", ".", "sum", "(", "log_sigma_k", ")", "/", "p", ".", "window_size", "\n", "if", "vad_decision", "<", "eta", ":", "\n", "            ", "noise_mu2", "=", "mu", "*", "noise_mu2", "+", "(", "1", "-", "mu", ")", "*", "sig2", "\n", "\n", "", "a", "=", "ksi", "/", "(", "1", "+", "ksi", ")", "\n", "vk", "=", "a", "*", "gammak", "\n", "ei_vk", "=", "0.5", "*", "expn", "(", "1", ",", "np", ".", "maximum", "(", "vk", ",", "1e-8", ")", ")", "\n", "hw", "=", "a", "*", "np", ".", "exp", "(", "ei_vk", ")", "\n", "sig", "=", "sig", "*", "hw", "\n", "xk_prev", "=", "sig", "**", "2", "\n", "xi_w", "=", "np", ".", "fft", ".", "ifft", "(", "hw", "*", "spec", ",", "p", ".", "n_fft", ",", "axis", "=", "0", ")", "\n", "xi_w", "=", "np", ".", "real", "(", "xi_w", ")", "\n", "\n", "x_final", "[", "k", ":", "k", "+", "p", ".", "len2", "]", "=", "x_old", "+", "xi_w", "[", "0", ":", "p", ".", "len1", "]", "\n", "x_old", "=", "xi_w", "[", "p", ".", "len1", ":", "p", ".", "window_size", "]", "\n", "\n", "", "output", "=", "from_float", "(", "x_final", ",", "dtype", ")", "\n", "output", "=", "np", ".", "pad", "(", "output", ",", "(", "0", ",", "len", "(", "wav", ")", "-", "len", "(", "output", ")", ")", ",", "mode", "=", "\"constant\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.to_float": [[221, 233], ["ValueError", "_input.astype"], "function", ["None"], ["", "def", "to_float", "(", "_input", ")", ":", "\n", "    ", "if", "_input", ".", "dtype", "==", "np", ".", "float64", ":", "\n", "        ", "return", "_input", ",", "_input", ".", "dtype", "\n", "", "elif", "_input", ".", "dtype", "==", "np", ".", "float32", ":", "\n", "        ", "return", "_input", ".", "astype", "(", "np", ".", "float64", ")", ",", "_input", ".", "dtype", "\n", "", "elif", "_input", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "        ", "return", "(", "_input", "-", "128", ")", "/", "128.", ",", "_input", ".", "dtype", "\n", "", "elif", "_input", ".", "dtype", "==", "np", ".", "int16", ":", "\n", "        ", "return", "_input", "/", "32768.", ",", "_input", ".", "dtype", "\n", "", "elif", "_input", ".", "dtype", "==", "np", ".", "int32", ":", "\n", "        ", "return", "_input", "/", "2147483648.", ",", "_input", ".", "dtype", "\n", "", "raise", "ValueError", "(", "'Unsupported wave file format'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.from_float": [[235, 248], ["ValueError", "_input.astype", "print"], "function", ["None"], ["", "def", "from_float", "(", "_input", ",", "dtype", ")", ":", "\n", "    ", "if", "dtype", "==", "np", ".", "float64", ":", "\n", "        ", "return", "_input", ",", "np", ".", "float64", "\n", "", "elif", "dtype", "==", "np", ".", "float32", ":", "\n", "        ", "return", "_input", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "elif", "dtype", "==", "np", ".", "uint8", ":", "\n", "        ", "return", "(", "(", "_input", "*", "128", ")", "+", "128", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "elif", "dtype", "==", "np", ".", "int16", ":", "\n", "        ", "return", "(", "_input", "*", "32768", ")", ".", "astype", "(", "np", ".", "int16", ")", "\n", "", "elif", "dtype", "==", "np", ".", "int32", ":", "\n", "        ", "print", "(", "_input", ")", "\n", "return", "(", "_input", "*", "2147483648", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "raise", "ValueError", "(", "'Unsupported wave file format'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.__init__": [[7, 12], ["time.perf_counter", "collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "summarize_every", "=", "5", ",", "disabled", "=", "False", ")", ":", "\n", "        ", "self", ".", "last_tick", "=", "timer", "(", ")", "\n", "self", ".", "logs", "=", "OrderedDict", "(", ")", "\n", "self", ".", "summarize_every", "=", "summarize_every", "\n", "self", ".", "disabled", "=", "disabled", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.tick": [[13, 26], ["profiler.Profiler.logs[].append", "profiler.Profiler.reset_timer", "len", "profiler.Profiler.summarize", "profiler.Profiler.purge_logs", "time.perf_counter"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.reset_timer", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.summarize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.purge_logs"], ["", "def", "tick", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "self", ".", "disabled", ":", "\n", "            ", "return", "\n", "\n", "# Log the time needed to execute that function", "\n", "", "if", "not", "name", "in", "self", ".", "logs", ":", "\n", "            ", "self", ".", "logs", "[", "name", "]", "=", "[", "]", "\n", "", "if", "len", "(", "self", ".", "logs", "[", "name", "]", ")", ">=", "self", ".", "summarize_every", ":", "\n", "            ", "self", ".", "summarize", "(", ")", "\n", "self", ".", "purge_logs", "(", ")", "\n", "", "self", ".", "logs", "[", "name", "]", ".", "append", "(", "timer", "(", ")", "-", "self", ".", "last_tick", ")", "\n", "\n", "self", ".", "reset_timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.purge_logs": [[27, 30], ["profiler.Profiler.logs[].clear"], "methods", ["None"], ["", "def", "purge_logs", "(", "self", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "logs", ":", "\n", "            ", "self", ".", "logs", "[", "name", "]", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.reset_timer": [[31, 33], ["time.perf_counter"], "methods", ["None"], ["", "", "def", "reset_timer", "(", "self", ")", ":", "\n", "        ", "self", ".", "last_tick", "=", "timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.profiler.Profiler.summarize": [[34, 45], ["max", "print", "max", "zip", "print", "map", "map", "profiler.Profiler.logs.values", "print", "profiler.Profiler.logs.values", "profiler.Profiler.logs.items", "len", "name_msg.ljust", "numpy.mean", "numpy.std"], "methods", ["None"], ["", "def", "summarize", "(", "self", ")", ":", "\n", "        ", "n", "=", "max", "(", "map", "(", "len", ",", "self", ".", "logs", ".", "values", "(", ")", ")", ")", "\n", "assert", "n", "==", "self", ".", "summarize_every", "\n", "print", "(", "\"\\nAverage execution time over %d steps:\"", "%", "n", ")", "\n", "\n", "name_msgs", "=", "[", "\"%s (%d/%d):\"", "%", "(", "name", ",", "len", "(", "deltas", ")", ",", "n", ")", "for", "name", ",", "deltas", "in", "self", ".", "logs", ".", "items", "(", ")", "]", "\n", "pad", "=", "max", "(", "map", "(", "len", ",", "name_msgs", ")", ")", "\n", "for", "name_msg", ",", "deltas", "in", "zip", "(", "name_msgs", ",", "self", ".", "logs", ".", "values", "(", ")", ")", ":", "\n", "            ", "print", "(", "\"  %s  mean: %4.0fms   std: %4.0fms\"", "%", "\n", "(", "name_msg", ".", "ljust", "(", "pad", ")", ",", "np", ".", "mean", "(", "deltas", ")", "*", "1000", ",", "np", ".", "std", "(", "deltas", ")", "*", "1000", ")", ")", "\n", "", "print", "(", "\"\"", ",", "flush", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.argutils._priority": [[13, 21], ["next", "next", "len", "enumerate", "enumerate", "isinstance", "type"], "function", ["None"], ["def", "_priority", "(", "o", ")", ":", "\n", "    ", "p", "=", "next", "(", "(", "i", "for", "i", ",", "t", "in", "enumerate", "(", "_type_priorities", ")", "if", "type", "(", "o", ")", "is", "t", ")", ",", "None", ")", "\n", "if", "p", "is", "not", "None", ":", "\n", "        ", "return", "p", "\n", "", "p", "=", "next", "(", "(", "i", "for", "i", ",", "t", "in", "enumerate", "(", "_type_priorities", ")", "if", "isinstance", "(", "o", ",", "t", ")", ")", ",", "None", ")", "\n", "if", "p", "is", "not", "None", ":", "\n", "        ", "return", "p", "\n", "", "return", "len", "(", "_type_priorities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.argutils.print_args": [[22, 40], ["vars", "numpy.lexsort", "list", "print", "print", "list", "list", "max", "vars.items", "print", "map", "map", "map", "list", "vars.values", "all_params.index", "len", "vars.keys", "vars.keys", "vars.keys", "len"], "function", ["None"], ["", "def", "print_args", "(", "args", ":", "argparse", ".", "Namespace", ",", "parser", "=", "None", ")", ":", "\n", "    ", "args", "=", "vars", "(", "args", ")", "\n", "if", "parser", "is", "None", ":", "\n", "        ", "priorities", "=", "list", "(", "map", "(", "_priority", ",", "args", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "all_params", "=", "[", "a", ".", "dest", "for", "g", "in", "parser", ".", "_action_groups", "for", "a", "in", "g", ".", "_group_actions", "]", "\n", "priority", "=", "lambda", "p", ":", "all_params", ".", "index", "(", "p", ")", "if", "p", "in", "all_params", "else", "len", "(", "all_params", ")", "\n", "priorities", "=", "list", "(", "map", "(", "priority", ",", "args", ".", "keys", "(", ")", ")", ")", "\n", "\n", "", "pad", "=", "max", "(", "map", "(", "len", ",", "args", ".", "keys", "(", ")", ")", ")", "+", "3", "\n", "indices", "=", "np", ".", "lexsort", "(", "(", "list", "(", "args", ".", "keys", "(", ")", ")", ",", "priorities", ")", ")", "\n", "items", "=", "list", "(", "args", ".", "items", "(", ")", ")", "\n", "\n", "print", "(", "\"Arguments:\"", ")", "\n", "for", "i", "in", "indices", ":", "\n", "        ", "param", ",", "value", "=", "items", "[", "i", "]", "\n", "print", "(", "\"    {0}:{1}{2}\"", ".", "format", "(", "param", ",", "' '", "*", "(", "pad", "-", "len", "(", "param", ")", ")", ",", "value", ")", ")", "\n", "", "print", "(", "\"\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.__init__": [[2, 5], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "window_size", "=", "100", ")", ":", "\n", "    ", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.append": [[6, 8], ["None"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "x", ")", ":", "\n", "    ", "self", ".", "_values", "=", "self", ".", "_values", "[", "-", "(", "self", ".", "_window_size", "-", "1", ")", ":", "]", "+", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.sum": [[9, 12], ["__init__.ValueWindow.sum"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "@", "property", "\n", "def", "sum", "(", "self", ")", ":", "\n", "    ", "return", "sum", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.count": [[13, 16], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "count", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.average": [[17, 20], ["max"], "methods", ["None"], ["", "@", "property", "\n", "def", "average", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "sum", "/", "max", "(", "1", ",", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.__init__.ValueWindow.reset": [[21, 23], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "_values", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.expand_abbreviations": [[43, 47], ["re.sub"], "function", ["None"], ["def", "expand_abbreviations", "(", "text", ")", ":", "\n", "  ", "for", "regex", ",", "replacement", "in", "_abbreviations", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "regex", ",", "replacement", ",", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.expand_numbers": [[49, 51], ["numbers.normalize_numbers"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.numbers.normalize_numbers"], ["", "def", "expand_numbers", "(", "text", ")", ":", "\n", "  ", "return", "normalize_numbers", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.lowercase": [[53, 56], ["text.lower"], "function", ["None"], ["", "def", "lowercase", "(", "text", ")", ":", "\n", "  ", "\"\"\"lowercase input tokens.\"\"\"", "\n", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.collapse_whitespace": [[58, 60], ["re.sub"], "function", ["None"], ["", "def", "collapse_whitespace", "(", "text", ")", ":", "\n", "  ", "return", "re", ".", "sub", "(", "_whitespace_re", ",", "\" \"", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.convert_to_ascii": [[62, 64], ["unidecode.unidecode"], "function", ["None"], ["", "def", "convert_to_ascii", "(", "text", ")", ":", "\n", "  ", "return", "unidecode", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.basic_cleaners": [[66, 71], ["cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.lowercase", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.collapse_whitespace"], ["", "def", "basic_cleaners", "(", "text", ")", ":", "\n", "  ", "\"\"\"Basic pipeline that lowercases and collapses whitespace without transliteration.\"\"\"", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.transliteration_cleaners": [[73, 79], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.lowercase", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.collapse_whitespace"], ["", "def", "transliteration_cleaners", "(", "text", ")", ":", "\n", "  ", "\"\"\"Pipeline for non-English text that transliterates to ASCII.\"\"\"", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.english_cleaners": [[81, 89], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.expand_numbers", "cleaners.expand_abbreviations", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.lowercase", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.expand_numbers", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.expand_abbreviations", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.cleaners.collapse_whitespace"], ["", "def", "english_cleaners", "(", "text", ")", ":", "\n", "  ", "\"\"\"Pipeline for English text, including number and abbreviation expansion.\"\"\"", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "expand_numbers", "(", "text", ")", "\n", "text", "=", "expand_abbreviations", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence": [[13, 41], ["len", "sequence.append", "_curly_re.match", "text._symbols_to_sequence", "text._arpabet_to_sequence", "_curly_re.match.group", "text._symbols_to_sequence", "text._clean_text", "_curly_re.match.group", "text._clean_text", "_curly_re.match.group"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._symbols_to_sequence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._arpabet_to_sequence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._symbols_to_sequence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._clean_text", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._clean_text"], ["def", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ":", "\n", "  ", "\"\"\"Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\n\n    The text can optionally have ARPAbet sequences enclosed in curly braces embedded\n    in it. For example, \"Turn left on {HH AW1 S S T AH0 N} Street.\"\n\n    Args:\n      text: string to convert to a sequence\n      cleaner_names: names of the cleaner functions to run the text through\n\n    Returns:\n      List of integers corresponding to the symbols in the text\n  \"\"\"", "\n", "sequence", "=", "[", "]", "\n", "\n", "# Check for curly braces and treat their contents as ARPAbet:", "\n", "while", "len", "(", "text", ")", ":", "\n", "    ", "m", "=", "_curly_re", ".", "match", "(", "text", ")", "\n", "if", "not", "m", ":", "\n", "      ", "sequence", "+=", "_symbols_to_sequence", "(", "_clean_text", "(", "text", ",", "cleaner_names", ")", ")", "\n", "break", "\n", "", "sequence", "+=", "_symbols_to_sequence", "(", "_clean_text", "(", "m", ".", "group", "(", "1", ")", ",", "cleaner_names", ")", ")", "\n", "sequence", "+=", "_arpabet_to_sequence", "(", "m", ".", "group", "(", "2", ")", ")", "\n", "text", "=", "m", ".", "group", "(", "3", ")", "\n", "\n", "# Append EOS token", "\n", "", "sequence", ".", "append", "(", "_symbol_to_id", "[", "\"~\"", "]", ")", "\n", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.sequence_to_text": [[43, 54], ["result.replace", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "sequence_to_text", "(", "sequence", ")", ":", "\n", "  ", "\"\"\"Converts a sequence of IDs back to a string\"\"\"", "\n", "result", "=", "\"\"", "\n", "for", "symbol_id", "in", "sequence", ":", "\n", "    ", "if", "symbol_id", "in", "_id_to_symbol", ":", "\n", "      ", "s", "=", "_id_to_symbol", "[", "symbol_id", "]", "\n", "# Enclose ARPAbet back in curly braces:", "\n", "if", "len", "(", "s", ")", ">", "1", "and", "s", "[", "0", "]", "==", "\"@\"", ":", "\n", "        ", "s", "=", "\"{%s}\"", "%", "s", "[", "1", ":", "]", "\n", "", "result", "+=", "s", "\n", "", "", "return", "result", ".", "replace", "(", "\"}{\"", ",", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._clean_text": [[56, 63], ["getattr", "getattr.", "Exception"], "function", ["None"], ["", "def", "_clean_text", "(", "text", ",", "cleaner_names", ")", ":", "\n", "  ", "for", "name", "in", "cleaner_names", ":", "\n", "    ", "cleaner", "=", "getattr", "(", "cleaners", ",", "name", ")", "\n", "if", "not", "cleaner", ":", "\n", "      ", "raise", "Exception", "(", "\"Unknown cleaner: %s\"", "%", "name", ")", "\n", "", "text", "=", "cleaner", "(", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._symbols_to_sequence": [[65, 67], ["text._should_keep_symbol"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._should_keep_symbol"], ["", "def", "_symbols_to_sequence", "(", "symbols", ")", ":", "\n", "  ", "return", "[", "_symbol_to_id", "[", "s", "]", "for", "s", "in", "symbols", "if", "_should_keep_symbol", "(", "s", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._arpabet_to_sequence": [[69, 71], ["text._symbols_to_sequence", "text.split"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._symbols_to_sequence"], ["", "def", "_arpabet_to_sequence", "(", "text", ")", ":", "\n", "  ", "return", "_symbols_to_sequence", "(", "[", "\"@\"", "+", "s", "for", "s", "in", "text", ".", "split", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text._should_keep_symbol": [[73, 75], ["None"], "function", ["None"], ["", "def", "_should_keep_symbol", "(", "s", ")", ":", "\n", "  ", "return", "s", "in", "_symbol_to_id", "and", "s", "not", "in", "(", "\"_\"", ",", "\"~\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict.CMUDict.__init__": [[18, 27], ["isinstance", "_cmudict._parse_cmudict", "open", "_cmudict._parse_cmudict", "_parse_cmudict.items", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict._parse_cmudict", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict._parse_cmudict"], ["def", "__init__", "(", "self", ",", "file_or_path", ",", "keep_ambiguous", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "file_or_path", ",", "str", ")", ":", "\n", "      ", "with", "open", "(", "file_or_path", ",", "encoding", "=", "\"latin-1\"", ")", "as", "f", ":", "\n", "        ", "entries", "=", "_parse_cmudict", "(", "f", ")", "\n", "", "", "else", ":", "\n", "      ", "entries", "=", "_parse_cmudict", "(", "file_or_path", ")", "\n", "", "if", "not", "keep_ambiguous", ":", "\n", "      ", "entries", "=", "{", "word", ":", "pron", "for", "word", ",", "pron", "in", "entries", ".", "items", "(", ")", "if", "len", "(", "pron", ")", "==", "1", "}", "\n", "", "self", ".", "_entries", "=", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict.CMUDict.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_entries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict.CMUDict.lookup": [[33, 36], ["_cmudict.CMUDict._entries.get", "word.upper"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "word", ")", ":", "\n", "    ", "\"\"\"Returns list of ARPAbet pronunciations of the given word.\"\"\"", "\n", "return", "self", ".", "_entries", ".", "get", "(", "word", ".", "upper", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict._parse_cmudict": [[42, 55], ["len", "line.split", "re.sub", "_cmudict._get_pronunciation", "cmudict[].append"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict._get_pronunciation", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["def", "_parse_cmudict", "(", "file", ")", ":", "\n", "  ", "cmudict", "=", "{", "}", "\n", "for", "line", "in", "file", ":", "\n", "    ", "if", "len", "(", "line", ")", "and", "(", "line", "[", "0", "]", ">=", "\"A\"", "and", "line", "[", "0", "]", "<=", "\"Z\"", "or", "line", "[", "0", "]", "==", "\"'\"", ")", ":", "\n", "      ", "parts", "=", "line", ".", "split", "(", "\"  \"", ")", "\n", "word", "=", "re", ".", "sub", "(", "_alt_re", ",", "\"\"", ",", "parts", "[", "0", "]", ")", "\n", "pronunciation", "=", "_get_pronunciation", "(", "parts", "[", "1", "]", ")", "\n", "if", "pronunciation", ":", "\n", "        ", "if", "word", "in", "cmudict", ":", "\n", "          ", "cmudict", "[", "word", "]", ".", "append", "(", "pronunciation", ")", "\n", "", "else", ":", "\n", "          ", "cmudict", "[", "word", "]", "=", "[", "pronunciation", "]", "\n", "", "", "", "", "return", "cmudict", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils._cmudict._get_pronunciation": [[57, 63], ["s.strip().split", "s.strip"], "function", ["None"], ["", "def", "_get_pronunciation", "(", "s", ")", ":", "\n", "  ", "parts", "=", "s", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "for", "part", "in", "parts", ":", "\n", "    ", "if", "part", "not", "in", "_valid_symbol_set", ":", "\n", "      ", "return", "None", "\n", "", "", "return", "\" \"", ".", "join", "(", "parts", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.split_title_line": [[7, 14], ["title_text.split", "range", "len"], "function", ["None"], ["def", "split_title_line", "(", "title_text", ",", "max_words", "=", "5", ")", ":", "\n", "\t", "\"\"\"\n\tA function that splits any string based on specific character\n\t(returning it with the string), with maximum number of words on it\n\t\"\"\"", "\n", "seq", "=", "title_text", ".", "split", "(", ")", "\n", "return", "\"\\n\"", ".", "join", "(", "[", "\" \"", ".", "join", "(", "seq", "[", "i", ":", "i", "+", "max_words", "]", ")", "for", "i", "in", "range", "(", "0", ",", "len", "(", "seq", ")", ",", "max_words", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment": [[15, 39], ["matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.imshow", "plt.figure.colorbar", "matplotlib.xlabel", "matplotlib.title", "matplotlib.ylabel", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "plot.split_title_line"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.split_title_line"], ["", "def", "plot_alignment", "(", "alignment", ",", "path", ",", "title", "=", "None", ",", "split_title", "=", "False", ",", "max_len", "=", "None", ")", ":", "\n", "\t", "if", "max_len", "is", "not", "None", ":", "\n", "\t\t", "alignment", "=", "alignment", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "\n", "im", "=", "ax", ".", "imshow", "(", "\n", "alignment", ",", "\n", "aspect", "=", "\"auto\"", ",", "\n", "origin", "=", "\"lower\"", ",", "\n", "interpolation", "=", "\"none\"", ")", "\n", "fig", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "xlabel", "=", "\"Decoder timestep\"", "\n", "\n", "if", "split_title", ":", "\n", "\t\t", "title", "=", "split_title_line", "(", "title", ")", "\n", "\n", "", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "ylabel", "(", "\"Encoder timestep\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "path", ",", "format", "=", "\"png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram": [[41, 77], ["matplotlib.figure", "plt.figure.text", "plt.figure.colorbar", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "plot.split_title_line", "plt.figure.add_subplot", "plt.figure.add_subplot", "fig.add_subplot.set_title", "plt.figure.colorbar", "fig.add_subplot.set_title", "plt.figure.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.imshow", "fig.add_subplot.imshow", "fig.add_subplot.imshow", "numpy.rot90", "numpy.rot90", "numpy.rot90", "numpy.rot90"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.split_title_line"], ["", "def", "plot_spectrogram", "(", "pred_spectrogram", ",", "path", ",", "title", "=", "None", ",", "split_title", "=", "False", ",", "target_spectrogram", "=", "None", ",", "max_len", "=", "None", ",", "auto_aspect", "=", "False", ")", ":", "\n", "\t", "if", "max_len", "is", "not", "None", ":", "\n", "\t\t", "target_spectrogram", "=", "target_spectrogram", "[", ":", "max_len", "]", "\n", "pred_spectrogram", "=", "pred_spectrogram", "[", ":", "max_len", "]", "\n", "\n", "", "if", "split_title", ":", "\n", "\t\t", "title", "=", "split_title_line", "(", "title", ")", "\n", "\n", "", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "8", ")", ")", "\n", "# Set common labels", "\n", "fig", ".", "text", "(", "0.5", ",", "0.18", ",", "title", ",", "horizontalalignment", "=", "\"center\"", ",", "fontsize", "=", "16", ")", "\n", "\n", "#target spectrogram subplot", "\n", "if", "target_spectrogram", "is", "not", "None", ":", "\n", "\t\t", "ax1", "=", "fig", ".", "add_subplot", "(", "311", ")", "\n", "ax2", "=", "fig", ".", "add_subplot", "(", "312", ")", "\n", "\n", "if", "auto_aspect", ":", "\n", "\t\t\t", "im", "=", "ax1", ".", "imshow", "(", "np", ".", "rot90", "(", "target_spectrogram", ")", ",", "aspect", "=", "\"auto\"", ",", "interpolation", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "im", "=", "ax1", ".", "imshow", "(", "np", ".", "rot90", "(", "target_spectrogram", ")", ",", "interpolation", "=", "\"none\"", ")", "\n", "", "ax1", ".", "set_title", "(", "\"Target Mel-Spectrogram\"", ")", "\n", "fig", ".", "colorbar", "(", "mappable", "=", "im", ",", "shrink", "=", "0.65", ",", "orientation", "=", "\"horizontal\"", ",", "ax", "=", "ax1", ")", "\n", "ax2", ".", "set_title", "(", "\"Predicted Mel-Spectrogram\"", ")", "\n", "", "else", ":", "\n", "\t\t", "ax2", "=", "fig", ".", "add_subplot", "(", "211", ")", "\n", "\n", "", "if", "auto_aspect", ":", "\n", "\t\t", "im", "=", "ax2", ".", "imshow", "(", "np", ".", "rot90", "(", "pred_spectrogram", ")", ",", "aspect", "=", "\"auto\"", ",", "interpolation", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "\t\t", "im", "=", "ax2", ".", "imshow", "(", "np", ".", "rot90", "(", "pred_spectrogram", ")", ",", "interpolation", "=", "\"none\"", ")", "\n", "", "fig", ".", "colorbar", "(", "mappable", "=", "im", ",", "shrink", "=", "0.65", ",", "orientation", "=", "\"horizontal\"", ",", "ax", "=", "ax2", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "path", ",", "format", "=", "\"png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder.__init__": [[18, 123], ["super().__init__", "os.path.join", "os.path.join", "numpy.arange", "sklearn.model_selection.train_test_split", "feeder.Feeder._round_down", "numpy.concatenate", "list", "list", "x.strip", "os.path.dirname", "os.path.dirname", "open", "feedback_synthesizer.infolog.log", "len", "len", "len", "tensorflow.device", "tensorflow.FIFOQueue", "tensorflow.FIFOQueue.enqueue", "tensorflow.FIFOQueue.dequeue", "feeder.Feeder.inputs.set_shape", "feeder.Feeder.input_lengths.set_shape", "feeder.Feeder.mel_targets.set_shape", "feeder.Feeder.token_targets.set_shape", "feeder.Feeder.targets_lengths.set_shape", "feeder.Feeder.split_infos.set_shape", "feeder.Feeder.speaker_embeddings.set_shape", "feeder.Feeder.embedding_masks.set_shape", "tensorflow.FIFOQueue", "tensorflow.FIFOQueue.enqueue", "tensorflow.FIFOQueue.dequeue", "feeder.Feeder.eval_inputs.set_shape", "feeder.Feeder.eval_input_lengths.set_shape", "feeder.Feeder.eval_mel_targets.set_shape", "feeder.Feeder.eval_token_targets.set_shape", "feeder.Feeder.eval_targets_lengths.set_shape", "feeder.Feeder.eval_split_infos.set_shape", "feeder.Feeder.eval_speaker_embeddings.set_shape", "feeder.Feeder.eval_embedding_masks.set_shape", "hparams.cleaners.split", "line.strip().split", "numpy.array", "numpy.array", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "sum", "len", "line.strip", "int"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._round_down", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["def", "__init__", "(", "self", ",", "coordinator", ",", "metadata_filename", ",", "hparams", ")", ":", "\n", "\t\t", "super", "(", "Feeder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_coord", "=", "coordinator", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "_cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "self", ".", "_train_offset", "=", "0", "\n", "self", ".", "_test_offset", "=", "0", "\n", "self", ".", "decrease_func", "=", "lambda", "x", ":", "(", "x", "-", "1", ")", "//", "2", "+", "1", "# x : ceil((x+1)/2)", "\n", "\n", "# Load metadata", "\n", "self", ".", "_mel_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"mels\"", ")", "\n", "self", ".", "_embed_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"embeds\"", ")", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t", "self", ".", "_metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n", "frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "self", ".", "_metadata", "]", ")", "*", "frame_shift_ms", "/", "(", "3600", ")", "\n", "log", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "self", ".", "_metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Train test split", "\n", "", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "is", "not", "None", "\n", "\n", "", "test_size", "=", "(", "hparams", ".", "tacotron_test_size", "if", "hparams", ".", "tacotron_test_size", "is", "not", "None", "\n", "else", "hparams", ".", "tacotron_test_batches", "*", "hparams", ".", "tacotron_batch_size", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_metadata", ")", ")", "\n", "train_indices", ",", "test_indices", "=", "train_test_split", "(", "indices", ",", "\n", "test_size", "=", "test_size", ",", "random_state", "=", "hparams", ".", "tacotron_data_random_state", ")", "\n", "\n", "#Make sure test_indices is a multiple of batch_size else round up", "\n", "len_test_indices", "=", "self", ".", "_round_down", "(", "len", "(", "test_indices", ")", ",", "hparams", ".", "tacotron_batch_size", ")", "\n", "extra_test", "=", "test_indices", "[", "len_test_indices", ":", "]", "\n", "test_indices", "=", "test_indices", "[", ":", "len_test_indices", "]", "\n", "train_indices", "=", "np", ".", "concatenate", "(", "[", "train_indices", ",", "extra_test", "]", ")", "\n", "\n", "self", ".", "_train_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "train_indices", "]", ")", "\n", "self", ".", "_test_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "test_indices", "]", ")", "\n", "\n", "self", ".", "test_steps", "=", "len", "(", "self", ".", "_test_meta", ")", "//", "hparams", ".", "tacotron_batch_size", "\n", "\n", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "==", "self", ".", "test_steps", "\n", "\n", "#pad input sequences with the <pad_token> 0 ( _ )", "\n", "", "self", ".", "_pad", "=", "0", "\n", "#explicitely setting the padding to a value that doesn\"t originally exist in the spectogram", "\n", "#to avoid any possible conflicts, without affecting the output range of the model too much", "\n", "if", "hparams", ".", "symmetric_mels", ":", "\n", "\t\t\t", "self", ".", "_target_pad", "=", "-", "hparams", ".", "max_abs_value", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "_target_pad", "=", "0.", "\n", "#Mark finished sequences with 1s", "\n", "", "self", ".", "_token_pad", "=", "1.", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "# Create placeholders for inputs and targets. Don\"t specify batch size because we want", "\n", "# to be able to feed different batch sizes at eval time.", "\n", "\t\t\t", "self", ".", "_placeholders", "=", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "\"inputs\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "\"input_lengths\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "hparams", ".", "num_mels", ")", ",", "\n", "name", "=", "\"mel_targets\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "\"token_targets\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "\"targets_lengths\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "hparams", ".", "tacotron_num_gpus", ",", "None", ")", ",", "\n", "name", "=", "\"split_infos\"", ")", ",", "\n", "\n", "# SV2TTS", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "hparams", ".", "speaker_embedding_size", ")", ",", "\n", "name", "=", "\"speaker_embeddings\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "None", ",", "hparams", ".", "speaker_embedding_size", "//", "2", ")", ",", "\n", "name", "=", "\"embedding_mask\"", ")", "\n", "]", "\n", "\n", "# Create queue for buffering data", "\n", "queue", "=", "tf", ".", "FIFOQueue", "(", "8", ",", "[", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "\n", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ",", "name", "=", "\"input_queue\"", ")", "\n", "self", ".", "_enqueue_op", "=", "queue", ".", "enqueue", "(", "self", ".", "_placeholders", ")", "\n", "self", ".", "inputs", ",", "self", ".", "input_lengths", ",", "self", ".", "mel_targets", ",", "self", ".", "token_targets", ",", "self", ".", "targets_lengths", ",", "self", ".", "split_infos", ",", "self", ".", "speaker_embeddings", ",", "self", ".", "embedding_masks", "=", "queue", ".", "dequeue", "(", ")", "\n", "\n", "self", ".", "inputs", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "0", "]", ".", "shape", ")", "\n", "self", ".", "input_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "1", "]", ".", "shape", ")", "\n", "self", ".", "mel_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "2", "]", ".", "shape", ")", "\n", "self", ".", "token_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "3", "]", ".", "shape", ")", "\n", "self", ".", "targets_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "4", "]", ".", "shape", ")", "\n", "self", ".", "split_infos", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "5", "]", ".", "shape", ")", "\n", "self", ".", "speaker_embeddings", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "6", "]", ".", "shape", ")", "\n", "self", ".", "embedding_masks", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "7", "]", ".", "shape", ")", "\n", "\n", "# Create eval queue for buffering eval data", "\n", "eval_queue", "=", "tf", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "\n", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ",", "name", "=", "\"eval_queue\"", ")", "\n", "self", ".", "_eval_enqueue_op", "=", "eval_queue", ".", "enqueue", "(", "self", ".", "_placeholders", ")", "\n", "self", ".", "eval_inputs", ",", "self", ".", "eval_input_lengths", ",", "self", ".", "eval_mel_targets", ",", "self", ".", "eval_token_targets", ",", "self", ".", "eval_targets_lengths", ",", "self", ".", "eval_split_infos", ",", "self", ".", "eval_speaker_embeddings", ",", "self", ".", "eval_embedding_masks", "=", "eval_queue", ".", "dequeue", "(", ")", "\n", "\n", "self", ".", "eval_inputs", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "0", "]", ".", "shape", ")", "\n", "self", ".", "eval_input_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "1", "]", ".", "shape", ")", "\n", "self", ".", "eval_mel_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "2", "]", ".", "shape", ")", "\n", "self", ".", "eval_token_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "3", "]", ".", "shape", ")", "\n", "self", ".", "eval_targets_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "4", "]", ".", "shape", ")", "\n", "self", ".", "eval_split_infos", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "5", "]", ".", "shape", ")", "\n", "self", ".", "eval_speaker_embeddings", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "6", "]", ".", "shape", ")", "\n", "self", ".", "eval_embedding_masks", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "7", "]", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder.start_threads": [[125, 134], ["threading.Thread", "threading.Thread.start", "threading.Thread", "threading.Thread.start"], "methods", ["None"], ["", "", "def", "start_threads", "(", "self", ",", "session", ")", ":", "\n", "\t\t", "self", ".", "_session", "=", "session", "\n", "thread", "=", "threading", ".", "Thread", "(", "name", "=", "\"background\"", ",", "target", "=", "self", ".", "_enqueue_next_train_group", ")", "\n", "thread", ".", "daemon", "=", "True", "#Thread will close when parent quits", "\n", "thread", ".", "start", "(", ")", "\n", "\n", "thread", "=", "threading", ".", "Thread", "(", "name", "=", "\"background\"", ",", "target", "=", "self", ".", "_enqueue_next_test_group", ")", "\n", "thread", ".", "daemon", "=", "True", "#Thread will close when parent quits", "\n", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._get_test_groups": [[135, 153], ["numpy.asarray", "numpy.load", "numpy.asarray", "numpy.load", "len", "range", "numpy.ones", "feedback_synthesizer.utils.text.text_to_sequence", "os.path.join", "os.path.join", "feeder.Feeder.decrease_func", "len", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["", "def", "_get_test_groups", "(", "self", ")", ":", "\n", "\t\t", "meta", "=", "self", ".", "_test_meta", "[", "self", ".", "_test_offset", "]", "\n", "self", ".", "_test_offset", "+=", "1", "\n", "\n", "text", "=", "meta", "[", "5", "]", "\n", "\n", "input_data", "=", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "self", ".", "_cleaner_names", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "mel_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_mel_dir", ",", "meta", "[", "1", "]", ")", ")", "\n", "#Create parallel sequences containing zeros to represent a non finished sequence", "\n", "token_target", "=", "np", ".", "asarray", "(", "[", "0.", "]", "*", "(", "len", "(", "mel_target", ")", "-", "1", ")", ")", "\n", "embed_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_embed_dir", ",", "meta", "[", "2", "]", ")", ")", "\n", "# Tf version of return x if remainder == 0 else x + multiple - remainder", "\n", "dc_len", "=", "len", "(", "mel_target", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\t\t\t", "dc_len", "=", "self", ".", "decrease_func", "(", "dc_len", ")", "\n", "", "embed_mask", "=", "np", ".", "ones", "(", "(", "dc_len", ",", "(", "self", ".", "_hparams", ".", "num_mels", "+", "7", ")", "//", "8", ",", "self", ".", "_hparams", ".", "speaker_embedding_size", "//", "2", ")", ")", "\n", "\n", "return", "input_data", ",", "mel_target", ",", "token_target", ",", "embed_target", ",", "len", "(", "mel_target", ")", ",", "embed_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder.make_test_batches": [[154, 171], ["time.time", "examples.sort", "numpy.random.shuffle", "feedback_synthesizer.infolog.log", "feeder.Feeder._get_test_groups", "range", "range", "len", "len", "len", "time.time"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_test_groups"], ["", "def", "make_test_batches", "(", "self", ")", ":", "\n", "\t\t", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Read a group of examples", "\n", "n", "=", "self", ".", "_hparams", ".", "tacotron_batch_size", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n", "\n", "#Test on entire test set", "\n", "examples", "=", "[", "self", ".", "_get_test_groups", "(", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_test_meta", ")", ")", "]", "\n", "\n", "# Bucket examples based on similar output sequence length for efficiency", "\n", "examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "2", "]", ")", "\n", "batches", "=", "[", "examples", "[", "i", ":", "i", "+", "n", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "examples", ")", ",", "n", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "log", "(", "\"\\nGenerated %d test batches of size %d in %.3f sec\"", "%", "(", "len", "(", "batches", ")", ",", "n", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "return", "batches", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._enqueue_next_train_group": [[172, 190], ["feeder.Feeder._coord.should_stop", "time.time", "examples.sort", "numpy.random.shuffle", "feedback_synthesizer.infolog.log", "feeder.Feeder._get_next_example", "dict", "feeder.Feeder._session.run", "range", "range", "len", "zip", "len", "time.time", "feeder.Feeder._prepare_batch"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_next_example", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_batch"], ["", "def", "_enqueue_next_train_group", "(", "self", ")", ":", "\n", "\t\t", "while", "not", "self", ".", "_coord", ".", "should_stop", "(", ")", ":", "\n", "\t\t\t", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Read a group of examples", "\n", "n", "=", "self", ".", "_hparams", ".", "tacotron_batch_size", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n", "examples", "=", "[", "self", ".", "_get_next_example", "(", ")", "for", "i", "in", "range", "(", "n", "*", "_batches_per_group", ")", "]", "\n", "\n", "# Bucket examples based on similar output sequence length for efficiency", "\n", "examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "2", "]", ")", "\n", "batches", "=", "[", "examples", "[", "i", ":", "i", "+", "n", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "examples", ")", ",", "n", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "log", "(", "\"\\nGenerated {} train batches of size {} in {:.3f} sec\"", ".", "format", "(", "len", "(", "batches", ")", ",", "n", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "for", "batch", "in", "batches", ":", "\n", "\t\t\t\t", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "_placeholders", ",", "self", ".", "_prepare_batch", "(", "batch", ",", "r", ")", ")", ")", "\n", "self", ".", "_session", ".", "run", "(", "self", ".", "_enqueue_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._enqueue_next_test_group": [[191, 198], ["feeder.Feeder.make_test_batches", "feeder.Feeder._coord.should_stop", "dict", "feeder.Feeder._session.run", "zip", "feeder.Feeder._prepare_batch"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.make_test_batches", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_batch"], ["", "", "", "def", "_enqueue_next_test_group", "(", "self", ")", ":", "\n", "#Create test batches once and evaluate on them for all test steps", "\n", "\t\t", "test_batches", ",", "r", "=", "self", ".", "make_test_batches", "(", ")", "\n", "while", "not", "self", ".", "_coord", ".", "should_stop", "(", ")", ":", "\n", "\t\t\t", "for", "batch", "in", "test_batches", ":", "\n", "\t\t\t\t", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "_placeholders", ",", "self", ".", "_prepare_batch", "(", "batch", ",", "r", ")", ")", ")", "\n", "self", ".", "_session", ".", "run", "(", "self", ".", "_eval_enqueue_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._get_next_example": [[199, 223], ["numpy.asarray", "numpy.load", "numpy.asarray", "numpy.load", "len", "range", "numpy.ones", "len", "numpy.random.shuffle", "feedback_synthesizer.utils.text.text_to_sequence", "os.path.join", "os.path.join", "feeder.Feeder.decrease_func", "len", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["", "", "", "def", "_get_next_example", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"Gets a single example (input, mel_target, token_target, linear_target, mel_length) from_ disk\n\t\t\"\"\"", "\n", "if", "self", ".", "_train_offset", ">=", "len", "(", "self", ".", "_train_meta", ")", ":", "\n", "\t\t\t", "self", ".", "_train_offset", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "_train_meta", ")", "\n", "\n", "", "meta", "=", "self", ".", "_train_meta", "[", "self", ".", "_train_offset", "]", "\n", "self", ".", "_train_offset", "+=", "1", "\n", "\n", "text", "=", "meta", "[", "5", "]", "\n", "\n", "input_data", "=", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "self", ".", "_cleaner_names", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "mel_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_mel_dir", ",", "meta", "[", "1", "]", ")", ")", "\n", "#Create parallel sequences containing zeros to represent a non finished sequence", "\n", "token_target", "=", "np", ".", "asarray", "(", "[", "0.", "]", "*", "(", "len", "(", "mel_target", ")", "-", "1", ")", ")", "\n", "embed_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_embed_dir", ",", "meta", "[", "2", "]", ")", ")", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n", "dc_len", "=", "len", "(", "mel_target", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\t\t\t", "dc_len", "=", "self", ".", "decrease_func", "(", "dc_len", ")", "\n", "", "embed_mask", "=", "np", ".", "ones", "(", "(", "dc_len", ",", "(", "self", ".", "_hparams", ".", "num_mels", "+", "7", ")", "//", "8", ",", "self", ".", "_hparams", ".", "speaker_embedding_size", "//", "2", ")", ")", "\n", "\n", "return", "input_data", ",", "mel_target", ",", "token_target", ",", "embed_target", ",", "len", "(", "mel_target", ")", ",", "embed_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_batch": [[224, 266], ["int", "numpy.random.shuffle", "numpy.asarray", "numpy.asarray", "range", "numpy.asarray", "numpy.asarray", "feeder.Feeder._prepare_inputs", "feeder.Feeder._prepare_targets", "feeder.Feeder._prepare_token_targets", "feeder.Feeder._prepare_embed_mask", "numpy.asarray.append", "len", "len", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_token_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_embed_mask", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_prepare_batch", "(", "self", ",", "batches", ",", "outputs_per_step", ")", ":", "\n", "\t\t", "assert", "0", "==", "len", "(", "batches", ")", "%", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "size_per_device", "=", "int", "(", "len", "(", "batches", ")", "/", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "inputs", "=", "None", "\n", "mel_targets", "=", "None", "\n", "token_targets", "=", "None", "\n", "targets_lengths", "=", "None", "\n", "embed_masks", "=", "None", "\n", "\n", "split_infos", "=", "[", "]", "\n", "\n", "targets_lengths", "=", "np", ".", "asarray", "(", "[", "x", "[", "-", "2", "]", "for", "x", "in", "batches", "]", ",", "dtype", "=", "np", ".", "int32", ")", "#Used to mask loss", "\n", "input_lengths", "=", "np", ".", "asarray", "(", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "batches", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "\t\t\t", "batch", "=", "batches", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "input_cur_device", ",", "input_max_len", "=", "self", ".", "_prepare_inputs", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", ")", "\n", "inputs", "=", "np", ".", "concatenate", "(", "(", "inputs", ",", "input_cur_device", ")", ",", "axis", "=", "1", ")", "if", "inputs", "is", "not", "None", "else", "input_cur_device", "\n", "mel_target_cur_device", ",", "mel_target_max_len", "=", "self", ".", "_prepare_targets", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n", "mel_targets", "=", "np", ".", "concatenate", "(", "(", "mel_targets", ",", "mel_target_cur_device", ")", ",", "axis", "=", "1", ")", "if", "mel_targets", "is", "not", "None", "else", "mel_target_cur_device", "\n", "\n", "#Pad sequences with 1 to infer that the sequence is done", "\n", "token_target_cur_device", ",", "token_target_max_len", "=", "self", ".", "_prepare_token_targets", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n", "token_targets", "=", "np", ".", "concatenate", "(", "(", "token_targets", ",", "token_target_cur_device", ")", ",", "axis", "=", "1", ")", "if", "token_targets", "is", "not", "None", "else", "token_target_cur_device", "\n", "\n", "embed_mask_cur_device", ",", "embed_mask_max_len", "=", "self", ".", "_prepare_embed_mask", "(", "[", "x", "[", "5", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n", "embed_masks", "=", "np", ".", "concatenate", "(", "(", "embed_masks", ",", "embed_mask_cur_device", ")", ",", "axis", "=", "1", ")", "if", "embed_masks", "is", "not", "None", "else", "embed_mask_cur_device", "\n", "\n", "split_infos", ".", "append", "(", "[", "input_max_len", ",", "mel_target_max_len", ",", "token_target_max_len", ",", "embed_mask_max_len", "]", ")", "\n", "\n", "", "split_infos", "=", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "### SV2TTS ###", "\n", "\n", "embed_targets", "=", "np", ".", "asarray", "(", "[", "x", "[", "3", "]", "for", "x", "in", "batches", "]", ")", "\n", "\n", "##############", "\n", "\n", "return", "inputs", ",", "input_lengths", ",", "mel_targets", ",", "token_targets", ",", "targets_lengths", ",", "split_infos", ",", "embed_targets", ",", "embed_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_inputs": [[267, 270], ["max", "numpy.stack", "len", "feeder.Feeder._pad_input"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_input"], ["", "def", "_prepare_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "inputs", "]", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_input", "(", "x", ",", "max_len", ")", "for", "x", "in", "inputs", "]", ")", ",", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_targets": [[271, 275], ["max", "feeder.Feeder._round_up", "numpy.stack", "len", "feeder.Feeder._pad_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_target"], ["", "def", "_prepare_targets", "(", "self", ",", "targets", ",", "alignment", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "targets", "]", ")", "\n", "data_len", "=", "self", ".", "_round_up", "(", "max_len", ",", "alignment", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_target", "(", "t", ",", "data_len", ")", "for", "t", "in", "targets", "]", ")", ",", "data_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_token_targets": [[276, 280], ["feeder.Feeder._round_up", "max", "numpy.stack", "len", "feeder.Feeder._pad_token_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._pad_token_target"], ["", "def", "_prepare_token_targets", "(", "self", ",", "targets", ",", "alignment", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "targets", "]", ")", "+", "1", "\n", "data_len", "=", "self", ".", "_round_up", "(", "max_len", ",", "alignment", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_token_target", "(", "t", ",", "data_len", ")", "for", "t", "in", "targets", "]", ")", ",", "data_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._prepare_embed_mask": [[281, 285], ["max", "numpy.stack", "len", "feeder.Feeder._pad_mask_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._pad_mask_target"], ["", "def", "_prepare_embed_mask", "(", "self", ",", "masks", ",", "alignment", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "masks", "]", ")", "\n", "data_len", "=", "max_len", "#self._round_up(max_len, alignment)", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_mask_target", "(", "t", ",", "data_len", ")", "for", "t", "in", "masks", "]", ")", ",", "data_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._pad_input": [[286, 288], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_input", "(", "self", ",", "x", ",", "length", ")", ":", "\n", "\t\t", "return", "np", ".", "pad", "(", "x", ",", "(", "0", ",", "length", "-", "x", ".", "shape", "[", "0", "]", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._pad_target": [[289, 291], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_target", "(", "self", ",", "t", ",", "length", ")", ":", "\n", "\t\t", "return", "np", ".", "pad", "(", "t", ",", "[", "(", "0", ",", "length", "-", "t", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_target_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._pad_token_target": [[292, 294], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_token_target", "(", "self", ",", "t", ",", "length", ")", ":", "\n", "\t\t", "return", "np", ".", "pad", "(", "t", ",", "(", "0", ",", "length", "-", "t", ".", "shape", "[", "0", "]", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_token_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._pad_mask_target": [[295, 297], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_mask_target", "(", "self", ",", "m", ",", "length", ")", ":", "\n", "\t\t", "return", "np", ".", "pad", "(", "m", ",", "[", "(", "0", ",", "length", "-", "m", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._round_up": [[298, 301], ["None"], "methods", ["None"], ["", "def", "_round_up", "(", "self", ",", "x", ",", "multiple", ")", ":", "\n", "\t\t", "remainder", "=", "x", "%", "multiple", "\n", "return", "x", "if", "remainder", "==", "0", "else", "x", "+", "multiple", "-", "remainder", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.feeder.Feeder._round_down": [[302, 305], ["None"], "methods", ["None"], ["", "def", "_round_down", "(", "self", ",", "x", ",", "multiple", ")", ":", "\n", "\t\t", "remainder", "=", "x", "%", "multiple", "\n", "return", "x", "if", "remainder", "==", "0", "else", "x", "-", "remainder", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.infolog.init": [[13, 23], ["infolog._close_logfile", "open", "open", "open.write", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._close_logfile"], ["def", "init", "(", "filename", ",", "run_name", ",", "slack_url", "=", "None", ")", ":", "\n", "\t", "global", "_file", ",", "_run_name", ",", "_slack_url", "\n", "_close_logfile", "(", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", ".", "write", "(", "\"\\n-----------------------------------------------------------------\\n\"", ")", "\n", "_file", ".", "write", "(", "\"Starting new {} training run\\n\"", ".", "format", "(", "run_name", ")", ")", "\n", "_file", ".", "write", "(", "\"-----------------------------------------------------------------\\n\"", ")", "\n", "_run_name", "=", "run_name", "\n", "_slack_url", "=", "slack_url", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.infolog.log": [[25, 31], ["print", "_file.write", "threading.Thread().start", "threading.Thread", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "log", "(", "msg", ",", "end", "=", "\"\\n\"", ",", "slack", "=", "False", ")", ":", "\n", "\t", "print", "(", "msg", ",", "end", "=", "end", ")", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "write", "(", "\"[%s]  %s\\n\"", "%", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "_format", ")", "[", ":", "-", "3", "]", ",", "msg", ")", ")", "\n", "", "if", "slack", "and", "_slack_url", "is", "not", "None", ":", "\n", "\t\t", "Thread", "(", "target", "=", "_send_slack", ",", "args", "=", "(", "msg", ",", ")", ")", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.infolog._close_logfile": [[33, 38], ["_file.close"], "function", ["None"], ["", "", "def", "_close_logfile", "(", ")", ":", "\n", "\t", "global", "_file", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "close", "(", ")", "\n", "_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.infolog._send_slack": [[40, 47], ["urllib.request.Request", "urllib.request.Request.add_header", "urllib.request.urlopen", "json.dumps().encode", "json.dumps"], "function", ["None"], ["", "", "def", "_send_slack", "(", "msg", ")", ":", "\n", "\t", "req", "=", "Request", "(", "_slack_url", ")", "\n", "req", ".", "add_header", "(", "\"Content-Type\"", ",", "\"application/json\"", ")", "\n", "urlopen", "(", "req", ",", "json", ".", "dumps", "(", "{", "\n", "\"username\"", ":", "\"tacotron\"", ",", "\n", "\"icon_emoji\"", ":", "\":taco:\"", ",", "\n", "\"text\"", ":", "\"*%s*: %s\"", "%", "(", "_run_name", ",", "msg", ")", "\n", "}", ")", ".", "encode", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.synthesize.run_eval": [[10, 38], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "feedback_synthesizer.infolog.log", "feedback_synthesizer.tacotron2.Tacotron2", "feedback_synthesizer.infolog.log", "feedback_synthesizer.infolog.log", "os.path.join", "os.path.join", "feedback_synthesizer.hparams.hparams_debug_string", "open", "enumerate", "range", "os.path.join", "tqdm.tqdm", "time.time", "feedback_synthesizer.tacotron2.Tacotron2.synthesize", "zip", "len", "file.write", "range", "len", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.synthesize"], ["def", "run_eval", "(", "args", ",", "checkpoint_path", ",", "output_dir", ",", "hparams", ",", "sentences", ")", ":", "\n", "    ", "eval_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval\"", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"logs-eval\"", ")", "\n", "\n", "#Create output path if it doesn\"t exist", "\n", "os", ".", "makedirs", "(", "eval_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "log", "(", "hparams_debug_string", "(", ")", ")", "\n", "synth", "=", "Tacotron2", "(", "checkpoint_path", ",", "hparams", ")", "\n", "\n", "#Set inputs batch wise", "\n", "sentences", "=", "[", "sentences", "[", "i", ":", "i", "+", "hparams", ".", "tacotron_synthesis_batch_size", "]", "for", "i", "\n", "in", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "hparams", ".", "tacotron_synthesis_batch_size", ")", "]", "\n", "\n", "log", "(", "\"Starting Synthesis\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_dir", ",", "\"map.txt\"", ")", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "for", "i", ",", "texts", "in", "enumerate", "(", "tqdm", "(", "sentences", ")", ")", ":", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "basenames", "=", "[", "\"batch_{}_sentence_{}\"", ".", "format", "(", "i", ",", "j", ")", "for", "j", "in", "range", "(", "len", "(", "texts", ")", ")", "]", "\n", "mel_filenames", ",", "speaker_ids", "=", "synth", ".", "synthesize", "(", "texts", ",", "basenames", ",", "eval_dir", ",", "log_dir", ",", "None", ")", "\n", "\n", "for", "elems", "in", "zip", "(", "texts", ",", "mel_filenames", ",", "speaker_ids", ")", ":", "\n", "                ", "file", ".", "write", "(", "\"|\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "log", "(", "\"synthesized mel spectrograms at {}\"", ".", "format", "(", "eval_dir", ")", ")", "\n", "return", "eval_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.synthesize.run_synthesis": [[39, 82], ["os.path.join", "os.makedirs", "os.path.join", "print", "os.path.join", "feedback_synthesizer.tacotron2.Tacotron2", "print", "os.path.join", "os.path.join", "os.path.join", "print", "feedback_synthesizer.hparams.hparams_debug_string", "tensorflow.train.get_checkpoint_state", "open", "print", "open", "enumerate", "line.strip().split", "range", "tqdm.tqdm", "feedback_synthesizer.tacotron2.Tacotron2.synthesize", "sum", "len", "len", "os.path.join", "os.path.join", "os.path.basename().replace().replace", "file.write", "line.strip", "int", "os.path.basename().replace", "os.path.basename", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.synthesize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "run_synthesis", "(", "in_dir", ",", "out_dir", ",", "model_dir", ",", "hparams", ")", ":", "\n", "    ", "synth_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"mels_gta\"", ")", "\n", "os", ".", "makedirs", "(", "synth_dir", ",", "exist_ok", "=", "True", ")", "\n", "metadata_filename", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"train.txt\"", ")", "\n", "print", "(", "hparams_debug_string", "(", ")", ")", "\n", "\n", "# Load the model in memory", "\n", "weights_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"taco_pretrained\"", ")", "\n", "checkpoint_fpath", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "weights_dir", ")", ".", "model_checkpoint_path", "\n", "synth", "=", "Tacotron2", "(", "checkpoint_fpath", ",", "hparams", ",", "gta", "=", "True", ")", "\n", "\n", "# Load the metadata", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n", "frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "metadata", "]", ")", "*", "frame_shift_ms", "/", "3600", "\n", "print", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Set inputs batch wise", "\n", "", "metadata", "=", "[", "metadata", "[", "i", ":", "i", "+", "hparams", ".", "tacotron_synthesis_batch_size", "]", "for", "i", "in", "\n", "range", "(", "0", ",", "len", "(", "metadata", ")", ",", "hparams", ".", "tacotron_synthesis_batch_size", ")", "]", "\n", "# TODO: come on big boy, fix this", "\n", "# Quick and dirty fix to make sure that all batches have the same size ", "\n", "metadata", "=", "metadata", "[", ":", "-", "1", "]", "\n", "\n", "print", "(", "\"Starting Synthesis\"", ")", "\n", "mel_dir", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"mels\"", ")", "\n", "embed_dir", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"embeds\"", ")", "\n", "meta_out_fpath", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"synthesized.txt\"", ")", "\n", "with", "open", "(", "meta_out_fpath", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "for", "i", ",", "meta", "in", "enumerate", "(", "tqdm", "(", "metadata", ")", ")", ":", "\n", "            ", "texts", "=", "[", "m", "[", "5", "]", "for", "m", "in", "meta", "]", "\n", "mel_filenames", "=", "[", "os", ".", "path", ".", "join", "(", "mel_dir", ",", "m", "[", "1", "]", ")", "for", "m", "in", "meta", "]", "\n", "embed_filenames", "=", "[", "os", ".", "path", ".", "join", "(", "embed_dir", ",", "m", "[", "2", "]", ")", "for", "m", "in", "meta", "]", "\n", "basenames", "=", "[", "os", ".", "path", ".", "basename", "(", "m", ")", ".", "replace", "(", "\".npy\"", ",", "\"\"", ")", ".", "replace", "(", "\"mel-\"", ",", "\"\"", ")", "\n", "for", "m", "in", "mel_filenames", "]", "\n", "synth", ".", "synthesize", "(", "texts", ",", "basenames", ",", "synth_dir", ",", "None", ",", "mel_filenames", ",", "embed_filenames", ")", "\n", "\n", "for", "elems", "in", "meta", ":", "\n", "                ", "file", ".", "write", "(", "\"|\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "print", "(", "\"Synthesized mel spectrograms at {}\"", ".", "format", "(", "synth_dir", ")", ")", "\n", "return", "meta_out_fpath", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.__init__": [[19, 44], ["tensorflow.train.get_checkpoint_state", "Exception", "checkpoints_dir.parent.name.replace", "int", "print", "inference.Synthesizer.checkpoint_fpath.rfind"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Loading model weights at %s\"", "%", "weights_fpath", ")", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "weights_fpath", ")", "\n", "_model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state'", "]", ")", "\n", "_model", ".", "eval", "(", ")", "\n", "\n", "\n", "", "def", "is_loaded", "(", ")", ":", "\n", "    ", "return", "_model", "is", "not", "None", "\n", "\n", "\n", "", "def", "infer_waveform", "(", "mel", ",", "normalize", "=", "True", ",", "batched", "=", "True", ",", "target", "=", "8000", ",", "overlap", "=", "800", ",", "\n", "progress_callback", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.is_loaded": [[45, 50], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.load": [[51, 62], ["tensorflow.reset_default_graph", "feedback_synthesizer.tacotron2.Tacotron2", "Exception", "tensorflow.variable_scope"], "methods", ["None"], ["if", "_model", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"Please load Wave-RNN in memory before using it\"", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "mel", "=", "mel", "/", "hp", ".", "mel_max_abs_value", "\n", "", "mel", "=", "torch", ".", "from_numpy", "(", "mel", "[", "None", ",", "...", "]", ")", "\n", "wav", "=", "_model", ".", "generate", "(", "mel", ",", "batched", ",", "target", ",", "overlap", ",", "hp", ".", "mu_law", ",", "progress_callback", ")", "\n", "return", "wav", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.synthesize_spectrograms": [[63, 90], ["inference.Synthesizer._model.my_synthesize", "inference.Synthesizer.is_loaded", "inference.Synthesizer.load", "multiprocess.pool.Pool().starmap", "multiprocess.pool.Pool"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.my_synthesize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.is_loaded", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer._one_shot_synthesize_spectrograms": [[91, 107], ["tensorflow.reset_default_graph", "feedback_synthesizer.tacotron2.Tacotron2", "feedback_synthesizer.tacotron2.Tacotron2.my_synthesize", "feedback_synthesizer.tacotron2.Tacotron2.session.close", "numba.cuda.select_device", "numba.cuda.close", "alignments.copy", "spec.copy"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.my_synthesize"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.load_preprocess_wav": [[108, 118], ["librosa.load", "numpy.abs().max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.make_spectrogram": [[119, 132], ["feedback_synthesizer.audio.melspectrogram().astype", "isinstance", "isinstance", "inference.Synthesizer.load_preprocess_wav", "feedback_synthesizer.audio.melspectrogram"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load_preprocess_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.inference.Synthesizer.griffin_lim": [[133, 140], ["feedback_synthesizer.audio.inv_mel_spectrogram"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.load_wav": [[9, 11], ["librosa.core.load", "librosa.core.load"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["    ", "return", "2", "*", "x", "/", "(", "2", "**", "bits", "-", "1.", ")", "-", "1.", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.save_wav": [[12, 16], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "function", ["None"], ["", "def", "float_2_label", "(", "x", ",", "bits", ")", ":", "\n", "    ", "assert", "abs", "(", "x", ")", ".", "max", "(", ")", "<=", "1.0", "\n", "x", "=", "(", "x", "+", "1.", ")", "*", "(", "2", "**", "bits", "-", "1", ")", "/", "2", "\n", "return", "x", ".", "clip", "(", "0", ",", "2", "**", "bits", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.save_wavenet_wav": [[17, 19], ["librosa.output.write_wav", "librosa.output.write_wav"], "function", ["None"], ["\n", "", "def", "load_wav", "(", "path", ")", ":", "\n", "    ", "return", "librosa", ".", "load", "(", "path", ",", "sr", "=", "hp", ".", "sample_rate", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.preemphasis": [[20, 24], ["scipy.signal.lfilter"], "function", ["None"], ["\n", "\n", "", "def", "save_wav", "(", "x", ",", "path", ")", ":", "\n", "    ", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "x", ".", "astype", "(", "np", ".", "float32", ")", ",", "sr", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.inv_preemphasis": [[25, 29], ["scipy.signal.lfilter"], "function", ["None"], ["\n", "", "def", "split_signal", "(", "x", ")", ":", "\n", "    ", "unsigned", "=", "x", "+", "2", "**", "15", "\n", "coarse", "=", "unsigned", "//", "256", "\n", "fine", "=", "unsigned", "%", "256", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.start_and_end_indices": [[31, 43], ["range", "range", "abs", "abs", "abs", "abs"], "function", ["None"], ["\n", "\n", "", "def", "combine_signal", "(", "coarse", ",", "fine", ")", ":", "\n", "    ", "return", "coarse", "*", "256", "+", "fine", "-", "2", "**", "15", "\n", "\n", "\n", "", "def", "encode_16bits", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "x", "*", "2", "**", "15", ",", "-", "2", "**", "15", ",", "2", "**", "15", "-", "1", ")", ".", "astype", "(", "np", ".", "int16", ")", "\n", "\n", "\n", "", "mel_basis", "=", "None", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.get_hop_size": [[44, 50], ["int"], "function", ["None"], ["def", "linear_to_mel", "(", "spectrogram", ")", ":", "\n", "    ", "global", "mel_basis", "\n", "if", "mel_basis", "is", "None", ":", "\n", "        ", "mel_basis", "=", "build_mel_basis", "(", ")", "\n", "", "return", "np", ".", "dot", "(", "mel_basis", ",", "spectrogram", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.linearspectrogram": [[51, 58], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize"], ["", "def", "build_mel_basis", "(", ")", ":", "\n", "    ", "return", "librosa", ".", "filters", ".", "mel", "(", "hp", ".", "sample_rate", ",", "hp", ".", "n_fft", ",", "n_mels", "=", "hp", ".", "num_mels", ",", "fmin", "=", "hp", ".", "fmin", ")", "\n", "\n", "\n", "", "def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "-", "hp", ".", "min_level_db", ")", "/", "-", "hp", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.melspectrogram": [[59, 66], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "audio._linear_to_mel", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._linear_to_mel"], ["", "def", "denormalize", "(", "S", ")", ":", "\n", "    ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "hp", ".", "min_level_db", ")", "+", "hp", ".", "min_level_db", "\n", "\n", "\n", "", "def", "amp_to_db", "(", "x", ")", ":", "\n", "    ", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "x", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.inv_linear_spectrogram": [[67, 83], ["audio._db_to_amp", "audio._denormalize", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_db_to_amp.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["", "def", "db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n", "\n", "", "def", "spectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "np", ".", "abs", "(", "D", ")", ")", "-", "hp", ".", "ref_level_db", "\n", "return", "normalize", "(", "S", ")", "\n", "\n", "\n", "", "def", "melspectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "\n", "return", "normalize", "(", "S", ")", "\n", "\n", "\n", "", "def", "stft", "(", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.inv_mel_spectrogram": [[84, 100], ["audio._mel_to_linear", "audio._denormalize", "audio._db_to_amp", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_mel_to_linear.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._mel_to_linear", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["    ", "return", "librosa", ".", "stft", "(", "y", "=", "y", ",", "n_fft", "=", "hp", ".", "n_fft", ",", "hop_length", "=", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ")", "\n", "\n", "\n", "", "def", "pre_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "[", "1", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "de_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "encode_mu_law", "(", "x", ",", "mu", ")", ":", "\n", "    ", "mu", "=", "mu", "-", "1", "\n", "fx", "=", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "x", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "return", "np", ".", "floor", "(", "(", "fx", "+", "1", ")", "/", "2", "*", "mu", "+", "0.5", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._lws_processor": [[101, 104], ["lws.lws", "audio.get_hop_size", "numpy.np.float32", "numpy.np.float32"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], ["", "def", "decode_mu_law", "(", "y", ",", "mu", ",", "from_labels", "=", "True", ")", ":", "\n", "    ", "if", "from_labels", ":", "\n", "        ", "y", "=", "label_2_float", "(", "y", ",", "math", ".", "log2", "(", "mu", ")", ")", "\n", "", "mu", "=", "mu", "-", "1", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._griffin_lim": [[105, 116], ["numpy.exp", "numpy.abs().astype", "audio._istft", "range", "numpy.exp", "audio._istft", "numpy.random.rand", "numpy.abs", "numpy.angle", "audio._stft"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft"], ["x", "=", "np", ".", "sign", "(", "y", ")", "/", "mu", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "y", ")", "-", "1", ")", "\n", "return", "x", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._stft": [[117, 122], ["librosa.stft", "librosa.stft", "_lws_processor().stft", "audio.get_hop_size", "audio._lws_processor"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._istft": [[123, 125], ["librosa.istft", "librosa.istft", "audio.get_hop_size"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.num_frames": [[128, 137], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.pad_lr": [[139, 147], ["audio.num_frames", "len", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.num_frames"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio.librosa_pad_lr": [[149, 151], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._linear_to_mel": [[156, 161], ["numpy.dot", "audio._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._mel_to_linear": [[162, 167], ["numpy.maximum", "numpy.linalg.pinv", "numpy.dot", "audio._build_mel_basis", "numpy.np.float64"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._build_mel_basis": [[168, 172], ["librosa.filters.mel", "librosa.filters.mel"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._amp_to_db": [[173, 176], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._db_to_amp": [[177, 179], ["numpy.power", "numpy.np.float64"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._normalize": [[180, 193], ["numpy.clip", "numpy.clip", "S.max", "S.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.audio._denormalize": [[194, 207], ["numpy.clip", "numpy.clip"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.add_embedding_stats": [[21, 35], ["tensorflow.contrib.tensorboard.plugins.projector.ProjectorConfig", "zip", "tensorflow.contrib.tensorboard.plugins.projector.visualize_embeddings", "tf.contrib.tensorboard.plugins.projector.ProjectorConfig.embeddings.add"], "function", ["None"], ["print", "(", "\"Initializing the model...\"", ")", "\n", "model", "=", "WaveRNN", "(", "\n", "rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.add_train_stats": [[38, 64], ["tensorflow.variable_scope", "range", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "range", "tensorflow.summary.scalar", "tensorflow.norm", "tensorflow.reduce_max", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "function", ["None"], ["optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "for", "p", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "p", "[", "\"lr\"", "]", "=", "hp", ".", "voc_lr", "\n", "", "loss_func", "=", "F", ".", "cross_entropy", "if", "model", ".", "mode", "==", "\"RAW\"", "else", "discretized_mix_logistic_loss", "\n", "\n", "# Load the weights", "\n", "model_dir", "=", "models_dir", ".", "joinpath", "(", "run_id", ")", "\n", "model_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "weights_fpath", "=", "model_dir", ".", "joinpath", "(", "run_id", "+", "\".pt\"", ")", "\n", "if", "force_restart", "or", "not", "weights_fpath", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "\"\\nStarting the training of WaveRNN from scratch\\n\"", ")", "\n", "model", ".", "save", "(", "weights_fpath", ",", "optimizer", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"\\nLoading weights at %s\"", "%", "weights_fpath", ")", "\n", "model", ".", "load", "(", "weights_fpath", ",", "optimizer", ")", "\n", "print", "(", "\"WaveRNN weights loaded from step %d\"", "%", "model", ".", "step", ")", "\n", "\n", "# Initialize the dataset", "\n", "", "metadata_fpath", "=", "syn_dir", ".", "joinpath", "(", "\"train.txt\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"synthesized.txt\"", ")", "\n", "mel_dir", "=", "syn_dir", ".", "joinpath", "(", "\"mels\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"mels_gta\"", ")", "\n", "wav_dir", "=", "syn_dir", ".", "joinpath", "(", "\"audio\"", ")", "\n", "dataset", "=", "VocoderDataset", "(", "metadata_fpath", ",", "mel_dir", ",", "wav_dir", ")", "\n", "test_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.add_eval_stats": [[65, 81], ["tensorflow.Summary", "summary_writer.add_summary", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "values.append", "tensorflow.Summary.Value"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["\n", "# Begin the training", "\n", "simple_table", "(", "[", "(", "'Batch size'", ",", "hp", ".", "voc_batch_size", ")", ",", "\n", "(", "'LR'", ",", "hp", ".", "voc_lr", ")", ",", "\n", "(", "'Sequence Len'", ",", "hp", ".", "voc_seq_len", ")", "]", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "350", ")", ":", "\n", "        ", "data_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "collate_fn", "=", "collate_vocoder", ",", "\n", "batch_size", "=", "hp", ".", "voc_batch_size", ",", "\n", "num_workers", "=", "2", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "running_loss", "=", "0.", "\n", "\n", "for", "i", ",", "(", "x", ",", "y", ",", "m", ")", "in", "enumerate", "(", "data_loader", ",", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.time_string": [[83, 85], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["\n", "# Forward pass", "\n", "y_hat", "=", "model", "(", "x", ",", "m", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.model_train_mode": [[87, 99], ["tensorflow.variable_scope", "feedback_synthesizer.models.create_model", "feedback_synthesizer.models.create_model.initialize", "feedback_synthesizer.models.create_model.add_loss", "feedback_synthesizer.models.create_model.add_optimizer", "train.add_train_stats", "feedback_synthesizer.models.embedding.Resnet.resnet_hparams"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_loss", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_optimizer", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_train_stats"], ["                ", "y_hat", "=", "y_hat", ".", "transpose", "(", "1", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "elif", "model", ".", "mode", "==", "'MOL'", ":", "\n", "                ", "y", "=", "y", ".", "float", "(", ")", "\n", "", "y", "=", "y", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Backward pass", "\n", "loss", "=", "loss_func", "(", "y_hat", ",", "y", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "speed", "=", "i", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.model_test_mode": [[100, 112], ["tensorflow.variable_scope", "feedback_synthesizer.models.create_model", "feedback_synthesizer.models.create_model.initialize", "feedback_synthesizer.models.create_model.add_loss", "feedback_synthesizer.models.embedding.Resnet.resnet_hparams"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_loss"], ["avg_loss", "=", "running_loss", "/", "i", "\n", "\n", "step", "=", "model", ".", "get_step", "(", ")", "\n", "k", "=", "step", "//", "1000", "\n", "\n", "if", "backup_every", "!=", "0", "and", "step", "%", "backup_every", "==", "0", ":", "\n", "                ", "model", ".", "checkpoint", "(", "model_dir", ",", "optimizer", ")", "\n", "\n", "", "if", "save_every", "!=", "0", "and", "step", "%", "save_every", "==", "0", ":", "\n", "                ", "model", ".", "save", "(", "weights_fpath", ",", "optimizer", ")", "\n", "\n", "", "msg", "=", "f\"| Epoch: {epoch} ({i}/{len(data_loader)}) | \"", "f\"Loss: {avg_loss:.4f} | {speed:.1f} \""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.train": [[114, 410], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.path.join", "os.path.join", "log", "log", "log", "log", "tensorflow.set_random_seed", "tensorflow.train.Coordinator", "tensorflow.get_default_graph", "log", "tensorflow.ConfigProto", "feedback_synthesizer.hparams.hparams_debug_string", "tf.get_default_graph.as_default", "tensorflow.Variable", "train.model_train_mode", "train.model_test_mode", "os.path.join", "char_embedding_meta.replace.replace", "feedback_synthesizer.utils.ValueWindow", "feedback_synthesizer.utils.ValueWindow", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.Session", "tensorflow.variable_scope", "feedback_synthesizer.feeder.Feeder", "tensorflow.variable_scope", "os.path.isfile", "tensorflow.summary.FileWriter", "sess.run", "feedback_synthesizer.feeder.Feeder.start_threads", "log", "open", "tensorflow.get_collection", "tensorflow.global_variables_initializer", "tf.train.Saver.restore", "tf.train.Saver.restore", "log", "tf.train.Saver.save", "time.time", "sess.run", "feedback_synthesizer.utils.ValueWindow.append", "feedback_synthesizer.utils.ValueWindow.append", "print", "log", "traceback.print_exc", "tf.train.Coordinator.request_stop", "f.write", "tensorflow.train.get_checkpoint_state", "tf.train.Coordinator.should_stop", "numpy.isnan", "print", "Exception", "log", "tf.summary.FileWriter.add_summary", "log", "log", "feedback_synthesizer.audio.inv_mel_spectrogram", "feedback_synthesizer.audio.save_wav", "feedback_synthesizer.utils.plot.plot_alignment", "feedback_synthesizer.utils.plot.plot_spectrogram", "log", "log", "train.add_eval_stats", "tf.train.Saver.save", "log", "sess.run", "numpy.save", "feedback_synthesizer.audio.inv_mel_spectrogram", "feedback_synthesizer.audio.save_wav", "feedback_synthesizer.utils.plot.plot_alignment", "feedback_synthesizer.utils.plot.plot_spectrogram", "log", "tensorflow.train.get_checkpoint_state", "log", "train.add_embedding_stats", "log", "tensorflow.get_collection", "log", "tf.train.Saver.restore", "log", "tf.train.Saver.save", "log", "time.time", "sess.run", "tqdm.tqdm", "feedback_synthesizer.audio.inv_linear_spectrogram", "feedback_synthesizer.audio.save_wav", "tqdm.tqdm", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "os.path.join", "os.path.join", "os.path.join", "feedback_synthesizer.utils.plot.plot_spectrogram", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "range", "sess.run", "eval_losses.append", "before_losses.append", "after_losses.append", "stop_token_losses.append", "linear_losses.append", "sum", "len", "os.path.join", "range", "sess.run", "eval_losses.append", "before_losses.append", "after_losses.append", "stop_token_losses.append", "os.path.join", "feedback_synthesizer.utils.text.sequence_to_text", "train.time_string", "train.time_string", "train.time_string", "train.time_string", "train.time_string"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_train_mode", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_test_mode", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.start_threads", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_eval_stats", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_embedding_stats", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_linear_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.sequence_to_text", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string"], ["stream", "(", "msg", ")", "\n", "\n", "\n", "", "gen_testset", "(", "model", ",", "test_loader", ",", "hp", ".", "voc_gen_at_checkpoint", ",", "hp", ".", "voc_gen_batched", ",", "\n", "hp", ".", "voc_target", ",", "hp", ".", "voc_overlap", ",", "model_dir", ")", "\n", "print", "(", "\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.train.feedback_tacotron_train": [[412, 414], ["train.train"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.train"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.preprocess_librispeech": [[13, 52], ["datasets_root.joinpath", "print", "all", "out_dir.joinpath().mkdir", "out_dir.joinpath().mkdir", "out_dir.joinpath", "out_dir.joinpath.open", "list", "functools.partial", "multiprocessing.pool.Pool().imap", "tqdm.tqdm", "metadata_fpath.open.close", "sum", "sum", "print", "print", "print", "print", "datasets_root.joinpath.joinpath", "datasets_root.joinpath.joinpath", "itertools.chain.from_iterable", "len", "out_dir.joinpath.open", "map", "input_dir.exists", "out_dir.joinpath", "out_dir.joinpath", "multiprocessing.pool.Pool", "metadata_fpath.open.write", "line.split", "int", "int", "max", "max", "max", "input_dir.glob", "len", "len", "int", "int", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["def", "preprocess_librispeech", "(", "datasets_root", ":", "Path", ",", "out_dir", ":", "Path", ",", "n_processes", ":", "int", ",", "\n", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "# Gather the input directories", "\n", "    ", "dataset_root", "=", "datasets_root", ".", "joinpath", "(", "\"LibriSpeech\"", ")", "\n", "input_dirs", "=", "[", "dataset_root", ".", "joinpath", "(", "\"train-clean-100\"", ")", ",", "\n", "dataset_root", ".", "joinpath", "(", "\"train-clean-360\"", ")", "]", "\n", "print", "(", "\"\\n    \"", ".", "join", "(", "map", "(", "str", ",", "[", "\"Using data from:\"", "]", "+", "input_dirs", ")", ")", ")", "\n", "assert", "all", "(", "input_dir", ".", "exists", "(", ")", "for", "input_dir", "in", "input_dirs", ")", "\n", "\n", "# Create the output directories for each output file type", "\n", "out_dir", ".", "joinpath", "(", "\"mels\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "out_dir", ".", "joinpath", "(", "\"audio\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "# Create a metadata file", "\n", "metadata_fpath", "=", "out_dir", ".", "joinpath", "(", "\"train.txt\"", ")", "\n", "metadata_file", "=", "metadata_fpath", ".", "open", "(", "\"a\"", "if", "skip_existing", "else", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "# Preprocess the dataset", "\n", "speaker_dirs", "=", "list", "(", "chain", ".", "from_iterable", "(", "input_dir", ".", "glob", "(", "\"*\"", ")", "for", "input_dir", "in", "input_dirs", ")", ")", "\n", "func", "=", "partial", "(", "preprocess_speaker", ",", "out_dir", "=", "out_dir", ",", "skip_existing", "=", "skip_existing", ",", "\n", "hparams", "=", "hparams", ")", "\n", "job", "=", "Pool", "(", "n_processes", ")", ".", "imap", "(", "func", ",", "speaker_dirs", ")", "\n", "for", "speaker_metadata", "in", "tqdm", "(", "job", ",", "\"LibriSpeech\"", ",", "len", "(", "speaker_dirs", ")", ",", "unit", "=", "\"speakers\"", ")", ":", "\n", "        ", "for", "metadatum", "in", "speaker_metadata", ":", "\n", "            ", "metadata_file", ".", "write", "(", "\"|\"", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "metadatum", ")", "+", "\"\\n\"", ")", "\n", "", "", "metadata_file", ".", "close", "(", ")", "\n", "\n", "# Verify the contents of the metadata file", "\n", "with", "metadata_fpath", ".", "open", "(", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "metadata_file", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "metadata_file", "]", "\n", "", "mel_frames", "=", "sum", "(", "[", "int", "(", "m", "[", "4", "]", ")", "for", "m", "in", "metadata", "]", ")", "\n", "timesteps", "=", "sum", "(", "[", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "metadata", "]", ")", "\n", "sample_rate", "=", "hparams", ".", "sample_rate", "\n", "hours", "=", "(", "timesteps", "/", "sample_rate", ")", "/", "3600", "\n", "print", "(", "\"The dataset consists of %d utterances, %d mel frames, %d audio timesteps (%.2f hours).\"", "%", "\n", "(", "len", "(", "metadata", ")", ",", "mel_frames", ",", "timesteps", ",", "hours", ")", ")", "\n", "print", "(", "\"Max input length (text chars): %d\"", "%", "max", "(", "len", "(", "m", "[", "5", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "print", "(", "\"Max mel frames length: %d\"", "%", "max", "(", "int", "(", "m", "[", "4", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "print", "(", "\"Max audio timesteps length: %d\"", "%", "max", "(", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.preprocess_speaker": [[54, 81], ["speaker_dir.glob", "next", "book_dir.joinpath", "book_dir.joinpath.exists", "words.replace().split.replace().split", "list", "preprocess.split_on_silences", "enumerate", "book_dir.glob", "next.open", "map", "zip", "metadata.append", "line.rstrip().split", "words.replace().split.replace", "list.replace().split", "preprocess.process_utterance", "line.rstrip", "list.replace"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.split_on_silences", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.process_utterance", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "preprocess_speaker", "(", "speaker_dir", ",", "out_dir", ":", "Path", ",", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "    ", "metadata", "=", "[", "]", "\n", "for", "book_dir", "in", "speaker_dir", ".", "glob", "(", "\"*\"", ")", ":", "\n", "# Gather the utterance audios and texts", "\n", "        ", "try", ":", "\n", "            ", "alignments_fpath", "=", "next", "(", "book_dir", ".", "glob", "(", "\"*.alignment.txt\"", ")", ")", "\n", "with", "alignments_fpath", ".", "open", "(", "\"r\"", ")", "as", "alignments_file", ":", "\n", "                ", "alignments", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "line", "in", "alignments_file", "]", "\n", "", "", "except", "StopIteration", ":", "\n", "# A few alignment files will be missing", "\n", "            ", "continue", "\n", "\n", "# Iterate over each entry in the alignments file", "\n", "", "for", "wav_fname", ",", "words", ",", "end_times", "in", "alignments", ":", "\n", "            ", "wav_fpath", "=", "book_dir", ".", "joinpath", "(", "wav_fname", "+", "\".flac\"", ")", "\n", "assert", "wav_fpath", ".", "exists", "(", ")", "\n", "words", "=", "words", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "end_times", "=", "list", "(", "map", "(", "float", ",", "end_times", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", ")", ")", "\n", "\n", "# Process each sub-utterance", "\n", "wavs", ",", "texts", "=", "split_on_silences", "(", "wav_fpath", ",", "words", ",", "end_times", ",", "hparams", ")", "\n", "for", "i", ",", "(", "wav", ",", "text", ")", "in", "enumerate", "(", "zip", "(", "wavs", ",", "texts", ")", ")", ":", "\n", "                ", "sub_basename", "=", "\"%s_%02d\"", "%", "(", "wav_fname", ",", "i", ")", "\n", "metadata", ".", "append", "(", "process_utterance", "(", "wav", ",", "text", ",", "out_dir", ",", "sub_basename", ",", "\n", "skip_existing", ",", "hparams", ")", ")", "\n", "\n", "", "", "", "return", "[", "m", "for", "m", "in", "metadata", "if", "m", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.split_on_silences": [[83, 153], ["librosa.load", "numpy.array", "numpy.array", "numpy.array", "numpy.concatenate", "list", "len", "len", "len", "numpy.where", "len", "utils.logmmse.profile_noise", "utils.logmmse.denoise", "zip", "len", "len", "numpy.abs().max", "numpy.array", "float", "float", "min", "numpy.array", "numpy.abs", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.profile_noise", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.denoise"], ["", "def", "split_on_silences", "(", "wav_fpath", ",", "words", ",", "end_times", ",", "hparams", ")", ":", "\n", "# Load the audio waveform", "\n", "    ", "wav", ",", "_", "=", "librosa", ".", "load", "(", "wav_fpath", ",", "hparams", ".", "sample_rate", ")", "\n", "if", "hparams", ".", "rescale", ":", "\n", "        ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "", "words", "=", "np", ".", "array", "(", "words", ")", "\n", "start_times", "=", "np", ".", "array", "(", "[", "0.0", "]", "+", "end_times", "[", ":", "-", "1", "]", ")", "\n", "end_times", "=", "np", ".", "array", "(", "end_times", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "end_times", ")", "==", "len", "(", "start_times", ")", "\n", "assert", "words", "[", "0", "]", "==", "\"\"", "and", "words", "[", "-", "1", "]", "==", "\"\"", "\n", "\n", "# Find pauses that are too long", "\n", "mask", "=", "(", "words", "==", "\"\"", ")", "&", "(", "end_times", "-", "start_times", ">=", "hparams", ".", "silence_min_duration_split", ")", "\n", "mask", "[", "0", "]", "=", "mask", "[", "-", "1", "]", "=", "True", "\n", "breaks", "=", "np", ".", "where", "(", "mask", ")", "[", "0", "]", "\n", "\n", "# Profile the noise from the silences and perform noise reduction on the waveform", "\n", "silence_times", "=", "[", "[", "start_times", "[", "i", "]", ",", "end_times", "[", "i", "]", "]", "for", "i", "in", "breaks", "]", "\n", "silence_times", "=", "(", "np", ".", "array", "(", "silence_times", ")", "*", "hparams", ".", "sample_rate", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "noisy_wav", "=", "np", ".", "concatenate", "(", "[", "wav", "[", "stime", "[", "0", "]", ":", "stime", "[", "1", "]", "]", "for", "stime", "in", "silence_times", "]", ")", "\n", "if", "len", "(", "noisy_wav", ")", ">", "hparams", ".", "sample_rate", "*", "0.02", ":", "\n", "        ", "profile", "=", "logmmse", ".", "profile_noise", "(", "noisy_wav", ",", "hparams", ".", "sample_rate", ")", "\n", "wav", "=", "logmmse", ".", "denoise", "(", "wav", ",", "profile", ",", "eta", "=", "0", ")", "\n", "\n", "# Re-attach segments that are too short", "\n", "", "segments", "=", "list", "(", "zip", "(", "breaks", "[", ":", "-", "1", "]", ",", "breaks", "[", "1", ":", "]", ")", ")", "\n", "segment_durations", "=", "[", "start_times", "[", "end", "]", "-", "end_times", "[", "start", "]", "for", "start", ",", "end", "in", "segments", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "segments", ")", "and", "len", "(", "segments", ")", ">", "1", ":", "\n", "        ", "if", "segment_durations", "[", "i", "]", "<", "hparams", ".", "utterance_min_duration", ":", "\n", "# See if the segment can be re-attached with the right or the left segment", "\n", "            ", "left_duration", "=", "float", "(", "\"inf\"", ")", "if", "i", "==", "0", "else", "segment_durations", "[", "i", "-", "1", "]", "\n", "right_duration", "=", "float", "(", "\"inf\"", ")", "if", "i", "==", "len", "(", "segments", ")", "-", "1", "else", "segment_durations", "[", "i", "+", "1", "]", "\n", "joined_duration", "=", "segment_durations", "[", "i", "]", "+", "min", "(", "left_duration", ",", "right_duration", ")", "\n", "\n", "# Do not re-attach if it causes the joined utterance to be too long", "\n", "if", "joined_duration", ">", "hparams", ".", "hop_size", "*", "hparams", ".", "max_mel_frames", "/", "hparams", ".", "sample_rate", ":", "\n", "                ", "i", "+=", "1", "\n", "continue", "\n", "\n", "# Re-attach the segment with the neighbour of shortest duration", "\n", "", "j", "=", "i", "-", "1", "if", "left_duration", "<=", "right_duration", "else", "i", "\n", "segments", "[", "j", "]", "=", "(", "segments", "[", "j", "]", "[", "0", "]", ",", "segments", "[", "j", "+", "1", "]", "[", "1", "]", ")", "\n", "segment_durations", "[", "j", "]", "=", "joined_duration", "\n", "del", "segments", "[", "j", "+", "1", "]", ",", "segment_durations", "[", "j", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "\n", "# Split the utterance", "\n", "", "", "segment_times", "=", "[", "[", "end_times", "[", "start", "]", ",", "start_times", "[", "end", "]", "]", "for", "start", ",", "end", "in", "segments", "]", "\n", "segment_times", "=", "(", "np", ".", "array", "(", "segment_times", ")", "*", "hparams", ".", "sample_rate", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "wavs", "=", "[", "wav", "[", "segment_time", "[", "0", "]", ":", "segment_time", "[", "1", "]", "]", "for", "segment_time", "in", "segment_times", "]", "\n", "texts", "=", "[", "\" \"", ".", "join", "(", "words", "[", "start", "+", "1", ":", "end", "]", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "for", "start", ",", "end", "in", "segments", "]", "\n", "\n", "# # DEBUG: play the audio segments (run with -n=1)", "\n", "# import sounddevice as sd", "\n", "# if len(wavs) > 1:", "\n", "#     print(\"This sentence was split in %d segments:\" % len(wavs))", "\n", "# else:", "\n", "#     print(\"There are no silences long enough for this sentence to be split:\")", "\n", "# for wav, text in zip(wavs, texts):", "\n", "#     # Pad the waveform with 1 second of silence because sounddevice tends to cut them early", "\n", "#     # when playing them. You shouldn't need to do that in your parsers.", "\n", "#     wav = np.concatenate((wav, [0] * 16000))", "\n", "#     print(\"\\t%s\" % text)", "\n", "#     sd.play(wav, 16000, blocking=True)", "\n", "# print(\"\")", "\n", "\n", "return", "wavs", ",", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.process_utterance": [[155, 194], ["out_dir.joinpath", "out_dir.joinpath", "synthesizer.audio.melspectrogram().astype", "numpy.save", "numpy.save", "out_dir.joinpath.exists", "out_dir.joinpath.exists", "len", "len", "synthesizer.audio.melspectrogram"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], ["", "def", "process_utterance", "(", "wav", ":", "np", ".", "ndarray", ",", "text", ":", "str", ",", "out_dir", ":", "Path", ",", "basename", ":", "str", ",", "\n", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "## FOR REFERENCE:", "\n", "# For you not to lose your head if you ever wish to change things here or implement your own", "\n", "# synthesizer.", "\n", "# - Both the audios and the mel spectrograms are saved as numpy arrays", "\n", "# - There is no processing done to the audios that will be saved to disk beyond volume  ", "\n", "#   normalization (in split_on_silences)", "\n", "# - However, pre-emphasis is applied to the audios before computing the mel spectrogram. This", "\n", "#   is why we re-apply it on the audio on the side of the vocoder.", "\n", "# - Librosa pads the waveform before computing the mel spectrogram. Here, the waveform is saved", "\n", "#   without extra padding. This means that you won't have an exact relation between the length", "\n", "#   of the wav and of the mel spectrogram. See the vocoder data loader.", "\n", "\n", "\n", "# Skip existing utterances if needed", "\n", "    ", "mel_fpath", "=", "out_dir", ".", "joinpath", "(", "\"mels\"", ",", "\"mel-%s.npy\"", "%", "basename", ")", "\n", "wav_fpath", "=", "out_dir", ".", "joinpath", "(", "\"audio\"", ",", "\"audio-%s.npy\"", "%", "basename", ")", "\n", "if", "skip_existing", "and", "mel_fpath", ".", "exists", "(", ")", "and", "wav_fpath", ".", "exists", "(", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "# Skip utterances that are too short", "\n", "", "if", "len", "(", "wav", ")", "<", "hparams", ".", "utterance_min_duration", "*", "hparams", ".", "sample_rate", ":", "\n", "        ", "return", "None", "\n", "\n", "# Compute the mel spectrogram", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ",", "hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mel_frames", "=", "mel_spectrogram", ".", "shape", "[", "1", "]", "\n", "\n", "# Skip utterances that are too long", "\n", "if", "mel_frames", ">", "hparams", ".", "max_mel_frames", "and", "hparams", ".", "clip_mels_length", ":", "\n", "        ", "return", "None", "\n", "\n", "# Write the spectrogram, embed and audio to disk", "\n", "", "np", ".", "save", "(", "mel_fpath", ",", "mel_spectrogram", ".", "T", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "wav_fpath", ",", "wav", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Return a tuple describing this training example", "\n", "return", "wav_fpath", ".", "name", ",", "mel_fpath", ".", "name", ",", "\"embed-%s.npy\"", "%", "basename", ",", "len", "(", "wav", ")", ",", "mel_frames", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.embed_utterance": [[196, 206], ["numpy.load", "encoder.inference.preprocess_wav", "encoder.inference.embed_utterance", "numpy.save", "encoder.inference.is_loaded", "encoder.inference.load_model"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.embed_utterance", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.is_loaded", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.inference.load_model"], ["", "def", "embed_utterance", "(", "fpaths", ",", "encoder_model_fpath", ")", ":", "\n", "    ", "if", "not", "encoder", ".", "is_loaded", "(", ")", ":", "\n", "        ", "encoder", ".", "load_model", "(", "encoder_model_fpath", ")", "\n", "\n", "# Compute the speaker embedding of the utterance", "\n", "", "wav_fpath", ",", "embed_fpath", "=", "fpaths", "\n", "wav", "=", "np", ".", "load", "(", "wav_fpath", ")", "\n", "wav", "=", "encoder", ".", "preprocess_wav", "(", "wav", ")", "\n", "embed", "=", "encoder", ".", "embed_utterance", "(", "wav", ")", "\n", "np", ".", "save", "(", "embed_fpath", ",", "embed", ",", "allow_pickle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.preprocess.create_embeddings": [[208, 225], ["synthesizer_root.joinpath", "synthesizer_root.joinpath", "synthesizer_root.joinpath", "synthesizer_root.joinpath.mkdir", "functools.partial", "multiprocessing.pool.Pool().imap", "list", "synthesizer_root.joinpath.exists", "synthesizer_root.joinpath.exists", "synthesizer_root.joinpath.open", "tqdm.tqdm", "line.split", "multiprocessing.pool.Pool", "len", "synthesizer_root.joinpath.joinpath", "synthesizer_root.joinpath.joinpath"], "function", ["None"], ["", "def", "create_embeddings", "(", "synthesizer_root", ":", "Path", ",", "encoder_model_fpath", ":", "Path", ",", "n_processes", ":", "int", ")", ":", "\n", "    ", "wav_dir", "=", "synthesizer_root", ".", "joinpath", "(", "\"audio\"", ")", "\n", "metadata_fpath", "=", "synthesizer_root", ".", "joinpath", "(", "\"train.txt\"", ")", "\n", "assert", "wav_dir", ".", "exists", "(", ")", "and", "metadata_fpath", ".", "exists", "(", ")", "\n", "embed_dir", "=", "synthesizer_root", ".", "joinpath", "(", "\"embeds\"", ")", "\n", "embed_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "# Gather the input wave filepath and the target output embed filepath", "\n", "with", "metadata_fpath", ".", "open", "(", "\"r\"", ")", "as", "metadata_file", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "metadata_file", "]", "\n", "fpaths", "=", "[", "(", "wav_dir", ".", "joinpath", "(", "m", "[", "0", "]", ")", ",", "embed_dir", ".", "joinpath", "(", "m", "[", "2", "]", ")", ")", "for", "m", "in", "metadata", "]", "\n", "\n", "# TODO: improve on the multiprocessing, it's terrible. Disk I/O is the bottleneck here.", "\n", "# Embed the utterances in separate threads", "\n", "", "func", "=", "partial", "(", "embed_utterance", ",", "encoder_model_fpath", "=", "encoder_model_fpath", ")", "\n", "job", "=", "Pool", "(", "n_processes", ")", ".", "imap", "(", "func", ",", "fpaths", ")", "\n", "list", "(", "tqdm", "(", "job", ",", "\"Embedding\"", ",", "len", "(", "fpaths", ")", ",", "unit", "=", "\"utterances\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2.__init__": [[12, 68], ["feedback_synthesizer.infolog.log", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "feedback_synthesizer.infolog.log", "tensorflow.ConfigProto", "tensorflow.Session", "tacotron2.Tacotron2.session.run", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "feedback_synthesizer.models.embedding.Resnet.ResNet", "tensorflow.variable_scope", "feedback_synthesizer.models.create_model", "tensorflow.global_variables_initializer", "tacotron2.Tacotron2.model.initialize", "tacotron2.Tacotron2.model.initialize"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize"], ["    ", "def", "__init__", "(", "self", ",", "checkpoint_path", ",", "hparams", ",", "resnet_scope", ",", "resnet_hp", ",", "gta", "=", "False", ",", "model_name", "=", "\"Tacotron\"", ")", ":", "\n", "        ", "log", "(", "\"Constructing model: %s\"", "%", "model_name", ")", "\n", "#Force the batch size to be known in order to use attention masking in batch synthesis", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", "None", ")", ",", "name", "=", "\"inputs\"", ")", "\n", "input_lengths", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ",", "name", "=", "\"input_lengths\"", ")", "\n", "speaker_embeddings", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "hparams", ".", "speaker_embedding_size", ")", ",", "\n", "name", "=", "\"speaker_embeddings\"", ")", "\n", "targets", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "None", ",", "hparams", ".", "num_mels", ")", ",", "name", "=", "\"mel_targets\"", ")", "\n", "split_infos", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "hparams", ".", "tacotron_num_gpus", ",", "None", ")", ",", "name", "=", "\"split_infos\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"Tacotron_model\"", ")", "as", "scope", ":", "\n", "            ", "self", ".", "model", "=", "create_model", "(", "model_name", ",", "hparams", ",", "resnet_scope", ",", "resnet_hp", ")", "\n", "if", "gta", ":", "\n", "                ", "self", ".", "model", ".", "initialize", "(", "inputs", ",", "input_lengths", ",", "speaker_embeddings", ",", "targets", ",", "gta", "=", "gta", ",", "\n", "split_infos", "=", "split_infos", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "model", ".", "initialize", "(", "inputs", ",", "input_lengths", ",", "speaker_embeddings", ",", "\n", "split_infos", "=", "split_infos", ")", "\n", "\n", "", "self", ".", "mel_outputs", "=", "self", ".", "model", ".", "tower_mel_outputs", "\n", "self", ".", "linear_outputs", "=", "self", ".", "model", ".", "tower_linear_outputs", "if", "(", "hparams", ".", "predict_linear", "and", "not", "gta", ")", "else", "None", "\n", "self", ".", "alignments", "=", "self", ".", "model", ".", "tower_alignments", "\n", "self", ".", "stop_token_prediction", "=", "self", ".", "model", ".", "tower_stop_token_prediction", "\n", "self", ".", "targets", "=", "targets", "\n", "\n", "", "self", ".", "gta", "=", "gta", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "#pad input sequences with the <pad_token> 0 ( _ )", "\n", "self", ".", "_pad", "=", "0", "\n", "#explicitely setting the padding to a value that doesn\"t originally exist in the spectogram", "\n", "#to avoid any possible conflicts, without affecting the output range of the model too much", "\n", "if", "hparams", ".", "symmetric_mels", ":", "\n", "            ", "self", ".", "_target_pad", "=", "-", "hparams", ".", "max_abs_value", "\n", "", "else", ":", "\n", "            ", "self", ".", "_target_pad", "=", "0.", "\n", "\n", "", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "input_lengths", "=", "input_lengths", "\n", "self", ".", "speaker_embeddings", "=", "speaker_embeddings", "\n", "self", ".", "targets", "=", "targets", "\n", "self", ".", "split_infos", "=", "split_infos", "\n", "\n", "log", "(", "\"Loading checkpoint: %s\"", "%", "checkpoint_path", ")", "\n", "#Memory allocation on the GPUs as needed", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "config", ".", "allow_soft_placement", "=", "True", "\n", "\n", "self", ".", "session", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "session", ",", "checkpoint_path", ")", "\n", "\n", "## resnet for speaker embeding extraction", "\n", "self", ".", "resnet_scope", "=", "resnet_scope", "\n", "self", ".", "resnet", "=", "ResNet", "(", "resnet_hp", ",", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2.my_synthesize": [[69, 103], ["tacotron2.Tacotron2._prepare_inputs", "tacotron2.Tacotron2.session.run", "range", "x.strip", "numpy.asarray", "len", "numpy.asarray", "numpy.asarray", "list", "len", "tacotron2.Tacotron2._hparams.cleaners.split", "feedback_synthesizer.utils.text.text_to_sequence", "list().index", "list", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["", "def", "my_synthesize", "(", "self", ",", "speaker_embeds", ",", "texts", ")", ":", "\n", "        ", "\"\"\"\n        Lighter synthesis function that directly returns the mel spectrograms.\n        \"\"\"", "\n", "\n", "# Prepare the input", "\n", "cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "_hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "seqs", "=", "[", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ")", "for", "text", "in", "texts", "]", "\n", "input_lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "seqs", "]", "\n", "input_seqs", ",", "max_seq_len", "=", "self", ".", "_prepare_inputs", "(", "seqs", ")", "\n", "split_infos", "=", "[", "[", "max_seq_len", ",", "0", ",", "0", ",", "0", "]", "]", "\n", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "input_seqs", ",", "\n", "self", ".", "input_lengths", ":", "np", ".", "asarray", "(", "input_lengths", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "self", ".", "split_infos", ":", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "self", ".", "speaker_embeddings", ":", "speaker_embeds", "\n", "}", "\n", "\n", "# Forward it", "\n", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "mels", ",", "alignments", ",", "stop_tokens", "=", "list", "(", "mels", "[", "0", "]", ")", ",", "alignments", "[", "0", "]", ",", "stop_tokens", "[", "0", "]", "\n", "\n", "# Trim the output", "\n", "for", "i", "in", "range", "(", "len", "(", "mels", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "target_length", "=", "list", "(", "np", ".", "round", "(", "stop_tokens", "[", "i", "]", ")", ")", ".", "index", "(", "1", ")", "\n", "mels", "[", "i", "]", "=", "mels", "[", "i", "]", "[", ":", "target_length", ",", ":", "]", "\n", "", "except", "ValueError", ":", "\n", "# If no token is generated, we simply do not trim the output", "\n", "                ", "continue", "\n", "\n", "", "", "return", "[", "mel", ".", "T", "for", "mel", "in", "mels", "]", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2.synthesize": [[104, 219], ["range", "numpy.asarray", "enumerate", "x.strip", "numpy.asarray", "len", "len", "tacotron2.Tacotron2._prepare_inputs", "split_infos.append", "numpy.asarray", "range", "numpy.load", "tacotron2.Tacotron2.session.run", "tacotron2.Tacotron2.session.run", "NotImplemented", "os.path.join", "numpy.save", "saved_mels_paths.append", "hparams.cleaners.split", "len", "feedback_synthesizer.utils.text.text_to_sequence", "numpy.concatenate", "numpy.load", "len", "tacotron2.Tacotron2._prepare_targets", "len", "len", "tacotron2.Tacotron2._get_output_lengths", "len", "len", "len", "len", "len", "feedback_synthesizer.audio.inv_mel_spectrogram", "feedback_synthesizer.audio.save_wav", "feedback_synthesizer.utils.plot.plot_alignment", "feedback_synthesizer.utils.plot.plot_spectrogram", "numpy.concatenate", "zip", "zip", "zip", "os.path.join", "os.path.join", "os.path.join", "feedback_synthesizer.audio.inv_linear_spectrogram", "feedback_synthesizer.audio.save_wav", "feedback_synthesizer.utils.plot.plot_spectrogram", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._get_output_lengths", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_linear_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram"], ["", "def", "synthesize", "(", "self", ",", "texts", ",", "basenames", ",", "out_dir", ",", "log_dir", ",", "mel_filenames", ",", "embed_filenames", ")", ":", "\n", "        ", "hparams", "=", "self", ".", "_hparams", "\n", "cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "assert", "0", "==", "len", "(", "texts", ")", "%", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "seqs", "=", "[", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ")", "for", "text", "in", "texts", "]", "\n", "input_lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "seqs", "]", "\n", "\n", "size_per_device", "=", "len", "(", "seqs", ")", "//", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "\n", "#Pad inputs according to each GPU max length", "\n", "input_seqs", "=", "None", "\n", "split_infos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "            ", "device_input", "=", "seqs", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "device_input", ",", "max_seq_len", "=", "self", ".", "_prepare_inputs", "(", "device_input", ")", "\n", "input_seqs", "=", "np", ".", "concatenate", "(", "(", "input_seqs", ",", "device_input", ")", ",", "axis", "=", "1", ")", "if", "input_seqs", "is", "not", "None", "else", "device_input", "\n", "split_infos", ".", "append", "(", "[", "max_seq_len", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "input_seqs", ",", "\n", "self", ".", "input_lengths", ":", "np", ".", "asarray", "(", "input_lengths", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "}", "\n", "\n", "if", "self", ".", "gta", ":", "\n", "            ", "np_targets", "=", "[", "np", ".", "load", "(", "mel_filename", ")", "for", "mel_filename", "in", "mel_filenames", "]", "\n", "target_lengths", "=", "[", "len", "(", "np_target", ")", "for", "np_target", "in", "np_targets", "]", "\n", "\n", "#pad targets according to each GPU max length", "\n", "target_seqs", "=", "None", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "                ", "device_target", "=", "np_targets", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "device_target", ",", "max_target_len", "=", "self", ".", "_prepare_targets", "(", "device_target", ",", "self", ".", "_hparams", ".", "outputs_per_step", ")", "\n", "target_seqs", "=", "np", ".", "concatenate", "(", "(", "target_seqs", ",", "device_target", ")", ",", "axis", "=", "1", ")", "if", "target_seqs", "is", "not", "None", "else", "device_target", "\n", "split_infos", "[", "i", "]", "[", "1", "]", "=", "max_target_len", "#Not really used but setting it in case for future development maybe?", "\n", "\n", "", "feed_dict", "[", "self", ".", "targets", "]", "=", "target_seqs", "\n", "assert", "len", "(", "np_targets", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "feed_dict", "[", "self", ".", "split_infos", "]", "=", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "feed_dict", "[", "self", ".", "speaker_embeddings", "]", "=", "[", "np", ".", "load", "(", "f", ")", "for", "f", "in", "embed_filenames", "]", "\n", "\n", "if", "self", ".", "gta", "or", "not", "hparams", ".", "predict_linear", ":", "\n", "            ", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "#Linearize outputs (1D arrays)", "\n", "mels", "=", "[", "mel", "for", "gpu_mels", "in", "mels", "for", "mel", "in", "gpu_mels", "]", "\n", "alignments", "=", "[", "align", "for", "gpu_aligns", "in", "alignments", "for", "align", "in", "gpu_aligns", "]", "\n", "stop_tokens", "=", "[", "token", "for", "gpu_token", "in", "stop_tokens", "for", "token", "in", "gpu_token", "]", "\n", "\n", "if", "not", "self", ".", "gta", ":", "\n", "#Natural batch synthesis", "\n", "#Get Mel lengths for the entire batch from stop_tokens predictions", "\n", "                ", "target_lengths", "=", "self", ".", "_get_output_lengths", "(", "stop_tokens", ")", "\n", "\n", "#Take off the batch wise padding", "\n", "", "mels", "=", "[", "mel", "[", ":", "target_length", ",", ":", "]", "for", "mel", ",", "target_length", "in", "zip", "(", "mels", ",", "target_lengths", ")", "]", "\n", "assert", "len", "(", "mels", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "else", ":", "\n", "            ", "linears", ",", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "linear_outputs", ",", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "\n", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "#Linearize outputs (1D arrays)", "\n", "linears", "=", "[", "linear", "for", "gpu_linear", "in", "linears", "for", "linear", "in", "gpu_linear", "]", "\n", "mels", "=", "[", "mel", "for", "gpu_mels", "in", "mels", "for", "mel", "in", "gpu_mels", "]", "\n", "alignments", "=", "[", "align", "for", "gpu_aligns", "in", "alignments", "for", "align", "in", "gpu_aligns", "]", "\n", "stop_tokens", "=", "[", "token", "for", "gpu_token", "in", "stop_tokens", "for", "token", "in", "gpu_token", "]", "\n", "\n", "#Natural batch synthesis", "\n", "#Get Mel/Linear lengths for the entire batch from stop_tokens predictions", "\n", "# target_lengths = self._get_output_lengths(stop_tokens)", "\n", "target_lengths", "=", "[", "9999", "]", "\n", "\n", "#Take off the batch wise padding", "\n", "mels", "=", "[", "mel", "[", ":", "target_length", ",", ":", "]", "for", "mel", ",", "target_length", "in", "zip", "(", "mels", ",", "target_lengths", ")", "]", "\n", "linears", "=", "[", "linear", "[", ":", "target_length", ",", ":", "]", "for", "linear", ",", "target_length", "in", "zip", "(", "linears", ",", "target_lengths", ")", "]", "\n", "assert", "len", "(", "mels", ")", "==", "len", "(", "linears", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "if", "basenames", "is", "None", ":", "\n", "            ", "raise", "NotImplemented", "(", ")", "\n", "\n", "", "saved_mels_paths", "=", "[", "]", "\n", "for", "i", ",", "mel", "in", "enumerate", "(", "mels", ")", ":", "\n", "# Write the spectrogram to disk", "\n", "# Note: outputs mel-spectrogram files and target ones have same names, just different folders", "\n", "            ", "mel_filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"mel-{}.npy\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", "\n", "np", ".", "save", "(", "mel_filename", ",", "mel", ",", "allow_pickle", "=", "False", ")", "\n", "saved_mels_paths", ".", "append", "(", "mel_filename", ")", "\n", "\n", "if", "log_dir", "is", "not", "None", ":", "\n", "#save wav (mel -> wav)", "\n", "                ", "wav", "=", "audio", ".", "inv_mel_spectrogram", "(", "mel", ".", "T", ",", "hparams", ")", "\n", "audio", ".", "save_wav", "(", "wav", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs/wav-{}-mel.wav\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n", "#save alignments", "\n", "plot", ".", "plot_alignment", "(", "alignments", "[", "i", "]", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/alignment-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n", "title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ",", "max_len", "=", "target_lengths", "[", "i", "]", ")", "\n", "\n", "#save mel spectrogram plot", "\n", "plot", ".", "plot_spectrogram", "(", "mel", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/mel-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n", "title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ")", "\n", "\n", "if", "hparams", ".", "predict_linear", ":", "\n", "#save wav (linear -> wav)", "\n", "                    ", "wav", "=", "audio", ".", "inv_linear_spectrogram", "(", "linears", "[", "i", "]", ".", "T", ",", "hparams", ")", "\n", "audio", ".", "save_wav", "(", "wav", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs/wav-{}-linear.wav\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n", "#save linear spectrogram plot", "\n", "plot", ".", "plot_spectrogram", "(", "linears", "[", "i", "]", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/linear-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n", "title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ",", "auto_aspect", "=", "True", ")", "\n", "\n", "", "", "", "return", "saved_mels_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._round_up": [[220, 223], ["None"], "methods", ["None"], ["", "def", "_round_up", "(", "self", ",", "x", ",", "multiple", ")", ":", "\n", "        ", "remainder", "=", "x", "%", "multiple", "\n", "return", "x", "if", "remainder", "==", "0", "else", "x", "+", "multiple", "-", "remainder", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._prepare_inputs": [[224, 227], ["max", "numpy.stack", "len", "tacotron2.Tacotron2._pad_input"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_input"], ["", "def", "_prepare_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "inputs", "]", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_input", "(", "x", ",", "max_len", ")", "for", "x", "in", "inputs", "]", ")", ",", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._pad_input": [[228, 230], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_input", "(", "self", ",", "x", ",", "length", ")", ":", "\n", "        ", "return", "np", ".", "pad", "(", "x", ",", "(", "0", ",", "length", "-", "x", ".", "shape", "[", "0", "]", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._prepare_targets": [[231, 235], ["max", "tacotron2.Tacotron2._round_up", "numpy.stack", "len", "tacotron2.Tacotron2._pad_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_target"], ["", "def", "_prepare_targets", "(", "self", ",", "targets", ",", "alignment", ")", ":", "\n", "        ", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "targets", "]", ")", "\n", "data_len", "=", "self", ".", "_round_up", "(", "max_len", ",", "alignment", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_target", "(", "t", ",", "data_len", ")", "for", "t", "in", "targets", "]", ")", ",", "data_len", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._pad_target": [[236, 238], ["numpy.pad"], "methods", ["None"], ["", "def", "_pad_target", "(", "self", ",", "t", ",", "length", ")", ":", "\n", "        ", "return", "np", ".", "pad", "(", "t", ",", "[", "(", "0", ",", "length", "-", "t", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_target_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.tacotron2.Tacotron2._get_output_lengths": [[239, 243], ["row.index", "numpy.round().tolist", "numpy.round"], "methods", ["None"], ["", "def", "_get_output_lengths", "(", "self", ",", "stop_tokens", ")", ":", "\n", "#Determine each mel length by the stop token predictions. (len = first occurence of 1 in stop_tokens row wise)", "\n", "        ", "output_lengths", "=", "[", "row", ".", "index", "(", "1", ")", "for", "row", "in", "np", ".", "round", "(", "stop_tokens", ")", ".", "tolist", "(", ")", "]", "\n", "return", "output_lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.feedback_synthesizer.hparams.hparams_debug_string": [[355, 359], ["hparams.values", "sorted"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder.FeederHParams.replace": [[12, 14], ["super()._replace"], "methods", ["None"], ["\n", "class", "Feeder", ":", "\n", "\t"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder.Feeder.__init__": [[16, 18], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "coordinator", ",", "metadata_filename", ",", "hparams", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder.Feeder._parse_func": [[19, 31], ["numpy.load", "os.path.join", "len", "random.randint", "mel_file.decode", "len", "numpy.concatenate", "spkid.decode", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["\t\t", "super", "(", "Feeder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_coord", "=", "coordinator", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "_cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "self", ".", "_train_offset", "=", "0", "\n", "self", ".", "_test_offset", "=", "0", "\n", "self", ".", "decrease_func", "=", "lambda", "x", ":", "(", "x", "-", "1", ")", "//", "2", "+", "1", "# x : ceil((x+1)/2)", "\n", "\n", "# Load metadata", "\n", "self", ".", "_mel_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"mels\"", ")", "\n", "self", ".", "_embed_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"embeds\"", ")", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t", "self", ".", "_metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder.Feeder.__call__": [[32, 58], ["tensorflow.data.experimental.CsvDataset", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "open", "dataset.batch.batch.shuffle", "dataset.batch.batch.repeat", "line.strip", "enumerate", "tuple", "fid.readlines", "tensorflow.py_func", "len", "line.strip"], "methods", ["None"], ["frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "self", ".", "_metadata", "]", ")", "*", "frame_shift_ms", "/", "(", "3600", ")", "\n", "log", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "self", ".", "_metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Train test split", "\n", "", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "is", "not", "None", "\n", "\n", "", "test_size", "=", "(", "hparams", ".", "tacotron_test_size", "if", "hparams", ".", "tacotron_test_size", "is", "not", "None", "\n", "else", "hparams", ".", "tacotron_test_batches", "*", "hparams", ".", "tacotron_batch_size", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_metadata", ")", ")", "\n", "train_indices", ",", "test_indices", "=", "train_test_split", "(", "indices", ",", "\n", "test_size", "=", "test_size", ",", "random_state", "=", "hparams", ".", "tacotron_data_random_state", ")", "\n", "\n", "#Make sure test_indices is a multiple of batch_size else round up", "\n", "len_test_indices", "=", "self", ".", "_round_down", "(", "len", "(", "test_indices", ")", ",", "hparams", ".", "tacotron_batch_size", ")", "\n", "extra_test", "=", "test_indices", "[", "len_test_indices", ":", "]", "\n", "test_indices", "=", "test_indices", "[", ":", "len_test_indices", "]", "\n", "train_indices", "=", "np", ".", "concatenate", "(", "[", "train_indices", ",", "extra_test", "]", ")", "\n", "\n", "self", ".", "_train_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "train_indices", "]", ")", "\n", "self", ".", "_test_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "test_indices", "]", ")", "\n", "\n", "self", ".", "test_steps", "=", "len", "(", "self", ".", "_test_meta", ")", "//", "hparams", ".", "tacotron_batch_size", "\n", "\n", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "==", "self", ".", "test_steps", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.infolog.init": [[13, 23], ["infolog._close_logfile", "open", "open", "open.write", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._close_logfile"], ["def", "init", "(", "filename", ",", "run_name", ",", "slack_url", "=", "None", ")", ":", "\n", "\t", "global", "_file", ",", "_run_name", ",", "_slack_url", "\n", "_close_logfile", "(", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", ".", "write", "(", "\"\\n-----------------------------------------------------------------\\n\"", ")", "\n", "_file", ".", "write", "(", "\"Starting new {} training run\\n\"", ".", "format", "(", "run_name", ")", ")", "\n", "_file", ".", "write", "(", "\"-----------------------------------------------------------------\\n\"", ")", "\n", "_run_name", "=", "run_name", "\n", "_slack_url", "=", "slack_url", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.infolog.log": [[25, 31], ["print", "_file.write", "threading.Thread().start", "threading.Thread", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "log", "(", "msg", ",", "end", "=", "\"\\n\"", ",", "slack", "=", "False", ")", ":", "\n", "\t", "print", "(", "msg", ",", "end", "=", "end", ")", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "write", "(", "\"[%s]  %s\\n\"", "%", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "_format", ")", "[", ":", "-", "3", "]", ",", "msg", ")", ")", "\n", "", "if", "slack", "and", "_slack_url", "is", "not", "None", ":", "\n", "\t\t", "Thread", "(", "target", "=", "_send_slack", ",", "args", "=", "(", "msg", ",", ")", ")", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.infolog._close_logfile": [[33, 38], ["_file.close"], "function", ["None"], ["", "", "def", "_close_logfile", "(", ")", ":", "\n", "\t", "global", "_file", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "close", "(", ")", "\n", "_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.infolog._send_slack": [[40, 47], ["urllib.request.Request", "urllib.request.Request.add_header", "urllib.request.urlopen", "json.dumps().encode", "json.dumps"], "function", ["None"], ["", "", "def", "_send_slack", "(", "msg", ")", ":", "\n", "\t", "req", "=", "Request", "(", "_slack_url", ")", "\n", "req", ".", "add_header", "(", "\"Content-Type\"", ",", "\"application/json\"", ")", "\n", "urlopen", "(", "req", ",", "json", ".", "dumps", "(", "{", "\n", "\"username\"", ":", "\"tacotron\"", ",", "\n", "\"icon_emoji\"", ":", "\":taco:\"", ",", "\n", "\"text\"", ":", "\"*%s*: %s\"", "%", "(", "_run_name", ",", "msg", ")", "\n", "}", ")", ".", "encode", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder_wav.FeederHParams.replace": [[16, 18], ["super()._replace"], "methods", ["None"], ["    ", "def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "FeederHParams", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder_wav.Feeder.__init__": [[20, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "self", ".", "hp", "=", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder_wav.Feeder._process_wave": [[23, 47], ["datasets.audio.preemphasis", "datasets.audio.load_wav", "datasets.audio.trim_silence", "len", "numpy.concatenate", "len", "random.randint", "datasets.audio.melspectrogram().astype", "print", "numpy.math.ceil", "len", "numpy.abs().max", "datasets.audio.melspectrogram", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], ["", "def", "_process_wave", "(", "self", ",", "wav_file", ",", "num_frames", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "wav", "=", "audio", ".", "load_wav", "(", "wav_file", ",", "sr", "=", "audio_hparams", ".", "sample_rate", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "print", "(", "'file {} present in csv metadata is not present in wav folder. skipping!'", ".", "format", "(", "wav_file", ")", ")", "\n", "\n", "", "if", "audio_hparams", ".", "trim_silence", ":", "\n", "            ", "wav", "=", "audio", ".", "trim_silence", "(", "wav", ",", "audio_hparams", ")", "\n", "\n", "", "expect_len", "=", "num_frames", "*", "audio_hparams", ".", "hop_size", "+", "audio_hparams", ".", "win_size", "\n", "if", "len", "(", "wav", ")", "<", "expect_len", ":", "\n", "            ", "wav", "=", "np", ".", "concatenate", "(", "[", "wav", "]", "*", "np", ".", "math", ".", "ceil", "(", "expect_len", "/", "len", "(", "wav", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "wav", ")", ">", "expect_len", ":", "\n", "            ", "sp", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "wav", ")", "-", "expect_len", ")", "\n", "wav", "=", "wav", "[", "sp", ":", "sp", "+", "expect_len", "]", "\n", "\n", "", "wav", "=", "audio", ".", "preemphasis", "(", "wav", ",", "audio_hparams", ".", "preemphasis", ",", "audio_hparams", ".", "preemphasize", ")", "\n", "\n", "if", "audio_hparams", ".", "rescale", ":", "\n", "            ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "audio_hparams", ".", "rescaling_max", "\n", "\n", "", "mels", "=", "audio", ".", "melspectrogram", "(", "wav", ",", "audio_hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "return", "mels", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder_wav.Feeder._parse_func": [[48, 51], ["feeder_wav.Feeder._process_wave", "wav_file.decode", "spkid.decode"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder._process_wave"], ["", "def", "_parse_func", "(", "self", ",", "spkid", ",", "wav_file", ",", "num_frames", ")", ":", "\n", "        ", "fbanks", "=", "self", ".", "_process_wave", "(", "wav_file", ".", "decode", "(", ")", ",", "num_frames", ")", "\n", "return", "fbanks", ",", "self", ".", "spk_dict", "[", "spkid", ".", "decode", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.feeder_wav.Feeder.__call__": [[52, 78], ["tensorflow.data.experimental.CsvDataset", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "open", "dataset.batch.batch.shuffle", "dataset.batch.batch.repeat", "line.strip", "enumerate", "tuple", "fid.readlines", "tensorflow.py_func", "len", "line.strip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "hp", "=", "self", ".", "hp", "\n", "\n", "with", "open", "(", "hp", ".", "spkfile", ")", "as", "fid", ":", "\n", "            ", "spklist", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fid", ".", "readlines", "(", ")", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "!=", "0", "]", "\n", "\n", "", "self", ".", "spk_dict", "=", "{", "spkid", ":", "idx", "for", "idx", ",", "spkid", "in", "enumerate", "(", "spklist", ")", "}", "\n", "\n", "dataset", "=", "tf", ".", "data", ".", "experimental", ".", "CsvDataset", "(", "hp", ".", "scp", ",", "\n", "record_defaults", "=", "hp", ".", "record_defaults", ",", "\n", "field_delim", "=", "hp", ".", "field_delim", ",", "\n", "select_cols", "=", "hp", ".", "select_cols", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "spkid", ",", "wav_file", ":", "\n", "tuple", "(", "tf", ".", "py_func", "(", "self", ".", "_parse_func", ",", "[", "spkid", ",", "wav_file", ",", "num_frames", "]", ",", "hp", ".", "dtypes", ")", ")", ",", "num_parallel_calls", "=", "-", "1", ")", "\n", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", "=", "hp", ".", "shuffle_size", ",", "reshuffle_each_iteration", "=", "True", ")", "if", "hp", ".", "shuffle", "==", "True", "else", "dataset", "\n", "\n", "dataset", "=", "dataset", ".", "repeat", "(", "hp", ".", "times", ")", "if", "hp", ".", "is_repeat", "==", "True", "else", "dataset", "\n", "\n", "# dataset = dataset.padded_batch(hp.batch_size, padded_shapes=hp.padded_shapes)", "\n", "dataset", "=", "dataset", ".", "batch", "(", "hp", ".", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "return", "iterator", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.train.time_string": [[20, 22], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["# Instantiate the model", "\n", "print", "(", "\"Initializing the model...\"", ")", "\n", "model", "=", "WaveRNN", "(", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.train.create_feeder": [[23, 34], ["feeder_wav.Feeder", "feeder_wav.Feeder.", "feeder_wav.Feeder", "feeder_wav.Feeder.", "tensorflow.data.Iterator.from_string_handle"], "function", ["None"], ["rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.train.create_model": [[35, 44], ["tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph", "tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph"], [")", ".", "cuda", "(", ")", "\n", "\n", "# Initialize the optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "for", "p", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "p", "[", "\"lr\"", "]", "=", "hp", ".", "voc_lr", "\n", "", "loss_func", "=", "F", ".", "cross_entropy", "if", "model", ".", "mode", "==", "\"RAW\"", "else", "discretized_mix_logistic_loss", "\n", "\n", "# Load the weights", "\n", "model_dir", "=", "models_dir", ".", "joinpath", "(", "run_id", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNetHParams.replace": [[39, 41], ["super()._replace"], "methods", ["None"], ["    ", "def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "ResNetHParams", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet.__init__": [[50, 64], ["tensorflow.expand_dims"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hps", ",", "fbanks", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"ResNet constructor.\n        Args:\n            hps: Hyperparameters.\n            fbanks: Batches of fbanks. [batch_size, time_step, fbank_dim]\n            labels: Batches of labels. [batch_size, num_classes]\n            mode: One of 'train' and 'eval'.\n        \"\"\"", "\n", "self", ".", "hps", "=", "hps", "\n", "self", ".", "fbanks", "=", "tf", ".", "expand_dims", "(", "fbanks", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "self", ".", "_extra_train_ops", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet.build_graph": [[65, 74], ["tensorflow.train.get_or_create_global_step", "resnet.ResNet._build_model_multi_gpu", "tensorflow.summary.merge_all", "resnet.ResNet._build_train_op_multi_gpu"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model_multi_gpu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_train_op_multi_gpu"], ["", "def", "build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build a whole graph for the model.\"\"\"", "\n", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "# self._build_model(self.fbanks, self.labels)", "\n", "self", ".", "_build_model_multi_gpu", "(", "self", ".", "fbanks", ",", "self", ".", "labels", ")", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "# self._build_train_op()", "\n", "            ", "self", ".", "_build_train_op_multi_gpu", "(", ")", "\n", "", "self", ".", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._stride_arr": [[75, 78], ["None"], "methods", ["None"], ["", "def", "_stride_arr", "(", "self", ",", "stride", ")", ":", "\n", "        ", "\"\"\"Map a stride scalar to the stride array for tf.nn.conv2d.\"\"\"", "\n", "return", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._build_model_multi_gpu": [[79, 103], ["list", "list", "list", "list", "list", "range", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.device", "tensorflow.split", "tensorflow.split", "tensorflow.stack", "tensorflow.stack", "tensorflow.device", "tensorflow.train.replica_device_setter", "tensorflow.variable_scope", "resnet.ResNet._build_model", "list.append", "list.append", "list.append", "list.append"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_build_model_multi_gpu", "(", "self", ",", "fbanks", ",", "labels", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "tower_fbanks", "=", "tf", ".", "split", "(", "fbanks", ",", "self", ".", "hps", ".", "num_gpus", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels", ",", "self", ".", "hps", ".", "num_gpus", ")", "\n", "\n", "", "tower_gvs", "=", "list", "(", ")", "\n", "tower_predictions", "=", "list", "(", ")", "\n", "tower_costs", "=", "list", "(", ")", "\n", "tower_accuracies", "=", "list", "(", ")", "\n", "tower_gradients", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "hps", ".", "num_gpus", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "'/cpu:0'", ",", "worker_device", "=", "'/gpu:{}'", ".", "format", "(", "i", ")", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "''", ")", ":", "\n", "                    ", "self", ".", "_build_model", "(", "tower_fbanks", "[", "i", "]", ",", "tower_labels", "[", "i", "]", ")", "\n", "tower_gvs", ".", "append", "(", "self", ".", "gv", ")", "\n", "tower_predictions", ".", "append", "(", "self", ".", "predictions", ")", "\n", "tower_costs", ".", "append", "(", "self", ".", "cost", ")", "\n", "tower_accuracies", ".", "append", "(", "self", ".", "accuracy", ")", "\n", "\n", "", "", "", "self", ".", "gv", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "tower_gvs", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "tower_predictions", ")", "\n", "self", ".", "cost", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_costs", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_accuracies", ")", ")", "\n", "self", ".", "costs", "=", "tower_costs", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._build_model": [[104, 179], ["six.moves.range", "six.moves.range", "six.moves.range", "six.moves.range", "tensorflow.variable_scope", "resnet.ResNet._conv", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._global_mean_std_pool", "tensorflow.variable_scope", "resnet.ResNet._fully_connected", "tensorflow.variable_scope", "resnet.ResNet._fully_connected", "tensorflow.nn.softmax", "tensorflow.variable_scope", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "resnet.ResNet._decay", "tensorflow.variable_scope", "tensorflow.equal", "tensorflow.reduce_mean", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "tensorflow.nn.dropout", "tensorflow.argmax", "tensorflow.cast", "tensorflow.cast", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._global_mean_std_pool", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._decay", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr"], ["", "def", "_build_model", "(", "self", ",", "fbanks", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Build the core model within the graph.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'init'", ")", ":", "\n", "            ", "x", "=", "fbanks", "\n", "x", "=", "self", ".", "_conv", "(", "'init_conv'", ",", "x", ",", "3", ",", "1", ",", "16", ",", "self", ".", "_stride_arr", "(", "1", ")", ")", "\n", "\n", "", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "activate_before_residual", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "if", "self", ".", "hps", ".", "use_bottleneck", ":", "\n", "            ", "res_func", "=", "self", ".", "_bottleneck_residual", "\n", "filters", "=", "[", "16", ",", "64", ",", "128", ",", "256", "]", "\n", "", "else", ":", "\n", "            ", "res_func", "=", "self", ".", "_residual", "\n", "filters", "=", "[", "16", ",", "32", ",", "64", ",", "128", "]", "\n", "# filters = [32, 64, 128, 256]", "\n", "# Uncomment the following codes to use w28-10 wide residual network.", "\n", "# It is more memory efficient than very deep residual network and has", "\n", "# comparably good performance.", "\n", "# https://arxiv.org/pdf/1605.07146v1.pdf", "\n", "# filters = [16, 160, 320, 640]", "\n", "# Update hps.num_residual_units to 4", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'unit_0_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "16", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "0", "]", ")", ",", "\n", "activate_before_residual", "[", "0", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "0", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_0_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_1_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "1", "]", ")", ",", "\n", "activate_before_residual", "[", "1", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "1", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_1_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_2_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "2", "]", ")", ",", "\n", "activate_before_residual", "[", "2", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "2", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_2_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_3_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "3", "]", ")", ",", "\n", "activate_before_residual", "[", "3", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "3", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_3_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "3", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_last'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'final_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_global_mean_std_pool", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'vector'", ")", ":", "\n", "            ", "self", ".", "gv", "=", "self", ".", "_fully_connected", "(", "x", ",", "self", ".", "hps", ".", "gv_dim", ")", "\n", "# self.gv = self.gv / tf.norm(self.gv, ord=2, axis=-1, keep_dims=True)", "\n", "dropout_gv", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "gv", ",", "keep_prob", "=", "1", "-", "self", ".", "hps", ".", "dropout_rate", ")", "if", "self", ".", "mode", "==", "'train'", "else", "self", ".", "gv", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'logit'", ")", ":", "\n", "            ", "logits", "=", "self", ".", "_fully_connected", "(", "dropout_gv", ",", "self", ".", "hps", ".", "num_classes", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'costs'", ")", ":", "\n", "            ", "xent", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n", "self", ".", "cost", "=", "tf", ".", "reduce_mean", "(", "xent", ",", "name", "=", "'xent'", ")", "\n", "self", ".", "cost", "+=", "self", ".", "_decay", "(", ")", "\n", "\n", "# tf.summary.scalar('cost', self.cost)", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'accuracy'", ")", ":", "\n", "            ", "correct_predictions", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "self", ".", "predictions", ",", "1", ",", "output_type", "=", "tf", ".", "int32", ")", ",", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int32", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_predictions", ",", "tf", ".", "float32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._compute_gradient": [[182, 186], ["tensorflow.trainable_variables", "tensorflow.gradients"], "methods", ["None"], ["", "", "def", "_compute_gradient", "(", "self", ",", "cost", ")", ":", "\n", "        ", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "cost", ",", "trainable_variables", ")", "\n", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._average_gradients": [[187, 200], ["list", "zip", "list", "tensorflow.concat", "tensorflow.reduce_mean", "list.append", "tensorflow.expand_dims", "list.append"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_average_gradients", "(", "self", ",", "gradients", ")", ":", "\n", "        ", "avg_grads", "=", "list", "(", ")", "\n", "for", "grads_per_gpu", "in", "zip", "(", "*", "gradients", ")", ":", "\n", "            ", "grads", "=", "list", "(", ")", "\n", "for", "g", "in", "grads_per_gpu", ":", "\n", "                ", "expanded_g", "=", "tf", ".", "expand_dims", "(", "g", ",", "0", ")", "\n", "grads", ".", "append", "(", "expanded_g", ")", "\n", "\n", "", "grad", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "grads", ")", "\n", "grad", "=", "tf", ".", "reduce_mean", "(", "grad", ",", "0", ")", "\n", "\n", "avg_grads", ".", "append", "(", "grad", ")", "\n", "", "return", "avg_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._build_train_op_multi_gpu": [[201, 232], ["resnet.ResNet._learning_rate_decay", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "list", "enumerate", "tensorflow.group", "tensorflow.device", "resnet.ResNet._average_gradients", "tensorflow.device", "list.append", "tensorflow.train.GradientDescentOptimizer", "tensorflow.clip_by_global_norm", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.replica_device_setter", "resnet.ResNet._compute_gradient", "tensorflow.train.MomentumOptimizer", "tensorflow.get_collection", "zip", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._average_gradients", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._compute_gradient"], ["", "def", "_build_train_op_multi_gpu", "(", "self", ")", ":", "\n", "# self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)", "\n", "        ", "self", ".", "lrn_rate", "=", "self", ".", "_learning_rate_decay", "(", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "self", ".", "lrn_rate", ")", "\n", "\n", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "gradients", "=", "list", "(", ")", "\n", "for", "i", ",", "cost", "in", "enumerate", "(", "self", ".", "costs", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "'/cpu:0'", ",", "worker_device", "=", "'/gpu:{}'", ".", "format", "(", "i", ")", ")", ")", ":", "\n", "                ", "gradients", ".", "append", "(", "self", ".", "_compute_gradient", "(", "cost", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "grads", "=", "self", ".", "_average_gradients", "(", "gradients", ")", "\n", "\n", "if", "self", ".", "hps", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "lrn_rate", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'mom'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'adam'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ",", "0.999", ",", "1e-6", ")", "\n", "\n", "", "if", "self", ".", "hps", ".", "clip_gradients", ":", "\n", "                ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "1.", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", ")", ":", "\n", "                ", "apply_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "zip", "(", "grads", ",", "trainable_variables", ")", ",", "\n", "global_step", "=", "self", ".", "global_step", ",", "name", "=", "'train_step'", ")", "\n", "\n", "", "", "train_ops", "=", "[", "apply_op", "]", "+", "self", ".", "_extra_train_ops", "\n", "self", ".", "train_op", "=", "tf", ".", "group", "(", "*", "train_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._build_train_op": [[233, 260], ["resnet.ResNet._learning_rate_decay", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.group", "tensorflow.train.GradientDescentOptimizer", "tensorflow.clip_by_global_norm", "zip", "tensorflow.train.MomentumOptimizer", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay"], ["", "def", "_build_train_op", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build training specific ops for the graph.\"\"\"", "\n", "# self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)", "\n", "self", ".", "lrn_rate", "=", "self", ".", "_learning_rate_decay", "(", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "self", ".", "lrn_rate", ")", "\n", "\n", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "self", ".", "cost", ",", "trainable_variables", ")", "\n", "\n", "if", "self", ".", "hps", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "lrn_rate", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'mom'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'adam'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ",", "0.999", ",", "1e-6", ")", "\n", "\n", "# grads, trainable_variables = zip(*optimizer.compute_gradients(self.cost))", "\n", "\n", "", "if", "self", ".", "hps", ".", "clip_gradients", ":", "\n", "            ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "1.", ")", "\n", "\n", "", "apply_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "zip", "(", "grads", ",", "trainable_variables", ")", ",", "\n", "global_step", "=", "self", ".", "global_step", ",", "name", "=", "'train_step'", ")", "\n", "\n", "train_ops", "=", "[", "apply_op", "]", "+", "self", ".", "_extra_train_ops", "\n", "self", ".", "train_op", "=", "tf", ".", "group", "(", "*", "train_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._batch_norm": [[262, 306], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.batch_normalization", "tensorflow.nn.batch_normalization.set_shape", "tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "resnet.ResNet._extra_train_ops.append", "resnet.ResNet._extra_train_ops.append", "tensorflow.get_variable", "tensorflow.get_variable", "x.get_shape", "x.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_batch_norm", "(", "self", ",", "name", ",", "x", ")", ":", "\n", "        ", "\"\"\"Batch normalization.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "params_shape", "=", "[", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", "\n", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "'beta'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "'gamma'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "                ", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", ",", "1", ",", "2", "]", ",", "name", "=", "'moments'", ")", "\n", "\n", "moving_mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_mean", ",", "mean", ",", "0.9", ")", ")", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_variance", ",", "variance", ",", "0.9", ")", ")", "\n", "", "else", ":", "\n", "                ", "mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "# tf.summary.histogram(mean.op.name, mean)", "\n", "# tf.summary.histogram(variance.op.name, variance)", "\n", "# epsilon used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.", "\n", "", "y", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "mean", ",", "variance", ",", "beta", ",", "gamma", ",", "0.001", ")", "\n", "y", ".", "set_shape", "(", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._residual": [[307, 342], ["tensorflow.logging.debug", "tensorflow.variable_scope", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet.get_shape", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv"], ["", "", "def", "_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n", "activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Residual unit with 2 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'shared_activation'", ")", ":", "\n", "                ", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_only_activation'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "3", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'sub_add_conv'", ",", "orig_x", ",", "3", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "'''\n                orig_x = tf.nn.avg_pool(orig_x, stride, stride, 'SAME')\n                orig_x = tf.pad(\n                        orig_x, [[0, 0], [0, 0], [0, 0],\n                                         [(out_filter-in_filter)//2, (out_filter-in_filter)//2]])\n                '''", "\n", "", "x", "+=", "orig_x", "\n", "\n", "", "tf", ".", "logging", ".", "debug", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._bottleneck_residual": [[343, 377], ["tensorflow.logging.info", "tensorflow.variable_scope", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet.get_shape", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv"], ["", "def", "_bottleneck_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n", "activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Bottleneck residual unit with 3 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'common_bn_relu'", ")", ":", "\n", "                ", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_bn_relu'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "1", ",", "in_filter", ",", "out_filter", "/", "4", ",", "stride", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", "/", "4", ",", "out_filter", "/", "4", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub3'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn3'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv3'", ",", "x", ",", "1", ",", "out_filter", "/", "4", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'project'", ",", "orig_x", ",", "1", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "", "x", "+=", "orig_x", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._decay": [[378, 387], ["tensorflow.trainable_variables", "tensorflow.multiply", "tensorflow.add_n", "var.op.name.find", "costs.append", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_decay", "(", "self", ")", ":", "\n", "        ", "\"\"\"L2 weight decay loss.\"\"\"", "\n", "costs", "=", "[", "]", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "if", "var", ".", "op", ".", "name", ".", "find", "(", "r'DW'", ")", ">", "0", ":", "\n", "                ", "costs", ".", "append", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ")", "\n", "# tf.summary.histogram(var.op.name, var)", "\n", "\n", "", "", "return", "tf", ".", "multiply", "(", "self", ".", "hps", ".", "weight_decay_rate", ",", "tf", ".", "add_n", "(", "costs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._conv": [[388, 397], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.random_normal_initializer", "numpy.sqrt"], "methods", ["None"], ["", "def", "_conv", "(", "self", ",", "name", ",", "x", ",", "filter_size", ",", "in_filters", ",", "out_filters", ",", "strides", ")", ":", "\n", "        ", "\"\"\"Convolution.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "n", "=", "filter_size", "*", "filter_size", "*", "out_filters", "\n", "kernel", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "filter_size", ",", "filter_size", ",", "in_filters", ",", "out_filters", "]", ",", "\n", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "kernel", ",", "strides", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._relu": [[398, 401], ["tensorflow.where", "tensorflow.less"], "methods", ["None"], ["", "", "def", "_relu", "(", "self", ",", "x", ",", "leakiness", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Relu, with optional leaky support.\"\"\"", "\n", "return", "tf", ".", "where", "(", "tf", ".", "less", "(", "x", ",", "0.0", ")", ",", "leakiness", "*", "x", ",", "x", ",", "name", "=", "'leaky_relu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._fully_connected": [[402, 411], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.constant_initializer", "x.get_shape"], "methods", ["None"], ["", "def", "_fully_connected", "(", "self", ",", "x", ",", "out_dim", ")", ":", "\n", "        ", "\"\"\"FullyConnected layer for final output.\"\"\"", "\n", "# x = tf.reshape(x, [tf.shape(x)[0], -1])", "\n", "w", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "x", ".", "get_shape", "(", ")", "[", "1", "]", ",", "out_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", "factor", "=", "1.0", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "[", "out_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", ")", ")", "\n", "return", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", ",", "w", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._global_avg_pool": [[412, 415], ["tensorflow.reduce_mean", "x.get_shape"], "methods", ["None"], ["", "def", "_global_avg_pool", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "return", "tf", ".", "reduce_mean", "(", "x", ",", "[", "1", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._global_mean_std_pool": [[416, 420], ["tensorflow.nn.moments", "tensorflow.concat", "x.get_shape"], "methods", ["None"], ["", "def", "_global_mean_std_pool", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "mean", ",", "std", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "1", ",", "2", "]", ")", "\n", "return", "tf", ".", "concat", "(", "[", "mean", ",", "std", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.resnet.ResNet._learning_rate_decay": [[421, 431], ["tensorflow.train.exponential_decay", "tensorflow.minimum", "tensorflow.constant", "tensorflow.maximum"], "methods", ["None"], ["", "def", "_learning_rate_decay", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "hps", ".", "decay_learning_rate", ":", "\n", "            ", "return", "tf", ".", "constant", "(", "self", ".", "hps", ".", "lrn_rate", ",", "tf", ".", "float32", ")", "\n", "\n", "", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "hps", ".", "lrn_rate", ",", "\n", "self", ".", "global_step", "-", "self", ".", "hps", ".", "start_decay", ",", "\n", "self", ".", "hps", ".", "decay_steps", ",", "\n", "self", ".", "hps", ".", "decay_rate", ")", "\n", "\n", "return", "tf", ".", "minimum", "(", "tf", ".", "maximum", "(", "lr", ",", "self", ".", "hps", ".", "min_lrn_rate", ")", ",", "self", ".", "hps", ".", "lrn_rate", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.hparams.hparams_debug_string": [[376, 380], ["hparams.values", "sorted"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.__init__": [[2, 5], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "window_size", "=", "100", ")", ":", "\n", "    ", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.append": [[6, 8], ["None"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "x", ")", ":", "\n", "    ", "self", ".", "_values", "=", "self", ".", "_values", "[", "-", "(", "self", ".", "_window_size", "-", "1", ")", ":", "]", "+", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.sum": [[9, 12], ["utils.ValueWindow.sum"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "@", "property", "\n", "def", "sum", "(", "self", ")", ":", "\n", "    ", "return", "sum", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.count": [[13, 16], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "count", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.average": [[17, 20], ["max"], "methods", ["None"], ["", "@", "property", "\n", "def", "average", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "sum", "/", "max", "(", "1", ",", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.utils.ValueWindow.reset": [[21, 23], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "_values", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNetHParams.replace": [[39, 41], ["super()._replace"], "methods", ["None"], ["    ", "def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "ResNetHParams", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet.__init__": [[66, 77], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hps", ",", "mode", ")", ":", "\n", "        ", "\"\"\"ResNet constructor.\n        Args:\n            hps: Hyperparameters.\n            fbanks: Batches of fbanks. [batch_size, time_step, fbank_dim]\n            labels: Batches of labels. [batch_size, num_classes]\n            mode: One of 'train' and 'eval'.\n        \"\"\"", "\n", "self", ".", "hps", "=", "hps", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "_extra_train_ops", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._stride_arr": [[78, 81], ["None"], "methods", ["None"], ["", "def", "_stride_arr", "(", "self", ",", "stride", ")", ":", "\n", "        ", "\"\"\"Map a stride scalar to the stride array for tf.nn.conv2d.\"\"\"", "\n", "return", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet.__call__": [[83, 146], ["tensorflow.expand_dims", "six.moves.range", "six.moves.range", "six.moves.range", "six.moves.range", "tensorflow.variable_scope", "Resnet.ResNet._conv", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "Resnet.ResNet._global_mean_std_pool", "tensorflow.variable_scope", "Resnet.ResNet._fully_connected", "Resnet.ResNet._stride_arr", "Resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "Resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "Resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "Resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "tensorflow.nn.dropout", "Resnet.ResNet._stride_arr", "Resnet.ResNet._stride_arr", "Resnet.ResNet._stride_arr", "Resnet.ResNet._stride_arr"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._global_mean_std_pool", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr"], ["", "def", "__call__", "(", "self", ",", "x", ",", "embed_masks", ")", ":", "\n", "        ", "\"\"\"Build the core model within the graph.\"\"\"", "\n", "x", "=", "tf", ".", "expand_dims", "(", "x", ",", "axis", "=", "-", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'init'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'init_conv'", ",", "x", ",", "3", ",", "1", ",", "16", ",", "self", ".", "_stride_arr", "(", "1", ")", ")", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ")", "\n", "\n", "", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "activate_before_residual", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "if", "self", ".", "hps", ".", "use_bottleneck", ":", "\n", "            ", "res_func", "=", "self", ".", "_bottleneck_residual", "\n", "filters", "=", "[", "16", ",", "64", ",", "128", ",", "256", "]", "\n", "", "else", ":", "\n", "            ", "res_func", "=", "self", ".", "_residual", "\n", "filters", "=", "[", "16", ",", "32", ",", "64", ",", "128", "]", "\n", "# filters = [32, 64, 128, 256]", "\n", "# Uncomment the following codes to use w28-10 wide residual network.", "\n", "# It is more memory efficient than very deep residual network and has", "\n", "# comparably good performance.", "\n", "# https://arxiv.org/pdf/1605.07146v1.pdf", "\n", "# filters = [16, 160, 320, 640]", "\n", "# Update hps.num_residual_units to 4", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'unit_0_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "16", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "0", "]", ")", ",", "\n", "activate_before_residual", "[", "0", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "0", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_0_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_1_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "1", "]", ")", ",", "\n", "activate_before_residual", "[", "1", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "1", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_1_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_2_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "2", "]", ")", ",", "\n", "activate_before_residual", "[", "2", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "2", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_2_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_3_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "3", "]", ")", ",", "\n", "activate_before_residual", "[", "3", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "3", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_3_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "3", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_last'", ")", ":", "\n", "#x = self._batch_norm('final_bn', x)", "\n", "#x = self._relu(x, self.hps.relu_leakiness)", "\n", "            ", "x", "=", "self", ".", "_global_mean_std_pool", "(", "x", ",", "embed_masks", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'vector'", ")", ":", "\n", "            ", "gv", "=", "self", ".", "_fully_connected", "(", "x", ",", "self", ".", "hps", ".", "gv_dim", ")", "\n", "# self.gv = self.gv / tf.norm(self.gv, ord=2, axis=-1, keep_dims=True)", "\n", "dropout_gv", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "gv", ",", "keep_prob", "=", "1", "-", "self", ".", "hps", ".", "dropout_rate", ")", "if", "self", ".", "mode", "==", "'train'", "else", "gv", "\n", "", "return", "dropout_gv", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._batch_norm": [[148, 192], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.batch_normalization", "tensorflow.nn.batch_normalization.set_shape", "tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "Resnet.ResNet._extra_train_ops.append", "Resnet.ResNet._extra_train_ops.append", "tensorflow.get_variable", "tensorflow.get_variable", "x.get_shape", "x.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_batch_norm", "(", "self", ",", "name", ",", "x", ")", ":", "\n", "        ", "\"\"\"Batch normalization.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "params_shape", "=", "[", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", "\n", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "'beta'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "'gamma'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "                ", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", ",", "1", ",", "2", "]", ",", "name", "=", "'moments'", ")", "\n", "\n", "moving_mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_mean", ",", "mean", ",", "0.9", ")", ")", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_variance", ",", "variance", ",", "0.9", ")", ")", "\n", "", "else", ":", "\n", "                ", "mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "# tf.summary.histogram(mean.op.name, mean)", "\n", "# tf.summary.histogram(variance.op.name, variance)", "\n", "# epsilon used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.", "\n", "", "y", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "mean", ",", "variance", ",", "beta", ",", "gamma", ",", "0.001", ")", "\n", "y", ".", "set_shape", "(", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._residual": [[193, 232], ["tensorflow.logging.debug", "tensorflow.variable_scope", "Resnet.ResNet._conv", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "tensorflow.variable_scope", "Resnet.ResNet._conv", "Resnet.ResNet._batch_norm", "tensorflow.variable_scope", "Resnet.ResNet._relu", "Resnet.ResNet.get_shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "Resnet.ResNet._conv", "Resnet.ResNet._batch_norm"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm"], ["", "", "def", "_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n", "activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Residual unit with 2 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'shared_activation'", ")", ":", "\n", "# x = self._batch_norm('init_bn', x)", "\n", "# x = self._relu(x, self.hps.relu_leakiness)", "\n", "                ", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_only_activation'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "3", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'bn1'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'sub_add_conv'", ",", "orig_x", ",", "1", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "orig_x", "=", "self", ".", "_batch_norm", "(", "'bn_add'", ",", "orig_x", ")", "\n", "'''\n                orig_x = tf.nn.avg_pool(orig_x, stride, stride, 'SAME')\n                orig_x = tf.pad(\n                        orig_x, [[0, 0], [0, 0], [0, 0],\n                                         [(out_filter-in_filter)//2, (out_filter-in_filter)//2]])\n                '''", "\n", "", "x", "+=", "orig_x", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "tf", ".", "logging", ".", "debug", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._bottleneck_residual": [[233, 267], ["tensorflow.logging.info", "tensorflow.variable_scope", "Resnet.ResNet._conv", "tensorflow.variable_scope", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "Resnet.ResNet._conv", "tensorflow.variable_scope", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "Resnet.ResNet._conv", "tensorflow.variable_scope", "Resnet.ResNet.get_shape", "tensorflow.variable_scope", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "tensorflow.variable_scope", "Resnet.ResNet._batch_norm", "Resnet.ResNet._relu", "Resnet.ResNet._conv"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv"], ["", "def", "_bottleneck_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n", "activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Bottleneck residual unit with 3 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'common_bn_relu'", ")", ":", "\n", "                ", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_bn_relu'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "1", ",", "in_filter", ",", "out_filter", "/", "4", ",", "stride", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", "/", "4", ",", "out_filter", "/", "4", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub3'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn3'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv3'", ",", "x", ",", "1", ",", "out_filter", "/", "4", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'project'", ",", "orig_x", ",", "1", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "", "x", "+=", "orig_x", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._decay": [[268, 277], ["tensorflow.trainable_variables", "tensorflow.multiply", "tensorflow.add_n", "var.op.name.find", "costs.append", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_decay", "(", "self", ")", ":", "\n", "        ", "\"\"\"L2 weight decay loss.\"\"\"", "\n", "costs", "=", "[", "]", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "if", "var", ".", "op", ".", "name", ".", "find", "(", "r'DW'", ")", ">", "0", ":", "\n", "                ", "costs", ".", "append", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ")", "\n", "# tf.summary.histogram(var.op.name, var)", "\n", "\n", "", "", "return", "tf", ".", "multiply", "(", "self", ".", "hps", ".", "weight_decay_rate", ",", "tf", ".", "add_n", "(", "costs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._conv": [[278, 287], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.random_normal_initializer", "numpy.sqrt"], "methods", ["None"], ["", "def", "_conv", "(", "self", ",", "name", ",", "x", ",", "filter_size", ",", "in_filters", ",", "out_filters", ",", "strides", ")", ":", "\n", "        ", "\"\"\"Convolution.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "n", "=", "filter_size", "*", "filter_size", "*", "out_filters", "\n", "kernel", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "filter_size", ",", "filter_size", ",", "in_filters", ",", "out_filters", "]", ",", "\n", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "kernel", ",", "strides", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._relu": [[288, 291], ["tensorflow.nn.relu"], "methods", ["None"], ["", "", "def", "_relu", "(", "self", ",", "x", ",", "leakiness", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Relu, with optional leaky support.\"\"\"", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "#return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._fully_connected": [[293, 302], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.constant_initializer", "x.get_shape"], "methods", ["None"], ["", "def", "_fully_connected", "(", "self", ",", "x", ",", "out_dim", ")", ":", "\n", "        ", "\"\"\"FullyConnected layer for final output.\"\"\"", "\n", "# x = tf.reshape(x, [tf.shape(x)[0], -1])", "\n", "w", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "x", ".", "get_shape", "(", ")", "[", "1", "]", ",", "out_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", "factor", "=", "1.0", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "[", "out_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", ")", ")", "\n", "return", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", ",", "w", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._global_avg_pool": [[303, 306], ["tensorflow.reduce_mean", "x.get_shape"], "methods", ["None"], ["", "def", "_global_avg_pool", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "return", "tf", ".", "reduce_mean", "(", "x", ",", "[", "1", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.embedding.Resnet.ResNet._global_mean_std_pool": [[307, 315], ["tensorflow.concat", "tensorflow.nn.moments", "tensorflow.nn.weighted_moments", "x.get_shape"], "methods", ["None"], ["", "def", "_global_mean_std_pool", "(", "self", ",", "x", ",", "embed_masks", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "if", "embed_masks", "==", "None", ":", "\n", "            ", "mean", ",", "std", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "1", ",", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "mean", ",", "std", "=", "tf", ".", "nn", ".", "weighted_moments", "(", "x", ",", "[", "1", ",", "2", "]", ",", "embed_masks", ")", "\n", "#mean, std = tf.nn.moments(x, axes=[1, 2])", "\n", "", "return", "tf", ".", "concat", "(", "[", "mean", ",", "std", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.wavenet_preprocessor.build_from_path": [[10, 37], ["concurrent.futures.ProcessPoolExecutor", "os.listdir", "os.path.join", "os.path.basename().replace", "futures.append", "future.result", "concurrent.futures.ProcessPoolExecutor.submit", "tqdm", "os.path.basename", "functools.partial", "future.result"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["def", "build_from_path", "(", "hparams", ",", "input_dir", ",", "mel_dir", ",", "wav_dir", ",", "n_jobs", "=", "12", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "\t", "\"\"\"\n\tPreprocesses the speech dataset from a gven input path to given output directories\n\n\tArgs:\n\t\t- hparams: hyper parameters\n\t\t- input_dir: input directory that contains the files to prerocess\n\t\t- mel_dir: output directory of the preprocessed speech mel-spectrogram dataset\n\t\t- linear_dir: output directory of the preprocessed speech linear-spectrogram dataset\n\t\t- wav_dir: output directory of the preprocessed speech audio dataset\n\t\t- n_jobs: Optional, number of worker process to parallelize across\n\t\t- tqdm: Optional, provides a nice progress bar\n\n\tReturns:\n\t\t- A list of tuple describing the train examples. this should be written to train.txt\n\t\"\"\"", "\n", "\n", "# We use ProcessPoolExecutor to parallelize across processes, this is just for", "\n", "# optimization purposes and it can be omited", "\n", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "n_jobs", ")", "\n", "futures", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "input_dir", ")", ":", "\n", "\t\t", "wav_path", "=", "os", ".", "path", ".", "join", "(", "input_dir", ",", "file", ")", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "wav_path", ")", ".", "replace", "(", "'.wav'", ",", "''", ")", "\n", "futures", ".", "append", "(", "executor", ".", "submit", "(", "partial", "(", "_process_utterance", ",", "mel_dir", ",", "wav_dir", ",", "basename", ",", "wav_path", ",", "hparams", ")", ")", ")", "\n", "\n", "", "return", "[", "future", ".", "result", "(", ")", "for", "future", "in", "tqdm", "(", "futures", ")", "if", "future", ".", "result", "(", ")", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.wavenet_preprocessor._process_utterance": [[39, 155], ["datasets.audio.preemphasis", "wavenet_vocoder.util.is_mulaw_quantize", "datasets.audio.melspectrogram().astype", "len", "os.path.join", "os.path.join", "numpy.save", "numpy.save", "datasets.audio.load_wav", "datasets.audio.trim_silence", "wavenet_vocoder.util.mulaw_quantize", "datasets.audio.start_and_end_indices", "wavenet_vocoder.util.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "datasets.audio.pad_lr", "numpy.pad", "datasets.audio.librosa_pad_lr", "numpy.pad", "len", "wavenet_vocoder.util.mulaw.astype", "RuntimeError", "print", "RuntimeError", "RuntimeError", "wavenet_vocoder.util.mulaw", "wavenet_vocoder.util.mulaw", "datasets.audio.melspectrogram", "datasets.audio.get_hop_size", "datasets.audio.get_hop_size", "datasets.audio.get_hop_size", "len", "datasets.audio.get_hop_size", "numpy.abs().max", "numpy.abs().max", "datasets.audio.get_hop_size", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.start_and_end_indices", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.pad_lr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.librosa_pad_lr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], ["", "def", "_process_utterance", "(", "mel_dir", ",", "wav_dir", ",", "index", ",", "wav_path", ",", "hparams", ")", ":", "\n", "\t", "\"\"\"\n\tPreprocesses a single utterance wav/text pair\n\n\tthis writes the mel scale spectogram to disk and return a tuple to write\n\tto the train.txt file\n\n\tArgs:\n\t\t- mel_dir: the directory to write the mel spectograms into\n\t\t- linear_dir: the directory to write the linear spectrograms into\n\t\t- wav_dir: the directory to write the preprocessed wav into\n\t\t- index: the numeric index to use in the spectrogram filename\n\t\t- wav_path: path to the audio file containing the speech input\n\t\t- text: text spoken in the input audio file\n\t\t- hparams: hyper parameters\n\n\tReturns:\n\t\t- A tuple: (audio_filename, mel_filename, linear_filename, time_steps, mel_frames, linear_frames, text)\n\t\"\"\"", "\n", "try", ":", "\n", "# Load the audio as numpy array", "\n", "\t\t", "wav", "=", "audio", ".", "load_wav", "(", "wav_path", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "", "except", "FileNotFoundError", ":", "#catch missing wav exception", "\n", "\t\t", "print", "(", "'file {} present in csv metadata is not present in wav folder. skipping!'", ".", "format", "(", "\n", "wav_path", ")", ")", "\n", "return", "None", "\n", "\n", "#M-AILABS extra silence specific", "\n", "", "if", "hparams", ".", "trim_silence", ":", "\n", "\t\t", "wav", "=", "audio", ".", "trim_silence", "(", "wav", ",", "hparams", ")", "\n", "\n", "#Pre-emphasize", "\n", "", "preem_wav", "=", "audio", ".", "preemphasis", "(", "wav", ",", "hparams", ".", "preemphasis", ",", "hparams", ".", "preemphasize", ")", "\n", "\n", "#rescale wav", "\n", "if", "hparams", ".", "rescale", ":", "\n", "\t\t", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "preem_wav", "=", "preem_wav", "/", "np", ".", "abs", "(", "preem_wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "#Assert all audio is in [-1, 1]", "\n", "if", "(", "wav", ">", "1.", ")", ".", "any", "(", ")", "or", "(", "wav", "<", "-", "1.", ")", ".", "any", "(", ")", ":", "\n", "\t\t\t", "raise", "RuntimeError", "(", "'wav has invalid value: {}'", ".", "format", "(", "wav_path", ")", ")", "\n", "", "if", "(", "preem_wav", ">", "1.", ")", ".", "any", "(", ")", "or", "(", "preem_wav", "<", "-", "1.", ")", ".", "any", "(", ")", ":", "\n", "\t\t\t", "raise", "RuntimeError", "(", "'wav has invalid value: {}'", ".", "format", "(", "wav_path", ")", ")", "\n", "\n", "#Mu-law quantize", "\n", "", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "#[0, quantize_channels)", "\n", "\t\t", "out", "=", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "#Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "preem_wav", "=", "preem_wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "\n", "constant_values", "=", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "#[-1, 1]", "\n", "\t\t", "out", "=", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "mulaw", "(", "0.", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "", "else", ":", "\n", "#[-1, 1]", "\n", "\t\t", "out", "=", "wav", "\n", "constant_values", "=", "0.", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute the mel scale spectrogram from the wav", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "preem_wav", ",", "hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mel_frames", "=", "mel_spectrogram", ".", "shape", "[", "1", "]", "\n", "\n", "if", "mel_frames", ">", "hparams", ".", "max_mel_frames", "and", "hparams", ".", "clip_mels_length", ":", "\n", "\t\t", "return", "None", "\n", "\n", "", "if", "hparams", ".", "use_lws", ":", "\n", "#Ensure time resolution adjustement between audio and mel-spectrogram", "\n", "\t\t", "fft_size", "=", "hparams", ".", "n_fft", "if", "hparams", ".", "win_size", "is", "None", "else", "hparams", ".", "win_size", "\n", "l", ",", "r", "=", "audio", ".", "pad_lr", "(", "wav", ",", "fft_size", ",", "audio", ".", "get_hop_size", "(", "hparams", ")", ")", "\n", "\n", "#Zero pad audio signal", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l", ",", "r", ")", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "constant_values", ")", "\n", "", "else", ":", "\n", "#Ensure time resolution adjustement between audio and mel-spectrogram", "\n", "\t\t", "l_pad", ",", "r_pad", "=", "audio", ".", "librosa_pad_lr", "(", "wav", ",", "hparams", ".", "n_fft", ",", "audio", ".", "get_hop_size", "(", "hparams", ")", ")", "\n", "\n", "#Reflect pad audio signal (Just like it's done in Librosa to avoid frame inconsistency)", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l_pad", ",", "r_pad", ")", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "constant_values", ")", "\n", "\n", "", "assert", "len", "(", "out", ")", ">=", "mel_frames", "*", "audio", ".", "get_hop_size", "(", "hparams", ")", "\n", "\n", "#time resolution adjustement", "\n", "#ensure length of raw audio is multiple of hop size so that we can use", "\n", "#transposed convolution to upsample", "\n", "out", "=", "out", "[", ":", "mel_frames", "*", "audio", ".", "get_hop_size", "(", "hparams", ")", "]", "\n", "assert", "len", "(", "out", ")", "%", "audio", ".", "get_hop_size", "(", "hparams", ")", "==", "0", "\n", "time_steps", "=", "len", "(", "out", ")", "\n", "\n", "# Write the spectrogram and audio to disk", "\n", "audio_filename", "=", "os", ".", "path", ".", "join", "(", "wav_dir", ",", "'audio-{}.npy'", ".", "format", "(", "index", ")", ")", "\n", "mel_filename", "=", "os", ".", "path", ".", "join", "(", "mel_dir", ",", "'mel-{}.npy'", ".", "format", "(", "index", ")", ")", "\n", "np", ".", "save", "(", "audio_filename", ",", "out", ".", "astype", "(", "out_dtype", ")", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "mel_filename", ",", "mel_spectrogram", ".", "T", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "#global condition features", "\n", "if", "hparams", ".", "gin_channels", ">", "0", ":", "\n", "\t\t", "raise", "RuntimeError", "(", "'When activating global conditions, please set your speaker_id rules in line 129 of datasets/wavenet_preprocessor.py to use them during training'", ")", "\n", "speaker_id", "=", "'<no_g>'", "#put the rule to determine how to assign speaker ids (using file names maybe? file basenames are available in \"index\" variable)", "\n", "", "else", ":", "\n", "\t\t", "speaker_id", "=", "'<no_g>'", "\n", "\n", "# Return a tuple describing this training example", "\n", "", "return", "(", "audio_filename", ",", "mel_filename", ",", "mel_filename", ",", "speaker_id", ",", "time_steps", ",", "mel_frames", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.load_wav": [[9, 16], ["librosa.load", "librosa.load", "print"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["    ", "return", "2", "*", "x", "/", "(", "2", "**", "bits", "-", "1.", ")", "-", "1.", "\n", "\n", "\n", "", "def", "float_2_label", "(", "x", ",", "bits", ")", ":", "\n", "    ", "assert", "abs", "(", "x", ")", ".", "max", "(", ")", "<=", "1.0", "\n", "x", "=", "(", "x", "+", "1.", ")", "*", "(", "2", "**", "bits", "-", "1", ")", "/", "2", "\n", "return", "x", ".", "clip", "(", "0", ",", "2", "**", "bits", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.save_wav": [[17, 21], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "function", ["None"], ["\n", "", "def", "load_wav", "(", "path", ")", ":", "\n", "    ", "return", "librosa", ".", "load", "(", "path", ",", "sr", "=", "hp", ".", "sample_rate", ")", "[", "0", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.save_wavenet_wav": [[22, 24], ["librosa.output.write_wav", "librosa.output.write_wav"], "function", ["None"], ["", "def", "save_wav", "(", "x", ",", "path", ")", ":", "\n", "    ", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "x", ".", "astype", "(", "np", ".", "float32", ")", ",", "sr", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.preemphasis": [[25, 29], ["scipy.signal.lfilter"], "function", ["None"], ["\n", "", "def", "split_signal", "(", "x", ")", ":", "\n", "    ", "unsigned", "=", "x", "+", "2", "**", "15", "\n", "coarse", "=", "unsigned", "//", "256", "\n", "fine", "=", "unsigned", "%", "256", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.inv_preemphasis": [[30, 34], ["scipy.signal.lfilter"], "function", ["None"], ["return", "coarse", ",", "fine", "\n", "\n", "\n", "", "def", "combine_signal", "(", "coarse", ",", "fine", ")", ":", "\n", "    ", "return", "coarse", "*", "256", "+", "fine", "-", "2", "**", "15", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.start_and_end_indices": [[39, 51], ["range", "range", "abs", "abs", "abs", "abs"], "function", ["None"], ["\n", "\n", "", "mel_basis", "=", "None", "\n", "\n", "\n", "def", "linear_to_mel", "(", "spectrogram", ")", ":", "\n", "    ", "global", "mel_basis", "\n", "if", "mel_basis", "is", "None", ":", "\n", "        ", "mel_basis", "=", "build_mel_basis", "(", ")", "\n", "", "return", "np", ".", "dot", "(", "mel_basis", ",", "spectrogram", ")", "\n", "\n", "\n", "", "def", "build_mel_basis", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence": [[35, 37], ["librosa.effects.trim", "librosa.effects.trim"], "function", ["None"], ["\n", "\n", "", "def", "encode_16bits", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.get_hop_size": [[52, 58], ["int"], "function", ["None"], ["    ", "return", "librosa", ".", "filters", ".", "mel", "(", "hp", ".", "sample_rate", ",", "hp", ".", "n_fft", ",", "n_mels", "=", "hp", ".", "num_mels", ",", "fmin", "=", "hp", ".", "fmin", ")", "\n", "\n", "\n", "", "def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "-", "hp", ".", "min_level_db", ")", "/", "-", "hp", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.linearspectrogram": [[59, 66], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize"], ["", "def", "denormalize", "(", "S", ")", ":", "\n", "    ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "hp", ".", "min_level_db", ")", "+", "hp", ".", "min_level_db", "\n", "\n", "\n", "", "def", "amp_to_db", "(", "x", ")", ":", "\n", "    ", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "x", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.melspectrogram": [[67, 74], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "audio._linear_to_mel", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._linear_to_mel"], ["", "def", "db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n", "\n", "", "def", "spectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "np", ".", "abs", "(", "D", ")", ")", "-", "hp", ".", "ref_level_db", "\n", "return", "normalize", "(", "S", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.inv_linear_spectrogram": [[75, 91], ["audio._db_to_amp", "audio._denormalize", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_db_to_amp.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["\n", "\n", "", "def", "melspectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "\n", "return", "normalize", "(", "S", ")", "\n", "\n", "\n", "", "def", "stft", "(", "y", ")", ":", "\n", "    ", "return", "librosa", ".", "stft", "(", "y", "=", "y", ",", "n_fft", "=", "hp", ".", "n_fft", ",", "hop_length", "=", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ")", "\n", "\n", "\n", "", "def", "pre_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "[", "1", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "de_emphasis", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.inv_mel_spectrogram": [[92, 108], ["audio._mel_to_linear", "audio._denormalize", "audio._db_to_amp", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_mel_to_linear.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._mel_to_linear", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["    ", "return", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "encode_mu_law", "(", "x", ",", "mu", ")", ":", "\n", "    ", "mu", "=", "mu", "-", "1", "\n", "fx", "=", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "x", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "return", "np", ".", "floor", "(", "(", "fx", "+", "1", ")", "/", "2", "*", "mu", "+", "0.5", ")", "\n", "\n", "\n", "", "def", "decode_mu_law", "(", "y", ",", "mu", ",", "from_labels", "=", "True", ")", ":", "\n", "    ", "if", "from_labels", ":", "\n", "        ", "y", "=", "label_2_float", "(", "y", ",", "math", ".", "log2", "(", "mu", ")", ")", "\n", "", "mu", "=", "mu", "-", "1", "\n", "x", "=", "np", ".", "sign", "(", "y", ")", "/", "mu", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "y", ")", "-", "1", ")", "\n", "return", "x", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.inv_linear_spectrogram_tensorflow": [[118, 130], ["tensorflow.pow", "audio._griffin_lim_tensorflow", "audio._denormalize_tensorflow", "audio._db_to_amp_tensorflow", "tensorflow.pow"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._griffin_lim_tensorflow", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._denormalize_tensorflow", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._db_to_amp_tensorflow"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.inv_mel_spectrogram_tensorflow": [[131, 144], ["tensorflow.pow", "audio._mel_to_linear_tensorflow", "audio._griffin_lim_tensorflow", "audio._denormalize_tensorflow", "audio._db_to_amp_tensorflow", "tensorflow.pow"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._mel_to_linear_tensorflow", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._griffin_lim_tensorflow", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._denormalize_tensorflow", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._db_to_amp_tensorflow"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._lws_processor": [[109, 112], ["lws.lws", "audio.get_hop_size", "numpy.np.float32", "numpy.np.float32"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._griffin_lim": [[113, 124], ["numpy.exp", "numpy.abs().astype", "audio._istft", "range", "numpy.exp", "audio._istft", "numpy.random.rand", "numpy.abs", "numpy.angle", "audio._stft"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._griffin_lim_tensorflow": [[163, 177], ["tensorflow.squeeze", "tensorflow.variable_scope", "tensorflow.expand_dims", "tensorflow.identity", "tensorflow.contrib.signal.inverse_stft", "range", "tensorflow.cast", "audio.get_hop_size", "tensorflow.contrib.signal.stft", "tensorflow.contrib.signal.inverse_stft", "audio.get_hop_size", "tensorflow.cast", "audio.get_hop_size", "tensorflow.maximum", "tensorflow.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._stft": [[125, 130], ["librosa.stft", "librosa.stft", "_lws_processor().stft", "audio.get_hop_size", "audio._lws_processor"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._istft": [[131, 133], ["librosa.istft", "librosa.istft", "audio.get_hop_size"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.num_frames": [[136, 145], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.pad_lr": [[147, 155], ["audio.num_frames", "len", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.num_frames"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.librosa_pad_lr": [[157, 159], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._linear_to_mel": [[164, 169], ["numpy.dot", "audio._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._mel_to_linear": [[170, 175], ["numpy.maximum", "numpy.linalg.pinv", "numpy.dot", "audio._build_mel_basis", "numpy.np.float64"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._mel_to_linear_tensorflow": [[237, 242], ["tensorflow.maximum", "numpy.linalg.pinv", "tensorflow.matmul", "audio._build_mel_basis", "tensorflow.transpose", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._build_mel_basis": [[176, 180], ["librosa.filters.mel", "librosa.filters.mel"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._amp_to_db": [[181, 184], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._db_to_amp": [[185, 187], ["numpy.power", "numpy.np.float64"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._db_to_amp_tensorflow": [[255, 257], ["tensorflow.pow", "tensorflow.ones", "tensorflow.shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._normalize": [[188, 201], ["numpy.clip", "numpy.clip", "S.max", "S.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._denormalize": [[202, 215], ["numpy.clip", "numpy.clip"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio._denormalize_tensorflow": [[286, 299], ["tensorflow.clip_by_value", "tensorflow.clip_by_value"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.preprocessor.build_from_path": [[10, 43], ["concurrent.futures.ProcessPoolExecutor", "future.result", "open", "tqdm", "os.path.join", "line.strip().split", "os.path.join", "futures.append", "future.result", "concurrent.futures.ProcessPoolExecutor.submit", "line.strip", "functools.partial"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["def", "build_from_path", "(", "hparams", ",", "input_dirs", ",", "mel_dir", ",", "linear_dir", ",", "wav_dir", ",", "n_jobs", "=", "12", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "\"\"\"\n    Preprocesses the speech dataset from a gven input path to given output directories\n\n    Args:\n        - hparams: hyper parameters\n        - input_dir: input directory that contains the files to prerocess\n        - mel_dir: output directory of the preprocessed speech mel-spectrogram dataset\n        - linear_dir: output directory of the preprocessed speech linear-spectrogram dataset\n        - wav_dir: output directory of the preprocessed speech audio dataset\n        - n_jobs: Optional, number of worker process to parallelize across\n        - tqdm: Optional, provides a nice progress bar\n\n    Returns:\n        - A list of tuple describing the train examples. this should be written to train.txt\n    \"\"\"", "\n", "\n", "# We use ProcessPoolExecutor to parallelize across processes, this is just for", "\n", "# optimization purposes and it can be omited", "\n", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "n_jobs", ")", "\n", "futures", "=", "[", "]", "\n", "index", "=", "1", "\n", "for", "input_dir", "in", "input_dirs", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "input_dir", ",", "'metadata.csv'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "spkid", ",", "uttid", "=", "parts", "[", "0", ":", "2", "]", "\n", "wav_path", "=", "os", ".", "path", ".", "join", "(", "input_dir", ",", "'wavs'", ",", "'{}/{}.wav'", ".", "format", "(", "spkid", ",", "uttid", ")", ")", "\n", "text", "=", "parts", "[", "3", "]", "\n", "futures", ".", "append", "(", "executor", ".", "submit", "(", "partial", "(", "_process_utterance", ",", "mel_dir", ",", "linear_dir", ",", "wav_dir", ",", "spkid", ",", "uttid", ",", "wav_path", ",", "text", ",", "hparams", ")", ")", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "", "return", "[", "future", ".", "result", "(", ")", "for", "future", "in", "tqdm", "(", "futures", ")", "if", "future", ".", "result", "(", ")", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.preprocessor._process_utterance": [[45, 171], ["datasets.audio.preemphasis", "wavenet_vocoder.util.is_mulaw_quantize", "datasets.audio.melspectrogram().astype", "datasets.audio.linearspectrogram().astype", "len", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "numpy.save", "numpy.save", "numpy.save", "datasets.audio.load_wav", "datasets.audio.trim_silence", "wavenet_vocoder.util.mulaw_quantize", "datasets.audio.start_and_end_indices", "wavenet_vocoder.util.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "datasets.audio.pad_lr", "numpy.pad", "datasets.audio.librosa_pad_lr", "numpy.pad", "len", "os.path.join", "wavenet_vocoder.util.mulaw.astype", "os.path.join", "os.path.join", "print", "RuntimeError", "RuntimeError", "wavenet_vocoder.util.mulaw", "wavenet_vocoder.util.mulaw", "datasets.audio.melspectrogram", "datasets.audio.linearspectrogram", "datasets.audio.get_hop_size", "datasets.audio.get_hop_size", "datasets.audio.get_hop_size", "len", "datasets.audio.get_hop_size", "numpy.abs().max", "numpy.abs().max", "datasets.audio.get_hop_size", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.start_and_end_indices", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.pad_lr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.librosa_pad_lr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.linearspectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], ["", "def", "_process_utterance", "(", "mel_dir", ",", "linear_dir", ",", "wav_dir", ",", "spkid", ",", "uttid", ",", "wav_path", ",", "text", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"\n    Preprocesses a single utterance wav/text pair\n\n    this writes the mel scale spectogram to disk and return a tuple to write\n    to the train.txt file\n\n    Args:\n        - mel_dir: the directory to write the mel spectograms into\n        - linear_dir: the directory to write the linear spectrograms into\n        - wav_dir: the directory to write the preprocessed wav into\n        - index: the numeric index to use in the spectogram filename\n        - wav_path: path to the audio file containing the speech input\n        - text: text spoken in the input audio file\n        - hparams: hyper parameters\n\n    Returns:\n        - A tuple: (audio_filename, mel_filename, linear_filename, time_steps, mel_frames, linear_frames, text)\n    \"\"\"", "\n", "try", ":", "\n", "# Load the audio as numpy array", "\n", "        ", "wav", "=", "audio", ".", "load_wav", "(", "wav_path", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "", "except", "FileNotFoundError", ":", "#catch missing wav exception", "\n", "        ", "print", "(", "'file {} present in csv metadata is not present in wav folder. skipping!'", ".", "format", "(", "\n", "wav_path", ")", ")", "\n", "return", "None", "\n", "\n", "#Trim lead/trail silences", "\n", "", "if", "hparams", ".", "trim_silence", ":", "\n", "        ", "wav", "=", "audio", ".", "trim_silence", "(", "wav", ",", "hparams", ")", "\n", "\n", "#Pre-emphasize", "\n", "", "preem_wav", "=", "audio", ".", "preemphasis", "(", "wav", ",", "hparams", ".", "preemphasis", ",", "hparams", ".", "preemphasize", ")", "\n", "\n", "#rescale wav", "\n", "if", "hparams", ".", "rescale", ":", "\n", "        ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "preem_wav", "=", "preem_wav", "/", "np", ".", "abs", "(", "preem_wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "#Assert all audio is in [-1, 1]", "\n", "if", "(", "wav", ">", "1.", ")", ".", "any", "(", ")", "or", "(", "wav", "<", "-", "1.", ")", ".", "any", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'wav has invalid value: {}'", ".", "format", "(", "wav_path", ")", ")", "\n", "", "if", "(", "preem_wav", ">", "1.", ")", ".", "any", "(", ")", "or", "(", "preem_wav", "<", "-", "1.", ")", ".", "any", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'wav has invalid value: {}'", ".", "format", "(", "wav_path", ")", ")", "\n", "\n", "#Mu-law quantize", "\n", "", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "#[0, quantize_channels)", "\n", "        ", "out", "=", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "#Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "preem_wav", "=", "preem_wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "\n", "constant_values", "=", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "#[-1, 1]", "\n", "        ", "out", "=", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "mulaw", "(", "0.", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "", "else", ":", "\n", "#[-1, 1]", "\n", "        ", "out", "=", "wav", "\n", "constant_values", "=", "0.", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute the mel scale spectrogram from the wav", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "preem_wav", ",", "hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mel_frames", "=", "mel_spectrogram", ".", "shape", "[", "1", "]", "\n", "\n", "if", "mel_frames", ">", "hparams", ".", "max_mel_frames", "and", "hparams", ".", "clip_mels_length", ":", "\n", "        ", "return", "None", "\n", "\n", "#Compute the linear scale spectrogram from the wav", "\n", "", "linear_spectrogram", "=", "audio", ".", "linearspectrogram", "(", "preem_wav", ",", "hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "linear_frames", "=", "linear_spectrogram", ".", "shape", "[", "1", "]", "\n", "\n", "#sanity check", "\n", "assert", "linear_frames", "==", "mel_frames", "\n", "\n", "if", "hparams", ".", "use_lws", ":", "\n", "#Ensure time resolution adjustement between audio and mel-spectrogram", "\n", "        ", "fft_size", "=", "hparams", ".", "n_fft", "if", "hparams", ".", "win_size", "is", "None", "else", "hparams", ".", "win_size", "\n", "l", ",", "r", "=", "audio", ".", "pad_lr", "(", "wav", ",", "fft_size", ",", "audio", ".", "get_hop_size", "(", "hparams", ")", ")", "\n", "\n", "#Zero pad audio signal", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l", ",", "r", ")", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "constant_values", ")", "\n", "", "else", ":", "\n", "#Ensure time resolution adjustement between audio and mel-spectrogram", "\n", "        ", "l_pad", ",", "r_pad", "=", "audio", ".", "librosa_pad_lr", "(", "wav", ",", "hparams", ".", "n_fft", ",", "audio", ".", "get_hop_size", "(", "hparams", ")", ",", "hparams", ".", "wavenet_pad_sides", ")", "\n", "\n", "#Reflect pad audio signal on the right (Just like it's done in Librosa to avoid frame inconsistency)", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l_pad", ",", "r_pad", ")", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "constant_values", ")", "\n", "\n", "", "assert", "len", "(", "out", ")", ">=", "mel_frames", "*", "audio", ".", "get_hop_size", "(", "hparams", ")", "\n", "\n", "#time resolution adjustement", "\n", "#ensure length of raw audio is multiple of hop size so that we can use", "\n", "#transposed convolution to upsample", "\n", "out", "=", "out", "[", ":", "mel_frames", "*", "audio", ".", "get_hop_size", "(", "hparams", ")", "]", "\n", "assert", "len", "(", "out", ")", "%", "audio", ".", "get_hop_size", "(", "hparams", ")", "==", "0", "\n", "time_steps", "=", "len", "(", "out", ")", "\n", "\n", "# Write the spectrogram and audio to disk", "\n", "sub_wav_dir", "=", "os", ".", "path", ".", "join", "(", "wav_dir", ",", "spkid", ")", "\n", "sub_mel_dir", "=", "os", ".", "path", ".", "join", "(", "mel_dir", ",", "spkid", ")", "\n", "sub_linear_dir", "=", "os", ".", "path", ".", "join", "(", "linear_dir", ",", "spkid", ")", "\n", "\n", "os", ".", "makedirs", "(", "sub_wav_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "sub_mel_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "sub_linear_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "audio_filename", "=", "'audio-{}.npy'", ".", "format", "(", "uttid", ")", "\n", "mel_filename", "=", "'mel-{}.npy'", ".", "format", "(", "uttid", ")", "\n", "linear_filename", "=", "'linear-{}.npy'", ".", "format", "(", "uttid", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "sub_wav_dir", ",", "audio_filename", ")", ",", "out", ".", "astype", "(", "out_dtype", ")", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "sub_mel_dir", ",", "mel_filename", ")", ",", "mel_spectrogram", ".", "T", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "sub_linear_dir", ",", "linear_filename", ")", ",", "linear_spectrogram", ".", "T", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Return a tuple describing this training example", "\n", "return", "(", "spkid", ",", "audio_filename", ",", "mel_filename", ",", "linear_filename", ",", "time_steps", ",", "mel_frames", ",", "text", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.__init__": [[17, 117], ["super().__init__", "os.path.join", "os.path.join", "numpy.arange", "sklearn.model_selection.train_test_split", "feeder.Feeder._round_down", "numpy.concatenate", "list", "list", "x.strip", "os.path.dirname", "os.path.dirname", "open", "synthesizer.infolog.log", "len", "len", "len", "tensorflow.device", "tensorflow.FIFOQueue", "tensorflow.FIFOQueue.enqueue", "tensorflow.FIFOQueue.dequeue", "feeder.Feeder.inputs.set_shape", "feeder.Feeder.input_lengths.set_shape", "feeder.Feeder.mel_targets.set_shape", "feeder.Feeder.token_targets.set_shape", "feeder.Feeder.targets_lengths.set_shape", "feeder.Feeder.split_infos.set_shape", "feeder.Feeder.speaker_embeddings.set_shape", "tensorflow.FIFOQueue", "tensorflow.FIFOQueue.enqueue", "tensorflow.FIFOQueue.dequeue", "feeder.Feeder.eval_inputs.set_shape", "feeder.Feeder.eval_input_lengths.set_shape", "feeder.Feeder.eval_mel_targets.set_shape", "feeder.Feeder.eval_token_targets.set_shape", "feeder.Feeder.eval_targets_lengths.set_shape", "feeder.Feeder.eval_split_infos.set_shape", "feeder.Feeder.eval_speaker_embeddings.set_shape", "hparams.cleaners.split", "line.strip().split", "numpy.array", "numpy.array", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "sum", "len", "line.strip", "int"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._round_down", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["\n", "def", "__init__", "(", "self", ",", "coordinator", ",", "metadata_filename", ",", "hparams", ")", ":", "\n", "\t\t", "super", "(", "Feeder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_coord", "=", "coordinator", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "_cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "self", ".", "_train_offset", "=", "0", "\n", "self", ".", "_test_offset", "=", "0", "\n", "self", ".", "decrease_func", "=", "lambda", "x", ":", "(", "x", "-", "1", ")", "//", "2", "+", "1", "# x : ceil((x+1)/2)", "\n", "\n", "# Load metadata", "\n", "self", ".", "_mel_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"mels\"", ")", "\n", "self", ".", "_embed_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"embeds\"", ")", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t", "self", ".", "_metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n", "frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "self", ".", "_metadata", "]", ")", "*", "frame_shift_ms", "/", "(", "3600", ")", "\n", "log", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "self", ".", "_metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Train test split", "\n", "", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "is", "not", "None", "\n", "\n", "", "test_size", "=", "(", "hparams", ".", "tacotron_test_size", "if", "hparams", ".", "tacotron_test_size", "is", "not", "None", "\n", "else", "hparams", ".", "tacotron_test_batches", "*", "hparams", ".", "tacotron_batch_size", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_metadata", ")", ")", "\n", "train_indices", ",", "test_indices", "=", "train_test_split", "(", "indices", ",", "\n", "test_size", "=", "test_size", ",", "random_state", "=", "hparams", ".", "tacotron_data_random_state", ")", "\n", "\n", "#Make sure test_indices is a multiple of batch_size else round up", "\n", "len_test_indices", "=", "self", ".", "_round_down", "(", "len", "(", "test_indices", ")", ",", "hparams", ".", "tacotron_batch_size", ")", "\n", "extra_test", "=", "test_indices", "[", "len_test_indices", ":", "]", "\n", "test_indices", "=", "test_indices", "[", ":", "len_test_indices", "]", "\n", "train_indices", "=", "np", ".", "concatenate", "(", "[", "train_indices", ",", "extra_test", "]", ")", "\n", "\n", "self", ".", "_train_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "train_indices", "]", ")", "\n", "self", ".", "_test_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "test_indices", "]", ")", "\n", "\n", "self", ".", "test_steps", "=", "len", "(", "self", ".", "_test_meta", ")", "//", "hparams", ".", "tacotron_batch_size", "\n", "\n", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "==", "self", ".", "test_steps", "\n", "\n", "#pad input sequences with the <pad_token> 0 ( _ )", "\n", "", "self", ".", "_pad", "=", "0", "\n", "#explicitely setting the padding to a value that doesn\"t originally exist in the spectogram", "\n", "#to avoid any possible conflicts, without affecting the output range of the model too much", "\n", "if", "hparams", ".", "symmetric_mels", ":", "\n", "\t\t\t", "self", ".", "_target_pad", "=", "-", "hparams", ".", "max_abs_value", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "_target_pad", "=", "0.", "\n", "#Mark finished sequences with 1s", "\n", "", "self", ".", "_token_pad", "=", "1.", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "# Create placeholders for inputs and targets. Don\"t specify batch size because we want", "\n", "# to be able to feed different batch sizes at eval time.", "\n", "\t\t\t", "self", ".", "_placeholders", "=", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "\"inputs\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "\"input_lengths\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "hparams", ".", "num_mels", ")", ",", "\n", "name", "=", "\"mel_targets\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "\"token_targets\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "\"targets_lengths\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "hparams", ".", "tacotron_num_gpus", ",", "None", ")", ",", "\n", "name", "=", "\"split_infos\"", ")", ",", "\n", "\n", "# SV2TTS", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "hparams", ".", "speaker_embedding_size", ")", ",", "\n", "name", "=", "\"speaker_embeddings\"", ")", ",", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "None", ",", "hparams", ".", "speaker_embedding_size", "//", "2", ")", ",", "\n", "name", "=", "\"embedding_mask\"", ")", "\n", "]", "\n", "\n", "# Create queue for buffering data", "\n", "queue", "=", "tf", ".", "FIFOQueue", "(", "8", ",", "[", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "\n", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ",", "name", "=", "\"input_queue\"", ")", "\n", "self", ".", "_enqueue_op", "=", "queue", ".", "enqueue", "(", "self", ".", "_placeholders", ")", "\n", "self", ".", "inputs", ",", "self", ".", "input_lengths", ",", "self", ".", "mel_targets", ",", "self", ".", "token_targets", ",", "self", ".", "targets_lengths", ",", "self", ".", "split_infos", ",", "self", ".", "speaker_embeddings", ",", "self", ".", "embedding_masks", "=", "queue", ".", "dequeue", "(", ")", "\n", "\n", "self", ".", "inputs", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "0", "]", ".", "shape", ")", "\n", "self", ".", "input_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "1", "]", ".", "shape", ")", "\n", "self", ".", "mel_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "2", "]", ".", "shape", ")", "\n", "self", ".", "token_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "3", "]", ".", "shape", ")", "\n", "self", ".", "targets_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "4", "]", ".", "shape", ")", "\n", "self", ".", "split_infos", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "5", "]", ".", "shape", ")", "\n", "self", ".", "speaker_embeddings", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "6", "]", ".", "shape", ")", "\n", "self", ".", "embedding_masks", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "7", "]", ".", "shape", ")", "\n", "\n", "# Create eval queue for buffering eval data", "\n", "eval_queue", "=", "tf", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "\n", "tf", ".", "int32", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ",", "name", "=", "\"eval_queue\"", ")", "\n", "self", ".", "_eval_enqueue_op", "=", "eval_queue", ".", "enqueue", "(", "self", ".", "_placeholders", ")", "\n", "self", ".", "eval_inputs", ",", "self", ".", "eval_input_lengths", ",", "self", ".", "eval_mel_targets", ",", "self", ".", "eval_token_targets", ",", "self", ".", "eval_targets_lengths", ",", "self", ".", "eval_split_infos", ",", "self", ".", "eval_speaker_embeddings", ",", "self", ".", "eval_embedding_masks", "=", "eval_queue", ".", "dequeue", "(", ")", "\n", "\n", "self", ".", "eval_inputs", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "0", "]", ".", "shape", ")", "\n", "self", ".", "eval_input_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "1", "]", ".", "shape", ")", "\n", "self", ".", "eval_mel_targets", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "2", "]", ".", "shape", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.start_threads": [[119, 128], ["threading.Thread", "threading.Thread.start", "threading.Thread", "threading.Thread.start"], "methods", ["None"], ["self", ".", "eval_targets_lengths", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "4", "]", ".", "shape", ")", "\n", "self", ".", "eval_split_infos", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "5", "]", ".", "shape", ")", "\n", "self", ".", "eval_speaker_embeddings", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "6", "]", ".", "shape", ")", "\n", "self", ".", "eval_embedding_masks", ".", "set_shape", "(", "self", ".", "_placeholders", "[", "7", "]", ".", "shape", ")", "\n", "\n", "\n", "", "", "def", "start_threads", "(", "self", ",", "session", ")", ":", "\n", "\t\t", "self", ".", "_session", "=", "session", "\n", "thread", "=", "threading", ".", "Thread", "(", "name", "=", "\"background\"", ",", "target", "=", "self", ".", "_enqueue_next_train_group", ")", "\n", "thread", ".", "daemon", "=", "True", "#Thread will close when parent quits", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_test_groups": [[129, 141], ["numpy.asarray", "numpy.load", "numpy.asarray", "numpy.load", "synthesizer.utils.text.text_to_sequence", "os.path.join", "os.path.join", "len", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["thread", ".", "start", "(", ")", "\n", "\n", "thread", "=", "threading", ".", "Thread", "(", "name", "=", "\"background\"", ",", "target", "=", "self", ".", "_enqueue_next_test_group", ")", "\n", "thread", ".", "daemon", "=", "True", "#Thread will close when parent quits", "\n", "thread", ".", "start", "(", ")", "\n", "\n", "", "def", "_get_test_groups", "(", "self", ")", ":", "\n", "\t\t", "meta", "=", "self", ".", "_test_meta", "[", "self", ".", "_test_offset", "]", "\n", "self", ".", "_test_offset", "+=", "1", "\n", "\n", "text", "=", "meta", "[", "5", "]", "\n", "\n", "input_data", "=", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "self", ".", "_cleaner_names", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.make_test_batches": [[142, 159], ["time.time", "examples.sort", "numpy.random.shuffle", "synthesizer.infolog.log", "feeder.Feeder._get_test_groups", "range", "range", "len", "len", "len", "time.time"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_test_groups"], ["mel_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_mel_dir", ",", "meta", "[", "1", "]", ")", ")", "\n", "#Create parallel sequences containing zeros to represent a non finished sequence", "\n", "token_target", "=", "np", ".", "asarray", "(", "[", "0.", "]", "*", "(", "len", "(", "mel_target", ")", "-", "1", ")", ")", "\n", "embed_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_embed_dir", ",", "meta", "[", "2", "]", ")", ")", "\n", "# Tf version of return x if remainder == 0 else x + multiple - remainder", "\n", "dc_len", "=", "len", "(", "mel_target", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\t\t\t", "dc_len", "=", "self", ".", "decrease_func", "(", "dc_len", ")", "\n", "", "embed_mask", "=", "np", ".", "ones", "(", "(", "dc_len", ",", "(", "self", ".", "_hparams", ".", "num_mels", "+", "7", ")", "//", "8", ",", "self", ".", "_hparams", ".", "speaker_embedding_size", "//", "2", ")", ")", "\n", "\n", "return", "input_data", ",", "mel_target", ",", "token_target", ",", "embed_target", ",", "len", "(", "mel_target", ")", ",", "embed_mask", "\n", "\n", "", "def", "make_test_batches", "(", "self", ")", ":", "\n", "\t\t", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Read a group of examples", "\n", "n", "=", "self", ".", "_hparams", ".", "tacotron_batch_size", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._enqueue_next_train_group": [[160, 178], ["feeder.Feeder._coord.should_stop", "time.time", "examples.sort", "numpy.random.shuffle", "synthesizer.infolog.log", "feeder.Feeder._get_next_example", "dict", "feeder.Feeder._session.run", "range", "range", "len", "zip", "len", "time.time", "feeder.Feeder._prepare_batch"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_next_example", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_batch"], ["\n", "#Test on entire test set", "\n", "examples", "=", "[", "self", ".", "_get_test_groups", "(", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_test_meta", ")", ")", "]", "\n", "\n", "# Bucket examples based on similar output sequence length for efficiency", "\n", "examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "2", "]", ")", "\n", "batches", "=", "[", "examples", "[", "i", ":", "i", "+", "n", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "examples", ")", ",", "n", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "log", "(", "\"\\nGenerated %d test batches of size %d in %.3f sec\"", "%", "(", "len", "(", "batches", ")", ",", "n", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "return", "batches", ",", "r", "\n", "\n", "", "def", "_enqueue_next_train_group", "(", "self", ")", ":", "\n", "\t\t", "while", "not", "self", ".", "_coord", ".", "should_stop", "(", ")", ":", "\n", "\t\t\t", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Read a group of examples", "\n", "n", "=", "self", ".", "_hparams", ".", "tacotron_batch_size", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._enqueue_next_test_group": [[179, 186], ["feeder.Feeder.make_test_batches", "feeder.Feeder._coord.should_stop", "dict", "feeder.Feeder._session.run", "zip", "feeder.Feeder._prepare_batch"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.make_test_batches", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_batch"], ["examples", "=", "[", "self", ".", "_get_next_example", "(", ")", "for", "i", "in", "range", "(", "n", "*", "_batches_per_group", ")", "]", "\n", "\n", "# Bucket examples based on similar output sequence length for efficiency", "\n", "examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "2", "]", ")", "\n", "batches", "=", "[", "examples", "[", "i", ":", "i", "+", "n", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "examples", ")", ",", "n", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "log", "(", "\"\\nGenerated {} train batches of size {} in {:.3f} sec\"", ".", "format", "(", "len", "(", "batches", ")", ",", "n", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._get_next_example": [[187, 205], ["numpy.asarray", "numpy.load", "numpy.asarray", "numpy.load", "len", "numpy.random.shuffle", "synthesizer.utils.text.text_to_sequence", "os.path.join", "os.path.join", "len", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["for", "batch", "in", "batches", ":", "\n", "\t\t\t\t", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "_placeholders", ",", "self", ".", "_prepare_batch", "(", "batch", ",", "r", ")", ")", ")", "\n", "self", ".", "_session", ".", "run", "(", "self", ".", "_enqueue_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "", "", "def", "_enqueue_next_test_group", "(", "self", ")", ":", "\n", "#Create test batches once and evaluate on them for all test steps", "\n", "\t\t", "test_batches", ",", "r", "=", "self", ".", "make_test_batches", "(", ")", "\n", "while", "not", "self", ".", "_coord", ".", "should_stop", "(", ")", ":", "\n", "\t\t\t", "for", "batch", "in", "test_batches", ":", "\n", "\t\t\t\t", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "_placeholders", ",", "self", ".", "_prepare_batch", "(", "batch", ",", "r", ")", ")", ")", "\n", "self", ".", "_session", ".", "run", "(", "self", ".", "_eval_enqueue_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "", "", "def", "_get_next_example", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"Gets a single example (input, mel_target, token_target, linear_target, mel_length) from_ disk\n\t\t\"\"\"", "\n", "if", "self", ".", "_train_offset", ">=", "len", "(", "self", ".", "_train_meta", ")", ":", "\n", "\t\t\t", "self", ".", "_train_offset", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "_train_meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_batch": [[206, 242], ["int", "numpy.random.shuffle", "numpy.asarray", "numpy.asarray", "range", "numpy.asarray", "numpy.asarray", "feeder.Feeder._prepare_inputs", "feeder.Feeder._prepare_targets", "feeder.Feeder._prepare_token_targets", "numpy.asarray.append", "len", "len", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_token_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "meta", "=", "self", ".", "_train_meta", "[", "self", ".", "_train_offset", "]", "\n", "self", ".", "_train_offset", "+=", "1", "\n", "\n", "text", "=", "meta", "[", "5", "]", "\n", "\n", "input_data", "=", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "self", ".", "_cleaner_names", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "mel_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_mel_dir", ",", "meta", "[", "1", "]", ")", ")", "\n", "#Create parallel sequences containing zeros to represent a non finished sequence", "\n", "token_target", "=", "np", ".", "asarray", "(", "[", "0.", "]", "*", "(", "len", "(", "mel_target", ")", "-", "1", ")", ")", "\n", "embed_target", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_embed_dir", ",", "meta", "[", "2", "]", ")", ")", "\n", "r", "=", "self", ".", "_hparams", ".", "outputs_per_step", "\n", "dc_len", "=", "len", "(", "mel_target", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\t\t\t", "dc_len", "=", "self", ".", "decrease_func", "(", "dc_len", ")", "\n", "", "embed_mask", "=", "np", ".", "ones", "(", "(", "dc_len", ",", "(", "self", ".", "_hparams", ".", "num_mels", "+", "7", ")", "//", "8", ",", "self", ".", "_hparams", ".", "speaker_embedding_size", "//", "2", ")", ")", "\n", "\n", "return", "input_data", ",", "mel_target", ",", "token_target", ",", "embed_target", ",", "len", "(", "mel_target", ")", ",", "embed_mask", "\n", "\n", "", "def", "_prepare_batch", "(", "self", ",", "batches", ",", "outputs_per_step", ")", ":", "\n", "\t\t", "assert", "0", "==", "len", "(", "batches", ")", "%", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "size_per_device", "=", "int", "(", "len", "(", "batches", ")", "/", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "inputs", "=", "None", "\n", "mel_targets", "=", "None", "\n", "token_targets", "=", "None", "\n", "targets_lengths", "=", "None", "\n", "embed_masks", "=", "None", "\n", "\n", "split_infos", "=", "[", "]", "\n", "\n", "targets_lengths", "=", "np", ".", "asarray", "(", "[", "x", "[", "-", "2", "]", "for", "x", "in", "batches", "]", ",", "dtype", "=", "np", ".", "int32", ")", "#Used to mask loss", "\n", "input_lengths", "=", "np", ".", "asarray", "(", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "batches", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "\t\t\t", "batch", "=", "batches", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "input_cur_device", ",", "input_max_len", "=", "self", ".", "_prepare_inputs", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_inputs": [[243, 246], ["max", "numpy.stack", "len", "feeder.Feeder._pad_input"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_input"], ["inputs", "=", "np", ".", "concatenate", "(", "(", "inputs", ",", "input_cur_device", ")", ",", "axis", "=", "1", ")", "if", "inputs", "is", "not", "None", "else", "input_cur_device", "\n", "mel_target_cur_device", ",", "mel_target_max_len", "=", "self", ".", "_prepare_targets", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n", "mel_targets", "=", "np", ".", "concatenate", "(", "(", "mel_targets", ",", "mel_target_cur_device", ")", ",", "axis", "=", "1", ")", "if", "mel_targets", "is", "not", "None", "else", "mel_target_cur_device", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_targets": [[247, 251], ["max", "feeder.Feeder._round_up", "numpy.stack", "len", "feeder.Feeder._pad_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_target"], ["#Pad sequences with 1 to infer that the sequence is done", "\n", "token_target_cur_device", ",", "token_target_max_len", "=", "self", ".", "_prepare_token_targets", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n", "token_targets", "=", "np", ".", "concatenate", "(", "(", "token_targets", ",", "token_target_cur_device", ")", ",", "axis", "=", "1", ")", "if", "token_targets", "is", "not", "None", "else", "token_target_cur_device", "\n", "\n", "embed_mask_cur_device", ",", "embed_mask_max_len", "=", "self", ".", "_prepare_embed_mask", "(", "[", "x", "[", "5", "]", "for", "x", "in", "batch", "]", ",", "outputs_per_step", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._prepare_token_targets": [[252, 256], ["feeder.Feeder._round_up", "max", "numpy.stack", "len", "feeder.Feeder._pad_token_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._pad_token_target"], ["embed_masks", "=", "np", ".", "concatenate", "(", "(", "embed_masks", ",", "embed_mask_cur_device", ")", ",", "axis", "=", "1", ")", "if", "embed_masks", "is", "not", "None", "else", "embed_mask_cur_device", "\n", "\n", "split_infos", ".", "append", "(", "[", "input_max_len", ",", "mel_target_max_len", ",", "token_target_max_len", ",", "embed_mask_max_len", "]", ")", "\n", "\n", "", "split_infos", "=", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._pad_input": [[257, 259], ["numpy.pad"], "methods", ["None"], ["\n", "### SV2TTS ###", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._pad_target": [[260, 262], ["numpy.pad"], "methods", ["None"], ["embed_targets", "=", "np", ".", "asarray", "(", "[", "x", "[", "3", "]", "for", "x", "in", "batches", "]", ")", "\n", "\n", "##############", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._pad_token_target": [[263, 265], ["numpy.pad"], "methods", ["None"], ["\n", "return", "inputs", ",", "input_lengths", ",", "mel_targets", ",", "token_targets", ",", "targets_lengths", ",", "split_infos", ",", "embed_targets", ",", "embed_masks", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._round_up": [[266, 269], ["None"], "methods", ["None"], ["\n", "", "def", "_prepare_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "inputs", "]", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_input", "(", "x", ",", "max_len", ")", "for", "x", "in", "inputs", "]", ")", ",", "max_len", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder._round_down": [[270, 273], ["None"], "methods", ["None"], ["\n", "", "def", "_prepare_targets", "(", "self", ",", "targets", ",", "alignment", ")", ":", "\n", "\t\t", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "targets", "]", ")", "\n", "data_len", "=", "self", ".", "_round_up", "(", "max_len", ",", "alignment", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.infolog.init": [[13, 23], ["infolog._close_logfile", "open", "open", "open.write", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._close_logfile"], ["def", "init", "(", "filename", ",", "run_name", ",", "slack_url", "=", "None", ")", ":", "\n", "\t", "global", "_file", ",", "_run_name", ",", "_slack_url", "\n", "_close_logfile", "(", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", ".", "write", "(", "\"\\n-----------------------------------------------------------------\\n\"", ")", "\n", "_file", ".", "write", "(", "\"Starting new {} training run\\n\"", ".", "format", "(", "run_name", ")", ")", "\n", "_file", ".", "write", "(", "\"-----------------------------------------------------------------\\n\"", ")", "\n", "_run_name", "=", "run_name", "\n", "_slack_url", "=", "slack_url", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.infolog.log": [[25, 31], ["print", "_file.write", "threading.Thread().start", "threading.Thread", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "log", "(", "msg", ",", "end", "=", "\"\\n\"", ",", "slack", "=", "False", ")", ":", "\n", "\t", "print", "(", "msg", ",", "end", "=", "end", ")", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "write", "(", "\"[%s]  %s\\n\"", "%", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "_format", ")", "[", ":", "-", "3", "]", ",", "msg", ")", ")", "\n", "", "if", "slack", "and", "_slack_url", "is", "not", "None", ":", "\n", "\t\t", "Thread", "(", "target", "=", "_send_slack", ",", "args", "=", "(", "msg", ",", ")", ")", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.infolog._close_logfile": [[33, 38], ["_file.close"], "function", ["None"], ["", "", "def", "_close_logfile", "(", ")", ":", "\n", "\t", "global", "_file", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "close", "(", ")", "\n", "_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.infolog._send_slack": [[40, 47], ["urllib.request.Request", "urllib.request.Request.add_header", "urllib.request.urlopen", "json.dumps().encode", "json.dumps"], "function", ["None"], ["", "", "def", "_send_slack", "(", "msg", ")", ":", "\n", "\t", "req", "=", "Request", "(", "_slack_url", ")", "\n", "req", ".", "add_header", "(", "\"Content-Type\"", ",", "\"application/json\"", ")", "\n", "urlopen", "(", "req", ",", "json", ".", "dumps", "(", "{", "\n", "\"username\"", ":", "\"tacotron\"", ",", "\n", "\"icon_emoji\"", ":", "\":taco:\"", ",", "\n", "\"text\"", ":", "\"*%s*: %s\"", "%", "(", "_run_name", ",", "msg", ")", "\n", "}", ")", ".", "encode", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.synthesize.run_eval": [[10, 38], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "synthesizer.infolog.log", "synthesizer.tacotron2.Tacotron2", "synthesizer.infolog.log", "synthesizer.infolog.log", "os.path.join", "os.path.join", "synthesizer.hparams.hparams_debug_string", "open", "enumerate", "range", "os.path.join", "tqdm.tqdm", "time.time", "synthesizer.tacotron2.Tacotron2.synthesize", "zip", "len", "file.write", "range", "len", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.synthesize"], ["def", "run_eval", "(", "args", ",", "checkpoint_path", ",", "output_dir", ",", "hparams", ",", "sentences", ")", ":", "\n", "    ", "eval_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval\"", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"logs-eval\"", ")", "\n", "\n", "#Create output path if it doesn\"t exist", "\n", "os", ".", "makedirs", "(", "eval_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "log", "(", "hparams_debug_string", "(", ")", ")", "\n", "synth", "=", "Tacotron2", "(", "checkpoint_path", ",", "hparams", ")", "\n", "\n", "#Set inputs batch wise", "\n", "sentences", "=", "[", "sentences", "[", "i", ":", "i", "+", "hparams", ".", "tacotron_synthesis_batch_size", "]", "for", "i", "\n", "in", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "hparams", ".", "tacotron_synthesis_batch_size", ")", "]", "\n", "\n", "log", "(", "\"Starting Synthesis\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_dir", ",", "\"map.txt\"", ")", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "for", "i", ",", "texts", "in", "enumerate", "(", "tqdm", "(", "sentences", ")", ")", ":", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "basenames", "=", "[", "\"batch_{}_sentence_{}\"", ".", "format", "(", "i", ",", "j", ")", "for", "j", "in", "range", "(", "len", "(", "texts", ")", ")", "]", "\n", "mel_filenames", ",", "speaker_ids", "=", "synth", ".", "synthesize", "(", "texts", ",", "basenames", ",", "eval_dir", ",", "log_dir", ",", "None", ")", "\n", "\n", "for", "elems", "in", "zip", "(", "texts", ",", "mel_filenames", ",", "speaker_ids", ")", ":", "\n", "                ", "file", ".", "write", "(", "\"|\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "log", "(", "\"synthesized mel spectrograms at {}\"", ".", "format", "(", "eval_dir", ")", ")", "\n", "return", "eval_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.synthesize.run_synthesis": [[39, 82], ["os.path.join", "os.makedirs", "os.path.join", "print", "os.path.join", "synthesizer.tacotron2.Tacotron2", "print", "os.path.join", "os.path.join", "os.path.join", "print", "synthesizer.hparams.hparams_debug_string", "tensorflow.train.get_checkpoint_state", "open", "print", "open", "enumerate", "line.strip().split", "range", "tqdm.tqdm", "synthesizer.tacotron2.Tacotron2.synthesize", "sum", "len", "len", "os.path.join", "os.path.join", "os.path.basename().replace().replace", "file.write", "line.strip", "int", "os.path.basename().replace", "os.path.basename", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.synthesize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "run_synthesis", "(", "in_dir", ",", "out_dir", ",", "model_dir", ",", "hparams", ")", ":", "\n", "    ", "synth_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"mels_gta\"", ")", "\n", "os", ".", "makedirs", "(", "synth_dir", ",", "exist_ok", "=", "True", ")", "\n", "metadata_filename", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"train.txt\"", ")", "\n", "print", "(", "hparams_debug_string", "(", ")", ")", "\n", "\n", "# Load the model in memory", "\n", "weights_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"taco_pretrained\"", ")", "\n", "checkpoint_fpath", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "weights_dir", ")", ".", "model_checkpoint_path", "\n", "synth", "=", "Tacotron2", "(", "checkpoint_fpath", ",", "hparams", ",", "gta", "=", "True", ")", "\n", "\n", "# Load the metadata", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n", "frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "metadata", "]", ")", "*", "frame_shift_ms", "/", "3600", "\n", "print", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Set inputs batch wise", "\n", "", "metadata", "=", "[", "metadata", "[", "i", ":", "i", "+", "hparams", ".", "tacotron_synthesis_batch_size", "]", "for", "i", "in", "\n", "range", "(", "0", ",", "len", "(", "metadata", ")", ",", "hparams", ".", "tacotron_synthesis_batch_size", ")", "]", "\n", "# TODO: come on big boy, fix this", "\n", "# Quick and dirty fix to make sure that all batches have the same size ", "\n", "metadata", "=", "metadata", "[", ":", "-", "1", "]", "\n", "\n", "print", "(", "\"Starting Synthesis\"", ")", "\n", "mel_dir", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"mels\"", ")", "\n", "embed_dir", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"embeds\"", ")", "\n", "meta_out_fpath", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"synthesized.txt\"", ")", "\n", "with", "open", "(", "meta_out_fpath", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "for", "i", ",", "meta", "in", "enumerate", "(", "tqdm", "(", "metadata", ")", ")", ":", "\n", "            ", "texts", "=", "[", "m", "[", "5", "]", "for", "m", "in", "meta", "]", "\n", "mel_filenames", "=", "[", "os", ".", "path", ".", "join", "(", "mel_dir", ",", "m", "[", "1", "]", ")", "for", "m", "in", "meta", "]", "\n", "embed_filenames", "=", "[", "os", ".", "path", ".", "join", "(", "embed_dir", ",", "m", "[", "2", "]", ")", "for", "m", "in", "meta", "]", "\n", "basenames", "=", "[", "os", ".", "path", ".", "basename", "(", "m", ")", ".", "replace", "(", "\".npy\"", ",", "\"\"", ")", ".", "replace", "(", "\"mel-\"", ",", "\"\"", ")", "\n", "for", "m", "in", "mel_filenames", "]", "\n", "synth", ".", "synthesize", "(", "texts", ",", "basenames", ",", "synth_dir", ",", "None", ",", "mel_filenames", ",", "embed_filenames", ")", "\n", "\n", "for", "elems", "in", "meta", ":", "\n", "                ", "file", ".", "write", "(", "\"|\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "print", "(", "\"Synthesized mel spectrograms at {}\"", ".", "format", "(", "synth_dir", ")", ")", "\n", "return", "meta_out_fpath", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.__init__": [[18, 43], ["tensorflow.train.get_checkpoint_state", "Exception", "checkpoints_dir.parent.name.replace", "int", "print", "inference.Synthesizer.checkpoint_fpath.rfind"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Loading model weights at %s\"", "%", "weights_fpath", ")", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "weights_fpath", ")", "\n", "_model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state'", "]", ")", "\n", "_model", ".", "eval", "(", ")", "\n", "\n", "\n", "", "def", "is_loaded", "(", ")", ":", "\n", "    ", "return", "_model", "is", "not", "None", "\n", "\n", "\n", "", "def", "infer_waveform", "(", "mel", ",", "normalize", "=", "True", ",", "batched", "=", "True", ",", "target", "=", "8000", ",", "overlap", "=", "800", ",", "\n", "progress_callback", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.is_loaded": [[44, 49], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load": [[50, 59], ["tensorflow.reset_default_graph", "synthesizer.tacotron2.Tacotron2", "Exception"], "methods", ["None"], ["\n", "if", "_model", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"Please load Wave-RNN in memory before using it\"", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "mel", "=", "mel", "/", "hp", ".", "mel_max_abs_value", "\n", "", "mel", "=", "torch", ".", "from_numpy", "(", "mel", "[", "None", ",", "...", "]", ")", "\n", "wav", "=", "_model", ".", "generate", "(", "mel", ",", "batched", ",", "target", ",", "overlap", ",", "hp", ".", "mu_law", ",", "progress_callback", ")", "\n", "return", "wav", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.synthesize_spectrograms": [[60, 87], ["inference.Synthesizer._model.my_synthesize", "inference.Synthesizer.is_loaded", "inference.Synthesizer.load", "multiprocess.pool.Pool().starmap", "multiprocess.pool.Pool"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.my_synthesize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.is_loaded", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer._one_shot_synthesize_spectrograms": [[88, 104], ["tensorflow.reset_default_graph", "synthesizer.tacotron2.Tacotron2", "synthesizer.tacotron2.Tacotron2.my_synthesize", "synthesizer.tacotron2.Tacotron2.session.close", "numba.cuda.select_device", "numba.cuda.close", "alignments.copy", "spec.copy"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.my_synthesize"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load_preprocess_wav": [[105, 115], ["librosa.load", "numpy.abs().max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.make_spectrogram": [[116, 129], ["synthesizer.audio.melspectrogram().astype", "isinstance", "isinstance", "inference.Synthesizer.load_preprocess_wav", "synthesizer.audio.melspectrogram"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load_preprocess_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.griffin_lim": [[130, 137], ["synthesizer.audio.inv_mel_spectrogram"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav": [[9, 11], ["librosa.core.load", "librosa.core.load"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["    ", "return", "2", "*", "x", "/", "(", "2", "**", "bits", "-", "1.", ")", "-", "1.", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav": [[12, 16], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "function", ["None"], ["", "def", "float_2_label", "(", "x", ",", "bits", ")", ":", "\n", "    ", "assert", "abs", "(", "x", ")", ".", "max", "(", ")", "<=", "1.0", "\n", "x", "=", "(", "x", "+", "1.", ")", "*", "(", "2", "**", "bits", "-", "1", ")", "/", "2", "\n", "return", "x", ".", "clip", "(", "0", ",", "2", "**", "bits", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wavenet_wav": [[17, 19], ["librosa.output.write_wav", "librosa.output.write_wav"], "function", ["None"], ["\n", "", "def", "load_wav", "(", "path", ")", ":", "\n", "    ", "return", "librosa", ".", "load", "(", "path", ",", "sr", "=", "hp", ".", "sample_rate", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis": [[20, 24], ["scipy.signal.lfilter"], "function", ["None"], ["\n", "\n", "", "def", "save_wav", "(", "x", ",", "path", ")", ":", "\n", "    ", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "x", ".", "astype", "(", "np", ".", "float32", ")", ",", "sr", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis": [[25, 29], ["scipy.signal.lfilter"], "function", ["None"], ["\n", "", "def", "split_signal", "(", "x", ")", ":", "\n", "    ", "unsigned", "=", "x", "+", "2", "**", "15", "\n", "coarse", "=", "unsigned", "//", "256", "\n", "fine", "=", "unsigned", "%", "256", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.start_and_end_indices": [[31, 43], ["range", "range", "abs", "abs", "abs", "abs"], "function", ["None"], ["\n", "\n", "", "def", "combine_signal", "(", "coarse", ",", "fine", ")", ":", "\n", "    ", "return", "coarse", "*", "256", "+", "fine", "-", "2", "**", "15", "\n", "\n", "\n", "", "def", "encode_16bits", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "x", "*", "2", "**", "15", ",", "-", "2", "**", "15", ",", "2", "**", "15", "-", "1", ")", ".", "astype", "(", "np", ".", "int16", ")", "\n", "\n", "\n", "", "mel_basis", "=", "None", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size": [[44, 50], ["int"], "function", ["None"], ["def", "linear_to_mel", "(", "spectrogram", ")", ":", "\n", "    ", "global", "mel_basis", "\n", "if", "mel_basis", "is", "None", ":", "\n", "        ", "mel_basis", "=", "build_mel_basis", "(", ")", "\n", "", "return", "np", ".", "dot", "(", "mel_basis", ",", "spectrogram", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.linearspectrogram": [[51, 58], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize"], ["", "def", "build_mel_basis", "(", ")", ":", "\n", "    ", "return", "librosa", ".", "filters", ".", "mel", "(", "hp", ".", "sample_rate", ",", "hp", ".", "n_fft", ",", "n_mels", "=", "hp", ".", "num_mels", ",", "fmin", "=", "hp", ".", "fmin", ")", "\n", "\n", "\n", "", "def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "-", "hp", ".", "min_level_db", ")", "/", "-", "hp", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram": [[59, 66], ["audio._stft", "audio.preemphasis", "audio._amp_to_db", "audio._normalize", "audio._linear_to_mel", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._linear_to_mel"], ["", "def", "denormalize", "(", "S", ")", ":", "\n", "    ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "hp", ".", "min_level_db", ")", "+", "hp", ".", "min_level_db", "\n", "\n", "\n", "", "def", "amp_to_db", "(", "x", ")", ":", "\n", "    ", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "x", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_linear_spectrogram": [[67, 83], ["audio._db_to_amp", "audio._denormalize", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_db_to_amp.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["", "def", "db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n", "\n", "", "def", "spectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "np", ".", "abs", "(", "D", ")", ")", "-", "hp", ".", "ref_level_db", "\n", "return", "normalize", "(", "S", ")", "\n", "\n", "\n", "", "def", "melspectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "stft", "(", "y", ")", "\n", "S", "=", "amp_to_db", "(", "linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "\n", "return", "normalize", "(", "S", ")", "\n", "\n", "\n", "", "def", "stft", "(", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram": [[84, 100], ["audio._mel_to_linear", "audio._denormalize", "audio._db_to_amp", "audio._lws_processor", "_lws_processor.run_lws", "_lws_processor.istft().astype", "audio.inv_preemphasis", "audio.inv_preemphasis", "audio._griffin_lim", "_lws_processor.istft", "_mel_to_linear.astype"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._mel_to_linear", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim"], ["    ", "return", "librosa", ".", "stft", "(", "y", "=", "y", ",", "n_fft", "=", "hp", ".", "n_fft", ",", "hop_length", "=", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ")", "\n", "\n", "\n", "", "def", "pre_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "[", "1", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "de_emphasis", "(", "x", ")", ":", "\n", "    ", "return", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "x", ")", "\n", "\n", "\n", "", "def", "encode_mu_law", "(", "x", ",", "mu", ")", ":", "\n", "    ", "mu", "=", "mu", "-", "1", "\n", "fx", "=", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "x", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "return", "np", ".", "floor", "(", "(", "fx", "+", "1", ")", "/", "2", "*", "mu", "+", "0.5", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor": [[101, 104], ["lws.lws", "audio.get_hop_size", "numpy.np.float32", "numpy.np.float32"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], ["", "def", "decode_mu_law", "(", "y", ",", "mu", ",", "from_labels", "=", "True", ")", ":", "\n", "    ", "if", "from_labels", ":", "\n", "        ", "y", "=", "label_2_float", "(", "y", ",", "math", ".", "log2", "(", "mu", ")", ")", "\n", "", "mu", "=", "mu", "-", "1", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._griffin_lim": [[105, 116], ["numpy.exp", "numpy.abs().astype", "audio._istft", "range", "numpy.exp", "audio._istft", "numpy.random.rand", "numpy.abs", "numpy.angle", "audio._stft"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft"], ["x", "=", "np", ".", "sign", "(", "y", ")", "/", "mu", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "y", ")", "-", "1", ")", "\n", "return", "x", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._stft": [[117, 122], ["librosa.stft", "librosa.stft", "_lws_processor().stft", "audio.get_hop_size", "audio._lws_processor"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.audio.stft", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._lws_processor"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._istft": [[123, 125], ["librosa.istft", "librosa.istft", "audio.get_hop_size"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.get_hop_size"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.num_frames": [[128, 137], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.pad_lr": [[139, 147], ["audio.num_frames", "len", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.num_frames"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.librosa_pad_lr": [[149, 151], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._linear_to_mel": [[156, 161], ["numpy.dot", "audio._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._mel_to_linear": [[162, 167], ["numpy.maximum", "numpy.linalg.pinv", "numpy.dot", "audio._build_mel_basis", "numpy.np.float64"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._build_mel_basis": [[168, 172], ["librosa.filters.mel", "librosa.filters.mel"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._amp_to_db": [[173, 176], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._db_to_amp": [[177, 179], ["numpy.power", "numpy.np.float64"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._normalize": [[180, 193], ["numpy.clip", "numpy.clip", "S.max", "S.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio._denormalize": [[194, 207], ["numpy.clip", "numpy.clip"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_embedding_stats": [[19, 33], ["tensorflow.contrib.tensorboard.plugins.projector.ProjectorConfig", "zip", "tensorflow.contrib.tensorboard.plugins.projector.visualize_embeddings", "tf.contrib.tensorboard.plugins.projector.ProjectorConfig.embeddings.add"], "function", ["None"], ["\n", "# Instantiate the model", "\n", "print", "(", "\"Initializing the model...\"", ")", "\n", "model", "=", "WaveRNN", "(", "\n", "rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n", "res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_train_stats": [[35, 61], ["tensorflow.variable_scope", "range", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "range", "tensorflow.summary.scalar", "tensorflow.norm", "tensorflow.reduce_max", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "function", ["None"], [")", ".", "cuda", "(", ")", "\n", "\n", "# Initialize the optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "for", "p", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "p", "[", "\"lr\"", "]", "=", "hp", ".", "voc_lr", "\n", "", "loss_func", "=", "F", ".", "cross_entropy", "if", "model", ".", "mode", "==", "\"RAW\"", "else", "discretized_mix_logistic_loss", "\n", "\n", "# Load the weights", "\n", "model_dir", "=", "models_dir", ".", "joinpath", "(", "run_id", ")", "\n", "model_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "weights_fpath", "=", "model_dir", ".", "joinpath", "(", "run_id", "+", "\".pt\"", ")", "\n", "if", "force_restart", "or", "not", "weights_fpath", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "\"\\nStarting the training of WaveRNN from scratch\\n\"", ")", "\n", "model", ".", "save", "(", "weights_fpath", ",", "optimizer", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"\\nLoading weights at %s\"", "%", "weights_fpath", ")", "\n", "model", ".", "load", "(", "weights_fpath", ",", "optimizer", ")", "\n", "print", "(", "\"WaveRNN weights loaded from step %d\"", "%", "model", ".", "step", ")", "\n", "\n", "# Initialize the dataset", "\n", "", "metadata_fpath", "=", "syn_dir", ".", "joinpath", "(", "\"train.txt\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"synthesized.txt\"", ")", "\n", "mel_dir", "=", "syn_dir", ".", "joinpath", "(", "\"mels\"", ")", "if", "ground_truth", "else", "voc_dir", ".", "joinpath", "(", "\"mels_gta\"", ")", "\n", "wav_dir", "=", "syn_dir", ".", "joinpath", "(", "\"audio\"", ")", "\n", "dataset", "=", "VocoderDataset", "(", "metadata_fpath", ",", "mel_dir", ",", "wav_dir", ")", "\n", "test_loader", "=", "DataLoader", "(", "dataset", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_eval_stats": [[63, 79], ["tensorflow.Summary", "summary_writer.add_summary", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "values.append", "tensorflow.Summary.Value"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "# Begin the training", "\n", "simple_table", "(", "[", "(", "'Batch size'", ",", "hp", ".", "voc_batch_size", ")", ",", "\n", "(", "'LR'", ",", "hp", ".", "voc_lr", ")", ",", "\n", "(", "'Sequence Len'", ",", "hp", ".", "voc_seq_len", ")", "]", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "350", ")", ":", "\n", "        ", "data_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "collate_fn", "=", "collate_vocoder", ",", "\n", "batch_size", "=", "hp", ".", "voc_batch_size", ",", "\n", "num_workers", "=", "2", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "running_loss", "=", "0.", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.time_string": [[81, 83], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["for", "i", ",", "(", "x", ",", "y", ",", "m", ")", "in", "enumerate", "(", "data_loader", ",", "1", ")", ":", "\n", "            ", "x", ",", "m", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "m", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_train_mode": [[85, 96], ["tensorflow.variable_scope", "synthesizer.models.create_model", "synthesizer.models.create_model.initialize", "synthesizer.models.create_model.add_loss", "synthesizer.models.create_model.add_optimizer", "train.add_train_stats"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_loss", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_optimizer", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_train_stats"], ["y_hat", "=", "model", "(", "x", ",", "m", ")", "\n", "if", "model", ".", "mode", "==", "'RAW'", ":", "\n", "                ", "y_hat", "=", "y_hat", ".", "transpose", "(", "1", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "elif", "model", ".", "mode", "==", "'MOL'", ":", "\n", "                ", "y", "=", "y", ".", "float", "(", ")", "\n", "", "y", "=", "y", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Backward pass", "\n", "loss", "=", "loss_func", "(", "y_hat", ",", "y", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_test_mode": [[98, 108], ["tensorflow.variable_scope", "synthesizer.models.create_model", "synthesizer.models.create_model.initialize", "synthesizer.models.create_model.add_loss"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.tacotron.Tacotron.add_loss"], ["running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "speed", "=", "i", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "avg_loss", "=", "running_loss", "/", "i", "\n", "\n", "step", "=", "model", ".", "get_step", "(", ")", "\n", "k", "=", "step", "//", "1000", "\n", "\n", "if", "backup_every", "!=", "0", "and", "step", "%", "backup_every", "==", "0", ":", "\n", "                ", "model", ".", "checkpoint", "(", "model_dir", ",", "optimizer", ")", "\n", "\n", "", "if", "save_every", "!=", "0", "and", "step", "%", "save_every", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.train": [[110, 389], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.path.join", "os.path.join", "log", "log", "log", "log", "tensorflow.set_random_seed", "tensorflow.train.Coordinator", "tensorflow.Variable", "train.model_train_mode", "train.model_test_mode", "os.path.join", "char_embedding_meta.replace.replace", "synthesizer.utils.ValueWindow", "synthesizer.utils.ValueWindow", "tensorflow.train.Saver", "log", "tensorflow.ConfigProto", "synthesizer.hparams.hparams_debug_string", "tensorflow.variable_scope", "synthesizer.feeder.Feeder", "os.path.isfile", "tensorflow.Session", "open", "tensorflow.summary.FileWriter", "sess.run", "synthesizer.feeder.Feeder.start_threads", "log", "f.write", "tensorflow.global_variables_initializer", "log", "tf.train.Saver.save", "time.time", "sess.run", "synthesizer.utils.ValueWindow.append", "synthesizer.utils.ValueWindow.append", "log", "log", "traceback.print_exc", "tf.train.Coordinator.request_stop", "tensorflow.train.get_checkpoint_state", "tf.train.Coordinator.should_stop", "numpy.isnan", "log", "Exception", "log", "tf.summary.FileWriter.add_summary", "log", "log", "synthesizer.audio.inv_mel_spectrogram", "synthesizer.audio.save_wav", "synthesizer.utils.plot.plot_alignment", "synthesizer.utils.plot.plot_spectrogram", "log", "log", "train.add_eval_stats", "tf.train.Saver.save", "log", "sess.run", "numpy.save", "synthesizer.audio.inv_mel_spectrogram", "synthesizer.audio.save_wav", "synthesizer.utils.plot.plot_alignment", "synthesizer.utils.plot.plot_spectrogram", "log", "tensorflow.train.get_checkpoint_state", "log", "train.add_embedding_stats", "log", "log", "tf.train.Saver.restore", "log", "tf.train.Saver.save", "log", "time.time", "sess.run", "tqdm.tqdm", "synthesizer.audio.inv_linear_spectrogram", "synthesizer.audio.save_wav", "tqdm.tqdm", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "os.path.join", "os.path.join", "os.path.join", "synthesizer.utils.plot.plot_spectrogram", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "range", "sess.run", "eval_losses.append", "before_losses.append", "after_losses.append", "stop_token_losses.append", "linear_losses.append", "sum", "len", "os.path.join", "range", "sess.run", "eval_losses.append", "before_losses.append", "after_losses.append", "stop_token_losses.append", "os.path.join", "synthesizer.utils.text.sequence_to_text", "train.time_string", "train.time_string", "train.time_string", "train.time_string", "train.time_string"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_train_mode", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.model_test_mode", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.feeder.Feeder.start_threads", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_eval_stats", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.add_embedding_stats", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_linear_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.sequence_to_text", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string"], ["\n", "", "msg", "=", "f\"| Epoch: {epoch} ({i}/{len(data_loader)}) | \"", "f\"Loss: {avg_loss:.4f} | {speed:.1f} \"", "f\"steps/s | Step: {k}k | \"", "\n", "stream", "(", "msg", ")", "\n", "\n", "\n", "", "gen_testset", "(", "model", ",", "test_loader", ",", "hp", ".", "voc_gen_at_checkpoint", ",", "hp", ".", "voc_gen_batched", ",", "\n", "hp", ".", "voc_target", ",", "hp", ".", "voc_overlap", ",", "model_dir", ")", "\n", "print", "(", "\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.tacotron_train": [[391, 393], ["train.train"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.train.train"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.preprocess_librispeech": [[13, 52], ["datasets_root.joinpath", "print", "all", "out_dir.joinpath().mkdir", "out_dir.joinpath().mkdir", "out_dir.joinpath", "out_dir.joinpath.open", "list", "functools.partial", "multiprocessing.pool.Pool().imap", "tqdm.tqdm", "metadata_fpath.open.close", "sum", "sum", "print", "print", "print", "print", "datasets_root.joinpath.joinpath", "datasets_root.joinpath.joinpath", "itertools.chain.from_iterable", "len", "out_dir.joinpath.open", "map", "input_dir.exists", "out_dir.joinpath", "out_dir.joinpath", "multiprocessing.pool.Pool", "metadata_fpath.open.write", "line.split", "int", "int", "max", "max", "max", "input_dir.glob", "len", "len", "int", "int", "str"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["def", "preprocess_librispeech", "(", "datasets_root", ":", "Path", ",", "out_dir", ":", "Path", ",", "n_processes", ":", "int", ",", "\n", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "# Gather the input directories", "\n", "    ", "dataset_root", "=", "datasets_root", ".", "joinpath", "(", "\"LibriSpeech\"", ")", "\n", "input_dirs", "=", "[", "dataset_root", ".", "joinpath", "(", "\"train-clean-100\"", ")", ",", "\n", "dataset_root", ".", "joinpath", "(", "\"train-clean-360\"", ")", "]", "\n", "print", "(", "\"\\n    \"", ".", "join", "(", "map", "(", "str", ",", "[", "\"Using data from:\"", "]", "+", "input_dirs", ")", ")", ")", "\n", "assert", "all", "(", "input_dir", ".", "exists", "(", ")", "for", "input_dir", "in", "input_dirs", ")", "\n", "\n", "# Create the output directories for each output file type", "\n", "out_dir", ".", "joinpath", "(", "\"mels\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "out_dir", ".", "joinpath", "(", "\"audio\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "# Create a metadata file", "\n", "metadata_fpath", "=", "out_dir", ".", "joinpath", "(", "\"train.txt\"", ")", "\n", "metadata_file", "=", "metadata_fpath", ".", "open", "(", "\"a\"", "if", "skip_existing", "else", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "# Preprocess the dataset", "\n", "speaker_dirs", "=", "list", "(", "chain", ".", "from_iterable", "(", "input_dir", ".", "glob", "(", "\"*\"", ")", "for", "input_dir", "in", "input_dirs", ")", ")", "\n", "func", "=", "partial", "(", "preprocess_speaker", ",", "out_dir", "=", "out_dir", ",", "skip_existing", "=", "skip_existing", ",", "\n", "hparams", "=", "hparams", ")", "\n", "job", "=", "Pool", "(", "n_processes", ")", ".", "imap", "(", "func", ",", "speaker_dirs", ")", "\n", "for", "speaker_metadata", "in", "tqdm", "(", "job", ",", "\"LibriSpeech\"", ",", "len", "(", "speaker_dirs", ")", ",", "unit", "=", "\"speakers\"", ")", ":", "\n", "        ", "for", "metadatum", "in", "speaker_metadata", ":", "\n", "            ", "metadata_file", ".", "write", "(", "\"|\"", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "metadatum", ")", "+", "\"\\n\"", ")", "\n", "", "", "metadata_file", ".", "close", "(", ")", "\n", "\n", "# Verify the contents of the metadata file", "\n", "with", "metadata_fpath", ".", "open", "(", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "metadata_file", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "metadata_file", "]", "\n", "", "mel_frames", "=", "sum", "(", "[", "int", "(", "m", "[", "4", "]", ")", "for", "m", "in", "metadata", "]", ")", "\n", "timesteps", "=", "sum", "(", "[", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "metadata", "]", ")", "\n", "sample_rate", "=", "hparams", ".", "sample_rate", "\n", "hours", "=", "(", "timesteps", "/", "sample_rate", ")", "/", "3600", "\n", "print", "(", "\"The dataset consists of %d utterances, %d mel frames, %d audio timesteps (%.2f hours).\"", "%", "\n", "(", "len", "(", "metadata", ")", ",", "mel_frames", ",", "timesteps", ",", "hours", ")", ")", "\n", "print", "(", "\"Max input length (text chars): %d\"", "%", "max", "(", "len", "(", "m", "[", "5", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "print", "(", "\"Max mel frames length: %d\"", "%", "max", "(", "int", "(", "m", "[", "4", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "print", "(", "\"Max audio timesteps length: %d\"", "%", "max", "(", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.preprocess_speaker": [[54, 86], ["speaker_dir.glob", "next", "book_dir.joinpath", "words.replace().split.replace().split", "list", "preprocess.split_on_silences", "enumerate", "book_dir.glob", "next.open", "print", "book_dir.joinpath.exists", "map", "zip", "metadata.append", "line.rstrip().split", "words.replace().split.replace", "list.replace().split", "preprocess.process_utterance", "line.rstrip", "list.replace"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.split_on_silences", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.process_utterance", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace"], ["", "def", "preprocess_speaker", "(", "speaker_dir", ",", "out_dir", ":", "Path", ",", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "    ", "metadata", "=", "[", "]", "\n", "for", "book_dir", "in", "speaker_dir", ".", "glob", "(", "\"*\"", ")", ":", "\n", "# Gather the utterance audios and texts", "\n", "        ", "try", ":", "\n", "            ", "alignments_fpath", "=", "next", "(", "book_dir", ".", "glob", "(", "\"*.alignment.txt\"", ")", ")", "\n", "with", "alignments_fpath", ".", "open", "(", "\"r\"", ")", "as", "alignments_file", ":", "\n", "                ", "alignments", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "line", "in", "alignments_file", "]", "\n", "", "", "except", "StopIteration", ":", "\n", "# A few alignment files will be missing", "\n", "            ", "continue", "\n", "\n", "# Iterate over each entry in the alignments file", "\n", "", "for", "wav_fname", ",", "words", ",", "end_times", "in", "alignments", ":", "\n", "            ", "wav_fpath", "=", "book_dir", ".", "joinpath", "(", "wav_fname", "+", "\".flac\"", ")", "\n", "assert", "wav_fpath", ".", "exists", "(", ")", "\n", "words", "=", "words", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "end_times", "=", "list", "(", "map", "(", "float", ",", "end_times", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", ")", ")", "\n", "\n", "# Process each sub-utterance", "\n", "wavs", ",", "texts", "=", "split_on_silences", "(", "wav_fpath", ",", "words", ",", "end_times", ",", "hparams", ")", "\n", "for", "i", ",", "(", "wav", ",", "text", ")", "in", "enumerate", "(", "zip", "(", "wavs", ",", "texts", ")", ")", ":", "\n", "                ", "sub_basename", "=", "\"%s_%02d\"", "%", "(", "wav_fname", ",", "i", ")", "\n", "metadata", ".", "append", "(", "process_utterance", "(", "wav", ",", "text", ",", "out_dir", ",", "sub_basename", ",", "\n", "skip_existing", ",", "hparams", ")", ")", "\n", "\n", "", "", "", "return", "[", "m", "for", "m", "in", "metadata", "if", "m", "is", "not", "None", "]", "\n", "\n", "\n", "", "def", "split_on_silences", "(", "wav_fpath", ",", "words", ",", "end_times", ",", "hparams", ")", ":", "\n", "# Load the audio waveform", "\n", "    ", "wav", ",", "_", "=", "librosa", ".", "load", "(", "wav_fpath", ",", "hparams", ".", "sample_rate", ")", "\n", "if", "hparams", ".", "rescale", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.split_on_silences": [[88, 158], ["librosa.load", "numpy.array", "numpy.array", "numpy.array", "numpy.concatenate", "list", "len", "len", "len", "numpy.where", "len", "utils.logmmse.profile_noise", "utils.logmmse.denoise", "zip", "len", "len", "numpy.abs().max", "numpy.array", "float", "float", "min", "numpy.array", "numpy.abs", "len"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.profile_noise", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.logmmse.denoise"], ["\n", "", "words", "=", "np", ".", "array", "(", "words", ")", "\n", "start_times", "=", "np", ".", "array", "(", "[", "0.0", "]", "+", "end_times", "[", ":", "-", "1", "]", ")", "\n", "end_times", "=", "np", ".", "array", "(", "end_times", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "end_times", ")", "==", "len", "(", "start_times", ")", "\n", "assert", "words", "[", "0", "]", "==", "\"\"", "and", "words", "[", "-", "1", "]", "==", "\"\"", "\n", "\n", "# Find pauses that are too long", "\n", "mask", "=", "(", "words", "==", "\"\"", ")", "&", "(", "end_times", "-", "start_times", ">=", "hparams", ".", "silence_min_duration_split", ")", "\n", "mask", "[", "0", "]", "=", "mask", "[", "-", "1", "]", "=", "True", "\n", "breaks", "=", "np", ".", "where", "(", "mask", ")", "[", "0", "]", "\n", "\n", "# Profile the noise from the silences and perform noise reduction on the waveform", "\n", "silence_times", "=", "[", "[", "start_times", "[", "i", "]", ",", "end_times", "[", "i", "]", "]", "for", "i", "in", "breaks", "]", "\n", "silence_times", "=", "(", "np", ".", "array", "(", "silence_times", ")", "*", "hparams", ".", "sample_rate", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "noisy_wav", "=", "np", ".", "concatenate", "(", "[", "wav", "[", "stime", "[", "0", "]", ":", "stime", "[", "1", "]", "]", "for", "stime", "in", "silence_times", "]", ")", "\n", "if", "len", "(", "noisy_wav", ")", ">", "hparams", ".", "sample_rate", "*", "0.02", ":", "\n", "        ", "profile", "=", "logmmse", ".", "profile_noise", "(", "noisy_wav", ",", "hparams", ".", "sample_rate", ")", "\n", "wav", "=", "logmmse", ".", "denoise", "(", "wav", ",", "profile", ",", "eta", "=", "0", ")", "\n", "\n", "# Re-attach segments that are too short", "\n", "", "segments", "=", "list", "(", "zip", "(", "breaks", "[", ":", "-", "1", "]", ",", "breaks", "[", "1", ":", "]", ")", ")", "\n", "segment_durations", "=", "[", "start_times", "[", "end", "]", "-", "end_times", "[", "start", "]", "for", "start", ",", "end", "in", "segments", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "segments", ")", "and", "len", "(", "segments", ")", ">", "1", ":", "\n", "        ", "if", "segment_durations", "[", "i", "]", "<", "hparams", ".", "utterance_min_duration", ":", "\n", "# See if the segment can be re-attached with the right or the left segment", "\n", "            ", "left_duration", "=", "float", "(", "\"inf\"", ")", "if", "i", "==", "0", "else", "segment_durations", "[", "i", "-", "1", "]", "\n", "right_duration", "=", "float", "(", "\"inf\"", ")", "if", "i", "==", "len", "(", "segments", ")", "-", "1", "else", "segment_durations", "[", "i", "+", "1", "]", "\n", "joined_duration", "=", "segment_durations", "[", "i", "]", "+", "min", "(", "left_duration", ",", "right_duration", ")", "\n", "\n", "# Do not re-attach if it causes the joined utterance to be too long", "\n", "if", "joined_duration", ">", "hparams", ".", "hop_size", "*", "hparams", ".", "max_mel_frames", "/", "hparams", ".", "sample_rate", ":", "\n", "                ", "i", "+=", "1", "\n", "continue", "\n", "\n", "# Re-attach the segment with the neighbour of shortest duration", "\n", "", "j", "=", "i", "-", "1", "if", "left_duration", "<=", "right_duration", "else", "i", "\n", "segments", "[", "j", "]", "=", "(", "segments", "[", "j", "]", "[", "0", "]", ",", "segments", "[", "j", "+", "1", "]", "[", "1", "]", ")", "\n", "segment_durations", "[", "j", "]", "=", "joined_duration", "\n", "del", "segments", "[", "j", "+", "1", "]", ",", "segment_durations", "[", "j", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "\n", "# Split the utterance", "\n", "", "", "segment_times", "=", "[", "[", "end_times", "[", "start", "]", ",", "start_times", "[", "end", "]", "]", "for", "start", ",", "end", "in", "segments", "]", "\n", "segment_times", "=", "(", "np", ".", "array", "(", "segment_times", ")", "*", "hparams", ".", "sample_rate", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "wavs", "=", "[", "wav", "[", "segment_time", "[", "0", "]", ":", "segment_time", "[", "1", "]", "]", "for", "segment_time", "in", "segment_times", "]", "\n", "texts", "=", "[", "\" \"", ".", "join", "(", "words", "[", "start", "+", "1", ":", "end", "]", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "for", "start", ",", "end", "in", "segments", "]", "\n", "\n", "# # DEBUG: play the audio segments (run with -n=1)", "\n", "# import sounddevice as sd", "\n", "# if len(wavs) > 1:", "\n", "#     print(\"This sentence was split in %d segments:\" % len(wavs))", "\n", "# else:", "\n", "#     print(\"There are no silences long enough for this sentence to be split:\")", "\n", "# for wav, text in zip(wavs, texts):", "\n", "#     # Pad the waveform with 1 second of silence because sounddevice tends to cut them early", "\n", "#     # when playing them. You shouldn't need to do that in your parsers.", "\n", "#     wav = np.concatenate((wav, [0] * 16000))", "\n", "#     print(\"\\t%s\" % text)", "\n", "#     sd.play(wav, 16000, blocking=True)", "\n", "# print(\"\")", "\n", "\n", "return", "wavs", ",", "texts", "\n", "\n", "\n", "", "def", "process_utterance", "(", "wav", ":", "np", ".", "ndarray", ",", "text", ":", "str", ",", "out_dir", ":", "Path", ",", "basename", ":", "str", ",", "\n", "skip_existing", ":", "bool", ",", "hparams", ")", ":", "\n", "## FOR REFERENCE:", "\n", "# For you not to lose your head if you ever wish to change things here or implement your own", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.process_utterance": [[160, 202], ["out_dir.joinpath", "out_dir.joinpath", "numpy.save", "numpy.save", "out_dir.joinpath.exists", "out_dir.joinpath.exists", "len", "synthesizer.audio.melspectrogram().astype", "len", "synthesizer.audio.melspectrogram"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], ["# - Both the audios and the mel spectrograms are saved as numpy arrays", "\n", "# - There is no processing done to the audios that will be saved to disk beyond volume  ", "\n", "#   normalization (in split_on_silences)", "\n", "# - However, pre-emphasis is applied to the audios before computing the mel spectrogram. This", "\n", "#   is why we re-apply it on the audio on the side of the vocoder.", "\n", "# - Librosa pads the waveform before computing the mel spectrogram. Here, the waveform is saved", "\n", "#   without extra padding. This means that you won't have an exact relation between the length", "\n", "#   of the wav and of the mel spectrogram. See the vocoder data loader.", "\n", "\n", "\n", "# Skip existing utterances if needed", "\n", "    ", "mel_fpath", "=", "out_dir", ".", "joinpath", "(", "\"mels\"", ",", "\"mel-%s.npy\"", "%", "basename", ")", "\n", "wav_fpath", "=", "out_dir", ".", "joinpath", "(", "\"audio\"", ",", "\"audio-%s.npy\"", "%", "basename", ")", "\n", "if", "skip_existing", "and", "mel_fpath", ".", "exists", "(", ")", "and", "wav_fpath", ".", "exists", "(", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "# Skip utterances that are too short", "\n", "", "if", "len", "(", "wav", ")", "<", "hparams", ".", "utterance_min_duration", "*", "hparams", ".", "sample_rate", ":", "\n", "        ", "return", "None", "\n", "\n", "# Compute the mel spectrogram", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ",", "hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mel_frames", "=", "mel_spectrogram", ".", "shape", "[", "1", "]", "\n", "\n", "# Skip utterances that are too long", "\n", "if", "mel_frames", ">", "hparams", ".", "max_mel_frames", "and", "hparams", ".", "clip_mels_length", ":", "\n", "        ", "return", "None", "\n", "\n", "# Write the spectrogram, embed and audio to disk", "\n", "", "np", ".", "save", "(", "mel_fpath", ",", "mel_spectrogram", ".", "T", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "wav_fpath", ",", "wav", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Return a tuple describing this training example", "\n", "return", "wav_fpath", ".", "name", ",", "mel_fpath", ".", "name", ",", "\"embed-%s.npy\"", "%", "basename", ",", "len", "(", "wav", ")", ",", "mel_frames", ",", "text", "\n", "\n", "\n", "", "def", "embed_utterance", "(", "fpaths", ",", "encoder_model_fpath", ")", ":", "\n", "    ", "if", "not", "encoder", ".", "is_loaded", "(", ")", ":", "\n", "        ", "encoder", ".", "load_model", "(", "encoder_model_fpath", ")", "\n", "\n", "# Compute the speaker embedding of the utterance", "\n", "", "wav_fpath", ",", "embed_fpath", "=", "fpaths", "\n", "wav", "=", "np", ".", "load", "(", "wav_fpath", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.embed_utterance": [[204, 214], ["numpy.load", "encoder.inference.preprocess_wav", "encoder.inference.embed_utterance", "numpy.save", "encoder.inference.is_loaded", "encoder.inference.load_model"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.embed_utterance", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.is_loaded", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.vocoder.inference.load_model"], ["embed", "=", "encoder", ".", "embed_utterance", "(", "wav", ")", "\n", "np", ".", "save", "(", "embed_fpath", ",", "embed", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "\n", "", "def", "create_embeddings", "(", "synthesizer_root", ":", "Path", ",", "encoder_model_fpath", ":", "Path", ",", "n_processes", ":", "int", ")", ":", "\n", "    ", "wav_dir", "=", "synthesizer_root", ".", "joinpath", "(", "\"audio\"", ")", "\n", "metadata_fpath", "=", "synthesizer_root", ".", "joinpath", "(", "\"train.txt\"", ")", "\n", "assert", "wav_dir", ".", "exists", "(", ")", "and", "metadata_fpath", ".", "exists", "(", ")", "\n", "embed_dir", "=", "synthesizer_root", ".", "joinpath", "(", "\"embeds\"", ")", "\n", "embed_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.preprocess.create_embeddings": [[216, 233], ["synthesizer_root.joinpath", "synthesizer_root.joinpath", "synthesizer_root.joinpath", "synthesizer_root.joinpath.mkdir", "functools.partial", "multiprocessing.pool.Pool().imap", "list", "synthesizer_root.joinpath.exists", "synthesizer_root.joinpath.exists", "synthesizer_root.joinpath.open", "tqdm.tqdm", "line.split", "multiprocessing.pool.Pool", "len", "synthesizer_root.joinpath.joinpath", "synthesizer_root.joinpath.joinpath"], "function", ["None"], ["with", "metadata_fpath", ".", "open", "(", "\"r\"", ")", "as", "metadata_file", ":", "\n", "        ", "metadata", "=", "[", "line", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "metadata_file", "]", "\n", "fpaths", "=", "[", "(", "wav_dir", ".", "joinpath", "(", "m", "[", "0", "]", ")", ",", "embed_dir", ".", "joinpath", "(", "m", "[", "2", "]", ")", ")", "for", "m", "in", "metadata", "]", "\n", "\n", "# TODO: improve on the multiprocessing, it's terrible. Disk I/O is the bottleneck here.", "\n", "# Embed the utterances in separate threads", "\n", "", "func", "=", "partial", "(", "embed_utterance", ",", "encoder_model_fpath", "=", "encoder_model_fpath", ")", "\n", "job", "=", "Pool", "(", "n_processes", ")", ".", "imap", "(", "func", ",", "fpaths", ")", "\n", "list", "(", "tqdm", "(", "job", ",", "\"Embedding\"", ",", "len", "(", "fpaths", ")", ",", "unit", "=", "\"utterances\"", ")", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.__init__": [[12, 64], ["synthesizer.infolog.log", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "synthesizer.infolog.log", "tensorflow.ConfigProto", "tensorflow.Session", "tacotron2.Tacotron2.session.run", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "tensorflow.variable_scope", "synthesizer.models.create_model", "tensorflow.global_variables_initializer", "tacotron2.Tacotron2.model.initialize", "tacotron2.Tacotron2.model.initialize"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.helpers.TacoTrainingHelper.initialize"], ["    ", "def", "__init__", "(", "self", ",", "checkpoint_path", ",", "hparams", ",", "resnet_scope", ",", "resnet_hp", ",", "gta", "=", "False", ",", "model_name", "=", "\"Tacotron\"", ")", ":", "\n", "        ", "log", "(", "\"Constructing model: %s\"", "%", "model_name", ")", "\n", "#Force the batch size to be known in order to use attention masking in batch synthesis", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", "None", ")", ",", "name", "=", "\"inputs\"", ")", "\n", "input_lengths", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ",", "name", "=", "\"input_lengths\"", ")", "\n", "speaker_embeddings", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "hparams", ".", "speaker_embedding_size", ")", ",", "\n", "name", "=", "\"speaker_embeddings\"", ")", "\n", "targets", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "None", ",", "hparams", ".", "num_mels", ")", ",", "name", "=", "\"mel_targets\"", ")", "\n", "split_infos", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "hparams", ".", "tacotron_num_gpus", ",", "None", ")", ",", "name", "=", "\"split_infos\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"Tacotron_model\"", ")", "as", "scope", ":", "\n", "            ", "self", ".", "model", "=", "create_model", "(", "model_name", ",", "hparams", ",", "resnet_scope", ",", "resnet_hp", ")", "\n", "if", "gta", ":", "\n", "                ", "self", ".", "model", ".", "initialize", "(", "inputs", ",", "input_lengths", ",", "speaker_embeddings", ",", "targets", ",", "gta", "=", "gta", ",", "\n", "split_infos", "=", "split_infos", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "model", ".", "initialize", "(", "inputs", ",", "input_lengths", ",", "speaker_embeddings", ",", "\n", "split_infos", "=", "split_infos", ")", "\n", "\n", "", "self", ".", "mel_outputs", "=", "self", ".", "model", ".", "tower_mel_outputs", "\n", "self", ".", "linear_outputs", "=", "self", ".", "model", ".", "tower_linear_outputs", "if", "(", "hparams", ".", "predict_linear", "and", "not", "gta", ")", "else", "None", "\n", "self", ".", "alignments", "=", "self", ".", "model", ".", "tower_alignments", "\n", "self", ".", "stop_token_prediction", "=", "self", ".", "model", ".", "tower_stop_token_prediction", "\n", "self", ".", "targets", "=", "targets", "\n", "\n", "", "self", ".", "gta", "=", "gta", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "#pad input sequences with the <pad_token> 0 ( _ )", "\n", "self", ".", "_pad", "=", "0", "\n", "#explicitely setting the padding to a value that doesn\"t originally exist in the spectogram", "\n", "#to avoid any possible conflicts, without affecting the output range of the model too much", "\n", "if", "hparams", ".", "symmetric_mels", ":", "\n", "            ", "self", ".", "_target_pad", "=", "-", "hparams", ".", "max_abs_value", "\n", "", "else", ":", "\n", "            ", "self", ".", "_target_pad", "=", "0.", "\n", "\n", "", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "input_lengths", "=", "input_lengths", "\n", "self", ".", "speaker_embeddings", "=", "speaker_embeddings", "\n", "self", ".", "targets", "=", "targets", "\n", "self", ".", "split_infos", "=", "split_infos", "\n", "\n", "log", "(", "\"Loading checkpoint: %s\"", "%", "checkpoint_path", ")", "\n", "#Memory allocation on the GPUs as needed", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "config", ".", "allow_soft_placement", "=", "True", "\n", "\n", "self", ".", "session", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "session", ",", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.my_synthesize": [[65, 99], ["tacotron2.Tacotron2._prepare_inputs", "tacotron2.Tacotron2.session.run", "range", "x.strip", "numpy.asarray", "len", "numpy.asarray", "numpy.asarray", "list", "len", "tacotron2.Tacotron2._hparams.cleaners.split", "synthesizer.utils.text.text_to_sequence", "list().index", "list", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence"], ["## resnet for speaker embeding extraction", "\n", "self", ".", "resnet_scope", "=", "resnet_scope", "\n", "self", ".", "resnet", "=", "ResNet", "(", "resnet_hp", ",", "'eval'", ")", "\n", "\n", "", "def", "my_synthesize", "(", "self", ",", "speaker_embeds", ",", "texts", ")", ":", "\n", "        ", "\"\"\"\n        Lighter synthesis function that directly returns the mel spectrograms.\n        \"\"\"", "\n", "\n", "# Prepare the input", "\n", "cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "_hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "seqs", "=", "[", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ")", "for", "text", "in", "texts", "]", "\n", "input_lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "seqs", "]", "\n", "input_seqs", ",", "max_seq_len", "=", "self", ".", "_prepare_inputs", "(", "seqs", ")", "\n", "split_infos", "=", "[", "[", "max_seq_len", ",", "0", ",", "0", ",", "0", "]", "]", "\n", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "input_seqs", ",", "\n", "self", ".", "input_lengths", ":", "np", ".", "asarray", "(", "input_lengths", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "self", ".", "split_infos", ":", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "self", ".", "speaker_embeddings", ":", "speaker_embeds", "\n", "}", "\n", "\n", "# Forward it", "\n", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "mels", ",", "alignments", ",", "stop_tokens", "=", "list", "(", "mels", "[", "0", "]", ")", ",", "alignments", "[", "0", "]", ",", "stop_tokens", "[", "0", "]", "\n", "\n", "# Trim the output", "\n", "for", "i", "in", "range", "(", "len", "(", "mels", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "target_length", "=", "list", "(", "np", ".", "round", "(", "stop_tokens", "[", "i", "]", ")", ")", ".", "index", "(", "1", ")", "\n", "mels", "[", "i", "]", "=", "mels", "[", "i", "]", "[", ":", "target_length", ",", ":", "]", "\n", "", "except", "ValueError", ":", "\n", "# If no token is generated, we simply do not trim the output", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2.synthesize": [[100, 215], ["range", "numpy.asarray", "enumerate", "x.strip", "numpy.asarray", "len", "len", "tacotron2.Tacotron2._prepare_inputs", "split_infos.append", "numpy.asarray", "range", "numpy.load", "tacotron2.Tacotron2.session.run", "tacotron2.Tacotron2.session.run", "NotImplemented", "os.path.join", "numpy.save", "saved_mels_paths.append", "hparams.cleaners.split", "len", "synthesizer.utils.text.text_to_sequence", "numpy.concatenate", "numpy.load", "len", "tacotron2.Tacotron2._prepare_targets", "len", "len", "tacotron2.Tacotron2._get_output_lengths", "len", "len", "len", "len", "len", "synthesizer.audio.inv_mel_spectrogram", "synthesizer.audio.save_wav", "synthesizer.utils.plot.plot_alignment", "synthesizer.utils.plot.plot_spectrogram", "numpy.concatenate", "zip", "zip", "zip", "os.path.join", "os.path.join", "os.path.join", "synthesizer.audio.inv_linear_spectrogram", "synthesizer.audio.save_wav", "synthesizer.utils.plot.plot_spectrogram", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.models.fatchord_version.WaveRNN.save", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.text.text_to_sequence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_targets", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._get_output_lengths", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_mel_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_alignment", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.inv_linear_spectrogram", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.save_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.utils.plot.plot_spectrogram"], ["                ", "continue", "\n", "\n", "", "", "return", "[", "mel", ".", "T", "for", "mel", "in", "mels", "]", ",", "alignments", "\n", "\n", "", "def", "synthesize", "(", "self", ",", "texts", ",", "basenames", ",", "out_dir", ",", "log_dir", ",", "mel_filenames", ",", "embed_filenames", ")", ":", "\n", "        ", "hparams", "=", "self", ".", "_hparams", "\n", "cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "assert", "0", "==", "len", "(", "texts", ")", "%", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "seqs", "=", "[", "np", ".", "asarray", "(", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ")", "for", "text", "in", "texts", "]", "\n", "input_lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "seqs", "]", "\n", "\n", "size_per_device", "=", "len", "(", "seqs", ")", "//", "self", ".", "_hparams", ".", "tacotron_num_gpus", "\n", "\n", "#Pad inputs according to each GPU max length", "\n", "input_seqs", "=", "None", "\n", "split_infos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "            ", "device_input", "=", "seqs", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "device_input", ",", "max_seq_len", "=", "self", ".", "_prepare_inputs", "(", "device_input", ")", "\n", "input_seqs", "=", "np", ".", "concatenate", "(", "(", "input_seqs", ",", "device_input", ")", ",", "axis", "=", "1", ")", "if", "input_seqs", "is", "not", "None", "else", "device_input", "\n", "split_infos", ".", "append", "(", "[", "max_seq_len", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "input_seqs", ",", "\n", "self", ".", "input_lengths", ":", "np", ".", "asarray", "(", "input_lengths", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "}", "\n", "\n", "if", "self", ".", "gta", ":", "\n", "            ", "np_targets", "=", "[", "np", ".", "load", "(", "mel_filename", ")", "for", "mel_filename", "in", "mel_filenames", "]", "\n", "target_lengths", "=", "[", "len", "(", "np_target", ")", "for", "np_target", "in", "np_targets", "]", "\n", "\n", "#pad targets according to each GPU max length", "\n", "target_seqs", "=", "None", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "tacotron_num_gpus", ")", ":", "\n", "                ", "device_target", "=", "np_targets", "[", "size_per_device", "*", "i", ":", "size_per_device", "*", "(", "i", "+", "1", ")", "]", "\n", "device_target", ",", "max_target_len", "=", "self", ".", "_prepare_targets", "(", "device_target", ",", "self", ".", "_hparams", ".", "outputs_per_step", ")", "\n", "target_seqs", "=", "np", ".", "concatenate", "(", "(", "target_seqs", ",", "device_target", ")", ",", "axis", "=", "1", ")", "if", "target_seqs", "is", "not", "None", "else", "device_target", "\n", "split_infos", "[", "i", "]", "[", "1", "]", "=", "max_target_len", "#Not really used but setting it in case for future development maybe?", "\n", "\n", "", "feed_dict", "[", "self", ".", "targets", "]", "=", "target_seqs", "\n", "assert", "len", "(", "np_targets", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "feed_dict", "[", "self", ".", "split_infos", "]", "=", "np", ".", "asarray", "(", "split_infos", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "feed_dict", "[", "self", ".", "speaker_embeddings", "]", "=", "[", "np", ".", "load", "(", "f", ")", "for", "f", "in", "embed_filenames", "]", "\n", "\n", "if", "self", ".", "gta", "or", "not", "hparams", ".", "predict_linear", ":", "\n", "            ", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "#Linearize outputs (1D arrays)", "\n", "mels", "=", "[", "mel", "for", "gpu_mels", "in", "mels", "for", "mel", "in", "gpu_mels", "]", "\n", "alignments", "=", "[", "align", "for", "gpu_aligns", "in", "alignments", "for", "align", "in", "gpu_aligns", "]", "\n", "stop_tokens", "=", "[", "token", "for", "gpu_token", "in", "stop_tokens", "for", "token", "in", "gpu_token", "]", "\n", "\n", "if", "not", "self", ".", "gta", ":", "\n", "#Natural batch synthesis", "\n", "#Get Mel lengths for the entire batch from stop_tokens predictions", "\n", "                ", "target_lengths", "=", "self", ".", "_get_output_lengths", "(", "stop_tokens", ")", "\n", "\n", "#Take off the batch wise padding", "\n", "", "mels", "=", "[", "mel", "[", ":", "target_length", ",", ":", "]", "for", "mel", ",", "target_length", "in", "zip", "(", "mels", ",", "target_lengths", ")", "]", "\n", "assert", "len", "(", "mels", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "else", ":", "\n", "            ", "linears", ",", "mels", ",", "alignments", ",", "stop_tokens", "=", "self", ".", "session", ".", "run", "(", "\n", "[", "self", ".", "linear_outputs", ",", "self", ".", "mel_outputs", ",", "self", ".", "alignments", ",", "\n", "self", ".", "stop_token_prediction", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "#Linearize outputs (1D arrays)", "\n", "linears", "=", "[", "linear", "for", "gpu_linear", "in", "linears", "for", "linear", "in", "gpu_linear", "]", "\n", "mels", "=", "[", "mel", "for", "gpu_mels", "in", "mels", "for", "mel", "in", "gpu_mels", "]", "\n", "alignments", "=", "[", "align", "for", "gpu_aligns", "in", "alignments", "for", "align", "in", "gpu_aligns", "]", "\n", "stop_tokens", "=", "[", "token", "for", "gpu_token", "in", "stop_tokens", "for", "token", "in", "gpu_token", "]", "\n", "\n", "#Natural batch synthesis", "\n", "#Get Mel/Linear lengths for the entire batch from stop_tokens predictions", "\n", "# target_lengths = self._get_output_lengths(stop_tokens)", "\n", "target_lengths", "=", "[", "9999", "]", "\n", "\n", "#Take off the batch wise padding", "\n", "mels", "=", "[", "mel", "[", ":", "target_length", ",", ":", "]", "for", "mel", ",", "target_length", "in", "zip", "(", "mels", ",", "target_lengths", ")", "]", "\n", "linears", "=", "[", "linear", "[", ":", "target_length", ",", ":", "]", "for", "linear", ",", "target_length", "in", "zip", "(", "linears", ",", "target_lengths", ")", "]", "\n", "assert", "len", "(", "mels", ")", "==", "len", "(", "linears", ")", "==", "len", "(", "texts", ")", "\n", "\n", "", "if", "basenames", "is", "None", ":", "\n", "            ", "raise", "NotImplemented", "(", ")", "\n", "\n", "", "saved_mels_paths", "=", "[", "]", "\n", "for", "i", ",", "mel", "in", "enumerate", "(", "mels", ")", ":", "\n", "# Write the spectrogram to disk", "\n", "# Note: outputs mel-spectrogram files and target ones have same names, just different folders", "\n", "            ", "mel_filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"mel-{}.npy\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", "\n", "np", ".", "save", "(", "mel_filename", ",", "mel", ",", "allow_pickle", "=", "False", ")", "\n", "saved_mels_paths", ".", "append", "(", "mel_filename", ")", "\n", "\n", "if", "log_dir", "is", "not", "None", ":", "\n", "#save wav (mel -> wav)", "\n", "                ", "wav", "=", "audio", ".", "inv_mel_spectrogram", "(", "mel", ".", "T", ",", "hparams", ")", "\n", "audio", ".", "save_wav", "(", "wav", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs/wav-{}-mel.wav\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n", "#save alignments", "\n", "plot", ".", "plot_alignment", "(", "alignments", "[", "i", "]", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/alignment-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n", "title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ",", "max_len", "=", "target_lengths", "[", "i", "]", ")", "\n", "\n", "#save mel spectrogram plot", "\n", "plot", ".", "plot_spectrogram", "(", "mel", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/mel-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n", "title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ")", "\n", "\n", "if", "hparams", ".", "predict_linear", ":", "\n", "#save wav (linear -> wav)", "\n", "                    ", "wav", "=", "audio", ".", "inv_linear_spectrogram", "(", "linears", "[", "i", "]", ".", "T", ",", "hparams", ")", "\n", "audio", ".", "save_wav", "(", "wav", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"wavs/wav-{}-linear.wav\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n", "#save linear spectrogram plot", "\n", "plot", ".", "plot_spectrogram", "(", "linears", "[", "i", "]", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"plots/linear-{}.png\"", ".", "format", "(", "basenames", "[", "i", "]", ")", ")", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up": [[216, 219], ["None"], "methods", ["None"], ["title", "=", "\"{}\"", ".", "format", "(", "texts", "[", "i", "]", ")", ",", "split_title", "=", "True", ",", "auto_aspect", "=", "True", ")", "\n", "\n", "", "", "", "return", "saved_mels_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_inputs": [[220, 223], ["max", "numpy.stack", "len", "tacotron2.Tacotron2._pad_input"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_input"], ["", "def", "_round_up", "(", "self", ",", "x", ",", "multiple", ")", ":", "\n", "        ", "remainder", "=", "x", "%", "multiple", "\n", "return", "x", "if", "remainder", "==", "0", "else", "x", "+", "multiple", "-", "remainder", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_input": [[224, 226], ["numpy.pad"], "methods", ["None"], ["", "def", "_prepare_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "inputs", "]", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_input", "(", "x", ",", "max_len", ")", "for", "x", "in", "inputs", "]", ")", ",", "max_len", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._prepare_targets": [[227, 231], ["max", "tacotron2.Tacotron2._round_up", "numpy.stack", "len", "tacotron2.Tacotron2._pad_target"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._round_up", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_target"], ["\n", "", "def", "_pad_input", "(", "self", ",", "x", ",", "length", ")", ":", "\n", "        ", "return", "np", ".", "pad", "(", "x", ",", "(", "0", ",", "length", "-", "x", ".", "shape", "[", "0", "]", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_pad", ")", "\n", "\n", "", "def", "_prepare_targets", "(", "self", ",", "targets", ",", "alignment", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._pad_target": [[232, 234], ["numpy.pad"], "methods", ["None"], ["        ", "max_len", "=", "max", "(", "[", "len", "(", "t", ")", "for", "t", "in", "targets", "]", ")", "\n", "data_len", "=", "self", ".", "_round_up", "(", "max_len", ",", "alignment", ")", "\n", "return", "np", ".", "stack", "(", "[", "self", ".", "_pad_target", "(", "t", ",", "data_len", ")", "for", "t", "in", "targets", "]", ")", ",", "data_len", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.tacotron2.Tacotron2._get_output_lengths": [[235, 239], ["row.index", "numpy.round().tolist", "numpy.round"], "methods", ["None"], ["\n", "", "def", "_pad_target", "(", "self", ",", "t", ",", "length", ")", ":", "\n", "        ", "return", "np", ".", "pad", "(", "t", ",", "[", "(", "0", ",", "length", "-", "t", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "self", ".", "_target_pad", ")", "\n", "\n", "", "def", "_get_output_lengths", "(", "self", ",", "stop_tokens", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.hparams.hparams_debug_string": [[350, 354], ["hparams.values", "sorted"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder.FeederHParams.replace": [[12, 14], ["super()._replace"], "methods", ["None"], ["\n", "class", "Feeder", ":", "\n", "\t"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder.Feeder.__init__": [[16, 18], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "coordinator", ",", "metadata_filename", ",", "hparams", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder.Feeder._parse_func": [[19, 31], ["numpy.load", "os.path.join", "len", "random.randint", "mel_file.decode", "len", "numpy.concatenate", "spkid.decode", "len"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.inference.Synthesizer.load"], ["\t\t", "super", "(", "Feeder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_coord", "=", "coordinator", "\n", "self", ".", "_hparams", "=", "hparams", "\n", "self", ".", "_cleaner_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "hparams", ".", "cleaners", ".", "split", "(", "\",\"", ")", "]", "\n", "self", ".", "_train_offset", "=", "0", "\n", "self", ".", "_test_offset", "=", "0", "\n", "self", ".", "decrease_func", "=", "lambda", "x", ":", "(", "x", "-", "1", ")", "//", "2", "+", "1", "# x : ceil((x+1)/2)", "\n", "\n", "# Load metadata", "\n", "self", ".", "_mel_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"mels\"", ")", "\n", "self", ".", "_embed_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "metadata_filename", ")", ",", "\"embeds\"", ")", "\n", "with", "open", "(", "metadata_filename", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t", "self", ".", "_metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "for", "line", "in", "f", "]", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder.Feeder.__call__": [[32, 58], ["tensorflow.data.experimental.CsvDataset", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "open", "dataset.batch.batch.shuffle", "dataset.batch.batch.repeat", "line.strip", "enumerate", "tuple", "fid.readlines", "tensorflow.py_func", "len", "line.strip"], "methods", ["None"], ["frame_shift_ms", "=", "hparams", ".", "hop_size", "/", "hparams", ".", "sample_rate", "\n", "hours", "=", "sum", "(", "[", "int", "(", "x", "[", "4", "]", ")", "for", "x", "in", "self", ".", "_metadata", "]", ")", "*", "frame_shift_ms", "/", "(", "3600", ")", "\n", "log", "(", "\"Loaded metadata for {} examples ({:.2f} hours)\"", ".", "format", "(", "len", "(", "self", ".", "_metadata", ")", ",", "hours", ")", ")", "\n", "\n", "#Train test split", "\n", "", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "is", "not", "None", "\n", "\n", "", "test_size", "=", "(", "hparams", ".", "tacotron_test_size", "if", "hparams", ".", "tacotron_test_size", "is", "not", "None", "\n", "else", "hparams", ".", "tacotron_test_batches", "*", "hparams", ".", "tacotron_batch_size", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_metadata", ")", ")", "\n", "train_indices", ",", "test_indices", "=", "train_test_split", "(", "indices", ",", "\n", "test_size", "=", "test_size", ",", "random_state", "=", "hparams", ".", "tacotron_data_random_state", ")", "\n", "\n", "#Make sure test_indices is a multiple of batch_size else round up", "\n", "len_test_indices", "=", "self", ".", "_round_down", "(", "len", "(", "test_indices", ")", ",", "hparams", ".", "tacotron_batch_size", ")", "\n", "extra_test", "=", "test_indices", "[", "len_test_indices", ":", "]", "\n", "test_indices", "=", "test_indices", "[", ":", "len_test_indices", "]", "\n", "train_indices", "=", "np", ".", "concatenate", "(", "[", "train_indices", ",", "extra_test", "]", ")", "\n", "\n", "self", ".", "_train_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "train_indices", "]", ")", "\n", "self", ".", "_test_meta", "=", "list", "(", "np", ".", "array", "(", "self", ".", "_metadata", ")", "[", "test_indices", "]", ")", "\n", "\n", "self", ".", "test_steps", "=", "len", "(", "self", ".", "_test_meta", ")", "//", "hparams", ".", "tacotron_batch_size", "\n", "\n", "if", "hparams", ".", "tacotron_test_size", "is", "None", ":", "\n", "\t\t\t", "assert", "hparams", ".", "tacotron_test_batches", "==", "self", ".", "test_steps", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.init": [[13, 23], ["infolog._close_logfile", "open", "open", "open.write", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._close_logfile"], ["def", "init", "(", "filename", ",", "run_name", ",", "slack_url", "=", "None", ")", ":", "\n", "\t", "global", "_file", ",", "_run_name", ",", "_slack_url", "\n", "_close_logfile", "(", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", "=", "open", "(", "filename", ",", "\"a\"", ")", "\n", "_file", ".", "write", "(", "\"\\n-----------------------------------------------------------------\\n\"", ")", "\n", "_file", ".", "write", "(", "\"Starting new {} training run\\n\"", ".", "format", "(", "run_name", ")", ")", "\n", "_file", ".", "write", "(", "\"-----------------------------------------------------------------\\n\"", ")", "\n", "_run_name", "=", "run_name", "\n", "_slack_url", "=", "slack_url", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog.log": [[25, 31], ["print", "_file.write", "threading.Thread().start", "threading.Thread", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "log", "(", "msg", ",", "end", "=", "\"\\n\"", ",", "slack", "=", "False", ")", ":", "\n", "\t", "print", "(", "msg", ",", "end", "=", "end", ")", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "write", "(", "\"[%s]  %s\\n\"", "%", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "_format", ")", "[", ":", "-", "3", "]", ",", "msg", ")", ")", "\n", "", "if", "slack", "and", "_slack_url", "is", "not", "None", ":", "\n", "\t\t", "Thread", "(", "target", "=", "_send_slack", ",", "args", "=", "(", "msg", ",", ")", ")", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._close_logfile": [[33, 38], ["_file.close"], "function", ["None"], ["", "", "def", "_close_logfile", "(", ")", ":", "\n", "\t", "global", "_file", "\n", "if", "_file", "is", "not", "None", ":", "\n", "\t\t", "_file", ".", "close", "(", ")", "\n", "_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.infolog._send_slack": [[40, 47], ["urllib.request.Request", "urllib.request.Request.add_header", "urllib.request.urlopen", "json.dumps().encode", "json.dumps"], "function", ["None"], ["", "", "def", "_send_slack", "(", "msg", ")", ":", "\n", "\t", "req", "=", "Request", "(", "_slack_url", ")", "\n", "req", ".", "add_header", "(", "\"Content-Type\"", ",", "\"application/json\"", ")", "\n", "urlopen", "(", "req", ",", "json", ".", "dumps", "(", "{", "\n", "\"username\"", ":", "\"tacotron\"", ",", "\n", "\"icon_emoji\"", ":", "\":taco:\"", ",", "\n", "\"text\"", ":", "\"*%s*: %s\"", "%", "(", "_run_name", ",", "msg", ")", "\n", "}", ")", ".", "encode", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.FeederHParams.replace": [[16, 18], ["super()._replace"], "methods", ["None"], ["    ", "def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "FeederHParams", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.Feeder.__init__": [[20, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "self", ".", "hp", "=", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.Feeder._process_wave": [[23, 47], ["datasets.audio.load_wav", "datasets.audio.trim_silence", "len", "numpy.concatenate", "len", "random.randint", "datasets.audio.melspectrogram().astype", "print", "numpy.math.ceil", "len", "numpy.abs().max", "datasets.audio.melspectrogram", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], ["", "def", "_process_wave", "(", "self", ",", "wav_file", ",", "num_frames", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "wav", "=", "audio", ".", "load_wav", "(", "wav_file", ",", "sr", "=", "audio_hparams", ".", "sample_rate", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "print", "(", "'file {} present in csv metadata is not present in wav folder. skipping!'", ".", "format", "(", "wav_file", ")", ")", "\n", "\n", "", "if", "audio_hparams", ".", "trim_silence", ":", "\n", "            ", "wav", "=", "audio", ".", "trim_silence", "(", "wav", ",", "audio_hparams", ")", "\n", "\n", "", "expect_len", "=", "num_frames", "*", "audio_hparams", ".", "hop_size", "+", "audio_hparams", ".", "win_size", "\n", "if", "len", "(", "wav", ")", "<", "expect_len", ":", "\n", "            ", "wav", "=", "np", ".", "concatenate", "(", "[", "wav", "]", "*", "np", ".", "math", ".", "ceil", "(", "expect_len", "/", "len", "(", "wav", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "wav", ")", ">", "expect_len", ":", "\n", "            ", "sp", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "wav", ")", "-", "expect_len", ")", "\n", "wav", "=", "wav", "[", "sp", ":", "sp", "+", "expect_len", "]", "\n", "\n", "", "wav", "=", "audio", ".", "preemphasis", "(", "wav", ",", "audio_hparams", ".", "preemphasis", ",", "audio_hparams", ".", "preemphasize", ")", "\n", "\n", "if", "audio_hparams", ".", "rescale", ":", "\n", "            ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "audio_hparams", ".", "rescaling_max", "\n", "\n", "", "mels", "=", "audio", ".", "melspectrogram", "(", "wav", ",", "audio_hparams", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "return", "mels", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.Feeder._parse_func": [[48, 51], ["feeder_wav.Feeder._process_wave", "wav_file.decode", "spkid.decode"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder._process_wave"], ["", "def", "_parse_func", "(", "self", ",", "spkid", ",", "wav_file", ",", "num_frames", ")", ":", "\n", "        ", "fbanks", "=", "self", ".", "_process_wave", "(", "wav_file", ".", "decode", "(", ")", ",", "num_frames", ")", "\n", "return", "fbanks", ",", "self", ".", "spk_dict", "[", "spkid", ".", "decode", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.Feeder.__call__": [[52, 81], ["tensorflow.data.experimental.CsvDataset", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "open", "dataset.batch.batch.shuffle", "dataset.batch.batch.repeat", "line.strip", "enumerate", "tuple", "fid.readlines", "tensorflow.py_func", "len", "line.strip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "hp", "=", "self", ".", "hp", "\n", "\n", "with", "open", "(", "hp", ".", "spkfile", ")", "as", "fid", ":", "\n", "            ", "spklist", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fid", ".", "readlines", "(", ")", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "!=", "0", "]", "\n", "\n", "", "self", ".", "spk_dict", "=", "{", "spkid", ":", "idx", "for", "idx", ",", "spkid", "in", "enumerate", "(", "spklist", ")", "}", "\n", "\n", "dataset", "=", "tf", ".", "data", ".", "experimental", ".", "CsvDataset", "(", "hp", ".", "scp", ",", "\n", "record_defaults", "=", "hp", ".", "record_defaults", ",", "\n", "field_delim", "=", "hp", ".", "field_delim", ",", "\n", "select_cols", "=", "hp", ".", "select_cols", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "spkid", ",", "wav_file", ":", "\n", "tuple", "(", "tf", ".", "py_func", "(", "self", ".", "_parse_func", ",", "[", "spkid", ",", "wav_file", ",", "num_frames", "]", ",", "hp", ".", "dtypes", ")", ")", ",", "num_parallel_calls", "=", "-", "1", ")", "\n", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", "=", "hp", ".", "shuffle_size", ",", "reshuffle_each_iteration", "=", "True", ")", "if", "hp", ".", "shuffle", "==", "True", "else", "dataset", "\n", "\n", "dataset", "=", "dataset", ".", "repeat", "(", "hp", ".", "times", ")", "if", "hp", ".", "is_repeat", "==", "True", "else", "dataset", "\n", "\n", "# dataset = dataset.padded_batch(hp.batch_size, padded_shapes=hp.padded_shapes)", "\n", "dataset", "=", "dataset", ".", "batch", "(", "hp", ".", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "return", "iterator", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder.__init__": [[83, 85], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder._process_wave": [[86, 110], ["datasets.audio.preemphasis", "datasets.audio.load_wav", "datasets.audio.trim_silence", "len", "numpy.concatenate", "len", "random.randint", "datasets.audio.melspectrogram().astype", "print", "numpy.math.ceil", "len", "numpy.abs().max", "datasets.audio.melspectrogram", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.preemphasis", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.load_wav", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.datasets.audio.trim_silence", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.synthesizer.audio.melspectrogram"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder._parse_func": [[111, 114], ["feeder_wav.EvalFeeder._process_wave", "wav_file.decode", "spkid.decode"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder._process_wave"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.feeder_wav.EvalFeeder.__call__": [[115, 145], ["tensorflow.data.experimental.CsvDataset", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "dataset.batch.batch.map", "dataset.batch.batch.batch", "dataset.batch.batch.make_initializable_iterator", "open", "dataset.batch.batch.shuffle", "dataset.batch.batch.repeat", "line.strip", "enumerate", "tuple", "fid.readlines", "tensorflow.py_func", "len", "line.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.train.time_string": [[15, 17], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "train", "(", "run_id", ":", "str", ",", "syn_dir", ":", "Path", ",", "voc_dir", ":", "Path", ",", "models_dir", ":", "Path", ",", "ground_truth", ":", "bool", ",", "\n", "save_every", ":", "int", ",", "backup_every", ":", "int", ",", "force_restart", ":", "bool", ")", ":", "\n", "# Check to make sure the hop length is correctly factorised", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.train.create_feeder": [[18, 29], ["feeder_wav.Feeder", "feeder_wav.Feeder.", "feeder_wav.Feeder", "feeder_wav.Feeder.", "tensorflow.data.Iterator.from_string_handle"], "function", ["None"], ["    ", "assert", "np", ".", "cumprod", "(", "hp", ".", "voc_upsample_factors", ")", "[", "-", "1", "]", "==", "hp", ".", "hop_length", "\n", "\n", "# Instantiate the model", "\n", "print", "(", "\"Initializing the model...\"", ")", "\n", "model", "=", "WaveRNN", "(", "\n", "rnn_dims", "=", "hp", ".", "voc_rnn_dims", ",", "\n", "fc_dims", "=", "hp", ".", "voc_fc_dims", ",", "\n", "bits", "=", "hp", ".", "bits", ",", "\n", "pad", "=", "hp", ".", "voc_pad", ",", "\n", "upsample_factors", "=", "hp", ".", "voc_upsample_factors", ",", "\n", "feat_dims", "=", "hp", ".", "num_mels", ",", "\n", "compute_dims", "=", "hp", ".", "voc_compute_dims", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.train.create_model": [[30, 39], ["tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph", "tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph"], ["res_out_dims", "=", "hp", ".", "voc_res_out_dims", ",", "\n", "res_blocks", "=", "hp", ".", "voc_res_blocks", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "sample_rate", "=", "hp", ".", "sample_rate", ",", "\n", "mode", "=", "hp", ".", "voc_mode", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "# Initialize the optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "for", "p", "in", "optimizer", ".", "param_groups", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.vox12_hparams.TrainHparams.replace": [[12, 14], ["super()._replace"], "methods", ["None"], ["available_gpus", "=", "GPUtil", ".", "getAvailable", "(", "order", "=", "'last'", ",", "limit", "=", "8", ",", "maxLoad", "=", "0.1", ",", "maxMemory", "=", "0.1", ",", "includeNan", "=", "False", ",", "excludeID", "=", "[", "]", ",", "excludeUUID", "=", "[", "]", ")", "\n", "num_gpus", "=", "len", "(", "available_gpus", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "','", ".", "join", "(", "map", "(", "str", ",", "available_gpus", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNetHParams.replace": [[39, 41], ["super()._replace"], "methods", ["None"], ["    ", "def", "replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "ResNetHParams", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.__init__": [[50, 64], ["tensorflow.expand_dims"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hps", ",", "fbanks", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"ResNet constructor.\n        Args:\n            hps: Hyperparameters.\n            fbanks: Batches of fbanks. [batch_size, time_step, fbank_dim]\n            labels: Batches of labels. [batch_size, num_classes]\n            mode: One of 'train' and 'eval'.\n        \"\"\"", "\n", "self", ".", "hps", "=", "hps", "\n", "self", ".", "fbanks", "=", "tf", ".", "expand_dims", "(", "fbanks", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "self", ".", "_extra_train_ops", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph": [[65, 74], ["tensorflow.train.get_or_create_global_step", "resnet.ResNet._build_model_multi_gpu", "tensorflow.summary.merge_all", "resnet.ResNet._build_train_op_multi_gpu"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model_multi_gpu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_train_op_multi_gpu"], ["", "def", "build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build a whole graph for the model.\"\"\"", "\n", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "# self._build_model(self.fbanks, self.labels)", "\n", "self", ".", "_build_model_multi_gpu", "(", "self", ".", "fbanks", ",", "self", ".", "labels", ")", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "# self._build_train_op()", "\n", "            ", "self", ".", "_build_train_op_multi_gpu", "(", ")", "\n", "", "self", ".", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr": [[75, 78], ["None"], "methods", ["None"], ["", "def", "_stride_arr", "(", "self", ",", "stride", ")", ":", "\n", "        ", "\"\"\"Map a stride scalar to the stride array for tf.nn.conv2d.\"\"\"", "\n", "return", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model_multi_gpu": [[79, 102], ["list", "list", "list", "list", "list", "range", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.device", "tensorflow.split", "tensorflow.split", "tensorflow.stack", "tensorflow.stack", "tensorflow.device", "resnet.ResNet._build_model", "list.append", "list.append", "list.append", "list.append", "tensorflow.train.replica_device_setter"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["", "def", "_build_model_multi_gpu", "(", "self", ",", "fbanks", ",", "labels", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "tower_fbanks", "=", "tf", ".", "split", "(", "fbanks", ",", "self", ".", "hps", ".", "num_gpus", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels", ",", "self", ".", "hps", ".", "num_gpus", ")", "\n", "\n", "", "tower_gvs", "=", "list", "(", ")", "\n", "tower_predictions", "=", "list", "(", ")", "\n", "tower_costs", "=", "list", "(", ")", "\n", "tower_accuracies", "=", "list", "(", ")", "\n", "tower_gradients", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "hps", ".", "num_gpus", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "'/cpu:0'", ",", "worker_device", "=", "'/gpu:{}'", ".", "format", "(", "i", ")", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "''", ")", ":", "\n", "                    ", "self", ".", "_build_model", "(", "tower_fbanks", "[", "i", "]", ",", "tower_labels", "[", "i", "]", ")", "\n", "tower_gvs", ".", "append", "(", "self", ".", "gv", ")", "\n", "tower_predictions", ".", "append", "(", "self", ".", "predictions", ")", "\n", "tower_costs", ".", "append", "(", "self", ".", "cost", ")", "\n", "tower_accuracies", ".", "append", "(", "self", ".", "accuracy", ")", "\n", "\n", "", "", "", "self", ".", "gv", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "tower_gvs", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "tower_predictions", ")", "\n", "self", ".", "cost", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_costs", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_accuracies", ")", ")", "\n", "self", ".", "costs", "=", "tower_costs", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_model": [[103, 180], ["six.moves.range", "six.moves.range", "six.moves.range", "six.moves.range", "tensorflow.variable_scope", "resnet.ResNet._conv", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "res_func", "tensorflow.variable_scope", "resnet.ResNet._global_mean_std_pool", "tensorflow.variable_scope", "resnet.ResNet._fully_connected", "tensorflow.variable_scope", "resnet.ResNet._fully_connected", "tensorflow.nn.softmax", "tensorflow.variable_scope", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "resnet.ResNet._decay", "tensorflow.variable_scope", "tensorflow.equal", "tensorflow.reduce_mean", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "resnet.ResNet._stride_arr", "tensorflow.variable_scope", "res_func", "tensorflow.nn.dropout", "tensorflow.argmax", "tensorflow.cast", "tensorflow.cast", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr", "resnet.ResNet._stride_arr"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._global_mean_std_pool", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._decay", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._stride_arr"], ["\n", "", "def", "_build_model", "(", "self", ",", "fbanks", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Build the core model within the graph.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'init'", ")", ":", "\n", "            ", "x", "=", "fbanks", "\n", "x", "=", "self", ".", "_conv", "(", "'init_conv'", ",", "x", ",", "3", ",", "1", ",", "16", ",", "self", ".", "_stride_arr", "(", "1", ")", ")", "\n", "\n", "", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "activate_before_residual", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "if", "self", ".", "hps", ".", "use_bottleneck", ":", "\n", "            ", "res_func", "=", "self", ".", "_bottleneck_residual", "\n", "filters", "=", "[", "16", ",", "64", ",", "128", ",", "256", "]", "\n", "", "else", ":", "\n", "            ", "res_func", "=", "self", ".", "_residual", "\n", "filters", "=", "[", "16", ",", "32", ",", "64", ",", "128", "]", "\n", "# filters = [32, 64, 128, 256]", "\n", "# Uncomment the following codes to use w28-10 wide residual network.", "\n", "# It is more memory efficient than very deep residual network and has", "\n", "# comparably good performance.", "\n", "# https://arxiv.org/pdf/1605.07146v1.pdf", "\n", "# filters = [16, 160, 320, 640]", "\n", "# Update hps.num_residual_units to 4", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'unit_0_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "16", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "0", "]", ")", ",", "\n", "activate_before_residual", "[", "0", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "0", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_0_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "0", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_1_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "0", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "1", "]", ")", ",", "\n", "activate_before_residual", "[", "1", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "1", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_1_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "1", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_2_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "1", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "2", "]", ")", ",", "\n", "activate_before_residual", "[", "2", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "2", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_2_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "2", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_3_0'", ")", ":", "\n", "            ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "2", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "strides", "[", "3", "]", ")", ",", "\n", "activate_before_residual", "[", "3", "]", ")", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "1", ",", "self", ".", "hps", ".", "num_residual_units", "[", "3", "]", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_3_%d'", "%", "i", ")", ":", "\n", "                ", "x", "=", "res_func", "(", "x", ",", "filters", "[", "3", "]", ",", "filters", "[", "3", "]", ",", "self", ".", "_stride_arr", "(", "1", ")", ",", "False", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_last'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'final_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_global_mean_std_pool", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'vector'", ")", ":", "\n", "            ", "self", ".", "gv", "=", "self", ".", "_fully_connected", "(", "x", ",", "self", ".", "hps", ".", "gv_dim", ")", "\n", "# self.gv = self.gv / tf.norm(self.gv, ord=2, axis=-1, keep_dims=True)", "\n", "dropout_gv", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "gv", ",", "keep_prob", "=", "1", "-", "self", ".", "hps", ".", "dropout_rate", ")", "if", "self", ".", "mode", "==", "'train'", "else", "self", ".", "gv", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'logit'", ")", ":", "\n", "            ", "logits", "=", "self", ".", "_fully_connected", "(", "dropout_gv", ",", "self", ".", "hps", ".", "num_classes", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'costs'", ")", ":", "\n", "            ", "xent", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n", "self", ".", "cost", "=", "tf", ".", "reduce_mean", "(", "xent", ",", "name", "=", "'xent'", ")", "\n", "self", ".", "cost", "+=", "self", ".", "_decay", "(", ")", "\n", "\n", "# tf.summary.scalar('cost', self.cost)", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'accuracy'", ")", ":", "\n", "            ", "correct_predictions", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "self", ".", "predictions", ",", "1", ",", "output_type", "=", "tf", ".", "int32", ")", ",", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int32", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_predictions", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "# tf.summary.scalar('accuracy', self.accuracy)", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._compute_gradient": [[183, 187], ["tensorflow.trainable_variables", "tensorflow.gradients"], "methods", ["None"], ["        ", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "cost", ",", "trainable_variables", ")", "\n", "return", "grads", "\n", "\n", "", "def", "_average_gradients", "(", "self", ",", "gradients", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._average_gradients": [[188, 201], ["list", "zip", "list", "tensorflow.concat", "tensorflow.reduce_mean", "list.append", "tensorflow.expand_dims", "list.append"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["        ", "avg_grads", "=", "list", "(", ")", "\n", "for", "grads_per_gpu", "in", "zip", "(", "*", "gradients", ")", ":", "\n", "            ", "grads", "=", "list", "(", ")", "\n", "for", "g", "in", "grads_per_gpu", ":", "\n", "                ", "expanded_g", "=", "tf", ".", "expand_dims", "(", "g", ",", "0", ")", "\n", "grads", ".", "append", "(", "expanded_g", ")", "\n", "\n", "", "grad", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "grads", ")", "\n", "grad", "=", "tf", ".", "reduce_mean", "(", "grad", ",", "0", ")", "\n", "\n", "avg_grads", ".", "append", "(", "grad", ")", "\n", "", "return", "avg_grads", "\n", "\n", "", "def", "_build_train_op_multi_gpu", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_train_op_multi_gpu": [[202, 233], ["resnet.ResNet._learning_rate_decay", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "list", "enumerate", "tensorflow.group", "tensorflow.device", "resnet.ResNet._average_gradients", "tensorflow.device", "list.append", "tensorflow.train.GradientDescentOptimizer", "tensorflow.clip_by_global_norm", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.replica_device_setter", "resnet.ResNet._compute_gradient", "tensorflow.train.MomentumOptimizer", "tensorflow.get_collection", "zip", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._average_gradients", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._compute_gradient"], ["# self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)", "\n", "        ", "self", ".", "lrn_rate", "=", "self", ".", "_learning_rate_decay", "(", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "self", ".", "lrn_rate", ")", "\n", "\n", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "gradients", "=", "list", "(", ")", "\n", "for", "i", ",", "cost", "in", "enumerate", "(", "self", ".", "costs", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "ps_tasks", "=", "1", ",", "ps_device", "=", "'/cpu:0'", ",", "worker_device", "=", "'/gpu:{}'", ".", "format", "(", "i", ")", ")", ")", ":", "\n", "                ", "gradients", ".", "append", "(", "self", ".", "_compute_gradient", "(", "cost", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "grads", "=", "self", ".", "_average_gradients", "(", "gradients", ")", "\n", "\n", "if", "self", ".", "hps", ".", "optimizer", "==", "'sgd'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "lrn_rate", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'mom'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'adam'", ":", "\n", "                ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ",", "0.999", ",", "1e-6", ")", "\n", "\n", "", "if", "self", ".", "hps", ".", "clip_gradients", ":", "\n", "                ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "1.", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", ")", ":", "\n", "                ", "apply_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "zip", "(", "grads", ",", "trainable_variables", ")", ",", "\n", "global_step", "=", "self", ".", "global_step", ",", "name", "=", "'train_step'", ")", "\n", "\n", "", "", "train_ops", "=", "[", "apply_op", "]", "+", "self", ".", "_extra_train_ops", "\n", "self", ".", "train_op", "=", "tf", ".", "group", "(", "*", "train_ops", ")", "\n", "\n", "", "def", "_build_train_op", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._build_train_op": [[234, 261], ["resnet.ResNet._learning_rate_decay", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.group", "tensorflow.train.GradientDescentOptimizer", "tensorflow.clip_by_global_norm", "zip", "tensorflow.train.MomentumOptimizer", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay"], ["        ", "\"\"\"Build training specific ops for the graph.\"\"\"", "\n", "# self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)", "\n", "self", ".", "lrn_rate", "=", "self", ".", "_learning_rate_decay", "(", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "self", ".", "lrn_rate", ")", "\n", "\n", "trainable_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "self", ".", "cost", ",", "trainable_variables", ")", "\n", "\n", "if", "self", ".", "hps", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "lrn_rate", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'mom'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ")", "\n", "", "elif", "self", ".", "hps", ".", "optimizer", "==", "'adam'", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lrn_rate", ",", "0.9", ",", "0.999", ",", "1e-6", ")", "\n", "\n", "# grads, trainable_variables = zip(*optimizer.compute_gradients(self.cost))", "\n", "\n", "", "if", "self", ".", "hps", ".", "clip_gradients", ":", "\n", "            ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "1.", ")", "\n", "\n", "", "apply_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "zip", "(", "grads", ",", "trainable_variables", ")", ",", "\n", "global_step", "=", "self", ".", "global_step", ",", "name", "=", "'train_step'", ")", "\n", "\n", "train_ops", "=", "[", "apply_op", "]", "+", "self", ".", "_extra_train_ops", "\n", "self", ".", "train_op", "=", "tf", ".", "group", "(", "*", "train_ops", ")", "\n", "\n", "# TODO(xpan): Consider batch_norm in contrib/layers/python/layers/layers.py", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm": [[263, 307], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.batch_normalization", "tensorflow.nn.batch_normalization.set_shape", "tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "resnet.ResNet._extra_train_ops.append", "resnet.ResNet._extra_train_ops.append", "tensorflow.get_variable", "tensorflow.get_variable", "x.get_shape", "x.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["        ", "\"\"\"Batch normalization.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "params_shape", "=", "[", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", "\n", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "'beta'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "'gamma'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "                ", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", ",", "1", ",", "2", "]", ",", "name", "=", "'moments'", ")", "\n", "\n", "moving_mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_mean", ",", "mean", ",", "0.9", ")", ")", "\n", "self", ".", "_extra_train_ops", ".", "append", "(", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_variance", ",", "variance", ",", "0.9", ")", ")", "\n", "", "else", ":", "\n", "                ", "mean", "=", "tf", ".", "get_variable", "(", "\n", "'moving_mean'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "variance", "=", "tf", ".", "get_variable", "(", "\n", "'moving_variance'", ",", "params_shape", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "# tf.summary.histogram(mean.op.name, mean)", "\n", "# tf.summary.histogram(variance.op.name, variance)", "\n", "# epsilon used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.", "\n", "", "y", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "mean", ",", "variance", ",", "beta", ",", "gamma", ",", "0.001", ")", "\n", "y", ".", "set_shape", "(", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "y", "\n", "\n", "", "", "def", "_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._residual": [[308, 348], ["tensorflow.logging.debug", "tensorflow.variable_scope", "resnet.ResNet._conv", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "tensorflow.variable_scope", "resnet.ResNet._conv", "resnet.ResNet._batch_norm", "tensorflow.variable_scope", "resnet.ResNet._relu", "resnet.ResNet.get_shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "resnet.ResNet._batch_norm"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm"], ["activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Residual unit with 2 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'shared_activation'", ")", ":", "\n", "                ", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_only_activation'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "3", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'sub_add_conv'", ",", "orig_x", ",", "3", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "'''\n                orig_x = tf.nn.avg_pool(orig_x, stride, stride, 'SAME')\n                orig_x = tf.pad(\n                        orig_x, [[0, 0], [0, 0], [0, 0],\n                                         [(out_filter-in_filter)//2, (out_filter-in_filter)//2]])\n                '''", "\n", "", "x", "+=", "orig_x", "\n", "\n", "", "tf", ".", "logging", ".", "debug", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n", "", "def", "_bottleneck_residual", "(", "self", ",", "x", ",", "in_filter", ",", "out_filter", ",", "stride", ",", "\n", "activate_before_residual", "=", "False", ")", ":", "\n", "        ", "\"\"\"Bottleneck residual unit with 3 sub layers.\"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'common_bn_relu'", ")", ":", "\n", "                ", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._bottleneck_residual": [[349, 383], ["tensorflow.logging.info", "tensorflow.variable_scope", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv", "tensorflow.variable_scope", "resnet.ResNet.get_shape", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "tensorflow.variable_scope", "resnet.ResNet._batch_norm", "resnet.ResNet._relu", "resnet.ResNet._conv"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._batch_norm", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv"], ["x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "orig_x", "=", "x", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'residual_bn_relu'", ")", ":", "\n", "                ", "orig_x", "=", "x", "\n", "x", "=", "self", ".", "_batch_norm", "(", "'init_bn'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'sub1'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_conv", "(", "'conv1'", ",", "x", ",", "1", ",", "in_filter", ",", "out_filter", "/", "4", ",", "stride", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub2'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn2'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv2'", ",", "x", ",", "3", ",", "out_filter", "/", "4", ",", "out_filter", "/", "4", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub3'", ")", ":", "\n", "            ", "x", "=", "self", ".", "_batch_norm", "(", "'bn3'", ",", "x", ")", "\n", "x", "=", "self", ".", "_relu", "(", "x", ",", "self", ".", "hps", ".", "relu_leakiness", ")", "\n", "x", "=", "self", ".", "_conv", "(", "'conv3'", ",", "x", ",", "1", ",", "out_filter", "/", "4", ",", "out_filter", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sub_add'", ")", ":", "\n", "            ", "if", "in_filter", "!=", "out_filter", ":", "\n", "                ", "orig_x", "=", "self", ".", "_conv", "(", "'project'", ",", "orig_x", ",", "1", ",", "in_filter", ",", "out_filter", ",", "stride", ")", "\n", "", "x", "+=", "orig_x", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'fbank after unit %s'", ",", "x", ".", "get_shape", "(", ")", ")", "\n", "return", "x", "\n", "\n", "", "def", "_decay", "(", "self", ")", ":", "\n", "        ", "\"\"\"L2 weight decay loss.\"\"\"", "\n", "costs", "=", "[", "]", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "if", "var", ".", "op", ".", "name", ".", "find", "(", "r'DW'", ")", ">", "0", ":", "\n", "                ", "costs", ".", "append", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._decay": [[384, 393], ["tensorflow.trainable_variables", "tensorflow.multiply", "tensorflow.add_n", "var.op.name.find", "costs.append", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append"], ["# tf.summary.histogram(var.op.name, var)", "\n", "\n", "", "", "return", "tf", ".", "multiply", "(", "self", ".", "hps", ".", "weight_decay_rate", ",", "tf", ".", "add_n", "(", "costs", ")", ")", "\n", "\n", "", "def", "_conv", "(", "self", ",", "name", ",", "x", ",", "filter_size", ",", "in_filters", ",", "out_filters", ",", "strides", ")", ":", "\n", "        ", "\"\"\"Convolution.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "n", "=", "filter_size", "*", "filter_size", "*", "out_filters", "\n", "kernel", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "filter_size", ",", "filter_size", ",", "in_filters", ",", "out_filters", "]", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._conv": [[394, 403], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.random_normal_initializer", "numpy.sqrt"], "methods", ["None"], ["tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "kernel", ",", "strides", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "", "", "def", "_relu", "(", "self", ",", "x", ",", "leakiness", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Relu, with optional leaky support.\"\"\"", "\n", "return", "tf", ".", "where", "(", "tf", ".", "less", "(", "x", ",", "0.0", ")", ",", "leakiness", "*", "x", ",", "x", ",", "name", "=", "'leaky_relu'", ")", "\n", "\n", "", "def", "_fully_connected", "(", "self", ",", "x", ",", "out_dim", ")", ":", "\n", "        ", "\"\"\"FullyConnected layer for final output.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._relu": [[404, 407], ["tensorflow.nn.relu"], "methods", ["None"], ["# x = tf.reshape(x, [tf.shape(x)[0], -1])", "\n", "w", "=", "tf", ".", "get_variable", "(", "\n", "'DW'", ",", "[", "x", ".", "get_shape", "(", ")", "[", "1", "]", ",", "out_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", "factor", "=", "1.0", ")", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._fully_connected": [[409, 418], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.constant_initializer", "x.get_shape"], "methods", ["None"], ["initializer", "=", "tf", ".", "constant_initializer", "(", ")", ")", "\n", "return", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", ",", "w", ",", "b", ")", "\n", "\n", "", "def", "_global_avg_pool", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "return", "tf", ".", "reduce_mean", "(", "x", ",", "[", "1", ",", "2", "]", ")", "\n", "\n", "", "def", "_global_mean_std_pool", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", "\n", "mean", ",", "std", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "1", ",", "2", "]", ")", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._global_avg_pool": [[419, 422], ["tensorflow.reduce_mean", "x.get_shape"], "methods", ["None"], ["return", "tf", ".", "concat", "(", "[", "mean", ",", "std", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "def", "_learning_rate_decay", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "hps", ".", "decay_learning_rate", ":", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._global_mean_std_pool": [[423, 427], ["tensorflow.nn.moments", "tensorflow.concat", "x.get_shape"], "methods", ["None"], ["            ", "return", "tf", ".", "constant", "(", "self", ".", "hps", ".", "lrn_rate", ",", "tf", ".", "float32", ")", "\n", "\n", "", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "hps", ".", "lrn_rate", ",", "\n", "self", ".", "global_step", "-", "self", ".", "hps", ".", "start_decay", ",", "\n", "self", ".", "hps", ".", "decay_steps", ",", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet._learning_rate_decay": [[428, 438], ["tensorflow.train.exponential_decay", "tensorflow.minimum", "tensorflow.constant", "tensorflow.maximum"], "methods", ["None"], ["self", ".", "hps", ".", "decay_rate", ")", "\n", "\n", "return", "tf", ".", "minimum", "(", "tf", ".", "maximum", "(", "lr", ",", "self", ".", "hps", ".", "min_lrn_rate", ")", ",", "self", ".", "hps", ".", "lrn_rate", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.time_string": [[17, 19], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "time_string", "(", ")", ":", "\n", "    ", "return", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_feeder": [[20, 31], ["feeder_wav.Feeder", "feeder_wav.Feeder.", "feeder_wav.Feeder", "feeder_wav.Feeder.", "tensorflow.data.Iterator.from_string_handle"], "function", ["None"], ["", "def", "create_feeder", "(", "num_frames", ",", "handle", ")", ":", "\n", "    ", "train_feeder", "=", "Feeder", "(", "hparams", "=", "train_feeder_hparams", ")", "\n", "train_iterator", "=", "train_feeder", "(", "num_frames", ")", "\n", "dev_feeder", "=", "Feeder", "(", "hparams", "=", "dev_feeder_hparams", ")", "\n", "dev_iterator", "=", "dev_feeder", "(", "num_frames", ")", "\n", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_string_handle", "(", "handle", ",", "\n", "train_iterator", ".", "output_types", ",", "\n", "train_iterator", ".", "output_shapes", ")", "\n", "\n", "return", "iterator", ",", "train_iterator", ",", "dev_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.test.create_model": [[32, 41], ["tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph", "tensorflow.variable_scope", "resnet.ResNet", "resnet.ResNet.build_graph"], "function", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph", "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.resnet.ResNet.build_graph"], ["", "def", "create_model", "(", "fbanks", ",", "labels", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'resnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "train_resnet", "=", "ResNet", "(", "resnet_hparams", ",", "fbanks", ",", "labels", ",", "'train'", ")", "\n", "train_resnet", ".", "build_graph", "(", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'resnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "eval_resnet", "=", "ResNet", "(", "resnet_hparams", ",", "fbanks", ",", "labels", ",", "'eval'", ")", "\n", "eval_resnet", ".", "build_graph", "(", ")", "\n", "\n", "", "return", "train_resnet", ",", "eval_resnet", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.hparams.hparams_debug_string": [[351, 355], ["hparams.values", "sorted"], "function", ["None"], []], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.__init__": [[2, 5], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "window_size", "=", "100", ")", ":", "\n", "    ", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_values", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.append": [[6, 8], ["None"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "x", ")", ":", "\n", "    ", "self", ".", "_values", "=", "self", ".", "_values", "[", "-", "(", "self", ".", "_window_size", "-", "1", ")", ":", "]", "+", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum": [[9, 12], ["utils.ValueWindow.sum"], "methods", ["home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.sum"], ["", "@", "property", "\n", "def", "sum", "(", "self", ")", ":", "\n", "    ", "return", "sum", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.count": [[13, 16], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "count", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.average": [[17, 20], ["max"], "methods", ["None"], ["", "@", "property", "\n", "def", "average", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "sum", "/", "max", "(", "1", ",", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.caizexin_tf_multispeakerTTS_fc.deep_speaker.utils.ValueWindow.reset": [[21, 23], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "_values", "=", "[", "]", "\n", "", "", ""]]}