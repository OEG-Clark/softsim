{"home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.SparseGTMetrics.__init__": [[53, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_rank_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.SparseGTMetrics.observe": [[56, 78], ["predicted_scores.detach.detach.detach", "metrics.scores_to_ranks", "predicted_ranks.view.view.size", "predicted_ranks.view.view.view", "target_ranks.view().long.view().long.view().long", "metrics.SparseGTMetrics._rank_list.extend", "list", "target_ranks.view().long.view().long.view", "predicted_gt_ranks.cpu().numpy", "torch.arange", "predicted_gt_ranks.cpu"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.scores_to_ranks"], ["", "def", "observe", "(", "\n", "self", ",", "predicted_scores", ":", "torch", ".", "Tensor", ",", "target_ranks", ":", "torch", ".", "Tensor", "\n", ")", ":", "\n", "        ", "predicted_scores", "=", "predicted_scores", ".", "detach", "(", ")", "\n", "\n", "# shape: (batch_size, num_rounds, num_options)", "\n", "predicted_ranks", "=", "scores_to_ranks", "(", "predicted_scores", ")", "\n", "batch_size", ",", "num_rounds", ",", "num_options", "=", "predicted_ranks", ".", "size", "(", ")", "\n", "\n", "# collapse batch dimension", "\n", "predicted_ranks", "=", "predicted_ranks", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", ",", "num_options", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds, )", "\n", "target_ranks", "=", "target_ranks", ".", "view", "(", "batch_size", "*", "num_rounds", ")", ".", "long", "(", ")", "\n", "\n", "# shape: (batch_size * num_rounds, )", "\n", "predicted_gt_ranks", "=", "predicted_ranks", "[", "\n", "torch", ".", "arange", "(", "batch_size", "*", "num_rounds", ")", ",", "target_ranks", "\n", "]", "\n", "self", ".", "_rank_list", ".", "extend", "(", "list", "(", "predicted_gt_ranks", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.SparseGTMetrics.retrieve": [[79, 97], ["len", "torch.tensor().float", "metrics.SparseGTMetrics.reset", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.tensor().float.reciprocal"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.reset"], ["", "def", "retrieve", "(", "self", ",", "reset", ":", "bool", "=", "True", ")", ":", "\n", "        ", "num_examples", "=", "len", "(", "self", ".", "_rank_list", ")", "\n", "if", "num_examples", ">", "0", ":", "\n", "# convert to numpy array for easy calculation.", "\n", "            ", "__rank_list", "=", "torch", ".", "tensor", "(", "self", ".", "_rank_list", ")", ".", "float", "(", ")", "\n", "metrics", "=", "{", "\n", "\"r@1\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "1", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"r@5\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "5", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"r@10\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "10", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"mean\"", ":", "torch", ".", "mean", "(", "__rank_list", ")", ".", "item", "(", ")", ",", "\n", "\"mrr\"", ":", "torch", ".", "mean", "(", "__rank_list", ".", "reciprocal", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.SparseGTMetrics.reset": [[98, 100], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_rank_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.__init__": [[103, 106], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.observe": [[107, 158], ["predicted_scores.unsqueeze.unsqueeze.detach", "predicted_scores.unsqueeze.unsqueeze.unsqueeze", "metrics.scores_to_ranks", "predicted_ranks.squeeze.squeeze.squeeze", "predicted_ranks.squeeze.squeeze.size", "torch.sum", "torch.sort", "torch.sort", "range", "sum", "metrics.NDCG._dcg", "metrics.NDCG._dcg", "batch_ndcg.append"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.scores_to_ranks", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG._dcg", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG._dcg", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "observe", "(", "\n", "self", ",", "predicted_scores", ":", "torch", ".", "Tensor", ",", "target_relevance", ":", "torch", ".", "Tensor", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Observe model output scores and target ground truth relevance and\n        accumulate NDCG metric.\n\n        Parameters\n        ----------\n        predicted_scores: torch.Tensor\n            A tensor of shape (batch_size, num_options), because dense\n            annotations are available for 1 randomly picked round out of 10.\n        target_relevance: torch.Tensor\n            A tensor of shape same as predicted scores, indicating ground truth\n            relevance of each answer option for a particular round.\n        \"\"\"", "\n", "predicted_scores", "=", "predicted_scores", ".", "detach", "(", ")", "\n", "\n", "# shape: (batch_size, 1, num_options)", "\n", "predicted_scores", "=", "predicted_scores", ".", "unsqueeze", "(", "1", ")", "\n", "predicted_ranks", "=", "scores_to_ranks", "(", "predicted_scores", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "predicted_ranks", "=", "predicted_ranks", ".", "squeeze", "(", ")", "\n", "batch_size", ",", "num_options", "=", "predicted_ranks", ".", "size", "(", ")", "\n", "\n", "k", "=", "torch", ".", "sum", "(", "target_relevance", "!=", "0", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "_", ",", "rankings", "=", "torch", ".", "sort", "(", "predicted_ranks", ",", "dim", "=", "-", "1", ")", "\n", "# Sort relevance in descending order so highest relevance gets top rnk.", "\n", "_", ",", "best_rankings", "=", "torch", ".", "sort", "(", "\n", "target_relevance", ",", "dim", "=", "-", "1", ",", "descending", "=", "True", "\n", ")", "\n", "\n", "# shape: (batch_size, )", "\n", "batch_ndcg", "=", "[", "]", "\n", "for", "batch_index", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "num_relevant", "=", "k", "[", "batch_index", "]", "\n", "dcg", "=", "self", ".", "_dcg", "(", "\n", "rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "\n", "target_relevance", "[", "batch_index", "]", ",", "\n", ")", "\n", "best_dcg", "=", "self", ".", "_dcg", "(", "\n", "best_rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "\n", "target_relevance", "[", "batch_index", "]", ",", "\n", ")", "\n", "batch_ndcg", ".", "append", "(", "dcg", "/", "best_dcg", ")", "\n", "\n", "", "self", ".", "_ndcg_denominator", "+=", "batch_size", "\n", "self", ".", "_ndcg_numerator", "+=", "sum", "(", "batch_ndcg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG._dcg": [[159, 163], ["relevance[].cpu().float", "torch.log2", "torch.sum", "relevance[].cpu", "torch.arange().float", "torch.arange", "len"], "methods", ["None"], ["", "def", "_dcg", "(", "self", ",", "rankings", ":", "torch", ".", "Tensor", ",", "relevance", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "sorted_relevance", "=", "relevance", "[", "rankings", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "discounts", "=", "torch", ".", "log2", "(", "torch", ".", "arange", "(", "len", "(", "rankings", ")", ")", ".", "float", "(", ")", "+", "2", ")", "\n", "return", "torch", ".", "sum", "(", "sorted_relevance", "/", "discounts", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.retrieve": [[164, 175], ["metrics.NDCG.reset", "float"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.reset"], ["", "def", "retrieve", "(", "self", ",", "reset", ":", "bool", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "_ndcg_denominator", ">", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "\"ndcg\"", ":", "float", "(", "self", ".", "_ndcg_numerator", "/", "self", ".", "_ndcg_denominator", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.NDCG.reset": [[176, 179], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.metrics.scores_to_ranks": [[26, 45], ["scores.view.size", "scores.view.view", "scores.view.sort", "ranked_idx.clone().fill_", "range", "ranks.view.view", "ranked_idx.size", "range", "ranked_idx.clone"], "function", ["None"], ["def", "scores_to_ranks", "(", "scores", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Convert model output scores into ranks.\"\"\"", "\n", "batch_size", ",", "num_rounds", ",", "num_options", "=", "scores", ".", "size", "(", ")", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "num_options", ")", "\n", "\n", "# sort in descending order - largest score gets highest rank", "\n", "sorted_ranks", ",", "ranked_idx", "=", "scores", ".", "sort", "(", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# i-th position in ranked_idx specifies which score shall take this", "\n", "# position but we want i-th position to have rank of score at that", "\n", "# position, do this conversion", "\n", "ranks", "=", "ranked_idx", ".", "clone", "(", ")", ".", "fill_", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "ranked_idx", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "ranks", "[", "i", "]", "[", "ranked_idx", "[", "i", "]", "[", "j", "]", "]", "=", "j", "\n", "# convert from 0-99 ranks to 1-100 ranks", "\n", "", "", "ranks", "+=", "1", "\n", "ranks", "=", "ranks", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "return", "ranks", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.model.EncoderDecoderModel.__init__": [[13, 17], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.visdialch.model.EncoderDecoderModel.forward": [[18, 22], ["model.EncoderDecoderModel.encoder", "model.EncoderDecoderModel.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "encoder_output", ",", "num_usage", "=", "self", ".", "encoder", "(", "batch", ")", "\n", "decoder_output", "=", "self", ".", "decoder", "(", "encoder_output", ",", "batch", ")", "\n", "return", "decoder_output", ",", "num_usage", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.__init__": [[10, 17], ["os.path.dirname", "open", "os.path.exists", "os.mkdir"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "output_name", ")", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "output_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dirname", ")", "\n", "\n", "", "self", ".", "log_file", "=", "open", "(", "output_name", ",", "'w'", ")", "\n", "self", ".", "infos", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append": [[18, 21], ["logging.Logger.infos.setdefault", "logging.Logger.append"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "append", "(", "self", ",", "key", ",", "val", ")", ":", "\n", "        ", "vals", "=", "self", ".", "infos", ".", "setdefault", "(", "key", ",", "[", "]", ")", "\n", "vals", ".", "append", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.log": [[22, 31], ["logging.Logger.infos.iteritems", "logging.Logger.log_file.write", "logging.Logger.log_file.flush", "msgs.append", "np.mean"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.write", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "log", "(", "self", ",", "extra_msg", "=", "''", ")", ":", "\n", "        ", "msgs", "=", "[", "extra_msg", "]", "\n", "for", "key", ",", "vals", "in", "self", ".", "infos", ".", "iteritems", "(", ")", ":", "\n", "            ", "msgs", ".", "append", "(", "'%s %.6f'", "%", "(", "key", ",", "np", ".", "mean", "(", "vals", ")", ")", ")", "\n", "", "msg", "=", "'\\n'", ".", "join", "(", "msgs", ")", "\n", "self", ".", "log_file", ".", "write", "(", "msg", "+", "'\\n'", ")", "\n", "self", ".", "log_file", ".", "flush", "(", ")", "\n", "self", ".", "infos", "=", "{", "}", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.write": [[32, 36], ["logging.Logger.log_file.write", "logging.Logger.log_file.flush", "print"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.write"], ["", "def", "write", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "log_file", ".", "write", "(", "msg", "+", "'\\n'", ")", "\n", "self", ".", "log_file", ".", "flush", "(", ")", "\n", "print", "(", "msg", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.initialization.initialize_model_weights": [[3, 31], ["print", "model.named_parameters", "print", "print", "param.data.zero_", "name.split", "len", "name.split", "param.size", "torch.nn.init.xavier_normal_", "name.split", "torch.nn.init.kaiming_normal_", "torch.nn.init.xavier_normal_", "name.split", "torch.nn.init.kaiming_normal_"], "function", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.split", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.split", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.split", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.split"], ["def", "initialize_model_weights", "(", "model", ",", "initialization", "=", "\"he\"", ",", "lstm_initialization", "=", "\"he\"", ")", ":", "\n", "    ", "if", "initialization", "==", "\"he\"", ":", "\n", "        ", "print", "(", "\"kaiming normal initialization.\"", ")", "\n", "", "elif", "initialization", "==", "\"xavier\"", ":", "\n", "        ", "print", "(", "\"xavier normal initialization.\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"default initialization, no changes made.\"", ")", "\n", "", "if", "(", "initialization", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "# Bias params", "\n", "            ", "if", "(", "\"bias\"", "in", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ")", ":", "\n", "                ", "param", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "# Batchnorm weight params", "\n", "", "elif", "(", "\"weight\"", "in", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "and", "len", "(", "param", ".", "size", "(", ")", ")", "==", "1", ")", ":", "\n", "                ", "continue", "\n", "# LSTM weight params", "\n", "", "elif", "(", "\"weight\"", "in", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "and", "\"lstm\"", "in", "name", ")", ":", "\n", "                ", "if", "\"xavier\"", "in", "lstm_initialization", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "param", ")", "\n", "", "elif", "\"he\"", "in", "lstm_initialization", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "param", ")", "\n", "# Other weight params", "\n", "", "", "elif", "(", "\"weight\"", "in", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "and", "\"lstm\"", "not", "in", "name", ")", ":", "\n", "                ", "if", "\"xavier\"", "in", "initialization", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "param", ")", "\n", "", "elif", "\"he\"", "in", "initialization", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "param", ")", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager.__init__": [[57, 81], ["pathlib.Path", "checkpointing.CheckpointManager.init_directory", "isinstance", "TypeError", "isinstance", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager.init_directory"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "checkpoint_dirpath", ",", "\n", "step_size", "=", "1", ",", "\n", "last_epoch", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"{} is not a Module\"", ".", "format", "(", "type", "(", "model", ")", ".", "__name__", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "optimizer", ",", "optim", ".", "Optimizer", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"{} is not an Optimizer\"", ".", "format", "(", "type", "(", "optimizer", ")", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "ckpt_dirpath", "=", "Path", "(", "checkpoint_dirpath", ")", "\n", "self", ".", "step_size", "=", "step_size", "\n", "self", ".", "last_epoch", "=", "last_epoch", "\n", "self", ".", "init_directory", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager.init_directory": [[82, 101], ["checkpointing.CheckpointManager.ckpt_dirpath.mkdir", "subprocess.Popen", "subprocess.Popen.communicate", "commit_sha.decode().strip().replace.decode().strip().replace.decode().strip().replace", "commit_sha_filepath.touch", "yaml.dump", "open", "commit_sha.decode().strip().replace.decode().strip().replace.decode().strip", "str", "commit_sha.decode().strip().replace.decode().strip().replace.decode"], "methods", ["None"], ["", "def", "init_directory", "(", "self", ",", "config", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialize empty checkpoint directory and record commit SHA\n        in it. Also save hyper-parameters config in this directory to\n        associate checkpoints with their hyper-parameters.\n        \"\"\"", "\n", "\n", "self", ".", "ckpt_dirpath", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# save current git commit hash in this checkpoint directory", "\n", "commit_sha_subprocess", "=", "Popen", "(", "\n", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--short\"", ",", "\"HEAD\"", "]", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", "\n", ")", "\n", "commit_sha", ",", "_", "=", "commit_sha_subprocess", ".", "communicate", "(", ")", "\n", "commit_sha", "=", "commit_sha", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "commit_sha_filepath", "=", "self", ".", "ckpt_dirpath", "/", "f\".commit-{commit_sha}\"", "\n", "commit_sha_filepath", ".", "touch", "(", ")", "\n", "yaml", ".", "dump", "(", "\n", "config", ",", "\n", "open", "(", "str", "(", "self", ".", "ckpt_dirpath", "/", "\"config.yml\"", ")", ",", "\"w\"", ")", ",", "\n", "default_flow_style", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager.step": [[103, 117], ["torch.save", "checkpointing.CheckpointManager._model_state_dict", "checkpointing.CheckpointManager.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.save", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager._model_state_dict"], ["", "def", "step", "(", "self", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "\"\"\"Save checkpoint if step size conditions meet. \"\"\"", "\n", "\n", "if", "not", "epoch", ":", "\n", "            ", "epoch", "=", "self", ".", "last_epoch", "+", "1", "\n", "", "self", ".", "last_epoch", "=", "epoch", "\n", "\n", "if", "not", "self", ".", "last_epoch", "%", "self", ".", "step_size", ":", "\n", "            ", "torch", ".", "save", "(", "\n", "{", "\n", "\"model\"", ":", "self", ".", "_model_state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "self", ".", "ckpt_dirpath", "/", "f\"checkpoint_{self.last_epoch}.pth\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.CheckpointManager._model_state_dict": [[119, 125], ["isinstance", "checkpointing.CheckpointManager.model.module.state_dict", "checkpointing.CheckpointManager.model.state_dict"], "methods", ["None"], ["", "", "def", "_model_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns state dict of model, taking care of DataParallel case.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "return", "self", ".", "model", ".", "module", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.checkpointing.load_checkpoint": [[127, 180], ["isinstance", "list", "torch.load", "pathlib.Path", "pathlib.Path.resolve", "checkpoint_dirpath.glob", "len", "warnings.warn", "subprocess.Popen", "subprocess.Popen.communicate", "commit_sha.decode().strip().replace.decode().strip().replace", "warnings.warn", "commit_sha.decode().strip().replace.decode().strip", "commit_sha.decode().strip().replace.decode"], "function", ["None"], ["", "", "", "def", "load_checkpoint", "(", "checkpoint_pthpath", ")", ":", "\n", "    ", "\"\"\"Given a path to saved checkpoint, load corresponding state dicts\n    of model and optimizer from it. This method checks if the current\n    commit SHA of codebase matches the commit SHA recorded when this\n    checkpoint was saved by checkpoint manager.\n\n    Parameters\n    ----------\n    checkpoint_pthpath: str or pathlib.Path\n        Path to saved checkpoint (as created by ``CheckpointManager``).\n\n    Returns\n    -------\n    nn.Module, optim.Optimizer\n        Model and optimizer state dicts loaded from checkpoint.\n\n    Raises\n    ------\n    UserWarning\n        If commit SHA do not match, or if the directory doesn't have\n        the recorded commit SHA.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "checkpoint_pthpath", ",", "str", ")", ":", "\n", "        ", "checkpoint_pthpath", "=", "Path", "(", "checkpoint_pthpath", ")", "\n", "", "checkpoint_dirpath", "=", "checkpoint_pthpath", ".", "resolve", "(", ")", ".", "parent", "\n", "checkpoint_commit_sha", "=", "list", "(", "checkpoint_dirpath", ".", "glob", "(", "\".commit-*\"", ")", ")", "\n", "\n", "if", "len", "(", "checkpoint_commit_sha", ")", "==", "0", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"Commit SHA was not recorded while saving checkpoints.\"", "\n", ")", "\n", "", "else", ":", "\n", "# verify commit sha, raise warning if it doesn't match", "\n", "        ", "commit_sha_subprocess", "=", "Popen", "(", "\n", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--short\"", ",", "\"HEAD\"", "]", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", "\n", ")", "\n", "commit_sha", ",", "_", "=", "commit_sha_subprocess", ".", "communicate", "(", ")", "\n", "commit_sha", "=", "commit_sha", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "\n", "# remove \".commit-\"", "\n", "checkpoint_commit_sha", "=", "checkpoint_commit_sha", "[", "0", "]", ".", "name", "[", "8", ":", "]", "\n", "\n", "if", "commit_sha", "!=", "checkpoint_commit_sha", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\"Current commit ({commit_sha}) and the commit \"", "\n", "f\"({checkpoint_commit_sha}) at which checkpoint was saved,\"", "\n", "\" are different. This might affect reproducibility.\"", "\n", ")", "\n", "\n", "# load encoder, decoder, optimizer state_dicts", "\n", "", "", "components", "=", "torch", ".", "load", "(", "checkpoint_pthpath", ")", "\n", "return", "components", "[", "\"model\"", "]", ",", "components", "[", "\"optimizer\"", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.cyclic_lr.__init__": [[9, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iter_per_epoch", ",", "base_lr", ",", "max_lr", ",", "epochs_per_cycle", "=", "2", ")", ":", "\n", "        ", "self", ".", "base_lr", "=", "base_lr", "\n", "self", ".", "max_lr", "=", "max_lr", "\n", "self", ".", "epochs_per_cycle", "=", "epochs_per_cycle", "\n", "self", ".", "iterations_per_epoch", "=", "iter_per_epoch", "\n", "self", ".", "step_size", "=", "(", "self", ".", "epochs_per_cycle", "*", "self", ".", "iterations_per_epoch", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.cyclic_lr.iteration": [[16, 18], ["None"], "methods", ["None"], ["", "def", "iteration", "(", "self", ",", "epoch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "epoch", "*", "self", ".", "iterations_per_epoch", "+", "batch_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.cyclic_lr.lr": [[19, 24], ["numpy.floor", "numpy.abs", "numpy.maximum", "scheduler.cyclic_lr.iteration", "scheduler.cyclic_lr.iteration"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.cyclic_lr.iteration", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.cyclic_lr.iteration"], ["", "def", "lr", "(", "self", ",", "epoch", ",", "batch_idx", ")", ":", "\n", "        ", "cycle", "=", "np", ".", "floor", "(", "1", "+", "self", ".", "iteration", "(", "epoch", ",", "batch_idx", ")", "/", "(", "2", "*", "self", ".", "step_size", ")", ")", "\n", "x", "=", "np", ".", "abs", "(", "self", ".", "iteration", "(", "epoch", ",", "batch_idx", ")", "/", "self", ".", "step_size", "-", "2", "*", "cycle", "+", "1", ")", "\n", "lr", "=", "self", ".", "base_lr", "+", "(", "self", ".", "max_lr", "-", "self", ".", "base_lr", ")", "*", "np", ".", "maximum", "(", "0", ",", "(", "1", "-", "x", ")", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.__init__": [[31, 38], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "lr_base", ",", "optimizer", ",", "data_size", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "lr_base", "=", "lr_base", "\n", "self", ".", "_rate", "=", "0", "\n", "self", ".", "data_size", "=", "data_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.step": [[40, 49], ["scheduler.WarmupOptimizer.rate", "scheduler.WarmupOptimizer.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.rate", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_step", "+=", "1", "\n", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.zero_grad": [[51, 53], ["scheduler.WarmupOptimizer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.WarmupOptimizer.rate": [[55, 69], ["int", "int", "int"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "\n", "", "if", "step", "<=", "int", "(", "self", ".", "data_size", "/", "self", ".", "batch_size", "*", "1", ")", ":", "\n", "            ", "r", "=", "self", ".", "lr_base", "*", "1", "/", "4.", "\n", "", "elif", "step", "<=", "int", "(", "self", ".", "data_size", "/", "self", ".", "batch_size", "*", "2", ")", ":", "\n", "            ", "r", "=", "self", ".", "lr_base", "*", "2", "/", "4.", "\n", "", "elif", "step", "<=", "int", "(", "self", ".", "data_size", "/", "self", ".", "batch_size", "*", "3", ")", ":", "\n", "            ", "r", "=", "self", ".", "lr_base", "*", "3", "/", "4.", "\n", "", "else", ":", "\n", "            ", "r", "=", "self", ".", "lr_base", "\n", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.get_optim": [[71, 85], ["scheduler.WarmupOptimizer", "torch.Adam", "filter", "model.parameters"], "function", ["None"], ["", "", "def", "get_optim", "(", "config", ",", "model", ",", "data_size", ",", "lr_base", "=", "None", ")", ":", "\n", "    ", "if", "lr_base", "is", "None", ":", "\n", "        ", "lr_base", "=", "config", "[", "\"solver\"", "]", "[", "\"initial_lr\"", "]", "\n", "\n", "", "return", "WarmupOptimizer", "(", "\n", "lr_base", ",", "\n", "Optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "0", ",", "\n", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "\n", "eps", "=", "1e-9", "\n", ")", ",", "\n", "data_size", ",", "\n", "config", "[", "\"solver\"", "]", "[", "\"batch_size\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.scheduler.adjust_lr": [[88, 90], ["None"], "function", ["None"], ["", "def", "adjust_lr", "(", "optim", ",", "decay_r", ")", ":", "\n", "    ", "optim", ".", "lr_base", "*=", "decay_r", "\n", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.dynamic_rnn.DynamicRNN.__init__": [[7, 10], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_model", "=", "rnn_model", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.dynamic_rnn.DynamicRNN.forward": [[11, 55], ["seq_input.size", "dynamic_rnn.DynamicRNN._get_sorted_order", "seq_input.index_select", "torch.nn.utils.rnn.pack_padded_sequence", "dynamic_rnn.DynamicRNN.rnn_model.flatten_parameters", "dynamic_rnn.DynamicRNN.rnn_model", "h_n[].index_select", "c_n[].index_select", "torch.nn.utils.rnn.pad_packed_sequence", "hx[].size"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.dynamic_rnn.DynamicRNN._get_sorted_order"], ["", "def", "forward", "(", "self", ",", "seq_input", ",", "seq_lens", ",", "initial_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"A wrapper over pytorch's rnn to handle sequences of variable length.\n\n        Arguments\n        ---------\n        seq_input : torch.Tensor\n            Input sequence tensor (padded) for RNN model.\n            Shape: (batch_size, max_sequence_length, embed_size)\n        seq_lens : torch.LongTensor\n            Length of sequences (b, )\n        initial_state : torch.Tensor\n            Initial (hidden, cell) states of RNN model.\n            \n        Returns\n        -------\n            Single tensor of shape (batch_size, rnn_hidden_size) corresponding\n            to the outputs of the RNN model at the last time step of each input\n            sequence.\n        \"\"\"", "\n", "max_sequence_length", "=", "seq_input", ".", "size", "(", "1", ")", "\n", "sorted_len", ",", "fwd_order", ",", "bwd_order", "=", "self", ".", "_get_sorted_order", "(", "seq_lens", ")", "\n", "sorted_seq_input", "=", "seq_input", ".", "index_select", "(", "0", ",", "fwd_order", ")", "\n", "packed_seq_input", "=", "pack_padded_sequence", "(", "\n", "sorted_seq_input", ",", "lengths", "=", "sorted_len", ",", "batch_first", "=", "True", "\n", ")", "\n", "\n", "if", "initial_state", "is", "not", "None", ":", "\n", "            ", "hx", "=", "initial_state", "\n", "assert", "hx", "[", "0", "]", ".", "size", "(", "0", ")", "==", "self", ".", "rnn_model", ".", "num_layers", "\n", "", "else", ":", "\n", "            ", "hx", "=", "None", "\n", "\n", "", "self", ".", "rnn_model", ".", "flatten_parameters", "(", ")", "\n", "outputs", ",", "(", "h_n", ",", "c_n", ")", "=", "self", ".", "rnn_model", "(", "packed_seq_input", ",", "hx", ")", "\n", "\n", "# pick hidden and cell states of last layer", "\n", "h_n", "=", "h_n", "[", "-", "1", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwd_order", ")", "\n", "c_n", "=", "c_n", "[", "-", "1", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwd_order", ")", "\n", "\n", "outputs", "=", "pad_packed_sequence", "(", "\n", "outputs", ",", "batch_first", "=", "True", ",", "total_length", "=", "max_sequence_length", "\n", ")", "\n", "\n", "return", "outputs", ",", "(", "h_n", ",", "c_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.dynamic_rnn.DynamicRNN._get_sorted_order": [[56, 64], ["torch.sort", "torch.sort", "list", "lens.contiguous().view", "lens.contiguous"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_sorted_order", "(", "lens", ")", ":", "\n", "        ", "sorted_len", ",", "fwd_order", "=", "torch", ".", "sort", "(", "\n", "lens", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "0", ",", "descending", "=", "True", "\n", ")", "\n", "_", ",", "bwd_order", "=", "torch", ".", "sort", "(", "fwd_order", ")", "\n", "sorted_len", "=", "list", "(", "sorted_len", ")", "\n", "return", "sorted_len", ",", "fwd_order", ",", "bwd_order", "", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.decoders.disc.DiscriminativeDecoder.__init__": [[11, 29], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "visdialch.utils.DynamicRNN", "len"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__C", "=", "__C", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "__C", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "self", ".", "option_rnn", "=", "nn", ".", "LSTM", "(", "\n", "__C", "[", "\"word_embedding_size\"", "]", ",", "\n", "__C", "[", "\"hidden_size\"", "]", ",", "\n", "__C", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", ")", "\n", "\n", "# Options are variable length padded sequences, use DynamicRNN.", "\n", "self", ".", "option_rnn", "=", "DynamicRNN", "(", "self", ".", "option_rnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.decoders.disc.DiscriminativeDecoder.forward": [[30, 97], ["options.view.view.size", "options.view.view.view", "options_length.view.view.view", "options_length.view.view.nonzero().squeeze", "disc.DiscriminativeDecoder.word_embed", "disc.DiscriminativeDecoder.option_rnn", "torch.zeros", "encoder_output.view.view.unsqueeze().repeat", "encoder_output.view.view.view", "torch.sum", "scores.view.view.view", "disc.DiscriminativeDecoder.size", "options_length.view.view.nonzero", "encoder_output.view.view.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_output", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Given `encoder_output` + candidate option sequences, predict a score\n        for each option sequence.\n\n        Parameters\n        ----------\n        encoder_output: torch.Tensor\n            Output from the encoder through its forward pass.\n            (batch_size, num_rounds, lstm_hidden_size)\n        \"\"\"", "\n", "\n", "options", "=", "batch", "[", "\"opt\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "num_options", ",", "max_sequence_length", "=", "(", "\n", "options", ".", "size", "(", ")", "\n", ")", "\n", "options", "=", "options", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "max_sequence_length", "\n", ")", "\n", "\n", "options_length", "=", "batch", "[", "\"opt_len\"", "]", "\n", "options_length", "=", "options_length", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", "\n", ")", "\n", "\n", "# Pick options with non-zero length (relevant for test split).", "\n", "nonzero_options_length_indices", "=", "options_length", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "nonzero_options_length", "=", "options_length", "[", "nonzero_options_length_indices", "]", "\n", "nonzero_options", "=", "options", "[", "nonzero_options_length_indices", "]", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, max_sequence_length,", "\n", "#         word_embedding_size)", "\n", "# FOR TEST SPLIT, shape: (batch_size * 1, num_options,", "\n", "#                         max_sequence_length, word_embedding_size)", "\n", "nonzero_options_embed", "=", "self", ".", "word_embed", "(", "nonzero_options", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, lstm_hidden_size)", "\n", "# FOR TEST SPLIT, shape: (batch_size * 1, num_options,", "\n", "#                         lstm_hidden_size)", "\n", "_", ",", "(", "nonzero_options_embed", ",", "_", ")", "=", "self", ".", "option_rnn", "(", "\n", "nonzero_options_embed", ",", "nonzero_options_length", "\n", ")", "\n", "\n", "options_embed", "=", "torch", ".", "zeros", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "\n", "nonzero_options_embed", ".", "size", "(", "-", "1", ")", ",", "\n", "device", "=", "nonzero_options_embed", ".", "device", ",", "\n", ")", "\n", "options_embed", "[", "nonzero_options_length_indices", "]", "=", "nonzero_options_embed", "\n", "\n", "# Repeat encoder output for every option.", "\n", "# shape: (batch_size, num_rounds, num_options, max_sequence_length)", "\n", "encoder_output", "=", "encoder_output", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "\n", "1", ",", "1", ",", "num_options", ",", "1", "\n", ")", "\n", "\n", "# Shape now same as `options`, can calculate dot product similarity.", "\n", "# shape: (batch_size * num_rounds * num_options, lstm_hidden_state)", "\n", "encoder_output", "=", "encoder_output", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "\n", "self", ".", "__C", "[", "\"hidden_size\"", "]", ",", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options)", "\n", "scores", "=", "torch", ".", "sum", "(", "options_embed", "*", "encoder_output", ",", "1", ")", "\n", "# shape: (batch_size, num_rounds, num_options)", "\n", "scores", "=", "scores", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.decoders.gen.GenerativeDecoder.__init__": [[11, 34], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.LogSoftmax", "len", "len"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "self", ".", "answer_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"lstm_dropout\"", "]", ",", "\n", ")", "\n", "\n", "self", ".", "lstm_to_words", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", ",", "len", "(", "vocabulary", ")", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"lstm_dropout\"", "]", ")", "\n", "self", ".", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.decoders.gen.GenerativeDecoder.forward": [[35, 137], ["ans_in.view.view.size", "ans_in.view.view.view", "gen.GenerativeDecoder.word_embed", "encoder_output.view", "init_hidden.repeat.repeat.repeat", "torch.zeros_like", "gen.GenerativeDecoder.answer_rnn", "gen.GenerativeDecoder.dropout", "gen.GenerativeDecoder.lstm_to_words", "ans_in.view.view.size", "ans_in.view.view.view", "gen.GenerativeDecoder.word_embed", "encoder_output.view", "init_hidden.repeat.repeat.repeat", "init_hidden.repeat.repeat.view", "init_hidden.repeat.repeat.repeat", "torch.zeros_like", "gen.GenerativeDecoder.answer_rnn", "gen.GenerativeDecoder.logsoftmax", "batch[].view", "torch.gather().squeeze", "torch.sum", "ans_scores.view.view.view", "gen.GenerativeDecoder.lstm_to_words", "torch.gather", "batch[].view.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_output", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Given `encoder_output`, learn to autoregressively predict\n        ground-truth answer word-by-word during training.\n\n        During evaluation, assign log-likelihood scores to all answer options.\n\n        Parameters\n        ----------\n        encoder_output: torch.Tensor\n            Output from the encoder through its forward pass.\n            (batch_size, num_rounds, lstm_hidden_size)\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "\n", "            ", "ans_in", "=", "batch", "[", "\"ans_in\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "max_sequence_length", "=", "ans_in", ".", "size", "(", ")", "\n", "\n", "ans_in", "=", "ans_in", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "max_sequence_length", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         word_embedding_size)", "\n", "ans_in_embed", "=", "self", ".", "word_embed", "(", "ans_in", ")", "\n", "\n", "# reshape encoder output to be set as initial hidden state of LSTM.", "\n", "# shape: (lstm_num_layers, batch_size * num_rounds,", "\n", "#         lstm_hidden_size)", "\n", "init_hidden", "=", "encoder_output", ".", "view", "(", "1", ",", "batch_size", "*", "num_rounds", ",", "-", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "\n", "self", ".", "config", "[", "\"lstm_num_layers\"", "]", ",", "1", ",", "1", "\n", ")", "\n", "init_cell", "=", "torch", ".", "zeros_like", "(", "init_hidden", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         lstm_hidden_size)", "\n", "ans_out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "answer_rnn", "(", "\n", "ans_in_embed", ",", "(", "init_hidden", ",", "init_cell", ")", "\n", ")", "\n", "ans_out", "=", "self", ".", "dropout", "(", "ans_out", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         vocabulary_size)", "\n", "ans_word_scores", "=", "self", ".", "lstm_to_words", "(", "ans_out", ")", "\n", "return", "ans_word_scores", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "ans_in", "=", "batch", "[", "\"opt_in\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "num_options", ",", "max_sequence_length", "=", "(", "\n", "ans_in", ".", "size", "(", ")", "\n", ")", "\n", "\n", "ans_in", "=", "ans_in", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "max_sequence_length", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, max_sequence_length", "\n", "#         word_embedding_size)", "\n", "ans_in_embed", "=", "self", ".", "word_embed", "(", "ans_in", ")", "\n", "\n", "# reshape encoder output to be set as initial hidden state of LSTM.", "\n", "# shape: (lstm_num_layers, batch_size * num_rounds * num_options,", "\n", "#         lstm_hidden_size)", "\n", "init_hidden", "=", "encoder_output", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "1", ",", "-", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "1", ",", "1", ",", "num_options", ",", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "view", "(", "\n", "1", ",", "batch_size", "*", "num_rounds", "*", "num_options", ",", "-", "1", "\n", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "\n", "self", ".", "config", "[", "\"lstm_num_layers\"", "]", ",", "1", ",", "1", "\n", ")", "\n", "init_cell", "=", "torch", ".", "zeros_like", "(", "init_hidden", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length, lstm_hidden_size)", "\n", "ans_out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "answer_rnn", "(", "\n", "ans_in_embed", ",", "(", "init_hidden", ",", "init_cell", ")", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length, vocabulary_size)", "\n", "ans_word_scores", "=", "self", ".", "logsoftmax", "(", "self", ".", "lstm_to_words", "(", "ans_out", ")", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length)", "\n", "target_ans_out", "=", "batch", "[", "\"opt_out\"", "]", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "-", "1", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length)", "\n", "ans_word_scores", "=", "torch", ".", "gather", "(", "\n", "ans_word_scores", ",", "-", "1", ",", "target_ans_out", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", ")", "\n", "ans_word_scores", "=", "(", "\n", "ans_word_scores", "*", "(", "target_ans_out", ">", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", ")", "# ugly", "\n", "\n", "ans_scores", "=", "torch", ".", "sum", "(", "ans_word_scores", ",", "-", "1", ")", "\n", "ans_scores", "=", "ans_scores", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "\n", "return", "ans_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.decoders.__init__.Decoder": [[5, 8], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.__init__": [[16, 60], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "net_utils.LayerNorm", "net_utils.LayerNorm", "sgln.AttFlat", "sgln.AttFlat", "sgln.AttFlat", "sgln.AttFlat", "module.NodeEmbeddingModule", "module.NodeEmbeddingModule", "module.SparseGraphLearningModule", "len"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__C", "=", "__C", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "num_embeddings", "=", "len", "(", "vocabulary", ")", ",", "\n", "embedding_dim", "=", "__C", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", "\n", ")", "\n", "\n", "self", ".", "h_rnn", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "__C", "[", "\"word_embedding_size\"", "]", ",", "\n", "hidden_size", "=", "__C", "[", "\"hidden_size\"", "]", ",", "\n", "num_layers", "=", "__C", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", ")", "\n", "self", ".", "q_rnn", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "__C", "[", "\"word_embedding_size\"", "]", ",", "\n", "hidden_size", "=", "__C", "[", "\"hidden_size\"", "]", ",", "\n", "num_layers", "=", "__C", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "\n", "__C", "[", "\"img_feature_size\"", "]", ",", "\n", "__C", "[", "\"hidden_size\"", "]", "\n", ")", "\n", "self", ".", "j_proj", "=", "nn", ".", "Linear", "(", "\n", "__C", "[", "\"hidden_size\"", "]", ",", "\n", "__C", "[", "\"hidden_size\"", "]", "\n", ")", "\n", "\n", "self", ".", "q_norm", "=", "LayerNorm", "(", "__C", "[", "'flat_out_size'", "]", ")", "\n", "self", ".", "h_norm", "=", "LayerNorm", "(", "__C", "[", "'flat_out_size'", "]", ")", "\n", "\n", "self", ".", "q_attflat_lang", "=", "AttFlat", "(", "__C", ")", "\n", "self", ".", "q_attflat_img", "=", "AttFlat", "(", "__C", ")", "\n", "\n", "self", ".", "h_attflat_lang", "=", "AttFlat", "(", "__C", ")", "\n", "self", ".", "h_attflat_img", "=", "AttFlat", "(", "__C", ")", "\n", "\n", "self", ".", "q_nem", "=", "NodeEmbeddingModule", "(", "__C", ")", "\n", "self", ".", "h_nem", "=", "NodeEmbeddingModule", "(", "__C", ")", "\n", "self", ".", "sgm", "=", "SparseGraphLearningModule", "(", "__C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.make_mask": [[61, 66], ["torch.sum", "torch.abs"], "methods", ["None"], ["", "def", "make_mask", "(", "self", ",", "feature", ")", ":", "\n", "        ", "return", "(", "torch", ".", "sum", "(", "\n", "torch", ".", "abs", "(", "feature", ")", ",", "\n", "dim", "=", "-", "1", "\n", ")", "==", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.lang_emb": [[67, 80], ["sgln.SGLN.make_mask", "sgln.SGLN.word_embed", "rnn_cls.flatten_parameters", "rnn_cls", "seq.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.make_mask"], ["", "def", "lang_emb", "(", "self", ",", "seq", ",", "lang_type", "=", "'ques'", ")", ":", "\n", "        ", "rnn_cls", "=", "None", "\n", "if", "lang_type", "==", "'hist'", ":", "\n", "            ", "rnn_cls", "=", "self", ".", "h_rnn", "\n", "", "if", "lang_type", "==", "'ques'", ":", "\n", "            ", "rnn_cls", "=", "self", ".", "q_rnn", "\n", "\n", "", "lang_feat_mask", "=", "self", ".", "make_mask", "(", "seq", ".", "unsqueeze", "(", "2", ")", ")", "\n", "lang_feat", "=", "self", ".", "word_embed", "(", "seq", ")", "\n", "\n", "rnn_cls", ".", "flatten_parameters", "(", ")", "\n", "lang_feat", ",", "_", "=", "rnn_cls", "(", "lang_feat", ")", "\n", "return", "lang_feat", ",", "lang_feat_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.forward": [[81, 169], ["sgln.SGLN.v_proj", "sgln.SGLN.make_mask", "q.size", "torch.autograd.Variable", "range", "torch.cat", "torch.cat", "sgln.SGLN.j_proj", "torch.tanh", "torch.zeros().cuda", "sgln.SGLN.lang_emb", "sgln.SGLN.lang_emb", "sgln.SGLN.q_nem", "sgln.SGLN.q_attflat_lang", "sgln.SGLN.q_attflat_img", "sgln.SGLN.q_norm", "sgln.SGLN.h_nem", "sgln.SGLN.h_attflat_lang", "sgln.SGLN.h_attflat_img", "sgln.SGLN.h_norm", "h_emb.unsqueeze.unsqueeze.unsqueeze", "q_emb.unsqueeze.unsqueeze.unsqueeze", "sgln.SGLN.sgm", "torch.autograd.Variable", "torch.cat", "torch.cat.append", "torch.autograd.Variable", "torch.cat", "torch.cat", "sgln.SGLN.sgm.update", "enc_outs.append", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.make_mask", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.lang_emb", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.SGLN.lang_emb", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SparseGraphLearningModule.update", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "q", "=", "batch", "[", "\"ques\"", "]", "# b x 10 x 20", "\n", "h", "=", "batch", "[", "\"hist\"", "]", "# b x 10 x 40", "\n", "v", "=", "batch", "[", "\"img_feat\"", "]", "# b x max_obj x 2048", "\n", "\n", "img_feat", "=", "self", ".", "v_proj", "(", "v", ")", "# b x 36 x 1024", "\n", "img_feat_mask", "=", "self", ".", "make_mask", "(", "img_feat", ")", "\n", "\n", "n_batch", ",", "n_round", ",", "_", "=", "q", ".", "size", "(", ")", "\n", "enc_outs", "=", "[", "]", "\n", "binary_strct", "=", "[", "]", "\n", "weighted_strct", "=", "Variable", "(", "torch", ".", "zeros", "(", "n_batch", ",", "1", ",", "n_round", "+", "1", ")", ".", "cuda", "(", ")", ")", "\n", "h_embs", "=", "None", "\n", "\n", "for", "i", "in", "range", "(", "n_round", ")", ":", "\n", "            ", "ques_feat", ",", "ques_feat_mask", "=", "self", ".", "lang_emb", "(", "q", "[", ":", ",", "i", ",", ":", "]", ",", "'ques'", ")", "\n", "hist_feat", ",", "hist_feat_mask", "=", "self", ".", "lang_emb", "(", "h", "[", ":", ",", "i", ",", ":", "]", ",", "'hist'", ")", "\n", "\n", "# question node embedding", "\n", "q_emb", ",", "qi_emb", "=", "self", ".", "q_nem", "(", "\n", "ques_feat", ",", "\n", "img_feat", ",", "\n", "ques_feat_mask", ",", "\n", "img_feat_mask", "\n", ")", "\n", "\n", "q_emb", "=", "self", ".", "q_attflat_lang", "(", "\n", "q_emb", ",", "\n", "ques_feat_mask", "\n", ")", "\n", "\n", "qi_emb", "=", "self", ".", "q_attflat_img", "(", "\n", "qi_emb", ",", "\n", "img_feat_mask", "\n", ")", "\n", "\n", "q_emb", "=", "self", ".", "q_norm", "(", "q_emb", "+", "qi_emb", ")", "\n", "\n", "# history node embedding", "\n", "h_emb", ",", "hi_emb", "=", "self", ".", "h_nem", "(", "\n", "hist_feat", ",", "\n", "img_feat", ",", "\n", "hist_feat_mask", ",", "\n", "img_feat_mask", "\n", ")", "\n", "\n", "h_emb", "=", "self", ".", "h_attflat_lang", "(", "\n", "h_emb", ",", "\n", "hist_feat_mask", "\n", ")", "\n", "\n", "hi_emb", "=", "self", ".", "h_attflat_img", "(", "\n", "hi_emb", ",", "\n", "img_feat_mask", "\n", ")", "\n", "\n", "h_emb", "=", "self", ".", "h_norm", "(", "h_emb", "+", "hi_emb", ")", "\n", "h_emb", "=", "h_emb", ".", "unsqueeze", "(", "1", ")", "\n", "q_emb", "=", "q_emb", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# stack each history node", "\n", "if", "i", "==", "0", ":", "h_embs", "=", "h_emb", "\n", "else", ":", "h_embs", "=", "torch", ".", "cat", "(", "(", "h_embs", ",", "h_emb", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# structural inference between question node and history node", "\n", "binary", ",", "w_att", "=", "self", ".", "sgm", "(", "q_emb", ",", "h_embs", ")", "\n", "\n", "# zero padding to binary structures for computing structural loss", "\n", "# making (n_batch x n_round x n_round) tensor", "\n", "b_pad", "=", "Variable", "(", "torch", ".", "zeros", "(", "n_batch", ",", "1", ",", "n_round", "-", "(", "i", "+", "1", ")", ")", ".", "cuda", "(", ")", ")", "\n", "binary", "=", "torch", ".", "cat", "(", "(", "binary", ",", "b_pad", ")", ",", "dim", "=", "2", ")", "\n", "binary_strct", ".", "append", "(", "binary", ")", "\n", "\n", "# zero padding to weighted structures for updating", "\n", "# making (n_batch x n_round+1 x n_round+1) tensor", "\n", "w_pad", "=", "Variable", "(", "torch", ".", "zeros", "(", "n_batch", ",", "1", ",", "n_round", "-", "i", ")", ".", "cuda", "(", ")", ")", "\n", "w_att", "=", "torch", ".", "cat", "(", "(", "w_att", ",", "w_pad", ")", ",", "dim", "=", "2", ")", "\n", "weighted_strct", "=", "torch", ".", "cat", "(", "(", "weighted_strct", ",", "w_att", ")", ",", "dim", "=", "1", ")", "\n", "\n", "adj", "=", "weighted_strct", "[", ":", ",", ":", ",", ":", "i", "+", "2", "]", "\n", "z", "=", "self", ".", "sgm", ".", "update", "(", "q_emb", ",", "h_embs", ",", "adj", ")", "\n", "enc_outs", ".", "append", "(", "z", ")", "\n", "\n", "", "binary_strct", "=", "torch", ".", "cat", "(", "binary_strct", ",", "dim", "=", "1", ")", "\n", "enc_out", "=", "torch", ".", "cat", "(", "enc_outs", ",", "dim", "=", "1", ")", "\n", "enc_out", "=", "self", ".", "j_proj", "(", "enc_out", ")", "\n", "enc_out", "=", "torch", ".", "tanh", "(", "enc_out", ")", "\n", "return", "enc_out", ",", "binary_strct", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.AttFlat.__init__": [[172, 187], ["torch.nn.Module.__init__", "net_utils.MLP", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "AttFlat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__C", "=", "__C", "\n", "\n", "self", ".", "mlp", "=", "MLP", "(", "\n", "in_size", "=", "__C", "[", "'hidden_size'", "]", ",", "\n", "mid_size", "=", "__C", "[", "'flat_mlp'", "]", ",", "\n", "out_size", "=", "__C", "[", "'flat_glimpses'", "]", ",", "\n", "dropout_r", "=", "__C", "[", "'model_dropout'", "]", ",", "\n", "use_relu", "=", "True", "\n", ")", "\n", "\n", "self", ".", "linear_merge", "=", "nn", ".", "Linear", "(", "\n", "__C", "[", "'hidden_size'", "]", "*", "__C", "[", "'flat_glimpses'", "]", ",", "\n", "__C", "[", "'flat_out_size'", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sgln.AttFlat.forward": [[189, 207], ["sgln.AttFlat.mlp", "torch.nn.functional.softmax.masked_fill", "torch.nn.functional.softmax", "range", "torch.cat", "sgln.AttFlat.linear_merge", "x_mask.squeeze().squeeze().unsqueeze", "att_list.append", "torch.sum", "x_mask.squeeze().squeeze", "x_mask.squeeze"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "att", "=", "self", ".", "mlp", "(", "x", ")", "\n", "att", "=", "att", ".", "masked_fill", "(", "\n", "x_mask", ".", "squeeze", "(", "1", ")", ".", "squeeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "-", "1e9", "\n", ")", "\n", "att", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "1", ")", "\n", "\n", "att_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "__C", "[", "'flat_glimpses'", "]", ")", ":", "\n", "            ", "att_list", ".", "append", "(", "\n", "torch", ".", "sum", "(", "att", "[", ":", ",", ":", ",", "i", ":", "i", "+", "1", "]", "*", "x", ",", "dim", "=", "1", ")", "\n", ")", "\n", "\n", "", "x_atted", "=", "torch", ".", "cat", "(", "att_list", ",", "dim", "=", "1", ")", "\n", "x_atted", "=", "self", ".", "linear_merge", "(", "x_atted", ")", "\n", "\n", "return", "x_atted", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.SANet.__init__": [[15, 25], ["torch.Module.__init__", "sparse.GumbelSoftmax", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "SANet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_head", "=", "8", "\n", "self", ".", "d_hid", "=", "__C", "[", "'hidden_size'", "]", "\n", "self", ".", "d_hid_head", "=", "__C", "[", "'hidden_size'", "]", "//", "8", "\n", "self", ".", "gs", "=", "GumbelSoftmax", "(", "d_in", "=", "self", ".", "d_hid_head", ",", "num_cls", "=", "2", ",", "dropout", "=", "__C", "[", "'model_dropout'", "]", ")", "\n", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "linear_k", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.SANet.attention": [[26, 35], ["logit.transpose.transpose.transpose", "sparse.SANet.gs", "q.unsqueeze", "k.unsqueeze", "logit.transpose.transpose.sum", "math.sqrt", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "q", ",", "k", ")", ":", "\n", "        ", "logit", "=", "q", ".", "unsqueeze", "(", "2", ")", "*", "k", ".", "unsqueeze", "(", "3", ")", "\n", "logit", "=", "logit", ".", "transpose", "(", "2", ",", "3", ")", "\n", "attn", "=", "logit", ".", "sum", "(", "-", "1", ")", "/", "math", ".", "sqrt", "(", "self", ".", "d_hid_head", ")", "\n", "\n", "binary", "=", "self", ".", "gs", "(", "logit", ")", "\n", "attn", "=", "attn", "*", "binary", "\n", "attn", "=", "F", ".", "normalize", "(", "attn", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "**", "2", "\n", "return", "binary", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.SANet.forward": [[36, 56], ["sparse.SANet.size", "sparse.SANet.linear_q().view().transpose", "sparse.SANet.linear_k().view().transpose", "sparse.SANet.attention", "binary.mean.mean.mean", "attn.mean.mean.mean", "sparse.SANet.linear_q().view", "sparse.SANet.linear_k().view", "sparse.SANet.linear_q", "sparse.SANet.linear_k"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.SANet.attention"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ")", ":", "\n", "        ", "n_batch", "=", "q", ".", "size", "(", "0", ")", "\n", "q", "=", "self", ".", "linear_q", "(", "q", ")", ".", "view", "(", "\n", "n_batch", ",", "\n", "-", "1", ",", "\n", "self", ".", "n_head", ",", "\n", "self", ".", "d_hid_head", "\n", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "k", "=", "self", ".", "linear_k", "(", "k", ")", ".", "view", "(", "\n", "n_batch", ",", "\n", "-", "1", ",", "\n", "self", ".", "n_head", ",", "\n", "self", ".", "d_hid_head", "\n", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "binary", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ")", "\n", "binary", "=", "binary", ".", "mean", "(", "dim", "=", "1", ")", "\n", "attn", "=", "attn", ".", "mean", "(", "dim", "=", "1", ")", "\n", "return", "binary", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.GumbelSoftmax.__init__": [[61, 72], ["torch.Module.__init__", "net_utils.MLP", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "num_cls", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_g", "=", "MLP", "(", "\n", "in_size", "=", "d_in", ",", "\n", "mid_size", "=", "d_in", "//", "2", ",", "\n", "out_size", "=", "num_cls", ",", "\n", "dropout_r", "=", "dropout", ",", "\n", "use_relu", "=", "True", "\n", ")", "\n", "\n", "self", ".", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.GumbelSoftmax.st_gumbel_softmax": [[73, 93], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.data.add_().log_().neg_", "torch.autograd.Variable.data.add_().log_().neg_", "torch.autograd.Variable.data.add_().log_().neg_", "torch.autograd.Variable.data.add_().log_().neg_", "torch.autograd.Variable.data.add_().log_().neg_", "torch.autograd.Variable.data.add_().log_().neg_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.view.scatter_", "y_hard.view.view.view", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "ind.view", "torch.autograd.Variable.data.add_().log_", "torch.autograd.Variable.data.add_().log_", "torch.autograd.Variable.data.add_().log_", "torch.autograd.Variable.data.add_().log_", "torch.autograd.Variable.data.add_().log_", "torch.autograd.Variable.data.add_().log_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "x.size", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.add_"], "methods", ["None"], ["", "def", "st_gumbel_softmax", "(", "self", ",", "x", ",", "temperature", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Straight Throught Gumbel Softmax\n        '''", "\n", "eps", "=", "1e-20", "\n", "noise", "=", "Variable", "(", "torch", ".", "rand", "(", "x", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "noise", ".", "data", ".", "add_", "(", "eps", ")", ".", "log_", "(", ")", ".", "neg_", "(", ")", "\n", "noise", ".", "data", ".", "add_", "(", "eps", ")", ".", "log_", "(", ")", ".", "neg_", "(", ")", "\n", "\n", "y", "=", "(", "x", "+", "noise", ")", "/", "temperature", "\n", "y", "=", "F", ".", "softmax", "(", "y", ",", "dim", "=", "-", "1", ")", "\n", "\n", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "y_hard", "=", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "return", "y_hard", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.GumbelSoftmax.forward": [[94, 105], ["sparse.GumbelSoftmax.linear_g", "sparse.GumbelSoftmax.logsoftmax", "sparse.GumbelSoftmax.st_gumbel_softmax", "sparse.GumbelSoftmax.detach().max", "sparse.GumbelSoftmax.detach().clone().zero_().scatter_", "sparse.GumbelSoftmax.detach", "sparse.GumbelSoftmax.detach().clone().zero_", "sparse.GumbelSoftmax.detach().clone", "sparse.GumbelSoftmax.detach"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.sparse.GumbelSoftmax.st_gumbel_softmax"], ["", "def", "forward", "(", "self", ",", "rel", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear_g", "(", "rel", ")", "\n", "x", "=", "self", ".", "logsoftmax", "(", "x", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "mask", "=", "self", ".", "st_gumbel_softmax", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "ind", "=", "x", ".", "detach", "(", ")", ".", "max", "(", "4", ",", "keepdim", "=", "True", ")", "\n", "mask", "=", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", ".", "scatter_", "(", "4", ",", "ind", ",", "1", ")", "\n", "", "mask", "=", "mask", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "1", "]", "\n", "return", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.FC.__init__": [[9, 21], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "dropout_r", "=", "0.", ",", "use_relu", "=", "True", ")", ":", "\n", "        ", "super", "(", "FC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_r", "=", "dropout_r", "\n", "self", ".", "use_relu", "=", "use_relu", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", "\n", "\n", "if", "use_relu", ":", "\n", "            ", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "", "if", "dropout_r", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.FC.forward": [[22, 32], ["net_utils.FC.linear", "net_utils.FC.relu", "net_utils.FC.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "\n", "if", "self", ".", "use_relu", ":", "\n", "            ", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "dropout_r", ">", "0", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.MLP.__init__": [[34, 39], ["torch.Module.__init__", "net_utils.FC", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_size", ",", "mid_size", ",", "out_size", ",", "dropout_r", "=", "0.", ",", "use_relu", "=", "True", ")", ":", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fc", "=", "FC", "(", "in_size", ",", "mid_size", ",", "dropout_r", "=", "dropout_r", ",", "use_relu", "=", "use_relu", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "mid_size", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.MLP.forward": [[40, 42], ["net_utils.MLP.linear", "net_utils.MLP.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "linear", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.LayerNorm.__init__": [[45, 51], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "size", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.net_utils.LayerNorm.forward": [[52, 57], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.NodeEmbeddingModule.__init__": [[14, 18], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "module.SA", "module.SGA", "range", "range"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "NodeEmbeddingModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "enc_list", "=", "nn", ".", "ModuleList", "(", "[", "SA", "(", "__C", ")", "for", "_", "in", "range", "(", "__C", "[", "'transformer_num_layers'", "]", ")", "]", ")", "\n", "self", ".", "dec_list", "=", "nn", ".", "ModuleList", "(", "[", "SGA", "(", "__C", ")", "for", "_", "in", "range", "(", "__C", "[", "'transformer_num_layers'", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.NodeEmbeddingModule.forward": [[19, 28], ["enc", "dec"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "x_mask", ",", "y_mask", ")", ":", "\n", "# Get hidden vector", "\n", "        ", "for", "enc", "in", "self", ".", "enc_list", ":", "\n", "            ", "x", "=", "enc", "(", "x", ",", "x_mask", ")", "\n", "\n", "", "for", "dec", "in", "self", ".", "dec_list", ":", "\n", "            ", "y", "=", "dec", "(", "y", ",", "x", ",", "y_mask", ",", "x_mask", ")", "\n", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SparseGraphLearningModule.__init__": [[30, 34], ["torch.nn.Module.__init__", "sparse.SANet", "torch.nn.ModuleList", "torch.nn.ModuleList", "module.UP", "range"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "SparseGraphLearningModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sparse", "=", "SANet", "(", "__C", ")", "\n", "self", ".", "upm", "=", "nn", ".", "ModuleList", "(", "[", "UP", "(", "__C", ")", "for", "_", "in", "range", "(", "__C", "[", "'sgl_update_num_layers'", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SparseGraphLearningModule.forward": [[35, 38], ["module.SparseGraphLearningModule.sparse"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "binary", ",", "w_att", "=", "self", ".", "sparse", "(", "x", ",", "y", ")", "\n", "return", "binary", ",", "w_att", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SparseGraphLearningModule.update": [[39, 45], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "up"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "x", ",", "y", ",", "adj", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "y", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "for", "up", "in", "self", ".", "upm", ":", "\n", "            ", "x", "=", "up", "(", "x", ",", "adj", ")", "\n", "\n", "", "return", "x", "[", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.UP.__init__": [[48, 55], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm", "net_utils.LayerNorm", "module.FFN"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "UP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm1", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "ffn", "=", "FFN", "(", "__C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.UP.forward": [[56, 61], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "module.UP.norm1", "module.UP.norm2", "module.UP.dropout1", "module.UP.dropout2", "module.UP.ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "adj", ")", ":", "\n", "        ", "output", "=", "torch", ".", "matmul", "(", "adj", ",", "x", ")", "\n", "x", "=", "self", ".", "norm1", "(", "x", "+", "self", ".", "dropout1", "(", "output", ")", ")", "\n", "x", "=", "self", ".", "norm2", "(", "x", "+", "self", ".", "dropout2", "(", "self", ".", "ffn", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.MHAtt.__init__": [[71, 81], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "MHAtt", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__C", "=", "__C", "\n", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "linear_k", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "self", ".", "linear_merge", "=", "nn", ".", "Linear", "(", "__C", "[", "'hidden_size'", "]", ",", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.MHAtt.forward": [[82, 116], ["module.MHAtt.size", "module.MHAtt.linear_v().view().transpose", "module.MHAtt.linear_k().view().transpose", "module.MHAtt.linear_q().view().transpose", "module.MHAtt.att", "module.MHAtt.transpose().contiguous().view", "module.MHAtt.linear_merge", "module.MHAtt.linear_v().view", "module.MHAtt.linear_k().view", "module.MHAtt.linear_q().view", "module.MHAtt.transpose().contiguous", "module.MHAtt.linear_v", "module.MHAtt.linear_k", "module.MHAtt.linear_q", "module.MHAtt.transpose"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.MHAtt.att"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", ")", ":", "\n", "        ", "n_batches", "=", "q", ".", "size", "(", "0", ")", "\n", "\n", "v", "=", "self", ".", "linear_v", "(", "v", ")", ".", "view", "(", "\n", "n_batches", ",", "\n", "-", "1", ",", "\n", "self", ".", "__C", "[", "'multi_head'", "]", ",", "\n", "self", ".", "__C", "[", "'hidden_size_head'", "]", "\n", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "k", "=", "self", ".", "linear_k", "(", "k", ")", ".", "view", "(", "\n", "n_batches", ",", "\n", "-", "1", ",", "\n", "self", ".", "__C", "[", "'multi_head'", "]", ",", "\n", "self", ".", "__C", "[", "'hidden_size_head'", "]", "\n", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "q", "=", "self", ".", "linear_q", "(", "q", ")", ".", "view", "(", "\n", "n_batches", ",", "\n", "-", "1", ",", "\n", "self", ".", "__C", "[", "'multi_head'", "]", ",", "\n", "self", ".", "__C", "[", "'hidden_size_head'", "]", "\n", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "atted", "=", "self", ".", "att", "(", "v", ",", "k", ",", "q", ",", "mask", ")", "\n", "atted", "=", "atted", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "n_batches", ",", "\n", "-", "1", ",", "\n", "self", ".", "__C", "[", "'hidden_size'", "]", "\n", ")", "\n", "\n", "atted", "=", "self", ".", "linear_merge", "(", "atted", ")", "\n", "\n", "return", "atted", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.MHAtt.att": [[117, 131], ["query.size", "torch.softmax", "torch.softmax", "module.MHAtt.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill.masked_fill", "key.transpose"], "methods", ["None"], ["", "def", "att", "(", "self", ",", "value", ",", "key", ",", "query", ",", "mask", ")", ":", "\n", "        ", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "\n", "\n", "scores", "=", "torch", ".", "matmul", "(", "\n", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e9", ")", "\n", "\n", "", "att_map", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "att_map", "=", "self", ".", "dropout", "(", "att_map", ")", "\n", "\n", "return", "torch", ".", "matmul", "(", "att_map", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.FFN.__init__": [[138, 147], ["torch.nn.Module.__init__", "net_utils.MLP"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "FFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mlp", "=", "MLP", "(", "\n", "in_size", "=", "__C", "[", "'hidden_size'", "]", ",", "\n", "mid_size", "=", "__C", "[", "'hidden_size'", "]", "*", "4", ",", "\n", "out_size", "=", "__C", "[", "'hidden_size'", "]", ",", "\n", "dropout_r", "=", "__C", "[", "'model_dropout'", "]", ",", "\n", "use_relu", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.FFN.forward": [[149, 151], ["module.FFN.mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mlp", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SA.__init__": [[158, 169], ["torch.nn.Module.__init__", "module.MHAtt", "module.FFN", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "SA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mhatt", "=", "MHAtt", "(", "__C", ")", "\n", "self", ".", "ffn", "=", "FFN", "(", "__C", ")", "\n", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm1", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SA.forward": [[170, 180], ["module.SA.norm1", "module.SA.norm2", "module.SA.dropout1", "module.SA.dropout2", "module.SA.mhatt", "module.SA.ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "norm1", "(", "x", "+", "self", ".", "dropout1", "(", "\n", "self", ".", "mhatt", "(", "x", ",", "x", ",", "x", ",", "x_mask", ")", "\n", ")", ")", "\n", "\n", "x", "=", "self", ".", "norm2", "(", "x", "+", "self", ".", "dropout2", "(", "\n", "self", ".", "ffn", "(", "x", ")", "\n", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SGA.__init__": [[187, 202], ["torch.nn.Module.__init__", "module.MHAtt", "module.MHAtt", "module.FFN", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "net_utils.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "__C", ")", ":", "\n", "        ", "super", "(", "SGA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mhatt1", "=", "MHAtt", "(", "__C", ")", "\n", "self", ".", "mhatt2", "=", "MHAtt", "(", "__C", ")", "\n", "self", ".", "ffn", "=", "FFN", "(", "__C", ")", "\n", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm1", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "__C", "[", "'model_dropout'", "]", ")", "\n", "self", ".", "norm3", "=", "LayerNorm", "(", "__C", "[", "'hidden_size'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.module.SGA.forward": [[203, 217], ["module.SGA.norm1", "module.SGA.norm2", "module.SGA.norm3", "module.SGA.dropout1", "module.SGA.dropout2", "module.SGA.dropout3", "module.SGA.mhatt1", "module.SGA.mhatt2", "module.SGA.ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "x_mask", ",", "y_mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "norm1", "(", "x", "+", "self", ".", "dropout1", "(", "\n", "self", ".", "mhatt1", "(", "x", ",", "x", ",", "x", ",", "x_mask", ")", "\n", ")", ")", "\n", "\n", "x", "=", "self", ".", "norm2", "(", "x", "+", "self", ".", "dropout2", "(", "\n", "self", ".", "mhatt2", "(", "y", ",", "y", ",", "x", ",", "y_mask", ")", "\n", ")", ")", "\n", "\n", "x", "=", "self", ".", "norm3", "(", "x", "+", "self", ".", "dropout3", "(", "\n", "self", ".", "ffn", "(", "x", ")", "\n", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.encoders.__init__.Encoder": [[4, 9], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DialogsReader.__init__": [[40, 103], ["open", "open", "json.load", "readers.DialogsReader.questions.append", "readers.DialogsReader.answers.append", "json.load", "print", "tqdm.tqdm.tqdm", "print", "tqdm.tqdm.tqdm", "print", "tqdm.tqdm.tqdm", "json.load", "len", "range", "range", "nltk.tokenize.word_tokenize", "range", "nltk.tokenize.word_tokenize", "readers.DialogsReader.captions.items", "nltk.tokenize.word_tokenize", "open", "len", "dialog_for_image[].append", "len", "len", "len", "image_ids.index", "image_ids.index"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["def", "__init__", "(", "self", ",", "dialogs_jsonpath", ":", "str", ",", "coref_structure_jsonpath", ":", "str", ",", "answer_plausibility_jsonpath", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "with", "open", "(", "dialogs_jsonpath", ",", "\"r\"", ")", "as", "visdial_file", ":", "\n", "            ", "with", "open", "(", "coref_structure_jsonpath", ",", "\"r\"", ")", "as", "cd_file", ":", "\n", "                ", "visdial_data", "=", "json", ".", "load", "(", "visdial_file", ")", "\n", "self", ".", "_split", "=", "visdial_data", "[", "\"split\"", "]", "\n", "\n", "self", ".", "questions", "=", "visdial_data", "[", "\"data\"", "]", "[", "\"questions\"", "]", "\n", "self", ".", "answers", "=", "visdial_data", "[", "\"data\"", "]", "[", "\"answers\"", "]", "\n", "\n", "# Add empty question, answer at the end, useful for padding dialog rounds for test.", "\n", "self", ".", "questions", ".", "append", "(", "\"\"", ")", "\n", "self", ".", "answers", ".", "append", "(", "\"\"", ")", "\n", "\n", "# Image_id serves as key for all four dicts here.", "\n", "self", ".", "captions", "=", "{", "}", "\n", "self", ".", "dialogs", "=", "{", "}", "\n", "self", ".", "num_rounds", "=", "{", "}", "\n", "self", ".", "coref_dependencies", "=", "{", "}", "\n", "self", ".", "answer_plausibility", "=", "{", "}", "\n", "\n", "# Load sentence-level coreference dependency annotations.", "\n", "cd_data", "=", "json", ".", "load", "(", "cd_file", ")", "\n", "if", "'train'", "in", "self", ".", "_split", ":", "\n", "                    ", "ap_data", "=", "json", ".", "load", "(", "open", "(", "answer_plausibility_jsonpath", ",", "\"r\"", ")", ")", "\n", "", "image_ids", "=", "[", "entry", "[", "\"image_id\"", "]", "for", "entry", "in", "cd_data", "]", "\n", "\n", "for", "dialog_for_image", "in", "visdial_data", "[", "\"data\"", "]", "[", "\"dialogs\"", "]", ":", "\n", "                    ", "self", ".", "captions", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "dialog_for_image", "[", "\"caption\"", "]", "\n", "self", ".", "coref_dependencies", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "cd_data", "[", "image_ids", ".", "index", "(", "dialog_for_image", "[", "\"image_id\"", "]", ")", "]", "[", "\"coref_dependency\"", "]", "\n", "\n", "if", "'train'", "in", "self", ".", "_split", ":", "\n", "                        ", "self", ".", "answer_plausibility", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "ap_data", "[", "image_ids", ".", "index", "(", "dialog_for_image", "[", "\"image_id\"", "]", ")", "]", "[", "\"scores\"", "]", "\n", "\n", "# Record original length of dialog, before padding.", "\n", "# 10 for train and val splits, 10 or less for test split.", "\n", "", "self", ".", "num_rounds", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", "\n", "\n", "# Pad dialog at the end with empty question and answer pairs (for test split).", "\n", "while", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", "<", "10", ":", "\n", "                        ", "dialog_for_image", "[", "\"dialog\"", "]", ".", "append", "(", "{", "\"question\"", ":", "-", "1", ",", "\"answer\"", ":", "-", "1", "}", ")", "\n", "\n", "# Add empty answer /answer options if not provided (for test split).", "\n", "", "for", "i", "in", "range", "(", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", ")", ":", "\n", "                        ", "if", "\"answer\"", "not", "in", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", ":", "\n", "                            ", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", "[", "\"answer\"", "]", "=", "-", "1", "\n", "", "if", "\"answer_options\"", "not", "in", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", ":", "\n", "                            ", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", "[", "\"answer_options\"", "]", "=", "[", "-", "1", "]", "*", "100", "\n", "\n", "", "", "self", ".", "dialogs", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "dialog_for_image", "[", "\"dialog\"", "]", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing questions...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "questions", ")", ")", ")", ":", "\n", "                    ", "self", ".", "questions", "[", "i", "]", "=", "word_tokenize", "(", "self", ".", "questions", "[", "i", "]", "+", "\"?\"", ")", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing answers...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "answers", ")", ")", ")", ":", "\n", "                    ", "self", ".", "answers", "[", "i", "]", "=", "word_tokenize", "(", "self", ".", "answers", "[", "i", "]", ")", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing captions...\"", ")", "\n", "for", "image_id", ",", "caption", "in", "tqdm", "(", "self", ".", "captions", ".", "items", "(", ")", ")", ":", "\n", "                    ", "self", ".", "captions", "[", "image_id", "]", "=", "word_tokenize", "(", "caption", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DialogsReader.__len__": [[104, 106], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dialogs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DialogsReader.__getitem__": [[107, 138], ["copy.deepcopy", "range", "len", "enumerate"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "str", ",", "List", "]", "]", ":", "\n", "        ", "caption_for_image", "=", "self", ".", "captions", "[", "image_id", "]", "\n", "dialog_for_image", "=", "copy", ".", "deepcopy", "(", "self", ".", "dialogs", "[", "image_id", "]", ")", "\n", "num_rounds", "=", "self", ".", "num_rounds", "[", "image_id", "]", "\n", "coref_dependency", "=", "self", ".", "coref_dependencies", "[", "image_id", "]", "\n", "if", "'train'", "in", "self", ".", "_split", ":", "\n", "            ", "plausible_answer", "=", "self", ".", "answer_plausibility", "[", "image_id", "]", "\n", "\n", "# Replace question and answer indices with actual word tokens.", "\n", "", "for", "i", "in", "range", "(", "len", "(", "dialog_for_image", ")", ")", ":", "\n", "            ", "dialog_for_image", "[", "i", "]", "[", "\"question\"", "]", "=", "self", ".", "questions", "[", "dialog_for_image", "[", "i", "]", "[", "\"question\"", "]", "]", "\n", "dialog_for_image", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "answers", "[", "dialog_for_image", "[", "i", "]", "[", "\"answer\"", "]", "]", "\n", "for", "j", ",", "answer_option", "in", "enumerate", "(", "dialog_for_image", "[", "i", "]", "[", "\"answer_options\"", "]", ")", ":", "\n", "                ", "dialog_for_image", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "=", "self", ".", "answers", "[", "answer_option", "]", "\n", "\n", "", "", "if", "'train'", "in", "self", ".", "_split", ":", "\n", "            ", "return", "{", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"caption\"", ":", "caption_for_image", ",", "\n", "\"dialog\"", ":", "dialog_for_image", ",", "\n", "\"num_rounds\"", ":", "num_rounds", ",", "\n", "\"structures\"", ":", "coref_dependency", ",", "\n", "\"teacher_scores\"", ":", "plausible_answer", "\n", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"caption\"", ":", "caption_for_image", ",", "\n", "\"dialog\"", ":", "dialog_for_image", ",", "\n", "\"num_rounds\"", ":", "num_rounds", ",", "\n", "\"structures\"", ":", "coref_dependency", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DialogsReader.keys": [[140, 142], ["list", "readers.DialogsReader.dialogs.keys"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.keys"], ["", "", "def", "keys", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "list", "(", "self", ".", "dialogs", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DialogsReader.split": [[143, 146], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_split", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DenseAnnotationsReader.__init__": [[159, 163], ["open", "json.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dense_annotations_jsonpath", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "dense_annotations_jsonpath", ",", "\"r\"", ")", "as", "visdial_file", ":", "\n", "            ", "self", ".", "_visdial_data", "=", "json", ".", "load", "(", "visdial_file", ")", "\n", "self", ".", "_image_ids", "=", "[", "entry", "[", "\"image_id\"", "]", "for", "entry", "in", "self", ".", "_visdial_data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DenseAnnotationsReader.__len__": [[164, 166], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_image_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DenseAnnotationsReader.__getitem__": [[167, 171], ["readers.DenseAnnotationsReader._image_ids.index"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "List", "]", "]", ":", "\n", "        ", "index", "=", "self", ".", "_image_ids", ".", "index", "(", "image_id", ")", "\n", "# keys: {\"image_id\", \"round_id\", \"gt_relevance\"}", "\n", "return", "self", ".", "_visdial_data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.DenseAnnotationsReader.split": [[172, 176], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "# always", "\n", "        ", "return", "\"val\"", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.__init__": [[200, 210], ["h5py.File", "list", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "features_hdfpath", ":", "str", ",", "in_memory", ":", "bool", "=", "False", ")", ":", "\n", "        ", "self", ".", "features_hdfpath", "=", "features_hdfpath", "\n", "self", ".", "_in_memory", "=", "in_memory", "\n", "\n", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "            ", "self", ".", "_split", "=", "features_hdf", ".", "attrs", "[", "\"split\"", "]", "\n", "self", ".", "image_id_list", "=", "list", "(", "features_hdf", "[", "\"image_id\"", "]", ")", "\n", "# \"features\" is List[np.ndarray] if the dataset is loaded in-memory", "\n", "# If not loaded in memory, then list of None.", "\n", "self", ".", "features", "=", "[", "None", "]", "*", "len", "(", "self", ".", "image_id_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.__len__": [[212, 214], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_id_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.__getitem__": [[215, 231], ["readers.ImageFeaturesHdfReader.image_id_list.index", "h5py.File", "h5py.File"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", ":", "\n", "        ", "index", "=", "self", ".", "image_id_list", ".", "index", "(", "image_id", ")", "\n", "if", "self", ".", "_in_memory", ":", "\n", "# Load features during first epoch, all not loaded together as it has a slow start.", "\n", "            ", "if", "self", ".", "features", "[", "index", "]", "is", "not", "None", ":", "\n", "                ", "image_id_features", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "                ", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "                    ", "image_id_features", "=", "features_hdf", "[", "\"features\"", "]", "[", "index", "]", "\n", "self", ".", "features", "[", "index", "]", "=", "image_id_features", "\n", "", "", "", "else", ":", "\n", "# Read chunk from file everytime if not loaded in memory.", "\n", "            ", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "                ", "image_id_features", "=", "features_hdf", "[", "\"features\"", "]", "[", "index", "]", "\n", "\n", "", "", "return", "image_id_features", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.keys": [[232, 234], ["None"], "methods", ["None"], ["", "def", "keys", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "self", ".", "image_id_list", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.split": [[235, 238], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_split", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.__init__": [[42, 66], ["enumerate", "os.path.exists", "FileNotFoundError", "open", "json.load", "sorted", "vocabulary.Vocabulary.word2index.items", "sorted.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "word_counts_path", ":", "str", ",", "min_count", ":", "int", "=", "5", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "word_counts_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Word counts do not exist at {word_counts_path}\"", ")", "\n", "\n", "", "with", "open", "(", "word_counts_path", ",", "\"r\"", ")", "as", "word_counts_file", ":", "\n", "            ", "word_counts", "=", "json", ".", "load", "(", "word_counts_file", ")", "\n", "\n", "# form a list of (word, count) tuples and apply min_count threshold", "\n", "word_counts", "=", "[", "\n", "(", "word", ",", "count", ")", "for", "word", ",", "count", "in", "word_counts", ".", "items", "(", ")", "if", "count", ">=", "min_count", "\n", "]", "\n", "# sort in descending order of word counts", "\n", "word_counts", "=", "sorted", "(", "word_counts", ",", "key", "=", "lambda", "wc", ":", "-", "wc", "[", "1", "]", ")", "\n", "words", "=", "[", "w", "[", "0", "]", "for", "w", "in", "word_counts", "]", "\n", "\n", "", "self", ".", "word2index", "=", "{", "}", "\n", "self", ".", "word2index", "[", "self", ".", "PAD_TOKEN", "]", "=", "self", ".", "PAD_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "SOS_TOKEN", "]", "=", "self", ".", "SOS_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "EOS_TOKEN", "]", "=", "self", ".", "EOS_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "UNK_TOKEN", "]", "=", "self", ".", "UNK_INDEX", "\n", "for", "index", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "self", ".", "word2index", "[", "word", "]", "=", "index", "+", "4", "\n", "\n", "", "self", ".", "index2word", "=", "{", "index", ":", "word", "for", "word", ",", "index", "in", "self", ".", "word2index", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.from_saved": [[67, 79], ["open", "json.load", "cls.word2index.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_saved", "(", "cls", ",", "saved_vocabulary_path", ":", "str", ")", "->", "\"Vocabulary\"", ":", "\n", "        ", "\"\"\"Build the vocabulary from a json file saved by ``save`` method.\n\n        Parameters\n        ----------\n        saved_vocabulary_path : str\n            Path to a json file containing word to integer mappings (saved vocabulary).\n        \"\"\"", "\n", "with", "open", "(", "saved_vocabulary_path", ",", "\"r\"", ")", "as", "saved_vocabulary_file", ":", "\n", "            ", "cls", ".", "word2index", "=", "json", ".", "load", "(", "saved_vocabulary_file", ")", "\n", "", "cls", ".", "index2word", "=", "{", "index", ":", "word", "for", "word", ",", "index", "in", "cls", ".", "word2index", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices": [[80, 82], ["vocabulary.Vocabulary.word2index.get"], "methods", ["None"], ["", "def", "to_indices", "(", "self", ",", "words", ":", "List", "[", "str", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "self", ".", "word2index", ".", "get", "(", "word", ",", "self", ".", "UNK_INDEX", ")", "for", "word", "in", "words", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_words": [[83, 85], ["vocabulary.Vocabulary.index2word.get"], "methods", ["None"], ["", "def", "to_words", "(", "self", ",", "indices", ":", "List", "[", "int", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "index2word", ".", "get", "(", "index", ",", "self", ".", "UNK_TOKEN", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.save": [[86, 89], ["open", "json.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_vocabulary_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "with", "open", "(", "save_vocabulary_path", ",", "\"w\"", ")", "as", "save_vocabulary_file", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "word2index", ",", "saved_vocabulary_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.__len__": [[90, 92], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "index2word", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__": [[31, 81], ["torch.utils.data.Dataset.__init__", "visdialch.data.readers.DialogsReader", "visdialch.data.vocabulary.Vocabulary", "h5py.File", "_pickle.load", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "list", "visdialch.data.readers.DenseAnnotationsReader", "open", "numpy.array", "numpy.array", "numpy.array", "dataset.VisDialDataset.dialogs_reader.dialogs.keys", "h5py.File.get", "h5py.File.get", "h5py.File.get"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__init__", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.readers.ImageFeaturesHdfReader.keys"], ["def", "__init__", "(", "\n", "self", ",", "\n", "config", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "dialogs_jsonpath", ":", "str", ",", "\n", "coref_dependencies_jsonpath", ":", "str", ",", "\n", "answer_plausibility_jsonpath", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "dense_annotations_jsonpath", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "overfit", ":", "bool", "=", "False", ",", "\n", "in_memory", ":", "bool", "=", "False", ",", "\n", "return_options", ":", "bool", "=", "True", ",", "\n", "add_boundary_toks", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "return_options", "=", "return_options", "\n", "self", ".", "add_boundary_toks", "=", "add_boundary_toks", "\n", "self", ".", "dialogs_reader", "=", "DialogsReader", "(", "dialogs_jsonpath", ",", "coref_dependencies_jsonpath", ",", "answer_plausibility_jsonpath", ")", "\n", "\n", "if", "\"val\"", "in", "self", ".", "split", "and", "dense_annotations_jsonpath", "is", "not", "None", ":", "\n", "            ", "self", ".", "annotations_reader", "=", "DenseAnnotationsReader", "(", "\n", "dense_annotations_jsonpath", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "annotations_reader", "=", "None", "\n", "\n", "", "self", ".", "vocabulary", "=", "Vocabulary", "(", "\n", "config", "[", "\"word_counts_json\"", "]", ",", "min_count", "=", "config", "[", "\"vocab_min_count\"", "]", "\n", ")", "\n", "\n", "# Initialize image features reader according to split.", "\n", "image_features_hdfpath", "=", "config", "[", "\"image_features_train_h5\"", "]", "\n", "input_img2idx", "=", "config", "[", "'image_id2idx_train'", "]", "\n", "\n", "if", "\"val\"", "in", "self", ".", "dialogs_reader", ".", "split", ":", "\n", "            ", "image_features_hdfpath", "=", "config", "[", "\"image_features_val_h5\"", "]", "\n", "input_img2idx", "=", "config", "[", "'image_id2idx_val'", "]", "\n", "", "elif", "\"test\"", "in", "self", ".", "dialogs_reader", ".", "split", ":", "\n", "            ", "image_features_hdfpath", "=", "config", "[", "\"image_features_test_h5\"", "]", "\n", "input_img2idx", "=", "config", "[", "'image_id2idx_test'", "]", "\n", "\n", "", "img_file", "=", "h5py", ".", "File", "(", "image_features_hdfpath", ",", "'r'", ")", "\n", "self", ".", "img_id2idx", "=", "cPickle", ".", "load", "(", "open", "(", "input_img2idx", ",", "'rb'", ")", ")", "\n", "self", ".", "img_feats", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "img_file", ".", "get", "(", "'image_features'", ")", ")", ")", "\n", "self", ".", "spatials", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "img_file", ".", "get", "(", "'spatial_features'", ")", ")", ")", "\n", "self", ".", "pos_boxes", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "img_file", ".", "get", "(", "'pos_boxes'", ")", ")", ")", "\n", "\n", "# Keep a list of image_ids as primary keys to access data.", "\n", "self", ".", "image_ids", "=", "list", "(", "self", ".", "dialogs_reader", ".", "dialogs", ".", "keys", "(", ")", ")", "\n", "if", "overfit", ":", "\n", "            ", "self", ".", "image_ids", "=", "self", ".", "image_ids", "[", ":", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.split": [[82, 85], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dialogs_reader", ".", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__len__": [[86, 88], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.__getitem__": [[89, 234], ["dataset.VisDialDataset.vocabulary.to_indices", "range", "dataset.VisDialDataset._pad_sequences", "dataset.VisDialDataset._get_history", "dataset.VisDialDataset._pad_sequences", "dataset.VisDialDataset._pad_sequences", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "questions.long", "history.long", "answers_in.long", "answers_out.long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "len", "dataset.VisDialDataset.vocabulary.to_indices", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "dataset.VisDialDataset.vocabulary.to_indices", "dataset.VisDialDataset.vocabulary.to_indices", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.long", "torch.stack.long", "torch.stack.long", "torch.stack.long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.long", "torch.stack.long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "len", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "torch.stack.append", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "torch.stack.append", "answer_option_lengths.append", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "torch.stack.append", "answer_option_lengths.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "dataset.VisDialDataset.vocabulary.to_indices", "dataset.VisDialDataset.vocabulary.to_indices", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._get_history", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.vocabulary.Vocabulary.to_indices"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# Get image_id, which serves as a primary key for current instance.", "\n", "        ", "image_id", "=", "self", ".", "image_ids", "[", "index", "]", "\n", "\n", "# Get image features", "\n", "feature_idx", "=", "self", ".", "img_id2idx", "[", "image_id", "]", "\n", "image_features", "=", "self", ".", "img_feats", "[", "self", ".", "pos_boxes", "[", "feature_idx", "]", "[", "0", "]", ":", "self", ".", "pos_boxes", "[", "feature_idx", "]", "[", "1", "]", ",", ":", "]", "\n", "\n", "# Normalize image features at zero-th dimension (since there's no batch", "\n", "# dimension).", "\n", "if", "self", ".", "config", "[", "\"img_norm\"", "]", ":", "\n", "            ", "image_features", "=", "normalize", "(", "image_features", ",", "dim", "=", "0", ",", "p", "=", "2", ")", "\n", "\n", "# Retrieve instance for this image_id using json reader.", "\n", "", "visdial_instance", "=", "self", ".", "dialogs_reader", "[", "image_id", "]", "\n", "caption", "=", "visdial_instance", "[", "\"caption\"", "]", "\n", "dialog", "=", "visdial_instance", "[", "\"dialog\"", "]", "\n", "\n", "# Convert word tokens of caption, question, answer and answer options", "\n", "# to integers.", "\n", "caption", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "caption", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dialog", ")", ")", ":", "\n", "            ", "dialog", "[", "i", "]", "[", "\"question\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"question\"", "]", "\n", ")", "\n", "if", "self", ".", "add_boundary_toks", ":", "\n", "                ", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "[", "self", ".", "vocabulary", ".", "SOS_TOKEN", "]", "\n", "+", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "\n", "+", "[", "self", ".", "vocabulary", ".", "EOS_TOKEN", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "\n", ")", "\n", "\n", "", "if", "self", ".", "return_options", ":", "\n", "                ", "for", "j", "in", "range", "(", "len", "(", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", ")", ")", ":", "\n", "                    ", "if", "self", ".", "add_boundary_toks", ":", "\n", "                        ", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "\n", "j", "\n", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "[", "self", ".", "vocabulary", ".", "SOS_TOKEN", "]", "\n", "+", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "\n", "+", "[", "self", ".", "vocabulary", ".", "EOS_TOKEN", "]", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "\n", "j", "\n", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "\n", ")", "\n", "\n", "", "", "", "", "questions", ",", "question_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"question\"", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "history", ",", "history_lengths", "=", "self", ".", "_get_history", "(", "\n", "caption", ",", "\n", "[", "dialog_round", "[", "\"question\"", "]", "for", "dialog_round", "in", "dialog", "]", ",", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "for", "dialog_round", "in", "dialog", "]", ",", "\n", ")", "\n", "answers_in", ",", "answer_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "[", ":", "-", "1", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "answers_out", ",", "_", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "[", "1", ":", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "\n", "# Collect everything as tensors for ``collate_fn`` of dataloader to", "\n", "# work seamlessly questions, history, etc. are converted to", "\n", "# LongTensors, for nn.Embedding input.", "\n", "item", "=", "{", "}", "\n", "item", "[", "\"img_ids\"", "]", "=", "torch", ".", "tensor", "(", "image_id", ")", ".", "long", "(", ")", "\n", "item", "[", "\"img_feat\"", "]", "=", "image_features", "\n", "item", "[", "\"ques\"", "]", "=", "questions", ".", "long", "(", ")", "\n", "item", "[", "\"hist\"", "]", "=", "history", ".", "long", "(", ")", "\n", "item", "[", "\"ans_in\"", "]", "=", "answers_in", ".", "long", "(", ")", "\n", "item", "[", "\"ans_out\"", "]", "=", "answers_out", ".", "long", "(", ")", "\n", "item", "[", "\"ques_len\"", "]", "=", "torch", ".", "tensor", "(", "question_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"hist_len\"", "]", "=", "torch", ".", "tensor", "(", "history_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"ans_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"num_rounds\"", "]", "=", "torch", ".", "tensor", "(", "visdial_instance", "[", "\"num_rounds\"", "]", ")", ".", "long", "(", ")", "\n", "item", "[", "\"structures\"", "]", "=", "torch", ".", "tensor", "(", "visdial_instance", "[", "\"structures\"", "]", ")", "\n", "if", "'train'", "in", "self", ".", "split", ":", "\n", "            ", "item", "[", "\"teacher_scores\"", "]", "=", "torch", ".", "tensor", "(", "visdial_instance", "[", "\"teacher_scores\"", "]", ")", "\n", "\n", "", "if", "self", ".", "return_options", ":", "\n", "            ", "if", "self", ".", "add_boundary_toks", ":", "\n", "                ", "answer_options_in", ",", "answer_options_out", "=", "[", "]", ",", "[", "]", "\n", "answer_option_lengths", "=", "[", "]", "\n", "for", "dialog_round", "in", "dialog", ":", "\n", "                    ", "options", ",", "option_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "\n", "option", "[", ":", "-", "1", "]", "\n", "for", "option", "in", "dialog_round", "[", "\"answer_options\"", "]", "\n", "]", "\n", ")", "\n", "answer_options_in", ".", "append", "(", "options", ")", "\n", "\n", "options", ",", "_", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "\n", "option", "[", "1", ":", "]", "\n", "for", "option", "in", "dialog_round", "[", "\"answer_options\"", "]", "\n", "]", "\n", ")", "\n", "answer_options_out", ".", "append", "(", "options", ")", "\n", "\n", "answer_option_lengths", ".", "append", "(", "option_lengths", ")", "\n", "", "answer_options_in", "=", "torch", ".", "stack", "(", "answer_options_in", ",", "0", ")", "\n", "answer_options_out", "=", "torch", ".", "stack", "(", "answer_options_out", ",", "0", ")", "\n", "\n", "item", "[", "\"opt_in\"", "]", "=", "answer_options_in", ".", "long", "(", ")", "\n", "item", "[", "\"opt_out\"", "]", "=", "answer_options_out", ".", "long", "(", ")", "\n", "item", "[", "\"opt_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_option_lengths", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "answer_options", "=", "[", "]", "\n", "answer_option_lengths", "=", "[", "]", "\n", "for", "dialog_round", "in", "dialog", ":", "\n", "                    ", "options", ",", "option_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "dialog_round", "[", "\"answer_options\"", "]", "\n", ")", "\n", "answer_options", ".", "append", "(", "options", ")", "\n", "answer_option_lengths", ".", "append", "(", "option_lengths", ")", "\n", "", "answer_options", "=", "torch", ".", "stack", "(", "answer_options", ",", "0", ")", "\n", "\n", "item", "[", "\"opt\"", "]", "=", "answer_options", ".", "long", "(", ")", "\n", "item", "[", "\"opt_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_option_lengths", ")", ".", "long", "(", ")", "\n", "\n", "", "if", "\"test\"", "not", "in", "self", ".", "split", ":", "\n", "                ", "answer_indices", "=", "[", "\n", "dialog_round", "[", "\"gt_index\"", "]", "for", "dialog_round", "in", "dialog", "\n", "]", "\n", "item", "[", "\"ans_ind\"", "]", "=", "torch", ".", "tensor", "(", "answer_indices", ")", ".", "long", "(", ")", "\n", "\n", "# Gather dense annotations.", "\n", "", "", "if", "\"val\"", "in", "self", ".", "split", ":", "\n", "            ", "dense_annotations", "=", "self", ".", "annotations_reader", "[", "image_id", "]", "\n", "item", "[", "\"gt_relevance\"", "]", "=", "torch", ".", "tensor", "(", "\n", "dense_annotations", "[", "\"gt_relevance\"", "]", "\n", ")", ".", "float", "(", ")", "\n", "item", "[", "\"round_id\"", "]", "=", "torch", ".", "tensor", "(", "\n", "dense_annotations", "[", "\"round_id\"", "]", "\n", ")", ".", "long", "(", ")", "\n", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset.collate_fn": [[235, 246], ["max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.size", "torch.pad", "torch.pad", "x.size"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "merged_batch", "=", "{", "key", ":", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", "for", "key", "in", "batch", "[", "0", "]", "}", "\n", "batch_keys", "=", "[", "key", "for", "key", "in", "batch", "[", "0", "]", "]", "\n", "out", "=", "{", "}", "\n", "for", "key", "in", "merged_batch", ":", "\n", "            ", "if", "key", "in", "{", "'img_feat'", "}", ":", "\n", "                ", "audio_visual_max_len", "=", "max", "(", "[", "x", ".", "size", "(", "0", ")", "for", "x", "in", "merged_batch", "[", "'img_feat'", "]", "]", ")", "\n", "out", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "audio_visual_max_len", "-", "x", ".", "size", "(", "0", ")", ")", ")", ".", "data", "for", "x", "in", "merged_batch", "[", "'img_feat'", "]", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "out", "[", "key", "]", "=", "torch", ".", "stack", "(", "merged_batch", "[", "key", "]", ",", "0", ")", "\n", "", "", "return", "{", "key", ":", "out", "[", "key", "]", "for", "key", "in", "batch_keys", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._pad_sequences": [[247, 287], ["range", "torch.full", "torch.full", "torch.full", "torch.full", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size"], "methods", ["None"], ["", "def", "_pad_sequences", "(", "self", ",", "sequences", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"Given tokenized sequences (either questions, answers or answer\n        options, tokenized in ``__getitem__``), padding them to maximum\n        specified sequence length. Return as a tensor of size\n        ``(*, max_sequence_length)``.\n\n        This method is only called in ``__getitem__``, chunked out separately\n        for readability.\n\n        Parameters\n        ----------\n        sequences : List[List[int]]\n            List of tokenized sequences, each sequence is typically a\n            List[int].\n\n        Returns\n        -------\n        torch.Tensor, torch.Tensor\n            Tensor of sequences padded to max length, and length of sequences\n            before padding.\n        \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "sequences", ")", ")", ":", "\n", "            ", "sequences", "[", "i", "]", "=", "sequences", "[", "i", "]", "[", "\n", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "\n", "]", "\n", "", "sequence_lengths", "=", "[", "len", "(", "sequence", ")", "for", "sequence", "in", "sequences", "]", "\n", "\n", "# Pad all sequences to max_sequence_length.", "\n", "maxpadded_sequences", "=", "torch", ".", "full", "(", "\n", "(", "len", "(", "sequences", ")", ",", "self", ".", "config", "[", "\"max_sequence_length\"", "]", ")", ",", "\n", "fill_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "padded_sequences", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "sequence", ")", "for", "sequence", "in", "sequences", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "maxpadded_sequences", "[", ":", ",", ":", "padded_sequences", ".", "size", "(", "1", ")", "]", "=", "padded_sequences", "\n", "return", "maxpadded_sequences", ",", "sequence_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.data.dataset.VisDialDataset._get_history": [[288, 342], ["range", "range", "history.append", "zip", "dataset.VisDialDataset.config.get", "torch.full", "torch.full", "torch.full", "torch.full", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "len", "len", "history.append", "concatenated_history.append", "range", "len", "len", "concatenated_history.append", "range", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "concatenated_history[].extend", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size"], "methods", ["home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append", "home.repos.pwc.inspect_result.gicheonkang_sglkt-visdial.utils.logging.Logger.append"], ["", "def", "_get_history", "(", "\n", "self", ",", "\n", "caption", ":", "List", "[", "int", "]", ",", "\n", "questions", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "answers", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", ")", ":", "\n", "# Allow double length of caption, equivalent to a concatenated QA pair.", "\n", "        ", "caption", "=", "caption", "[", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "-", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "            ", "questions", "[", "i", "]", "=", "questions", "[", "i", "]", "[", "\n", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "\n", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "answers", ")", ")", ":", "\n", "            ", "answers", "[", "i", "]", "=", "answers", "[", "i", "]", "[", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "]", "\n", "\n", "# History for first round is caption, else concatenated QA pair of", "\n", "# previous round.", "\n", "", "history", "=", "[", "]", "\n", "history", ".", "append", "(", "caption", ")", "\n", "for", "question", ",", "answer", "in", "zip", "(", "questions", ",", "answers", ")", ":", "\n", "            ", "history", ".", "append", "(", "question", "+", "answer", "+", "[", "self", ".", "vocabulary", ".", "EOS_INDEX", "]", ")", "\n", "# Drop last entry from history (there's no eleventh question).", "\n", "", "history", "=", "history", "[", ":", "-", "1", "]", "\n", "max_history_length", "=", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "\n", "\n", "if", "self", ".", "config", ".", "get", "(", "\"concat_history\"", ",", "False", ")", ":", "\n", "# Concatenated_history has similar structure as history, except it", "\n", "# contains concatenated QA pairs from previous rounds.", "\n", "            ", "concatenated_history", "=", "[", "]", "\n", "concatenated_history", ".", "append", "(", "caption", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "history", ")", ")", ":", "\n", "                ", "concatenated_history", ".", "append", "(", "[", "]", ")", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ")", ":", "\n", "                    ", "concatenated_history", "[", "i", "]", ".", "extend", "(", "history", "[", "j", "]", ")", "\n", "\n", "", "", "max_history_length", "=", "(", "\n", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "*", "len", "(", "history", ")", "\n", ")", "\n", "history", "=", "concatenated_history", "\n", "\n", "", "history_lengths", "=", "[", "len", "(", "round_history", ")", "for", "round_history", "in", "history", "]", "\n", "maxpadded_history", "=", "torch", ".", "full", "(", "\n", "(", "len", "(", "history", ")", ",", "max_history_length", ")", ",", "\n", "fill_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "padded_history", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "round_history", ")", "for", "round_history", "in", "history", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "maxpadded_history", "[", ":", ",", ":", "padded_history", ".", "size", "(", "1", ")", "]", "=", "padded_history", "\n", "return", "maxpadded_history", ",", "history_lengths", "\n", "", "", ""]]}