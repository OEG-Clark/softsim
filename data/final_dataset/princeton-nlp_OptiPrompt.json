{"home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__init__": [[19, 94], ["super().__init__", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "transformers.AutoConfig.from_pretrained", "isinstance", "models.Prober.mlm_model.eval", "list", "logger.info", "models.Prober._init_inverse_vocab", "logger.info", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "transformers.AlbertTokenizer.from_pretrained", "transformers.AlbertForMaskedLM.from_pretrained", "isinstance", "logger.info", "models.Prober.mlm_model._init_weights", "models.Prober.tokenizer.get_vocab().keys", "str", "logger.info", "transformers.AlbertForMaskedLM", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaForMaskedLM.from_pretrained", "isinstance", "len", "logger.info", "transformers.RobertaForMaskedLM", "transformers.BertTokenizer.from_pretrained", "transformers.BertForMaskedLM.from_pretrained", "ValueError", "models.Prober.tokenizer.get_vocab", "logger.info", "transformers.BertForMaskedLM"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__init__", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._init_inverse_vocab"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "random_init", "=", "'none'", ")", ":", "\n", "        ", "assert", "(", "random_init", "in", "[", "'none'", ",", "'all'", ",", "'embedding'", "]", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_model_device", "=", "'cpu'", "\n", "\n", "model_name", "=", "args", ".", "model_name", "\n", "vocab_name", "=", "model_name", "\n", "\n", "if", "args", ".", "model_dir", "is", "not", "None", ":", "\n", "# load bert model from file", "\n", "            ", "model_name", "=", "str", "(", "args", ".", "model_dir", ")", "+", "\"/\"", "\n", "vocab_name", "=", "model_name", "\n", "logger", ".", "info", "(", "\"loading BERT model from {}\"", ".", "format", "(", "model_name", ")", ")", "\n", "\n", "# Load pre-trained model tokenizer (vocabulary)", "\n", "", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "if", "isinstance", "(", "config", ",", "AlbertConfig", ")", ":", "\n", "            ", "self", ".", "model_type", "=", "'albert'", "\n", "self", ".", "tokenizer", "=", "AlbertTokenizer", ".", "from_pretrained", "(", "vocab_name", ")", "\n", "self", ".", "mlm_model", "=", "AlbertForMaskedLM", ".", "from_pretrained", "(", "model_name", ")", "\n", "if", "random_init", "==", "'all'", ":", "\n", "                ", "logger", ".", "info", "(", "'Random initialize model...'", ")", "\n", "self", ".", "mlm_model", "=", "AlbertForMaskedLM", "(", "self", ".", "mlm_model", ".", "config", ")", "\n", "", "self", ".", "base_model", "=", "self", ".", "mlm_model", ".", "albert", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "self", ".", "model_type", "=", "'roberta'", "\n", "self", ".", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "vocab_name", ")", "\n", "self", ".", "mlm_model", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "model_name", ")", "\n", "if", "random_init", "==", "'all'", ":", "\n", "                ", "logger", ".", "info", "(", "'Random initialize model...'", ")", "\n", "self", ".", "mlm_model", "=", "RobertaForMaskedLM", "(", "self", ".", "mlm_model", ".", "config", ")", "\n", "", "self", ".", "base_model", "=", "self", ".", "mlm_model", ".", "roberta", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "self", ".", "model_type", "=", "'bert'", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "vocab_name", ")", "\n", "self", ".", "mlm_model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "model_name", ")", "\n", "if", "random_init", "==", "'all'", ":", "\n", "                ", "logger", ".", "info", "(", "'Random initialize model...'", ")", "\n", "self", ".", "mlm_model", "=", "BertForMaskedLM", "(", "self", ".", "mlm_model", ".", "config", ")", "\n", "", "self", ".", "base_model", "=", "self", ".", "mlm_model", ".", "bert", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Model %s not supported yet!'", "%", "(", "model_name", ")", ")", "\n", "\n", "", "self", ".", "mlm_model", ".", "eval", "(", ")", "\n", "\n", "if", "random_init", "==", "'embedding'", ":", "\n", "            ", "logger", ".", "info", "(", "'Random initialize embedding layer...'", ")", "\n", "self", ".", "mlm_model", ".", "_init_weights", "(", "self", ".", "base_model", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n", "# original vocab", "\n", "", "self", ".", "map_indices", "=", "None", "\n", "self", ".", "vocab", "=", "list", "(", "self", ".", "tokenizer", ".", "get_vocab", "(", ")", ".", "keys", "(", ")", ")", "\n", "logger", ".", "info", "(", "'Vocab size: %d'", "%", "len", "(", "self", ".", "vocab", ")", ")", "\n", "self", ".", "_init_inverse_vocab", "(", ")", "\n", "\n", "self", ".", "MASK", "=", "self", ".", "tokenizer", ".", "mask_token", "\n", "self", ".", "EOS", "=", "self", ".", "tokenizer", ".", "eos_token", "\n", "self", ".", "CLS", "=", "self", ".", "tokenizer", ".", "cls_token", "\n", "self", ".", "SEP", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "self", ".", "UNK", "=", "self", ".", "tokenizer", ".", "unk_token", "\n", "# print(self.MASK, self.EOS, self.CLS, self.SEP, self.UNK)", "\n", "\n", "self", ".", "pad_id", "=", "self", ".", "inverse_vocab", "[", "self", ".", "tokenizer", ".", "pad_token", "]", "\n", "self", ".", "unk_index", "=", "self", ".", "inverse_vocab", "[", "self", ".", "tokenizer", ".", "unk_token", "]", "\n", "\n", "# used to output top-k predictions", "\n", "self", ".", "k", "=", "args", ".", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._cuda": [[95, 97], ["models.Prober.mlm_model.cuda"], "methods", ["None"], ["", "def", "_cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mlm_model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.try_cuda": [[98, 107], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "logger.info", "logger.info", "models.Prober._cuda"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._cuda"], ["", "def", "try_cuda", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move model to GPU if one is available.\"\"\"", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "if", "self", ".", "_model_device", "!=", "'cuda'", ":", "\n", "                ", "logger", ".", "info", "(", "'Moving model to CUDA'", ")", "\n", "self", ".", "_cuda", "(", ")", "\n", "self", ".", "_model_device", "=", "'cuda'", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'No CUDA found'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.init_indices_for_filter_logprobs": [[108, 125], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "models.Prober.tokenizer.tokenize", "index_list.append", "new_vocab_subset.append", "len", "logger.warning", "logger.info", "models.Prober.tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["", "", "def", "init_indices_for_filter_logprobs", "(", "self", ",", "vocab_subset", ",", "logger", "=", "None", ")", ":", "\n", "        ", "index_list", "=", "[", "]", "\n", "new_vocab_subset", "=", "[", "]", "\n", "for", "word", "in", "vocab_subset", ":", "\n", "            ", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "if", "(", "len", "(", "tokens", ")", "==", "1", ")", "and", "(", "tokens", "[", "0", "]", "!=", "self", ".", "UNK", ")", ":", "\n", "                ", "index_list", ".", "append", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "[", "0", "]", ")", "\n", "new_vocab_subset", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "                ", "msg", "=", "\"word {} from vocab_subset not in model vocabulary!\"", ".", "format", "(", "word", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "                    ", "logger", ".", "warning", "(", "msg", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "info", "(", "\"WARNING: {}\"", ".", "format", "(", "msg", ")", ")", "\n", "\n", "", "", "", "indices", "=", "torch", ".", "as_tensor", "(", "index_list", ")", "\n", "return", "indices", ",", "index_list", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._init_inverse_vocab": [[126, 128], ["enumerate"], "methods", ["None"], ["", "def", "_init_inverse_vocab", "(", "self", ")", ":", "\n", "        ", "self", ".", "inverse_vocab", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "vocab", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.get_id": [[129, 137], ["models.Prober.tokenizer.tokenize", "models.Prober.tokenizer.convert_tokens_to_ids", "models.Prober.convert_ids"], "methods", ["None"], ["", "def", "get_id", "(", "self", ",", "string", ")", ":", "\n", "        ", "tokenized_text", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "string", ")", "\n", "indexed_string", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "if", "self", ".", "map_indices", "is", "not", "None", ":", "\n", "# map indices to subset of the vocabulary", "\n", "            ", "indexed_string", "=", "self", ".", "convert_ids", "(", "indexed_string", ")", "\n", "\n", "", "return", "indexed_string", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._get_input_tensors_batch_train": [[138, 189], ["zip", "zip", "models.Prober.__get_input_tensors", "tokens_tensors_list.append", "segments_tensors_list.append", "masked_indices_list.append", "tokenized_text_list.append", "mlm_labels_tensor_list.append", "mlm_label_ids.append", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_input_tensors"], ["", "def", "_get_input_tensors_batch_train", "(", "self", ",", "sentences_list", ",", "samples_list", ")", ":", "\n", "        ", "tokens_tensors_list", "=", "[", "]", "\n", "segments_tensors_list", "=", "[", "]", "\n", "masked_indices_list", "=", "[", "]", "\n", "tokenized_text_list", "=", "[", "]", "\n", "mlm_labels_tensor_list", "=", "[", "]", "\n", "mlm_label_ids", "=", "[", "]", "\n", "\n", "max_tokens", "=", "0", "\n", "for", "(", "sentences", ",", "samples", ")", "in", "zip", "(", "sentences_list", ",", "samples_list", ")", ":", "\n", "            ", "tokens_tensor", ",", "segments_tensor", ",", "masked_indices", ",", "tokenized_text", ",", "mlm_labels_tensor", ",", "mlm_label_id", "=", "self", ".", "__get_input_tensors", "(", "sentences", ",", "mlm_label", "=", "samples", "[", "'obj_label'", "]", ")", "\n", "tokens_tensors_list", ".", "append", "(", "tokens_tensor", ")", "\n", "segments_tensors_list", ".", "append", "(", "segments_tensor", ")", "\n", "masked_indices_list", ".", "append", "(", "masked_indices", ")", "\n", "tokenized_text_list", ".", "append", "(", "tokenized_text", ")", "\n", "mlm_labels_tensor_list", ".", "append", "(", "mlm_labels_tensor", ")", "\n", "mlm_label_ids", ".", "append", "(", "mlm_label_id", ")", "\n", "if", "(", "tokens_tensor", ".", "shape", "[", "1", "]", ">", "max_tokens", ")", ":", "\n", "                ", "max_tokens", "=", "tokens_tensor", ".", "shape", "[", "1", "]", "\n", "\n", "# apply padding and concatenate tensors", "\n", "# use [PAD] for tokens and 0 for segments", "\n", "", "", "final_tokens_tensor", "=", "None", "\n", "final_segments_tensor", "=", "None", "\n", "final_attention_mask", "=", "None", "\n", "final_mlm_labels_tensor", "=", "None", "\n", "for", "tokens_tensor", ",", "segments_tensor", ",", "mlm_labels_tensor", "in", "zip", "(", "tokens_tensors_list", ",", "segments_tensors_list", ",", "mlm_labels_tensor_list", ")", ":", "\n", "            ", "dim_tensor", "=", "tokens_tensor", ".", "shape", "[", "1", "]", "\n", "pad_lenght", "=", "max_tokens", "-", "dim_tensor", "\n", "attention_tensor", "=", "torch", ".", "full", "(", "[", "1", ",", "dim_tensor", "]", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "pad_lenght", ">", "0", ":", "\n", "                ", "pad_1", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "self", ".", "pad_id", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "pad_2", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "0", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "attention_pad", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "0", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "pad_3", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "-", "100", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "tokens_tensor", "=", "torch", ".", "cat", "(", "(", "tokens_tensor", ",", "pad_1", ")", ",", "dim", "=", "1", ")", "\n", "segments_tensor", "=", "torch", ".", "cat", "(", "(", "segments_tensor", ",", "pad_2", ")", ",", "dim", "=", "1", ")", "\n", "attention_tensor", "=", "torch", ".", "cat", "(", "(", "attention_tensor", ",", "attention_pad", ")", ",", "dim", "=", "1", ")", "\n", "mlm_labels_tensor", "=", "torch", ".", "cat", "(", "(", "mlm_labels_tensor", ",", "pad_3", ")", ",", "dim", "=", "1", ")", "\n", "", "if", "final_tokens_tensor", "is", "None", ":", "\n", "                ", "final_tokens_tensor", "=", "tokens_tensor", "\n", "final_segments_tensor", "=", "segments_tensor", "\n", "final_attention_mask", "=", "attention_tensor", "\n", "final_mlm_labels_tensor", "=", "mlm_labels_tensor", "\n", "", "else", ":", "\n", "                ", "final_tokens_tensor", "=", "torch", ".", "cat", "(", "(", "final_tokens_tensor", ",", "tokens_tensor", ")", ",", "dim", "=", "0", ")", "\n", "final_segments_tensor", "=", "torch", ".", "cat", "(", "(", "final_segments_tensor", ",", "segments_tensor", ")", ",", "dim", "=", "0", ")", "\n", "final_attention_mask", "=", "torch", ".", "cat", "(", "(", "final_attention_mask", ",", "attention_tensor", ")", ",", "dim", "=", "0", ")", "\n", "final_mlm_labels_tensor", "=", "torch", ".", "cat", "(", "(", "final_mlm_labels_tensor", ",", "mlm_labels_tensor", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "return", "final_tokens_tensor", ",", "final_segments_tensor", ",", "final_attention_mask", ",", "masked_indices_list", ",", "tokenized_text_list", ",", "final_mlm_labels_tensor", ",", "mlm_label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_input_tensors_batch": [[190, 236], ["zip", "models.Prober.__get_input_tensors", "tokens_tensors_list.append", "segments_tensors_list.append", "masked_indices_list.append", "tokenized_text_list.append", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_input_tensors"], ["", "def", "__get_input_tensors_batch", "(", "self", ",", "sentences_list", ")", ":", "\n", "        ", "tokens_tensors_list", "=", "[", "]", "\n", "segments_tensors_list", "=", "[", "]", "\n", "masked_indices_list", "=", "[", "]", "\n", "tokenized_text_list", "=", "[", "]", "\n", "max_tokens", "=", "0", "\n", "for", "sentences", "in", "sentences_list", ":", "\n", "            ", "tokens_tensor", ",", "segments_tensor", ",", "masked_indices", ",", "tokenized_text", "=", "self", ".", "__get_input_tensors", "(", "sentences", ")", "\n", "tokens_tensors_list", ".", "append", "(", "tokens_tensor", ")", "\n", "segments_tensors_list", ".", "append", "(", "segments_tensor", ")", "\n", "masked_indices_list", ".", "append", "(", "masked_indices", ")", "\n", "tokenized_text_list", ".", "append", "(", "tokenized_text", ")", "\n", "if", "(", "tokens_tensor", ".", "shape", "[", "1", "]", ">", "max_tokens", ")", ":", "\n", "                ", "max_tokens", "=", "tokens_tensor", ".", "shape", "[", "1", "]", "\n", "# logger.info(\"MAX_TOKENS: {}\".format(max_tokens))", "\n", "# apply padding and concatenate tensors", "\n", "# use [PAD] for tokens and 0 for segments", "\n", "", "", "final_tokens_tensor", "=", "None", "\n", "final_segments_tensor", "=", "None", "\n", "final_attention_mask", "=", "None", "\n", "for", "tokens_tensor", ",", "segments_tensor", "in", "zip", "(", "tokens_tensors_list", ",", "segments_tensors_list", ")", ":", "\n", "            ", "dim_tensor", "=", "tokens_tensor", ".", "shape", "[", "1", "]", "\n", "pad_lenght", "=", "max_tokens", "-", "dim_tensor", "\n", "attention_tensor", "=", "torch", ".", "full", "(", "[", "1", ",", "dim_tensor", "]", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "pad_lenght", ">", "0", ":", "\n", "                ", "pad_1", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "self", ".", "pad_id", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "pad_2", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "0", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "attention_pad", "=", "torch", ".", "full", "(", "[", "1", ",", "pad_lenght", "]", ",", "0", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "tokens_tensor", "=", "torch", ".", "cat", "(", "(", "tokens_tensor", ",", "pad_1", ")", ",", "dim", "=", "1", ")", "\n", "segments_tensor", "=", "torch", ".", "cat", "(", "(", "segments_tensor", ",", "pad_2", ")", ",", "dim", "=", "1", ")", "\n", "attention_tensor", "=", "torch", ".", "cat", "(", "(", "attention_tensor", ",", "attention_pad", ")", ",", "dim", "=", "1", ")", "\n", "", "if", "final_tokens_tensor", "is", "None", ":", "\n", "                ", "final_tokens_tensor", "=", "tokens_tensor", "\n", "final_segments_tensor", "=", "segments_tensor", "\n", "final_attention_mask", "=", "attention_tensor", "\n", "", "else", ":", "\n", "                ", "final_tokens_tensor", "=", "torch", ".", "cat", "(", "(", "final_tokens_tensor", ",", "tokens_tensor", ")", ",", "dim", "=", "0", ")", "\n", "final_segments_tensor", "=", "torch", ".", "cat", "(", "(", "final_segments_tensor", ",", "segments_tensor", ")", ",", "dim", "=", "0", ")", "\n", "final_attention_mask", "=", "torch", ".", "cat", "(", "(", "final_attention_mask", ",", "attention_tensor", ")", ",", "dim", "=", "0", ")", "\n", "# logger.info(final_tokens_tensor)", "\n", "# logger.info(final_segments_tensor)", "\n", "# logger.info(final_attention_mask)", "\n", "# logger.info(final_tokens_tensor.shape)", "\n", "# logger.info(final_segments_tensor.shape)", "\n", "# logger.info(final_attention_mask.shape)", "\n", "", "", "return", "final_tokens_tensor", ",", "final_segments_tensor", ",", "final_attention_mask", ",", "masked_indices_list", ",", "tokenized_text_list", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_input_tensors": [[237, 298], ["numpy.zeros().tolist", "models.Prober.append", "numpy.zeros().tolist.append", "tokenized_text.insert", "segments_ids.insert", "range", "models.Prober.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.full().tolist", "models.Prober.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "logger.info", "ValueError", "models.Prober.tokenizer.tokenize", "len", "numpy.full().tolist", "models.Prober.append", "numpy.full().tolist.append", "len", "models.Prober.tokenizer.tokenize", "len", "models.Prober.tokenizer.tokenize", "sentences[].split", "numpy.zeros", "models.Prober.tokenizer.tokenize", "masked_indices.append", "numpy.full", "len", "models.Prober.tokenizer.tokenize", "sentences[].split", "numpy.full", "len", "token.startswith", "token.startswith", "len"], "methods", ["None"], ["", "def", "__get_input_tensors", "(", "self", ",", "sentences", ",", "mlm_label", "=", "None", ")", ":", "\n", "\n", "        ", "if", "len", "(", "sentences", ")", ">", "2", ":", "\n", "            ", "logger", ".", "info", "(", "sentences", ")", "\n", "raise", "ValueError", "(", "\"BERT accepts maximum two sentences in input for each data point\"", ")", "\n", "\n", "", "first_tokenized_sentence", "=", "[", "self", ".", "tokenizer", ".", "tokenize", "(", "token", ")", "if", "(", "(", "not", "token", ".", "startswith", "(", "'[unused'", ")", ")", "and", "(", "token", "!=", "self", ".", "MASK", ")", ")", "else", "[", "token", "]", "for", "token", "in", "sentences", "[", "0", "]", ".", "split", "(", ")", "]", "\n", "first_tokenized_sentence", "=", "[", "item", "for", "sublist", "in", "first_tokenized_sentence", "for", "item", "in", "sublist", "]", "\n", "if", "self", ".", "model_type", "==", "'roberta'", ":", "\n", "            ", "first_tokenized_sentence", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sentences", "[", "0", "]", ")", "\n", "", "first_segment_id", "=", "np", ".", "zeros", "(", "len", "(", "first_tokenized_sentence", ")", ",", "dtype", "=", "int", ")", ".", "tolist", "(", ")", "\n", "\n", "# add [SEP] token at the end", "\n", "first_tokenized_sentence", ".", "append", "(", "self", ".", "SEP", ")", "\n", "first_segment_id", ".", "append", "(", "0", ")", "\n", "\n", "if", "len", "(", "sentences", ")", ">", "1", ":", "\n", "            ", "second_tokenized_sentece", "=", "[", "self", ".", "tokenizer", ".", "tokenize", "(", "token", ")", "if", "not", "token", ".", "startswith", "(", "'[unused'", ")", "else", "[", "token", "]", "for", "token", "in", "sentences", "[", "1", "]", ".", "split", "(", ")", "]", "\n", "second_tokenized_sentece", "=", "[", "item", "for", "sublist", "in", "second_tokenized_sentece", "for", "item", "in", "sublist", "]", "\n", "if", "self", ".", "model_type", "==", "'roberta'", ":", "\n", "                ", "second_tokenized_sentece", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sentences", "[", "1", "]", ")", "\n", "", "second_segment_id", "=", "np", ".", "full", "(", "len", "(", "second_tokenized_sentece", ")", ",", "1", ",", "dtype", "=", "int", ")", ".", "tolist", "(", ")", "\n", "\n", "# add [SEP] token at the end", "\n", "second_tokenized_sentece", ".", "append", "(", "self", ".", "SEP", ")", "\n", "second_segment_id", ".", "append", "(", "1", ")", "\n", "\n", "tokenized_text", "=", "first_tokenized_sentence", "+", "second_tokenized_sentece", "\n", "segments_ids", "=", "first_segment_id", "+", "second_segment_id", "\n", "", "else", ":", "\n", "            ", "tokenized_text", "=", "first_tokenized_sentence", "\n", "segments_ids", "=", "first_segment_id", "\n", "\n", "# add [CLS] token at the beginning", "\n", "", "tokenized_text", ".", "insert", "(", "0", ",", "self", ".", "CLS", ")", "\n", "segments_ids", ".", "insert", "(", "0", ",", "0", ")", "\n", "\n", "# look for masked indices", "\n", "masked_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tokenized_text", ")", ")", ":", "\n", "            ", "token", "=", "tokenized_text", "[", "i", "]", "\n", "if", "token", "==", "self", ".", "MASK", ":", "\n", "                ", "masked_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "", "indexed_tokens", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "\n", "# Convert inputs to PyTorch tensors", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", "\n", "segments_tensors", "=", "torch", ".", "tensor", "(", "[", "segments_ids", "]", ")", "\n", "\n", "if", "mlm_label", "is", "None", ":", "\n", "            ", "return", "tokens_tensor", ",", "segments_tensors", ",", "masked_indices", ",", "tokenized_text", "\n", "\n", "# Handle mlm_label", "\n", "", "mlm_labels", "=", "np", ".", "full", "(", "len", "(", "tokenized_text", ")", ",", "-", "100", ",", "dtype", "=", "int", ")", ".", "tolist", "(", ")", "\n", "tmp_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "' '", "+", "mlm_label", ")", ")", "\n", "assert", "(", "len", "(", "tmp_ids", ")", "==", "1", ")", "\n", "mlm_labels", "[", "masked_indices", "[", "-", "1", "]", "]", "=", "tmp_ids", "[", "0", "]", "\n", "mlm_labels_tensor", "=", "torch", ".", "tensor", "(", "[", "mlm_labels", "]", ")", "\n", "\n", "return", "tokens_tensor", ",", "segments_tensors", ",", "masked_indices", ",", "tokenized_text", ",", "mlm_labels_tensor", ",", "tmp_ids", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_token_ids_from_tensor": [[299, 308], ["models.Prober.convert_ids", "numpy.asarray"], "methods", ["None"], ["", "def", "__get_token_ids_from_tensor", "(", "self", ",", "indexed_string", ")", ":", "\n", "        ", "token_ids", "=", "[", "]", "\n", "if", "self", ".", "map_indices", "is", "not", "None", ":", "\n", "# map indices to subset of the vocabulary", "\n", "            ", "indexed_string", "=", "self", ".", "convert_ids", "(", "indexed_string", ")", "\n", "token_ids", "=", "np", ".", "asarray", "(", "indexed_string", ")", "\n", "", "else", ":", "\n", "            ", "token_ids", "=", "indexed_string", "\n", "", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.get_batch_generation": [[309, 335], ["models.Prober.__get_input_tensors_batch", "tokens_tensor.numpy", "models.Prober.try_cuda", "logger.debug", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.Prober.mlm_model", "torch.log_softmax().cpu", "torch.log_softmax().cpu", "token_ids_list.append", "models.Prober.__get_token_ids_from_tensor", "tokens_tensor.to", "segments_tensor.to", "attention_mask_tensor.to", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_input_tensors_batch", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.try_cuda", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.__get_token_ids_from_tensor"], ["", "def", "get_batch_generation", "(", "self", ",", "sentences_list", ",", "logger", "=", "None", ",", "\n", "try_cuda", "=", "True", ")", ":", "\n", "        ", "if", "not", "sentences_list", ":", "\n", "            ", "return", "None", "\n", "", "if", "try_cuda", ":", "\n", "            ", "self", ".", "try_cuda", "(", ")", "\n", "\n", "", "tokens_tensor", ",", "segments_tensor", ",", "attention_mask_tensor", ",", "masked_indices_list", ",", "tokenized_text_list", "=", "self", ".", "__get_input_tensors_batch", "(", "sentences_list", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "debug", "(", "\"\\n{}\\n\"", ".", "format", "(", "tokenized_text_list", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "self", ".", "mlm_model", "(", "\n", "input_ids", "=", "tokens_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "token_type_ids", "=", "segments_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "attention_mask", "=", "attention_mask_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", ")", "\n", "\n", "log_probs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n", "", "token_ids_list", "=", "[", "]", "\n", "for", "indexed_string", "in", "tokens_tensor", ".", "numpy", "(", ")", ":", "\n", "            ", "token_ids_list", ".", "append", "(", "self", ".", "__get_token_ids_from_tensor", "(", "indexed_string", ")", ")", "\n", "\n", "", "return", "log_probs", ",", "token_ids_list", ",", "masked_indices_list", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.run_batch": [[336, 405], ["models.Prober._get_input_tensors_batch_train", "models.Prober.try_cuda", "models.Prober.mlm_model.train", "models.Prober.mlm_model", "models.Prober.mlm_model.eval", "torch.log_softmax().cpu", "torch.log_softmax().cpu", "range", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.Prober.mlm_model", "tokens_tensor.to", "segments_tensor.to", "attention_mask_tensor.to", "mlm_labels_tensor.to", "torch.log_softmax", "torch.log_softmax", "log_prob.index_select.index_select.index_select", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "zip", "topk.append", "[].cpu().index_select", "common_vocab_loss.append", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "topk.append", "preds.append", "preds.append", "tokens_tensor.to", "segments_tensor.to", "attention_mask_tensor.to", "mlm_labels_tensor.to", "topk_preds.append", "torch.log_softmax", "torch.log_softmax", "common_log_prob[].item", "[].cpu", "log_prob_i.item"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober._get_input_tensors_batch_train", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.try_cuda"], ["", "def", "run_batch", "(", "self", ",", "sentences_list", ",", "samples_list", ",", "try_cuda", "=", "True", ",", "training", "=", "True", ",", "filter_indices", "=", "None", ",", "index_list", "=", "None", ",", "vocab_to_common_vocab", "=", "None", ")", ":", "\n", "        ", "if", "try_cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", ":", "\n", "            ", "self", ".", "try_cuda", "(", ")", "\n", "\n", "", "tokens_tensor", ",", "segments_tensor", ",", "attention_mask_tensor", ",", "masked_indices_list", ",", "tokenized_text_list", ",", "mlm_labels_tensor", ",", "mlm_label_ids", "=", "self", ".", "_get_input_tensors_batch_train", "(", "sentences_list", ",", "samples_list", ")", "\n", "\n", "if", "training", ":", "\n", "            ", "self", ".", "mlm_model", ".", "train", "(", ")", "\n", "loss", "=", "self", ".", "mlm_model", "(", "\n", "input_ids", "=", "tokens_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "token_type_ids", "=", "segments_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "attention_mask", "=", "attention_mask_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "masked_lm_labels", "=", "mlm_labels_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", ")", "\n", "loss", "=", "loss", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "mlm_model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", ",", "logits", "=", "self", ".", "mlm_model", "(", "\n", "input_ids", "=", "tokens_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "token_type_ids", "=", "segments_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "attention_mask", "=", "attention_mask_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", "masked_lm_labels", "=", "mlm_labels_tensor", ".", "to", "(", "self", ".", "_model_device", ")", ",", "\n", ")", "\n", "", "log_probs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n", "", "if", "training", ":", "\n", "            ", "return", "loss", "\n", "", "else", ":", "\n", "# During testing, return accuracy and top-k predictions", "\n", "            ", "tot", "=", "log_probs", ".", "shape", "[", "0", "]", "\n", "cor", "=", "0", "\n", "preds", "=", "[", "]", "\n", "topk", "=", "[", "]", "\n", "common_vocab_loss", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "log_probs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "masked_index", "=", "masked_indices_list", "[", "i", "]", "[", "0", "]", "\n", "log_prob", "=", "log_probs", "[", "i", "]", "[", "masked_index", "]", "\n", "mlm_label", "=", "mlm_label_ids", "[", "i", "]", "\n", "if", "filter_indices", "is", "not", "None", ":", "\n", "                    ", "log_prob", "=", "log_prob", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "filter_indices", ")", "\n", "pred_common_vocab", "=", "torch", ".", "argmax", "(", "log_prob", ")", "\n", "pred", "=", "index_list", "[", "pred_common_vocab", "]", "\n", "\n", "# get top-k predictions", "\n", "topk_preds", "=", "[", "]", "\n", "topk_log_prob", ",", "topk_ids", "=", "torch", ".", "topk", "(", "log_prob", ",", "self", ".", "k", ")", "\n", "for", "log_prob_i", ",", "idx", "in", "zip", "(", "topk_log_prob", ",", "topk_ids", ")", ":", "\n", "                        ", "ori_idx", "=", "index_list", "[", "idx", "]", "\n", "token", "=", "self", ".", "vocab", "[", "ori_idx", "]", "\n", "topk_preds", ".", "append", "(", "{", "'token'", ":", "token", ",", "'log_prob'", ":", "log_prob_i", ".", "item", "(", ")", "}", ")", "\n", "", "topk", ".", "append", "(", "topk_preds", ")", "\n", "\n", "# compute entropy on common vocab", "\n", "common_logits", "=", "logits", "[", "i", "]", "[", "masked_index", "]", ".", "cpu", "(", ")", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "filter_indices", ")", "\n", "common_log_prob", "=", "-", "F", ".", "log_softmax", "(", "common_logits", ",", "dim", "=", "-", "1", ")", "\n", "common_label_id", "=", "vocab_to_common_vocab", "[", "mlm_label", "]", "\n", "common_vocab_loss", ".", "append", "(", "common_log_prob", "[", "common_label_id", "]", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "pred", "=", "torch", ".", "argmax", "(", "log_prob", ")", "\n", "topk", ".", "append", "(", "[", "]", ")", "\n", "", "if", "pred", "==", "mlm_labels_tensor", "[", "i", "]", "[", "masked_index", "]", ":", "\n", "                    ", "cor", "+=", "1", "\n", "preds", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "preds", ".", "append", "(", "0", ")", "\n", "\n", "", "", "return", "log_probs", ",", "cor", ",", "tot", ",", "preds", ",", "topk", ",", "loss", ",", "common_vocab_loss", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.get_new_token": [[26, 29], ["None"], "function", ["None"], ["def", "get_new_token", "(", "vid", ")", ":", "\n", "    ", "assert", "(", "vid", ">", "0", "and", "vid", "<=", "MAX_NUM_VECTORS", ")", "\n", "return", "'[V%d]'", "%", "(", "vid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.convert_manual_to_dense": [[30, 54], ["manual_template.split", "logger.info", "model.tokenizer.convert_tokens_to_ids", "model.tokenizer.convert_tokens_to_ids", "torch.no_grad", "model.base_model.embeddings.word_embeddings.weight[].detach().clone", "template.append", "model.tokenizer.tokenize", "template.append", "run_optiprompt.convert_manual_to_dense.assign_embedding"], "function", ["None"], ["", "def", "convert_manual_to_dense", "(", "manual_template", ",", "model", ")", ":", "\n", "    ", "def", "assign_embedding", "(", "new_token", ",", "token", ")", ":", "\n", "        ", "\"\"\"\n        assign the embedding of token to new_token\n        \"\"\"", "\n", "logger", ".", "info", "(", "'Tie embeddings of tokens: (%s, %s)'", "%", "(", "new_token", ",", "token", ")", ")", "\n", "id_a", "=", "model", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "new_token", "]", ")", "[", "0", "]", "\n", "id_b", "=", "model", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "token", "]", ")", "[", "0", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model", ".", "base_model", ".", "embeddings", ".", "word_embeddings", ".", "weight", "[", "id_a", "]", "=", "model", ".", "base_model", ".", "embeddings", ".", "word_embeddings", ".", "weight", "[", "id_b", "]", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "", "", "new_token_id", "=", "0", "\n", "template", "=", "[", "]", "\n", "for", "word", "in", "manual_template", ".", "split", "(", ")", ":", "\n", "        ", "if", "word", "in", "[", "'[X]'", ",", "'[Y]'", "]", ":", "\n", "            ", "template", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "model", ".", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "new_token_id", "+=", "1", "\n", "template", ".", "append", "(", "get_new_token", "(", "new_token_id", ")", ")", "\n", "assign_embedding", "(", "get_new_token", "(", "new_token_id", ")", ",", "token", ")", "\n", "\n", "", "", "", "return", "' '", ".", "join", "(", "template", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.init_template": [[55, 62], ["utils.get_relation_meta", "run_optiprompt.convert_manual_to_dense", "range"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.get_relation_meta", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.convert_manual_to_dense"], ["", "def", "init_template", "(", "args", ",", "model", ")", ":", "\n", "    ", "if", "args", ".", "init_manual_template", ":", "\n", "        ", "relation", "=", "get_relation_meta", "(", "args", ")", "\n", "template", "=", "convert_manual_to_dense", "(", "relation", "[", "'template'", "]", ",", "model", ")", "\n", "", "else", ":", "\n", "        ", "template", "=", "'[X] '", "+", "' '", ".", "join", "(", "[", "'[V%d]'", "%", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "args", ".", "num_vectors", ")", "]", ")", "+", "' [Y] .'", "\n", "", "return", "template", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.prepare_for_dense_prompt": [[63, 68], ["model.tokenizer.add_tokens", "model.mlm_model.resize_token_embeddings", "logger.info", "run_optiprompt.get_new_token", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.get_new_token"], ["", "def", "prepare_for_dense_prompt", "(", "model", ")", ":", "\n", "    ", "new_tokens", "=", "[", "get_new_token", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "MAX_NUM_VECTORS", ")", "]", "\n", "model", ".", "tokenizer", ".", "add_tokens", "(", "new_tokens", ")", "\n", "ebd", "=", "model", ".", "mlm_model", ".", "resize_token_embeddings", "(", "len", "(", "model", ".", "tokenizer", ")", ")", "\n", "logger", ".", "info", "(", "'# vocab after adding new tokens: %d'", "%", "len", "(", "model", ".", "tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.save_optiprompt": [[69, 74], ["logger.info", "model.base_model.embeddings.word_embeddings.weight[].detach().cpu().numpy", "open", "numpy.save", "model.base_model.embeddings.word_embeddings.weight[].detach().cpu", "os.path.join", "model.base_model.embeddings.word_embeddings.weight[].detach"], "function", ["None"], ["", "def", "save_optiprompt", "(", "args", ",", "model", ",", "original_vocab_size", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Saving OptiPrompt's [V]s..\"", ")", "\n", "vs", "=", "model", ".", "base_model", ".", "embeddings", ".", "word_embeddings", ".", "weight", "[", "original_vocab_size", ":", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'prompt_vecs.npy'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "np", ".", "save", "(", "f", ",", "vs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.load_optiprompt": [[75, 89], ["models.Prober", "len", "run_optiprompt.prepare_for_dense_prompt", "logger.info", "list", "open", "numpy.load", "torch.no_grad", "torch.Tensor", "models.Prober.tokenizer.get_vocab", "os.path.join"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_optiprompt.prepare_for_dense_prompt"], ["", "", "def", "load_optiprompt", "(", "args", ")", ":", "\n", "# load bert model (pre-trained)", "\n", "    ", "model", "=", "Prober", "(", "args", ",", "random_init", "=", "args", ".", "random_init", ")", "\n", "original_vocab_size", "=", "len", "(", "list", "(", "model", ".", "tokenizer", ".", "get_vocab", "(", ")", ")", ")", "\n", "prepare_for_dense_prompt", "(", "model", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading OptiPrompt's [V]s..\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'prompt_vecs.npy'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "vs", "=", "np", ".", "load", "(", "f", ")", "\n", "\n", "# copy fine-tuned new_tokens to the pre-trained model", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "base_model", ".", "embeddings", ".", "word_embeddings", ".", "weight", "[", "original_vocab_size", ":", "]", "=", "torch", ".", "Tensor", "(", "vs", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_finetune.init_template": [[20, 26], ["utils.get_relation_meta"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.get_relation_meta"], ["def", "init_template", "(", "args", ",", "model", ")", ":", "\n", "    ", "if", "args", ".", "no_template", ":", "\n", "        ", "return", "'[X] [Y]'", "\n", "", "else", ":", "\n", "        ", "relation", "=", "get_relation_meta", "(", "args", ")", "\n", "return", "relation", "[", "'template'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.load_vocab": [[9, 14], ["open", "f.readlines", "x.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_filename", ")", ":", "\n", "    ", "with", "open", "(", "vocab_filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "vocab", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "lines", "]", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.load_file": [[15, 21], ["open", "f.readlines", "data.append", "json.loads"], "function", ["None"], ["", "def", "load_file", "(", "filename", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "data", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.parse_template": [[22, 28], ["template.replace.replace", "template.replace.replace"], "function", ["None"], ["", "def", "parse_template", "(", "template", ",", "subject_label", ",", "object_label", "=", "'[MASK]'", ")", ":", "\n", "    ", "SUBJ_SYMBOL", "=", "\"[X]\"", "\n", "OBJ_SYMBOL", "=", "\"[Y]\"", "\n", "template", "=", "template", ".", "replace", "(", "SUBJ_SYMBOL", ",", "subject_label", ")", "\n", "template", "=", "template", ".", "replace", "(", "OBJ_SYMBOL", ",", "object_label", ")", "\n", "return", "[", "template", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.convert_tokens_to_string": [[29, 32], ["None"], "function", ["None"], ["", "def", "convert_tokens_to_string", "(", "tokens", ")", ":", "\n", "    ", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.get_relation_meta": [[33, 39], ["utils.load_file", "ValueError"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.load_file"], ["", "def", "get_relation_meta", "(", "args", ")", ":", "\n", "    ", "relations", "=", "load_file", "(", "args", ".", "relation_profile", ")", "\n", "for", "relation", "in", "relations", ":", "\n", "        ", "if", "relation", "[", "'relation'", "]", "==", "args", ".", "relation", ":", "\n", "            ", "return", "relation", "\n", "", "", "raise", "ValueError", "(", "'Relation info %s not found in file %s'", "%", "(", "args", ".", "relation", ",", "args", ".", "relation_profile", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.batchify": [[40, 64], ["current_samples_batch.append", "current_sentences_batches.append", "list_samples_batches.append", "list_sentences_batches.append", "list_samples_batches.append", "list_sentences_batches.append", "len"], "function", ["None"], ["", "def", "batchify", "(", "data", ",", "batch_size", ")", ":", "\n", "    ", "list_samples_batches", "=", "[", "]", "\n", "list_sentences_batches", "=", "[", "]", "\n", "current_samples_batch", "=", "[", "]", "\n", "current_sentences_batches", "=", "[", "]", "\n", "\n", "c", "=", "0", "\n", "for", "sample", "in", "data", ":", "\n", "        ", "input_sentences", "=", "sample", "[", "'input_sentences'", "]", "\n", "current_samples_batch", ".", "append", "(", "sample", ")", "\n", "current_sentences_batches", ".", "append", "(", "input_sentences", ")", "\n", "c", "+=", "1", "\n", "if", "c", ">=", "batch_size", ":", "\n", "            ", "list_samples_batches", ".", "append", "(", "current_samples_batch", ")", "\n", "list_sentences_batches", ".", "append", "(", "current_sentences_batches", ")", "\n", "current_samples_batch", "=", "[", "]", "\n", "current_sentences_batches", "=", "[", "]", "\n", "c", "=", "0", "\n", "\n", "", "", "if", "current_samples_batch", "and", "len", "(", "current_samples_batch", ")", ">", "0", ":", "\n", "        ", "list_samples_batches", ".", "append", "(", "current_samples_batch", ")", "\n", "list_sentences_batches", ".", "append", "(", "current_sentences_batches", ")", "\n", "\n", "", "return", "list_samples_batches", ",", "list_sentences_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.save_model": [[66, 71], ["logger.info", "model_to_save.save_pretrained", "model.tokenizer.save_pretrained"], "function", ["None"], ["", "def", "save_model", "(", "model", ",", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Saving model...'", ")", "\n", "model_to_save", "=", "model", ".", "mlm_model", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.output_result": [[72, 92], ["logger.info", "logger.info", "logger.info", "sys.stdout.flush", "logger.info", "len", "len", "len", "len"], "function", ["None"], ["", "def", "output_result", "(", "result", ",", "eval_loss", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'* Evaluation result *'", ")", "\n", "cor", "=", "0", "\n", "tot", "=", "0", "\n", "macro", "=", "0.0", "\n", "loss", "=", "0.0", "\n", "for", "rel", "in", "result", ":", "\n", "        ", "cor_", ",", "tot_", ",", "avg_", ",", "loss_", "=", "result", "[", "rel", "]", "\n", "cor", "+=", "cor_", "\n", "tot", "+=", "tot_", "\n", "macro", "+=", "avg_", "\n", "loss_", "/=", "tot_", "\n", "loss", "+=", "loss_", "\n", "logger", ".", "info", "(", "'%s\\t%.5f\\t%d\\t%d\\t%.5f'", "%", "(", "rel", ",", "avg_", ",", "cor_", ",", "tot_", ",", "loss_", ")", ")", "\n", "", "macro", "=", "cor", "/", "tot", "if", "tot", ">", "0", "else", "0.0", "\n", "micro", "=", "macro", "/", "len", "(", "result", ")", "if", "len", "(", "result", ")", ">", "0", "else", "0.0", "\n", "logger", ".", "info", "(", "'Macro avg: %.5f'", "%", "macro", ")", "\n", "logger", ".", "info", "(", "'Micro avg: %.5f, Eval_loss: %.5f, Eval_loss (common vocab): %.5f'", "%", "(", "micro", ",", "eval_loss", "/", "tot", ",", "loss", "/", "len", "(", "result", ")", "if", "len", "(", "result", ")", ">", "0", "else", "0.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "return", "micro", ",", "macro", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.evaluate": [[93, 143], ["tqdm.tqdm", "utils.output_result", "enumerate", "range", "model.run_batch", "zip", "logger.info", "len", "list_of_predictions[].append", "loss.item", "open", "f.write", "os.path.join", "json.dumps"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.output_result", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.models.Prober.run_batch"], ["", "def", "evaluate", "(", "model", ",", "samples_batches", ",", "sentences_batches", ",", "filter_indices", "=", "None", ",", "index_list", "=", "None", ",", "output_topk", "=", "None", ")", ":", "\n", "    ", "vocab_to_common_vocab", "=", "None", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "        ", "vocab_to_common_vocab", "=", "{", "}", "\n", "for", "cid", ",", "idx", "in", "enumerate", "(", "index_list", ")", ":", "\n", "            ", "vocab_to_common_vocab", "[", "idx", "]", "=", "cid", "\n", "\n", "", "", "cor_all", "=", "0", "\n", "tot_all", "=", "0", "\n", "result", "=", "{", "}", "\n", "list_of_predictions", "=", "{", "}", "\n", "eval_loss", "=", "0.0", "\n", "common_eval_loss", "=", "0.0", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "samples_batches", ")", ")", ")", ":", "\n", "        ", "samples_b", "=", "samples_batches", "[", "i", "]", "\n", "sentences_b", "=", "sentences_batches", "[", "i", "]", "\n", "\n", "log_probs", ",", "cor_b", ",", "tot_b", ",", "pred_b", ",", "topk_preds", ",", "loss", ",", "common_vocab_loss", "=", "model", ".", "run_batch", "(", "sentences_b", ",", "samples_b", ",", "training", "=", "False", ",", "filter_indices", "=", "filter_indices", ",", "index_list", "=", "index_list", ",", "vocab_to_common_vocab", "=", "vocab_to_common_vocab", ")", "\n", "cor_all", "+=", "cor_b", "\n", "tot_all", "+=", "tot_b", "\n", "\n", "for", "pred", ",", "sample", ",", "topk", ",", "vocab_loss", "in", "zip", "(", "pred_b", ",", "samples_b", ",", "topk_preds", ",", "common_vocab_loss", ")", ":", "\n", "            ", "rel", "=", "sample", "[", "'predicate_id'", "]", "\n", "if", "rel", "not", "in", "result", ":", "\n", "                ", "result", "[", "rel", "]", "=", "(", "0", ",", "0", ",", "0", ",", "0.0", ")", "\n", "list_of_predictions", "[", "rel", "]", "=", "[", "]", "\n", "", "cor", ",", "tot", ",", "_", ",", "rel_tot_loss", "=", "result", "[", "rel", "]", "\n", "tot", "+=", "1", "\n", "cor", "+=", "pred", "\n", "rel_tot_loss", "+=", "vocab_loss", "\n", "result", "[", "rel", "]", "=", "(", "cor", ",", "tot", ",", "cor", "/", "tot", "if", "tot", ">", "0", "else", "0.0", ",", "rel_tot_loss", ")", "\n", "list_of_predictions", "[", "rel", "]", ".", "append", "(", "{", "\n", "'uuid'", ":", "sample", "[", "'uuid'", "]", ",", "\n", "'relation'", ":", "sample", "[", "'predicate_id'", "]", ",", "\n", "'sub_label'", ":", "sample", "[", "'sub_label'", "]", ",", "\n", "'obj_label'", ":", "sample", "[", "'obj_label'", "]", ",", "\n", "'masked_sentences'", ":", "sample", "[", "'input_sentences'", "]", ",", "\n", "'topk'", ":", "topk", ",", "\n", "}", ")", "\n", "\n", "", "eval_loss", "+=", "loss", ".", "item", "(", ")", "*", "tot_b", "\n", "\n", "", "if", "output_topk", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "'Output top-k prediction to %s..'", "%", "output_topk", ")", "\n", "for", "rel", "in", "list_of_predictions", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_topk", ",", "'%s_predictions.jsonl'", "%", "rel", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "[", "json", ".", "dumps", "(", "x", ")", "for", "x", "in", "list_of_predictions", "[", "rel", "]", "]", ")", ")", "\n", "\n", "", "", "", "micro", ",", "macro", "=", "output_result", "(", "result", ",", "eval_loss", ")", "\n", "return", "micro", ",", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.gen_feature_sample": [[144, 153], ["utils.parse_template", "template.strip", "feature_sample[].strip"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.parse_template"], ["", "def", "gen_feature_sample", "(", "data_sample", ",", "template", ",", "mask_token", "=", "'[MASK]'", ")", ":", "\n", "    ", "feature_sample", "=", "{", "}", "\n", "feature_sample", "[", "'predicate_id'", "]", "=", "data_sample", "[", "'predicate_id'", "]", "\n", "feature_sample", "[", "'sub_label'", "]", "=", "data_sample", "[", "'sub_label'", "]", "\n", "feature_sample", "[", "'obj_label'", "]", "=", "data_sample", "[", "'obj_label'", "]", "\n", "feature_sample", "[", "'uuid'", "]", "=", "data_sample", "[", "'uuid'", "]", "if", "'uuid'", "in", "data_sample", "else", "''", "\n", "masked_sentence", "=", "parse_template", "(", "template", ".", "strip", "(", ")", ",", "feature_sample", "[", "'sub_label'", "]", ".", "strip", "(", ")", ",", "mask_token", ")", "\n", "feature_sample", "[", "'input_sentences'", "]", "=", "[", "masked_sentence", "[", "0", "]", "]", "\n", "return", "feature_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.load_data": [[154, 171], ["set", "utils.load_file", "set.add", "utils.gen_feature_sample", "all_samples.append"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.load_file", "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.gen_feature_sample"], ["", "def", "load_data", "(", "data_path", ",", "template", ",", "vocab_subset", "=", "None", ",", "mask_token", "=", "'[MASK]'", ")", ":", "\n", "    ", "all_samples", "=", "[", "]", "\n", "\n", "distinct_facts", "=", "set", "(", ")", "\n", "raw_samples", "=", "load_file", "(", "data_path", ")", "\n", "for", "data_sample", "in", "raw_samples", ":", "\n", "# follow the LAMA setting, only keep distinct (sub, obj) pairs", "\n", "        ", "if", "(", "data_sample", "[", "'sub_label'", "]", ",", "data_sample", "[", "'obj_label'", "]", ")", "in", "distinct_facts", ":", "\n", "            ", "continue", "\n", "", "if", "(", "data_sample", "[", "'obj_label'", "]", "not", "in", "vocab_subset", ")", ":", "\n", "            ", "continue", "\n", "", "distinct_facts", ".", "add", "(", "(", "data_sample", "[", "'sub_label'", "]", ",", "data_sample", "[", "'obj_label'", "]", ")", ")", "\n", "\n", "feature_sample", "=", "gen_feature_sample", "(", "data_sample", ",", "template", ",", "mask_token", ")", "\n", "all_samples", ".", "append", "(", "feature_sample", ")", "\n", "\n", "", "return", "all_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.run_eval_prompts.init_template": [[20, 23], ["utils.get_relation_meta"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_OptiPrompt.code.utils.get_relation_meta"], ["def", "init_template", "(", "args", ",", "model", ")", ":", "\n", "    ", "relation", "=", "get_relation_meta", "(", "args", ")", "\n", "return", "relation", "[", "'template'", "]", "\n", "\n"]]}