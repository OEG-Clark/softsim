{"home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.estimateDCMFromMOM": [[9, 23], ["bayeslex_stats.getEMu", "n_i.sum", "numpy.array", "numpy.array", "x.power().sum", "x.sum", "x.power", "numpy.array", "x.sum"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.getEMu"], ["def", "estimateDCMFromMOM", "(", "x", ")", ":", "\n", "    ", "'''\n    A method-of-moments estimator for the concentration parameter of the DCM\n    '''", "\n", "n_ii_diag", "=", "np", ".", "array", "(", "x", ".", "power", "(", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", ")", "[", "0", "]", "\n", "Nsq_sum", "=", "(", "np", ".", "array", "(", "x", ".", "sum", "(", "axis", "=", "1", ")", ".", "T", ")", "[", "0", "]", "**", "2", ")", ".", "sum", "(", ")", "\n", "n_i", "=", "np", ".", "array", "(", "x", ".", "sum", "(", "axis", "=", "0", ")", ")", "[", "0", "]", "\n", "\n", "e_mu", "=", "getEMu", "(", "x", ")", "\n", "N_sum", "=", "n_i", ".", "sum", "(", ")", "\n", "numerator", "=", "(", "(", "1", "-", "e_mu", ")", "*", "e_mu", "*", "(", "e_mu", "*", "Nsq_sum", "-", "n_ii_diag", ")", ")", ".", "sum", "(", ")", "\n", "denominator", "=", "(", "(", "(", "1", "-", "e_mu", ")", "*", "e_mu", "*", "(", "n_ii_diag", "-", "e_mu", "**", "2", "*", "(", "Nsq_sum", "-", "N_sum", ")", "-", "e_mu", "*", "N_sum", ")", ")", ")", ".", "sum", "(", ")", "\n", "e_c", "=", "numerator", "/", "denominator", "\n", "return", "e_mu", ",", "e_c", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.getEMu": [[24, 26], ["numpy.array", "x.sum", "x.sum"], "function", ["None"], ["", "def", "getEMu", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "x", ".", "sum", "(", "axis", "=", "0", ")", "/", "(", "0.", "+", "x", ".", "sum", "(", ")", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeS": [[27, 36], ["numpy.array().flatten", "numpy.inner", "numpy.array", "x.sum"], "function", ["None"], ["", "def", "computeS", "(", "x", ",", "c", "=", "sys", ".", "float_info", ".", "max", ")", ":", "\n", "    ", "'''\n    s is a constant term in the expected co-occurrence counts for the Bayesian model.\n\n    In the non-Bayesian model, $c \\to \\infty$\n    '''", "\n", "N_t", "=", "np", ".", "array", "(", "x", ".", "sum", "(", "axis", "=", "1", ")", ")", ".", "flatten", "(", ")", "\n", "s", "=", "np", ".", "inner", "(", "N_t", ",", "N_t", "-", "(", "N_t", "+", "c", ")", "/", "(", "1", "+", "c", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.estimateK": [[37, 43], ["bayeslex_stats.getCoCountsTwoLex", "numpy.sqrt", "e_cc_pn.sum", "cc_pn.sum"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.getCoCountsTwoLex"], ["", "def", "estimateK", "(", "x", ",", "pos_words", ",", "neg_words", ")", ":", "\n", "    ", "'''\n    This estimates a single predictiveness parameter\n    '''", "\n", "cc_pn", ",", "e_cc_pn", "=", "getCoCountsTwoLex", "(", "x", ",", "pos_words", ",", "neg_words", ")", "\n", "return", "np", ".", "sqrt", "(", "e_cc_pn", ".", "sum", "(", ")", "/", "cc_pn", ".", "sum", "(", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.getCoCountsTwoLex": [[44, 65], ["filter_to_x_shape", "filter_to_x_shape", "x1.T.dot().toarray", "bayeslex_stats.computeS", "numpy.array", "x1.sum", "p_x.sum", "x2.sum", "p_x.sum", "bayeslex_stats.estimateDCMFromMOM", "x1.T.dot", "mu1.T.dot"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeS", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.estimateDCMFromMOM"], ["", "def", "getCoCountsTwoLex", "(", "p_x", ",", "p_lex1", ",", "p_lex2", ",", "Bayesian", "=", "False", ")", ":", "\n", "    ", "filter_to_x_shape", "=", "lambda", "lex", ":", "[", "i", "for", "i", "in", "lex", "if", "i", "<", "p_x", ".", "shape", "[", "1", "]", "]", "\n", "p_lex1", "=", "filter_to_x_shape", "(", "p_lex1", ")", "\n", "p_lex2", "=", "filter_to_x_shape", "(", "p_lex2", ")", "\n", "x1", "=", "p_x", "[", ":", ",", "p_lex1", "]", "\n", "x2", "=", "p_x", "[", ":", ",", "p_lex2", "]", "\n", "\n", "co_counts", "=", "(", "x1", ".", "T", ".", "dot", "(", "x2", ")", ")", ".", "toarray", "(", ")", "\n", "\n", "mu1", "=", "x1", ".", "sum", "(", "axis", "=", "0", ")", "/", "p_x", ".", "sum", "(", ")", "\n", "mu2", "=", "x2", ".", "sum", "(", "axis", "=", "0", ")", "/", "p_x", ".", "sum", "(", ")", "\n", "\n", "if", "Bayesian", ":", "\n", "        ", "_", ",", "c", "=", "estimateDCMFromMOM", "(", "p_x", ")", "\n", "", "else", ":", "\n", "        ", "c", "=", "sys", ".", "float_info", ".", "max", "\n", "\n", "", "s", "=", "computeS", "(", "p_x", ")", "\n", "e_co_counts", "=", "np", ".", "array", "(", "s", "*", "mu1", ".", "T", ".", "dot", "(", "mu2", ")", ")", "\n", "\n", "return", "co_counts", ",", "e_co_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeR": [[66, 81], ["bayeslex_stats.getEMu", "x[].todense", "scipy.special.gammaln", "scipy.special.gammaln", "scipy.special.gammaln", "scipy.special.gammaln", "numpy.array", "numer.sum", "denom.sum"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.getEMu"], ["", "def", "computeR", "(", "x", ",", "lex", ",", "k_hat", ",", "c_hat", ")", ":", "\n", "    ", "'''\n    Compute the prediction rule for a given lexicon\n    '''", "\n", "e_mu", "=", "getEMu", "(", "x", ")", "\n", "x_lex", "=", "x", "[", ":", ",", "lex", "]", ".", "todense", "(", ")", "\n", "\n", "numer", "=", "gammaln", "(", "1e-20", "+", "x_lex", "+", "(", "1", "+", "k_hat", ")", "*", "c_hat", "*", "e_mu", "[", "lex", "]", ")", "-", "gammaln", "(", "1e-20", "+", "x_lex", "+", "(", "1", "-", "k_hat", ")", "*", "c_hat", "*", "e_mu", "[", "lex", "]", ")", "\n", "\n", "#print \"trouble?\",gammaln(x_lex + (1-k_hat)*c_hat*e_mu[lex]).min(),gammaln(x_lex + (1-k_hat)*c_hat*e_mu[lex]).max()", "\n", "\n", "denom", "=", "gammaln", "(", "1e-20", "+", "(", "1", "+", "k_hat", ")", "*", "c_hat", "*", "e_mu", "[", "lex", "]", ")", "-", "gammaln", "(", "1e-20", "+", "(", "1", "-", "k_hat", ")", "*", "c_hat", "*", "e_mu", "[", "lex", "]", ")", "\n", "return", "np", ".", "array", "(", "numer", ".", "sum", "(", "axis", "=", "1", ")", "-", "denom", ".", "sum", "(", ")", ")", ".", "T", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeRNonBayes": [[82, 85], ["x[].dot", "numpy.log", "numpy.log"], "function", ["None"], ["", "def", "computeRNonBayes", "(", "x", ",", "lex", ",", "k_hat", ")", ":", "\n", "    ", "weights", "=", "np", ".", "log", "(", "1", "+", "k_hat", ")", "-", "np", ".", "log", "(", "1", "-", "k_hat", ")", "\n", "return", "x", "[", ":", ",", "lex", "]", ".", "dot", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.e_co_diff": [[87, 89], ["numpy.outer"], "function", ["None"], ["", "def", "e_co_diff", "(", "outer_mu", ",", "k1", ",", "k2", ")", ":", "\n", "    ", "return", "(", "1.", "-", "np", ".", "outer", "(", "k1", ",", "k2", ")", ")", "*", "outer_mu", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.makePredictionsKPerWord": [[90, 102], ["scale", "bayeslex_stats.computeR", "bayeslex_stats.computeR", "bayeslex_stats.computeRNonBayes", "bayeslex_stats.computeRNonBayes"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeR", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeR", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeRNonBayes", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_stats.computeRNonBayes"], ["", "def", "makePredictionsKPerWord", "(", "x", ",", "pos_lex", ",", "neg_lex", ",", "k_hat_pos", ",", "k_hat_neg", ",", "c_hat", ",", "scale_preds", "=", "True", ",", "bayesian", "=", "True", ")", ":", "\n", "    ", "'''\n    separate \\hat{k} for each lexicon.\n    use this if seperate \\hat{k} for each word too\n    '''", "\n", "if", "bayesian", ":", "\n", "        ", "preds", "=", "computeR", "(", "x", ",", "pos_lex", ",", "k_hat_pos", ",", "c_hat", ")", "-", "computeR", "(", "x", ",", "neg_lex", ",", "k_hat_neg", ",", "c_hat", ")", "\n", "", "else", ":", "\n", "        ", "preds", "=", "computeRNonBayes", "(", "x", ",", "pos_lex", ",", "k_hat_pos", ")", "-", "computeRNonBayes", "(", "x", ",", "neg_lex", ",", "k_hat_neg", ")", "\n", "", "if", "scale", ":", "\n", "        ", "preds", "=", "scale", "(", "preds", ",", "x", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_eval.threeClassAcc": [[4, 13], ["numpy.abs().sum", "numpy.abs"], "function", ["None"], ["def", "threeClassAcc", "(", "labels", ",", "preds", ")", ":", "\n", "    ", "'''\n    This is for cases where labels are in {-1,0,1}, and preds are true and false.\n    It's something like recall.\n    '''", "\n", "tp", "=", "(", "(", "labels", ">", "0", ")", "&", "preds", ")", ".", "sum", "(", ")", "\n", "tn", "=", "(", "(", "labels", "<", "0", ")", "&", "~", "preds", ")", ".", "sum", "(", ")", "\n", "acc", "=", "(", "tp", "+", "tn", ")", "/", "np", ".", "abs", "(", "labels", ")", ".", "sum", "(", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_eval.resultString": [[14, 21], ["bayeslex_eval.threeClassAcc", "sklearn.metrics.roc_auc_score"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_eval.threeClassAcc"], ["", "def", "resultString", "(", "predictions", ",", "y", ",", "sysname", ")", ":", "\n", "    ", "'''\n    predictions should be a number, positive = positive label\n    '''", "\n", "acc", "=", "threeClassAcc", "(", "y", ",", "predictions", ">", "0", ")", "\n", "auc", "=", "roc_auc_score", "(", "y", ">", "0", ",", "predictions", ")", "\n", "return", "\"OOO %s:\\t%.3f\\t%.3f\"", "%", "(", "sysname", ",", "acc", ",", "auc", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.counterString": [[27, 29], ["counts.iteritems"], "function", ["None"], ["def", "counterString", "(", "counts", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "[", "'%s:%s'", "%", "(", "key", ",", "val", ")", "for", "key", ",", "val", "in", "counts", ".", "iteritems", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getIMDBWordCounts": [[30, 37], ["collections.Counter", "data-preprocessing.counterString", "codecs.open", "nltk.tokenize.sent_tokenize", "collections.Counter", "x.lower", "nltk.tokenize.word_tokenize", "x.isalpha"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.counterString"], ["", "def", "getIMDBWordCounts", "(", "docname", ")", ":", "\n", "    ", "counter", "=", "Counter", "(", ")", "\n", "with", "codecs", ".", "open", "(", "docname", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "for", "sent", "in", "sent_tokenize", "(", "line", ")", ":", "\n", "                ", "counter", "+=", "Counter", "(", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "word_tokenize", "(", "sent", ")", "if", "x", ".", "isalpha", "(", ")", "]", ")", "\n", "", "", "", "return", "counterString", "(", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getCorpusCineCountsAndLabels": [[38, 51], ["xml.XMLParser", "open", "xml.fromstring", "int", "fin.read", "ET.fromstring.iter", "collections.Counter", "ET.fromstring.find", "token.lower", "body.text.split", "token.isalpha"], "function", ["None"], ["", "def", "getCorpusCineCountsAndLabels", "(", "filename", ")", ":", "\n", "    ", "parser", "=", "ET", ".", "XMLParser", "(", ")", "\n", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ")", "as", "fin", ":", "\n", "        ", "tree", "=", "ET", ".", "fromstring", "(", "fin", ".", "read", "(", ")", ",", "parser", "=", "parser", ")", "\n", "rank", "=", "int", "(", "tree", ".", "find", "(", "'.'", ")", ".", "attrib", "[", "'rank'", "]", ")", "\n", "counts", "=", "None", "\n", "label", "=", "None", "\n", "if", "rank", "!=", "3", ":", "\n", "            ", "for", "body", "in", "tree", ".", "iter", "(", "'body'", ")", ":", "\n", "                ", "counts", "=", "Counter", "(", "[", "token", ".", "lower", "(", ")", "for", "token", "in", "body", ".", "text", ".", "split", "(", ")", "if", "token", ".", "isalpha", "(", ")", "]", ")", "\n", "if", "rank", ">", "3", ":", "label", "=", "'POS'", "\n", "else", ":", "label", "=", "'NEG'", "\n", "", "", "", "return", "counts", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getCornellCounts": [[52, 58], ["collections.Counter", "data-preprocessing.counterString", "open", "collections.Counter", "x.lower", "nltk.tokenize.word_tokenize", "x.isalpha"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.counterString"], ["", "def", "getCornellCounts", "(", "filename", ")", ":", "\n", "    ", "counts", "=", "Counter", "(", ")", "\n", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "counts", "+=", "Counter", "(", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "word_tokenize", "(", "line", ")", "if", "x", ".", "isalpha", "(", ")", "]", ")", "\n", "", "", "return", "counterString", "(", "counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doIMDB": [[59, 71], ["glob.glob", "glob.glob", "os.path.join", "os.path.join", "codecs.open", "codecs.open", "data-preprocessing.getIMDBWordCounts", "data-preprocessing.getIMDBWordCounts"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getIMDBWordCounts", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getIMDBWordCounts"], ["", "def", "doIMDB", "(", "outprefix", ")", ":", "\n", "    ", "negdocs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "imdb_base", ",", "'neg/*txt'", ")", ")", "\n", "posdocs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "imdb_base", ",", "'pos/*txt'", ")", ")", "\n", "# todo: abstract this pattern", "\n", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.bow'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout_bow", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.key'", ",", "'w'", ")", "as", "fout_key", ":", "\n", "            ", "for", "filename", "in", "posdocs", ":", "\n", "                ", "print", ">>", "fout_key", ",", "filename", ",", "'POS'", "\n", "print", ">>", "fout_bow", ",", "getIMDBWordCounts", "(", "filename", ")", "\n", "", "for", "filename", "in", "negdocs", ":", "\n", "                ", "print", ">>", "fout_key", ",", "filename", ",", "'NEG'", "\n", "print", ">>", "fout_bow", ",", "getIMDBWordCounts", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doCornell": [[72, 83], ["glob.glob", "glob.glob", "os.path.join", "os.path.join", "codecs.open", "codecs.open", "data-preprocessing.getCornellCounts", "data-preprocessing.getCornellCounts"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getCornellCounts", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getCornellCounts"], ["", "", "", "", "def", "doCornell", "(", "outprefix", ")", ":", "\n", "    ", "negdocs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "cornell_base", ",", "'neg/*.txt'", ")", ")", "\n", "posdocs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "cornell_base", ",", "'pos/*.txt'", ")", ")", "\n", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.bow'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout_bow", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.key'", ",", "'w'", ")", "as", "fout_key", ":", "\n", "            ", "for", "filename", "in", "posdocs", ":", "\n", "                ", "print", ">>", "fout_key", ",", "filename", ",", "'POS'", "\n", "print", ">>", "fout_bow", ",", "getCornellCounts", "(", "filename", ")", "\n", "", "for", "filename", "in", "negdocs", ":", "\n", "                ", "print", ">>", "fout_key", ",", "filename", ",", "'NEG'", "\n", "print", ">>", "fout_bow", ",", "getCornellCounts", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doCorpusCine": [[84, 97], ["codecs.open", "codecs.open", "glob.glob", "os.path.join", "data-preprocessing.getCorpusCineCountsAndLabels", "fails.append", "data-preprocessing.counterString"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.getCorpusCineCountsAndLabels", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.counterString"], ["", "", "", "", "def", "doCorpusCine", "(", "outprefix", ")", ":", "\n", "    ", "fails", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.bow'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout_bow", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.key'", ",", "'w'", ")", "as", "fout_key", ":", "\n", "            ", "for", "filename", "in", "glob", "(", "os", ".", "path", ".", "join", "(", "cine_base", ",", "'*.xml'", ")", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "counts", ",", "label", "=", "getCorpusCineCountsAndLabels", "(", "filename", ")", "\n", "if", "counts", "is", "not", "None", ":", "\n", "                        ", "print", ">>", "fout_bow", ",", "counterString", "(", "counts", ")", "\n", "print", ">>", "fout_key", ",", "filename", ",", "label", "\n", "", "", "except", ":", "\n", "                    ", "fails", ".", "append", "(", "filename", ")", "\n", "", "", "", "", "return", "fails", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doAmazonLabelGroup": [[98, 107], ["open", "x.split", "int", "data-preprocessing.counterString", "line.split", "valid", "i.isalpha"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.counterString"], ["", "def", "doAmazonLabelGroup", "(", "files", ",", "label", ",", "fout_key", ",", "fout_bow", ")", ":", "\n", "    ", "valid", "=", "lambda", "string", ":", "'_'", "not", "in", "string", "and", "'<'", "not", "in", "string", "and", "'#'", "not", "in", "string", "\n", "for", "filename", "in", "files", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "kvpairs", "=", "[", "x", ".", "split", "(", "':'", ")", "for", "x", "in", "line", ".", "split", "(", ")", "if", "valid", "(", "x", ")", "]", "\n", "counts", "=", "{", "i", ":", "int", "(", "j", ")", "for", "i", ",", "j", "in", "kvpairs", "if", "i", ".", "isalpha", "(", ")", "}", "\n", "print", ">>", "fout_bow", ",", "counterString", "(", "counts", ")", "\n", "print", ">>", "fout_key", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doAmazon": [[109, 125], ["codecs.open", "data-preprocessing.doAmazonLabelGroup", "codecs.open", "glob.glob", "codecs.open", "data-preprocessing.doAmazonLabelGroup", "data-preprocessing.doAmazonLabelGroup", "os.path.join", "glob.glob", "glob.glob", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doAmazonLabelGroup", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doAmazonLabelGroup", "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.data-preprocessing.doAmazonLabelGroup"], ["", "", "", "", "def", "doAmazon", "(", "outprefix", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "outprefix", "+", "\"-unlabeled.bow\"", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout_bow", ":", "\n", "        ", "doAmazonLabelGroup", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "amazon_base", ",", "'*/unlabeled.review'", ")", ")", ",", "\n", "'UNK'", ",", "\n", "None", ",", "\n", "fout_bow", ")", "\n", "", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.bow'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout_bow", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "outprefix", "+", "'.key'", ",", "'w'", ")", "as", "fout_key", ":", "\n", "            ", "doAmazonLabelGroup", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "amazon_base", ",", "'*/positive.review'", ")", ")", ",", "\n", "'POS'", ",", "\n", "fout_key", ",", "\n", "fout_bow", ")", "\n", "doAmazonLabelGroup", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "amazon_base", ",", "'*/negative.review'", ")", ")", ",", "\n", "'NEG'", ",", "\n", "fout_key", ",", "\n", "fout_bow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_baselines.getLexClassifier": [[4, 9], ["scipy.sparse.csr_matrix", "numpy.hstack", "numpy.zeros", "numpy.hstack", "len", "numpy.ones", "numpy.ones", "len", "len", "len", "len"], "function", ["None"], ["def", "getLexClassifier", "(", "pos_words", ",", "neg_words", ",", "vocab", ")", ":", "\n", "    ", "clf", "=", "csr_matrix", "(", "(", "np", ".", "hstack", "(", "[", "-", "1", "*", "np", ".", "ones", "(", "len", "(", "neg_words", ")", ")", ",", "np", ".", "ones", "(", "len", "(", "pos_words", ")", ")", "]", ")", ",", "\n", "(", "np", ".", "zeros", "(", "len", "(", "neg_words", ")", "+", "len", "(", "pos_words", ")", ")", ",", "\n", "np", ".", "hstack", "(", "[", "neg_words", ",", "pos_words", "]", ")", ")", ")", ",", "shape", "=", "[", "1", ",", "len", "(", "vocab", ")", "]", ")", "\n", "return", "clf", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_baselines.pmiPredictor": [[11, 27], ["bayeslex_baselines.pmiPredictor.getPMI"], "function", ["None"], ["", "def", "pmiPredictor", "(", "x", ",", "pos_lex", ",", "neg_lex", ")", ":", "\n", "    ", "'''\n    based on Turney (2002) and Mohammed et al (2013)\n    '''", "\n", "def", "getPMI", "(", "x", ",", "lex1", ",", "lex2", ",", "smoothing", "=", "1e-3", ")", ":", "\n", "        ", "docs", "=", "(", "x", "[", ":", ",", "lex1", "]", ".", "sum", "(", "axis", "=", "1", ")", ">", "x", "[", ":", ",", "lex2", "]", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "pmi", "=", "np", ".", "log", "(", "x", ".", "T", ".", "dot", "(", "docs", ")", "+", "smoothing", ")", ".", "T", "-", "np", ".", "log", "(", "x", ".", "sum", "(", "axis", "=", "0", ")", "+", ".001", ")", "-", "np", ".", "log", "(", "docs", ".", "sum", "(", ")", ")", "\n", "return", "np", ".", "array", "(", "pmi", ")", "[", "0", "]", ",", "np", ".", "array", "(", "docs", ".", "T", ")", "[", "0", "]", "\n", "\n", "", "pmi_pos", ",", "pos_docs", "=", "getPMI", "(", "x", ",", "pos_lex", ",", "neg_lex", ")", "\n", "pmi_neg", ",", "neg_docs", "=", "getPMI", "(", "x", ",", "neg_lex", ",", "pos_lex", ")", "\n", "\n", "term_filter", "=", "np", ".", "array", "(", "(", "1", "*", "(", "x", "[", "pos_docs", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">=", "5", ")", "|", "(", "x", "[", "neg_docs", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">", "5", ")", ")", ")", "[", "0", "]", "\n", "\n", "so", "=", "term_filter", "*", "(", "pmi_pos", "-", "pmi_neg", ")", "\n", "return", "x", ".", "dot", "(", "so", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_data.loadData": [[14, 76], ["collections.Counter", "scipy.sparse.csr_matrix().astype", "open", "open", "numpy.array", "getTokenCounts", "enumerate", "open", "scipy.sparse.csr_matrix", "collections.Counter.most_common", "fin_bow.readline", "int", "min", "key_line.rstrip", "labels.append", "getTokenCounts", "len", "ValueError", "len", "collections.Counter.keys", "docs.append", "words.append", "counts.append", "int"], "function", ["None"], ["def", "loadData", "(", "prefix", ",", "max_vocab", ")", ":", "\n", "    ", "\"\"\" load bag-of-words and key files, up to max_vocab\n    \n    Parameters\n    ----------\n    prefix: str\n    max_vocab: int\n    \n    Returns\n    -------\n    labels: np.array\n    x: csr_matrix\n    vocab: doct\n    \"\"\"", "\n", "\n", "vocab", "=", "{", "}", "\n", "\n", "docs", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "counts", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "t", "=", "0", "\n", "\n", "vocab_counter", "=", "Counter", "(", ")", "\n", "\n", "with", "open", "(", "prefix", "+", "'.bow'", ",", "'r'", ")", "as", "fin_bow", ":", "\n", "        ", "for", "line", "in", "fin_bow", ":", "\n", "            ", "for", "word", ",", "count", "in", "getTokenCounts", "(", "line", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "vocab_counter", "[", "word", "]", "+=", "int", "(", "count", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "", "", "", "", "vocab", "=", "{", "j", "[", "0", "]", ":", "i", "for", "i", ",", "j", "in", "enumerate", "(", "vocab_counter", ".", "most_common", "(", "min", "(", "max_vocab", ",", "len", "(", "vocab_counter", ".", "keys", "(", ")", ")", ")", ")", ")", "}", "\n", "\n", "with", "open", "(", "prefix", "+", "\".key\"", ",", "'r'", ")", "as", "fin_key", ":", "\n", "        ", "with", "open", "(", "prefix", "+", "\".bow\"", ",", "'r'", ")", "as", "fin_bow", ":", "\n", "            ", "for", "key_line", "in", "fin_key", ":", "\n", "                ", "bow_line", "=", "fin_bow", ".", "readline", "(", ")", "\n", "label_str", "=", "key_line", ".", "rstrip", "(", ")", "[", "-", "3", ":", "]", "\n", "label", "=", "None", "\n", "\n", "if", "label_str", "==", "'POS'", ":", "\n", "                    ", "label", "=", "1.", "\n", "", "elif", "label_str", "==", "'NEG'", ":", "\n", "                    ", "label", "=", "-", "1.", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"%s is not a valid label\"", "%", "(", "label", ")", ")", "\n", "", "if", "label", "is", "not", "None", ":", "\n", "                    ", "labels", ".", "append", "(", "label", ")", "\n", "for", "word", ",", "count", "in", "getTokenCounts", "(", "bow_line", ")", ":", "\n", "#for word,count in [token.split(':') for token in bow_line.split()]:", "\n", "                        ", "try", ":", "\n", "                            ", "if", "word", "in", "vocab", ":", "\n", "                                ", "docs", ".", "append", "(", "t", ")", "\n", "words", ".", "append", "(", "vocab", "[", "word", "]", ")", "\n", "counts", ".", "append", "(", "int", "(", "count", ")", ")", "\n", "", "", "except", ":", "\n", "                            ", "pass", "\n", "", "", "t", "+=", "1", "\n", "\n", "", "", "", "", "x", "=", "csr_matrix", "(", "(", "counts", ",", "(", "docs", ",", "words", ")", ")", ",", "shape", "=", "(", "docs", "[", "-", "1", "]", "+", "1", ",", "len", "(", "vocab", ")", ")", ")", ".", "astype", "(", "'float'", ")", "\n", "return", "np", ".", "array", "(", "labels", ")", ",", "x", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_data.loadExtraData": [[77, 101], ["scipy.sparse.csr_matrix().astype", "open", "enumerate", "getTokenCounts", "scipy.sparse.csr_matrix", "docs.append", "words.append", "counts.append", "int", "len"], "function", ["None"], ["", "def", "loadExtraData", "(", "filename", ",", "vocab", ")", ":", "\n", "    ", "\"\"\" load extra bag-of-words, given existing vocabulary\n    \n    Parameters\n    ----------\n    filename: str\n    vocab: dict\n    \n    Returns\n    -------\n    x: csr_matrix\n    \"\"\"", "\n", "\n", "counts", "=", "[", "]", "\n", "docs", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "            ", "for", "word", ",", "count", "in", "getTokenCounts", "(", "line", ")", ":", "\n", "                ", "if", "word", "in", "vocab", ":", "\n", "                    ", "docs", ".", "append", "(", "i", ")", "\n", "words", ".", "append", "(", "vocab", "[", "word", "]", ")", "\n", "counts", ".", "append", "(", "int", "(", "count", ")", ")", "\n", "", "", "", "", "return", "csr_matrix", "(", "(", "counts", ",", "(", "docs", ",", "words", ")", ")", ",", "shape", "=", "(", "docs", "[", "-", "1", "]", "+", "1", ",", "len", "(", "vocab", ")", ")", ")", ".", "astype", "(", "'float'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.bayeslex_data.getLex": [[102, 127], ["open", "fin.readlines", "sorted", "word.rstrip", "word.rstrip"], "function", ["None"], ["", "def", "getLex", "(", "lexfile", ",", "vocab", ")", ":", "\n", "    ", "\"\"\" get a lexicon, given a file and a vocabulary dict\n    \n    Parameters\n    ----------\n    lexfile: name of a file containing a lexicon\n    vocab: a dict of words to indices\n    \n    Returns\n    -------\n    x: sorted list of word indices\n    \"\"\"", "\n", "\n", "'''\n    Inputs:\n    \n    - lexfile: name of a file containing a lexicon\n    - a dict of words to indices\n    \n    Outputs:\n    - a sorted list of word indices from the lexicon\n    '''", "\n", "with", "open", "(", "lexfile", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "words", "=", "fin", ".", "readlines", "(", ")", "\n", "return", "sorted", "(", "[", "vocab", "[", "word", ".", "rstrip", "(", ")", "]", "for", "word", "in", "words", "if", "word", ".", "rstrip", "(", ")", "in", "vocab", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.admm.lowRankPlusDiagonalSolve": [[4, 31], ["d_inv_u.T.dot", "d_inv_u.dot.dot", "numpy.reshape", "numpy.eye", "d_inv_u.T.dot", "numpy.linalg.inv", "d_inv_u.dot", "numpy.linalg.solve"], "function", ["None"], ["def", "lowRankPlusDiagonalSolve", "(", "d", ",", "u", ",", "y", ",", "explicit_invert", "=", "True", ")", ":", "\n", "# solve Ax = y for A = Diad(d) + uu'", "\n", "\n", "# dimensions ", "\n", "# d: Kx1", "\n", "# u: KxN", "\n", "# y: Kx1", "\n", "# assume K >> N", "\n", "#weirdly, explicit inversion seems to be faster", "\n", "\n", "    ", "K1", "=", "d", ".", "shape", "[", "0", "]", "\n", "K", ",", "N", "=", "u", ".", "shape", "\n", "assert", "(", "K1", "==", "K", ")", "\n", "d_inv", "=", "1", "/", "d", "# K x 1", "\n", "part1", "=", "d_inv", "*", "y", "#elementwise multiplication. K x 1", "\n", "d_inv_u", "=", "np", ".", "reshape", "(", "d_inv", ",", "[", "K", ",", "1", "]", ")", "*", "u", "#K x N", "\n", "\n", "denom", "=", "np", ".", "eye", "(", "N", ")", "+", "d_inv_u", ".", "T", ".", "dot", "(", "u", ")", "#N x N", "\n", "\n", "if", "explicit_invert", ":", "\n", "        ", "inv_denom", "=", "np", ".", "linalg", ".", "inv", "(", "denom", ")", "#N x N", "\n", "left_part", "=", "d_inv_u", ".", "dot", "(", "inv_denom", ")", "#K x N", "\n", "", "else", ":", "\n", "        ", "left_part", "=", "np", ".", "linalg", ".", "solve", "(", "denom", ",", "d_inv_u", ".", "T", ")", ".", "T", "\n", "", "right_part", "=", "d_inv_u", ".", "T", ".", "dot", "(", "y", ")", "#N x 1", "\n", "part2", "=", "left_part", ".", "dot", "(", "right_part", ")", "#K x 1", "\n", "return", "part1", "-", "part2", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.admm.lowRankPlusDiagonalQuadProd": [[32, 36], ["numpy.array", "u.T.dot", "x.dot", "np.array.T.dot"], "function", ["None"], ["", "def", "lowRankPlusDiagonalQuadProd", "(", "d", ",", "u", ",", "x", ")", ":", "\n", "# A = diag(d) + U U'", "\n", "    ", "utx", "=", "np", ".", "array", "(", "u", ".", "T", ".", "dot", "(", "x", ")", ")", "\n", "return", "x", ".", "dot", "(", "d", "*", "x", ")", "+", "utx", ".", "T", ".", "dot", "(", "utx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.admm.admmQuadBounded": [[37, 50], ["numpy.zeros_like", "numpy.zeros_like", "range", "projection", "admm.lowRankPlusDiagonalSolve", "projection"], "function", ["home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.admm.lowRankPlusDiagonalSolve"], ["", "def", "admmQuadBounded", "(", "P_diag", ",", "P_low_rank", ",", "q", ",", "projection", ",", "max_iter", "=", "100", ",", "rho", "=", "1.", ")", ":", "\n", "    ", "a", "=", "np", ".", "zeros_like", "(", "q", ")", "#projected", "\n", "v", "=", "np", ".", "zeros_like", "(", "q", ")", "#dual variable", "\n", "\n", "P_diag", "+=", "rho", "\n", "for", "_", "in", "range", "(", "max_iter", ")", ":", "\n", "        ", "x", "=", "lowRankPlusDiagonalSolve", "(", "P_diag", ",", "P_low_rank", ",", "-", "q", ")", "\n", "q", "-=", "rho", "*", "(", "v", "-", "a", ")", "\n", "a", "=", "projection", "(", "x", "+", "v", ")", "\n", "v", "+=", "x", "-", "a", "\n", "q", "+=", "rho", "*", "(", "v", "-", "a", ")", "\n", "#print np.linalg.norm(v)**2", "\n", "", "return", "projection", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jacobeisenstein_probabilistic-lexicon-classification.None.admm.updateRho": [[51, 64], ["None"], "function", ["None"], ["", "def", "updateRho", "(", "u", ",", "rho", ",", "primal_residual", ",", "dual_residual", ",", "mu", "=", "5.", ",", "tau_incr", "=", "2.", ",", "tau_decr", "=", "2.", ")", ":", "\n", "    ", "'''\n    Adaptive computation of the ADMM penalty\n    See page 20 of Boyd et al\n    '''", "\n", "\n", "if", "primal_residual", ">", "mu", "*", "dual_residual", ":", "\n", "        ", "rho", "*=", "tau_incr", "\n", "u", "/=", "tau_incr", "\n", "", "elif", "dual_residual", "<", "mu", "*", "primal_residual", ":", "\n", "        ", "rho", "/=", "tau_decr", "\n", "u", "*=", "tau_decr", "\n", "", "return", "rho", ",", "u", "\n", "\n"]]}