{"home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.evaluate_model": [[27, 102], ["model.eval", "multiprocess_input_pipeline.get_multiprocess_batch_queue", "_logger.info", "_logger.info", "torch.no_grad", "allennlp.common.Tqdm.tqdm", "validation_exit.set", "_logger.info", "_logger.exception", "print", "glob.glob", "range", "allennlp.nn.util.move_to_device", "model.forward", "output.cpu.cpu", "enumerate", "validation_queue.qsize", "_logger.error", "str", "str", "validation_queue.get", "copy.deepcopy", "int", "int", "validation_results[].append", "proc.is_alive", "validation_queue.qsize", "len", "cached_batches.append", "proc.terminate", "float"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.multiprocess_input_pipeline.get_multiprocess_batch_queue", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward"], ["def", "evaluate_model", "(", "model", ",", "config", ",", "_logger", ",", "cuda_device", ",", "eval_tsv", ",", "eval_batch_count", ",", "use_cache", "=", "False", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "# turning off training", "\n", "validation_results", "=", "{", "}", "\n", "fill_cache", "=", "False", "\n", "cached_batches", "=", "None", "\n", "\n", "try", ":", "\n", "        ", "if", "use_cache", ":", "\n", "            ", "global", "evaluate_cache", "\n", "if", "eval_tsv", "not", "in", "evaluate_cache", ":", "\n", "                ", "fill_cache", "=", "True", "\n", "evaluate_cache", "[", "eval_tsv", "]", "=", "[", "]", "\n", "", "cached_batches", "=", "evaluate_cache", "[", "eval_tsv", "]", "\n", "\n", "", "if", "not", "use_cache", "or", "fill_cache", ":", "\n", "            ", "validation_queue", ",", "validation_processes", ",", "validation_exit", "=", "get_multiprocess_batch_queue", "(", "\"eval-batches\"", ",", "\n", "multiprocess_validation_loader", ",", "\n", "glob", ".", "glob", "(", "eval_tsv", ")", ",", "\n", "config", ",", "\n", "_logger", ",", "\n", "queue_size", "=", "200", ")", "\n", "#time.sleep(len(validation_processes))  # fill the queue", "\n", "_logger", ".", "info", "(", "\"[eval_model] --- Start validation with queue.size:\"", "+", "str", "(", "validation_queue", ".", "qsize", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "_logger", ".", "info", "(", "\"[eval_model] --- Start validation with cache size:\"", "+", "str", "(", "len", "(", "cached_batches", ")", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "Tqdm", ".", "tqdm", "(", "range", "(", "0", ",", "eval_batch_count", ")", ",", "disable", "=", "config", "[", "\"tqdm_disabled\"", "]", ")", ":", "\n", "\n", "                ", "if", "not", "use_cache", "or", "fill_cache", ":", "\n", "                    ", "batch_orig", "=", "validation_queue", ".", "get", "(", ")", "\n", "if", "fill_cache", ":", "\n", "                        ", "cached_batches", ".", "append", "(", "batch_orig", ")", "\n", "", "", "else", ":", "\n", "                    ", "batch_orig", "=", "cached_batches", "[", "i", "]", "\n", "\n", "", "batch", "=", "move_to_device", "(", "copy", ".", "deepcopy", "(", "batch_orig", ")", ",", "cuda_device", ")", "\n", "\n", "output", "=", "model", ".", "forward", "(", "batch", "[", "\"query_tokens\"", "]", ",", "batch", "[", "\"doc_tokens\"", "]", ",", "batch", "[", "\"query_length\"", "]", ",", "batch", "[", "\"doc_length\"", "]", ")", "\n", "output", "=", "output", ".", "cpu", "(", ")", "# get the output back to the cpu - in one piece", "\n", "\n", "for", "sample_i", ",", "sample_query_id", "in", "enumerate", "(", "batch_orig", "[", "\"query_id\"", "]", ")", ":", "# operate on cpu memory", "\n", "\n", "                    ", "sample_query_id", "=", "int", "(", "sample_query_id", ")", "\n", "sample_doc_id", "=", "int", "(", "batch_orig", "[", "\"doc_id\"", "]", "[", "sample_i", "]", ")", "# again operate on cpu memory", "\n", "\n", "if", "sample_query_id", "not", "in", "validation_results", ":", "\n", "                        ", "validation_results", "[", "sample_query_id", "]", "=", "[", "]", "\n", "\n", "", "validation_results", "[", "sample_query_id", "]", ".", "append", "(", "(", "sample_doc_id", ",", "float", "(", "output", "[", "sample_i", "]", ")", ")", ")", "\n", "\n", "#if not use_cache or fill_cache and i % 100 == 0: # only to check for performance regresion", "\n", "#    if validation_queue.qsize() < 10:", "\n", "#        _logger.warning(\"validation_queue.qsize() < 10\")", "\n", "\n", "", "", "", "if", "not", "use_cache", "or", "fill_cache", ":", "\n", "# make sure we didn't make a mistake in the configuration / data preparation", "\n", "            ", "if", "validation_queue", ".", "qsize", "(", ")", "!=", "0", ":", "\n", "                ", "_logger", ".", "error", "(", "\"validation_queue.qsize() is not empty after evaluation\"", ")", "\n", "\n", "", "validation_exit", ".", "set", "(", ")", "# allow sub-processes to exit", "\n", "\n", "", "", "except", "BaseException", "as", "e", ":", "\n", "        ", "_logger", ".", "info", "(", "'-'", "*", "89", ")", "\n", "_logger", ".", "exception", "(", "'[eval_model] Got exception: '", ")", "\n", "print", "(", "\"----- Attention! - something went wrong in eval_model (see logger) ----- \"", ")", "\n", "\n", "if", "not", "use_cache", "or", "fill_cache", ":", "\n", "            ", "for", "proc", "in", "validation_processes", ":", "\n", "                ", "if", "proc", ".", "is_alive", "(", ")", ":", "\n", "                    ", "proc", ".", "terminate", "(", ")", "\n", "", "", "", "raise", "e", "\n", "\n", "", "return", "validation_results", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.validate_model": [[106, 189], ["eval.evaluate_model", "os.path.join", "eval.save_sorted_results", "str", "evaluation.msmarco_eval.compute_metrics_with_cs_at_n", "os.path.join", "eval.save_one_metric_multiN", "range", "evaluation.msmarco_eval.compute_metrics_from_files", "os.path.join", "eval.save_fullmetrics_oneN", "os.remove", "str", "range", "os.path.join", "eval.save_fullmetrics_rangeN", "os.path.join", "eval.save_sorted_results", "str", "eval.save_fullmetrics_oneN", "os.path.join", "range", "str"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.evaluate_model", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_sorted_results", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_with_cs_at_n", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_one_metric_multiN", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_from_files", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_oneN", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_rangeN", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_sorted_results", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_oneN"], ["", "def", "validate_model", "(", "val_type", ",", "model", ",", "config", ",", "run_folder", ",", "_logger", ",", "cuda_device", ",", "epoch_number", ",", "batch_number", "=", "-", "1", ",", "global_best_info", "=", "None", ",", "candidate_set", "=", "None", ",", "use_cache", "=", "False", ")", ":", "\n", "\n", "# this means we currently after a completed batch", "\n", "    ", "if", "batch_number", "==", "-", "1", ":", "\n", "        ", "evaluation_id", "=", "str", "(", "epoch_number", ")", "\n", "\n", "# this means we currently are in an inter-batch evaluation", "\n", "", "else", ":", "\n", "        ", "evaluation_id", "=", "str", "(", "epoch_number", ")", "+", "\"-\"", "+", "str", "(", "batch_number", ")", "\n", "\n", "", "if", "val_type", "==", "\"end\"", ":", "\n", "        ", "evaluation_id", "=", "\"end-\"", "+", "evaluation_id", "\n", "config_prefix", "=", "\"validation_end\"", "\n", "", "else", ":", "\n", "        ", "config_prefix", "=", "\"validation_cont\"", "\n", "\n", "", "validation_results", "=", "evaluate_model", "(", "model", ",", "config", ",", "_logger", ",", "cuda_device", ",", "config", "[", "config_prefix", "+", "\"_tsv\"", "]", ",", "config", "[", "config_prefix", "+", "\"_batch_count\"", "]", ",", "use_cache", ")", "\n", "\n", "#", "\n", "# save sorted results", "\n", "#", "\n", "validation_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"validation-output-\"", "+", "evaluation_id", "+", "\".txt\"", ")", "\n", "lines", "=", "save_sorted_results", "(", "validation_results", ",", "validation_file_path", ")", "\n", "\n", "#", "\n", "# compute ir metrics (for ms_marco) and output them (to the logger + own csv file)", "\n", "# ---------------------------------", "\n", "#", "\n", "best_metric_info", "=", "{", "}", "\n", "best_metric_info", "[", "\"epoch\"", "]", "=", "epoch_number", "\n", "best_metric_info", "[", "\"batch_number\"", "]", "=", "batch_number", "\n", "\n", "#", "\n", "# do a cs@n over multiple n evaluation", "\n", "#", "\n", "if", "candidate_set", "!=", "None", ":", "\n", "        ", "metrics", "=", "compute_metrics_with_cs_at_n", "(", "config", "[", "config_prefix", "+", "\"_qrels\"", "]", ",", "validation_file_path", ",", "candidate_set", ",", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", ")", "\n", "\n", "# save mrr overview", "\n", "metric_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"validation-mrr-all.csv\"", ")", "\n", "save_one_metric_multiN", "(", "metric_file_path", ",", "metrics", ",", "\n", "\"MRR\"", ",", "range", "(", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "0", "]", ",", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "1", "]", "+", "1", ")", ",", "\n", "epoch_number", ",", "batch_number", ")", "\n", "\n", "# save all info + get best mrr", "\n", "best_mrr", "=", "0", "\n", "for", "current_cs_n", "in", "range", "(", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "0", "]", ",", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "1", "]", "+", "1", ")", ":", "\n", "            ", "metric_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"validation-metrics-cs_\"", "+", "str", "(", "current_cs_n", ")", "+", "\".csv\"", ")", "\n", "if", "val_type", "!=", "\"end\"", ":", "\n", "                ", "save_fullmetrics_oneN", "(", "metric_file_path", ",", "metrics", "[", "current_cs_n", "]", ",", "epoch_number", ",", "batch_number", ")", "\n", "", "if", "metrics", "[", "current_cs_n", "]", "[", "\"MRR\"", "]", ">", "best_mrr", ":", "\n", "                ", "best_mrr", "=", "metrics", "[", "current_cs_n", "]", "[", "\"MRR\"", "]", "\n", "best_metric_info", "[", "\"metrics\"", "]", "=", "metrics", "[", "current_cs_n", "]", "\n", "best_metric_info", "[", "\"cs@n\"", "]", "=", "current_cs_n", "\n", "\n", "# save at the end all in one file", "\n", "", "", "if", "val_type", "==", "\"end\"", ":", "\n", "            ", "save_fullmetrics_rangeN", "(", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"validation-metrics-end.csv\"", ")", ",", "metrics", ",", "range", "(", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "0", "]", ",", "config", "[", "config_prefix", "+", "\"_candidate_set_from_to\"", "]", "[", "1", "]", "+", "1", ")", ")", "\n", "\n", "#", "\n", "# do a 1x evaluation over the full given validation set", "\n", "#", "\n", "", "", "else", ":", "\n", "        ", "metrics", "=", "compute_metrics_from_files", "(", "config", "[", "config_prefix", "+", "\"_qrels\"", "]", ",", "validation_file_path", ")", "\n", "metric_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"validation-metrics.csv\"", ")", "\n", "save_fullmetrics_oneN", "(", "metric_file_path", ",", "metrics", ",", "epoch_number", ",", "batch_number", ")", "\n", "best_metric_info", "[", "\"metrics\"", "]", "=", "metrics", "\n", "best_metric_info", "[", "\"cs@n\"", "]", "=", "\"-\"", "\n", "best_mrr", "=", "metrics", "[", "\"MRR\"", "]", "\n", "#", "\n", "# save best results", "\n", "#", "\n", "", "if", "config", "[", "config_prefix", "+", "\"_save_only_best\"", "]", "==", "True", "and", "global_best_info", "!=", "None", ":", "\n", "        ", "os", ".", "remove", "(", "validation_file_path", ")", "\n", "if", "best_mrr", ">", "global_best_info", "[", "\"metrics\"", "]", "[", "\"MRR\"", "]", ":", "\n", "            ", "validation_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"best-validation-output.txt\"", ")", "\n", "save_sorted_results", "(", "validation_results", ",", "validation_file_path", ")", "\n", "\n", "#_logger.info('Validation for' + evaluation_id)", "\n", "#for metric in sorted(best_metric_info):", "\n", "#    _logger.info('{}: {}'.format(metric, best_metric_info[metric]))", "\n", "\n", "", "", "return", "best_metric_info", ",", "metrics", ",", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.test_model": [[193, 220], ["eval.evaluate_model", "os.path.join", "eval.save_sorted_results", "os.path.join", "eval.save_fullmetrics_oneN", "evaluation.msmarco_eval.compute_metrics_with_cs_at_n", "evaluation.msmarco_eval.compute_metrics_from_files"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.evaluate_model", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_sorted_results", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_oneN", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_with_cs_at_n", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_from_files"], ["", "def", "test_model", "(", "model", ",", "config", ",", "run_folder", ",", "_logger", ",", "cuda_device", ",", "candidate_set", "=", "None", ",", "candidate_set_n", "=", "None", ")", ":", "\n", "\n", "    ", "test_results", "=", "evaluate_model", "(", "model", ",", "config", ",", "_logger", ",", "cuda_device", ",", "config", "[", "\"test_tsv\"", "]", ",", "config", "[", "\"test_batch_count\"", "]", ")", "\n", "\n", "#", "\n", "# save sorted results", "\n", "#", "\n", "test_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"test-output.txt\"", ")", "\n", "save_sorted_results", "(", "test_results", ",", "test_file_path", ")", "\n", "\n", "#", "\n", "# compute ir metrics (for ms_marco) and output them (to the logger + own csv file)", "\n", "# ---------------------------------", "\n", "#", "\n", "metrics", "=", "None", "\n", "if", "\"test_qrels\"", "in", "config", ":", "\n", "\n", "        ", "if", "candidate_set", "!=", "None", ":", "\n", "            ", "metrics", "=", "compute_metrics_with_cs_at_n", "(", "config", "[", "\"test_qrels\"", "]", ",", "test_file_path", ",", "candidate_set", ",", "candidate_set_n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "compute_metrics_from_files", "(", "config", "[", "\"test_qrels\"", "]", ",", "test_file_path", ")", "\n", "\n", "", "metric_file_path", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"test-metrics.csv\"", ")", "\n", "save_fullmetrics_oneN", "(", "metric_file_path", ",", "metrics", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_sorted_results": [[222, 234], ["open", "results.items", "enumerate", "sorted", "val_file.write", "str"], "function", ["None"], ["", "def", "save_sorted_results", "(", "results", ",", "file", ",", "until_rank", "=", "-", "1", ")", ":", "\n", "    ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "val_file", ":", "\n", "        ", "lines", "=", "0", "\n", "for", "query_id", ",", "query_data", "in", "results", ".", "items", "(", ")", ":", "\n", "\n", "# sort the results per query based on the output", "\n", "            ", "for", "rank_i", ",", "(", "doc_id", ",", "output_value", ")", "in", "enumerate", "(", "sorted", "(", "query_data", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", ":", "\n", "                ", "val_file", ".", "write", "(", "\"\\t\"", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "[", "query_id", ",", "doc_id", ",", "rank_i", "+", "1", ",", "output_value", "]", ")", "+", "\"\\n\"", ")", "\n", "lines", "+=", "1", "\n", "if", "until_rank", ">", "-", "1", "and", "rank_i", "==", "until_rank", "+", "1", ":", "\n", "                    ", "break", "\n", "", "", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_oneN": [[235, 243], ["os.path.isfile", "open", "metric_file.write", "open", "metric_file.write", "str", "str", "str", "metrics.items", "metrics.items"], "function", ["None"], ["", "def", "save_fullmetrics_oneN", "(", "file", ",", "metrics", ",", "epoch_number", ",", "batch_number", ")", ":", "\n", "# write csv header once", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "metric_file", ":", "\n", "            ", "metric_file", ".", "write", "(", "\"sep=,\\nEpoch,After_Batch,\"", "+", "\",\"", ".", "join", "(", "k", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "# append single row", "\n", "", "", "with", "open", "(", "file", ",", "\"a\"", ")", "as", "metric_file", ":", "\n", "        ", "metric_file", ".", "write", "(", "str", "(", "epoch_number", ")", "+", "\",\"", "+", "str", "(", "batch_number", ")", "+", "\",\"", "+", "\",\"", ".", "join", "(", "str", "(", "v", ")", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_fullmetrics_rangeN": [[244, 253], ["os.path.isfile", "open", "open", "metric_file.write", "metric_file.write", "str", "str", "metrics[].items", "metrics[].items"], "function", ["None"], ["", "", "def", "save_fullmetrics_rangeN", "(", "file", ",", "metrics", ",", "m_range", ")", ":", "\n", "# write csv header once", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "metric_file", ":", "\n", "            ", "metric_file", ".", "write", "(", "\"sep=,\\ncs@n,\"", "+", "\",\"", ".", "join", "(", "k", "for", "k", ",", "v", "in", "metrics", "[", "m_range", ".", "start", "]", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "# append single row", "\n", "", "", "with", "open", "(", "file", ",", "\"a\"", ")", "as", "metric_file", ":", "\n", "        ", "for", "cs_n", "in", "m_range", ":", "\n", "            ", "metric_file", ".", "write", "(", "str", "(", "cs_n", ")", "+", "\",\"", "+", "\",\"", ".", "join", "(", "str", "(", "v", ")", "for", "k", ",", "v", "in", "metrics", "[", "cs_n", "]", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_best_info": [[255, 259], ["open", "metric_file.write", "metric_file.write", "str", "str", "best_info[].items", "best_info[].items", "str", "str"], "function", ["None"], ["", "", "", "def", "save_best_info", "(", "file", ",", "best_info", ")", ":", "\n", "    ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "metric_file", ":", "\n", "        ", "metric_file", ".", "write", "(", "\"sep=,\\nEpoch,batch_number,cs@n,\"", "+", "\",\"", ".", "join", "(", "k", "for", "k", ",", "v", "in", "best_info", "[", "\"metrics\"", "]", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "metric_file", ".", "write", "(", "str", "(", "best_info", "[", "\"epoch\"", "]", ")", "+", "\",\"", "+", "str", "(", "best_info", "[", "\"batch_number\"", "]", ")", "+", "\",\"", "+", "str", "(", "best_info", "[", "\"cs@n\"", "]", ")", "+", "\",\"", "+", "\",\"", ".", "join", "(", "str", "(", "v", ")", "for", "k", ",", "v", "in", "best_info", "[", "\"metrics\"", "]", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.eval.save_one_metric_multiN": [[261, 270], ["os.path.isfile", "open", "metric_file.write", "open", "metric_file.write", "str", "str", "str", "str", "metrics.items"], "function", ["None"], ["", "", "def", "save_one_metric_multiN", "(", "file", ",", "metrics", ",", "selected_metric", ",", "over_range", ",", "epoch_number", ",", "batch_number", ")", ":", "\n", "# write csv header once", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "metric_file", ":", "\n", "            ", "metric_file", ".", "write", "(", "\"sep=,\\nEpoch,After_Batch,\"", "+", "\",\"", ".", "join", "(", "str", "(", "k", ")", "for", "k", "in", "over_range", ")", "+", "\"\\n\"", ")", "\n", "\n", "# append single row", "\n", "", "", "with", "open", "(", "file", ",", "\"a\"", ")", "as", "metric_file", ":", "\n", "        ", "metric_file", ".", "write", "(", "str", "(", "epoch_number", ")", "+", "\",\"", "+", "str", "(", "batch_number", ")", "+", "\",\"", "+", "\",\"", ".", "join", "(", "str", "(", "v", "[", "selected_metric", "]", ")", "for", "cs_at_n", ",", "v", "in", "metrics", ".", "items", "(", ")", ")", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.performance_monitor.PerformanceMonitor.__init__": [[4, 7], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "timings", "=", "{", "}", "\n", "self", ".", "current_times", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.performance_monitor.PerformanceMonitor.start_block": [[8, 10], ["timeit.default_timer"], "methods", ["None"], ["", "def", "start_block", "(", "self", ",", "category", ":", "str", ")", ":", "\n", "        ", "self", ".", "current_times", "[", "category", "]", "=", "default_timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.performance_monitor.PerformanceMonitor.stop_block": [[11, 18], ["timeit.default_timer"], "methods", ["None"], ["", "def", "stop_block", "(", "self", ",", "category", ":", "str", ",", "instances", ":", "int", "=", "1", ")", ":", "\n", "        ", "if", "not", "category", "in", "self", ".", "timings", ":", "\n", "            ", "self", ".", "timings", "[", "category", "]", "=", "(", "0", ",", "0", ")", "\n", "\n", "", "time", ",", "old_instances", "=", "self", ".", "timings", "[", "category", "]", "\n", "\n", "self", ".", "timings", "[", "category", "]", "=", "(", "time", "+", "default_timer", "(", ")", "-", "self", ".", "current_times", "[", "category", "]", ",", "old_instances", "+", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.performance_monitor.PerformanceMonitor.print_summary": [[19, 25], ["performance_monitor.PerformanceMonitor.timings.items", "print", "print"], "methods", ["None"], ["", "def", "print_summary", "(", "self", ")", ":", "\n", "        ", "for", "cat", ",", "(", "time", ",", "instances", ")", "in", "self", ".", "timings", ".", "items", "(", ")", ":", "\n", "            ", "if", "instances", ">", "1", ":", "\n", "                ", "print", "(", "cat", ",", "instances", "/", "time", ",", "\"it/s\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "cat", ",", "time", ",", "\"s\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.performance_monitor.PerformanceMonitor.save_summary": [[26, 33], ["open", "performance_monitor.PerformanceMonitor.timings.items", "out_file.write", "out_file.write", "str", "str"], "methods", ["None"], ["", "", "", "def", "save_summary", "(", "self", ",", "file", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "out_file", ":", "\n", "            ", "for", "cat", ",", "(", "time", ",", "instances", ")", "in", "self", ".", "timings", ".", "items", "(", ")", ":", "\n", "                ", "if", "instances", ">", "1", ":", "\n", "                    ", "out_file", ".", "write", "(", "cat", "+", "str", "(", "instances", "/", "time", ")", "+", "\"it/s\\n\"", ")", "\n", "", "else", ":", "\n", "                    ", "out_file", ".", "write", "(", "cat", "+", "str", "(", "time", ")", "+", "\"s\\n\"", ")", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.Timer.__init__": [[12, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "message", ")", ":", "\n", "        ", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.Timer.__enter__": [[15, 18], ["timeit.default_timer", "print"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "default_timer", "(", ")", "\n", "print", "(", "self", ".", "message", "+", "\" started ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.Timer.__exit__": [[19, 22], ["print", "timeit.default_timer"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "type", ",", "value", ",", "traceback", ")", ":", "\n", "        ", "print", "(", "self", ".", "message", "+", "\" finished, after (s): \"", ",", "\n", "(", "default_timer", "(", ")", "-", "self", ".", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.EarlyStopping.__init__": [[124, 134], ["utils.EarlyStopping._init_is_better"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.EarlyStopping._init_is_better"], ["    ", "def", "__init__", "(", "self", ",", "mode", "=", "'min'", ",", "min_delta", "=", "0", ",", "patience", "=", "10", ",", "percentage", "=", "False", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "self", ".", "min_delta", "=", "min_delta", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "best", "=", "None", "\n", "self", ".", "num_bad_epochs", "=", "0", "\n", "self", ".", "is_better", "=", "None", "\n", "self", ".", "_init_is_better", "(", "mode", ",", "min_delta", ",", "percentage", ")", "\n", "\n", "self", ".", "stop", "=", "False", "\n", "#if patience == 0:", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.EarlyStopping.step": [[138, 158], ["numpy.isnan", "utils.EarlyStopping.is_better"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "metrics", ")", ":", "\n", "        ", "if", "self", ".", "best", "is", "None", ":", "\n", "            ", "self", ".", "best", "=", "metrics", "\n", "return", "False", "\n", "\n", "", "if", "numpy", ".", "isnan", "(", "metrics", ")", ":", "\n", "            ", "self", ".", "stop", "=", "True", "\n", "return", "True", "\n", "\n", "", "if", "self", ".", "is_better", "(", "metrics", ",", "self", ".", "best", ")", ":", "\n", "            ", "self", ".", "num_bad_epochs", "=", "0", "\n", "self", ".", "best", "=", "metrics", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_bad_epochs", "+=", "1", "\n", "\n", "", "if", "self", ".", "num_bad_epochs", ">=", "self", ".", "patience", ":", "\n", "            ", "self", ".", "stop", "=", "True", "\n", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.EarlyStopping._init_is_better": [[159, 174], ["ValueError"], "methods", ["None"], ["", "def", "_init_is_better", "(", "self", ",", "mode", ",", "min_delta", ",", "percentage", ")", ":", "\n", "        ", "if", "mode", "not", "in", "{", "'min'", ",", "'max'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "'mode '", "+", "mode", "+", "' is unknown!'", ")", "\n", "", "if", "not", "percentage", ":", "\n", "            ", "if", "mode", "==", "'min'", ":", "\n", "                ", "self", ".", "is_better", "=", "lambda", "a", ",", "best", ":", "a", "<", "best", "-", "min_delta", "\n", "", "if", "mode", "==", "'max'", ":", "\n", "                ", "self", ".", "is_better", "=", "lambda", "a", ",", "best", ":", "a", ">", "best", "+", "min_delta", "\n", "", "", "else", ":", "\n", "            ", "if", "mode", "==", "'min'", ":", "\n", "                ", "self", ".", "is_better", "=", "lambda", "a", ",", "best", ":", "a", "<", "best", "-", "(", "\n", "best", "*", "min_delta", "/", "100", ")", "\n", "", "if", "mode", "==", "'max'", ":", "\n", "                ", "self", ".", "is_better", "=", "lambda", "a", ",", "best", ":", "a", ">", "best", "+", "(", "\n", "best", "*", "min_delta", "/", "100", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.get_config": [[23, 35], ["open", "yaml.load", "yaml.load", "d.items", "overwrites.split"], "function", ["None"], ["", "", "def", "get_config", "(", "config_path", ":", "str", ",", "overwrites", ":", "str", "=", "None", ")", "->", "Dict", "[", "str", ",", "any", "]", ":", "\n", "    ", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "ymlfile", ":", "\n", "        ", "cfg", "=", "yaml", ".", "load", "(", "ymlfile", ")", "\n", "\n", "", "if", "overwrites", "is", "not", "None", "and", "overwrites", "!=", "\"\"", ":", "\n", "        ", "over_parts", "=", "[", "yaml", ".", "load", "(", "x", ")", "for", "x", "in", "overwrites", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "for", "d", "in", "over_parts", ":", "\n", "            ", "for", "key", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "cfg", "[", "key", "]", "=", "value", "\n", "\n", "", "", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.save_config": [[36, 39], ["open", "yaml.safe_dump"], "function", ["None"], ["", "def", "save_config", "(", "config_path", ":", "str", ",", "config", ":", "Dict", "[", "str", ",", "any", "]", ")", ":", "\n", "    ", "with", "open", "(", "config_path", ",", "'w'", ")", "as", "ymlfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "config", ",", "ymlfile", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.get_parser": [[41, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--run-name'", ",", "action", "=", "'store'", ",", "dest", "=", "'run_name'", ",", "\n", "help", "=", "'run name, used for the run folder (no spaces, special characters)'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--run-folder'", ",", "action", "=", "'store'", ",", "dest", "=", "'run_folder'", ",", "\n", "help", "=", "'run folder if it exists, if not set a new one is created using run-name'", ",", "required", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--config-file'", ",", "action", "=", "'store'", ",", "dest", "=", "'config_file'", ",", "\n", "help", "=", "'config file with all hyper-params & paths'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--config-overwrites'", ",", "action", "=", "'store'", ",", "dest", "=", "'config_overwrites'", ",", "\n", "help", "=", "'overwrite config values -> key1: valueA,key2: valueB '", ",", "required", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gpu-id'", ",", "action", "=", "'store'", ",", "dest", "=", "'cuda_device_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'optional cuda device id for multi gpu parallel runs of train.py'", ",", "required", "=", "False", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.get_logger_to_file": [[58, 70], ["logging.getLogger", "logging.Formatter", "logging.getLogger.setLevel", "os.path.join", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.FileHandler.setLevel", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "get_logger_to_file", "(", "run_folder", ",", "name", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)s %(message)s'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "log_filepath", "=", "os", ".", "path", ".", "join", "(", "run_folder", ",", "'log.txt'", ")", "\n", "file_hdlr", "=", "logging", ".", "FileHandler", "(", "log_filepath", ")", "\n", "file_hdlr", ".", "setFormatter", "(", "formatter", ")", "\n", "file_hdlr", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "logger", ".", "addHandler", "(", "file_hdlr", ")", "\n", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.prepare_experiment_folder": [[71, 79], ["datetime.datetime.now().strftime", "os.path.join", "os.makedirs", "datetime.datetime.now"], "function", ["None"], ["", "def", "prepare_experiment_folder", "(", "base_path", ",", "run_name", ")", ":", "\n", "    ", "time_stamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d_%H%M'", ")", "\n", "\n", "run_folder", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "time_stamp", "+", "\"_\"", "+", "run_name", ")", "\n", "\n", "os", ".", "makedirs", "(", "run_folder", ")", "\n", "\n", "return", "run_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.prepare_experiment": [[80, 98], ["utils.save_config", "os.path.dirname", "shutil.copytree", "utils.prepare_experiment_folder", "os.path.join", "os.path.realpath", "os.path.join", "shutil.ignore_patterns"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.save_config", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.prepare_experiment_folder"], ["", "def", "prepare_experiment", "(", "args", ",", "config", ")", ":", "\n", "    ", "if", "args", ".", "run_folder", "is", "not", "None", ":", "\n", "        ", "run_folder", "=", "args", ".", "run_folder", "\n", "", "else", ":", "\n", "        ", "run_folder", "=", "prepare_experiment_folder", "(", "config", "[", "\"expirement_base_path\"", "]", ",", "args", ".", "run_name", ")", "\n", "#", "\n", "# saved uased config (with overwrites)", "\n", "#     ", "\n", "", "save_config", "(", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"config.yaml\"", ")", ",", "config", ")", "\n", "\n", "#", "\n", "# copy source code of matchmaker", "\n", "#", "\n", "dir_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "\n", "shutil", ".", "copytree", "(", "dir_path", ",", "os", ".", "path", ".", "join", "(", "run_folder", ",", "\"matchmaker-src\"", ")", ",", "ignore", "=", "shutil", ".", "ignore_patterns", "(", "\"__pycache__\"", ")", ")", "\n", "\n", "return", "run_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.utils.parse_candidate_set": [[99, 118], ["open", "line.split.split", "int", "int", "int"], "function", ["None"], ["", "def", "parse_candidate_set", "(", "file_path", ",", "to_N", ")", ":", "\n", "    ", "candidate_set", "=", "{", "}", "# dict[qid] -> dict[did] -> rank", "\n", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "cs_file", ":", "\n", "        ", "for", "line", "in", "cs_file", ":", "\n", "            ", "line", "=", "line", ".", "split", "(", ")", "\n", "\n", "rank", "=", "int", "(", "line", "[", "3", "]", ")", "\n", "\n", "if", "rank", "<=", "to_N", ":", "\n", "\n", "                ", "q_id", "=", "int", "(", "line", "[", "0", "]", ")", "\n", "d_id", "=", "int", "(", "line", "[", "2", "]", ")", "\n", "\n", "if", "q_id", "not", "in", "candidate_set", ":", "\n", "                    ", "candidate_set", "[", "q_id", "]", "=", "{", "}", "\n", "", "candidate_set", "[", "q_id", "]", "[", "d_id", "]", "=", "rank", "\n", "\n", "", "", "", "return", "candidate_set", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.multiprocess_input_pipeline.get_multiprocess_batch_queue": [[33, 59], ["torch.get_context", "mp.get_context.Queue", "mp.get_context.Event", "enumerate", "len", "_logger.error", "exit", "_logger.info", "mp.get_context.Process", "ctx.Process.start", "_processes.append", "dataloaders.fasttext_token_indexer.FastTextVocab.load_ids", "fasttext_vocab_cached_data.share_memory_", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextVocab.load_ids"], ["def", "get_multiprocess_batch_queue", "(", "name_prefix", ":", "str", ",", "target_function", ",", "files", ",", "conf", ",", "_logger", ",", "queue_size", "=", "100", ")", "->", "Tuple", "[", "mp", ".", "Queue", ",", "List", "[", "mp", ".", "Process", "]", ",", "mp", ".", "Event", "]", ":", "\n", "    ", "ctx", "=", "mp", ".", "get_context", "(", "'spawn'", ")", "# also set so that windows & linux behave the same ", "\n", "_queue", "=", "ctx", ".", "Queue", "(", "queue_size", ")", "\n", "_processes", "=", "[", "]", "\n", "_finish_notification", "=", "ctx", ".", "Event", "(", ")", "\n", "\n", "if", "len", "(", "files", ")", "==", "0", ":", "\n", "        ", "_logger", ".", "error", "(", "\"No files for multiprocess loading specified, for: \"", "+", "name_prefix", ")", "\n", "exit", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "_logger", ".", "info", "(", "\"Starting \"", "+", "str", "(", "len", "(", "files", ")", ")", "+", "\" data loader processes, for:\"", "+", "name_prefix", ")", "\n", "\n", "", "if", "conf", "[", "\"token_embedder_type\"", "]", "==", "\"fasttext\"", ":", "\n", "        ", "global", "fasttext_vocab_cached_mapping", "\n", "global", "fasttext_vocab_cached_data", "\n", "if", "fasttext_vocab_cached_data", "is", "None", ":", "\n", "            ", "fasttext_vocab_cached_mapping", ",", "fasttext_vocab_cached_data", "=", "FastTextVocab", ".", "load_ids", "(", "conf", "[", "\"fasttext_vocab_mapping\"", "]", ",", "conf", "[", "\"fasttext_max_subwords\"", "]", ")", "\n", "fasttext_vocab_cached_data", ".", "share_memory_", "(", ")", "\n", "\n", "", "", "for", "proc_number", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "process", "=", "ctx", ".", "Process", "(", "name", "=", "name_prefix", "+", "\"-\"", "+", "str", "(", "proc_number", ")", ",", "\n", "target", "=", "target_function", ",", "\n", "args", "=", "(", "proc_number", ",", "conf", ",", "_queue", ",", "_finish_notification", ",", "file", ",", "fasttext_vocab_cached_mapping", ",", "fasttext_vocab_cached_data", ")", ")", "\n", "process", ".", "start", "(", ")", "\n", "_processes", ".", "append", "(", "process", ")", "\n", "", "return", "_queue", ",", "_processes", ",", "_finish_notification", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.multiprocess_input_pipeline.multiprocess_training_loader": [[66, 99], ["dataloaders.ir_triple_loader.IrTripleDatasetReader", "allennlp.data.iterators.BucketIterator", "allennlp.data.iterators.BucketIterator.index_with", "allennlp.data.iterators.BucketIterator.", "_queue.close", "_wait_for_exit.wait", "WordTokenizer", "allennlp.data.vocabulary.Vocabulary.from_files", "dataloaders.ir_triple_loader.IrTripleDatasetReader.read", "_queue.put", "SingleIdTokenIndexer", "dataloaders.fasttext_token_indexer.FastTextVocab", "int", "allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter", "dataloaders.fasttext_token_indexer.FastTextNGramIndexer", "allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer"], "function", ["None"], ["", "def", "multiprocess_training_loader", "(", "process_number", ":", "int", ",", "_config", ",", "_queue", ":", "mp", ".", "Queue", ",", "_wait_for_exit", ":", "mp", ".", "Event", ",", "_local_file", ",", "_fasttext_vocab_cached_mapping", ",", "_fasttext_vocab_cached_data", ")", ":", "\n", "\n", "# workflow: we tokenize the data files with the costly spacy before training in a preprocessing step ", "\n", "# (and concat the tokens with single whitespaces), so here we only split on the whitepsaces", "\n", "    ", "_tokenizer", "=", "None", "\n", "if", "_config", "[", "\"preprocessed_tokenized\"", "]", "==", "True", ":", "\n", "        ", "_tokenizer", "=", "WordTokenizer", "(", "word_splitter", "=", "JustSpacesWordSplitter", "(", ")", ")", "\n", "\n", "", "if", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"embedding\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "lowercase_tokens", "=", "True", ")", "}", "\n", "_vocab", "=", "Vocabulary", ".", "from_files", "(", "_config", "[", "\"vocab_directory\"", "]", ")", "\n", "\n", "", "elif", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"fasttext\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "FastTextNGramIndexer", "(", "_config", "[", "\"fasttext_max_subwords\"", "]", ")", "}", "\n", "_vocab", "=", "FastTextVocab", "(", "_fasttext_vocab_cached_mapping", ",", "_fasttext_vocab_cached_data", ",", "_config", "[", "\"fasttext_max_subwords\"", "]", ")", "\n", "\n", "", "elif", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"elmo\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "ELMoTokenCharactersIndexer", "(", ")", "}", "\n", "_vocab", "=", "None", "\n", "\n", "", "_triple_loader", "=", "IrTripleDatasetReader", "(", "lazy", "=", "True", ",", "tokenizer", "=", "_tokenizer", ",", "token_indexers", "=", "_token_indexers", ",", "max_doc_length", "=", "_config", "[", "\"max_doc_length\"", "]", ",", "max_query_length", "=", "_config", "[", "\"max_query_length\"", "]", ")", "\n", "\n", "_iterator", "=", "BucketIterator", "(", "batch_size", "=", "int", "(", "_config", "[", "\"batch_size_train\"", "]", ")", ",", "\n", "sorting_keys", "=", "[", "(", "\"doc_pos_tokens\"", ",", "\"num_tokens\"", ")", ",", "(", "\"doc_neg_tokens\"", ",", "\"num_tokens\"", ")", "]", ")", "\n", "\n", "_iterator", ".", "index_with", "(", "_vocab", ")", "\n", "\n", "for", "training_batch", "in", "_iterator", "(", "_triple_loader", ".", "read", "(", "_local_file", ")", ",", "num_epochs", "=", "1", ")", ":", "\n", "\n", "        ", "_queue", ".", "put", "(", "training_batch", ")", "# this moves the tensors in to shared memory", "\n", "\n", "", "_queue", ".", "close", "(", ")", "# indicate this local thread is done", "\n", "_wait_for_exit", ".", "wait", "(", ")", "# keep this process alive until all the shared memory is used and not needed anymore", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.matchmaker.multiprocess_input_pipeline.multiprocess_validation_loader": [[105, 138], ["dataloaders.ir_labeled_tuple_loader.IrLabeledTupleDatasetReader", "allennlp.data.iterators.BucketIterator", "allennlp.data.iterators.BucketIterator.index_with", "allennlp.data.iterators.BucketIterator.", "_queue.close", "_wait_for_exit.wait", "WordTokenizer", "allennlp.data.vocabulary.Vocabulary.from_files", "dataloaders.ir_labeled_tuple_loader.IrLabeledTupleDatasetReader.read", "_queue.put", "SingleIdTokenIndexer", "dataloaders.fasttext_token_indexer.FastTextVocab", "int", "allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter", "dataloaders.fasttext_token_indexer.FastTextNGramIndexer", "allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer"], "function", ["None"], ["", "def", "multiprocess_validation_loader", "(", "process_number", ":", "int", ",", "_config", ",", "_queue", ":", "mp", ".", "Queue", ",", "_wait_for_exit", ":", "mp", ".", "Event", ",", "_local_file", ",", "_fasttext_vocab_cached_mapping", ",", "_fasttext_vocab_cached_data", ")", ":", "\n", "\n", "# workflow: we tokenize the data files with the costly spacy before training in a preprocessing step ", "\n", "# (and concat the tokens with single whitespaces), so here we only split on the whitepsaces", "\n", "    ", "_tokenizer", "=", "None", "\n", "if", "_config", "and", "_config", "[", "\"preprocessed_tokenized\"", "]", "==", "True", ":", "\n", "        ", "_tokenizer", "=", "WordTokenizer", "(", "word_splitter", "=", "JustSpacesWordSplitter", "(", ")", ")", "\n", "\n", "", "if", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"embedding\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "lowercase_tokens", "=", "True", ")", "}", "\n", "_vocab", "=", "Vocabulary", ".", "from_files", "(", "_config", "[", "\"vocab_directory\"", "]", ")", "\n", "\n", "", "elif", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"fasttext\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "FastTextNGramIndexer", "(", "_config", "[", "\"fasttext_max_subwords\"", "]", ")", "}", "\n", "_vocab", "=", "FastTextVocab", "(", "_fasttext_vocab_cached_mapping", ",", "_fasttext_vocab_cached_data", ",", "_config", "[", "\"fasttext_max_subwords\"", "]", ")", "\n", "\n", "", "elif", "_config", "[", "\"token_embedder_type\"", "]", "==", "\"elmo\"", ":", "\n", "        ", "_token_indexers", "=", "{", "\"tokens\"", ":", "ELMoTokenCharactersIndexer", "(", ")", "}", "\n", "_vocab", "=", "None", "\n", "\n", "", "_tuple_loader", "=", "IrLabeledTupleDatasetReader", "(", "lazy", "=", "True", ",", "tokenizer", "=", "_tokenizer", ",", "token_indexers", "=", "_token_indexers", ",", "max_doc_length", "=", "_config", "[", "\"max_doc_length\"", "]", ",", "max_query_length", "=", "_config", "[", "\"max_query_length\"", "]", ")", "\n", "\n", "_iterator", "=", "BucketIterator", "(", "batch_size", "=", "int", "(", "_config", "[", "\"batch_size_eval\"", "]", ")", ",", "\n", "sorting_keys", "=", "[", "(", "\"doc_tokens\"", ",", "\"num_tokens\"", ")", ",", "(", "\"query_tokens\"", ",", "\"num_tokens\"", ")", "]", ")", "\n", "\n", "_iterator", ".", "index_with", "(", "_vocab", ")", "\n", "\n", "for", "training_batch", "in", "_iterator", "(", "_tuple_loader", ".", "read", "(", "_local_file", ")", ",", "num_epochs", "=", "1", ")", ":", "\n", "\n", "        ", "_queue", ".", "put", "(", "training_batch", ")", "# this moves the tensors in to shared memory", "\n", "\n", "", "_queue", ".", "close", "(", ")", "# indicate this local thread is done", "\n", "_wait_for_exit", ".", "wait", "(", ")", "# keep this process alive until all the shared memory is used and not needed anymore", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.preprocessing.generate_vocab.getInstances": [[54, 59], ["loader.read", "Instance"], "function", ["None"], ["def", "getInstances", "(", ")", ":", "\n", "    ", "for", "file", "in", "args", ".", "dataset_files", ":", "\n", "        ", "instances", "=", "loader", ".", "read", "(", "file", ")", "\n", "for", "i", "in", "instances", ":", "\n", "            ", "yield", "Instance", "(", "{", "\"text\"", ":", "i", "[", "\"target_tokens\"", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.modules.fasttext_token_embedder.FastTextEmbeddingBag.__init__": [[9, 13], ["torch.nn.modules.sparse.EmbeddingBag.__init__", "fasttext_token_embedder.FastTextEmbeddingBag.weight.data.copy_", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_matrix", ",", "sparse", "=", "False", ")", ":", "\n", "        ", "embedding_matrix_shape", "=", "embedding_matrix", ".", "shape", "\n", "super", "(", ")", ".", "__init__", "(", "embedding_matrix_shape", "[", "0", "]", ",", "embedding_matrix_shape", "[", "1", "]", ",", "sparse", "=", "sparse", ")", "\n", "self", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "FloatTensor", "(", "embedding_matrix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.modules.fasttext_token_embedder.FastTextEmbeddingBag.get_output_dim": [[14, 16], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "weight", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.modules.fasttext_token_embedder.FastTextEmbeddingBag.forward": [[19, 33], ["token_subwordIds.view", "super().forward", "super().forward.view"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward"], ["", "def", "forward", "(", "self", ",", "token_subwordIds", ")", ":", "\n", "\n", "#token_subwordIds.shape = batch, token_max (padded), subword_max (padded)", "\n", "\n", "#one_view.shape = batch * token_max (padded), subword_max (padded)", "\n", "        ", "one_view", "=", "token_subwordIds", ".", "view", "(", "-", "1", ",", "token_subwordIds", ".", "shape", "[", "2", "]", ")", "\n", "\n", "#out.shape = batch * token_max (padded), embedding_dim", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "one_view", ")", "\n", "\n", "#out_batched.shape = batch, token_max (padded), embedding_dim", "\n", "out_batched", "=", "out", ".", "view", "(", "token_subwordIds", ".", "shape", "[", "0", "]", ",", "token_subwordIds", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "return", "out_batched", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.knrm.KNRM.__init__": [[20, 40], ["torch.Module.__init__", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "allennlp.modules.matrix_attention.cosine_matrix_attention.CosineMatrixAttention", "torch.Linear", "torch.Linear", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "knrm.KNRM.kernel_mus", "knrm.KNRM.kernel_sigmas"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_mus", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_sigmas"], ["def", "__init__", "(", "self", ",", "\n", "word_embeddings", ":", "TextFieldEmbedder", ",", "\n", "n_kernels", ":", "int", ")", ":", "\n", "\n", "        ", "super", "(", "KNRM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embeddings", "=", "word_embeddings", "\n", "\n", "# static - kernel size & magnitude variables", "\n", "self", ".", "mu", "=", "Variable", "(", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "kernel_mus", "(", "n_kernels", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "n_kernels", ")", "\n", "self", ".", "sigma", "=", "Variable", "(", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "kernel_sigmas", "(", "n_kernels", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "n_kernels", ")", "\n", "\n", "# this does not really do \"attention\" - just a plain cosine matrix calculation (without learnable weights) ", "\n", "self", ".", "cosine_module", "=", "CosineMatrixAttention", "(", ")", "\n", "\n", "# bias is set to True in original code (we found it to not help, how could it?)", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "n_kernels", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "# init with small weights, otherwise the dense output is way to high for the tanh -> resulting in loss == 1 all the time", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "dense", ".", "weight", ",", "-", "0.014", ",", "0.014", ")", "# inits taken from matchzoo", "\n", "#self.dense.bias.data.fill_(0.0)", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.knrm.KNRM.forward": [[42, 104], ["knrm.KNRM.word_embeddings", "knrm.KNRM.word_embeddings", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.unsqueeze", "torch.bmm.unsqueeze", "knrm.KNRM.cosine_module.forward", "cosine_matrix_masked.unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "knrm.KNRM.dense", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "len", "query_pad_oov_mask.unsqueeze", "document_pad_oov_mask.unsqueeze().transpose", "torch.log", "torch.log", "torch.log", "torch.log", "query_pad_oov_mask.unsqueeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "document_pad_oov_mask.unsqueeze", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward"], ["", "def", "forward", "(", "self", ",", "query", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "document", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "query_length", ":", "torch", ".", "Tensor", ",", "document_length", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=arguments-differ", "\n", "\n", "#", "\n", "# prepare embedding tensors & paddings masks", "\n", "# -------------------------------------------------------", "\n", "\n", "# shape: (batch, query_max,emb_dim)", "\n", "        ", "query_embeddings", "=", "self", ".", "word_embeddings", "(", "query", ")", "\n", "\n", "# shape: (batch, document_max,emb_dim)", "\n", "document_embeddings", "=", "self", ".", "word_embeddings", "(", "document", ")", "\n", "\n", "# we assume 1 is the unknown token, 0 is padding - both need to be removed", "\n", "\n", "if", "len", "(", "query", "[", "\"tokens\"", "]", ".", "shape", ")", "==", "2", ":", "# (embedding lookup matrix)", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "query", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "document", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "", "else", ":", "# == 3 (elmo characters per word)", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "query", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "document", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "\n", "", "query_by_doc_mask", "=", "torch", ".", "bmm", "(", "query_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "document_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "query_by_doc_mask_view", "=", "query_by_doc_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "#", "\n", "# cosine matrix", "\n", "# -------------------------------------------------------", "\n", "\n", "# shape: (batch, query_max, doc_max)", "\n", "cosine_matrix", "=", "self", ".", "cosine_module", ".", "forward", "(", "query_embeddings", ",", "document_embeddings", ")", "\n", "cosine_matrix_masked", "=", "cosine_matrix", "*", "query_by_doc_mask", "\n", "cosine_matrix_extradim", "=", "cosine_matrix_masked", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "#", "\n", "# gaussian kernels & soft-TF", "\n", "#", "\n", "# first run through kernel, then sum on doc dim then sum on query dim", "\n", "# -------------------------------------------------------", "\n", "\n", "raw_kernel_results", "=", "torch", ".", "exp", "(", "-", "torch", ".", "pow", "(", "cosine_matrix_extradim", "-", "self", ".", "mu", ",", "2", ")", "/", "(", "2", "*", "torch", ".", "pow", "(", "self", ".", "sigma", ",", "2", ")", ")", ")", "\n", "kernel_results_masked", "=", "raw_kernel_results", "*", "query_by_doc_mask_view", "\n", "\n", "per_kernel_query", "=", "torch", ".", "sum", "(", "kernel_results_masked", ",", "2", ")", "\n", "log_per_kernel_query", "=", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "per_kernel_query", ",", "min", "=", "1e-10", ")", ")", "*", "0.01", "\n", "log_per_kernel_query_masked", "=", "log_per_kernel_query", "*", "query_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "# make sure we mask out padding values", "\n", "\n", "per_kernel", "=", "torch", ".", "sum", "(", "log_per_kernel_query_masked", ",", "1", ")", "\n", "\n", "##", "\n", "## \"Learning to rank\" layer - connects kernels with learned weights", "\n", "## -------------------------------------------------------", "\n", "\n", "dense_out", "=", "self", ".", "dense", "(", "per_kernel", ")", "\n", "score", "=", "torch", ".", "squeeze", "(", "dense_out", ",", "1", ")", "#torch.tanh(dense_out), 1)", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.knrm.KNRM.kernel_mus": [[105, 120], ["l_mu.append", "range", "l_mu.append"], "methods", ["None"], ["", "def", "kernel_mus", "(", "self", ",", "n_kernels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        get the mu for each guassian kernel. Mu is the middle of each bin\n        :param n_kernels: number of kernels (including exact match). first one is exact match\n        :return: l_mu, a list of mu.\n        \"\"\"", "\n", "l_mu", "=", "[", "1.0", "]", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_mu", "\n", "\n", "", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "# score range from [-1, 1]", "\n", "l_mu", ".", "append", "(", "1", "-", "bin_size", "/", "2", ")", "# mu: middle of the bin", "\n", "for", "i", "in", "range", "(", "1", ",", "n_kernels", "-", "1", ")", ":", "\n", "            ", "l_mu", ".", "append", "(", "l_mu", "[", "i", "]", "-", "bin_size", ")", "\n", "", "return", "l_mu", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.knrm.KNRM.kernel_sigmas": [[121, 136], ["None"], "methods", ["None"], ["", "def", "kernel_sigmas", "(", "self", ",", "n_kernels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        get sigmas for each guassian kernel.\n        :param n_kernels: number of kernels (including exactmath.)\n        :param lamb:\n        :param use_exact:\n        :return: l_sigma, a list of simga\n        \"\"\"", "\n", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "\n", "l_sigma", "=", "[", "0.0001", "]", "# for exact match. small variance -> exact match", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_sigma", "\n", "\n", "", "l_sigma", "+=", "[", "0.5", "*", "bin_size", "]", "*", "(", "n_kernels", "-", "1", ")", "\n", "return", "l_sigma", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.__init__": [[20, 53], ["torch.Module.__init__", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "allennlp.modules.matrix_attention.cosine_matrix_attention.CosineMatrixAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "conv_knrm.Conv_KNRM.convolutions.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.ConstantPad1d", "torch.ConstantPad1d", "torch.ConstantPad1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "conv_knrm.Conv_KNRM.kernel_mus", "conv_knrm.Conv_KNRM.kernel_sigmas", "word_embeddings.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_mus", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_sigmas", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.modules.fasttext_token_embedder.FastTextEmbeddingBag.get_output_dim"], ["def", "__init__", "(", "self", ",", "\n", "word_embeddings", ":", "TextFieldEmbedder", ",", "\n", "n_grams", ":", "int", ",", "\n", "n_kernels", ":", "int", ",", "\n", "conv_out_dim", ":", "int", ")", ":", "\n", "\n", "        ", "super", "(", "Conv_KNRM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embeddings", "=", "word_embeddings", "\n", "\n", "# static - kernel size & magnitude variables", "\n", "self", ".", "mu", "=", "Variable", "(", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "kernel_mus", "(", "n_kernels", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "n_kernels", ")", "\n", "self", ".", "sigma", "=", "Variable", "(", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "kernel_sigmas", "(", "n_kernels", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "n_kernels", ")", "\n", "\n", "self", ".", "convolutions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "n_grams", "+", "1", ")", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConstantPad1d", "(", "(", "0", ",", "i", "-", "1", ")", ",", "0", ")", ",", "\n", "nn", ".", "Conv1d", "(", "kernel_size", "=", "i", ",", "in_channels", "=", "word_embeddings", ".", "get_output_dim", "(", ")", ",", "out_channels", "=", "conv_out_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", ")", "\n", "", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", "self", ".", "convolutions", ")", "# register conv as part of the model", "\n", "\n", "\n", "# this does not really do \"attention\" - just a plain cosine matrix calculation (without learnable weights) ", "\n", "self", ".", "cosine_module", "=", "CosineMatrixAttention", "(", ")", "\n", "\n", "# *9 because we concat the 3x3 conv match sums together before the dense layer", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "n_kernels", "*", "n_grams", "*", "n_grams", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "# init with small weights, otherwise the dense output is way to high fot", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "dense", ".", "weight", ",", "-", "0.014", ",", "0.014", ")", "# inits taken from matchzoo", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.forward": [[54, 126], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "query_embeddings.transpose", "document_embeddings.transpose", "enumerate", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv_knrm.Conv_KNRM.dense", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "len", "query_pad_mask.unsqueeze", "document_pad_mask.unsqueeze().transpose", "conv_knrm.Conv_KNRM.word_embeddings", "query_pad_oov_mask.unsqueeze", "conv_knrm.Conv_KNRM.word_embeddings", "document_pad_oov_mask.unsqueeze", "conv().transpose", "conv().transpose", "query_results.append", "document_results.append", "len", "range", "len", "matched_results.append", "document_pad_mask.unsqueeze", "conv", "conv", "conv_knrm.Conv_KNRM.forward_matrix_kernel_pooling", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.forward_matrix_kernel_pooling"], ["", "def", "forward", "(", "self", ",", "query", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "document", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "query_length", ":", "torch", ".", "Tensor", ",", "document_length", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "#", "\n", "# prepare embedding tensors", "\n", "# -------------------------------------------------------", "\n", "\n", "# we assume 1 is the unknown token, 0 is padding - both need to be removed", "\n", "        ", "if", "len", "(", "query", "[", "\"tokens\"", "]", ".", "shape", ")", "==", "2", ":", "# (embedding lookup matrix)", "\n", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "query", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "document", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "\n", "# shape: (batch, query_max)", "\n", "query_pad_mask", "=", "(", "query", "[", "\"tokens\"", "]", ">", "0", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_mask", "=", "(", "document", "[", "\"tokens\"", "]", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "", "else", ":", "# == 3 (elmo characters per word)", "\n", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "query", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "query_pad_mask", "=", "query_pad_oov_mask", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "document", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "document_pad_mask", "=", "document_pad_oov_mask", "\n", "\n", "", "query_by_doc_mask", "=", "torch", ".", "bmm", "(", "query_pad_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "document_pad_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "#query_by_doc_mask_view = query_by_doc_mask.unsqueeze(-1)", "\n", "\n", "# shape: (batch, query_max,emb_dim)", "\n", "query_embeddings", "=", "self", ".", "word_embeddings", "(", "query", ")", "*", "query_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# shape: (batch, document_max,emb_dim)", "\n", "document_embeddings", "=", "self", ".", "word_embeddings", "(", "document", ")", "*", "document_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# !! conv1d requires tensor in shape: [batch, emb_dim, sequence_length ]", "\n", "# so we transpose embedding tensors from : [batch, sequence_length,emb_dim] to [batch, emb_dim, sequence_length ]", "\n", "# feed that into the conv1d and reshape output from [batch, conv1d_out_channels, sequence_length ] ", "\n", "# to [batch, sequence_length, conv1d_out_channels]", "\n", "\n", "query_embeddings_t", "=", "query_embeddings", ".", "transpose", "(", "1", ",", "2", ")", "\n", "document_embeddings_t", "=", "document_embeddings", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "query_results", "=", "[", "]", "\n", "document_results", "=", "[", "]", "\n", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convolutions", ")", ":", "\n", "            ", "query_conv", "=", "conv", "(", "query_embeddings_t", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "document_conv", "=", "conv", "(", "document_embeddings_t", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "query_results", ".", "append", "(", "query_conv", ")", "\n", "document_results", ".", "append", "(", "document_conv", ")", "\n", "\n", "", "matched_results", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "query_results", ")", ")", ":", "\n", "            ", "for", "t", "in", "range", "(", "len", "(", "query_results", ")", ")", ":", "\n", "                ", "matched_results", ".", "append", "(", "self", ".", "forward_matrix_kernel_pooling", "(", "query_results", "[", "i", "]", ",", "document_results", "[", "t", "]", ",", "query_by_doc_mask", ",", "query_pad_mask", ")", ")", "\n", "\n", "#", "\n", "# \"Learning to rank\" layer", "\n", "# -------------------------------------------------------", "\n", "\n", "", "", "all_grams", "=", "torch", ".", "cat", "(", "matched_results", ",", "1", ")", "\n", "\n", "dense_out", "=", "self", ".", "dense", "(", "all_grams", ")", "\n", "#tanh_out = torch.tanh(dense_out)", "\n", "\n", "output", "=", "torch", ".", "squeeze", "(", "dense_out", ",", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.forward_matrix_kernel_pooling": [[130, 157], ["conv_knrm.Conv_KNRM.cosine_module.forward", "cosine_matrix_masked.unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "query_by_doc_mask.unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "query_pad_oov_mask.unsqueeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward"], ["", "def", "forward_matrix_kernel_pooling", "(", "self", ",", "query_tensor", ",", "document_tensor", ",", "query_by_doc_mask", ",", "query_pad_oov_mask", ")", ":", "\n", "\n", "#", "\n", "# cosine matrix", "\n", "# -------------------------------------------------------", "\n", "# shape: (batch, query_max, doc_max)", "\n", "\n", "        ", "cosine_matrix", "=", "self", ".", "cosine_module", ".", "forward", "(", "query_tensor", ",", "document_tensor", ")", "\n", "cosine_matrix_masked", "=", "cosine_matrix", "*", "query_by_doc_mask", "\n", "cosine_matrix_extradim", "=", "cosine_matrix_masked", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "#", "\n", "# gaussian kernels & soft-TF", "\n", "#", "\n", "# first run through kernel, then sum on doc dim then sum on query dim", "\n", "# -------------------------------------------------------", "\n", "\n", "raw_kernel_results", "=", "torch", ".", "exp", "(", "-", "torch", ".", "pow", "(", "cosine_matrix_extradim", "-", "self", ".", "mu", ",", "2", ")", "/", "(", "2", "*", "torch", ".", "pow", "(", "self", ".", "sigma", ",", "2", ")", ")", ")", "\n", "kernel_results_masked", "=", "raw_kernel_results", "*", "query_by_doc_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "per_kernel_query", "=", "torch", ".", "sum", "(", "kernel_results_masked", ",", "2", ")", "\n", "log_per_kernel_query", "=", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "per_kernel_query", ",", "min", "=", "1e-10", ")", ")", "*", "0.01", "\n", "log_per_kernel_query_masked", "=", "log_per_kernel_query", "*", "query_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "# make sure we mask out padding values", "\n", "\n", "per_kernel", "=", "torch", ".", "sum", "(", "log_per_kernel_query_masked", ",", "1", ")", "\n", "\n", "return", "per_kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_mus": [[158, 173], ["l_mu.append", "range", "l_mu.append"], "methods", ["None"], ["", "def", "kernel_mus", "(", "self", ",", "n_kernels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        get the mu for each guassian kernel. Mu is the middle of each bin\n        :param n_kernels: number of kernels (including exact match). first one is exact match\n        :return: l_mu, a list of mu.\n        \"\"\"", "\n", "l_mu", "=", "[", "1.0", "]", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_mu", "\n", "\n", "", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "# score range from [-1, 1]", "\n", "l_mu", ".", "append", "(", "1", "-", "bin_size", "/", "2", ")", "# mu: middle of the bin", "\n", "for", "i", "in", "range", "(", "1", ",", "n_kernels", "-", "1", ")", ":", "\n", "            ", "l_mu", ".", "append", "(", "l_mu", "[", "i", "]", "-", "bin_size", ")", "\n", "", "return", "l_mu", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.conv_knrm.Conv_KNRM.kernel_sigmas": [[174, 189], ["None"], "methods", ["None"], ["", "def", "kernel_sigmas", "(", "self", ",", "n_kernels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        get sigmas for each guassian kernel.\n        :param n_kernels: number of kernels (including exactmath.)\n        :param lamb:\n        :param use_exact:\n        :return: l_sigma, a list of simga\n        \"\"\"", "\n", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "\n", "l_sigma", "=", "[", "0.001", "]", "# for exact match. small variance -> exact match", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_sigma", "\n", "\n", "", "l_sigma", "+=", "[", "0.5", "*", "bin_size", "]", "*", "(", "n_kernels", "-", "1", ")", "\n", "return", "l_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.__init__": [[29, 61], ["torch.Module.__init__", "allennlp.modules.matrix_attention.cosine_matrix_attention.CosineMatrixAttention", "collections.OrderedDict", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Exception", "len", "torch.ConstantPad2d", "torch.ConstantPad2d", "torch.ConstantPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "len", "len", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "word_embeddings", ":", "TextFieldEmbedder", ",", "\n", "conv_output_size", ":", "List", "[", "int", "]", ",", "\n", "conv_kernel_size", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "adaptive_pooling_size", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ")", ":", "\n", "\n", "        ", "super", "(", "MatchPyramid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embeddings", "=", "word_embeddings", "\n", "self", ".", "cosine_module", "=", "CosineMatrixAttention", "(", ")", "\n", "#self.cosine_module = DotProductMatrixAttention()", "\n", "\n", "if", "len", "(", "conv_output_size", ")", "!=", "len", "(", "conv_kernel_size", ")", "or", "len", "(", "conv_output_size", ")", "!=", "len", "(", "adaptive_pooling_size", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"conv_output_size, conv_kernel_size, adaptive_pooling_size must have the same length\"", ")", "\n", "\n", "", "conv_layer_dict", "=", "OrderedDict", "(", ")", "\n", "last_channel_out", "=", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_output_size", ")", ")", ":", "\n", "            ", "conv_layer_dict", "[", "\"pad \"", "+", "str", "(", "i", ")", "]", "=", "nn", ".", "ConstantPad2d", "(", "(", "0", ",", "conv_kernel_size", "[", "i", "]", "[", "0", "]", "-", "1", ",", "0", ",", "conv_kernel_size", "[", "i", "]", "[", "1", "]", "-", "1", ")", ",", "0", ")", "\n", "conv_layer_dict", "[", "\"conv \"", "+", "str", "(", "i", ")", "]", "=", "nn", ".", "Conv2d", "(", "kernel_size", "=", "conv_kernel_size", "[", "i", "]", ",", "in_channels", "=", "last_channel_out", ",", "out_channels", "=", "conv_output_size", "[", "i", "]", ")", "\n", "conv_layer_dict", "[", "\"relu \"", "+", "str", "(", "i", ")", "]", "=", "nn", ".", "ReLU", "(", ")", "\n", "conv_layer_dict", "[", "\"pool \"", "+", "str", "(", "i", ")", "]", "=", "nn", ".", "AdaptiveMaxPool2d", "(", "adaptive_pooling_size", "[", "i", "]", ")", "# this is strange - but so written in the paper", "\n", "# would think only to pool at the end ??", "\n", "last_channel_out", "=", "conv_output_size", "[", "i", "]", "\n", "\n", "", "self", ".", "conv_layers", "=", "nn", ".", "Sequential", "(", "conv_layer_dict", ")", "\n", "\n", "#self.dropout = nn.Dropout(0)", "\n", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "conv_output_size", "[", "-", "1", "]", "*", "adaptive_pooling_size", "[", "-", "1", "]", "[", "0", "]", "*", "adaptive_pooling_size", "[", "-", "1", "]", "[", "1", "]", ",", "out_features", "=", "100", ",", "bias", "=", "True", ")", "\n", "self", ".", "dense2", "=", "nn", ".", "Linear", "(", "100", ",", "out_features", "=", "10", ",", "bias", "=", "True", ")", "\n", "self", ".", "dense3", "=", "nn", ".", "Linear", "(", "10", ",", "out_features", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward": [[66, 127], ["matchpyramid.MatchPyramid.cosine_module.forward", "matchpyramid.MatchPyramid.conv_layers", "matchpyramid.MatchPyramid.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "matchpyramid.MatchPyramid.dense3", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "len", "matchpyramid.MatchPyramid.word_embeddings", "query_pad_oov_mask.unsqueeze", "matchpyramid.MatchPyramid.word_embeddings", "document_pad_oov_mask.unsqueeze", "matchpyramid.MatchPyramid.size", "matchpyramid.MatchPyramid.dense", "matchpyramid.MatchPyramid.dense2", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.models.matchpyramid.MatchPyramid.forward"], ["", "def", "forward", "(", "self", ",", "query", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "document", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "query_length", ":", "torch", ".", "Tensor", ",", "document_length", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# pylint: disable=arguments-differ", "\n", "\n", "#", "\n", "# prepare embedding tensors", "\n", "# -------------------------------------------------------", "\n", "\n", "# we assume 1 is the unknown token, 0 is padding - both need to be removed", "\n", "        ", "if", "len", "(", "query", "[", "\"tokens\"", "]", ".", "shape", ")", "==", "2", ":", "# (embedding lookup matrix)", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "query", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "document", "[", "\"tokens\"", "]", ">", "1", ")", ".", "float", "(", ")", "\n", "", "else", ":", "# == 3 (elmo characters per word)", "\n", "# shape: (batch, query_max)", "\n", "            ", "query_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "query", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "# shape: (batch, doc_max)", "\n", "document_pad_oov_mask", "=", "(", "torch", ".", "sum", "(", "document", "[", "\"tokens\"", "]", ",", "2", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "# shape: (batch, query_max,emb_dim)", "\n", "", "query_embeddings", "=", "self", ".", "word_embeddings", "(", "query", ")", "*", "query_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# shape: (batch, document_max,emb_dim)", "\n", "document_embeddings", "=", "self", ".", "word_embeddings", "(", "document", ")", "*", "document_pad_oov_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "#", "\n", "# similarity matrix", "\n", "# -------------------------------------------------------", "\n", "\n", "cosine_matrix", "=", "self", ".", "cosine_module", ".", "forward", "(", "query_embeddings", ",", "document_embeddings", ")", "\n", "# shape: (batch, 1, query_max, doc_max) for the input of conv_2d", "\n", "cosine_matrix", "=", "cosine_matrix", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "\n", "#", "\n", "# convolution", "\n", "# -------------------------------------------------------", "\n", "# shape: (batch, conv_output_size, query_max, doc_max) ", "\n", "\n", "conv_result", "=", "self", ".", "conv_layers", "(", "cosine_matrix", ")", "\n", "\n", "#", "\n", "# dynamic pooling", "\n", "# -------------------------------------------------------", "\n", "\n", "# flatten the output of dynamic pooling", "\n", "\n", "# shape: (batch, conv_output_size * pool_h * pool_w) ", "\n", "conv_result_flat", "=", "conv_result", ".", "view", "(", "conv_result", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "#conv_result_flat = self.dropout(conv_result_flat)", "\n", "\n", "#", "\n", "# Learning to rank layer", "\n", "# -------------------------------------------------------", "\n", "dense_out", "=", "F", ".", "relu", "(", "self", ".", "dense", "(", "conv_result_flat", ")", ")", "\n", "dense_out", "=", "F", ".", "relu", "(", "self", ".", "dense2", "(", "dense_out", ")", ")", "\n", "dense_out", "=", "self", ".", "dense3", "(", "dense_out", ")", "\n", "#tanh_out = torch.tanh(dense_out)", "\n", "\n", "output", "=", "torch", ".", "squeeze", "(", "dense_out", ",", "1", ")", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference_from_stream": [[21, 39], ["l.strip().split.strip().split", "int", "qids_to_relevant_passageids[].append", "int", "IOError", "l.strip().split.strip"], "function", ["None"], ["def", "load_reference_from_stream", "(", "f", ")", ":", "\n", "    ", "\"\"\"Load Reference reference relevant passages\n    Args:f (stream): stream to load.\n    Returns:qids_to_relevant_passageids (dict): dictionary mapping from query_id (int) to relevant passages (list of ints). \n    \"\"\"", "\n", "qids_to_relevant_passageids", "=", "{", "}", "\n", "for", "l", "in", "f", ":", "\n", "        ", "try", ":", "\n", "            ", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "qid", "=", "int", "(", "l", "[", "0", "]", ")", "\n", "if", "qid", "in", "qids_to_relevant_passageids", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "qids_to_relevant_passageids", "[", "qid", "]", "=", "[", "]", "\n", "", "qids_to_relevant_passageids", "[", "qid", "]", ".", "append", "(", "int", "(", "l", "[", "2", "]", ")", ")", "# changed here from original for new qrel format", "\n", "", "except", ":", "\n", "            ", "raise", "IOError", "(", "'\\\"%s\\\" is not valid format'", "%", "l", ")", "\n", "", "", "return", "qids_to_relevant_passageids", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference": [[40, 48], ["open", "msmarco_eval.load_reference_from_stream"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference_from_stream"], ["", "def", "load_reference", "(", "path_to_reference", ")", ":", "\n", "    ", "\"\"\"Load Reference reference relevant passages\n    Args:path_to_reference (str): path to a file to load.\n    Returns:qids_to_relevant_passageids (dict): dictionary mapping from query_id (int) to relevant passages (list of ints). \n    \"\"\"", "\n", "with", "open", "(", "path_to_reference", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "qids_to_relevant_passageids", "=", "load_reference_from_stream", "(", "f", ")", "\n", "", "return", "qids_to_relevant_passageids", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate_from_stream": [[49, 78], ["l.strip().split.strip().split", "len", "int", "int", "int", "len", "int", "int", "int", "print", "l.strip().split.strip"], "function", ["None"], ["", "def", "load_candidate_from_stream", "(", "f", ")", ":", "\n", "    ", "\"\"\"Load candidate data from a stream.\n    Args:f (stream): stream to load.\n    Returns:qid_to_ranked_candidate_passages (dict): dictionary mapping from query_id (int) to a list of 1000 passage ids(int) ranked by relevance and importance\n    \"\"\"", "\n", "qid_to_ranked_candidate_passages", "=", "{", "}", "\n", "for", "l", "in", "f", ":", "\n", "        ", "try", ":", "\n", "            ", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n", "if", "len", "(", "l", ")", "==", "4", ":", "# own format", "\n", "                ", "qid", "=", "int", "(", "l", "[", "0", "]", ")", "\n", "pid", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "rank", "=", "int", "(", "l", "[", "2", "]", ")", "\n", "", "if", "len", "(", "l", ")", "==", "6", ":", "# original trec format", "\n", "                ", "qid", "=", "int", "(", "l", "[", "0", "]", ")", "\n", "pid", "=", "int", "(", "l", "[", "2", "]", ")", "\n", "rank", "=", "int", "(", "l", "[", "3", "]", ")", "\n", "", "if", "qid", "in", "qid_to_ranked_candidate_passages", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "# By default, all PIDs in the list of 1000 are 0. Only override those that are given", "\n", "                ", "tmp", "=", "[", "0", "]", "*", "1000", "\n", "qid_to_ranked_candidate_passages", "[", "qid", "]", "=", "tmp", "\n", "", "qid_to_ranked_candidate_passages", "[", "qid", "]", "[", "rank", "-", "1", "]", "=", "pid", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"error for \"", ",", "l", ")", "\n", "#raise IOError('\\\"%s\\\" is not valid format' % l)", "\n", "", "", "return", "qid_to_ranked_candidate_passages", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate_from_stream_with_score": [[79, 98], ["l.strip().split.strip().split", "int", "int", "int", "float", "qid_to_ranked_candidate_passages[].append", "IOError", "l.strip().split.strip"], "function", ["None"], ["", "def", "load_candidate_from_stream_with_score", "(", "f", ")", ":", "\n", "    ", "\"\"\"Load candidate data from a stream.\n    Args:f (stream): stream to load.\n    Returns:qid_to_ranked_candidate_passages (dict): dictionary mapping from query_id (int) to a list of 1000 passage ids(int) ranked by relevance and importance\n    \"\"\"", "\n", "qid_to_ranked_candidate_passages", "=", "{", "}", "\n", "for", "l", "in", "f", ":", "\n", "        ", "try", ":", "\n", "            ", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "qid", "=", "int", "(", "l", "[", "0", "]", ")", "\n", "pid", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "rank", "=", "int", "(", "l", "[", "2", "]", ")", "\n", "score", "=", "float", "(", "l", "[", "3", "]", ")", "\n", "if", "qid", "not", "in", "qid_to_ranked_candidate_passages", ":", "\n", "                ", "qid_to_ranked_candidate_passages", "[", "qid", "]", "=", "[", "]", "\n", "", "qid_to_ranked_candidate_passages", "[", "qid", "]", ".", "append", "(", "(", "pid", ",", "rank", ",", "score", ")", ")", "\n", "", "except", ":", "\n", "            ", "raise", "IOError", "(", "'\\\"%s\\\" is not valid format'", "%", "l", ")", "\n", "", "", "return", "qid_to_ranked_candidate_passages", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate": [[99, 108], ["open", "msmarco_eval.load_candidate_from_stream"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate_from_stream"], ["", "def", "load_candidate", "(", "path_to_candidate", ")", ":", "\n", "    ", "\"\"\"Load candidate data from a file.\n    Args:path_to_candidate (str): path to file to load.\n    Returns:qid_to_ranked_candidate_passages (dict): dictionary mapping from query_id (int) to a list of 1000 passage ids(int) ranked by relevance and importance\n    \"\"\"", "\n", "\n", "with", "open", "(", "path_to_candidate", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "qid_to_ranked_candidate_passages", "=", "load_candidate_from_stream", "(", "f", ")", "\n", "", "return", "qid_to_ranked_candidate_passages", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.quality_checks_qids": [[109, 147], ["set", "set", "qids_to_ranked_candidate_passages.keys", "qids_to_relevant_passageids.keys", "set", "len", "collections.Counter().items", "set", "list", "collections.Counter"], "function", ["None"], ["", "def", "quality_checks_qids", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ")", ":", "\n", "    ", "\"\"\"Perform quality checks on the dictionaries\n\n    Args:\n    p_qids_to_relevant_passageids (dict): dictionary of query-passage mapping\n        Dict as read in with load_reference or load_reference_from_stream\n    p_qids_to_ranked_candidate_passages (dict): dictionary of query-passage candidates\n    Returns:\n        bool,str: Boolean whether allowed, message to be shown in case of a problem\n    \"\"\"", "\n", "message", "=", "''", "\n", "allowed", "=", "True", "\n", "\n", "# Create sets of the QIDs for the submitted and reference queries", "\n", "candidate_set", "=", "set", "(", "qids_to_ranked_candidate_passages", ".", "keys", "(", ")", ")", "\n", "ref_set", "=", "set", "(", "qids_to_relevant_passageids", ".", "keys", "(", ")", ")", "\n", "\n", "# Check whether the queries match the evaluation set", "\n", "if", "candidate_set", "!=", "ref_set", ":", "\n", "        ", "if", "candidate_set", ">=", "ref_set", ":", "\n", "# This is to be expected, since we have split the evaluation set in validation & test", "\n", "            ", "pass", "\n", "", "elif", "candidate_set", "<", "ref_set", ":", "\n", "            ", "message", "=", "\"Not all queries seem to be ranked. Are you scoring the right set?\"", "\n", "", "else", ":", "\n", "            ", "message", "=", "\"The submitted queries do not fully match the queries in the evaluation set. Are you scoring the right set?\"", "\n", "\n", "# Check that we do not have multiple passages per query", "\n", "", "", "for", "qid", "in", "qids_to_ranked_candidate_passages", ":", "\n", "# Remove all zeros from the candidates", "\n", "        ", "duplicate_pids", "=", "set", "(", "[", "item", "for", "item", ",", "count", "in", "Counter", "(", "qids_to_ranked_candidate_passages", "[", "qid", "]", ")", ".", "items", "(", ")", "if", "count", ">", "1", "]", ")", "\n", "\n", "if", "len", "(", "duplicate_pids", "-", "set", "(", "[", "0", "]", ")", ")", ">", "0", ":", "\n", "            ", "message", "=", "\"Cannot rank a passage multiple times for a single query. QID={qid}, PID={pid}\"", ".", "format", "(", "\n", "qid", "=", "qid", ",", "pid", "=", "list", "(", "duplicate_pids", ")", "[", "0", "]", ")", "\n", "allowed", "=", "False", "\n", "\n", "", "", "return", "allowed", ",", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics": [[148, 189], ["len", "sum", "sum", "statistics.mean", "statistics.median", "statistics.mean", "statistics.median", "statistics.harmonic_mean", "len", "IOError", "len", "ranking.append", "range", "str", "str", "ranking.pop", "ranking.append"], "function", ["None"], ["", "def", "compute_metrics", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ",", "MaxMRRRank", "=", "10", ")", ":", "\n", "    ", "\"\"\"Compute MRR metric\n    Args:    \n    p_qids_to_relevant_passageids (dict): dictionary of query-passage mapping\n        Dict as read in with load_reference or load_reference_from_stream\n    p_qids_to_ranked_candidate_passages (dict): dictionary of query-passage candidates\n    Returns:\n        dict: dictionary of metrics {'MRR': <MRR Score>}\n    \"\"\"", "\n", "all_scores", "=", "{", "}", "\n", "MRR", "=", "0", "\n", "qids_with_relevant_passages", "=", "0", "\n", "ranking", "=", "[", "]", "\n", "for", "qid", "in", "qids_to_ranked_candidate_passages", ":", "\n", "        ", "if", "qid", "in", "qids_to_relevant_passageids", ":", "\n", "            ", "ranking", ".", "append", "(", "0", ")", "\n", "target_pid", "=", "qids_to_relevant_passageids", "[", "qid", "]", "\n", "candidate_pid", "=", "qids_to_ranked_candidate_passages", "[", "qid", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "MaxMRRRank", ")", ":", "\n", "                ", "if", "candidate_pid", "[", "i", "]", "in", "target_pid", ":", "\n", "                    ", "MRR", "+=", "1", "/", "(", "i", "+", "1", ")", "\n", "ranking", ".", "pop", "(", ")", "\n", "ranking", ".", "append", "(", "i", "+", "1", ")", "\n", "break", "\n", "\n", "", "", "", "", "if", "len", "(", "ranking", ")", "==", "0", ":", "\n", "        ", "raise", "IOError", "(", "\"No matching QIDs found. Are you sure you are scoring the evaluation set?\"", ")", "\n", "\n", "", "MRR", "=", "MRR", "/", "len", "(", "ranking", ")", "\n", "all_scores", "[", "'MRR'", "]", "=", "MRR", "\n", "all_scores", "[", "'QueriesRanked'", "]", "=", "len", "(", "ranking", ")", "\n", "all_scores", "[", "'QueriesWithNoRelevant'", "]", "=", "sum", "(", "(", "1", "for", "x", "in", "ranking", "if", "x", "==", "0", ")", ")", "\n", "all_scores", "[", "'QueriesWithRelevant'", "]", "=", "sum", "(", "(", "1", "for", "x", "in", "ranking", "if", "x", ">", "0", ")", ")", "\n", "\n", "all_scores", "[", "'AverageRankGoldLabel@'", "+", "str", "(", "MaxMRRRank", ")", "]", "=", "statistics", ".", "mean", "(", "(", "x", "for", "x", "in", "ranking", "if", "x", ">", "0", ")", ")", "\n", "all_scores", "[", "'MedianRankGoldLabel@'", "+", "str", "(", "MaxMRRRank", ")", "]", "=", "statistics", ".", "median", "(", "(", "x", "for", "x", "in", "ranking", "if", "x", ">", "0", ")", ")", "\n", "\n", "all_scores", "[", "'AverageRankGoldLabel'", "]", "=", "statistics", ".", "mean", "(", "ranking", ")", "\n", "all_scores", "[", "'MedianRankGoldLabel'", "]", "=", "statistics", ".", "median", "(", "ranking", ")", "\n", "all_scores", "[", "'HarmonicMeanRankingGoldLabel'", "]", "=", "statistics", ".", "harmonic_mean", "(", "ranking", ")", "\n", "return", "all_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_from_files": [[190, 214], ["msmarco_eval.load_reference", "msmarco_eval.load_candidate", "msmarco_eval.compute_metrics", "msmarco_eval.quality_checks_qids", "print"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.quality_checks_qids"], ["", "def", "compute_metrics_from_files", "(", "path_to_reference", ",", "path_to_candidate", ",", "perform_checks", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute MRR metric\n    Args:    \n    p_path_to_reference_file (str): path to reference file.\n        Reference file should contain lines in the following format:\n            QUERYID\\tPASSAGEID\n            Where PASSAGEID is a relevant passage for a query. Note QUERYID can repeat on different lines with different PASSAGEIDs\n    p_path_to_candidate_file (str): path to candidate file.\n        Candidate file sould contain lines in the following format:\n            QUERYID\\tPASSAGEID1\\tRank\n            If a user wishes to use the TREC format please run the script with a -t flag at the end. If this flag is used the expected format is \n            QUERYID\\tITER\\tDOCNO\\tRANK\\tSIM\\tRUNID \n            Where the values are separated by tabs and ranked in order of relevance \n    Returns:\n        dict: dictionary of metrics {'MRR': <MRR Score>}\n    \"\"\"", "\n", "\n", "qids_to_relevant_passageids", "=", "load_reference", "(", "path_to_reference", ")", "\n", "qids_to_ranked_candidate_passages", "=", "load_candidate", "(", "path_to_candidate", ")", "\n", "if", "perform_checks", ":", "\n", "        ", "allowed", ",", "message", "=", "quality_checks_qids", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ")", "\n", "if", "message", "!=", "''", ":", "print", "(", "message", ")", "\n", "\n", "", "return", "compute_metrics", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_with_cs_at_n": [[215, 219], ["msmarco_eval.load_reference", "msmarco_eval.load_candidate", "msmarco_eval.compute_metrics_with_cs_at_n_memory"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_with_cs_at_n_memory"], ["", "def", "compute_metrics_with_cs_at_n", "(", "path_to_reference", ",", "path_to_neural_output", ",", "candidate_set", ",", "candidate_from_to", ",", "perform_checks", "=", "True", ")", ":", "\n", "    ", "qids_to_relevant_passageids", "=", "load_reference", "(", "path_to_reference", ")", "\n", "qids_to_ranked_candidate_passages", "=", "load_candidate", "(", "path_to_neural_output", ")", "\n", "return", "compute_metrics_with_cs_at_n_memory", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ",", "candidate_set", ",", "candidate_from_to", ",", "perform_checks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_with_cs_at_n_memory": [[220, 264], ["msmarco_eval.quality_checks_qids", "type", "range", "qids_to_ranked_candidate_passages.items", "msmarco_eval.compute_metrics", "print", "qids_to_ranked_candidate_passages.items", "msmarco_eval.compute_metrics", "enumerate", "enumerate"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.quality_checks_qids", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics"], ["", "def", "compute_metrics_with_cs_at_n_memory", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ",", "candidate_set", ",", "candidate_from_to", ",", "perform_checks", "=", "True", ")", ":", "\n", "\n", "    ", "if", "perform_checks", ":", "\n", "        ", "allowed", ",", "message", "=", "quality_checks_qids", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ")", "\n", "if", "message", "!=", "''", ":", "print", "(", "message", ")", "\n", "\n", "", "if", "type", "(", "candidate_from_to", ")", "!=", "int", ":", "\n", "\n", "        ", "results", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "candidate_from_to", "[", "0", "]", ",", "candidate_from_to", "[", "1", "]", "+", "1", ")", ":", "\n", "\n", "            ", "pruned_qids_to_ranked_candidate_passages", "=", "{", "}", "\n", "\n", "for", "query", ",", "rank_list", "in", "qids_to_ranked_candidate_passages", ".", "items", "(", ")", ":", "#qid_to_ranked_candidate_passages[qid][rank-1]=pid", "\n", "                ", "pruned_qids_to_ranked_candidate_passages", "[", "query", "]", "=", "[", "0", "]", "*", "1000", "\n", "added", "=", "0", "\n", "for", "rank", ",", "pid", "in", "enumerate", "(", "rank_list", ")", ":", "\n", "                    ", "if", "pid", "==", "0", ":", "# 0 means no more entries > 0 ", "\n", "                        ", "break", "\n", "\n", "#rank = rank + 1", "\n", "", "if", "pid", "in", "candidate_set", "[", "query", "]", "and", "candidate_set", "[", "query", "]", "[", "pid", "]", "<=", "i", ":", "\n", "                        ", "pruned_qids_to_ranked_candidate_passages", "[", "query", "]", "[", "added", "]", "=", "pid", "\n", "added", "+=", "1", "\n", "\n", "\n", "", "", "", "results", "[", "i", "]", "=", "compute_metrics", "(", "qids_to_relevant_passageids", ",", "pruned_qids_to_ranked_candidate_passages", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "else", ":", "# assume single number", "\n", "        ", "pruned_qids_to_ranked_candidate_passages", "=", "{", "}", "\n", "\n", "for", "query", ",", "rank_list", "in", "qids_to_ranked_candidate_passages", ".", "items", "(", ")", ":", "#qid_to_ranked_candidate_passages[qid][rank-1]=pid", "\n", "            ", "pruned_qids_to_ranked_candidate_passages", "[", "query", "]", "=", "[", "0", "]", "*", "1000", "\n", "added", "=", "0", "\n", "for", "rank", ",", "pid", "in", "enumerate", "(", "rank_list", ")", ":", "\n", "                ", "if", "pid", "==", "0", ":", "# 0 means no more entries > 0 ", "\n", "                    ", "break", "\n", "", "if", "pid", "in", "candidate_set", "[", "query", "]", "and", "candidate_set", "[", "query", "]", "[", "pid", "]", "<=", "candidate_from_to", ":", "\n", "                    ", "pruned_qids_to_ranked_candidate_passages", "[", "query", "]", "[", "added", "]", "=", "pid", "\n", "added", "+=", "1", "\n", "\n", "", "", "", "return", "compute_metrics", "(", "qids_to_relevant_passageids", ",", "pruned_qids_to_ranked_candidate_passages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.main": [[266, 310], ["len", "msmarco_eval.compute_metrics_from_files", "print", "sorted", "print", "print", "len", "msmarco_eval.load_reference", "msmarco_eval.load_candidate", "list", "msmarco_eval.compute_metrics", "print", "sorted", "print", "print", "exit", "open", "load_candidate.keys", "print", "load_candidate.pop", "int", "line.split"], "function", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics_from_files", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_reference", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.load_candidate", "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.evaluation.msmarco_eval.compute_metrics"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Command line:\n    python msmarco_eval_ranking.py <path_to_reference_file> <path_to_candidate_file>\n    \n    or: \n    \n    python msmarco_eval_ranking.py <path_to_reference_file> <path_to_candidate_file> <path_to_query-id_subset_file>\n    \"\"\"", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "3", ":", "\n", "        ", "path_to_reference", "=", "sys", ".", "argv", "[", "1", "]", "\n", "path_to_candidate", "=", "sys", ".", "argv", "[", "2", "]", "\n", "metrics", "=", "compute_metrics_from_files", "(", "path_to_reference", ",", "path_to_candidate", ")", "\n", "print", "(", "'#####################'", ")", "\n", "for", "metric", "in", "sorted", "(", "metrics", ")", ":", "\n", "            ", "print", "(", "'{}: {}'", ".", "format", "(", "metric", ",", "metrics", "[", "metric", "]", ")", ")", "\n", "", "print", "(", "'#####################'", ")", "\n", "\n", "", "elif", "len", "(", "sys", ".", "argv", ")", "==", "4", ":", "\n", "        ", "path_to_reference", "=", "sys", ".", "argv", "[", "1", "]", "\n", "path_to_candidate", "=", "sys", ".", "argv", "[", "2", "]", "\n", "path_to_query_to_select", "=", "sys", ".", "argv", "[", "3", "]", "\n", "\n", "qids_to_relevant_passageids", "=", "load_reference", "(", "path_to_reference", ")", "\n", "qids_to_ranked_candidate_passages", "=", "load_candidate", "(", "path_to_candidate", ")", "\n", "\n", "select_queries", "=", "{", "}", "\n", "with", "open", "(", "path_to_query_to_select", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "select_queries", "[", "int", "(", "line", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "]", "=", "1", "\n", "\n", "", "", "for", "q", "in", "list", "(", "qids_to_ranked_candidate_passages", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "q", "not", "in", "select_queries", ":", "\n", "                ", "qids_to_ranked_candidate_passages", ".", "pop", "(", "q", ",", "None", ")", "\n", "\n", "", "", "metrics", "=", "compute_metrics", "(", "qids_to_relevant_passageids", ",", "qids_to_ranked_candidate_passages", ")", "\n", "\n", "print", "(", "'#####################'", ")", "\n", "for", "metric", "in", "sorted", "(", "metrics", ")", ":", "\n", "            ", "print", "(", "'{}: {}'", ".", "format", "(", "metric", ",", "metrics", "[", "metric", "]", ")", ")", "\n", "", "print", "(", "'#####################'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Usage: msmarco_eval_ranking.py <reference ranking> <candidate ranking>'", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_triple_loader.IrTripleDatasetReader.__init__": [[42, 55], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "source_add_start_token", ":", "bool", "=", "True", ",", "\n", "max_doc_length", ":", "int", "=", "-", "1", ",", "\n", "max_query_length", ":", "int", "=", "-", "1", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "WordTokenizer", "(", ")", "# little bit faster, useful for multicore proc. word_splitter=SimpleWordSplitter()", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "lowercase_tokens", "=", "True", ")", "}", "\n", "self", ".", "_source_add_start_token", "=", "source_add_start_token", "\n", "self", ".", "max_doc_length", "=", "max_doc_length", "\n", "self", ".", "max_query_length", "=", "max_query_length", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_triple_loader.IrTripleDatasetReader._read": [[56, 71], ["open", "enumerate", "allennlp.common.file_utils.cached_path", "line.strip.strip.strip", "line.strip.strip.split", "len", "allennlp.common.checks.ConfigurationError", "ir_triple_loader.IrTripleDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "data_file", ":", "\n", "#logger.info(\"Reading instances from lines in file at: %s\", file_path)", "\n", "            ", "for", "line_num", ",", "line", "in", "enumerate", "(", "data_file", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "\n", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "\n", "", "line_parts", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "line_parts", ")", "!=", "3", ":", "\n", "                    ", "raise", "ConfigurationError", "(", "\"Invalid line format: %s (line number %d)\"", "%", "(", "line", ",", "line_num", "+", "1", ")", ")", "\n", "", "query_sequence", ",", "doc_pos_sequence", ",", "doc_neg_sequence", "=", "line_parts", "\n", "yield", "self", ".", "text_to_instance", "(", "query_sequence", ",", "doc_pos_sequence", ",", "doc_neg_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_triple_loader.IrTripleDatasetReader.text_to_instance": [[72, 111], ["ir_triple_loader.IrTripleDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "ir_triple_loader.IrTripleDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "ir_triple_loader.IrTripleDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp.data.fields.LabelField", "allennlp.data.fields.LabelField", "allennlp.data.fields.LabelField", "allennlp.data.instance.Instance", "len", "len", "len"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "query_sequence", ":", "str", ",", "doc_pos_sequence", ":", "str", ",", "doc_neg_sequence", ":", "str", ")", "->", "Instance", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "query_tokenized", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "query_sequence", ")", "\n", "#if self._source_add_start_token:", "\n", "#    query_tokenized.insert(0, Token(START_SYMBOL))", "\n", "#query_tokenized.append(Token(END_SYMBOL))", "\n", "if", "self", ".", "max_query_length", ">", "-", "1", ":", "\n", "            ", "query_tokenized", "=", "query_tokenized", "[", ":", "self", ".", "max_query_length", "]", "\n", "\n", "", "query_field", "=", "TextField", "(", "query_tokenized", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "doc_pos_tokenized", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "doc_pos_sequence", ")", "\n", "#doc_pos_tokenized.insert(0, Token(START_SYMBOL))", "\n", "#doc_pos_tokenized.append(Token(END_SYMBOL))", "\n", "if", "self", ".", "max_doc_length", ">", "-", "1", ":", "\n", "            ", "doc_pos_tokenized", "=", "doc_pos_tokenized", "[", ":", "self", ".", "max_doc_length", "]", "\n", "\n", "", "doc_pos_field", "=", "TextField", "(", "doc_pos_tokenized", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "doc_neg_tokenized", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "doc_neg_sequence", ")", "\n", "#doc_neg_tokenized.insert(0, Token(START_SYMBOL))", "\n", "#doc_neg_tokenized.append(Token(END_SYMBOL))", "\n", "if", "self", ".", "max_doc_length", ">", "-", "1", ":", "\n", "            ", "doc_neg_tokenized", "=", "doc_neg_tokenized", "[", ":", "self", ".", "max_doc_length", "]", "\n", "\n", "", "doc_neg_field", "=", "TextField", "(", "doc_neg_tokenized", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "query_length", "=", "LabelField", "(", "len", "(", "query_tokenized", ")", ",", "skip_indexing", "=", "True", ")", "\n", "doc_pos_length", "=", "LabelField", "(", "len", "(", "doc_pos_tokenized", ")", ",", "skip_indexing", "=", "True", ")", "\n", "doc_neg_length", "=", "LabelField", "(", "len", "(", "doc_neg_tokenized", ")", ",", "skip_indexing", "=", "True", ")", "\n", "\n", "return", "Instance", "(", "{", "\n", "\"query_tokens\"", ":", "query_field", ",", "\n", "\"doc_pos_tokens\"", ":", "doc_pos_field", ",", "\n", "\"doc_neg_tokens\"", ":", "doc_neg_field", ",", "\n", "\"query_length\"", ":", "query_length", ",", "\n", "\"doc_pos_length\"", ":", "doc_pos_length", ",", "\n", "\"doc_neg_length\"", ":", "doc_neg_length", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_labeled_tuple_loader.IrLabeledTupleDatasetReader.__init__": [[43, 56], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "source_add_start_token", ":", "bool", "=", "True", ",", "\n", "max_doc_length", ":", "int", "=", "-", "1", ",", "\n", "max_query_length", ":", "int", "=", "-", "1", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "WordTokenizer", "(", ")", "# little bit faster, useful for multicore proc. word_splitter=SimpleWordSplitter()", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "lowercase_tokens", "=", "True", ")", "}", "\n", "self", ".", "_source_add_start_token", "=", "source_add_start_token", "\n", "self", ".", "max_doc_length", "=", "max_doc_length", "\n", "self", ".", "max_query_length", "=", "max_query_length", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_labeled_tuple_loader.IrLabeledTupleDatasetReader._read": [[57, 72], ["open", "enumerate", "allennlp.common.file_utils.cached_path", "line.strip.strip.strip", "line.strip.strip.split", "len", "allennlp.common.checks.ConfigurationError", "ir_labeled_tuple_loader.IrLabeledTupleDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "data_file", ":", "\n", "#logger.info(\"Reading instances from lines in file at: %s\", file_path)", "\n", "            ", "for", "line_num", ",", "line", "in", "enumerate", "(", "data_file", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "\n", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "\n", "", "line_parts", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "line_parts", ")", "!=", "4", ":", "\n", "                    ", "raise", "ConfigurationError", "(", "\"Invalid line format: %s (line number %d)\"", "%", "(", "line", ",", "line_num", "+", "1", ")", ")", "\n", "", "query_id", ",", "doc_id", ",", "query_sequence", ",", "doc_sequence", "=", "line_parts", "\n", "yield", "self", ".", "text_to_instance", "(", "query_id", ",", "doc_id", ",", "query_sequence", ",", "doc_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_labeled_tuple_loader.IrLabeledTupleDatasetReader.text_to_instance": [[73, 107], ["allennlp.data.fields.LabelField", "allennlp.data.fields.LabelField", "ir_labeled_tuple_loader.IrLabeledTupleDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "ir_labeled_tuple_loader.IrLabeledTupleDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp.data.fields.LabelField", "allennlp.data.fields.LabelField", "allennlp.data.instance.Instance", "int", "int", "len", "len"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "query_id", ":", "str", ",", "doc_id", ":", "str", ",", "query_sequence", ":", "str", ",", "doc_sequence", ":", "str", ")", "->", "Instance", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ", "\n", "\n", "        ", "query_id_field", "=", "LabelField", "(", "int", "(", "query_id", ")", ",", "skip_indexing", "=", "True", ")", "\n", "doc_id_field", "=", "LabelField", "(", "int", "(", "doc_id", ")", ",", "skip_indexing", "=", "True", ")", "\n", "\n", "query_tokenized", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "query_sequence", ")", "\n", "#if self._source_add_start_token:", "\n", "#    query_tokenized.insert(0, Token(START_SYMBOL))", "\n", "#query_tokenized.append(Token(END_SYMBOL))", "\n", "if", "self", ".", "max_query_length", ">", "-", "1", ":", "\n", "            ", "query_tokenized", "=", "query_tokenized", "[", ":", "self", ".", "max_query_length", "]", "\n", "\n", "", "query_field", "=", "TextField", "(", "query_tokenized", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "doc_tokenized", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "doc_sequence", ")", "\n", "#doc_tokenized.insert(0, Token(START_SYMBOL))", "\n", "#doc_tokenized.append(Token(END_SYMBOL))", "\n", "if", "self", ".", "max_doc_length", ">", "-", "1", ":", "\n", "            ", "doc_tokenized", "=", "doc_tokenized", "[", ":", "self", ".", "max_doc_length", "]", "\n", "\n", "", "doc_field", "=", "TextField", "(", "doc_tokenized", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "query_length", "=", "LabelField", "(", "len", "(", "query_tokenized", ")", ",", "skip_indexing", "=", "True", ")", "\n", "doc_length", "=", "LabelField", "(", "len", "(", "doc_tokenized", ")", ",", "skip_indexing", "=", "True", ")", "\n", "\n", "return", "Instance", "(", "{", "\n", "\"query_id\"", ":", "query_id_field", ",", "\n", "\"doc_id\"", ":", "doc_id_field", ",", "\n", "\"query_tokens\"", ":", "query_field", ",", "\n", "\"doc_tokens\"", ":", "doc_field", ",", "\n", "\"query_length\"", ":", "query_length", ",", "\n", "\"doc_length\"", ":", "doc_length", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader.__init__": [[51, 65], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "source_tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "target_tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "source_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "target_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "source_add_start_token", ":", "bool", "=", "True", ",", "\n", "lowercase", ":", "bool", "=", "True", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_source_tokenizer", "=", "source_tokenizer", "or", "WordTokenizer", "(", ")", "#word_splitter=SimpleWordSplitter()", "\n", "self", ".", "_target_tokenizer", "=", "target_tokenizer", "or", "self", ".", "_source_tokenizer", "\n", "self", ".", "_source_token_indexers", "=", "source_token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "lowercase_tokens", "=", "lowercase", ")", "}", "\n", "self", ".", "_target_token_indexers", "=", "target_token_indexers", "or", "self", ".", "_source_token_indexers", "\n", "self", ".", "_source_add_start_token", "=", "source_add_start_token", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader._read": [[66, 81], ["open", "logger.info", "enumerate", "allennlp.common.file_utils.cached_path", "line.strip.strip.strip", "line.strip.strip.split", "len", "allennlp.common.checks.ConfigurationError", "ir_tuple_loader.IrTupleDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "for", "line_num", ",", "line", "in", "enumerate", "(", "data_file", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "\n", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "\n", "", "line_parts", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "line_parts", ")", "!=", "2", ":", "\n", "                    ", "raise", "ConfigurationError", "(", "\"Invalid line format: %s (line number %d)\"", "%", "(", "line", ",", "line_num", "+", "1", ")", ")", "\n", "", "source_sequence", ",", "target_sequence", "=", "line_parts", "\n", "yield", "self", ".", "text_to_instance", "(", "source_sequence", ",", "target_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.ir_tuple_loader.IrTupleDatasetReader.text_to_instance": [[82, 93], ["ir_tuple_loader.IrTupleDatasetReader._source_tokenizer.tokenize", "allennlp.data.fields.TextField", "ir_tuple_loader.IrTupleDatasetReader._target_tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp.data.instance.Instance"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "source_string", ":", "str", ",", "target_string", ":", "str", "=", "None", ")", "->", "Instance", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ", "\n", "\n", "        ", "tokenized_source", "=", "self", ".", "_source_tokenizer", ".", "tokenize", "(", "source_string", ")", "\n", "source_field", "=", "TextField", "(", "tokenized_source", ",", "self", ".", "_source_token_indexers", ")", "\n", "\n", "tokenized_target", "=", "self", ".", "_target_tokenizer", ".", "tokenize", "(", "target_string", ")", "\n", "target_field", "=", "TextField", "(", "tokenized_target", ",", "self", ".", "_target_token_indexers", ")", "\n", "\n", "return", "Instance", "(", "{", "\"source_tokens\"", ":", "source_field", ",", "\"target_tokens\"", ":", "target_field", "}", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextVocab.__init__": [[15, 20], ["torch.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mapping", ",", "shared_tensor", ",", "max_subwords", ")", "->", "None", ":", "\n", "        ", "self", ".", "mapping", "=", "mapping", "\n", "self", ".", "data", "=", "shared_tensor", "\n", "self", ".", "max_subwords", "=", "max_subwords", "\n", "self", ".", "default", "=", "torch", ".", "zeros", "(", "max_subwords", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextVocab.get_subword_ids": [[21, 29], ["None"], "methods", ["None"], ["", "def", "get_subword_ids", "(", "self", ",", "word", ")", ":", "\n", "#print(word)", "\n", "        ", "if", "word", "not", "in", "self", ".", "mapping", ":", "\n", "            ", "return", "self", ".", "default", "\n", "\n", "#print(self.mapping[word],self.data[self.mapping[word]])", "\n", "\n", "", "return", "self", ".", "data", "[", "self", ".", "mapping", "[", "word", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextVocab.load_ids": [[30, 46], ["open", "enumerate", "torch.IntTensor", "l.rstrip().split.rstrip().split.rstrip().split", "enumerate", "data.append", "int", "l.rstrip().split.rstrip().split.rstrip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_ids", "(", "file", ",", "max_subwords", ")", ":", "\n", "        ", "mapping", "=", "{", "}", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "in_file", ":", "\n", "            ", "for", "i", ",", "l", "in", "enumerate", "(", "in_file", ")", ":", "\n", "                ", "l", "=", "l", ".", "rstrip", "(", ")", ".", "split", "(", ")", "\n", "\n", "ids", "=", "[", "0", "]", "*", "max_subwords", "\n", "for", "k", ",", "val", "in", "enumerate", "(", "l", "[", "1", ":", "max_subwords", "]", ")", ":", "\n", "                    ", "ids", "[", "k", "]", "=", "int", "(", "val", ")", "\n", "\n", "", "mapping", "[", "l", "[", "0", "]", "]", "=", "i", "\n", "data", ".", "append", "(", "ids", ")", "\n", "\n", "", "", "return", "mapping", ",", "torch", ".", "IntTensor", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.__init__": [[58, 63], ["torch.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "max_subwords", ",", "\n", "namespace", ":", "str", "=", "'fasttext_grams'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "def_padding", "=", "torch", ".", "zeros", "(", "max_subwords", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.count_vocab_items": [[64, 67], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.tokens_to_indices": [[68, 80], ["any", "token.text.lower", "allennlp.common.checks.ConfigurationError", "vocabulary.get_subword_ids"], "methods", ["home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextVocab.get_subword_ids"], ["", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "FastTextVocab", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "texts", "=", "[", "token", ".", "text", ".", "lower", "(", ")", "for", "token", "in", "tokens", "]", "\n", "\n", "if", "any", "(", "text", "is", "None", "for", "text", "in", "texts", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'FastTextNGramIndexer needs a tokenizer '", "\n", "'that retains text'", ")", "\n", "", "return", "{", "index_name", ":", "[", "vocabulary", ".", "get_subword_ids", "(", "text", ")", "for", "text", "in", "texts", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.get_padding_lengths": [[81, 85], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "List", "[", "int", "]", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.get_padding_token": [[86, 89], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_token", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer._default_value_for_padding": [[90, 92], ["None"], "methods", ["None"], ["", "def", "_default_value_for_padding", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "def_padding", "\n", "\n"]], "home.repos.pwc.inspect_result.sebastian-hofstaetter_sigir19-neural-ir.dataloaders.fasttext_token_indexer.FastTextNGramIndexer.pad_token_sequence": [[93, 102], ["torch.stack().long", "tokens.items", "torch.stack", "allennlp.common.util.pad_sequence_to_length"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "pad_token_sequence", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "torch", ".", "stack", "(", "pad_sequence_to_length", "(", "val", ",", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "self", ".", "_default_value_for_padding", ")", ")", ".", "long", "(", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "", "", ""]]}